title,authors,url,abstract,abstract_ja,avg_rating,figure1_or_table1
How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks,"['Keyulu Xu', 'Mozhi Zhang', 'Jingling Li', 'Simon Shaolei Du', 'Ken-Ichi Kawarabayashi', 'Stefanie Jegelka']",https://openreview.net/forum?id=UH-cmocLJC,"We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while multilayer perceptrons (MLPs) do not extrapolate well in certain simple tasks, Graph Neural Network (GNN), a structured network with MLP modules, has shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most non-linear functions. But, they provably learn a linear target function when the training distribution is sufficiently ""diverse"". Second, in connection to analyzing successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of overparameterized networks to the neural tangent kernel. Empirically, our theory holds across different training settings.",勾配降下法によってトレーニングされたニューラルネットワークがどのように外挿するか、つまり、トレーニング分布のサポート外で学習することを研究します。以前の研究では、ニューラルネットワークで外挿すると、さまざまな経験的結果が報告されています。多層パーセプトロン（MLP）は特定の単純なタスクではうまく外挿できませんが、MLPモジュールを備えた構造化ネットワークであるグラフニューラルネットワーク（GNN）は、より複雑なタスクである程度の成功を収めています。理論的な説明に向けて、MLPとGNNが適切に外挿する条件を特定します。まず、ReLU MLPが原点から任意の方向に沿って線形関数にすばやく収束するという観察結果を定量化します。これは、ReLUMLPがほとんどの非線形関数を外挿しないことを意味します。しかし、トレーニング分布が十分に「多様」である場合、彼らは線形ターゲット関数を確実に学習します。第二に、GNNの成功と制限の分析に関連して、これらの結果は、理論的および経験的証拠を提供する仮説を示唆しています。アルゴリズムタスクを新しいデータ（たとえば、より大きなグラフやエッジの重み）に外挿する際のGNNの成功は、エンコードタスクに依存します。 -アーキテクチャまたは機能の特定の非線形性。私たちの理論的分析は、パラメータ化されたネットワークのニューラルタンジェントカーネルへの接続に基づいています。経験的に、私たちの理論はさまざまなトレーニング設定に当てはまります。,8.75,https://d3i71xaburhd42.cloudfront.net/e307bc8b8371b91ada2c0f165998d07b81ba14cd/4-Figure1-1.png
Dataset Condensation with Gradient Matching,"['Bo Zhao', 'Konda Reddy Mopuri', 'Hakan Bilen']",https://openreview.net/forum?id=mSAKhLYLSsl,"As the state-of-the-art machine learning methods in many fields rely on larger datasets, storing them and training models on them becomes more expensive. This paper proposes a training set synthesis technique for \emph{data-efficient} learning, called \emph{Dataset Condensation}, that learns to condense a large dataset into a small set of informative samples for training deep neural networks from scratch. We formulate this goal as a gradient matching problem between the gradients of a deep neural network trained on the original data and our synthetic data. We rigorously evaluate its performance in several computer vision benchmarks and demonstrate that it significantly outperforms the state-of-the-art methods. Finally we explore the use of our method in continual learning and neural architecture search and show that it achieves promising gains on a tight budget of memory and computations.",多くの分野の最先端の機械学習方法はより大きなデータセットに依存しているため、それらを保存してモデルをトレーニングすることはより高価になります。このペーパーでは、データセット凝縮と呼ばれるデータ効率の高い学習のためのトレーニングセット合成手法を提案します。これは、ディープニューラルネットワークを最初からトレーニングするために、大きなデータセットを小さなセットの有益なサンプルに凝縮することを学習します。この目標は、元のデータと合成データでトレーニングされたディープニューラルネットワークの勾配間の勾配マッチング問題として定式化されます。いくつかのコンピュータービジョンベンチマークでそのパフォーマンスを厳密に評価し、最先端の方法を大幅に上回っていることを示しています。最後に、継続的な学習とニューラルアーキテクチャの検索での方法の使用を検討し、メモリと計算の厳しい予算で有望な利益を達成することを示します。,8.33,https://d3i71xaburhd42.cloudfront.net/5a94bcc168330318d3020aa4d41bd73cf68ab285/2-Figure1-1.png
Learning Generalizable Visual Representations via Interactive Gameplay,"['Luca Weihs', 'Aniruddha Kembhavi', 'Kiana Ehsani', 'Sarah M Pratt', 'Winson Han', 'Alvaro Herrasti', 'Eric Kolve', 'Dustin Schwenk', 'Roozbeh Mottaghi', 'Ali Farhadi']",https://openreview.net/forum?id=UuchYL8wSZo,"A growing body of research suggests that embodied gameplay, prevalent not just in human cultures but across a variety of animal species including turtles and ravens, is critical in developing the neural flexibility for creative problem solving, decision making, and socialization. Comparatively little is known regarding the impact of embodied gameplay upon artificial agents. While recent work has produced agents proficient in abstract games, these environments are far removed the real world and thus these agents can provide little insight into the advantages of embodied play. Hiding games, such as hide-and-seek, played universally, provide a rich ground for studying the impact of embodied gameplay on representation learning in the context of perspective taking, secret keeping, and false belief understanding. Here we are the first to show that embodied adversarial reinforcement learning agents playing Cache, a variant of hide-and-seek, in a high fidelity, interactive, environment, learn generalizable representations of their observations encoding information such as object permanence, free space, and containment. Moving closer to biologically motivated learning strategies, our agents' representations, enhanced by intentionality and memory, are developed through interaction and play. These results serve as a model for studying how facets of vision develop through interaction, provide an experimental framework for assessing what is learned by artificial agents, and demonstrates the value of moving from large, static, datasets towards experiential, interactive, representation learning.",研究の増加は、人間の文化だけでなく、カメやカラスを含むさまざまな動物種に普及している具体化されたゲームプレイが、創造的な問題解決、意思決定、および社会化のための神経の柔軟性を開発する上で重要であることを示唆しています。人工的なエージェントに対する具体化されたゲームプレイの影響に関しては、比較的ほとんど知られていません。最近の仕事は抽象ゲームに堪能なエージェントを生み出しましたが、これらの環境は現実の世界から遠く離れているため、これらのエージェントは具体化された遊びの利点についてほとんど洞察を提供できません。かくれんぼなどの隠しゲームは、普遍的にプレイされ、視点の取得、秘密の保持、誤った信念の理解のコンテキストで、表現学習に対する具体化されたゲームプレイの影響を研究するための豊富な基盤を提供します。ここでは、ハイドアンドシークの変形であるキャッシュを再生する具体化された敵対的強化学習エージェントが、忠実度の高いインタラクティブな環境で、オブジェクトの永続性、自由空間などの情報をエンコードする観察の一般化可能な表現を学習することを初めて示しました。と封じ込め。生物学的に動機付けられた学習戦略に近づくと、志向性と記憶によって強化されたエージェントの表現は、相互作用と遊びを通して開発されます。これらの結果は、視覚のファセットが相互作用を通じてどのように発達するかを研究するためのモデルとして機能し、人工エージェントによって学習されたものを評価するための実験的フレームワークを提供し、大規模で静的なデータセットから体験的でインタラクティブな表現学習に移行することの価値を示します。,8.25,
Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding,"['David A. Klindt', 'Lukas Schott', 'Yash Sharma', 'Ivan Ustyuzhaninov', 'Wieland Brendel', 'Matthias Bethge', 'Dylan Paiton']",https://openreview.net/forum?id=EbIDjBynYJ8,"Disentangling the underlying generative factors from complex data has so far been limited to carefully constructed scenarios. We propose a path towards natural data by first showing that the statistics of natural data provide enough structure to enable disentanglement, both theoretically and empirically. Specifically, we provide evidence that objects in natural movies undergo transitions that are typically small in magnitude with occasional large jumps, which is characteristic of a temporally sparse distribution. To address this finding we provide a novel proof that relies on a sparse prior on temporally adjacent observations to recover the true latent variables up to permutations and sign flips, directly providing a stronger result than previous work. We show that equipping practical estimation methods with our prior often surpasses the current state-of-the-art on several established benchmark datasets without any impractical assumptions, such as knowledge of the number of changing generative factors. Furthermore, we contribute two new benchmarks, Natural Sprites and KITTI Masks, which integrate the measured natural dynamics to enable disentanglement evaluation with more realistic datasets. We leverage these benchmarks to test our theory, demonstrating improved performance. We also identify non-obvious challenges for current methods in scaling to more natural domains. Taken together our work addresses key issues in disentanglement research for moving towards more natural settings. ",複雑なデータから根本的な生成要因を解きほぐすことは、これまで慎重に構築されたシナリオに限定されていました。自然データの統計が理論的にも経験的にも解きほぐしを可能にするのに十分な構造を提供することを最初に示すことによって、自然データへの道を提案します。具体的には、自然の映画のオブジェクトは、時間的にまばらな分布の特徴である、時折大きなジャンプを伴う通常は大きさが小さい遷移を経るという証拠を提供します。この発見に対処するために、時間的に隣接する観測値のスパース事前確率に依存して、順列と符号反転まで真の潜在変数を回復し、以前の作業よりも強力な結果を直接提供する新しい証明を提供します。実用的な推定方法を以前のものに装備することは、変化する生成要因の数の知識などの非実用的な仮定なしに、いくつかの確立されたベンチマークデータセットの現在の最先端を超えることが多いことを示します。さらに、2つの新しいベンチマーク、NaturalSpritesとKITTIMasksを提供します。これらは、測定された自然のダイナミクスを統合して、より現実的なデータセットで解きほぐしの評価を可能にします。これらのベンチマークを活用して理論をテストし、パフォーマンスの向上を実証します。また、より自然なドメインへのスケーリングにおける現在の方法の非自明な課題を特定します。一緒に私たちの仕事は、より自然な設定に向かって移動するための解きほぐし研究の重要な問題に対処します。,8.25,
On the mapping between Hopfield networks and Restricted Boltzmann Machines,"['Matthew Smart', 'Anton Zilman']",https://openreview.net/forum?id=RGJbergVIoO,"Hopfield networks (HNs) and Restricted Boltzmann Machines (RBMs) are two important models at the interface of statistical physics, machine learning, and neuroscience. Recently, there has been interest in the relationship between HNs and RBMs, due to their similarity under the statistical mechanics formalism. An exact mapping between HNs and RBMs has been previously noted for the special case of orthogonal (“uncorrelated”) encoded patterns. We present here an exact mapping in the general case of correlated pattern HNs, which are more broadly applicable to existing datasets. Specifically, we show that any HN with $N$ binary variables and $p<N$ potentially correlated binary patterns can be transformed into an RBM with $N$ binary visible variables and $p$ gaussian hidden variables. We outline the conditions under which the reverse mapping exists, and conduct experiments on the MNIST dataset which suggest the mapping provides a useful initialization to the RBM weights. We discuss extensions, the potential importance of this correspondence for the training of RBMs, and for understanding the performance of feature extraction methods which utilize RBMs.",ホップフィールドネットワーク（HN）と制限付きボルツマンマシン（RBM）は、統計物理学、機械学習、および神経科学のインターフェースにおける2つの重要なモデルです。最近、統計力学の形式の下での類似性のために、HNとRBMの関係に関心が集まっています。 HNとRBMの間の正確なマッピングは、直交する（相関のない）エンコードされたパターンの特殊なケースについて以前に指摘されています。ここでは、相関パターンHNの一般的なケースでの正確なマッピングを示します。これは、既存のデータセットにより広く適用できます。具体的には、N個のバイナリ変数とp &lt;N個の潜在的に相関するバイナリパターンを持つHNを、N個のバイナリ可視変数とp個のガウス隠れ変数を持つRBMに変換できることを示します。逆マッピングが存在する条件の概要を説明し、MNISTデータセットで実験を行って、マッピングがRBMの重みに有用な初期化を提供することを示唆します。拡張、RBMのトレーニング、およびRBMを利用する特徴抽出方法のパフォーマンスを理解するためのこの対応の潜在的な重要性について説明します。,8.0,https://d3i71xaburhd42.cloudfront.net/593d8f1de69f6f335609e1f0e6b3ae83ce4e3116/3-Figure1-1.png
Learning a Latent Simplex in Input Sparsity Time,"['Ainesh Bakshi', 'Chiranjib Bhattacharyya', 'Ravi Kannan', 'David Woodruff', 'Samson Zhou']",https://openreview.net/forum?id=04LZCAxMSco,"We consider the problem of learning a latent $k$-vertex simplex $K\in\mathbb{R}^d$, given $\mathbf{A}\in\mathbb{R}^{d\times n}$, which can be viewed as $n$ data points that are formed by randomly perturbing some latent points in $K$, possibly beyond $K$. A large class of latent variable models, such as adversarial clustering, mixed membership stochastic block models, and topic models can be cast in this view of learning a latent simplex. Bhattacharyya and Kannan (SODA 2020) give an algorithm for learning such a $k$-vertex latent simplex in time roughly $O(k\cdot\text{nnz}(\mathbf{A}))$, where $\text{nnz}(\mathbf{A})$ is the number of non-zeros in $\mathbf{A}$. We show that the dependence on $k$ in the running time is unnecessary given a natural assumption about the mass of the top $k$ singular values of $\mathbf{A}$, which holds in many of these applications. Further, we show this assumption is necessary, as otherwise an algorithm for learning a latent simplex would imply a better low rank approximation algorithm than what is known. 

We obtain a spectral low-rank approximation to $\mathbf{A}$ in input-sparsity time and show that the column space thus obtained has small $\sin\Theta$ (angular) distance to the right top-$k$ singular space of $\mathbf{A}$. Our algorithm then selects $k$ points in the low-rank  subspace with the largest inner product (in absolute value) with $k$ carefully chosen random vectors. By working in the low-rank subspace, we avoid reading the entire matrix in each iteration and thus circumvent the $\Theta(k\cdot\text{nnz}(\mathbf{A}))$ running time.",AR ^（dn）が与えられた場合、潜在的なk頂点シンプレックスKR ^（d）を学習する問題を検討します。これは、K内のいくつかの潜在点をランダムに摂動することによって形成されるn個のデータ点と見なすことができます。潜在シンプレックスを学習するというこのビューでは、敵対的クラスタリング、混合メンバーシップ確率ブロックモデル、トピックモデルなどの潜在変数モデルの大規模なクラスをキャストできます。 BhattacharyyaとKannan（SODA 2020）は、このようなk頂点の潜在シンプレックスを時間でおよそO（k nnz（A））で学習するためのアルゴリズムを提供します。ここで、nnz（A）はAの非ゼロの数です。これらのアプリケーションの多くに当てはまる、Aの上位k個の特異値の質量に関する自然な仮定を考えると、実行時間のkへの依存は不要です。さらに、潜在シンプレックスを学習するためのアルゴリズムは、既知のものよりも優れた低ランク近似アルゴリズムを意味するため、この仮定が必要であることを示します。入力スパーシティ時間でAのスペクトル低ランク近似を取得し、このようにして得られた列空間がAの右上k個の特異空間に対して小さいsin（角）距離を持っていることを示します。次に、アルゴリズムは低位のk点を選択します。 -慎重に選択されたk個のランダムベクトルを使用して、（絶対値で）最大の内積を持つ部分空間をランク付けします。下位の部分空間で作業することにより、各反復で行列全体を読み取ることを回避し、（k nnz（A））の実行時間を回避します。,8.0,
What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale Study,"['Marcin Andrychowicz', 'Anton Raichuk', 'Piotr Stańczyk', 'Manu Orsini', 'Sertan Girgin', 'Raphaël Marinier', 'Leonard Hussenot', 'Matthieu Geist', 'Olivier Pietquin', 'Marcin Michalski', 'Sylvain Gelly', 'Olivier Bachem']",https://openreview.net/forum?id=nIAxjsniDzg,"In recent years, reinforcement learning (RL) has been successfully applied to many different continuous control tasks. While RL algorithms are often conceptually simple, their state-of-the-art implementations take numerous low- and high-level design decisions that strongly affect the performance of the resulting agents. Those choices are usually not extensively discussed in the literature, leading to discrepancy between published descriptions of algorithms and their implementations. This makes it hard to attribute progress in RL and slows down overall progress [Engstrom'20]. As a step towards filling that gap, we implement >50 such ``""choices"" in a unified on-policy deep actor-critic framework, allowing us to investigate their impact in a large-scale empirical study. We train over 250'000 agents in five continuous control environments of different complexity and provide insights and practical recommendations for the training of on-policy deep actor-critic RL agents.",近年、強化学習（RL）は多くの異なる連続制御タスクにうまく適用されています。 RLアルゴリズムは概念的に単純であることがよくありますが、それらの最先端の実装は、結果として得られるエージェントのパフォーマンスに大きく影響する多数の低レベルおよび高レベルの設計上の決定を行います。これらの選択は通常、文献で広く議論されておらず、公開されているアルゴリズムの説明とその実装の間に矛盾が生じます。これにより、RLの進行状況を特定することが難しくなり、全体的な進行状況が遅くなります[Engstrom20]。そのギャップを埋めるためのステップとして、統一されたオンポリシーの深いアクター批評フレームワークに50を超えるそのような「選択」を実装し、大規模な実証研究でそれらの影響を調査できるようにします。複雑さの異なる5つの連続制御環境で250000を超えるエージェントをトレーニングし、ポリシーに準拠した深いアクター批評家のRLエージェントのトレーニングに関する洞察と実践的な推奨事項を提供します。,8.0,
Parameterization of Hypercomplex Multiplications,"['Aston Zhang', 'Yi Tay', 'SHUAI Zhang', 'Alvin Chan', 'Anh Tuan Luu', 'Siu Hui', 'Jie Fu']",https://openreview.net/forum?id=rcQdycl0zyk,"Recent works have demonstrated reasonable success of representation learning in hypercomplex space. Specifically, the Hamilton product (4D hypercomplex multiplication) enables learning effective representations while saving up to 75% parameters. However, one key caveat is that hypercomplex space only exists at very few predefined dimensions. This restricts the flexibility of models that leverage hypercomplex multiplications. To this end, we propose parameterizing hypercomplex multiplications, allowing models to learn multiplication rules from data regardless of whether such rules are predefined. As a result, our method not only subsumes the Hamilton product, but also learns to operate on any arbitrary nD hypercomplex space, providing more architectural flexibility. Experiments of applications to LSTM and Transformer on natural language inference, machine translation, text style transfer, and subject verb agreement demonstrate architectural flexibility and effectiveness of the proposed approach.",最近の研究は、超複雑な空間での表現学習の合理的な成功を示しています。具体的には、ハミルトン積（4D多元数乗算）により、最大75を節約しながら、効果的な表現を学習できます。,8.0,
Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data,"['Colin Wei', 'Kendrick Shen', 'Yining Chen', 'Tengyu Ma']",https://openreview.net/forum?id=rC8sJ4i6kaH,"Self-training algorithms, which train a model to fit pseudolabels predicted by another previously-learned model, have been very successful for learning with unlabeled data using neural networks. However, the current theoretical understanding of self-training only applies to linear models. This work provides a unified theoretical analysis of self-training with deep networks for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning. At the core of our analysis is a simple but realistic ``""expansion"" assumption, which states that a low-probability subset of the data must expand to a neighborhood with large probability relative to the subset. We also assume that neighborhoods of examples in different classes have minimal overlap. We prove that under these assumptions, the minimizers of population objectives based on self-training and input-consistency regularization will achieve high accuracy with respect to ground-truth labels. By using off-the-shelf generalization bounds, we immediately convert this result to sample complexity guarantees for neural nets that are polynomial in the margin and Lipschitzness. Our results help explain the empirical successes of recently proposed self-training algorithms which use input consistency regularization.",以前に学習した別のモデルによって予測された疑似ラベルに適合するようにモデルをトレーニングする自己トレーニングアルゴリズムは、ニューラルネットワークを使用したラベルなしデータでの学習に非常に成功しています。ただし、セルフトレーニングの現在の理論的理解は線形モデルにのみ適用されます。この作業は、半教師あり学習、教師なしドメイン適応、および教師なし学習のための深いネットワークを使用した自己トレーニングの統一された理論的分析を提供します。分析の中核となるのは、単純ですが現実的な「拡張」の仮定です。これは、データの確率の低いサブセットが、サブセットに比べて確率の高い近隣に拡張する必要があることを示しています。また、異なるクラスの例の近傍の重複は最小限であると想定しています。これらの仮定の下で、自己訓練と入力整合性の正則化に基づく人口目標の最小化は、グラウンドトゥルースラベルに関して高精度を達成することを証明します。既製の一般化境界を使用することにより、この結果を、マージンとリプシッツネスで多項式であるニューラルネットのサンプルの複雑さの保証にすぐに変換します。私たちの結果は、入力整合性の正則化を使用する最近提案された自己トレーニングアルゴリズムの経験的な成功を説明するのに役立ちます。,8.0,https://d3i71xaburhd42.cloudfront.net/481c2580f4647ee1fa9c6d7b8a07a23a25c79538/3-Figure1-1.png
Score-Based Generative Modeling through Stochastic Differential Equations,"['Yang Song', 'Jascha Sohl-Dickstein', 'Diederik P Kingma', 'Abhishek Kumar', 'Stefano Ermon', 'Ben Poole']",https://openreview.net/forum?id=PxTIG12RRHS,"Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and score-based generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of $1024\times 1024$ images for the first time from a score-based generative model.",データからノイズを作成するのは簡単です。ノイズからデータを作成することは生成モデリングです。ノイズをゆっくりと注入することによって複雑なデータ分布を既知の事前分布にスムーズに変換する確率微分方程式（SDE）と、ノイズをゆっくりと除去することによって事前分布をデータ分布に戻す対応する逆時間SDEを示します。重要なことに、逆時間SDEは、摂動されたデータ分布の時間依存勾配フィールド（別名、スコア）のみに依存します。スコアベースの生成モデリングの進歩を活用することで、ニューラルネットワークでこれらのスコアを正確に推定し、数値SDEソルバーを使用してサンプルを生成できます。このフレームワークが拡散確率モデリングとスコアベースの生成モデリングにおける以前のアプローチをカプセル化し、新しいサンプリング手順を可能にすることを示します。特に、離散化された逆時間SDEの進化におけるエラーを修正するための予測子修正子フレームワークを導入します。また、SDEと同じ分布からサンプリングする同等のニューラルODEを導出します。これにより、正確な尤度計算が可能になり、サンプリング効率が向上します。さらに、クラス条件付き生成、画像の修復、および色付けの実験で示すように、フレームワークでは無条件モデルを使用した条件付き生成が可能です。複数のアーキテクチャの改善と組み合わせることで、CIFAR-10での無条件の画像生成で記録的なパフォーマンスを達成します。開始スコアは9.89、FIDは2.20、競争力は3.10ビット/ dimであり、10241024画像の高忠実度生成を実証します。スコアベースの生成モデルから初めて。,8.0,https://d3i71xaburhd42.cloudfront.net/633e2fbfc0b21e959a244100937c5853afca4853/2-Figure1-1.png
Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes,"['Mike Gartrell', 'Insu Han', 'Elvis Dohmatob', 'Jennifer Gillenwater', 'Victor-Emmanuel Brunel']",https://openreview.net/forum?id=HajQFbx_yB,"Determinantal point processes (DPPs) have attracted significant attention in machine learning for their ability to model subsets drawn from a large item collection. Recent work shows that nonsymmetric DPP (NDPP) kernels have significant advantages over symmetric kernels in terms of modeling power and predictive performance. However, for an item collection of size $M$, existing NDPP learning and inference algorithms require memory quadratic in $M$ and runtime cubic (for learning) or quadratic (for inference) in $M$, making them impractical for many typical subset selection tasks. In this work, we develop a learning algorithm with space and time requirements linear in $M$ by introducing a new NDPP kernel decomposition. We also derive a linear-complexity NDPP maximum a posteriori (MAP) inference algorithm that applies not only to our new kernel but also to that of prior work. Through evaluation on real-world datasets, we show that our algorithms scale significantly better, and can match the predictive performance of prior work.",決定点過程（DPP）は、大規模なアイテムコレクションから抽出されたサブセットをモデル化できるため、機械学習で大きな注目を集めています。最近の研究によると、非対称DP​​P（NDPP）カーネルは、モデリング能力と予測パフォーマンスの点で対称カーネルよりも大きな利点があります。ただし、サイズMのアイテムコレクションの場合、既存のNDPP学習および推論アルゴリズムでは、Mで2次メモリ、Mで実行時2次（学習用）または2次（推論用）が必要であるため、多くの一般的なサブセット選択タスクでは実用的ではありません。この作業では、新しいNDPPカーネル分解を導入することにより、Mで線形の空間と時間の要件を持つ学習アルゴリズムを開発します。また、新しいカーネルだけでなく、以前の作業のカーネルにも適用される線形複雑度NDPP最大事後（MAP）推論アルゴリズムを導出します。実際のデータセットでの評価を通じて、アルゴリズムのスケーリングが大幅に向上し、以前の作業の予測パフォーマンスと一致できることを示しています。,8.0,https://d3i71xaburhd42.cloudfront.net/1a180e019dc2d194feb39a053ddfa60a780c248e/13-Figure2-1.png
Deformable DETR: Deformable Transformers for End-to-End Object Detection,"['Xizhou Zhu', 'Weijie Su', 'Lewei Lu', 'Bin Li', 'Xiaogang Wang', 'Jifeng Dai']",https://openreview.net/forum?id=gZ9hCDWe6ke,"DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10$\times$ less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code shall be released.",DETRは最近、優れたパフォーマンスを示しながら、オブジェクト検出で多くの手作業で設計されたコンポーネントの必要性を排除するために提案されました。ただし、画像の特徴マップを処理する際のTransformerアテンションモジュールの制限により、収束が遅く、特徴の空間解像度が制限されるという問題があります。これらの問題を軽減するために、Deformable DETRを提案しました。その注意モジュールは、参照の周りの主要なサンプリングポイントの小さなセットにのみ対応します。変形可能なDETRは、トレーニングエポックが10少ないため、DETR（特に小さなオブジェクト）よりも優れたパフォーマンスを実現できます。 COCOベンチマークに関する広範な実験は、私たちのアプローチの有効性を示しています。コードはリリースされます。,8.0,https://d3i71xaburhd42.cloudfront.net/39ca8f8ff28cc640e3b41a6bd7814ab85c586504/2-Figure1-1.png
Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting,"['Vincent LE GUEN', 'Yuan Yin', 'Jérémie DONA', 'Ibrahim Ayed', 'Emmanuel de Bezenac', 'Nicolas THOME', 'patrick gallinari']",https://openreview.net/forum?id=kmG8vRXTFv,"Forecasting complex dynamical phenomena in settings where only partial knowledge of their dynamics is available is a prevalent problem across various scientific fields. While purely data-driven approaches are arguably insufficient in this context, standard physical modeling based approaches tend to be over-simplistic, inducing non-negligible errors. In this work, we introduce the APHYNITY framework, a principled approach for augmenting incomplete physical dynamics described by differential equations with deep data-driven models. It consists in decomposing the dynamics into two components: a physical component accounting for the dynamics for which we have some prior knowledge, and a data-driven component accounting for errors of the physical model. The learning problem is carefully formulated such that the physical model explains as much of the data as possible, while the data-driven component only describes information that cannot be captured by the physical model, no more, no less. This not only provides the existence and uniqueness for this decomposition, but also ensures interpretability and benefits generalization. Experiments made on three important use cases, each representative of a different family of phenomena, i.e. reaction-diffusion equations, wave equations and the non-linear damped pendulum, show that APHYNITY can efficiently leverage approximate physical models to accurately forecast the evolution of the system and correctly identify relevant physical parameters.",ダイナミクスの部分的な知識しか利用できない状況で複雑なダイナミクス現象を予測することは、さまざまな科学分野で蔓延している問題です。このコンテキストでは、純粋にデータ駆動型のアプローチでは間違いなく不十分ですが、標準的な物理モデリングベースのアプローチは単純すぎる傾向があり、無視できないエラーが発生します。この作業では、APHYNITYフレームワークを紹介します。これは、深いデータ駆動型モデルを使用して微分方程式で記述された不完全な物理ダイナミクスを拡張するための原理的なアプローチです。これは、ダイナミクスを2つのコンポーネントに分解することで構成されます。1つは、事前の知識があるダイナミクスを説明する物理コンポーネント、もう1つは、物理モデルのエラーを説明するデータ駆動型コンポーネントです。学習問題は、物理モデルが可能な限り多くのデータを説明するように注意深く定式化されますが、データ駆動型コンポーネントは、物理モデルではキャプチャできない情報のみを説明します。それ以上でもそれ以下でもありません。これは、この分解の存在と一意性を提供するだけでなく、解釈可能性を保証し、一般化に役立ちます。反応拡散方程式、波動方程式、非線形減衰振り子など、それぞれが異なる現象ファミリーを表す3つの重要な使用例で行われた実験は、APHYNITYが近似物理モデルを効率的に活用してシステムの進化を正確に予測できることを示しています。関連する物理パラメータを正しく識別します。,8.0,
Complex Query Answering with Neural Link Predictors,"['Erik Arakelyan', 'Daniel Daza', 'Pasquale Minervini', 'Michael Cochez']",https://openreview.net/forum?id=Mos9F9kDwkz,"Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\land$), disjunctions ($\lor$) and existential quantifiers ($\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms.",ニューラルリンク予測子は、大規模な知識グラフで欠落しているエッジを識別するのに非常に役立ちます。ただし、これらのモデルを使用して、論理積（）、論理和（）、存在記号（）を使用するクエリなど、多くのドメインで発生するより複雑なクエリに応答する方法はまだ明確ではありませんが、欠落しているエッジを考慮しています。この作業では、不完全な知識グラフの複雑なクエリに効率的に答えるためのフレームワークを提案します。各クエリをエンドツーエンドの微分可能な目的に変換します。各アトムの真理値は、事前にトレーニングされたニューラルリンク予測子によって計算されます。次に、勾配ベースの検索と組み合わせ検索を含む、最適化問題の2つのソリューションを分析します。私たちの実験では、提案されたアプローチは、大規模で多様な一連の複雑なクエリのトレーニングを必要とせずに、生成された数百万のクエリでトレーニングされた最先端の方法のブラックボックスニューラルモデルよりも正確な結果を生成します。桁違いに少ないトレーニングデータを使用して、8からの範囲の相対的な改善を取得します,8.0,https://d3i71xaburhd42.cloudfront.net/62ba6604ed24c808062f89f8f41eda3b6a566917/2-Figure1-1.png
Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients,"['Brenden K Petersen', 'Mikel Landajuela Larma', 'Terrell N. Mundhenk', 'Claudio Prata Santiago', 'Soo Kyung Kim', 'Joanne Taery Kim']",https://openreview.net/forum?id=m5Qsh0kBQG,"Discovering the underlying mathematical expressions describing a dataset is a core challenge for artificial intelligence. This is the problem of symbolic regression. Despite recent advances in training neural networks to solve complex tasks, deep learning approaches to symbolic regression are underexplored. We propose a framework that leverages deep learning for symbolic regression via a simple idea: use a large model to search the space of small models. Specifically, we use a recurrent neural network to emit a distribution over tractable mathematical expressions and employ a novel risk-seeking policy gradient to train the network to generate better-fitting expressions. Our algorithm outperforms several baseline methods (including Eureqa, the gold standard for symbolic regression) in its ability to exactly recover symbolic expressions on a series of benchmark problems, both with and without added noise. More broadly, our contributions include a framework that can be applied to optimize hierarchical, variable-length objects under a black-box performance metric, with the ability to incorporate constraints in situ, and a risk-seeking policy gradient formulation that optimizes for best-case performance instead of expected performance.",データセットを説明する基礎となる数式を発見することは、人工知能の中心的な課題です。これがシンボリック回帰の問題です。複雑なタスクを解決するためのニューラルネットワークのトレーニングにおける最近の進歩にもかかわらず、シンボリック回帰への深層学習アプローチは十分に検討されていません。大きなモデルを使用して小さなモデルの空間を検索するという単純なアイデアを介して、シンボリック回帰の深層学習を活用するフレームワークを提案します。具体的には、リカレントニューラルネットワークを使用して扱いやすい数式の分布を出力し、新しいリスクを求めるポリシー勾配を使用してネットワークをトレーニングし、より適切な式を生成します。私たちのアルゴリズムは、ノイズが追加されている場合とされていない場合の両方で、一連のベンチマーク問題でシンボリック式を正確に回復する能力において、いくつかのベースライン手法（シンボリック回帰のゴールドスタンダードであるEureqaを含む）よりも優れています。より広義には、私たちの貢献には、ブラックボックスのパフォーマンスメトリックの下で階層的な可変長オブジェクトを最適化するために適用できるフレームワークと、その場で制約を組み込む機能、および最適化するリスクを追求するポリシー勾配の定式化が含まれます。期待されるパフォーマンスではなく、ケースのパフォーマンス。,8.0,
Learning Mesh-Based Simulation with Graph Networks,"['Tobias Pfaff', 'Meire Fortunato', 'Alvaro Sanchez-Gonzalez', 'Peter Battaglia']",https://openreview.net/forum?id=roNqYL0_XP,"Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, high-dimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied.
Here we introduce MeshGraphNets, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks.",メッシュベースのシミュレーションは、科学と工学の多くの分野で複雑な物理システムをモデル化する上で中心的な役割を果たします。メッシュ表現は強力な数値積分法をサポートし、その解像度を適応させて、精度と効率の間の有利なトレードオフを打つことができます。ただし、高次元の科学シミュレーションの実行には非常にコストがかかるため、ソルバーとパラメーターは、調査する各システムに合わせて個別に調整する必要があります。ここでは、グラフニューラルネットワークを使用してメッシュベースのシミュレーションを学習するためのフレームワークであるMeshGraphNetsを紹介します。私たちのモデルは、メッシュグラフでメッセージを渡し、フォワードシミュレーション中にメッシュの離散化を適応させるようにトレーニングできます。私たちの結果は、空気力学、構造力学、布など、さまざまな物理システムのダイナミクスを正確に予測できることを示しています。モデルの適応性は、解像度に依存しないダイナミクスの学習をサポートし、テスト時に、より複雑な状態空間に拡張できます。また、私たちの方法は非常に効率的であり、トレーニングされたシミュレーションよりも1〜2桁速く実行されます。私たちのアプローチは、ニューラルネットワークシミュレーターが動作できる問題の範囲を広げ、複雑で科学的なモデリングタスクの効率を改善することを約束します。,7.75,https://d3i71xaburhd42.cloudfront.net/ff82518fbec6ba368ce2d0dc9ba55f9419bac5fd/2-Figure1-1.png
Learning Cross-Domain Correspondence for Control with Dynamics Cycle-Consistency,"['Qiang Zhang', 'Tete Xiao', 'Alexei A Efros', 'Lerrel Pinto', 'Xiaolong Wang']",https://openreview.net/forum?id=QIRlze3I6hX,"At the heart of many robotics problems is the challenge of learning correspondences across domains. For instance, imitation learning requires obtaining correspondence between humans and robots; sim-to-real requires correspondence between physics simulators and real hardware; transfer learning requires correspondences between different robot environments. In this paper, we propose to learn correspondence across such domains emphasizing on differing modalities (vision and internal state), physics parameters (mass and friction), and morphologies (number of limbs). Importantly, correspondences are learned using unpaired and randomly collected data from the two domains. We propose dynamics cycles that align dynamic robotic behavior across two domains using a cycle consistency constraint. Once this correspondence is found, we can directly transfer the policy trained on one domain to the other, without needing any additional fine-tuning on the second domain. We perform experiments across a variety of problem domains, both in simulation and on real robots. Our framework is able to align uncalibrated monocular video of a real robot arm to dynamic state-action trajectories of a simulated arm without paired data. Video demonstrations of our results are available at: https://sites.google.com/view/cycledynamics .",多くのロボット工学の問題の中心にあるのは、ドメイン間の対応を学習するという課題です。たとえば、模倣学習では、人間とロボットの間の対応を取得する必要があります。 sim-to-realには、物理​​シミュレータと実際のハードウェア間の対応が必要です。転移学習には、異なるロボット環境間の対応が必要です。この論文では、異なるモダリティ（視覚と内部状態）、物理パラメータ（質量と摩擦）、および形態（手足の数）に重点を置いて、このようなドメイン間の対応を学習することを提案します。重要なことに、対応は、2つのドメインからペアになっていないランダムに収集されたデータを使用して学習されます。サイクル整合性制約を使用して、2つのドメイン間で動的なロボットの動作を調整するダイナミクスサイクルを提案します。この対応が見つかると、2番目のドメインで追加の微調整を行うことなく、1つのドメインでトレーニングされたポリシーを別のドメインに直接転送できます。シミュレーションと実際のロボットの両方で、さまざまな問題領域にわたって実験を行います。私たちのフレームワークは、実際のロボットアームのキャリブレーションされていない単眼ビデオを、ペアのデータなしでシミュレートされたアームの動的な状態-アクション軌道に合わせることができます。結果のビデオデモンストレーションは、https：//sites.google.com/view/cycledynamicsで入手できます。,7.75,https://d3i71xaburhd42.cloudfront.net/0003b8fef7d5e048a9870cdafdec27af129ae990/2-Figure1-1.png
Autoregressive Entity Retrieval,"['Nicola De Cao', 'Gautier Izacard', 'Sebastian Riedel', 'Fabio Petroni']",https://openreview.net/forum?id=5k8F6UU39V,"Entities are at the center of how we represent and aggregate knowledge. For instance, Encyclopedias such as Wikipedia are structured by entities (e.g., one per Wikipedia article). The ability to retrieve such entities given a query is fundamental for knowledge-intensive tasks such as entity linking and open-domain question answering. One way to understand current approaches is as classifiers among atomic labels, one for each entity. Their weight vectors are dense entity representations produced by encoding entity meta information such as their descriptions. This approach leads to several shortcomings: (i) context and entity affinity is mainly captured through a vector dot product, potentially missing fine-grained interactions between the two; (ii) a large memory footprint is needed to store dense representations when considering large entity sets; (iii) an appropriately hard set of negative data has to be subsampled at training time. In this work, we propose GENRE, the first system that retrieves entities by generating their unique names, left to right, token-by-token in an autoregressive fashion, and conditioned on the context. This enables us to mitigate the aforementioned technical issues since: (i) the autoregressive formulation allows us to directly capture relations between context and entity name, effectively cross encoding both; (ii) the memory footprint is greatly reduced because the parameters of our encoder-decoder architecture scale with vocabulary size, not entity count; (iii) the exact softmax loss can be efficiently computed without the need to subsample negative data. We show the efficacy of the approach, experimenting with more than 20 datasets on entity disambiguation, end-to-end entity linking and document retrieval tasks, achieving new state-of-the-art, or very competitive results while using a tiny fraction of the memory footprint of competing systems. Finally, we demonstrate that new entities can be added by simply specifying their unambiguous name.",エンティティは、知識を表現および集約する方法の中心です。たとえば、ウィキペディアなどの百科事典はエンティティごとに構成されています（たとえば、ウィキペディアの記事ごとに1つ）。クエリを指定してそのようなエンティティを取得する機能は、エンティティのリンクやオープンドメインの質問応答などの知識集約型のタスクの基本です。現在のアプローチを理解する1つの方法は、エンティティごとに1つずつ、アトミックラベル間の分類子として使用することです。それらの重みベクトルは、説明などのエンティティメタ情報をエンコードすることによって生成される密なエンティティ表現です。このアプローチにはいくつかの欠点があります。（i）コンテキストとエンティティの親和性は主にベクトル内積によって取得され、2つの間のきめ細かい相互作用が失われる可能性があります。 （ii）大きなエンティティセットを検討する場合、高密度の表現を格納するには、大きなメモリフットプリントが必要です。 （iii）トレーニング時に、適切にハードなネガティブデータのセットをサブサンプリングする必要があります。この作業では、GENREを提案します。これは、一意の名前を左から右に、自己回帰方式でトークンごとに生成し、コンテキストを条件としてエンティティを取得する最初のシステムです。これにより、前述の技術的な問題を軽減できます。（i）自己回帰定式化により、コンテキストとエンティティ名の間の関係を直接キャプチャし、両方を効果的にクロスエンコーディングできます。 （ii）エンコーダ-デコーダアーキテクチャのパラメータがエンティティ数ではなく語彙サイズに比例するため、メモリフットプリントが大幅に削減されます。 （iii）負のデータをサブサンプリングする必要なしに、正確なソフトマックス損失を効率的に計算できます。このアプローチの有効性を示し、エンティティの明確化、エンドツーエンドのエンティティリンク、ドキュメント検索タスクに関する20以上のデータセットを実験し、ごく一部を使用しながら、新しい最先端の、または非常に競争力のある結果を達成します。競合するシステムのメモリフットプリント。最後に、明確な名前を指定するだけで新しいエンティティを追加できることを示します。,7.75,
Expressive Power of Invariant and Equivariant Graph Neural Networks,"['Waiss Azizian', 'marc lelarge']",https://openreview.net/forum?id=lxHgXYN4bwl,"Various classes of Graph Neural Networks (GNN) have been proposed and shown to be successful in a wide range of applications with graph structured data. In this paper, we propose a theoretical framework able to compare the expressive power of these GNN architectures. The current universality theorems only apply to intractable classes of GNNs. Here, we prove the first approximation guarantees for practical GNNs, paving the way for a better understanding of their generalization. Our theoretical results are proved for invariant GNNs computing a graph embedding (permutation of the nodes of the input graph does not affect the output) and equivariant GNNs computing an embedding of the nodes (permutation of the input permutes the output). We show that Folklore Graph Neural Networks (FGNN), which are tensor based GNNs augmented with matrix multiplication are the most expressive architectures proposed so far for a given tensor order. We illustrate our results on the Quadratic Assignment Problem (a NP-Hard combinatorial problem) by showing that FGNNs are able to learn how to solve the problem, leading to much better average performances than existing algorithms (based on spectral, SDP or other GNNs architectures). On a practical side, we also implement masked tensors to handle batches of graphs of varying sizes. ",さまざまなクラスのグラフニューラルネットワーク（GNN）が提案され、グラフ構造化データを使用する幅広いアプリケーションで成功することが示されています。この論文では、これらのGNNアーキテクチャの表現力を比較できる理論的フレームワークを提案します。現在の普遍性の定理は、扱いにくいクラスのGNNにのみ適用されます。ここでは、実用的なGNNの最初の近似保証を証明し、それらの一般化をよりよく理解するための道を開きます。私たちの理論的結果は、グラフ埋め込みを計算する不変GNN（入力グラフのノードの順列は出力に影響を与えません）とノードの埋め込みを計算する同変GNN（入力の順列は出力を並べ替えます）で証明されています。行列乗算で拡張されたテンソルベースのGNNであるFolkloreGraph Neural Networks（FGNN）が、特定のテンソル次数に対してこれまでに提案された最も表現力豊かなアーキテクチャであることを示します。二次割り当て問題（NP困難な組み合わせ問題）の結果を、FGNNが問題の解決方法を学習できることを示し、既存のアルゴリズム（スペクトル、SDP、またはその他のGNNアーキテクチャに基づく）よりもはるかに優れた平均パフォーマンスをもたらすことを示します。 ）。実用面では、さまざまなサイズのグラフのバッチを処理するためにマスクされたテンソルも実装します。,7.75,
Rethinking Architecture Selection in Differentiable NAS,"['Ruochen Wang', 'Minhao Cheng', 'Xiangning Chen', 'Xiaocheng Tang', 'Cho-Jui Hsieh']",https://openreview.net/forum?id=PKubaeJkw3,"Differentiable Neural Architecture Search is one of the most popular Neural Architecture Search (NAS) methods for its search efficiency and simplicity, accomplished by jointly optimizing the model weight and architecture parameters in a weight-sharing supernet via gradient-based algorithms. At the end of the search phrase, the operations with the largest architecture parameters will be selected to form the final architecture, with the implicit assumption that the values of architecture parameters reflect the operation strength. While much has been discussed about the supernet's optimization, the architecture selection process has received little attention. We provide empirical and theoretical analysis to show that the magnitude of architecture parameters does not necessarily indicate how much the operation contributes to the supernet's performance. We propose an alternative perturbation-based architecture selection that directly measures each operation's influence on the supernet. We re-evaluate several differentiable NAS methods with the proposed architecture selection and find that it is able to extract significantly improved architectures from the underlying supernets consistently. Furthermore, we find that several failure modes of Darts can be greatly alleviated with the proposed selection method, indicating that much of the poor generalization observed in Darts can be attributed to the failure of magnitude-based architecture selection rather than entirely the optimization of its supernet. Our code will be made publicly available shortly.",微分可能なニューラルアーキテクチャ検索は、検索の効率と単純さで最も人気のあるニューラルアーキテクチャ検索（NAS）メソッドの1つであり、勾配ベースのアルゴリズムを介して重み共有スーパーネットでモデルの重みとアーキテクチャパラメータを共同で最適化します。検索フレーズの最後で、アーキテクチャパラメータの値が操作の強度を反映しているという暗黙の前提の下で、アーキテクチャパラメータが最大の操作が選択されて最終的なアーキテクチャが形成されます。スーパーネットの最適化については多くの議論がなされてきましたが、アーキテクチャの選択プロセスはほとんど注目されていません。アーキテクチャパラメータの大きさが、操作がスーパーネットのパフォーマンスにどの程度貢献しているかを必ずしも示していないことを示すために、経験的および理論的な分析を提供します。スーパーネットに対する各操作の影響を直接測定する、代替の摂動ベースのアーキテクチャ選択を提案します。提案されたアーキテクチャの選択を使用して、いくつかの差別化可能なNASメソッドを再評価し、基盤となるスーパーネットから大幅に改善されたアーキテクチャを一貫して抽出できることを確認しました。さらに、ダーツのいくつかの故障モードは、提案された選択方法で大幅に軽減できることがわかりました。これは、ダーツで観察された不十分な一般化の多くが、スーパーネットの完全な最適化ではなく、マグニチュードベースのアーキテクチャ選択の故障に起因する可能性があることを示しています。 。私たちのコードはまもなく公開されます。,7.75,
Share or Not? Learning to Schedule Language-Specific Capacity for Multilingual Translation,"['Biao Zhang', 'Ankur Bapna', 'Rico Sennrich', 'Orhan Firat']",https://openreview.net/forum?id=Wj4ODo0uyCF,"Using a mix of shared and language-specific (LS) parameters has shown promise in multilingual neural machine translation (MNMT), but the question of when and where LS capacity matters most is still under-studied. We offer such a study by proposing conditional language-specific routing (CLSR). CLSR employs hard binary gates conditioned on token representations to dynamically select LS or shared paths. By manipulating these gates, it can schedule LS capacity across sub-layers in MNMT subject to the guidance of translation signals and budget constraints. Moreover, CLSR can easily scale up to massively multilingual settings. Experiments with Transformer on OPUS-100 and WMT datasets show that: 1) MNMT is sensitive to both the amount and the position of LS modeling: distributing 10%-30% LS computation to the top and/or bottom encoder/decoder layers delivers the best performance; and 2) one-to-many translation benefits more from CLSR compared to many-to-one translation, particularly with unbalanced training data. Our study further verifies the trade-off between the shared capacity and LS capacity for multilingual translation. We corroborate our analysis by confirming the soundness of our findings as foundation of our improved multilingual Transformers. Source code and models will be released.",共有パラメーターと言語固有（LS）パラメーターを組み合わせて使用​​することは、多言語ニューラル機械翻訳（MNMT）で有望であることが示されていますが、LS容量が最も重要な時期と場所の問題はまだ十分に研究されていません。条件付き言語固有ルーティング（CLSR）を提案することにより、このような調査を提供します。 CLSRは、トークン表現を条件とするハードバイナリゲートを使用して、LSまたは共有パスを動的に選択します。これらのゲートを操作することにより、変換信号と予算の制約のガイダンスに従って、MNMTのサブレイヤー全体でLS容量をスケジュールできます。さらに、CLSRは大規模な多言語設定に簡単にスケールアップできます。 OPUS-100およびWMTデータセットでのTransformerの実験は、次のことを示しています。1）MNMTは、LSモデリングの量と位置の両方に敏感です。,7.75,
When Do Curricula Work?,"['Xiaoxia Wu', 'Ethan Dyer', 'Behnam Neyshabur']",https://openreview.net/forum?id=tW4QEInpni,"Inspired by human learning, researchers have proposed ordering examples during training based on their difficulty. Both curriculum learning, exposing a network to easier examples early in training, and anti-curriculum learning, showing the most difficult examples first, have been suggested as improvements to the standard i.i.d. training. In this work, we set out to investigate the relative benefits of ordered learning. We first investigate the implicit curricula resulting from architectural and optimization bias and find that samples are learned in a highly consistent order. Next, to quantify the benefit of explicit curricula, we conduct extensive experiments over thousands of orderings spanning three kinds of learning: curriculum, anti-curriculum, and random-curriculum -- in which the size of the training dataset is dynamically increased over time, but the examples are randomly ordered. We find that for standard benchmark datasets, curricula have only marginal benefits, and that randomly ordered samples perform as well or better than curricula and anti-curricula, suggesting that any benefit is entirely due to the dynamic training set size. Inspired by common use cases of curriculum learning in practice, we investigate the role of limited training time budget and noisy data in the success of curriculum learning. Our experiments demonstrate that curriculum, but not anti-curriculum or random ordering can indeed improve the performance either with limited training time budget or in the existence of noisy data.",人間の学習に触発されて、研究者は彼らの難しさに基づいて訓練中に例を注文することを提案しました。標準のiidトレーニングの改善として、トレーニングの早い段階でネットワークをより簡単な例に公開するカリキュラム学習と、最も難しい例を最初に示す反カリキュラム学習の両方が提案されています。この作業では、順序付けられた学習の相対的な利点を調査することに着手しました。最初に、アーキテクチャと最適化のバイアスから生じる暗黙のカリキュラムを調査し、サンプルが非常に一貫した順序で学習されることを発見します。次に、明示的なカリキュラムの利点を定量化するために、カリキュラム、反カリキュラム、およびトレーニングデータセットのサイズが時間の経過とともに動的に増加するランダムカリキュラムの3種類の学習にまたがる、数千の順序で広範な実験を行います。例はランダムに並べられています。標準のベンチマークデータセットの場合、カリキュラムにはわずかなメリットしかなく、ランダムに並べられたサンプルはカリキュラムやアンチカリキュラムと同等またはそれ以上のパフォーマンスを発揮することがわかりました。これは、メリットが完全に動的トレーニングセットのサイズによるものであることを示唆しています。実際のカリキュラム学習の一般的な使用例に触発されて、カリキュラム学習の成功における限られたトレーニング時間の予算とノイズの多いデータの役割を調査します。私たちの実験は、カリキュラムではなく、反カリキュラムやランダムな順序付けが、限られたトレーニング時間の予算で、またはノイズの多いデータが存在する場合に、実際にパフォーマンスを向上させることができることを示しています。,7.67,https://d3i71xaburhd42.cloudfront.net/9d2c96574019305a8c86cc5b84cb9f616ccf0eb3/3-Figure1-1.png
Invariant Representations for Reinforcement Learning without Reconstruction,"['Amy Zhang', 'Rowan Thomas McAllister', 'Roberto Calandra', 'Yarin Gal', 'Sergey Levine']",https://openreview.net/forum?id=-2FCwDKRREu,"We study how representation learning can accelerate reinforcement learning from rich observations, such as images, without relying either on domain knowledge or pixel-reconstruction. Our goal is to learn representations that provide for effective downstream control and invariance to task-irrelevant details. Bisimulation metrics quantify behavioral similarity between states in continuous MDPs, which we propose using to learn robust latent representations which encode only the task-relevant information from observations. Our method trains encoders such that distances in latent space equal bisimulation distances in state space. We demonstrate the effectiveness of our method at disregarding task-irrelevant information using modified visual MuJoCo tasks, where the background is replaced with moving distractors and natural videos, while achieving SOTA performance. We also test a first-person highway driving task where our method learns invariance to clouds, weather, and time of day. Finally, we provide generalization results drawn from properties of bisimulation metrics, and links to causal inference.",ドメイン知識やピクセル再構成に依存することなく、表現学習が画像などの豊富な観察からの強化学習をどのように加速できるかを研究します。私たちの目標は、効果的なダウンストリーム制御とタスクに関係のない詳細への不変性を提供する表現を学習することです。双模倣メトリックは、連続MDPの状態間の動作の類似性を定量化します。これを使用して、観測からタスク関連情報のみをエンコードする堅牢な潜在表現を学習することを提案します。私たちの方法は、潜在空間の距離が状態空間の双模倣距離と等しくなるようにエンコーダーをトレーニングします。 SOTAのパフォーマンスを達成しながら、背景が動く気晴らしと自然なビデオに置き換えられる、修正された視覚的なMuJoCoタスクを使用して、タスクに関係のない情報を無視する方法の有効性を示します。また、私たちの方法が雲、天気、および時刻に対する不変性を学習する一人称の高速道路運転タスクをテストします。最後に、双模倣メトリックのプロパティから引き出された一般化の結果と、因果推論へのリンクを提供します。,7.67,https://d3i71xaburhd42.cloudfront.net/518b827e340c26582b5093401283a4f5cff605b9/1-Figure1-1.png
Do 2D GANs Know 3D Shape? Unsupervised 3D Shape Reconstruction from 2D Image GANs,"['Xingang Pan', 'Bo Dai', 'Ziwei Liu', 'Chen Change Loy', 'Ping Luo']",https://openreview.net/forum?id=FGqiDsBUKL0,"Natural images are projections of 3D objects on a 2D image plane. While state-of-the-art 2D generative models like GANs show unprecedented quality in modeling the natural image manifold, it is unclear whether they implicitly capture the underlying 3D object structures. And if so, how could we exploit such knowledge to recover the 3D shapes of objects in the images? To answer these questions, in this work, we present the first attempt to directly mine 3D geometric clues from an off-the-shelf 2D GAN that is trained on RGB images only. Through our investigation, we found that such a pre-trained GAN indeed contains rich 3D knowledge and thus can be used to recover 3D shape from a single 2D image in an unsupervised manner. The core of our framework is an iterative strategy that explores and exploits diverse viewpoint and lighting variations in the GAN image manifold. The framework does not require 2D keypoint or 3D annotations, or strong assumptions on object shapes (e.g. shapes are symmetric), yet it successfully recovers 3D shapes with high precision for human faces, cats, cars, and buildings. The recovered 3D shapes immediately allow high-quality image editing like relighting and object rotation. We quantitatively demonstrate the effectiveness of our approach compared to previous methods in both 3D shape reconstruction and face rotation. Our code and models will be released.",自然画像は、2D画像平面上の3Dオブジェクトの投影です。 GANのような最先端の2D生成モデルは、自然な画像多様体のモデリングにおいて前例のない品質を示していますが、基礎となる3Dオブジェクト構造を暗黙的にキャプチャするかどうかは不明です。もしそうなら、どうすればそのような知識を利用して、画像内のオブジェクトの3D形状を復元できますか？これらの質問に答えるために、この作業では、RGB画像のみでトレーニングされた既製の2DGANから3D幾何学的手がかりを直接マイニングする最初の試みを紹介します。調査の結果、このような事前トレーニング済みのGANには確かに豊富な3D知識が含まれているため、教師なしで単一の2D画像から3D形状を復元できることがわかりました。私たちのフレームワークの中核は、GAN画像多様体の多様な視点と照明のバリエーションを調査して活用する反復戦略です。このフレームワークは、2Dキーポイントや3D注釈、またはオブジェクトの形状に関する強い仮定（形状が対称であるなど）を必要としませんが、人間の顔、猫、車、建物の3D形状を高精度で復元することに成功しています。復元された3D形状により、再照明やオブジェクトの回転などの高品質の画像編集がすぐに可能になります。 3D形状の再構築と顔の回転の両方で、以前の方法と比較したアプローチの有効性を定量的に示します。コードとモデルがリリースされます。,7.67,https://d3i71xaburhd42.cloudfront.net/d3e33d56c7f246dea87a81c4983a3bb7083da973/2-Figure2-1.png
Distributional Sliced-Wasserstein and Applications to Generative Modeling,"['Khai Nguyen', 'Nhat Ho', 'Tung Pham', 'Hung Bui']",https://openreview.net/forum?id=QYjO70ACDK,"Sliced-Wasserstein distance (SW) and its variant, Max Sliced-Wasserstein distance (Max-SW), have been used widely in the recent years due to their fast computation and scalability even when the probability measures lie in a very high dimensional space. However, SW requires many unnecessary projection samples to approximate its value while Max-SW only uses the most important projection, which ignores the information of other useful directions. In order to account for these weaknesses, we propose a novel distance, named Distributional Sliced-Wasserstein distance (DSW), that finds an optimal distribution over projections that can balance between exploring distinctive projecting directions and the informativeness of projections themselves. We show that the DSW is a generalization of Max-SW, and it can be computed efficiently by searching for the optimal push-forward measure over a set of probability measures over the unit sphere satisfying certain regularizing constraints that favor distinct directions. Finally, we conduct extensive experiments with large-scale datasets to demonstrate the favorable performances of the proposed distances over the previous sliced-based distances in generative modeling applications.",スライスワッサースタイン距離（SW）とその変形である最大スライスワッサースタイン距離（Max-SW）は、確率測度が非常に高次元の空間にある場合でも、計算が高速でスケーラビリティが高いため、近年広く使用されています。ただし、SWはその値を概算するために多くの不要な投影サンプルを必要としますが、Max-SWは最も重要な投影のみを使用し、他の有用な方向の情報を無視します。これらの弱点を説明するために、Distribution Sliced-Wasserstein distance（DSW）という名前の新しい距離を提案します。これは、特徴的な投影方向の探索と投影自体の有益性のバランスをとることができる、投影上の最適な分布を見つけます。 DSWはMax-SWの一般化であり、明確な方向を優先する特定の正規化制約を満たす単位球上の一連の確率測度で最適なプッシュフォワード測度を検索することで効率的に計算できることを示します。最後に、大規模なデータセットを使用して広範な実験を行い、生成モデリングアプリケーションで以前のスライスベースの距離よりも提案された距離の好ましいパフォーマンスを示します。,7.67,https://d3i71xaburhd42.cloudfront.net/a27b1f09cc31bfa8b313f5e31d529be6d75bbd34/7-Figure1-1.png
Geometry-aware Instance-reweighted Adversarial Training,"['Jingfeng Zhang', 'Jianing Zhu', 'Gang Niu', 'Bo Han', 'Masashi Sugiyama', 'Mohan Kankanhalli']",https://openreview.net/forum?id=iAX0l6Cz8ub,"In adversarial machine learning, there was a common belief that robustness and accuracy hurt each other. The belief was challenged by recent studies where we can maintain the robustness and improve the accuracy. However, the other direction, whether we can keep the accuracy while improving the robustness, is conceptually and practically more interesting, since robust accuracy should be lower than standard accuracy for any model. In this paper, we show this direction is also promising. Firstly, we find even over-parameterized deep networks may still have insufficient model capacity, because adversarial training has an overwhelming smoothing effect. Secondly, given limited model capacity, we argue adversarial data should have unequal importance: geometrically speaking, a natural data point closer to/farther from the class boundary is less/more robust, and the corresponding adversarial data point should be assigned with larger/smaller weight. Finally, to implement the idea, we propose geometry-aware instance-reweighted adversarial training, where the weights are based on how difficult it is to attack a natural data point. Experiments show that our proposal boosts the robustness of standard adversarial training; combining two directions, we improve both robustness and accuracy of standard adversarial training.",敵対的機械学習では、堅牢性と正確性が互いに傷つくという共通の信念がありました。この信念は、堅牢性を維持し、精度を向上させることができる最近の研究によって異議を唱えられました。ただし、ロバスト性を向上させながら精度を維持できるかどうかという別の方向は、ロバスト性の精度がどのモデルの標準精度よりも低くなければならないため、概念的および実用的に興味深いものです。この論文では、この方向性も有望であることを示しています。まず、敵対的なトレーニングには圧倒的な平滑化効果があるため、パラメーターが多すぎるディープネットワークでもモデル容量が不十分である可能性があることがわかります。第二に、モデルの容量が限られていることを考えると、敵対的なデータの重要性は等しくないはずです。幾何学的に言えば、クラスの境界に近い/遠い自然なデータポイントはより堅牢ではなく、対応する敵対的なデータポイントにはより大きな/より小さなデータポイントを割り当てる必要があります。重量。最後に、このアイデアを実装するために、ジオメトリを意識したインスタンスで再重み付けされた敵対的トレーニングを提案します。このトレーニングでは、自然なデータポイントを攻撃するのがどれほど難しいかに基づいて重み付けが行われます。実験は、私たちの提案が標準的な敵対的訓練の頑健性を高めることを示しています。 2つの方向を組み合わせることで、標準的な敵対訓練の堅牢性と精度の両方を向上させます。,7.67,https://d3i71xaburhd42.cloudfront.net/a6fa981b9f89572317a2024c2de590718a2827a7/2-Figure1-1.png
Predicting Infectiousness for Proactive Contact Tracing,"['Yoshua Bengio', 'Prateek Gupta', 'Tegan Maharaj', 'Nasim Rahaman', 'Martin Weiss', 'Tristan Deleu', 'Eilif Benjamin Muller', 'Meng Qu', 'victor schmidt', 'Pierre-luc St-charles', 'hannah alsdurf', 'Olexa Bilaniuk', 'david buckeridge', 'gaetan caron', 'pierre luc carrier', 'Joumana Ghosn', 'satya ortiz gagne', 'Christopher Pal', 'Irina Rish', 'Bernhard Schölkopf', 'abhinav sharma', 'Jian Tang', 'andrew williams']",https://openreview.net/forum?id=lVgB2FUbzuQ,"The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual contact tracing in many countries and resulting in widespread lockdowns for emergency containment. Large-scale digital contact tracing (DCT) has emerged as a potential solution to resume economic and social activity while minimizing spread of the virus. Various DCT methods have been proposed, each making trade-offs be-tween privacy, mobility restrictions, and public health. The most common approach, binary contact tracing (BCT), models infection as a binary event, informed only by an individual’s test results, with corresponding binary recommendations that either all or none of the individual’s contacts quarantine. BCT ignores the inherent uncertainty in contacts and the infection process, which could be used to tailor messaging to high-risk individuals, and prompt proactive testing or earlier warnings. It also does not make use of observations such as symptoms or pre-existing medical conditions, which could be used to make more accurate infectiousness predictions. In this paper, we use a recently-proposed COVID-19 epidemiological simulator to develop and test methods that can be deployed to a smartphone to locally and proactively predict an individual’s infectiousness (risk of infecting others) based on their contact history and other information, while respecting strong privacy constraints. Predictions are used to provide personalized recommendations to the individual via an app, as well as to send anonymized messages to the individual’s contacts, who use this information to better predict their own infectiousness, an approach we call proactive contact tracing (PCT). Similarly to other works, we find that compared to no tracing, all DCT methods tested are able to reduce spread of the disease and thus save lives, even at low adoption rates, strongly supporting a role for DCT methods in managing the pandemic. Further, we find a deep-learning based PCT method which improves over BCT for equivalent average mobility, suggesting PCT could help in safe re-opening and second-wave prevention.",COVID-19のパンデミックは世界中に急速に広がり、多くの国で手動のコンタクトトレーシングを圧倒し、緊急封じ込めのための広範な封鎖をもたらしました。大規模なデジタルコンタクトトレーシング（DCT）は、ウイルスの拡散を最小限に抑えながら、経済的および社会的活動を再開するための潜在的なソリューションとして浮上しています。さまざまなDCT方法が提案されており、それぞれがプライバシー、移動制限、および公衆衛生の間でトレードオフを行っています。最も一般的なアプローチであるバイナリコンタクトトレーシング（BCT）は、感染をバイナリイベントとしてモデル化し、個人のテスト結果によってのみ通知されます。対応するバイナリの推奨事項では、すべての個人が検疫に接触するか、まったく接触しません。 BCTは、連絡先と感染プロセスに内在する不確実性を無視します。これは、リスクの高い個人に合わせてメッセージングを調整し、予防的なテストまたは早期の警告を促すために使用できます。また、より正確な感染性予測を行うために使用できる症状や既存の病状などの観察結果も利用しません。この論文では、最近提案されたCOVID-19疫学シミュレーターを使用して、スマートフォンに展開できる方法を開発およびテストし、連絡履歴やその他の情報に基づいて、個人の感染性（他人に感染するリスク）をローカルかつプロアクティブに予測します。強いプライバシーの制約を尊重しながら。予測は、アプリを介して個人にパーソナライズされた推奨事項を提供するため、および匿名化されたメッセージを個人の連絡先に送信するために使用されます。連絡先は、この情報を使用して自分の感染性をより正確に予測します。これは、プロアクティブコンタクトトレーシング（PCT）と呼ばれるアプローチです。他の研究と同様に、トレースなしと比較して、テストされたすべてのDCTメソッドは、病気の蔓延を減らし、したがって、低い採用率でも命を救うことができ、パンデミックの管理におけるDCTメソッドの役割を強力にサポートします。さらに、同等の平均移動度でBCTを改善するディープラーニングベースのPCTメソッドを見つけました。これは、PCTが安全な再開と第2波の防止に役立つ可能性があることを示唆しています。,7.67,https://d3i71xaburhd42.cloudfront.net/59078a88b2a94636bd2bfb6b4186f6ab8a7813bc/3-Figure1-1.png
EigenGame: PCA as a Nash Equilibrium,"['Ian Gemp', 'Brian McWilliams', 'Claire Vernade', 'Thore Graepel']",https://openreview.net/forum?id=NzTU59SYbNq,We present a novel view on principal components analysis as a competitive game in which each approximate eigenvector is controlled by a player whose goal is to maximize their own utility function. We analyze the properties of this PCA game and the behavior of its gradient based updates. The resulting algorithm---which combines elements from Oja's rule with a  generalized Gram-Schmidt orthogonalization---is naturally decentralized and hence parallelizable through message passing. We demonstrate the scalability of the algorithm with experiments on large image datasets and neural network activations. We discuss how this new view of PCA as a differentiable game can lead to further algorithmic developments and insights.,主成分分析に関する新しい見方を、それぞれの近似固有ベクトルが、自身の効用関数を最大化することを目標とするプレーヤーによって制御される競争ゲームとして提示します。このPCAゲームのプロパティと、勾配ベースの更新の動作を分析します。オヤの法則の要素を一般化されたグラムシュミット直交化と組み合わせた結果のアルゴリズムは、自然に分散化されているため、メッセージパッシングを通じて並列化できます。大規模な画像データセットとニューラルネットワークのアクティブ化に関する実験で、アルゴリズムのスケーラビリティを示します。微分可能なゲームとしてのPCAのこの新しい見方が、アルゴリズムの開発と洞察にどのようにつながるかについて説明します。,7.67,
Extreme Memorization via Scale of Initialization,"['Harsh Mehta', 'Ashok Cutkosky', 'Behnam Neyshabur']",https://openreview.net/forum?id=Z4R1vxLbRLO,"We construct an experimental setup in which changing the scale of initialization strongly impacts the implicit regularization induced by SGD, interpolating from good generalization performance to completely memorizing the training set while making little progress on the test set. Moreover, we find that the extent and manner in which generalization ability is affected depends on the activation and loss function used, with sin activation being the most extreme. In the case of the homogeneous ReLU activation, we show that this behavior can be attributed to the loss function. Our empirical investigation reveals that increasing the scale of initialization correlates with misalignment of representations and gradients across examples in the same class. This insight allows us to device an alignment measure over gradients and representations which can capture this phenomenon. We demonstrate that our alignment measure correlates with generalization of deep models trained on image classification tasks.",初期化のスケールを変更すると、SGDによって引き起こされる暗黙の正則化に強く影響し、テストセットをほとんど進行させずに、良好な一般化パフォーマンスからトレーニングセットを完全に記憶するように補間する実験セットアップを構築します。さらに、一般化能力が影響を受ける程度と方法は、使用される活性化と損失関数に依存し、罪の活性化が最も極端であることがわかります。同種のReLUアクティベーションの場合、この動作が損失関数に起因する可能性があることを示します。私たちの経験的調査は、初期化のスケールを増やすことは、同じクラスの例全体の表現と勾配の不整合と相関していることを明らかにしています。この洞察により、この現象を捉えることができる勾配と表現のアライメント測定をデバイス化することができます。私たちのアライメント測定は、画像分類タスクで訓練された深いモデルの一般化と相関していることを示しています。,7.67,https://d3i71xaburhd42.cloudfront.net/278deef534ae68676f87bd45a65441804edad05a/2-Figure1-1.png
Neural Synthesis of Binaural Speech,"['Alexander Richard', 'Dejan Markovic', 'Israel D. Gebru', 'Steven Krenn', 'Gladstone Alexander Butler', 'Fernando Torre', 'Yaser Sheikh']",https://openreview.net/forum?id=uAX8q61EVRu,"We present a neural rendering approach for binaural sound synthesis that can produce realistic and spatially accurate binaural sound in realtime. The network takes, as input, a single-channel audio source and synthesizes, as output, two-channel binaural sound, conditioned on the relative position and orientation of the listener with respect to the source. We investigate deficiencies of the l2-loss on raw waveforms in a theoretical analysis and introduce an improved loss that overcomes these limitations. In an empirical evaluation, we establish that our approach is the first to generate spatially accurate waveform outputs (as measured by real recordings) and outperforms existing approaches by a considerable margin, both quantitatively and in a perceptual study. We will release a first-of-its-kind binaural audio dataset as a benchmark for future research.",リアルで空間的に正確なバイノーラルサウンドをリアルタイムで生成できるバイノーラルサウンド合成のニューラルレンダリングアプローチを紹介します。ネットワークは、入力として単一チャネルのオーディオソースを受け取り、出力として、ソースに対するリスナーの相対的な位置と向きを条件として、2チャネルのバイノーラルサウンドを合成します。理論的分析で生の波形のl2損失の欠陥を調査し、これらの制限を克服する改善された損失を導入します。経験的評価では、私たちのアプローチは、空間的に正確な波形出力（実際の記録で測定）を生成する最初のものであり、定量的および知覚的研究の両方で、既存のアプローチをかなりの差で上回っています。今後の研究のベンチマークとして、この種では初めてのバイノーラルオーディオデータセットをリリースします。,7.67,
Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime,"['Atsushi Nitanda', 'Taiji Suzuki']",https://openreview.net/forum?id=PULSD5qI2N1,"We analyze the convergence of the averaged stochastic gradient descent for overparameterized two-layer neural networks for regression problems. It was recently found that a neural tangent kernel (NTK) plays an important role in showing the global convergence of gradient-based methods under the NTK regime, where the learning dynamics for overparameterized neural networks can be almost characterized by that for the associated reproducing kernel Hilbert space (RKHS). However, there is still room for a convergence rate analysis in the NTK regime. In this study, we show that the averaged stochastic gradient descent can achieve the minimax optimal convergence rate, with the global convergence guarantee, by exploiting the complexities of the target function and the RKHS associated with the NTK. Moreover, we show that the target function specified by the NTK of a ReLU network can be learned at the optimal convergence rate through a smooth approximation of a ReLU network under certain conditions.",回帰問題について、パラメーター化された2層ニューラルネットワークの平均確率的勾配降下法の収束を分析します。最近、ニューラルタンジェントカーネル（NTK）が、NTKレジーム下での勾配ベースの方法のグローバルな収束を示す上で重要な役割を果たしていることがわかりました。ヒルベルト空間（RKHS）。ただし、NTK体制では収束率分析の余地がまだあります。この研究では、平均確率的勾配降下法が、NTKに関連するターゲット関数とRKHSの複雑さを利用することにより、グローバル収束保証付きでミニマックス最適収束率を達成できることを示します。さらに、ReLUネットワークのNTKによって指定されたターゲット関数は、特定の条件下でReLUネットワークを滑らかに近似することにより、最適な収束率で学習できることを示します。,7.6,https://d3i71xaburhd42.cloudfront.net/46853d8d21831be69eed5949b380d8d9aad31bf5/2-Figure1-1.png
DiffWave: A Versatile Diffusion Model for Audio Synthesis,"['Zhifeng Kong', 'Wei Ping', 'Jiaji Huang', 'Kexin Zhao', 'Bryan Catanzaro']",https://openreview.net/forum?id=a-xFK8Ymz5J,"In this work, we propose DiffWave, a versatile diffusion probabilistic model for conditional and unconditional waveform generation. The model is non-autoregressive, and converts the white noise signal into structured waveform through a Markov chain with a constant number of steps at synthesis. It is efficiently trained by optimizing a variant of variational bound on the data likelihood. DiffWave produces high-fidelity audios in different waveform generation tasks, including neural vocoding conditioned on mel spectrogram, class-conditional generation, and unconditional generation. We demonstrate that DiffWave matches a strong WaveNet vocoder in terms of speech quality (MOS: 4.44 versus 4.43), while synthesizing orders of magnitude faster. In particular, it significantly outperforms autoregressive and GAN-based waveform models in the challenging unconditional generation task in terms of audio quality and sample diversity from various automatic and human evaluations.",この作業では、条件付きおよび無条件の波形生成のための多用途の拡散確率モデルであるDiffWaveを提案します。このモデルは非自己回帰であり、合成時に一定のステップ数でマルコフ連鎖を介してホワイトノイズ信号を構造化波形に変換します。これは、データ尤度の変分限界のバリアントを最適化することによって効率的にトレーニングされます。 DiffWaveは、メルスペクトログラムを条件とするニューラルボコーディング、クラス条件付き生成、無条件生成など、さまざまな波形生成タスクで忠実度の高いオーディオを生成します。 DiffWaveが音声品質（MOS：4.44対4.43）の点で強力なWaveNetボコーダーと一致する一方で、桁違いに高速に合成することを示します。特に、さまざまな自動評価および人間による評価からのオーディオ品質とサンプルの多様性の点で、困難な無条件生成タスクにおいて、自己回帰およびGANベースの波形モデルを大幅に上回っています。,7.6,https://d3i71xaburhd42.cloudfront.net/34bf13e58c7226d615afead0c0f679432502940e/2-Figure1-1.png
Human-Level Performance in No-Press Diplomacy via Equilibrium Search,"['Jonathan Gray', 'Adam Lerer', 'Anton Bakhtin', 'Noam Brown']",https://openreview.net/forum?id=0-uUGPbIjD,"Prior AI breakthroughs in complex games have focused on either the purely adversarial or purely cooperative settings. In contrast, Diplomacy is a game of shifting alliances that involves both cooperation and competition. For this reason, Diplomacy has proven to be a formidable research challenge. In this paper we describe an agent for the no-press variant of Diplomacy that combines supervised learning on human data with one-step lookahead search via external regret minimization. External regret minimization techniques have been behind previous AI successes in adversarial games, most notably poker, but have not previously been shown to be successful in large-scale games involving cooperation. We show that our agent greatly exceeds the performance of past no-press Diplomacy bots, is unexploitable by expert humans, and achieves a rank of 23 out of 1,128 human players when playing anonymous games on a popular Diplomacy website.","複雑なゲームにおけるこれまでのAIのブレークスルーは、純粋に敵対的な設定または純粋に協力的な設定のいずれかに焦点を合わせてきました。対照的に、外交は協力と競争の両方を伴う同盟をシフトするゲームです。このため、外交は手ごわい研究課題であることが証明されています。この論文では、人間のデータに関する教師あり学習と、外部の後悔の最小化によるワンステップの先読み検索を組み合わせた、外交のノープレスバリアントのエージェントについて説明します。外部の後悔最小化技術は、敵対的なゲーム、特にポーカーでの以前のAIの成功に遅れをとっていますが、協力を伴う大規模なゲームで成功することはこれまで示されていません。私たちのエージェントは、過去のノープレス外交ボットのパフォーマンスを大幅に上回り、熟練した人間が悪用することはできず、人気のある外交ウェブサイトで匿名のゲームをプレイすると、1,128人の人間プレイヤーのうち23人のランクを達成することを示しています。",7.5,https://d3i71xaburhd42.cloudfront.net/e69f87e7c066d7dd5d83af88a2380ceabfb2568d/5-Figure1-1.png
Rethinking Attention with Performers,"['Krzysztof Marcin Choromanski', 'Valerii Likhosherstov', 'David Dohan', 'Xingyou Song', 'Andreea Gane', 'Tamas Sarlos', 'Peter Hawkins', 'Jared Quincy Davis', 'Afroz Mohiuddin', 'Lukasz Kaiser', 'David Benjamin Belanger', 'Lucy J Colwell', 'Adrian Weller']",https://openreview.net/forum?id=Ua6zuk0WRH,"We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attention-kernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can also be used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low  estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers. ",パフォーマー、証明可能な精度で通常の（softmax）フルランクアテンショントランスフォーマーを推定できるトランスフォーマーアーキテクチャを紹介しますが、スパース性や低ランクなどの事前情報に依存することなく、線形（2次ではなく）空間と時間の複雑さのみを使用します。ソフトマックスアテンションカーネルを概算するために、パフォーマーは、スケーラブルなカーネル法にとって独立した関心事である可能性がある、正の直交ランダム機能アプローチ（FAVOR +）を介した新しい高速アテンションを使用します。 FAVOR +は、softmaxを超えてカーネル化可能な注意メカニズムを効率的にモデル化するためにも使用できます。この表現力は、通常のTransformerの範囲を超えて、大規模なタスクで初めてsoftmaxを他のカーネルと正確に比較し、最適なアテンションカーネルを調査するために重要です。パフォーマーは、通常のトランスフォーマーと完全に互換性があり、強力な理論的保証を備えた線形アーキテクチャです。注意マトリックスの不偏またはほぼ不偏の推定、均一な収束、および低い推定分散。ピクセル予測からテキストモデル、タンパク質配列モデリングに至るまで、豊富なタスクセットでパフォーマーをテストしました。パフォーマーが活用する新しい注意学習パラダイムの有効性を示す、他の検討された効率的なスパースおよびデンスアテンションメソッドとの競争力のある結果を示します。,7.5,https://d3i71xaburhd42.cloudfront.net/abc9d9585599b9af3a2354b033891fa6d46681be/3-Figure1-1.png
Implicit Normalizing Flows,"['Cheng Lu', 'Jianfei Chen', 'Chongxuan Li', 'Qiuhao Wang', 'Jun Zhu']",https://openreview.net/forum?id=8PS8m9oYtNy,"Normalizing flows define a probability distribution by an explicit invertible transformation $\boldsymbol{\mathbf{z}}=f(\boldsymbol{\mathbf{x}})$. In this work, we present implicit normalizing flows (ImpFlows), which generalize normalizing flows by allowing the mapping to be implicitly defined by the roots of an equation $F(\boldsymbol{\mathbf{z}}, \boldsymbol{\mathbf{x}})= \boldsymbol{\mathbf{0}}$. ImpFlows build on residual flows (ResFlows) with a proper balance between expressiveness and tractability. Through theoretical analysis, we show that the function space of ImpFlow is strictly richer than that of ResFlows. Furthermore, for any ResFlow with a fixed number of blocks, there exists some function that ResFlow has a non-negligible approximation error. However, the function is exactly representable by a single-block ImpFlow. We propose a scalable algorithm to train and draw samples from ImpFlows. Empirically, we evaluate ImpFlow on several classification and density modeling tasks, and ImpFlow outperforms ResFlow with a comparable amount of parameters on all the benchmarks.",正規化フローは、明示的な可逆変換Z = f（X）によって確率分布を定義します。この作業では、方程式F（Z、X）= 0の根によってマッピングを暗黙的に定義できるようにすることで正規化フローを一般化する暗黙的な正規化フロー（ImpFlows）を示します。ImpFlowsは残差フロー（ResFlows）に基づいて構築されます。表現力と扱いやすさの適切なバランス。理論的分析を通じて、ImpFlowの関数空間がResFlowの関数空間よりも厳密に豊富であることを示します。さらに、ブロック数が固定されているResFlowの場合、ResFlowに無視できない近似誤差がある関数がいくつかあります。ただし、この関数は単一ブロックのImpFlowで正確に表すことができます。 ImpFlowsからサンプルをトレーニングおよび描画するためのスケーラブルなアルゴリズムを提案します。経験的に、いくつかの分類および密度モデリングタスクでImpFlowを評価し、ImpFlowは、すべてのベンチマークで同等の量のパラメーターを使用してResFlowよりも優れています。,7.5,
Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability,"['Suraj Srinivas', 'Francois Fleuret']",https://openreview.net/forum?id=dYeAHXnpWJ4,"Current methods for the interpretability of discriminative deep neural networks commonly rely on the model's input-gradients, i.e., the gradients of the output logits w.r.t. the inputs. The common assumption is that these input-gradients contain information regarding $p_{\theta} ( y\mid \mathbf{x} )$, the model's discriminative capabilities, thus justifying their use for interpretability. However, in this work, we show that these input-gradients can be arbitrarily manipulated as a consequence of the shift-invariance of softmax without changing the discriminative function. This leaves an open question: given that input-gradients can be arbitrary, why are they highly structured and explanatory in standard models?

In this work, we re-interpret the logits of standard softmax-based classifiers as unnormalized log-densities of the data distribution and show that input-gradients can be viewed as gradients of a class-conditional generative model $p_{\theta}(\mathbf{x} \mid y)$ implicit in the discriminative model. This leads us to hypothesize that the highly structured and explanatory nature of input-gradients may be due to the alignment of this class-conditional model $p_{\theta}(\mathbf{x} \mid y)$ with that of the ground truth data distribution $p_{\text{data}} (\mathbf{x} \mid y)$. We test this hypothesis by studying the effect of density alignment on gradient explanations. To achieve this density alignment, we use an algorithm called score-matching, and propose novel approximations to this algorithm to enable training large-scale models.

Our experiments show that improving the alignment of the implicit density model with the data distribution enhances gradient structure and explanatory power while reducing this alignment has the opposite effect. This also leads us to conjecture that unintended density alignment in standard neural network training may explain the highly structured nature of input-gradients observed in practice. Overall, our finding that input-gradients capture information regarding an implicit generative model implies that we need to re-think their use for interpreting discriminative models.",識別可能な深層ニューラルネットワークの解釈可能性の現在の方法は、一般にモデルの入力勾配、つまり入力に対する出力ロジットの勾配に依存しています。一般的な仮定は、これらの入力勾配には、モデルの識別能力であるp（）（y X）に関する情報が含まれているため、解釈可能性のためにそれらを使用することを正当化するというものです。ただし、この作業では、これらの入力勾配が、識別関数を変更せずに、softmaxのシフト不変性の結果として任意に操作できることを示します。これは未解決の質問を残します：入力勾配が任意である可能性があることを考えると、なぜそれらは標準モデルで高度に構造化され説明的であるのですか？この作業では、標準のソフトマックスベースの分類器のロジットをデータ分布の正規化されていない対数密度として再解釈し、入力勾配をクラス条件付き生成モデルp（）（X y）の勾配として表示できることを示します。識別モデルに暗黙的に含まれています。これにより、入力勾配の高度に構造化された説明的な性質は、このクラス条件付きモデルp（）（X y）とグラウンドトゥルースデータ分布p（data）（X y）の整合に起因する可能性があるという仮説が導き出されます。 ）。勾配の説明に対する密度の整列の影響を研究することにより、この仮説を検証します。この密度アラインメントを実現するために、スコアマッチングと呼ばれるアルゴリズムを使用し、このアルゴリズムの新しい近似を提案して、大規模モデルのトレーニングを可能にします。私たちの実験は、暗黙の密度モデルとデータ分布のアラインメントを改善すると、勾配構造と説明力が向上する一方で、このアラインメントを減らすと逆の効果があることを示しています。これはまた、標準的なニューラルネットワークトレーニングでの意図しない密度アラインメントが、実際に観察される入力勾配の高度に構造化された性質を説明する可能性があるという推測につながります。全体として、入力勾配が暗黙の生成モデルに関する情報を取得するという私たちの発見は、識別モデルを解釈するためのそれらの使用を再考する必要があることを意味します。,7.5,
Learning-based Support Estimation in Sublinear Time,"['Talya Eden', 'Piotr Indyk', 'Shyam Narayanan', 'Ronitt Rubinfeld', 'Sandeep Silwal', 'Tal Wagner']",https://openreview.net/forum?id=tilovEHA3YS,"We consider the  problem of estimating the number of distinct elements in a large data set (or, equivalently, the support size of the distribution induced by the data set) from a random sample of its elements. The problem occurs in many applications, including biology, genomics, computer systems and linguistics. A line of research spanning the last decade resulted in algorithms that estimate the support up to $ \pm \varepsilon n$ from a sample of size $O(\log^2(1/\varepsilon) \cdot n/\log n)$, where $n$ is the data set size.  Unfortunately, this bound is known to be tight, limiting further improvements to the complexity of this problem. In this paper we consider estimation algorithms augmented with a machine-learning-based predictor that, given any element, returns an estimation of  its frequency.  We show that if the predictor is correct up to a constant approximation factor, then the sample complexity can be reduced significantly,  to
$$ \ \log (1/\varepsilon) \cdot n^{1-\Theta(1/\log(1/\varepsilon))}. $$
We evaluate the proposed algorithms on a collection of data sets, using the neural-network based estimators from {Hsu et al, ICLR'19} as predictors. Our experiments  demonstrate substantial (up to 3x) improvements in the estimation accuracy compared to the state of the art algorithm.",大規模なデータセット内の個別の要素の数（または、同等に、データセットによって誘導される分布のサポートサイズ）を、その要素のランダムサンプルから推定する問題を検討します。この問題は、生物学、ゲノミクス、コンピューターシステム、言語学など、多くのアプリケーションで発生します。過去10年間にわたる一連の調査の結果、サイズO（log2（1 /）n / log n）のサンプルからnまでのサポートを推定するアルゴリズムが得られました。ここでnはデータセットのサイズです。残念ながら、この限界は厳しいことが知られており、この問題の複雑さに対するさらなる改善を制限しています。このホワイトペーパーでは、任意の要素が与えられると、その頻度の推定値を返す機械学習ベースの予測子で拡張された推定アルゴリズムについて検討します。予測子が一定の近似係数まで正しい場合、サンプルの複雑さを大幅に減らしてlog（1 /）n ^（1（1 / log（1 /）））にすることができることを示します。 Hsu et al、ICLR19のニューラルネットワークベースの推定量を予測子として使用して、データセットのコレクションで提案されたアルゴリズムを評価します。私たちの実験は、最先端のアルゴリズムと比較して、推定精度が大幅に（最大3倍）向上することを示しています。,7.5,
Grounded Language Learning Fast and Slow,"['Felix Hill', 'Olivier Tieleman', 'Tamara von Glehn', 'Nathaniel Wong', 'Hamza Merzic', 'Stephen Clark']",https://openreview.net/forum?id=wpSWuz_hyqA,"Recent work has shown that large text-based neural language models acquire a surprising propensity for one-shot learning. Here, we show that an agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional RL algorithms. After a single introduction to a novel object via visual perception and language (""This is a dax""), the agent can manipulate the object as instructed (""Put the dax on the bed""), combining short-term, within-episode knowledge of the nonsense word with long-term lexical and motor knowledge. We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful later. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for 'fast-mapping', a fundamental pillar of human cognitive development and a potentially transformative capacity for artificial agents.   ",最近の研究は、大規模なテキストベースの神経言語モデルがワンショット学習の驚くべき傾向を獲得することを示しています。ここでは、シミュレートされた3Dの世界に配置され、新しいデュアルコーディング外部メモリを備えたエージェントが、従来のRLアルゴリズムでトレーニングされたときに同様のワンショット単語学習を示すことができることを示します。視覚と言語（「これはダックスです」）を介して新しいオブジェクトを1回紹介した後、エージェントは指示に従ってオブジェクトを操作し（「ダックスをベッドに置く」）、短期間のエピソード内の知識を組み合わせます。長期的な語彙と運動の知識を持つナンセンスな単語の。特定のトレーニング条件下で、特定のメモリ書き込みメカニズムを使用すると、エージェントのワンショット単語オブジェクトバインディングは、同じShapeNetカテゴリ内の新しいエグザンプラに一般化され、オブジェクトの数が不慣れな設定で効果的であることがわかります。さらに、デュアルコーディングメモリを本質的な動機付けのシグナルとして活用し、エージェントが後で役立つ可能性のあるオブジェクトの名前を探すように刺激する方法を示します。まとめると、結果は、ディープニューラルネットワークがメタ学習、エピソード記憶、および明示的にマルチモーダルな環境を活用して、高速マッピング、人間の認知発達の基本的な柱、および人工エージェントの潜在的な変革能力を説明できることを示しています。,7.5,https://d3i71xaburhd42.cloudfront.net/412d6f105dc9e0233d2870faf54c59fe7b483a2e/2-Figure1-1.png
Randomized Automatic Differentiation,"['Deniz Oktay', 'Nick McGreivy', 'Joshua Aduol', 'Alex Beatson', 'Ryan P Adams']",https://openreview.net/forum?id=xpx9zj7CUlY,"The successes of deep learning, variational inference, and many other fields have been aided by specialized implementations of reverse-mode automatic differentiation (AD) to compute gradients of mega-dimensional objectives. The AD techniques underlying these tools were designed to compute exact gradients to numerical precision, but modern machine learning models are almost always trained with stochastic gradient descent. Why spend computation and memory on exact (minibatch) gradients only to use them for stochastic optimization? We develop a general framework and approach for randomized automatic differentiation (RAD), which can allow unbiased gradient estimates to be computed with reduced memory in return for variance. We examine limitations of the general approach, and argue that we must leverage problem specific structure to realize benefits. We develop RAD techniques for a variety of simple neural network architectures, and show that for a fixed memory budget, RAD converges in fewer iterations than using a small batch size for feedforward networks, and in a similar number for recurrent networks. We also show that RAD can be applied to scientific computing, and use it to develop a low-memory stochastic gradient method for optimizing the control parameters of a linear reaction-diffusion PDE representing a fission reactor.",深層学習、変分推論、およびその他の多くの分野の成功は、メガ次元の目的の勾配を計算するための逆モード自動微分（AD）の特殊な実装によって支援されてきました。これらのツールの基礎となるAD手法は、数値精度で正確な勾配を計算するように設計されていますが、最新の機械学習モデルは、ほとんどの場合、確率的勾配降下法でトレーニングされています。確率的最適化にのみ使用するために、正確な（ミニバッチ）勾配に計算とメモリを費やすのはなぜですか？ランダム化自動微分（RAD）の一般的なフレームワークとアプローチを開発します。これにより、分散と引き換えにメモリを減らして不偏勾配推定を計算できます。一般的なアプローチの限界を検討し、利益を実現するために問題固有の構造を活用する必要があると主張します。さまざまな単純なニューラルネットワークアーキテクチャ用のRAD手法を開発し、固定メモリバジェットの場合、フィードフォワードネットワークに小さなバッチサイズを使用するよりも少ない反復で、リカレントネットワークに同様の数でRADが収束することを示します。また、RADを科学計算に適用し、それを使用して、核分裂炉を表す線形反応拡散偏微分方程式の制御パラメーターを最適化するための低メモリ確率的勾配法を開発できることも示します。,7.5,https://d3i71xaburhd42.cloudfront.net/766bd9633ea0ed0ee2d8cc11ab083322666a3db9/2-Figure1-1.png
Conditional Generative Modeling via Learning the Latent Space,"['Sameera Ramasinghe', 'Kanchana Nisal Ranasinghe', 'Salman Khan', 'Nick Barnes', 'Stephen Gould']",https://openreview.net/forum?id=VJnrYcnRc6,"Although deep learning has achieved appealing results on several machine learning tasks, most of the models are deterministic at inference, limiting their application to single-modal settings. We propose a novel general-purpose framework for conditional generation in multimodal spaces, that uses latent variables to model generalizable learning patterns while minimizing a family of regression cost functions. At inference, the latent variables are optimized to find optimal solutions corresponding to multiple output modes.  Compared to existing generative solutions, our approach demonstrates faster and stable convergence, and can learn better representations for downstream tasks. Importantly, it provides a simple generic model that can beat highly engineered pipelines tailored using domain expertise on a variety of tasks, while generating diverse outputs. Our codes will be released.",ディープラーニングはいくつかの機械学習タスクで魅力的な結果を達成しましたが、ほとんどのモデルは推論において決定論的であり、アプリケーションを単一モーダル設定に制限しています。マルチモーダル空間での条件付き生成のための新しい汎用フレームワークを提案します。これは、潜在変数を使用して、回帰コスト関数のファミリーを最小化しながら、一般化可能な学習パターンをモデル化します。推論では、潜在変数は、複数の出力モードに対応する最適解を見つけるために最適化されます。既存の生成ソリューションと比較して、私たちのアプローチは、より高速で安定した収束を示し、ダウンストリームタスクのより良い表現を学習できます。重要なのは、さまざまなタスクでドメインの専門知識を使用して調整された高度に設計されたパイプラインを打ち負かし、さまざまな出力を生成できる単純な汎用モデルを提供することです。コードがリリースされます。,7.5,https://d3i71xaburhd42.cloudfront.net/09d7708c4460c74212d09ad7ea9293b210133207/3-Figure1-1.png
The Traveling Observer Model: Multi-task Learning Through Spatial Variable Embeddings,"['Elliot Meyerson', 'Risto Miikkulainen']",https://openreview.net/forum?id=qYda4oLEc1,"This paper frames a general prediction system as an observer traveling around a continuous space, measuring values at some locations, and predicting them at others. The observer is completely agnostic about any particular task being solved; it cares only about measurement locations and their values. This perspective leads to a machine learning framework in which seemingly unrelated tasks can be solved by a single model, by embedding their input and output variables into a shared space. An implementation of the framework is developed in which these variable embeddings are learned jointly with internal model parameters. In experiments, the approach is shown to (1) recover intuitive locations of variables in space and time, (2) exploit regularities across related datasets with completely disjoint input and output spaces, and (3) exploit regularities across seemingly unrelated tasks, outperforming task-specific single-task models and multi-task learning alternatives. The results suggest that even seemingly unrelated tasks may originate from similar underlying processes, a fact that the traveling observer model can use to make better predictions.",この論文では、一般的な予測システムを、連続空間を移動し、ある場所で値を測定し、他の場所でそれらを予測するオブザーバーとして構成します。オブザーバーは、解決されている特定のタスクについて完全に不可知論者です。測定場所とその値のみを考慮します。この視点は、入力変数と出力変数を共有スペースに埋め込むことにより、一見無関係に見えるタスクを単一のモデルで解決できる機械学習フレームワークにつながります。フレームワークの実装が開発され、これらの変数の埋め込みが内部モデルパラメータと一緒に学習されます。実験では、（1）空間と時間の変数の直感的な位置を回復し、（2）完全に分離した入力スペースと出力スペースを持つ関連データセット全体の規則性を活用し、（3）一見無関係なタスク全体の規則性を活用してタスクを上回るアプローチが示されています-特定のシングルタスクモデルとマルチタスク学習の選択肢。結果は、一見無関係に見えるタスクでさえ、同様の基礎となるプロセスから発生する可能性があることを示唆しています。これは、移動するオブザーバーモデルがより良い予測を行うために使用できるという事実です。,7.5,https://d3i71xaburhd42.cloudfront.net/e50e2cba5568a810deeb2e542176802c6d8121f7/1-Figure1-1.png
Winning the L2RPN Challenge: Power Grid Management via Semi-Markov Afterstate Actor-Critic,"['Deunsol Yoon', 'Sunghoon Hong', 'Byung-Jun Lee', 'Kee-Eung Kim']",https://openreview.net/forum?id=LmUJqB1Cz8,"Safe and reliable electricity transmission in power grids is crucial for modern society. It is thus quite natural that there has been a growing interest in the automatic management of power grids, exempliﬁed by the Learning to Run a Power Network Challenge (L2RPN), modeling the problem as a reinforcement learning (RL) task. However, it is highly challenging to manage a real-world scale power grid, mostly due to the massive scale of its state and action space. In this paper, we present an off-policy actor-critic approach that effectively tackles the unique challenges in power grid management by RL, adopting the hierarchical policy together with the afterstate representation. Our agent ranked ﬁrst in the latest challenge (L2RPN WCCI 2020), being able to avoid disastrous situations while maintaining the highest level of operational efﬁciency in every test scenarios. This paper provides a formal description of the algorithmic aspect of our approach, as well as further experimental studies on diverse power grids.",電力網における安全で信頼性の高い送電は、現代社会にとって非常に重要です。したがって、強化学習（RL）タスクとして問題をモデル化する、電力ネットワークチャレンジの実行学習（L2RPN）に代表される、電力網の自動管理への関心が高まっているのは非常に自然なことです。ただし、主にその状態とアクションスペースの大規模さのために、実際の規模の電力網を管理することは非常に困難です。この論文では、後の状態の表現と一緒に階層的なポリシーを採用し、RLによる電力グリッド管理の固有の課題に効果的に取り組む、ポリシー外のアクター批評的アプローチを提示します。私たちのエージェントは、最新のチャレンジ（L2RPN WCCI 2020）で第1位にランクされ、すべてのテストシナリオで最高レベルの運用効率を維持しながら、悲惨な状況を回避することができました。このホワイトペーパーでは、私たちのアプローチのアルゴリズム的側面について正式に説明し、さまざまな電力網に関するさらなる実験的研究を行います。,7.5,
Learning to Reach Goals via Iterated Supervised Learning,"['Dibya Ghosh', 'Abhishek Gupta', 'Ashwin Reddy', 'Coline Manon Devin', 'Benjamin Eysenbach', 'Sergey Levine']",https://openreview.net/forum?id=rALA0Xo6yNJ,"Current reinforcement learning (RL) algorithms can be brittle and difficult to use, especially when learning goal-reaching behaviors from sparse rewards. Although supervised imitation learning provides a simple and stable alternative, it requires access to demonstrations from a human supervisor. In this paper, we study RL algorithms that use imitation learning to acquire goal reaching policies from scratch, without the need for expert demonstrations or a value function. In lieu of demonstrations, we leverage the property that any trajectory is a successful demonstration for reaching the final state in that same trajectory. We propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal-reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. We formally show that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy, and empirically demonstrate improved goal-reaching performance and robustness over current RL algorithms in several benchmark tasks. ",現在の強化学習（RL）アルゴリズムは、特にまばらな報酬から目標に到達する行動を学習する場合、脆弱で使いにくい場合があります。教師あり模倣学習は、シンプルで安定した代替手段を提供しますが、人間の監督者からのデモンストレーションへのアクセスが必要です。この論文では、専門家のデモンストレーションや価値関数を必要とせずに、模倣学習を使用して目標達成ポリシーを最初から取得するRLアルゴリズムを研究します。デモンストレーションの代わりに、どの軌道も同じ軌道の最終状態に到達するための成功したデモンストレーションであるという特性を活用します。エージェントが生成する軌道を継続的に再ラベル付けして模倣し、目標に到達する動作を最初から徐々に学習する単純なアルゴリズムを提案します。反復ごとに、エージェントは最新のポリシーを使用して新しい軌道を収集し、ポリシーを改善するために、実際に達成された目標の下でこれらの軌道に沿ったアクションの可能性を最大化します。この反復教師あり学習手順がRL目標の限界を最適化し、学習したポリシーのパフォーマンス限界を導き出し、いくつかのベンチマークタスクで現在のRLアルゴリズムよりも改善された目標達成パフォーマンスと堅牢性を経験的に実証することを正式に示します。,7.5,
Recurrent Independent Mechanisms,"['Anirudh Goyal', 'Alex Lamb', 'Jordan Hoffmann', 'Shagun Sodhani', 'Sergey Levine', 'Yoshua Bengio', 'Bernhard Schölkopf']",https://openreview.net/forum?id=mLcmdlEUxy-,"We explore the hypothesis that learning modular structures which reflect the dynamics of the environment can lead to better generalization and robustness to changes that only affect a few of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a new recurrent architecture in which multiple groups of recurrent cells operate with nearly independent transition dynamics, communicate only sparingly through the bottleneck of attention, and compete with each other so they are updated only at time steps where they are most relevant.  We show that this leads to specialization amongst the RIMs, which in turn allows for remarkably improved generalization on tasks where some factors of variation differ systematically between training and evaluation.
",環境のダイナミクスを反映するモジュラー構造を学習することで、根本的な原因のいくつかにのみ影響する変更に対する一般化と堅牢性を向上させることができるという仮説を探ります。反復セルの複数のグループがほぼ独立した遷移ダイナミクスで動作し、注意のボトルネックを介して控えめにのみ通信し、互いに競合するため、時間ステップでのみ更新される新しい反復アーキテクチャである反復独立メカニズム（RIM）を提案します。それらは最も関連性があります。これにより、RIM間の特殊化が可能になり、トレーニングと評価の間で変動のいくつかの要因が体系的に異なるタスクの一般化が大幅に改善されることを示します。,7.5,https://d3i71xaburhd42.cloudfront.net/2f28e6c7056883c54ef561fd039e9b10c0a3585b/2-Figure1-1.png
Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric graphs,"['Pim De Haan', 'Maurice Weiler', 'Taco Cohen', 'Max Welling']",https://openreview.net/forum?id=Jnspzp-oIZE,"A common approach to define convolutions on meshes is to interpret them as a graph and apply graph convolutional networks (GCNs).  Such GCNs utilize isotropic kernels and are therefore insensitive to the relative orientation of vertices and thus to the geometry of the mesh as a whole. We propose Gauge Equivariant Mesh CNNs which generalize GCNs to apply anisotropic gauge equivariant kernels. Since the resulting features carry orientation information, we introduce a geometric message passing scheme defined by parallel transporting features over mesh edges. Our experiments validate the significantly improved expressivity of the proposed model over conventional GCNs and other methods.",メッシュの畳み込みを定義する一般的なアプローチは、メッシュをグラフとして解釈し、グラフ畳み込みネットワーク（GCN）を適用することです。このようなGCNは等方性カーネルを利用するため、頂点の相対的な向き、したがってメッシュ全体のジオメトリの影響を受けません。異方性ゲージ同変カーネルを適用するためにGCNを一般化するゲージ同変メッシュCNNを提案します。結果として得られる特徴は方向情報を運ぶので、メッシュエッジ上での平行移動特徴によって定義される幾何学的メッセージパッシングスキームを導入します。私たちの実験は、従来のGCNや他の方法に比べて提案されたモデルの大幅に改善された表現力を検証します。,7.5,
Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images,['Rewon Child'],https://openreview.net/forum?id=RLRXCV6DbEJ,"We present a hierarchical VAE that, for the first time, outperforms the PixelCNN in log-likelihood on all natural image benchmarks. Our work is motivated by the observation that VAEs can actually implement autoregressive models, and other, more efficient generative models, if made sufficiently deep. Despite this, autoregressive models have traditionally outperformed VAEs. To test if depth explains why, we develop an architecture with more stochastic layers than previous work and train it on CIFAR-10, ImageNet, and FFHQ. We find that, in comparison to the PixelCNN, very deep VAEs achieve higher likelihoods, use fewer parameters, generate samples thousands of times faster, and are more easily applied to high-resolution images. We attribute this to the VAEs learning efficient hierarchical representations, which we verify with visualizations of the generative process.",階層型VAEを初めて提示します。これは、すべての自然画像ベンチマークで対数尤度でPixelCNNを初めて上回ります。私たちの仕事は、VAEが十分に深くなれば、自己回帰モデルや他のより効率的な生成モデルを実際に実装できるという観察に動機付けられています。それにもかかわらず、自己回帰モデルは伝統的にVAEを上回っています。深さが理由を説明するかどうかをテストするために、以前の作業よりも確率的なレイヤーを備えたアーキテクチャを開発し、CIFAR-10、ImageNet、およびFFHQでトレーニングします。 PixelCNNと比較して、非常に深いVAEは、より高い可能性を達成し、より少ないパラメーターを使用し、数千倍速くサンプルを生成し、高解像度画像により簡単に適用できることがわかります。これは、VAEが効率的な階層表現を学習しているためであり、生成プロセスの視覚化によって検証されます。,7.5,https://d3i71xaburhd42.cloudfront.net/3e577c9bdc82cb7fed337a74f90bbc4505fdfb69/1-Figure1-1.png
Parrot: Data-Driven Behavioral Priors for Reinforcement Learning,"['Avi Singh', 'Huihan Liu', 'Gaoyue Zhou', 'Albert Yu', 'Nicholas Rhinehart', 'Sergey Levine']",https://openreview.net/forum?id=Ysuv-WOFeKR,"Reinforcement learning provides a general framework for flexible decision making and control, but requires extensive data collection for each new task that an agent needs to learn. In other machine learning fields, such as natural language processing or computer vision, pre-training on large, previously collected datasets to bootstrap learning for new tasks has emerged as a powerful paradigm to reduce data requirements when learning a new task. In this paper, we ask the following question: how can we enable similarly useful pre-training for RL agents? We propose a method for pre-training behavioral priors that can capture complex input-output relationships observed in successful trials from a wide range of previously seen tasks, and we show how this learned prior can be used for rapidly learning new tasks without impeding the RL agent's ability to try out novel behaviors. We demonstrate the effectiveness of our approach in challenging robotic manipulation domains involving image observations and sparse reward functions, where our method outperforms prior works by a substantial margin. ",強化学習は、柔軟な意思決定と制御のための一般的なフレームワークを提供しますが、エージェントが学習する必要のある新しいタスクごとに広範なデータ収集を必要とします。自然言語処理やコンピュータービジョンなどの他の機械学習分野では、以前に収集した大規模なデータセットを事前トレーニングして、新しいタスクの学習をブートストラップすることが、新しいタスクを学習する際のデータ要件を削減する強力なパラダイムとして浮上しています。このホワイトペーパーでは、次の質問をします。RLエージェントに対して同様に役立つ事前トレーニングを有効にするにはどうすればよいですか。以前に見たさまざまなタスクからの成功した試行で観察された複雑な入出力関係をキャプチャできる行動事前確率を事前トレーニングする方法を提案し、この学習した事前確率を使用して、RLを妨げることなく新しいタスクを迅速に学習する方法を示します。エージェントが新しい行動を試す能力。私たちは、画像観察とまばらな報酬関数を含むロボット操作領域に挑戦する際のアプローチの有効性を示しています。,7.5,https://d3i71xaburhd42.cloudfront.net/f5275f5eb6569ddb5ba9a959ede09875d56e3bac/2-Figure1-1.png
End-to-end Adversarial Text-to-Speech,"['Jeff Donahue', 'Sander Dieleman', 'Mikolaj Binkowski', 'Erich Elsen', 'Karen Simonyan']",https://openreview.net/forum?id=rsf1z-JSj87,"Modern text-to-speech synthesis pipelines typically involve multiple processing stages, each of which is designed or learnt independently from the rest. In this work, we take on the challenging task of learning to synthesise speech from normalised text or phonemes in an end-to-end manner, resulting in models which operate directly on character or phoneme input sequences and produce raw speech audio outputs. Our proposed generator is feed-forward and thus efficient for both training and inference, using a differentiable alignment scheme based on token length prediction. It learns to produce high fidelity audio through a combination of adversarial feedback and prediction losses constraining the generated audio to roughly match the ground truth in terms of its total duration and mel-spectrogram. To allow the model to capture temporal variation in the generated audio, we employ soft dynamic time warping in the spectrogram-based prediction loss. The resulting model achieves a mean opinion score exceeding 4 on a 5 point scale, which is comparable to the state-of-the-art models relying on multi-stage training and additional supervision.",最新のテキスト読み上げ合成パイプラインには通常、複数の処理段階が含まれ、各段階は他の段階から独立して設計または学習されます。この作業では、正規化されたテキストまたは音素からエンドツーエンドの方法で音声を合成することを学習するという難しいタスクに取り組み、文字または音素の入力シーケンスを直接操作して生の音声音声出力を生成するモデルを作成します。提案されたジェネレーターはフィードフォワードであるため、トークンの長さの予測に基づく微分可能なアライメントスキームを使用して、トレーニングと推論の両方に効率的です。敵対的なフィードバックと予測損失の組み合わせにより、生成されたオーディオがその合計持続時間とメルスペクトログラムの点でグラウンドトゥルースとほぼ一致するように制約することにより、忠実度の高いオーディオを生成することを学習します。モデルが生成されたオーディオの時間的変動をキャプチャできるようにするために、スペクトログラムベースの予測損失にソフトダイナミックタイムワーピングを採用しています。結果として得られるモデルは、5ポイントスケールで4を超える平均オピニオン評点を達成します。これは、多段階のトレーニングと追加の監督に依存する最先端のモデルに匹敵します。,7.5,https://d3i71xaburhd42.cloudfront.net/c035cf0e1231eb196968d7255ab55827e932ec7a/3-Figure1-1.png
Correcting experience replay for multi-agent communication,"['Sanjeevan Ahilan', 'Peter Dayan']",https://openreview.net/forum?id=xvxPuCkCNPO,"We consider the problem of learning to communicate using multi-agent reinforcement learning (MARL). A common approach is to learn off-policy, using data sampled from a replay buffer. However, messages received in the past may not accurately reflect the current communication policy of each agent, and this complicates learning. We therefore introduce a 'communication correction' which accounts for the non-stationarity of observed communication induced by multi-agent learning. It works by relabelling the received message to make it likely under the communicator's current policy, and thus be a better reflection of the receiver's current environment. To account for cases in which agents are both senders and receivers, we introduce an ordered relabelling scheme. Our correction is computationally efficient and can be integrated with a range of off-policy algorithms. We find in our experiments that it substantially improves the ability of communicating MARL systems to learn across a variety of cooperative and competitive tasks.",マルチエージェント強化学習（MARL）を使用してコミュニケーションを学習することの問題を検討します。一般的なアプローチは、再生バッファーからサンプリングされたデータを使用して、ポリシー外を学習することです。ただし、過去に受信​​したメッセージは、各エージェントの現在の通信ポリシーを正確に反映していない可能性があり、これにより学習が複雑になります。したがって、マルチエージェント学習によって誘発された観測されたコミュニケーションの非定常性を説明するコミュニケーション修正を紹介します。これは、受信したメッセージにラベルを付け直して、コミュニケーターの現在のポリシーの下でメッセージを送信できるようにすることで機能します。これにより、受信者の現在の環境をより適切に反映できます。エージェントが送信者と受信者の両方である場合を説明するために、順序付けられた再ラベル付けスキームを導入します。私たちの修正は計算効率が高く、さまざまなポリシー外のアルゴリズムと統合できます。私たちの実験では、MARLシステムを通信して、さまざまな協調的および競争的なタスクにわたって学習する能力が大幅に向上することがわかりました。,7.5,https://d3i71xaburhd42.cloudfront.net/fddd1bc82e4460b4dc0e18a6a82dad924474ccde/4-Figure1-1.png
Global Convergence of Three-layer Neural Networks in the Mean Field Regime,"['Huy Tuan Pham', 'Phan-Minh Nguyen']",https://openreview.net/forum?id=KvyxFqZS_D,"In the mean field regime, neural networks are appropriately scaled so that as the width tends to infinity, the learning dynamics tends to a nonlinear and nontrivial dynamical limit, known as the mean field limit. This lends a way to study large-width neural networks via analyzing the mean field limit. Recent works have successfully applied such analysis to two-layer networks and provided global convergence guarantees. The extension to multilayer ones however has been a highly challenging puzzle, and little is known about the optimization efficiency in the mean field regime when there are more than two layers.

In this work, we prove a global convergence result for unregularized feedforward three-layer networks in the mean field regime. We first develop a rigorous framework to establish the mean field limit of three-layer networks under stochastic gradient descent training. To that end, we propose the idea of a neuronal embedding, which comprises of a fixed probability space that encapsulates neural networks of arbitrary sizes. The identified mean field limit is then used to prove a global convergence guarantee under suitable regularity and convergence mode assumptions, which – unlike previous works on two-layer networks – does not rely critically on convexity. Underlying the result is a universal approximation property, natural of neural networks, which importantly is shown to hold at any finite training time (not necessarily at convergence) via an algebraic topology argument.",平均場レジームでは、幅が無限大になる傾向があるため、学習ダイナミクスが平均場限界として知られる非線形で自明でない動的限界になるように、ニューラルネットワークが適切にスケーリングされます。これは、平均場限界を分析することにより、大幅ニューラルネットワークを研究する方法を提供します。最近の研究は、そのような分析を2層ネットワークにうまく適用し、グローバルな収束保証を提供しています。しかし、多層のものへの拡張は非常に挑戦的なパズルであり、3つ以上の層がある場合の平均場レジームでの最適化効率についてはほとんど知られていません。この作業では、平均場レジームにおける非正規化フィードフォワード3層ネットワークのグローバル収束結果を証明します。最初に、確率的勾配降下法のトレーニングの下で​​3層ネットワークの平均場限界を確立するための厳密なフレームワークを開発します。そのために、任意のサイズのニューラルネットワークをカプセル化する固定確率空間で構成されるニューロン埋め込みのアイデアを提案します。次に、識別された平均場限界を使用して、適切な規則性と収束モードの仮定の下でグローバル収束保証を証明します。これは、2層ネットワークでの以前の作業とは異なり、凸性に大きく依存しません。結果の根底にあるのは、ニューラルネットワークの自然な普遍近似特性です。これは、代数的トポロジー引数を介して、任意の有限トレーニング時間（必ずしも収束時ではない）で保持されることが重要です。,7.5,
What are the Statistical Limits of Offline RL with Linear Function Approximation?,"['Ruosong Wang', 'Dean Foster', 'Sham M. Kakade']",https://openreview.net/forum?id=30EvkP2aQLD,"Offline reinforcement learning seeks to utilize offline (observational) data to guide the learning of (causal) sequential decision making strategies. The hope is that offline reinforcement learning coupled with function approximation methods (to deal with the curse of dimensionality) can provide a means to help alleviate the excessive sample complexity burden in modern sequential decision making problems. However, the extent to which this broader approach can be effective is not well understood, where the literature largely consists of sufficient conditions.
This work focuses on the basic question of what are necessary representational and distributional conditions that permit provable sample-efficient offline reinforcement learning. Perhaps surprisingly, our main result shows that even if: i) we have realizability in that the true value function of \emph{every} policy is linear in a given set of features and 2) our off-policy data has good  coverage over all features (under a strong spectral condition), then any algorithm still (information-theoretically) requires a number of offline samples that is exponential in the problem horizon in order to non-trivially estimate the value of \emph{any} given policy. Our results highlight that sample-efficient offline policy evaluation is simply not possible unless significantly stronger conditions hold; such conditions include either having low distribution shift (where the offline data distribution is close to the distribution of the policy to be evaluated) or significantly stronger representational conditions (beyond realizability).",オフライン強化学習は、オフライン（観察）データを利用して、（因果的）順次意思決定戦略の学習をガイドしようとします。関数近似法（次元の呪いに対処するため）と組み合わせたオフライン強化学習が、現代の順次意思決定問題における過度のサンプル複雑性の負担を軽減するのに役立つ手段を提供できることが期待されています。ただし、このより広範なアプローチが効果的である範囲は十分に理解されておらず、文献は主に十分条件で構成されています。この作業は、証明可能なサンプル効率の高いオフライン強化学習を可能にする必要な表現および分布条件が何であるかという基本的な質問に焦点を当てています。おそらく驚くべきことに、私たちの主な結果は、次の場合でも、i）すべてのポリシーの真の値関数が特定の機能セットで線形であるという実現可能性があり、2）ポリシー外のデータがすべての機能（強いスペクトル条件）の場合、アルゴリズムは（情報理論的に）、特定のポリシーの値を自明ではないように推定するために、問題の範囲内で指数関数的な多数のオフラインサンプルを必要とします。私たちの結果は、非常に強い条件が満たされない限り、サンプル効率の高いオフラインポリシー評価は単純に不可能であることを強調しています。このような条件には、配布シフトが小さい（オフラインデータ配布が評価対象のポリシーの配布に近い）か、表現条件が大幅に強い（実現可能性を超えている）かのいずれかが含まれます。,7.5,https://d3i71xaburhd42.cloudfront.net/bf53ddef241c58303b509faad4ec7514d3a6fc14/9-Figure1-1.png
Learning with feature dependent label noise: a progressive approach,"['Yikai Zhang', 'Songzhu Zheng', 'Pengxiang Wu', 'Mayank Goswami', 'Chao Chen']",https://openreview.net/forum?id=ZPa2SyGcbwh,"Label noise is frequently observed in real world large scale datasets. The noise is introduced due to a variety of reasons; it is heterogeneous and feature-dependent. Most existing approaches to handle noisy labels fall into two categories: they either assume an ideal feature-independent noise, or remain heuristic without theoretical guarantees. 
In this paper, we propose to target a new family of feature-dependent label noise. 
This is much more general than commonly used i.i.d.~label noise and encompasses a broad spectrum of noise patterns.
Focusing on this general noise family, we propose a progressive label correction algorithm that iteratively corrects labels and refine the model. We provide theoretical guarantees showing that for a wide variety of (unknown) noise patterns, a classifier trained with this strategy will converge to be consistent with the Bayes classifier. 
On different datasets, our method outperforms multiple SOTA baselines and is robust to various noise types and levels.",ラベルノイズは、実世界の大規模データセットで頻繁に観察されます。ノイズはさまざまな理由で発生します。それは異種であり、機能に依存します。ノイズの多いラベルを処理するための既存のアプローチのほとんどは、2つのカテゴリに分類されます。理想的な機能に依存しないノイズを想定するか、理論的な保証なしにヒューリスティックなままです。この論文では、特徴に依存するラベルノイズの新しいファミリをターゲットにすることを提案します。これは、一般的に使用されるiidラベルノイズよりもはるかに一般的であり、幅広いノイズパターンを網羅しています。この一般的なノイズファミリに焦点を当てて、ラベルを繰り返し修正し、モデルを改良するプログレッシブラベル修正アルゴリズムを提案します。多種多様な（未知の）ノイズパターンに対して、この戦略でトレーニングされた分類器が収束してベイズ分類器と一致することを示す理論的保証を提供します。さまざまなデータセットで、私たちの方法は複数のSOTAベースラインを上回り、さまざまなノイズタイプとレベルに対して堅牢です。,7.5,
Gradient Projection Memory for Continual Learning,"['Gobinda Saha', 'Kaushik Roy']",https://openreview.net/forum?id=3AOj0RCNC2,"The ability to learn continually without forgetting the past tasks is a desired attribute for artificial learning systems. Existing approaches to enable such learning in artificial neural networks usually rely on network growth, importance based weight update or replay of old data from the memory. In contrast, we propose a novel approach where a neural network learns new tasks by taking gradient steps in the orthogonal direction to the gradient subspaces deemed important for past tasks. We find the bases of these subspaces by analyzing network representations (activations) after learning each task with Singular Value Decomposition (SVD) in a single shot manner and store them in the memory as Gradient Projection Memory (GPM). With qualitative and quantitative analyses, we show that such orthogonal gradient decent induces minimum to no interference with the past tasks, thereby mitigating forgetting. We evaluate our algorithm on diverse image classification datasets with short and long sequences of tasks and report better or on-par performance compared to the state-of-the-art approaches. ",過去の課題を忘れずに継続的に学習できることは、人工学習システムにとって望ましい属性です。人工ニューラルネットワークでこのような学習を可能にする既存のアプローチは、通常、ネットワークの成長、重要度に基づく重みの更新、またはメモリからの古いデータの再生に依存しています。対照的に、ニューラルネットワークが過去のタスクにとって重要であると考えられる勾配部分空間に直交する方向に勾配ステップをとることによって新しいタスクを学習する新しいアプローチを提案します。特異値分解（SVD）を使用して各タスクをシングルショットで学習した後、ネットワーク表現（アクティブ化）を分析してこれらの部分空間のベースを見つけ、勾配投影メモリ（GPM）としてメモリに保存します。定性的および定量的分析により、このような直交最急降下法が過去のタスクへの干渉を最小限に抑えるか、まったく引き起こさないことを示し、それによって忘却を軽減します。タスクの短いシーケンスと長いシーケンスを持つ多様な画像分類データセットでアルゴリズムを評価し、最先端のアプローチと比較して、より優れた、または同等のパフォーマンスを報告します。,7.5,
Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures,"['Pedro Hermosilla', 'Marco Schäfer', 'Matej Lang', 'Gloria Fackelmann', 'Pere-Pau Vázquez', 'Barbora Kozlikova', 'Michael Krone', 'Tobias Ritschel', 'Timo Ropinski']",https://openreview.net/forum?id=l0mSUROpwY,"Proteins perform a large variety of functions in living organisms and thus play a key role in biology. However, commonly used algorithms in protein representation learning were not specifically designed for protein data, and are therefore not able to capture all relevant structural levels of a protein during learning. To fill this gap, we propose two new learning operators, specifically designed to process protein structures. First, we introduce a novel convolution operator that considers the primary, secondary, and tertiary structure of a protein by using $n$-D convolutions defined on both the Euclidean distance, as well as multiple geodesic distances between the atoms in a multi-graph. Second, we introduce a set of hierarchical pooling operators that enable multi-scale protein analysis. We further evaluate the accuracy of our algorithms on common downstream tasks, where we outperform state-of-the-art protein learning algorithms.",タンパク質は生物の中で多種多様な機能を果たし、生物学において重要な役割を果たします。ただし、タンパク質表現学習で一般的に使用されるアルゴリズムは、タンパク質データ用に特別に設計されたものではないため、学習中にタンパク質の関連するすべての構造レベルをキャプチャすることはできません。このギャップを埋めるために、タンパク質構造を処理するために特別に設計された2つの新しい学習演算子を提案します。最初に、ユークリッド距離とマルチグラフ内の原子間の複数の測地線距離の両方で定義されたnD畳み込みを使用して、タンパク質の一次、二次、および三次構造を考慮する新しい畳み込み演算子を紹介します。次に、マルチスケールタンパク質分析を可能にする一連の階層型プーリング演算子を紹介します。さらに、最先端のタンパク質学習アルゴリズムよりも優れた、一般的なダウンストリームタスクでのアルゴリズムの精度を評価します。,7.4,
Sequential Density Ratio Estimation for Simultaneous Optimization of Speed and Accuracy,"['Akinori F Ebihara', 'Taiki Miyagawa', 'Kazuyuki Sakurai', 'Hitoshi Imaoka']",https://openreview.net/forum?id=Rhsu5qD36cL,"Classifying sequential data as early and as accurately as possible is a challenging yet critical problem, especially when a sampling cost is high. One algorithm that achieves this goal is the sequential probability ratio test (SPRT), which is known as Bayes-optimal: it can keep the expected number of data samples as small as possible, given the desired error upper-bound. However, the original SPRT makes two critical assumptions that limit its application in real-world scenarios: (i) samples are independently and identically distributed, and (ii) the likelihood of the data being derived from each class can be calculated precisely. Here, we propose the SPRT-TANDEM, a deep neural network-based SPRT algorithm that overcomes the above two obstacles. The SPRT-TANDEM sequentially estimates the log-likelihood ratio of two alternative hypotheses by leveraging a novel Loss function for Log-Likelihood Ratio estimation (LLLR) while allowing correlations up to $N (\in \mathbb{N})$  preceding samples. In tests on one original and two public video databases, Nosaic MNIST, UCF101, and SiW, the SPRT-TANDEM achieves statistically significantly better classification accuracy than other baseline classifiers, with a smaller number of data samples. The code and Nosaic MNIST are publicly available at https://anonymous.4open.science/r/8e802b42-ec6f-4545-b34e-fb320cba4c4d/#home.",シーケンシャルデータをできるだけ早く正確に分類することは、特にサンプリングコストが高い場合、困難でありながら重大な問題です。この目標を達成する1つのアルゴリズムは、ベイズ最適として知られる逐次確率比検定（SPRT）です。これは、目的のエラーの上限が与えられた場合に、予想されるデータサンプル数を可能な限り少なく保つことができます。ただし、元のSPRTは、実際のシナリオでの適用を制限する2つの重要な仮定を行っています。（i）サンプルが独立して同一に分布していること、および（ii）各クラスからデータが派生する可能性を正確に計算できることです。ここでは、上記の2つの障害を克服するディープニューラルネットワークベースのSPRTアルゴリズムであるSPRT-TANDEMを提案します。 SPRT-TANDEMは、対数尤度比推定（LLLR）の新しい損失関数を利用して、2つの対立仮説の対数尤度比を順次推定し、先行するサンプルN（N）までの相関を可能にします。 1つのオリジナルビデオデータベースと2つのパブリックビデオデータベース、Nosaic MNIST、UCF101、およびSiWでのテストでは、SPRT-TANDEMは、データサンプルの数が少なく、他のベースライン分類器よりも統計的に有意に優れた分類精度を実現します。コードとNosaicMNISTは、https：//anonymous.4open.science/r/8e802b42-ec6f-4545-b34e-fb320cba4c4d/#homeで公開されています。,7.4,
Tent: Fully Test-Time Adaptation by Entropy Minimization,"['Dequan Wang', 'Evan Shelhamer', 'Shaoteng Liu', 'Bruno Olshausen', 'Trevor Darrell']",https://openreview.net/forum?id=uXl3bZLkr3c,"A model must adapt itself to generalize to new and different data during testing. This is the setting of fully test-time adaptation given only unlabeled test data and the model parameters. We propose test-time entropy minimization (tent): we optimize for model confidence as measured by the entropy of its predictions. During testing, we adapt the model features by estimating normalization statistics and optimizing channel-wise affine transformations. Tent improves robustness to corruptions for image classification on ImageNet and CIFAR-10/100 and achieves state-of-the-art error on ImageNet-C for ResNet-50. Tent shows the feasibility of target-only domain adaptation for digit classification from SVHN to MNIST/MNIST-M/USPS and semantic segmentation from GTA to Cityscapes.",モデルは、テスト中に新しい異なるデータに一般化するように適応する必要があります。これは、ラベルのないテストデータとモデルパラメータのみが与えられた場合の完全なテスト時間適応の設定です。テスト時のエントロピー最小化（テント）を提案します。予測のエントロピーによって測定されるモデルの信頼性を最適化します。テスト中に、正規化統計を推定し、チャネルごとのアフィン変換を最適化することにより、モデルの機能を適応させます。 Tentは、ImageNetおよびCIFAR-10 / 100での画像分類の破損に対する堅牢性を向上させ、ResNet-50のImageNet-Cで最先端のエラーを実現します。テントは、SVHNからMNIST / MNIST-M / USPSへの数字分類、およびGTAから都市景観へのセマンティックセグメンテーションのためのターゲットのみのドメイン適応の実現可能性を示しています。,7.33,https://d3i71xaburhd42.cloudfront.net/9ce09b03f056253252f3e8c0c65d86a27117a0ac/2-Figure1-1.png
UPDeT: Universal Multi-agent RL via Policy Decoupling with Transformers,"['Siyi Hu', 'Fengda Zhu', 'Xiaojun Chang', 'Xiaodan Liang']",https://openreview.net/forum?id=v9c7hr9ADKx,"Recent advances in multi-agent reinforcement learning have been largely limited in training one model from scratch for every new task. The limitation is due to the restricted model architecture related to fixed input and output dimensions. This hinders the experience accumulation and transfer of the learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs 6 multi-agent games).  In this paper, we make the first attempt to explore a universal multi-agent reinforcement learning pipeline, designing one single architecture to fit tasks with the requirement of different observation and action configurations. Unlike previous RNN-based models, we utilize a transformer-based model to generate a flexible policy by decoupling the policy distribution from the intertwined input observation with an importance weight measured by the merits of the self-attention mechanism. Compared to a standard transformer block, the proposed model, named as Universal Policy Decoupling Transformer (UPDeT), further relaxes the action restriction and makes the multi-agent task's decision process more explainable. UPDeT is general enough to be plugged into any multi-agent reinforcement learning pipeline and equip them with strong generalization abilities that enables the handling of multiple tasks at a time. Extensive experiments on large-scale SMAC multi-agent competitive games demonstrate that the proposed UPDeT-based multi-agent reinforcement learning achieves significant results relative to state-of-the-art approaches, demonstrating advantageous transfer capability in terms of both performance and training speed (10 times faster).",マルチエージェント強化学習の最近の進歩は、新しいタスクごとに1つのモデルを最初からトレーニングすることで大きく制限されています。この制限は、固定の入力および出力ディメンションに関連する制限されたモデルアーキテクチャによるものです。これは、さまざまなレベルの難易度のタスク（たとえば、3対3または5対6のマルチエージェントゲーム）での学習したエージェントの経験の蓄積と転送を妨げます。このホワイトペーパーでは、ユニバーサルマルチエージェント強化学習パイプラインを探索する最初の試みを行い、さまざまな観察およびアクション構成の要件を持つタスクに適合する単一のアーキテクチャを設計します。以前のRNNベースのモデルとは異なり、トランスフォーマーベースのモデルを利用して、自己注意メカニズムのメリットによって測定される重要度の重みを使用して、絡み合った入力観測からポリシー分布を分離することにより、柔軟なポリシーを生成します。標準のトランスフォーマーブロックと比較して、Universal Policy Decoupleing Transformer（UPDeT）という名前の提案されたモデルは、アクションの制限をさらに緩和し、マルチエージェントタスクの決定プロセスをより説明しやすくします。 UPDeTは、マルチエージェント強化学習パイプラインにプラグインできるほど一般的であり、一度に複数のタスクを処理できる強力な一般化機能を備えています。大規模なSMACマルチエージェント競争ゲームに関する広範な実験は、提案されたUPDeTベースのマルチエージェント強化学習が最先端のアプローチと比較して有意な結果を達成することを示し、パフォーマンスとトレーニング速度の両方の点で有利な転送能力を示しています（10倍速い）。,7.33,
Evolving Reinforcement Learning Algorithms,"['John D Co-Reyes', 'Yingjie Miao', 'Daiyi Peng', 'Quoc V Le', 'Sergey Levine', 'Honglak Lee', 'Aleksandra Faust']",https://openreview.net/forum?id=0XXpJ4OtjW,"We propose a method for meta-learning reinforcement learning algorithms by searching over the space of computational graphs which compute the loss function for a value-based model-free RL agent to optimize. The learned algorithms are domain-agnostic and can generalize to new environments not seen during training. Our method can both learn from scratch and bootstrap off known existing algorithms, like DQN, enabling interpretable modifications which improve performance. Learning from scratch on simple classical control and gridworld tasks, our method rediscovers the temporal-difference (TD) algorithm. Bootstrapped from DQN, we highlight two learned algorithms which obtain good generalization performance over other classical control tasks, gridworld type tasks, and Atari games. The analysis of the learned algorithm behavior shows resemblance to recently proposed RL algorithms that address overestimation in value-based methods.",最適化する値ベースのモデルフリーRLエージェントの損失関数を計算する計算グラフの空間を検索することにより、メタ学習強化学習アルゴリズムの方法を提案します。学習したアルゴリズムはドメインに依存せず、トレーニング中には見ら​​れない新しい環境に一般化できます。私たちの方法は、ゼロから学習し、DQNなどの既知の既存のアルゴリズムをブートストラップして、パフォーマンスを向上させる解釈可能な変更を可能にします。単純な古典制御とgridworldタスクをゼロから学習することで、私たちの方法は時間差（TD）アルゴリズムを再発見します。 DQNからブートストラップされ、他の古典的な制御タスク、gridworldタイプのタスク、およびAtariゲームよりも優れた一般化パフォーマンスを実現する2つの学習済みアルゴリズムに焦点を当てます。学習したアルゴリズムの動作の分析は、値ベースの方法での過大評価に対処する最近提案されたRLアルゴリズムとの類似性を示しています。,7.33,https://d3i71xaburhd42.cloudfront.net/b88840a3ba1e404db9814047f52ea3fec2c48fa7/2-Figure1-1.png
Unsupervised Object Keypoint Learning using Local Spatial Predictability,"['Anand Gopalakrishnan', 'Sjoerd van Steenkiste', 'Jürgen Schmidhuber']",https://openreview.net/forum?id=GJwMHetHc73,"We propose PermaKey, a novel approach to representation learning based on object keypoints. It leverages the predictability of local image regions from spatial neighborhoods to identify salient regions that correspond to object parts, which are then converted to keypoints. Unlike prior approaches, it utilizes predictability to discover object keypoints, an intrinsic property of objects. This ensures that it does not overly bias keypoints to focus on characteristics that are not unique to objects, such as movement, shape, colour etc.  We demonstrate the efficacy of PermaKey on Atari where it learns keypoints corresponding to the most salient object parts and is robust to certain visual distractors. Further, on downstream RL tasks in the Atari domain we demonstrate how agents equipped with our keypoints outperform those using competing alternatives, even on challenging environments with moving backgrounds or distractor objects.
",オブジェクトのキーポイントに基づく表現学習への新しいアプローチであるPermaKeyを提案します。空間的近隣からのローカル画像領域の予測可能性を活用して、オブジェクトパーツに対応する顕著な領域を識別し、それがキーポイントに変換されます。以前のアプローチとは異なり、予測可能性を利用して、オブジェクトの固有のプロパティであるオブジェクトのキーポイントを検出します。これにより、動き、形状、色など、オブジェクトに固有ではない特性に焦点を合わせるためにキーポイントに過度のバイアスがかからないことが保証されます。最も顕著なオブジェクトパーツに対応するキーポイントを学習するAtariでのPermaKeyの有効性を示します。特定の視覚的注意散漫に対して堅牢です。さらに、AtariドメインのダウンストリームRLタスクでは、背景やディストラクタオブジェクトが移動する困難な環境でも、キーポイントを備えたエージェントが競合する代替手段を使用したエージェントよりも優れていることを示します。,7.33,https://d3i71xaburhd42.cloudfront.net/c399fcb43a9475c6a9abad12011f44564bc40c32/2-Figure1-1.png
Rao-Blackwellizing the Straight-Through Gumbel-Softmax Gradient Estimator,"['Max B Paulus', 'Chris J. Maddison', 'Andreas Krause']",https://openreview.net/forum?id=Mk6PZtgAgfq,"Gradient estimation in models with discrete latent variables is a challenging problem, because the simplest unbiased estimators tend to have high variance. To counteract this, modern estimators either introduce bias, rely on multiple function evaluations, or use learned, input-dependent baselines. Thus, there is a need for estimators that require minimal tuning, are computationally cheap, and have low mean squared error. In this paper, we show that the variance of the straight-through variant of the popular Gumbel-Softmax estimator can be reduced through Rao-Blackwellization without increasing the number of function evaluations. This provably reduces the mean squared error. We empirically demonstrate that this leads to variance reduction, faster convergence, and generally improved performance in two unsupervised latent variable models.",最も単純な不偏推定量は分散が大きい傾向があるため、離散潜在変数を持つモデルの勾配推定は困難な問題です。これに対抗するために、最新の推定量は、バイアスを導入するか、複数の関数評価に依存するか、学習された入力依存のベースラインを使用します。したがって、最小限の調整を必要とし、計算コストが低く、平均二乗誤差が低い推定量が必要です。この論文では、人気のあるガンベル-ソフトマックス推定量のストレートスルーバリアントの分散が、関数評価の数を増やすことなく、Rao-Blackwellizationによって減らすことができることを示します。これにより、平均二乗誤差が確実に減少します。これにより、2つの教師なし潜在変数モデルで分散が減少し、収束が速くなり、パフォーマンスが一般的に向上することを経験的に示します。,7.33,https://d3i71xaburhd42.cloudfront.net/e61db54fe46bd13e1ef7a6ce293f4db202e3317e/6-Figure1-1.png
Stabilized Medical Image Attacks,"['Gege Qi', 'Lijun GONG', 'Yibing Song', 'Kai Ma', 'Yefeng Zheng']",https://openreview.net/forum?id=QfTXQiGYudJ,"Convolutional Neural Networks (CNNs) have advanced existing medical systems for automatic disease diagnosis. However, a threat to these systems arises that adversarial attacks make CNNs vulnerable. Inaccurate diagnosis results make a negative influence on human healthcare. There is a need to investigate potential adversarial attacks to robustify deep medical diagnosis systems. On the other side, there are several modalities of medical images (e.g., CT, fundus, and endoscopic image) of which each type is significantly different from others. It is more challenging to generate adversarial perturbations for different types of medical images. In this paper, we propose an image-based medical adversarial attack method to consistently produce adversarial perturbations on medical images. The objective function of our method consists of a loss deviation term and a loss stabilization term. The loss deviation term increases the divergence between the CNN prediction of an adversarial example and its ground truth label. Meanwhile, the loss stabilization term ensures similar CNN predictions of this example and its smoothed input. From the perspective of the whole iterations for perturbation generation, the proposed loss stabilization term exhaustively searches the perturbation space to smooth the single spot for local optimal escape. We further analyze the KL-divergence of the proposed loss function and find that the loss stabilization term makes the perturbations updated towards a fixed objective spot while deviating from the ground truth. This stabilization ensures the proposed medical attack effective for different types of medical images while producing perturbations in small variance. Experiments on several medical image analysis benchmarks including the recent COVID-19 dataset show the stability of the proposed method.",畳み込みニューラルネットワーク（CNN）は、自動疾患診断のための既存の医療システムを進歩させてきました。ただし、これらのシステムに対する脅威が発生し、敵対的攻撃によってCNNが脆弱になります。不正確な診断結果は、人間の医療に悪影響を及ぼします。深い医療診断システムを強化するために、潜在的な敵対的攻撃を調査する必要があります。一方、医用画像（CT、眼底、内視鏡画像など）にはいくつかのモダリティがあり、それぞれのタイプが他のタイプとは大きく異なります。さまざまなタイプの医用画像に対して敵対的な摂動を生成することは、より困難です。本論文では、医用画像上で敵対的摂動を一貫して生成するための画像ベースの医用敵対的攻撃法を提案する。この方法の目的関数は、損失偏差項と損失安定化項で構成されます。損失偏差項は、敵対的な例のCNN予測とそのグラウンドトゥルースラベルの間の相違を増加させます。一方、損失安定化項は、この例とその平滑化された入力の同様のCNN予測を保証します。摂動生成の反復全体の観点から、提案された損失安定化項は、摂動空間を徹底的に検索して、局所的な最適脱出のために単一のスポットを平滑化します。さらに、提案された損失関数のKL発散を分析し、損失安定化項によって、グラウンドトゥルースから逸脱しながら、摂動が固定された目的のスポットに向かって更新されることを発見します。この安定化により、提案された医療攻撃がさまざまなタイプの医用画像に効果的になり、小さな分散で摂動が生成されます。最近のCOVID-19データセットを含むいくつかの医療画像分析ベンチマークでの実験は、提案された方法の安定性を示しています。,7.33,
A Distributional Approach to Controlled Text Generation,"['Muhammad Khalifa', 'Hady Elsahar', 'Marc Dymetman']",https://openreview.net/forum?id=jWkw45-9AbL,"We propose a Distributional Approach to address Controlled Text Generation from pre-trained Language Models (LMs). This view permits to define, in a single formal framework, “pointwise” and “distributional” constraints over the target LM --- to our knowledge, this is the first approach with such generality --- while minimizing KL divergence with the initial LM distribution. The optimal target distribution is then uniquely determined as an explicit EBM (Energy-Based Model) representation.  From that optimal representation, we then train the target controlled autoregressive LM through an adaptive distributional variant of Policy Gradient. We conduct a first set of experiments over pointwise constraints showing the advantages of our approach over a set of baselines, in terms of obtaining a controlled LM balancing constraint satisfaction with divergence from the initial LM (GPT-2).  We then perform experiments over distributional constraints, a unique feature of our approach, demonstrating its potential as a remedy to the problem of Bias in Language Models. Through an ablation study, we show the effectiveness of our adaptive technique for obtaining faster convergence.",事前にトレーニングされた言語モデル（LM）からの制御されたテキスト生成に対処するための分散アプローチを提案します。このビューでは、単一の正式なフレームワークで、ターゲットLMに対する点ごとの分布制約を定義できます。これは、初期LM分布とのKL発散を最小限に抑えながら、このような一般性を備えた最初のアプローチです。次に、最適なターゲット分布が、明示的なEBM（エネルギーベースモデル）表現として一意に決定されます。次に、その最適な表現から、ポリシー勾配の適応分布バリアントを介してターゲット制御の自己回帰LMをトレーニングします。最初のLM（GPT-2）からの逸脱を伴う、制御されたLMバランシング制約の満足度を取得するという点で、一連のベースラインに対するアプローチの利点を示す、点ごとの制約に対して最初の一連の実験を実行します。次に、私たちのアプローチのユニークな機能である分布制約について実験を行い、言語モデルのバイアスの問題に対する救済策としての可能性を示します。アブレーション研究を通して、より速い収束を得るための適応技術の有効性を示します。,7.33,https://d3i71xaburhd42.cloudfront.net/b3aaf4770ff5ab02a468f9909f994cf7bb6c4898/3-Figure1-1.png
Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions,"['Zhengxian Lin', 'Kin-Ho Lam', 'Alan Fern']",https://openreview.net/forum?id=Ud3DSz72nYR,"We investigate a deep reinforcement learning (RL) architecture that supports explaining why a learned agent prefers one action over another. The key idea is to learn action-values that are directly represented via human-understandable properties of expected futures. This is realized via the embedded self-prediction (ESP) model, which learns said properties in terms of human provided features. Action preferences can then be explained by contrasting the future properties predicted for each action. To address cases where there are a large number of features, we develop a novel method for computing minimal sufficient explanations from an ESP. Our case studies in three domains, including a complex strategy game, show that ESP models can be effectively learned and support insightful explanations. ",学習したエージェントがあるアクションを別のアクションよりも好む理由の説明をサポートする深層強化学習（RL）アーキテクチャを調査します。重要なアイデアは、予想される先物の人間が理解できる特性を介して直接表されるアクション値を学習することです。これは、人間が提供する機能の観点から前述のプロパティを学習する埋め込み自己予測（ESP）モデルを介して実現されます。次に、アクションの好みは、各アクションについて予測される将来のプロパティを対比することによって説明できます。多数の機能がある場合に対処するために、ESPから最小限の十分な説明を計算するための新しい方法を開発します。複雑な戦略ゲームを含む3つのドメインでのケーススタディは、ESPモデルを効果的に学習し、洞察に満ちた説明をサポートできることを示しています。,7.33,https://d3i71xaburhd42.cloudfront.net/2e0b1b6ac7a48e1c992cb26967c7272c5e798757/6-Figure1-1.png
Image GANs meet Differentiable Rendering for Inverse Graphics and Interpretable 3D Neural Rendering,"['Yuxuan Zhang', 'Wenzheng Chen', 'Huan Ling', 'Jun Gao', 'Yinan Zhang', 'Antonio Torralba', 'Sanja Fidler']",https://openreview.net/forum?id=yWkP7JuHX1,"Differentiable rendering has paved the way to training neural networks to perform “inverse graphics” tasks such as predicting 3D geometry from monocular photographs. To train high performing models, most of the current approaches rely on multi-view imagery which are not readily available in practice.  Recent Generative Adversarial Networks (GANs) that synthesize images, in contrast, seem to acquire 3D knowledge implicitly during training: object viewpoints can be manipulated by simply manipulating the latent codes. However, these latent codes often lack further physical interpretation and thus GANs cannot easily be inverted to perform explicit 3D reasoning. In this paper, we aim to extract and disentangle 3D knowledge learned by generative models by utilizing differentiable renderers. Key to our approach is to exploit GANs as a multi-view data generator to train an inverse graphics network using an off-the-shelf differentiable renderer, and the trained inverse graphics network as a teacher to disentangle the GAN's latent code into interpretable 3D properties. The entire architecture is trained iteratively using cycle consistency losses. We show that our approach significantly outperforms state-of-the-art inverse graphics networks trained on existing datasets, both quantitatively and via user studies. We further showcase the disentangled GAN as a controllable 3D “neural renderer"", complementing traditional graphics renderers.",微分可能なレンダリングにより、単眼写真から3Dジオメトリを予測するなど、逆グラフィックスタスクを実行するようにニューラルネットワークをトレーニングする道が開かれました。高性能モデルをトレーニングするために、現在のアプローチのほとんどは、実際には容易に利用できないマルチビュー画像に依存しています。対照的に、画像を合成する最近の生成的敵対的ネットワーク（GAN）は、トレーニング中に暗黙的に3D知識を取得するようです。オブジェクトの視点は、潜在的なコードを操作するだけで操作できます。ただし、これらの潜在的なコードには物理的な解釈が欠けていることが多いため、GANを簡単に反転して明示的な3D推論を実行することはできません。この論文では、微分可能なレンダラーを利用して、生成モデルによって学習された3D知識を抽出して解きほぐすことを目指しています。私たちのアプローチの鍵は、GANをマルチビューデータジェネレーターとして活用して、既製の微分可能なレンダラーを使用して逆グラフィックスネットワークをトレーニングし、トレーニングされた逆グラフィックスネットワークを教師として活用して、GANの潜在的なコードを解釈可能な3Dプロパティに解きほぐすことです。 。アーキテクチャ全体は、サイクルの一貫性の損失を使用して繰り返しトレーニングされます。私たちのアプローチは、定量的にもユーザー調査によっても、既存のデータセットでトレーニングされた最先端の逆グラフィックスネットワークを大幅に上回っていることを示しています。さらに、従来のグラフィックスレンダラーを補完する、制御可能な3Dニューラルレンダラーとして解きほぐされたGANを紹介します。,7.33,https://d3i71xaburhd42.cloudfront.net/288e170e5771200653b2f65d4837b74295b2c258/2-Figure1-1.png
RMSprop can converge with proper hyper-parameter,"['Naichen Shi', 'Dawei Li', 'Mingyi Hong', 'Ruoyu Sun']",https://openreview.net/forum?id=3UDSdyIcBDA,"Despite the existence of divergence examples, RMSprop remains one of the most popular algorithms in machine learning. Towards closing the gap between theory and practice, we prove that RMSprop can converge with proper choice of hyper-parameters under certain conditions. More specifically, we prove that  when the hyper-parameter $\beta_2$ is large enough, the random shuffling version of RMSprop converges to a bounded region in general, and converges to a stationary point in the interpolation regime. It is worth mentioning that our results do not depend on ""bounded gradient""  assumption, which is often the key assumption utilized by existing theoretical work for RMSprop. Removing this assumption allows us to establish a phase transition from divergence to non-divergence for RMSProp. 
Finally, based on our theory, we conjecture that there is a critical threshold in practice, such that RMSprop generates reasonably good results only if $\beta_2\ge {\sf {th}}$. We provide empirical evidence about such a phase transition in our numerical experiments.",発散の例が存在するにもかかわらず、RMSpropは機械学習で最も人気のあるアルゴリズムの1つです。理論と実践の間のギャップを埋めるために、RMSpropが特定の条件下でハイパーパラメータの適切な選択に収束できることを証明します。より具体的には、ハイパーパラメータ2が十分に大きい場合、RMSpropのランダムシャッフルバージョンは一般に有界領域に収束し、補間領域の停留点に収束することを証明します。私たちの結果は「有界勾配」の仮定に依存しないことに言及する価値があります。これは、RMSpropの既存の理論的研究で利用される重要な仮定であることがよくあります。この仮定を取り除くことで、RMSPropの発散から非発散への相転移を確立することができます。最後に、私たちの理論に基づいて、RMSpropが$ \ beta2 \ ge {\ sf {th}} $の場合にのみ適度に良い結果を生成するように、実際には重要なしきい値があると推測します。数値実験では、このような相転移に関する経験的証拠を提供します。,7.33,
Meta-GMVAE: Mixture of Gaussian VAE for Unsupervised Meta-Learning,"['Dong Bok Lee', 'Dongchan Min', 'Seanie Lee', 'Sung Ju Hwang']",https://openreview.net/forum?id=wS0UFjsNYjn,"Unsupervised learning aims to learn meaningful representations from unlabeled data which can captures its intrinsic structure, that can be transferred to downstream tasks. Meta-learning, whose objective is to learn to generalize across tasks such that the learned model can rapidly adapt to a novel task, shares the spirit of unsupervised learning in that the both seek to learn more effective and efficient learning procedure than learning from scratch. The fundamental difference of the two is that the most meta-learning approaches are supervised, assuming full access to the labels. However, acquiring labeled dataset for meta-training not only is costly as it requires human efforts in labeling but also limits its applications to pre-defined task distributions. In this paper, we propose a principled unsupervised meta-learning model, namely Meta-GMVAE, based on Variational Autoencoder (VAE) and set-level variational inference. Moreover, we introduce a mixture of Gaussian (GMM) prior, assuming that each modality represents each class-concept in a randomly sampled episode, which we optimize with Expectation-Maximization (EM). Then, the learned model can be used for downstream few-shot classification tasks, where we obtain task-specific parameters by performing semi-supervised EM on the latent representations of the support and query set, and predict labels of the query set by computing aggregated posteriors. We validate our model on Omniglot and Mini-ImageNet datasets by evaluating its performance on downstream few-shot classification tasks. The results show that our model obtain impressive performance gains over existing unsupervised meta-learning baselines, even outperforming supervised MAML on a certain setting.",教師なし学習は、ラベルのないデータから意味のある表現を学習することを目的としています。このデータは、その固有の構造をキャプチャでき、ダウンストリームタスクに転送できます。メタ学習は、学習したモデルが新しいタスクに迅速に適応できるようにタスク間で一般化することを学ぶことを目的としており、教師なし学習の精神を共有しており、どちらもゼロから学習するよりも効果的で効率的な学習手順を学習しようとします。 2つの基本的な違いは、ラベルへのフルアクセスを前提として、ほとんどのメタ学習アプローチが監視されていることです。ただし、メタトレーニング用にラベル付けされたデータセットを取得するには、ラベル付けに人的労力が必要になるだけでなく、アプリケーションが事前定義されたタスク分散に制限されるため、コストがかかります。この論文では、変分オートエンコーダ（VAE）とセットレベルの変分推論に基づいて、原理的な教師なしメタ学習モデル、つまりMeta-GMVAEを提案します。さらに、各モダリティがランダムにサンプリングされたエピソードの各クラス概念を表すと仮定して、事前にガウス（GMM）の混合を導入します。これは、期待値最大化（EM）で最適化します。次に、学習したモデルをダウンストリームの数ショット分類タスクに使用できます。ここでは、サポートとクエリセットの潜在的な表現に対して半教師ありEMを実行してタスク固有のパラメータを取得し、集計を計算してクエリセットのラベルを予測します。事後。 OmniglotおよびMini-ImageNetデータセットでモデルを検証するために、ダウンストリームの数ショット分類タスクでのパフォーマンスを評価します。結果は、私たちのモデルが、特定の設定で教師ありMAMLを上回っていても、既存の教師なしメタ学習ベースラインよりも優れたパフォーマンスの向上を実現していることを示しています。,7.25,
Learning from Protein Structure with Geometric Vector Perceptrons,"['Bowen Jing', 'Stephan Eismann', 'Patricia Suriana', 'Raphael John Lamarre Townshend', 'Ron Dror']",https://openreview.net/forum?id=1YLJDvSx6J4,"Learning on 3D structures of large biomolecules is emerging as a distinct area in machine learning, but there has yet to emerge a unifying network architecture that simultaneously leverages the geometric and relational aspects of the problem domain. To address this gap, we introduce geometric vector perceptrons, which extend standard dense layers to operate on collections of Euclidean vectors. Graph neural networks equipped with such layers are able to perform both geometric and relational reasoning on efficient representations of macromolecules. We demonstrate our approach on two important problems in learning from protein structure: model quality assessment and computational protein design. Our approach improves over existing classes of architectures on both problems, including state-of-the-art convolutional neural networks and graph neural networks.",大きな生体分子の3D構造に関する学習は、機械学習の明確な領域として浮上していますが、問題領域の幾何学的側面と関係的側面を同時に活用する統合ネットワークアーキテクチャはまだ出現していません。このギャップに対処するために、幾何学的ベクトルパーセプトロンを導入します。これは、標準の高密度レイヤーを拡張して、ユークリッドベクトルのコレクションを操作します。このような層を備えたグラフニューラルネットワークは、高分子の効率的な表現に対して幾何学的推論とリレーショナル推論の両方を実行できます。タンパク質構造から学習する際の2つの重要な問題であるモデル品質評価と計算タンパク質設計に対するアプローチを示します。私たちのアプローチは、最先端の畳み込みニューラルネットワークやグラフニューラルネットワークなど、両方の問題について既存のクラスのアーキテクチャを改善します。,7.25,https://d3i71xaburhd42.cloudfront.net/0b9db2c144ab2a94752760534ccc078a7919be2a/4-Table1-1.png
Long-tail learning via logit adjustment,"['Aditya Krishna Menon', 'Sadeep Jayasumana', 'Ankit Singh Rawat', 'Himanshu Jain', 'Andreas Veit', 'Sanjiv Kumar']",https://openreview.net/forum?id=37nvvqkCo5,"Real-world classification problems typically exhibit an imbalanced or long-tailed label distribution, wherein many labels have only a few associated samples. This poses a challenge for generalisation on such labels, and also  makes naive learning biased towards dominant labels. In this paper,  we present a statistical framework that unifies and generalises several recent proposals to cope with these challenges. Our framework revisits the classic idea of logit adjustment based on the label frequencies, which encourages a large relative margin between logits of rare positive versus dominant negative labels. This yields two techniques  for long-tail learning, where such adjustment is either applied post-hoc to a trained model, or enforced in the loss during training. These techniques are statistically grounded, and practically effective on four real-world datasets with long-tailed label distributions. ",実世界の分類問題は、通常、不均衡またはロングテールのラベル分布を示し、多くのラベルには少数の関連サンプルしかありません。これは、そのようなラベルの一般化に課題をもたらし、また、ナイーブな学習を支配的なラベルに偏らせます。この論文では、これらの課題に対処するためのいくつかの最近の提案を統合および一般化する統計的フレームワークを提示します。私たちのフレームワークは、ラベルの頻度に基づいたロジット調整の古典的な考え方を再検討します。これにより、まれなポジティブラベルとドミナントネガティブラベルのロジット間の相対的なマージンが大きくなります。これにより、ロングテール学習の2つの手法が得られます。このような調整は、トレーニングされたモデルに事後的に適用されるか、トレーニング中の損失に適用されます。これらの手法は統計的に根拠があり、ロングテールのラベル分布を持つ4つの実世界のデータセットで実際に効果的です。,7.25,https://d3i71xaburhd42.cloudfront.net/5f2959f27a1a11a2e4b692834127c0e24ca8475f/4-Figure1-1.png
Improving Adversarial Robustness via Channel-wise Activation Suppressing,"['Yang Bai', 'Yuyuan Zeng', 'Yong Jiang', 'Shu-Tao Xia', 'Xingjun Ma', 'Yisen Wang']",https://openreview.net/forum?id=zQTezqCCtNx,"The study of adversarial examples and their activations have attracted significant attention for secure and robust learning with deep neural networks (DNNs).  Different from existing works, in this paper, we highlight two new characteristics of adversarial examples from the channel-wise activation perspective:  1) the activation magnitudes of adversarial examples are higher than that of natural examples; and 2) the channels are activated more uniformly by adversarial examples than natural examples. We find that, while the state-of-the-art defense adversarial training has addressed the first issue of high activation magnitude via training on adversarial examples, the second issue of uniform activation remains.  This motivates us to suppress redundant activations from being activated by adversarial perturbations during the adversarial training process, via a Channel-wise Activation Suppressing (CAS) training strategy.  We show that CAS can train a model that inherently suppresses adversarial activations, and can be easily applied to existing defense methods to further improve their robustness. Our work provides a simplebut generic training strategy for robustifying the intermediate layer activations of DNNs.",敵対的な例とその活性化の研究は、ディープニューラルネットワーク（DNN）を使用した安全で堅牢な学習に大きな注目を集めています。既存の研究とは異なり、この論文では、チャネルごとの活性化の観点から、敵対的な例の2つの新しい特徴を強調します。1）敵対的な例の活性化の大きさは自然な例よりも高い。 2）チャネルは、自然な例よりも敵対的な例によってより均一にアクティブ化されます。最先端の防衛敵対訓練は、敵対例の訓練を通じて高い活性化の大きさの最初の問題に対処しましたが、均一な活性化の2番目の問題は残っていることがわかります。これにより、チャネルごとのアクティベーション抑制（CAS）トレーニング戦略を介して、敵対的なトレーニングプロセス中に敵対的な摂動によって冗長なアクティベーションがアクティブ化されるのを抑制するようになります。 CASは、敵対的なアクティベーションを本質的に抑制するモデルをトレーニングでき、既存の防御方法に簡単に適用して、堅牢性をさらに向上させることができることを示します。私たちの仕事は、DNNの中間層のアクティブ化を強化するためのシンプルだが一般的なトレーニング戦略を提供します。,7.25,
Orthogonalizing Convolutional Layers with the Cayley Transform,"['Asher Trockman', 'J Zico Kolter']",https://openreview.net/forum?id=Pbj8H_jEHYv,"Recent work has highlighted several advantages of enforcing orthogonality in the weight layers of deep networks, such as maintaining the stability of activations, preserving gradient norms, and enhancing adversarial robustness by enforcing low Lipschitz constants. Although numerous methods exist for enforcing the orthogonality of fully-connected layers, those for convolutional layers are more heuristic in nature, often focusing on penalty methods or limited classes of convolutions. In this work, we propose and evaluate an alternative approach to directly parameterize convolutional layers that are constrained to be orthogonal. Specifically, we propose to apply the Cayley transform to a skew-symmetric convolution in the Fourier domain, so that the inverse convolution needed by the Cayley transform can be computed efficiently. We compare our method to previous Lipschitz-constrained and orthogonal convolutional layers and show that it indeed preserves orthogonality to a high degree even for large convolutions. Applied to the problem of certified adversarial robustness, we show that networks incorporating the layer outperform existing deterministic methods for certified defense against $\ell_2$-norm-bounded adversaries, while scaling to larger architectures than previously investigated.",最近の研究では、活性化の安定性の維持、勾配ノルムの維持、低いリプシッツ定数の適用による敵対的ロバスト性の強化など、深いネットワークの重み層に直交性を適用することのいくつかの利点が強調されています。完全に接続された層の直交性を強制するための方法は多数存在しますが、畳み込み層の方法は本質的によりヒューリスティックであり、多くの場合、ペナルティ法または限られたクラスの畳み込みに焦点を当てています。この作業では、直交するように制約されている畳み込み層を直接パラメーター化するための代替アプローチを提案および評価します。具体的には、ケイリー変換に必要な逆畳み込みを効率的に計算できるように、フーリエ領域のスキュー対称畳み込みにケイリー変換を適用することを提案します。私たちの方法を以前のリプシッツ制約付き直交畳み込み層と比較し、大きな畳み込みに対しても実際に高度に直交性を維持することを示します。認定された敵対者の堅牢性の問題に適用すると、レイヤーを組み込んだネットワークは、以前に調査したよりも大きなアーキテクチャに拡張しながら、l2ノルムに制限された敵対者に対する認定された防御のための既存の決定論的方法よりも優れていることを示します。,7.25,
Dynamics of Deep Equilibrium Linear Models,['Kenji Kawaguchi'],https://openreview.net/forum?id=p-NZIuwqhI4,"A deep equilibrium linear model is implicitly defined through an equilibrium point of an infinite sequence of computation. It avoids any explicit computation of the infinite sequence by finding an equilibrium point directly via root-finding and by computing gradients via implicit differentiation. In this paper, we analyze the gradient dynamics of deep equilibrium linear models with non-convex objective functions for a general class of losses used in regression and classification. Convergence to global optimum at a linear rate is guaranteed without any assumption on the width of the models, allowing the width to be smaller than the output dimension and the number of data points. Moreover, we prove a relation between the gradient dynamics of deep equilibrium linear models and the dynamics of trust region Newton method of shallow models with time-dependent quadratic norms. This mathematically proven relation along with our numerical observation suggests the importance of understanding implicit bias and a possible open problem on the topic. Our proofs differ significantly from those in the related literature.    
 
",深い平衡線形モデルは、計算の無限シーケンスの平衡点を介して暗黙的に定義されます。求根アルゴリズムを介して直接平衡点を見つけ、暗黙の微分を介して勾配を計算することにより、無限シーケンスの明示的な計算を回避します。この論文では、回帰と分類で使用される損失の一般的なクラスについて、非凸目的関数を使用した深平衡線形モデルの勾配ダイナミクスを分析します。線形レートでのグローバル最適化への収束は、モデルの幅を想定せずに保証されるため、幅を出力次元およびデータポイントの数よりも小さくすることができます。さらに、深い平衡線形モデルの勾配ダイナミクスと、時間依存の二次ノルムを持つ浅いモデルの信頼領域ニュートン法のダイナミクスとの関係を証明します。この数学的に証明された関係と私たちの数値的観察は、暗黙のバイアスとトピックに関する潜在的な未解決の問題を理解することの重要性を示唆しています。私たちの証明は、関連文献のものとは大きく異なります。,7.25,
Minimum Width for Universal Approximation,"['Sejun Park', 'Chulhee Yun', 'Jaeho Lee', 'Jinwoo Shin']",https://openreview.net/forum?id=O-XJwyoIF-k,"The universal approximation property of width-bounded networks has been studied as a dual of classical universal approximation results on depth-bounded networks. However, the critical width enabling the universal approximation has not been exactly characterized in terms of the input dimension $d_x$ and the output dimension $d_y$. In this work, we provide the first definitive result in this direction for networks using the ReLU activation functions: The minimum width required for the universal approximation of the $L^p$ functions is exactly $\max\{d_x+1,d_y\}$. We also prove that the same conclusion does not hold for the uniform approximation with ReLU, but does hold with an additional threshold activation function. Our proof technique can be also used to derive a tighter upper bound on the minimum width required for the universal approximation using networks with general activation functions.",幅が制限されたネットワークの普遍近似特性は、深さが制限されたネットワークでの古典的な普遍近似結果の二重として研究されてきました。ただし、普遍近似を可能にする臨界幅は、入力次元d（x）と出力次元d（y）に関して正確に特徴付けられていません。この作業では、ReLU活性化関数を使用して、ネットワークに対してこの方向で最初の決定的な結果を提供します。L^（p）関数の普遍近似に必要な最小幅は、正確に最大{d（x）+ 1、d（ y）}。また、同じ結論がReLUによる均一近似には当てはまらないが、追加のしきい値活性化関数にも当てはまることを証明します。私たちの証明手法は、一般的な活性化関数を備えたネットワークを使用して、普遍近似に必要な最小幅のより厳しい上限を導出するためにも使用できます。,7.25,https://d3i71xaburhd42.cloudfront.net/f63405f53db3b1016f565f555fc8fa409f02fdbd/6-Figure1-1.png
Multiplicative Filter Networks,"['Rizal Fathony', 'Anit Kumar Sahu', 'Devin Willmott', 'J Zico Kolter']",https://openreview.net/forum?id=OmtmcPkkhT,"Although deep networks are typically used to approximate functions over high dimensional inputs, recent work has increased interest in neural networks as function approximators for low-dimensional-but-complex functions, such as representing images as a function of pixel coordinates, solving differential equations, or representing signed distance fields or neural radiance fields.  Key to these recent successes has been the use of new elements such as sinusoidal nonlinearities, or Fourier features in positional encodings, which vastly outperform simple ReLU networks.  In this paper, we propose and empirically demonstrate that an arguably simpler class of function approximators can work just as well for such problems: multiplicative filter networks.  In these networks, we avoid traditional compositional depth altogether, and simply multiply together (linear functions of) sinusoidal or Gabor wavelet functions applied to the input.  This representation has the notable advantage that the entire function can simply be viewed as a linear function approximator over an exponential number of Fourier or Gabor basis functions, respectively.  Despite this simplicity, when compared to recent approaches that use Fourier features with ReLU networks or sinusoidal activation networks, we show that these multiplicative filter networks largely outperform or match the performance of these recent approaches on the domains highlighted in these past works.",ディープネットワークは通常、高次元入力の関数を近似するために使用されますが、最近の研究では、ピクセル座標の関数としての画像の表現、微分方程式の解法など、低次元であるが複雑な関数の関数近似器としてニューラルネットワークへの関心が高まっています。または符号付き距離フィールドまたはニューラル放射フィールドを表します。これらの最近の成功の鍵は、正弦波非線形性や、単純なReLUネットワークを大幅に上回る位置エンコーディングでのフーリエ機能などの新しい要素の使用です。この論文では、おそらくより単純なクラスの関数近似器がそのような問題、つまり乗法フィルターネットワークに対しても同様に機能することを提案し、経験的に実証します。これらのネットワークでは、従来の合成深度を完全に回避し、入力に適用される正弦波関数またはガボールウェーブレット関数（の線形関数）を単純に乗算します。この表現には、関数全体を、それぞれ指数関数的な数のフーリエまたはガボール基底関数に対する線形関数近似器として簡単に表示できるという顕著な利点があります。この単純さにもかかわらず、ReLUネットワークまたは正弦波活性化ネットワークでフーリエ機能を使用する最近のアプローチと比較すると、これらの乗法フィルターネットワークは、これらの過去の研究で強調されたドメインでのこれらの最近のアプローチのパフォーマンスを大幅に上回るか、一致することを示します。,7.25,
Unlearnable Examples: Making Personal Data Unexploitable,"['Hanxun Huang', 'Xingjun Ma', 'Sarah Monazam Erfani', 'James Bailey', 'Yisen Wang']",https://openreview.net/forum?id=iAmZUo0DxC0,"The volume of ""free"" data on the internet has been key to the current success of deep learning. However, it also raises privacy concerns about the unauthorized exploitation of personal data for training commercial models. It is thus crucial to develop methods to prevent unauthorized data exploitation. This paper raises the question: can data be made unlearnable for deep learning models? We present a type of error-minimizing noise that can indeed make training examples unlearnable. Error-minimizing noise is intentionally generated to reduce the error of one or more of the training example(s) close to zero, which can trick the model into believing there is ""nothing"" to learn from these example(s). The noise is restricted to be imperceptible to human eyes, and thus does not affect normal data utility. We empirically verify the effectiveness of error-minimizing noise in both sample-wise and class-wise forms. We also demonstrate its flexibility under extensive experimental settings and practicability in a case study of face recognition. Our work establishes an important ﬁrst step towards making personal data unexploitable to deep learning models.",インターネット上の「無料」データの量は、ディープラーニングの現在の成功の鍵となっています。ただし、商用モデルをトレーニングするための個人データの不正な悪用に関するプライバシーの懸念も生じます。したがって、不正なデータの悪用を防ぐ方法を開発することが重要です。このホワイトペーパーでは、深層学習モデルでデータを学習不能にすることができるかという疑問が生じます。トレーニングの例を実際に学習不能にする可能性のある、エラーを最小化するノイズのタイプを示します。エラー最小化ノイズは、ゼロに近い1つ以上のトレーニング例のエラーを減らすために意図的に生成されます。これにより、モデルをだまして、これらの例から学ぶことは「何もない」と信じ込ませることができます。ノイズは人間の目には知覚できないように制限されているため、通常のデータユーティリティには影響しません。サンプルごととクラスごとの両方の形式で、エラーを最小化するノイズの有効性を経験的に検証します。また、顔認識のケーススタディで、広範な実験設定と実用性の下での柔軟性を示します。私たちの仕事は、個人データをディープラーニングモデルで利用できないようにするための重要な第一歩を確立します。,7.25,https://d3i71xaburhd42.cloudfront.net/9a1090c590474190df976bf5a91c3e5cc1a30864/5-Figure1-1.png
On the Origin of Implicit Regularization in Stochastic Gradient Descent,"['Samuel L Smith', 'Benoit Dherin', 'David Barrett', 'Soham De']",https://openreview.net/forum?id=rq_Qr0c1Hyo,"For infinitesimal learning rates, stochastic gradient descent (SGD) follows the path of gradient flow on the full batch loss function. However moderately large learning rates can achieve higher test accuracies, and this generalization benefit is not explained by convergence bounds, since the learning rate which maximizes test accuracy is often larger than the learning rate which minimizes training loss. To interpret this phenomenon we prove that for SGD with random shuffling, the mean SGD iterate also stays close to the path of gradient flow if the learning rate is small and finite, but on a modified loss. This modified loss is composed of the original loss function and an implicit regularizer, which penalizes the norms of the minibatch gradients. Under mild assumptions, when the batch size is small the scale of the implicit regularization term is proportional to the ratio of the learning rate to the batch size. We verify empirically that explicitly including the implicit regularizer in the loss can enhance the test accuracy when the learning rate is small.",微小な学習率の場合、確率的勾配降下法（SGD）は、完全なバッチ損失関数の勾配フローのパスに従います。ただし、適度に大きい学習率はより高いテスト精度を達成でき、テスト精度を最大化する学習率はトレーニング損失を最小化する学習率よりも大きいことが多いため、この一般化の利点は収束限界によって説明されません。この現象を解釈するために、ランダムシャッフルを使用したSGDの場合、学習率が小さく有限であるが、損失が修正されている場合、平均SGD反復も勾配流の経路に近いままであることを証明します。この変更された損失は、元の損失関数と、ミニバッチ勾配の基準にペナルティを課す暗黙の正則化で構成されます。穏やかな仮定の下で、バッチサイズが小さい場合、暗黙の正則化項のスケールは、バッチサイズに対する学習率の比率に比例します。損失に暗黙の正則化を明示的に含めると、学習率が小さい場合にテストの精度が向上することを経験的に検証します。,7.25,https://d3i71xaburhd42.cloudfront.net/4fa32fec61c50f8339a05e097dacebe71cf9ab8e/6-Figure1-1.png
PlasticineLab: A Soft-Body Manipulation Benchmark with Differentiable Physics,"['Zhiao Huang', 'Yuanming Hu', 'Tao Du', 'Siyuan Zhou', 'Hao Su', 'Joshua B. Tenenbaum', 'Chuang Gan']",https://openreview.net/forum?id=xCcdBRQEDW,"Simulated virtual environments serve as one of the main driving forces behind developing and evaluating skill learning algorithms. However, existing environments typically only simulate rigid body physics. Additionally, the simulation process usually does not provide gradients that might be useful for planning and control optimizations. We introduce a new differentiable physics benchmark called PasticineLab, which includes a diverse collection of soft body manipulation tasks. In each task, the agent uses manipulators to deform the plasticine into a desired configuration. The underlying physics engine supports differentiable elastic and plastic deformation using the DiffTaichi system, posing many under-explored challenges to robotic agents. We evaluate several existing reinforcement learning (RL) methods and gradient-based methods on this benchmark. Experimental results suggest that 1) RL-based approaches struggle to solve most of the tasks efficiently;  2) gradient-based approaches, by optimizing open-loop control sequences with the built-in differentiable physics engine, can rapidly find a solution within tens of iterations, but still fall short on multi-stage tasks that require long-term planning. We expect that PlasticineLab will encourage the development of novel algorithms that combine differentiable physics and RL for more complex physics-based skill learning tasks. PlasticineLab will be made publicly available.",シミュレートされた仮想環境は、スキル学習アルゴリズムの開発と評価の背後にある主要な推進力の1つとして機能します。ただし、既存の環境は通常、剛体物理のみをシミュレートします。さらに、シミュレーションプロセスは通常、最適化の計画と制御に役立つ可能性のある勾配を提供しません。 PasticineLabと呼ばれる新しい微分可能な物理ベンチマークを紹介します。これには、ソフトボディ操作タスクの多様なコレクションが含まれています。各タスクで、エージェントはマニピュレータを使用して粘土を目的の構成に変形します。基礎となる物理エンジンは、DiffTaichiシステムを使用して微分可能な弾性変形と塑性変形をサポートし、ロボットエージェントに多くの未踏の課題をもたらします。このベンチマークで、いくつかの既存の強化学習（RL）メソッドと勾配ベースのメソッドを評価します。実験結果は、1）RLベースのアプローチがほとんどのタスクを効率的に解決するのに苦労していることを示唆しています。 2）組み込みの微分可能物理エンジンを使用して開ループ制御シーケンスを最適化することにより、勾配ベースのアプローチは、数十回の反復で解決策を迅速に見つけることができますが、長期計画を必要とする多段階タスクでは不十分です。 PlasticineLabは、より複雑な物理ベースのスキル学習タスクのために、微分可能な物理とRLを組み合わせた新しいアルゴリズムの開発を促進することを期待しています。 PlasticineLabは一般公開されます。,7.25,
Model Patching: Closing the Subgroup Performance Gap with Data Augmentation,"['Karan Goel', 'Albert Gu', 'Yixuan Li', 'Christopher Re']",https://openreview.net/forum?id=9YlaeLfuhJF,"Classifiers in machine learning are often brittle when deployed. Particularly concerning are models with inconsistent performance on specific subgroups of a class, e.g., exhibiting disparities in skin cancer classification in the presence or absence of a spurious bandage. To mitigate these performance differences, we introduce model patching, a two-stage framework for improving robustness that encourages the model to be invariant to subgroup differences, and focus on class information shared by subgroups. Model patching first models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate subgroup features. We instantiate model patching with CAMEL, which (1) uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and (2) balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. We demonstrate CAMEL’s effectiveness on 3 benchmark datasets, with reductions in robust error of up to 33% relative to the best baseline. Lastly, CAMEL successfully patches a model that fails due to spurious features on a real-world skin cancer dataset.",機械学習の分類子は、デプロイすると脆弱になることがよくあります。特に懸念されるのは、クラスの特定のサブグループで一貫性のないパフォーマンスを持つモデルです。たとえば、偽の包帯の存在下または非存在下で皮膚がんの分類に差異が見られます。これらのパフォーマンスの違いを軽減するために、モデルのパッチ適用を導入します。これは、モデルがサブグループの違いに対して不変であることを促進する堅牢性を向上させるための2段階のフレームワークであり、サブグループによって共有されるクラス情報に焦点を当てます。モデルパッチは、最初にクラス内のサブグループ機能をモデル化し、それらの間のセマンティック変換を学習し、次にサブグループ機能を意図的に操作するデータ拡張を使用して分類器をトレーニングします。 CAMELを使用してモデルのパッチをインスタンス化します。これは、（1）CycleGANを使用してクラス内、サブグループ間の拡張を学習し、（2）理論的に動機付けられたサブグループ整合性正則化を使用してサブグループのパフォーマンスのバランスを取り、新しい堅牢な目標を伴います。 3つのベンチマークデータセットでCAMELの有効性を示し、最大33のロバストエラーを削減します,7.25,https://d3i71xaburhd42.cloudfront.net/9207480a5cd071a3e85f408082b09283413cbfa5/2-Figure1-1.png
Locally Free Weight sharing for Network Width Search,"['Xiu Su', 'Shan You', 'Tao Huang', 'Fei Wang', 'Chen Qian', 'Changshui Zhang', 'Chang Xu']",https://openreview.net/forum?id=S0UdquAnr9k,"Searching for network width is an effective way to slim deep neural networks with hardware budgets. With this aim, a one-shot supernet is usually leveraged as a performance evaluator to rank the performance \wrt~different width. Nevertheless, current methods mainly follow a manually fixed weight sharing pattern, which is limited to distinguish the performance gap of different width. In this paper, to better evaluate each width, we propose a locally free weight sharing strategy (CafeNet) accordingly. In CafeNet, weights are more freely shared, and each width is jointly indicated by its base channels and free channels, where free channels are supposed to locate freely in a local zone to better represent each width. Besides, we propose to further reduce the search space by leveraging our introduced FLOPs-sensitive bins. As a result, our CafeNet can be trained stochastically and get optimized within a min-min strategy. Extensive experiments on ImageNet, CIFAR-10, CelebA and MS COCO dataset have verified our superiority comparing to other state-of-the-art baselines. For example, our method can further boost the benchmark NAS network EfficientNet-B0 by 0.41\% via searching its width more delicately.",ネットワーク幅の検索は、ハードウェアの予算でディープニューラルネットワークをスリム化する効果的な方法です。この目的で、ワンショットスーパーネットは通常、パフォーマンス評価者として活用され、パフォーマンスのさまざまな幅をランク付けします。それにもかかわらず、現在の方法は主に手動で固定された重量共有パターンに従います。これは、異なる幅のパフォーマンスギャップを区別するために制限されています。この論文では、各幅をより適切に評価するために、それに応じてローカルフリーウェイトシェアリング戦略（CafeNet）を提案します。 CafeNetでは、重みはより自由に共有され、各幅はベースチャネルとフリーチャネルによって共同で示されます。フリーチャネルは、各幅をより適切に表すためにローカルゾーンに自由に配置されることになっています。さらに、導入されたFLOPsセンシティブビンを活用して、検索スペースをさらに削減することを提案します。その結果、CafeNetは確率的にトレーニングされ、最小-最小戦略内で最適化されます。 ImageNet、CIFAR-10、CelebA、およびMS COCOデータセットでの広範な実験により、他の最先端のベースラインと比較した当社の優位性が検証されました。たとえば、私たちの方法では、ベンチマークNASネットワークEfficientNet-B0の幅をより詳細に検索することで、その幅を0.41％さらに高めることができます。,7.25,
DDPNOpt: Differential Dynamic Programming Neural Optimizer,"['Guan-Horng Liu', 'Tianrong Chen', 'Evangelos Theodorou']",https://openreview.net/forum?id=6s7ME_X5_Un,"Interpretation of Deep Neural Networks (DNNs) training as an optimal control problem with nonlinear dynamical systems has received considerable attention recently, yet the algorithmic development remains relatively limited. In this work, we make an attempt along this line by reformulating the training procedure from the trajectory optimization perspective. We first show that most widely-used algorithms for training DNNs can be linked to the Differential Dynamic Programming (DDP), a celebrated second-order method rooted in the Approximate Dynamic Programming. In this vein, we propose a new class of optimizer, DDP Neural Optimizer (DDPNOpt), for training feedforward and convolution networks. DDPNOpt features layer-wise feedback policies which improve convergence and reduce sensitivity to hyper-parameter over existing methods. It outperforms other optimal-control inspired training methods in both convergence and complexity, and is competitive against state-of-the-art first and second order methods. We also observe DDPNOpt has surprising benefit in preventing gradient vanishing. Our work opens up new avenues for principled algorithmic design built upon the optimal control theory.",非線形動的システムの最適制御問題としてのディープニューラルネットワーク（DNN）トレーニングの解釈は、最近かなりの注目を集めていますが、アルゴリズムの開発は比較的限られたままです。この作業では、軌道最適化の観点からトレーニング手順を再定式化することにより、この方針に沿って試みます。最初に、DNNをトレーニングするために最も広く使用されているアルゴリズムが、近似動的計画法に根ざした有名な2次計画法である微分動的計画法（DDP）にリンクできることを示します。この流れの中で、フィードフォワードネットワークと畳み込みネットワークをトレーニングするための新しいクラスのオプティマイザーであるDDPニューラルオプティマイザー（DDPNOpt）を提案します。 DDPNOptは、既存の方法よりも収束を改善し、ハイパーパラメータに対する感度を低下させるレイヤーごとのフィードバックポリシーを備えています。収束と複雑さの両方で、他の最適制御に触発されたトレーニング方法よりも優れており、最先端の1次および2次の方法と競合します。また、DDPNOptには、勾配消失を防ぐという驚くべき利点があることもわかりました。私たちの仕事は、最適制御理論に基づいて構築された原理的なアルゴリズム設計の新しい道を切り開きます。,7.25,https://d3i71xaburhd42.cloudfront.net/604e9fba62bf2614cd34cc1ec0e0ccbd07ca3499/1-Figure1-1.png
Generalization in data-driven models of primary visual cortex,"['Konstantin-Klemens Lurz', 'Mohammad Bashiri', 'Konstantin Willeke', 'Akshay Jagadish', 'Eric Wang', 'Edgar Y. Walker', 'Santiago A Cadena', 'Taliah Muhammad', 'Erick Cobos', 'Andreas S. Tolias', 'Alexander S Ecker', 'Fabian H. Sinz']",https://openreview.net/forum?id=Tp7kI90Htd,"Deep neural networks (DNN) have set new standards at predicting responses of neural populations to visual input.  Most such DNNs consist of a convolutional network (core) shared across all neurons which learns a representation of neural computation in visual cortex and a neuron-specific readout that linearly combines the relevant features in this representation. The goal of this paper is to test whether such a representation is indeed generally characteristic for visual cortex, i.e. generalizes between animals of a species, and what factors contribute to obtaining such a generalizing core. To push all non-linear computations into the core where the generalizing cortical features should be learned, we devise a novel readout that reduces the number of parameters per neuron in the readout by up to two orders of magnitude compared to the previous state-of-the-art. It does so by taking advantage of retinotopy and learns a Gaussian distribution over the neuron’s receptive field position.  With this new readout we train our network on neural responses from mouse primary visual cortex (V1) and obtain a gain in performance of 7% compared to the previous state-of-the-art network.  We then investigate whether the convolutional core indeed captures general cortical features by using the core in transfer learning to a different animal.  When transferring a core trained on thousands of neurons from various animals and scans we exceed the performance of training directly on that animal by 12%, and outperform a commonly used VGG16 core pre-trained on imagenet by 33%. In addition, transfer learning with our data-driven core is more data-efficient than direct training, achieving the same performance with only 40% of the data. Our model with its novel readout thus sets a new state-of-the-art for neural response prediction in mouse visual cortex from natural images, generalizes between animals, and captures better characteristic cortical features than current task-driven pre-training approaches such as VGG16.",ディープニューラルネットワーク（DNN）は、視覚入力に対する神経集団の応答を予測する際の新しい基準を設定しました。このようなDNNのほとんどは、視覚野の神経計算の表現を学習するすべてのニューロンで共有される畳み込みネットワーク（コア）と、この表現の関連する機能を線形に組み合わせるニューロン固有の読み出しで構成されます。この論文の目的は、そのような表現が実際に視覚野に一般的に特徴的であるかどうか、つまり種の動物間で一般化するかどうか、およびそのような一般化コアの取得に寄与する要因をテストすることです。一般化された皮質の特徴を学習する必要があるコアにすべての非線形計算をプッシュするために、以前の状態と比較して、読み出しのニューロンあたりのパラメーターの数を最大2桁減らす新しい読み出しを考案します。アート。これは、レチノトピーを利用してこれを行い、ニューロンの受容野の位置にわたるガウス分布を学習します。この新しい読み出しにより、マウスの一次視覚野（V1）からの神経応答についてネットワークをトレーニングし、7のパフォーマンスを向上させます。,7.25,
Fidelity-based Deep Adiabatic Scheduling,"['Eli Ovits', 'Lior Wolf']",https://openreview.net/forum?id=NECTfffOvn1,"Adiabatic quantum computation is a form of computation that acts by slowly interpolating a quantum system between an easy to prepare initial state and a final state that represents a solution to a given computational problem. The choice of the interpolation schedule is critical to the performance: if at a certain time point, the evolution is too rapid, the system has a high probability to transfer to a higher energy state, which does not represent a solution to the problem. On the other hand, an evolution that is too slow leads to a loss of computation time and increases the probability of failure due to decoherence. In this work, we train deep neural models to produce optimal schedules that are conditioned on the problem at hand.  We consider two types of problem representation: the Hamiltonian form, and the Quadratic Unconstrained Binary Optimization (QUBO) form. A novel loss function that scores schedules according to their approximated success probability is introduced. We benchmark our approach on random QUBO problems, Grover search, 3-SAT, and MAX-CUT problems and show that our approach outperforms, by a sizable margin, the linear schedules as well as alternative approaches that were very recently proposed.",断熱量子計算は、準備が容易な初期状態と、特定の計算問題の解決策を表す最終状態との間で量子システムをゆっくりと補間することによって機能する計算の形式です。補間スケジュールの選択は、パフォーマンスにとって重要です。特定の時点で進化が速すぎる場合、システムはより高いエネルギー状態に移行する可能性が高く、問題の解決策にはなりません。一方、進化が遅すぎると、計算時間が失われ、デコヒーレンスによる失敗の可能性が高くなります。この作業では、目前の問題を条件とする最適なスケジュールを作成するために、ディープニューラルモデルをトレーニングします。ハミルトニアン形式と2次非制約付きバイナリ最適化（QUBO）形式の2種類の問題表現を検討します。おおよその成功確率に従ってスケジュールをスコアリングする新しい損失関数が導入されています。ランダムQUBO問題、グローバー検索、3-SAT、およびMAX-CUT問題に対するアプローチのベンチマークを行い、ごく最近提案された代替アプローチだけでなく、かなりのマージンでアプローチが優れていることを示しています。,7.25,
SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments,"['Glen Berseth', 'Daniel Geng', 'Coline Manon Devin', 'Nicholas Rhinehart', 'Chelsea Finn', 'Dinesh Jayaraman', 'Sergey Levine']",https://openreview.net/forum?id=cPZOyoDloxl,"Every living organism struggles against disruptive environmental forces to carve out and maintain an orderly niche. We propose that such a struggle to achieve and preserve order might offer a principle for the emergence of useful behaviors in artificial agents. We formalize this idea into an unsupervised reinforcement learning method called surprise minimizing reinforcement learning (SMiRL). SMiRL alternates between learning a density model to evaluate the surprise of a stimulus, and improving the policy to seek more predictable stimuli. The policy seeks out stable and repeatable situations that counteract the environment's prevailing sources of entropy. This might include avoiding other hostile agents, or finding a stable, balanced pose for a bipedal robot in the face of disturbance forces. We demonstrate that our surprise minimizing agents can successfully play Tetris, Doom, control a humanoid to avoid falls, and navigate to escape enemies in a maze without any task-specific reward supervision. We further show that SMiRL can be used together with standard task rewards to accelerate reward-driven learning.",すべての生物は、破壊的な環境の力と闘い、秩序あるニッチを切り開いて維持します。秩序を達成し維持するためのそのような闘争は、人工エージェントにおける有用な行動の出現の原則を提供するかもしれないことを提案します。このアイデアを、サプライズ最小化強化学習（SMiRL）と呼ばれる教師なし強化学習方法に形式化します。 SMiRLは、刺激の驚きを評価するための密度モデルの学習と、より予測可能な刺激を探すためのポリシーの改善を交互に行います。このポリシーは、エントロピーの一般的なソースを打ち消す、安定した再現可能な状況を探します。これには、他の敵対的なエージェントを回避することや、外乱力に直面した二足歩行ロボットの安定したバランスの取れたポーズを見つけることが含まれる場合があります。驚きを最小限に抑えるエージェントが、テトリス、ドゥームをうまくプレイし、人型生物を制御して転倒を回避し、タスク固有の報酬の監督なしに迷路の中で敵を脱出するためにナビゲートできることを示します。さらに、SMiRLを標準のタスク報酬と一緒に使用して、報酬主導型の学習を加速できることを示します。,7.25,
Self-training For Few-shot Transfer Across Extreme Task Differences,"['Cheng Perng Phoo', 'Bharath Hariharan']",https://openreview.net/forum?id=O3Y56aqpChA,"Most few-shot learning techniques are pre-trained on a large, labeled “base dataset”. In problem domains where such large labeled datasets are not available for pre-training (e.g., X-ray, satellite images), one must resort to pre-training in a different “source” problem domain (e.g., ImageNet), which can be very different from the desired target task. Traditional few-shot and transfer learning techniques fail in the presence of such extreme differences between the source and target tasks. In this paper, we present a simple and effective solution to tackle this extreme domain gap: self-training a source domain representation on unlabeled data from the target domain. We show that this improves one-shot performance on the target domain by 2.9 points on average on the challenging BSCD-FSL benchmark consisting of datasets from multiple domains.",ほとんどの数ショットの学習手法は、ラベルが付けられた大規模なベースデータセットで事前にトレーニングされています。このような大きなラベル付きデータセットが事前トレーニングに利用できない問題ドメイン（X線、衛星画像など）では、別のソース問題ドメイン（ImageNetなど）で事前トレーニングを行う必要があります。これは非常に異なる場合があります。目的のターゲットタスクから。ソースタスクとターゲットタスクの間にこのような極端な違いがあると、従来の数ショットおよび転送学習手法は失敗します。このホワイトペーパーでは、この極端なドメインギャップに対処するためのシンプルで効果的なソリューションを紹介します。ターゲットドメインからのラベルなしデータでソースドメイン表現をセルフトレーニングします。これにより、複数のドメインからのデータセットで構成される挑戦的なBSCD-FSLベンチマークで、ターゲットドメインのワンショットパフォーマンスが平均2.9ポイント向上することを示します。,7.25,https://d3i71xaburhd42.cloudfront.net/1d16d4cdc3fcce26e2c2097d13896ec09683eee3/2-Figure1-1.png
Unbiased Teacher for Semi-Supervised Object Detection,"['Yen-Cheng Liu', 'Chih-Yao Ma', 'Zijian He', 'Chia-Wen Kuo', 'Kan Chen', 'Peizhao Zhang', 'Bichen Wu', 'Zsolt Kira', 'Peter Vajda']",https://openreview.net/forum?id=MJIve1zgR_,"Semi-supervised learning, i.e., training networks with both labeled and unlabeled data, has made significant progress recently. However, existing works have primarily focused on image classification tasks and neglected object detection which requires more annotation effort. In this work, we revisit the Semi-Supervised Object Detection (SS-OD) and identify the pseudo-labeling bias issue in SS-OD. To address this, we introduce Unbiased Teacher, a simple yet effective approach that jointly trains a student and a gradually progressing teacher in a mutually-beneficial manner. Together with a class-balance loss to downweight overly confident pseudo-labels, Unbiased Teacher consistently improved state-of-the-art methods by significant margins on COCO-standard, COCO-additional, and VOC datasets. Specifically, Unbiased Teacher achieves 6.8 absolute mAP improvements against state-of-the-art method when using 1% of labeled data on MS-COCO, achieves around 10 mAP improvements against the supervised baseline when using only 0.5, 1, 2% of labeled data on MS-COCO.",半教師あり学習、つまり、ラベル付きデータとラベルなしデータの両方を使用したトレーニングネットワークは、最近大きな進歩を遂げました。ただし、既存の作業は主に画像分類タスクに焦点を当てており、より多くの注釈作業を必要とするオブジェクト検出を無視しています。この作業では、半教師ありオブジェクト検出（SS-OD）を再検討し、SS-ODの疑似ラベルバイアスの問題を特定します。これに対処するために、私たちは偏りのない教師を紹介します。これは、学生と徐々に進歩する教師を相互に有益な方法で共同で訓練する、シンプルで効果的なアプローチです。 Unbiased Teacherは、自信過剰な疑似ラベルをダウンウェイトするためのクラスバランスの低下とともに、COCO標準、COCO追加、およびVOCデータセットの大幅なマージンにより、最先端の方法を一貫して改善しました。具体的には、Unbiased Teacherは、1を使用すると、最先端の方法に対して6.8の絶対mAPの改善を達成します。,7.25,
Graph Convolution with Low-rank Learnable Local Filters,"['Xiuyuan Cheng', 'Zichen Miao', 'Qiang Qiu']",https://openreview.net/forum?id=9OHFhefeB86,"Geometric variations like rotation, scaling, and viewpoint changes pose a significant challenge to visual understanding. One common solution is to directly model certain intrinsic structures, e.g., using landmarks. However, it then becomes non-trivial to build effective deep models, especially when the underlying non-Euclidean grid is irregular and coarse. Recent deep models using graph convolutions provide an appropriate framework to handle such non-Euclidean data, but many of them, particularly those based on global graph Laplacians, lack expressiveness to capture local features required for representation of signals lying on the non-Euclidean grid. The current paper introduces a new type of graph convolution with learnable low-rank local filters, which is provably more expressive than previous spectral graph convolution methods. The model also provides a unified framework for both spectral and spatial graph convolutions. To improve model robustness, regularization by local graph Laplacians is introduced. The representation stability against input graph data perturbation is theoretically proved, making use of the graph filter locality and the local graph regularization. Experiments on spherical mesh data, real-world facial expression recognition/skeleton-based action recognition data, and data with simulated graph noise show the empirical advantage of the proposed model.",回転、スケーリング、視点の変更などの幾何学的な変化は、視覚的な理解に大きな課題をもたらします。一般的な解決策の1つは、ランドマークを使用するなど、特定の固有の構造を直接モデル化することです。ただし、特に基礎となる非ユークリッドグリッドが不規則で粗い場合は、効果的なディープモデルを構築することは簡単ではありません。グラフ畳み込みを使用する最近の深いモデルは、そのような非ユークリッドデータを処理するための適切なフレームワークを提供しますが、それらの多く、特にグローバルグラフラプラシアンに基づくモデルは、非ユークリッドグリッド上にある信号の表現に必要なローカル特徴をキャプチャする表現力に欠けています。現在の論文では、学習可能な低ランクのローカルフィルターを使用した新しいタイプのグラフ畳み込みを紹介しています。これは、以前のスペクトルグラフ畳み込み法よりも表現力が高いことが証明されています。このモデルは、スペクトルグラフと空間グラフの両方の畳み込みのための統一されたフレームワークも提供します。モデルのロバスト性を向上させるために、ローカルグラフラプラシアンによる正則化が導入されています。入力グラフデータの摂動に対する表現の安定性は、グラフフィルターの局所性とローカルグラフの正則化を利用して理論的に証明されています。球形メッシュデータ、実際の表情認識/スケルトンベースのアクション認識データ、およびシミュレートされたグラフノイズを使用したデータに関する実験は、提案されたモデルの経験的な利点を示しています。,7.25,
MONGOOSE: A Learnable LSH Framework for Efficient Neural Network Training,"['Beidi Chen', 'Zichang Liu', 'Binghui Peng', 'Zhaozhuo Xu', 'Jonathan Lingjie Li', 'Tri Dao', 'Zhao Song', 'Anshumali Shrivastava', 'Christopher Re']",https://openreview.net/forum?id=wWK7yXkULyh,"Recent advances by practitioners in the deep learning community have breathed new life into Locality Sensitive Hashing (LSH), using it to reduce memory and time bottlenecks in neural network (NN) training. However, while LSH has sub-linear guarantees for approximate near-neighbor search in theory, it is known to have inefficient query time in practice due to its use of random hash functions. Moreover, when model parameters are changing, LSH suffers from update overhead. This work is motivated by an observation that model parameters evolve slowly, such that the changes do not always require an LSH update to maintain performance. This phenomenon points to the potential for a reduction in update time and allows for a modified learnable version of data-dependent LSH to improve query time at a low cost. We use the above insights to build MONGOOSE, an end-to-end LSH framework for efficient NN training. In particular, MONGOOSE is equipped with a scheduling algorithm to adaptively perform LSH updates with provable guarantees and learnable hash functions to improve query efficiency. Empirically, we validate MONGOOSE on large-scale deep learning models for recommendation systems and language modeling. We find that it achieves up to 8% better accuracy compared to previous LSH approaches, with $6.5 \times$ speed-up and $6\times$ reduction in memory usage.",ディープラーニングコミュニティの実践者による最近の進歩により、局所性鋭敏型ハッシュ（LSH）に新しい命が吹き込まれ、ニューラルネットワーク（NN）トレーニングのメモリと時間のボトルネックが削減されました。ただし、LSHは理論的には近似近傍検索に対して劣線形保証を持っていますが、ランダムハッシュ関数を使用しているため、実際にはクエリ時間が非効率的であることが知られています。さらに、モデルパラメータが変更されると、LSHは更新のオーバーヘッドに悩まされます。この作業は、モデルパラメータの進化が遅いため、パフォーマンスを維持するために変更が必ずしもLSHの更新を必要としないという観察によって動機付けられています。この現象は、更新時間の短縮の可能性を示しており、データ依存LSHの学習可能なバージョンを変更して、低コストでクエリ時間を改善することができます。上記の洞察を使用して、効率的なNNトレーニングのためのエンドツーエンドのLSHフレームワークであるMONGOOSEを構築します。特に、MONGOOSEは、クエリの効率を向上させるために、証明可能な保証と学習可能なハッシュ関数を使用してLSH更新を適応的に実行するスケジューリングアルゴリズムを備えています。経験的に、レコメンデーションシステムと言語モデリングのための大規模な深層学習モデルでMONGOOSEを検証します。最大8を達成することがわかります,7.25,
Self-supervised Visual Reinforcement Learning with Object-centric Representations,"['Andrii Zadaianchuk', 'Maximilian Seitzer', 'Georg Martius']",https://openreview.net/forum?id=xppLmXCbOw1,"Autonomous agents need large repertoires of skills to act reasonably on new tasks that they have not seen before. However, acquiring these skills using only a stream of high-dimensional, unstructured, and unlabeled observations is a tricky challenge for any autonomous agent. Previous methods have used variational autoencoders to encode a scene into a low-dimensional vector that can be used as a goal for an agent to discover new skills. Nevertheless, in compositional/multi-object environments it is difficult to disentangle all the factors of variation into such a fixed-length representation of the whole scene. We propose to use object-centric representations as a modular and structured observation space, which is learned with a compositional generative world model.
We show that the structure in the representations in combination with goal-conditioned attention policies helps the autonomous agent to discover and learn useful skills. These skills can be further combined to address compositional tasks like the manipulation of several different objects.",自律エージェントは、これまでに見たことのない新しいタスクに合理的に対処するために、スキルの大きなレパートリーを必要とします。ただし、高次元、構造化されていない、ラベルのない観測のストリームのみを使用してこれらのスキルを習得することは、自律エージェントにとって難しい課題です。以前の方法では、変分オートエンコーダーを使用してシーンを低次元のベクトルにエンコードしました。これは、エージェントが新しいスキルを発見するための目標として使用できます。それにもかかわらず、構図/マルチオブジェクト環境では、変化のすべての要因をシーン全体のそのような固定長の表現に解きほぐすことは困難です。オブジェクト中心の表現をモジュール式で構造化された観測空間として使用することを提案します。これは、構成生成世界モデルで学習されます。目標条件付き注意ポリシーと組み合わせた表現の構造が、自律エージェントが有用なスキルを発見して学習するのに役立つことを示します。これらのスキルをさらに組み合わせて、いくつかの異なるオブジェクトの操作などの構成タスクに対処できます。,7.25,https://d3i71xaburhd42.cloudfront.net/7c1b75ab7bed79163d3d830a6a83a4023b496ebb/2-Figure1-1.png
Improved Autoregressive Modeling with Distribution Smoothing,"['Chenlin Meng', 'Jiaming Song', 'Yang Song', 'Shengjia Zhao', 'Stefano Ermon']",https://openreview.net/forum?id=rJA5Pz7lHKb,"While autoregressive models excel at image compression, their sample quality is often lacking. Inspired by randomized smoothing for adversarial defense, we incorporate randomized smoothing techniques into autoregressive generative modeling. We first model a smoothed version of the data distribution and then recover the data distribution by learning to reverse the smoothing process. We demonstrate empirically on a 1-d dataset that by appropriately choosing the smoothing level, we can keep the proposed process relatively easier to model than directly learning a data distribution with a high Lipschitz constant. Since autoregressive generative modeling consists of a sequence of 1-d density estimation problems, we believe the same arguments can be generalized to an autoregressive model. This seemingly simple procedure drastically improves the sample quality of existing autoregressive models on several synthetic and real-world datasets while obtaining competitive likelihoods on synthetic datasets.",自己回帰モデルは画像圧縮に優れていますが、サンプル品質が不足していることがよくあります。敵対的防御のためのランダム化平滑化に触発されて、ランダム化平滑化手法を自己回帰生成モデリングに組み込みます。最初にデータ分布の平滑化バージョンをモデル化し、次に平滑化プロセスを逆にすることを学習してデータ分布を回復します。平滑化レベルを適切に選択することにより、高いリプシッツ定数でデータ分布を直接学習するよりも、提案されたプロセスを比較的簡単にモデル化できることを、1次元データセットで経験的に示します。自己回帰生成モデリングは一連の1次元密度推定問題で構成されているため、同じ議論を自己回帰モデルに一般化できると考えています。この一見単純な手順により、いくつかの合成データセットと実世界のデータセットで既存の自己回帰モデルのサンプル品質が大幅に向上し、合成データセットで競合する可能性が得られます。,7.25,
Federated Learning Based on Dynamic Regularization,"['Durmus Alp Emre Acar', 'Yue Zhao', 'Ramon Matas', 'Matthew Mattina', 'Paul Whatmough', 'Venkatesh Saligrama']",https://openreview.net/forum?id=B7v4QMR6Z9w,"We propose a novel federated learning method for distributively training neural network models, where the server orchestrates cooperation between a subset of randomly chosen devices in each round. We view Federated Learning problem primarily from a communication perspective and allow more device level computations to save transmission costs. We point out a fundamental dilemma, in that the minima of the local-device level empirical loss are inconsistent with those of the global empirical loss. Different from recent prior works, that either attempt inexact minimization or utilize devices for parallelizing gradient computation, we propose a dynamic regularizer for each device at each round, so that in the limit the global and device solutions are aligned. We demonstrate both through empirical results on real and synthetic data as well as analytical results that our scheme leads to efficient training, in both convex and non-convex settings, while being fully agnostic to device heterogeneity and robust to large number of devices, partial participation and unbalanced data.",サーバーが各ラウンドでランダムに選択されたデバイスのサブセット間の協調を調整する、ニューラルネットワークモデルを分散的にトレーニングするための新しい連合学習方法を提案します。連合学習の問題を主に通信の観点から見て、より多くのデバイスレベルの計算を可能にして、伝送コストを節約します。ローカルデバイスレベルの経験的損失の最小値がグローバルな経験的損失の最小値と一致しないという根本的なジレンマを指摘します。不正確な最小化を試みるか、勾配計算を並列化するためにデバイスを利用する最近の以前の研究とは異なり、各ラウンドで各デバイスの動的正則化を提案し、制限内でグローバルソリューションとデバイスソリューションを調整します。実データと合成データの経験的結果と分析結果の両方を通じて、私たちのスキームが凸型と非凸型の両方の設定で効率的なトレーニングにつながることを示しますが、デバイスの不均一性に完全にとらわれず、多数のデバイスに堅牢であり、部分的な参加不均衡なデータ。,7.25,
Growing Efficient Deep Networks by Structured Continuous Sparsification,"['Xin Yuan', 'Pedro Henrique Pamplona Savarese', 'Michael Maire']",https://openreview.net/forum?id=wb3wxCObbRT,"We develop an approach to growing deep network architectures over the course of training, driven by a principled combination of accuracy and sparsity objectives.  Unlike existing pruning or architecture search techniques that operate on full-sized models or supernet architectures, our method can start from a small, simple seed architecture and dynamically grow and prune both layers and filters.  By combining a continuous relaxation of discrete network structure optimization with a scheme for sampling sparse subnetworks, we produce compact, pruned networks, while also drastically reducing the computational expense of training.  For example, we achieve $49.7\%$ inference FLOPs and $47.4\%$ training FLOPs savings compared to a baseline ResNet-50 on ImageNet, while maintaining $75.2\%$ top-1 validation accuracy --- all without any dedicated fine-tuning stage.  Experiments across CIFAR, ImageNet, PASCAL VOC, and Penn Treebank, with convolutional networks for image classification and semantic segmentation, and recurrent networks for language modeling, demonstrate that we both train faster and produce more efficient networks than competing architecture pruning or search methods.",精度とスパース性の目標の原則的な組み合わせに基づいて、トレーニングの過程でディープネットワークアーキテクチャを成長させるアプローチを開発します。フルサイズのモデルまたはスーパーネットアーキテクチャで動作する既存のプルーニングまたはアーキテクチャ検索手法とは異なり、この方法は、小さくて単純なシードアーキテクチャから開始して、レイヤーとフィルターの両方を動的に拡張およびプルーニングできます。離散ネットワーク構造最適化の継続的な緩和とスパースサブネットワークをサンプリングするスキームを組み合わせることにより、コンパクトで剪定されたネットワークを生成すると同時に、トレーニングの計算コストを大幅に削減します。たとえば、ImageNetのベースラインResNet-50と比較して49.7％の推論FLOPと47.4％のトレーニングFLOPの節約を達成し、専用の微調整段階なしで75.2％のトップ1検証精度を維持します。画像分類とセマンティックセグメンテーションのための畳み込みネットワーク、および言語モデリングのためのリカレントネットワークを使用した、CIFAR、ImageNet、PASCAL VOC、およびPenn Treebankでの実験は、競合するアーキテクチャのプルーニングや検索方法よりも高速にトレーニングし、より効率的なネットワークを生成することを示しています。,7.25,https://d3i71xaburhd42.cloudfront.net/708a8f29f828e5a167547959f49a49ef8e0ca8cc/2-Figure1-1.png
Go with the flow: Adaptive control for Neural ODEs,"['Mathieu Chalvidal', 'Matthew Ricci', 'Rufin VanRullen', 'Thomas Serre']",https://openreview.net/forum?id=giit4HdDNa,"Despite their elegant formulation and lightweight memory cost, neural ordinary differential equations (NODEs) suffer from known representational limitations. In particular, the single flow learned by NODEs cannot express all homeomorphisms from a given data space to itself, and their static weight parameterization restricts the type of functions they can learn compared to discrete architectures with layer-dependent weights. Here, we describe a new module called neurally-controlled ODE (N-CODE) designed to improve the expressivity of NODEs. The parameters of N-CODE modules are dynamic variables governed by a trainable map from initial or current activation state, resulting in forms of open-loop and closed-loop control, respectively. A single module is sufficient for learning a distribution on non-autonomous flows that adaptively drive neural representations. We provide theoretical and empirical evidence that N-CODE circumvents limitations of previous NODEs models and show how increased model expressivity manifests in several supervised and unsupervised learning problems. These favorable empirical results indicate the potential of using data- and activity-dependent plasticity in neural networks across numerous domains.",洗練された定式化と軽量のメモリコストにもかかわらず、ニューラル常微分方程式（NODE）には既知の表現上の制限があります。特に、NODEによって学習された単一のフローは、特定のデータ空間からそれ自体へのすべての同相写像を表現できるわけではなく、静的な重みのパラメーター化により、レイヤーに依存する重みを持つ離散アーキテクチャと比較して、学習できる関数のタイプが制限されます。ここでは、NODEの表現力を向上させるために設計された神経制御ODE（N-CODE）と呼ばれる新しいモジュールについて説明します。 N-CODEモジュールのパラメーターは、初期または現在のアクティブ化状態からのトレーニング可能なマップによって制御される動的変数であり、それぞれ開ループおよび閉ループ制御の形式になります。神経表現を適応的に駆動する非自律フローの分布を学習するには、単一のモジュールで十分です。 N-CODEが以前のNODEモデルの制限を回避するという理論的および経験的証拠を提供し、モデルの表現力の向上がいくつかの教師あり学習問題と教師なし学習問題でどのように現れるかを示します。これらの好ましい経験的結果は、多数のドメインにわたるニューラルネットワークでデータおよびアクティビティに依存する可塑性を使用する可能性を示しています。,7.25,
Long-tailed Recognition by Routing Diverse Distribution-Aware Experts,"['Xudong Wang', 'Long Lian', 'Zhongqi Miao', 'Ziwei Liu', 'Stella Yu']",https://openreview.net/forum?id=D9I3drBz4UC,"Natural data are often long-tail distributed over semantic classes. Existing recognition methods tend to focus on tail performance gain, often at the expense of head performance loss from increased classifier variance. The low tail performance manifests itself in large inter-class confusion and high classifier variance.  We aim to reduce both the bias and the variance of a long-tailed classifier by RoutIng Diverse Experts (RIDE). It has three components: 1) a shared architecture for multiple classifiers (experts); 2) a distribution-aware diversity loss that encourages more diverse decisions for classes with fewer training instances; and 3) an expert routing module that dynamically assigns more ambiguous instances to additional experts.  With on-par computational complexity, RIDE significantly outperforms the state-of-the-art methods by 5$\%$ to 7$\%$ on all the benchmarks including CIFAR100-LT, ImageNet-LT and iNaturalist. RIDE is also a universal framework that can be applied to different backbone networks and integrated into various long-tailed algorithms and training mechanisms for consistent performance gains. ",自然データは、多くの場合、セマンティッククラスにロングテールで分散されます。既存の認識方法は、多くの場合、分類器の分散の増加によるヘッドパフォーマンスの低下を犠牲にして、テールパフォーマンスの向上に焦点を合わせる傾向があります。ローテールパフォーマンスは、クラス間の大きな混乱と高い分類器の分散に現れます。 RoutIng Diverse Experts（RIDE）によるロングテール分類器のバイアスと分散の両方を減らすことを目指しています。これには3つのコンポーネントがあります。1）複数の分類子（エキスパート）用の共有アーキテクチャ。 2）トレーニングインスタンスが少ないクラスでより多様な意思決定を促進する、配布を意識した多様性の喪失。 3）よりあいまいなインスタンスを追加のエキスパートに動的に割り当てるエキスパートルーティングモジュール。計算の複雑さが同等であるため、RIDEは、CIFAR100-LT、ImageNet-LT、iNaturalistを含むすべてのベンチマークで、最先端の方法を5％から7％大幅に上回っています。 RIDEは、さまざまなバックボーンネットワークに適用でき、さまざまなロングテールアルゴリズムおよびトレーニングメカニズムに統合して、一貫したパフォーマンスを向上させることができるユニバーサルフレームワークでもあります。,7.25,https://d3i71xaburhd42.cloudfront.net/1d2bc7bf0772799650ce00dcbe7d57121fbf15b2/2-Figure1-1.png
Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies,"['T. Konstantin Rusch', 'Siddhartha Mishra']",https://openreview.net/forum?id=F3s69XzWOia,"Circuits of biological neurons, such as in the functional parts of the brain can be modeled as networks of coupled oscillators. Inspired by the ability of these systems to express a rich set of outputs while keeping (gradients of) state variables bounded, we propose a novel architecture for recurrent neural networks. Our proposed RNN is based on a time-discretization of a system of second-order ordinary differential equations, modeling networks of controlled nonlinear oscillators. We prove precise bounds on the gradients of the hidden states, leading to the mitigation of the exploding and vanishing gradient problem for this RNN. Experiments show that the proposed RNN is comparable in performance to the state of the art on a variety of benchmarks, demonstrating the potential of this architecture to provide stable and accurate RNNs for processing complex sequential data.",脳の機能部分などの生物学的ニューロンの回路は、結合された発振器のネットワークとしてモデル化できます。状態変数（の勾配）を制限したまま、豊富な出力セットを表現するこれらのシステムの機能に触発されて、リカレントニューラルネットワークの新しいアーキテクチャを提案します。私たちが提案するRNNは、2次常微分方程式のシステムの時間離散化に基づいており、制御された非線形オシレーターのネットワークをモデル化します。隠れた状態の勾配の正確な境界を証明し、このRNNの爆発および消失勾配問題の軽減につながります。実験は、提案されたRNNのパフォーマンスがさまざまなベンチマークで最新技術に匹敵することを示しており、複雑なシーケンシャルデータを処理するための安定した正確なRNNを提供するこのアーキテクチャの可能性を示しています。,7.25,https://d3i71xaburhd42.cloudfront.net/fac144db777ddc3d85bb314087889689293affa0/5-Figure1-1.png
Benefit of deep learning with non-convex noisy gradient descent: Provable excess risk bound and superiority to kernel methods,"['Taiji Suzuki', 'Shunta Akiyama']",https://openreview.net/forum?id=2m0g1wEafh,"Establishing a theoretical analysis that explains why deep learning can outperform shallow learning such as kernel methods is one of the biggest issues in the deep learning literature. Towards answering this question, we evaluate excess risk of a deep learning estimator trained by a noisy gradient descent with ridge regularization on a mildly overparameterized neural network, 
and discuss its superiority to a class of linear estimators that includes neural tangent kernel approach, random feature model, other kernel methods, $k$-NN estimator and so on. We consider a teacher-student regression model, and eventually show that {\it any} linear estimator can be outperformed by deep learning in a sense of the minimax optimal rate especially for a high dimension setting. The obtained excess bounds are so-called fast learning rate which is faster than $O(1/\sqrt{n})$ that is obtained by usual Rademacher complexity analysis. This discrepancy is induced by the non-convex geometry of the model and the noisy gradient descent used for neural network training provably reaches a near global optimal solution even though the loss landscape is highly non-convex. Although the noisy gradient descent does not employ any explicit or implicit sparsity inducing regularization, it shows a preferable generalization performance that dominates linear estimators.",ディープラーニングがカーネル法などの浅い学習よりも優れている理由を説明する理論的分析を確立することは、ディープラーニングの文献における最大の問題の1つです。この質問への回答に向けて、軽度にパラメーター化されたニューラルネットワークでのリッジ正則化を伴うノイズの多い勾配降下法によってトレーニングされた深層学習推定量の過剰リスクを評価し、ニューラルタンジェントカーネルアプローチ、ランダム特徴モデルを含む線形推定量のクラスに対するその優位性について説明します、他のカーネル法、k-NN推定量など。教師と生徒の回帰モデルを検討し、最終的には、特に高次元の設定で、ミニマックス最適率の意味で深層学習によって線形推定量を上回ることができることを示します。得られる超過限界は、通常のラデマッハー複雑度分析によって得られる$ O（1 / \ sqrt {n}）$よりも速いいわゆる高速学習率です。この不一致は、モデルの非凸幾何学によって引き起こされ、ニューラルネットワークトレーニングに使用されるノイズの多い勾配降下法は、損失ランドスケープが非常に非凸である場合でも、ほぼグローバルな最適解に到達する可能性があります。ノイズの多い最急降下法は、正則化を誘発する明示的または暗黙的なスパース性を使用しませんが、線形推定量を支配する好ましい一般化パフォーマンスを示します。,7.25,
Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?,"['Zhiyuan Li', 'Yi Zhang', 'Sanjeev Arora']",https://openreview.net/forum?id=uCY5MuAxcxU,"Convolutional neural networks often dominate fully-connected counterparts in generalization performance, especially on image classification tasks. This is often explained in terms of \textquotedblleft better inductive bias.\textquotedblright\  However, this has not been made mathematically rigorous, and the hurdle is that the fully connected net can always simulate the convolutional net  (for a fixed task). Thus the training algorithm plays a role. The current work describes a natural task on which a provable sample complexity gap can be shown, for standard training algorithms. We construct a single natural distribution on $\mathbb{R}^d\times\{\pm 1\}$ on which any orthogonal-invariant algorithm (i.e. fully-connected networks trained with most gradient-based methods from gaussian initialization) requires $\Omega(d^2)$ samples to generalize while $O(1)$ samples suffice for convolutional architectures. Furthermore, we demonstrate a single target function, learning which on all possible distributions leads to an $O(1)$ vs $\Omega(d^2/\varepsilon)$ gap. The proof relies on the fact that SGD on fully-connected network is orthogonal equivariant. Similar results are achieved for $\ell_2$ regression and adaptive training algorithms, e.g. Adam and AdaGrad, which are only permutation equivariant.",畳み込みニューラルネットワークは、特に画像分類タスクにおいて、一般化パフォーマンスにおいて完全に接続された対応物を支配することがよくあります。これは多くの場合、より良い誘導バイアスの観点から説明されます。ただし、これは数学的に厳密にはされておらず、ハードルは、完全に接続されたネットが常に畳み込みネットをシミュレートできることです（固定タスクの場合）。したがって、トレーニングアルゴリズムが役割を果たします。現在の作業では、標準のトレーニングアルゴリズムについて、証明可能なサンプルの複雑さのギャップを示すことができる自然なタスクについて説明しています。 R ^（d）{1}上に単一の自然分布を構築します。この分布では、直交不変アルゴリズム（つまり、ガウス初期化からのほとんどの勾配ベースの方法でトレーニングされた完全接続ネットワーク）で、一般化するために（d2）サンプルが必要です。 ）畳み込みアーキテクチャにはサンプルで十分です。さらに、単一のターゲット関数を示し、すべての可能な分布でO（1）と（d2 /）のギャップにつながることを学習します。証明は、完全に接続されたネットワーク上のSGDが直交同変であるという事実に依存しています。同様の結果が、l2回帰および適応トレーニングアルゴリズム（たとえば、順列同変のみであるAdamおよびAdaGrad）でも達成されます。,7.25,https://d3i71xaburhd42.cloudfront.net/881a28b1736e3026ae9f2d540786793a83deb1fc/2-Figure1-1.png
Mutual Information State Intrinsic Control,"['Rui Zhao', 'Yang Gao', 'Pieter Abbeel', 'Volker Tresp', 'Wei Xu']",https://openreview.net/forum?id=OthEq8I5v1,"Reinforcement learning has been shown to be highly successful at many challenging tasks. However, success heavily relies on well-shaped rewards. Intrinsically motivated RL attempts to remove this constraint by defining an intrinsic reward function. Motivated by the self-consciousness concept in psychology, we make a natural assumption that the agent knows what constitutes itself, and propose a new intrinsic objective that encourages the agent to have maximum control on the environment. We mathematically formalize this reward as the mutual information between the agent state and the surrounding state under the current agent policy. With this new intrinsic motivation, we are able to outperform previous methods, including being able to complete the pick-and-place task for the first time without using any task reward. A video showing experimental results is available in the supplementary material.",強化学習は、多くの困難なタスクで非常に成功することが示されています。ただし、成功は形の整った報酬に大きく依存します。本質的に動機付けられたRLは、本質的な報酬関数を定義することによって、この制約を取り除こうとします。心理学における自己意識の概念に動機付けられて、私たちはエージェントが自分自身を構成するものを知っているという自然な仮定を立て、エージェントが環境を最大限に制御することを奨励する新しい本質的な目的を提案します。この報酬は、現在のエージェントポリシーの下で、エージェントの状態と周囲の状態の間の相互情報量として数学的に形式化されます。この新しい本質的な動機により、タスクの報酬を使用せずに初めてピックアンドプレースタスクを完了することができるなど、以前の方法を上回ることができます。実験結果を示すビデオは、補足資料で利用できます。,7.25,
Is Attention Better Than Matrix Decomposition?,"['Zhengyang Geng', 'Meng-Hao Guo', 'Hongxu Chen', 'Xia Li', 'Ke Wei', 'Zhouchen Lin']",https://openreview.net/forum?id=1FvkSpWosOl,"As an essential ingredient of modern deep learning, attention mechanism, especially self-attention, plays a vital role in the global correlation discovery. However, is hand-crafted attention irreplaceable when modeling the global context? Our intriguing finding is that self-attention is not better than the matrix decomposition (MD) model developed 20 years ago regarding the performance and computational cost for encoding the long-distance dependencies. We model the global context issue as a low-rank completion problem and show that its optimization algorithms can help design global information blocks. This paper then proposes a series of Hamburgers, in which we employ the optimization algorithms for solving MDs to factorize the input representations into sub-matrices and reconstruct a low-rank embedding. Hamburgers with different MDs can perform favorably against the popular global context module self-attention when carefully coping with gradients back-propagated through MDs. Comprehensive experiments are conducted in the vision tasks where it is crucial to learn the global context, including semantic segmentation and image generation, demonstrating significant improvements over self-attention and its variants.",現代の深層学習の不可欠な要素として、注意メカニズム、特に自己注意は、グローバルな相関関係の発見において重要な役割を果たします。しかし、グローバルコンテキストをモデル化する場合、手作りの注意はかけがえのないものですか？私たちの興味深い発見は、長距離依存関係をエンコードするためのパフォーマンスと計算コストに関して、自己注意は20年前に開発された行列分解（MD）モデルよりも優れていないということです。グローバルコンテキストの問題を低ランクの完了問題としてモデル化し、その最適化アルゴリズムがグローバル情報ブロックの設計に役立つことを示します。次に、この論文では、MDを解くための最適化アルゴリズムを使用して、入力表現をサブ行列に因数分解し、低ランクの埋め込みを再構築する一連のハンバーガーを提案します。異なるMDを持つハンバーガーは、MDを介して逆伝播された勾配に注意深く対処する場合、人気のあるグローバルコンテキストモジュールの自己注意に対して有利に機能します。包括的な実験は、セマンティックセグメンテーションや画像生成などのグローバルコンテキストを学習することが重要なビジョンタスクで実施され、自己注意とその変形に対する大幅な改善を示しています。,7.25,
Sharpness-aware Minimization for Efficiently Improving Generalization,"['Pierre Foret', 'Ariel Kleiner', 'Hossein Mobahi', 'Behnam Neyshabur']",https://openreview.net/forum?id=6Tm1mposlrM,"In today's heavily overparameterized models, the value of the training loss provides few guarantees on model generalization ability. Indeed, optimizing only the training loss value, as is commonly done, can easily lead to suboptimal model quality. Motivated by prior work connecting the geometry of the loss landscape and generalization, we introduce a novel, effective procedure for instead simultaneously minimizing loss value and loss sharpness.  In particular, our procedure, Sharpness-Aware Minimization (SAM), seeks parameters that lie in neighborhoods having uniformly low loss; this formulation results in a min-max optimization problem on which gradient descent can be performed efficiently. We present empirical results showing that SAM improves model generalization across a variety of benchmark datasets (e.g., CIFAR-{10, 100}, ImageNet, finetuning tasks) and models, yielding novel state-of-the-art performance for several.  Additionally, we find that SAM natively provides robustness to label noise on par with that provided by state-of-the-art procedures that specifically target learning with noisy labels.",今日の非常にパラメータ化されたモデルでは、トレーニング損失の値はモデルの一般化能力についてほとんど保証を提供しません。実際、一般的に行われているように、トレーニング損失値のみを最適化すると、モデルの品質が最適ではなくなる可能性があります。損失ランドスケープのジオメトリと一般化を結び付ける以前の作業に動機付けられて、代わりに損失値と損失シャープネスを同時に最小化するための新しい効果的な手順を紹介します。特に、私たちの手順であるSharpness-Aware Minimization（SAM）は、損失が均一に低い近傍にあるパラメーターを探します。この定式化により、最急降下法を効率的に実行できる最小-最大最適化問題が発生します。 SAMがさまざまなベンチマークデータセット（CIFAR-10、100、ImageNet、微調整タスクなど）およびモデル全体でモデルの一般化を改善し、いくつかの新しい最先端のパフォーマンスを生み出すことを示す経験的結果を提示します。さらに、SAMは、ノイズの多いラベルを使用した学習を特に対象とする最先端の手順によって提供されるものと同等の、ノイズをラベル付けするための堅牢性をネイティブに提供することがわかりました。,7.25,https://d3i71xaburhd42.cloudfront.net/c2f306f752e30ace26640af8a09d2c07036999d7/2-Figure1-1.png
SALD: Sign Agnostic Learning with Derivatives,"['Matan Atzmon', 'Yaron Lipman']",https://openreview.net/forum?id=7EDgLu9reQD,"earning 3D geometry directly from raw data, such as point clouds, triangle soups, or unoriented meshes is still a challenging task that feeds many downstream computer vision and graphics applications. 

In this paper, we introduce SALD: a method for learning implicit neural representations of shapes directly from raw data. We generalize sign agnostic learning (SAL) to include derivatives: given an unsigned distance function to the input raw data, we advocate a novel sign agnostic regression loss, incorporating both pointwise values and gradients of the unsigned distance function. Optimizing this loss leads to a signed implicit function solution, the zero level set of which is a high quality and valid manifold approximation to the input 3D data. The motivation behind SALD is that incorporating derivatives in a regression loss leads to a lower sample complexity, and consequently better fitting. In addition, we provide empirical evidence, as well as theoretical motivation in 2D that SAL enjoys a minimal surface property, favoring minimal area solutions. More importantly, we are able to show that this property still holds for SALD, i.e.,  with derivatives included.

We demonstrate the efficacy of SALD for shape space learning on two challenging datasets: ShapeNet that contains inconsistent orientation and non-manifold meshes, and D-Faust that contains raw 3D scans (triangle soups). On both these datasets, we present state-of-the-art results.",点群、三角形のスープ、方向性のないメッシュなどの生データから直接3Dジオメトリを取得することは、多くのダウンストリームコンピュータビジョンおよびグラフィックスアプリケーションを養う困難な作業です。この論文では、SALDを紹介します。これは、生データから直接形状の陰的神経表現を学習する方法です。符号にとらわれない学習（SAL）を一般化して、導関数を含めます。入力された生データに符号なしの距離関数が与えられると、符号なしの距離関数の点ごとの値と勾配の両方を組み込んだ、新しい符号にとらわれない回帰損失を提唱します。この損失を最適化すると、符号付き陰関数ソリューションが得られます。そのゼロレベルセットは、入力3Dデータに対する高品質で有効な多様体近似です。 SALDの背後にある動機は、回帰損失に導関数を組み込むと、サンプルの複雑さが低下し、その結果、フィッティングが向上することです。さらに、SALが最小の表面特性を享受し、最小の面積のソリューションを支持するという経験的証拠と2Dの理論的動機を提供します。さらに重要なことに、このプロパティがSALDにも当てはまる、つまり導関数が含まれていることを示すことができます。一貫性のない方向と非多様体メッシュを含むShapeNetと生の3Dスキャン（三角形のスープ）を含むD-Faustの2つの挑戦的なデータセットでの形状空間学習に対するSALDの有効性を示します。これらのデータセットの両方で、最先端の結果を示します。,7.25,https://d3i71xaburhd42.cloudfront.net/7e91d3e42fafcb5c3c1f411b30f5c10a3ad2bd6b/2-Figure1-1.png
PMI-Masking: Principled masking of correlated spans,"['Yoav Levine', 'Barak Lenz', 'Opher Lieber', 'Omri Abend', 'Kevin Leyton-Brown', 'Moshe Tennenholtz', 'Yoav Shoham']",https://openreview.net/forum?id=3Aoft6NWFej,"Masking tokens uniformly at random constitutes a common flaw in the pretraining of Masked Language Models (MLMs) such as BERT. We show that such uniform masking allows an MLM to minimize its training objective by latching onto shallow local signals, leading to pretraining inefficiency and suboptimal downstream performance. To address this flaw, we propose PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information (PMI), which jointly masks a token n-gram if it exhibits high collocation over the corpus. PMI-Masking motivates, unifies, and improves upon prior more heuristic approaches that attempt to address the drawback of random uniform token masking, such as whole-word masking, entity/phrase masking, and random-span masking. Specifically, we show experimentally that PMI-Masking reaches the performance of prior masking approaches in half the training time, and consistently improves performance at the end of pretraining.",トークンをランダムに均一にマスキングすることは、BERTなどのマスクされた言語モデル（MLM）の事前トレーニングにおける一般的な欠陥を構成します。このような均一なマスキングにより、MLMは浅いローカル信号をラッチすることでトレーニングの目的を最小限に抑えることができ、トレーニング前の非効率性と最適ではないダウンストリームパフォーマンスにつながることを示します。この欠陥に対処するために、PMI-Maskingを提案します。これは、Pointwise Mutual Information（PMI）の概念に基づく原理的なマスキング戦略であり、コーパス上で高いコロケーションを示す場合にトークンn-gramを共同でマスキングします。 PMI-Maskingは、単語全体のマスキング、エンティティ/フレーズのマスキング、ランダムスパンのマスキングなど、ランダムな均一トークンマスキングの欠点に対処しようとする、以前のよりヒューリスティックなアプローチを動機付け、統合し、改善します。具体的には、PMIマスキングがトレーニング時間の半分で以前のマスキングアプローチのパフォーマンスに到達し、事前トレーニングの終了時に一貫してパフォーマンスを向上させることを実験的に示します。,7.25,https://d3i71xaburhd42.cloudfront.net/518cb6d4247bdebf21e2811f296b0c7372602a0a/2-Figure1-1.png
Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows,"['Kashif Rasul', 'Abdul-Saboor Sheikh', 'Ingmar Schuster', 'Urs M Bergmann', 'Roland Vollgraf']",https://openreview.net/forum?id=WiGQBFuVRv,"Time series forecasting is often fundamental to scientific and engineering problems and enables decision making. With ever increasing data set sizes, a trivial solution to scale up predictions is to assume independence between interacting time series. However, modeling statistical dependencies can improve accuracy and enable analysis of interaction effects. Deep learning methods are well suited for this problem, but multi-variate models often assume a simple parametric distribution and do not scale to high dimensions. In this work we model the multi-variate temporal dynamics of time series via an autoregressive deep learning model, where the data distribution  is represented by a conditioned normalizing flow. This combination retains the power of autoregressive models, such as good performance in extrapolation into the future, with the flexibility of flows as a general purpose high-dimensional distribution model, while remaining computationally tractable. We show that it improves over the state-of-the-art for standard metrics on many real-world data sets with several thousand interacting time-series.",時系列予測は、多くの場合、科学的および工学的問題の基本であり、意思決定を可能にします。データセットのサイズが増え続ける中で、予測をスケールアップするための簡単な解決策は、相互作用する時系列間の独立性を想定することです。ただし、統計的依存関係をモデル化すると、精度が向上し、交互作用効果の分析が可能になります。深層学習法はこの問題に適していますが、多変量モデルは単純なパラメトリック分布を想定していることが多く、高次元にスケーリングしません。この作業では、自己回帰深層学習モデルを介して時系列の多変量時間ダイナミクスをモデル化します。このモデルでは、データ分布が条件付き正規化フローによって表されます。この組み合わせは、将来の外挿における優れたパフォーマンスなどの自己回帰モデルの能力を保持し、計算上扱いやすいまま、汎用の高次元分布モデルとしてのフローの柔軟性を備えています。数千の相互作用する時系列を持つ多くの実世界のデータセットの標準メトリックの最先端よりも優れていることを示します。,7.25,https://d3i71xaburhd42.cloudfront.net/be2a43bfd092781058e2a1597335061d3dc5d5ce/4-Figure1-1.png
Support-set bottlenecks for video-text representation learning,"['Mandela Patrick', 'Po-Yao Huang', 'Yuki Asano', 'Florian Metze', 'Alexander G Hauptmann', 'Joao F. Henriques', 'Andrea Vedaldi']",https://openreview.net/forum?id=EqoXe2zmhrh,"The dominant paradigm for learning video-text representations – noise contrastive learning – increases the similarity of the representations of pairs of samples that are known to be related, such as text and video from the same sample, and pushes away the representations of all other pairs. We posit that this last behaviour is too strict, enforcing dissimilar representations even for samples that are semantically-related – for example, visually similar videos or ones that share the same depicted action. In this paper, we propose a novel method that alleviates this by leveraging a generative model to naturally push these related samples together: each sample’s caption must be reconstructed as a weighted combination of a support set of visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples, unlike noise contrastive learning. Our proposed method outperforms others by a large margin on MSR-VTT, VATEX, ActivityNet, and MSVD for video-to-text and text-to-video retrieval.",ビデオテキスト表現を学習するための主要なパラダイムノイズ対照学習は、同じサンプルからのテキストとビデオなど、関連することがわかっているサンプルのペアの表現の類似性を高め、他のすべてのペアの表現を押しのけます。この最後の動作は厳密すぎて、たとえば視覚的に類似したビデオや同じ描写されたアクションを共有するビデオなど、意味的に関連するサンプルに対しても異なる表現を強制すると考えます。この論文では、生成モデルを活用してこれらの関連サンプルを自然にプッシュすることにより、これを軽減する新しい方法を提案します。各サンプルのキャプションは、視覚的表現のサポートセットの重み付けされた組み合わせとして再構築する必要があります。この単純なアイデアにより、表現が個々のサンプルに過度に特化されておらず、データセット全体で再利用可能であり、ノイズ対照学習とは異なり、サンプル間で共有されるセマンティクスを明示的にエンコードする表現が得られます。私たちが提案する方法は、ビデオからテキストへの検索およびテキストからビデオへの検索において、MSR-VTT、VATEX、ActivityNet、およびMSVDで他の方法よりも大幅に優れています。,7.25,https://d3i71xaburhd42.cloudfront.net/78bc767ebd02c0cc690fdb334c37bf64cfaf0115/2-Figure1-1.png
Mind the Pad -- CNNs Can Develop Blind Spots,"['Bilal Alsallakh', 'Narine Kokhlikyan', 'Vivek Miglani', 'Jun Yuan', 'Orion Reblitz-Richardson']",https://openreview.net/forum?id=m1CD7tPubNy,"We show how feature maps in convolutional networks are susceptible to spatial bias. Due to a combination of architectural choices, the activation at certain locations is systematically elevated or weakened. The major source of this bias is the padding mechanism. Depending on several aspects of convolution arithmetic, this mechanism can apply the padding unevenly, leading to asymmetries in the learned weights. We demonstrate how such bias can be detrimental to certain tasks such as small object detection: the activation is suppressed if the stimulus lies in the impacted area, leading to blind spots and misdetection. We explore alternative padding methods and propose solutions for analyzing and mitigating spatial bias.
",畳み込みネットワークの特徴マップが空間バイアスの影響を受けやすいことを示します。アーキテクチャの選択の組み合わせにより、特定の場所でのアクティベーションは体系的に上昇または弱まります。このバイアスの主な原因は、パディングメカニズムです。畳み込み演算のいくつかの側面に応じて、このメカニズムはパディングを不均一に適用し、学習された重みに非対称性をもたらす可能性があります。このようなバイアスが、小さなオブジェクトの検出などの特定のタスクにどのように悪影響を与える可能性があるかを示します。刺激が影響を受けた領域にある場合、アクティブ化が抑制され、死角や誤検出につながります。代替のパディング方法を検討し、空間バイアスを分析および軽減するためのソリューションを提案します。,7.25,
Decoupling Global and Local Representations via Invertible Generative Flows,"['Xuezhe Ma', 'Xiang Kong', 'Shanghang Zhang', 'Eduard H Hovy']",https://openreview.net/forum?id=iWLByfvUhN,"In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.
Specifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.
Experimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.
Importantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based  objective is capable of learning decoupled representations, requiring no explicit supervision.",この作業では、VAEフレームワークに生成フローを埋め込んでデコーダーをモデル化することにより、完全に教師なしの設定で画像のグローバル表現とローカル表現を自動的に分離できる新しい生成モデルを提案します。具体的には、提案されたモデルは、変分自動エンコードフレームワークを利用して、潜在変数の（低次元）ベクトルを学習し、アーキテクチャを借用したフローベースの可逆デコーダーへの条件付き入力として供給される画像のグローバル情報をキャプチャします。スタイル転送の文献から。標準画像ベンチマークの実験結果は、密度推定、画像生成、教師なし表現学習の観点から、モデルの有効性を示しています。重要なことに、この作業は、アーキテクチャの誘導バイアスのみで、尤度ベースの目的を持つ生成モデルが分離された表現を学習でき、明示的な監視を必要としないことを示しています。,7.0,
DINO: A Conditional Energy-Based GAN for Domain Translation,"['Konstantinos Vougioukas', 'Stavros Petridis', 'Maja Pantic']",https://openreview.net/forum?id=WAISmwsqDsb,"Domain translation is the process of transforming data from one domain to another while preserving the common semantics. Some of the most popular domain translation systems are based on conditional generative adversarial networks, which use source domain data to drive the generator and as an input to the discriminator. However, this approach does not enforce the preservation of shared semantics since the conditional input can often be ignored by the discriminator. We propose an alternative method for conditioning and present a new framework, where two networks are simultaneously trained, in a supervised manner, to perform domain translation in opposite directions. Our method is not only better at capturing the shared information between two domains but is more generic and can be applied to a broader range of problems. The proposed framework performs well even in challenging cross-modal translations, such as video-driven speech reconstruction, for which other systems struggle to maintain correspondence.",ドメイン変換は、一般的なセマンティクスを維持しながら、あるドメインから別のドメインにデータを変換するプロセスです。最も人気のあるドメイン変換システムのいくつかは、条件付き生成的敵対的ネットワークに基づいており、ソースドメインデータを使用してジェネレーターを駆動し、ディスクリミネーターへの入力として使用します。ただし、条件付き入力はディスクリミネーターによって無視されることが多いため、このアプローチでは共有セマンティクスの保持は強制されません。条件付けの代替方法を提案し、2つのネットワークを監視ありの方法で同時にトレーニングして、反対方向にドメイン変換を実行する新しいフレームワークを提示します。私たちの方法は、2つのドメイン間で共有される情報をキャプチャするのに優れているだけでなく、より一般的であり、より幅広い問題に適用できます。提案されたフレームワークは、他のシステムが対応を維持するのに苦労しているビデオ駆動型音声再構成などの挑戦的なクロスモーダル翻訳でもうまく機能します。,7.0,
Fast Geometric Projections for Local Robustness Certification,"['Aymeric Fromherz', 'Klas Leino', 'Matt Fredrikson', 'Bryan Parno', 'Corina Pasareanu']",https://openreview.net/forum?id=zWy1uxjDdZJ,"Local robustness ensures that a model classifies all inputs within an $\ell_p$-ball consistently, which precludes various forms of adversarial inputs.
In this paper, we present a fast procedure for checking local robustness in feed-forward neural networks with piecewise-linear activation functions.
Such networks partition the input space into a set of convex polyhedral regions in which the network’s behavior is linear; 
hence, a systematic search for decision boundaries within the regions around a given input is sufficient for assessing robustness.
Crucially, we show how the regions around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly-parallel GPU implementation that excels particularly for the $\ell_2$ norm, where previous work has been less effective.
Empirically we find this approach to be far more precise than many approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers, and scaling to much deeper networks.",ローカルロバスト性により、モデルはl（p）ボール内のすべての入力を一貫して分類し、さまざまな形式の敵対的な入力を排除します。この論文では、区分的線形活性化関数を使用してフィードフォワードニューラルネットワークの局所的なロバスト性をチェックするための高速な手順を示します。このようなネットワークは、入力空間を、ネットワークの動作が線形である凸多面体領域のセットに分割します。したがって、ロバスト性を評価するには、特定の入力の周囲の領域内の決定境界を体系的に検索するだけで十分です。重要なのは、単純な幾何学的投影を使用してポイント周辺の領域を分析する方法を示し、以前の作業があまり効果的でなかったl2ノルムに特に優れた効率的で高度に並列なGPU実装を認めることです。経験的に、このアプローチは多くの近似検証アプローチよりもはるかに正確であると同時に、完全な検証者よりも数桁速く実行し、はるかに深いネットワークにスケーリングすることがわかります。,7.0,
Self-Supervised Policy Adaptation during Deployment,"['Nicklas Hansen', 'Rishabh Jangir', 'Yu Sun', 'Guillem Alenyà', 'Pieter Abbeel', 'Alexei A Efros', 'Lerrel Pinto', 'Xiaolong Wang']",https://openreview.net/forum?id=o_V-MjyyGV_,"In most real world scenarios, a policy trained by reinforcement learning in one environment needs to be deployed in another, potentially quite different environment. However, generalization across different environments is known to be hard. A natural solution would be to keep training after deployment in the new environment, but this cannot be done if the new environment offers no reward signal. Our work explores the use of self-supervision to allow the policy to continue training after deployment without using any rewards. While previous methods explicitly anticipate changes in the new environment, we assume no prior knowledge of those changes yet still obtain significant improvements. Empirical evaluations are performed on diverse simulation environments from DeepMind Control suite and ViZDoom, as well as real robotic manipulation tasks in  continuously changing environments, taking observations from an uncalibrated camera. Our method improves generalization in 28 out of 32 environments across various tasks and outperforms domain randomization on a majority of environments. Videos are available at https://iclr2021submission.github.io/ICLR2021_Anonymized_PAD/.",ほとんどの現実世界のシナリオでは、ある環境で強化学習によってトレーニングされたポリシーを、別の、場合によってはまったく異なる環境に展開する必要があります。ただし、さまざまな環境にまたがる一般化は難しいことが知られています。自然な解決策は、新しい環境に展開した後もトレーニングを継続することですが、新しい環境が報酬シグナルを提供しない場合、これを行うことはできません。私たちの仕事は、自己監視の使用を調査して、ポリシーが報酬を使用せずに展開後もトレーニングを継続できるようにします。以前の方法では、新しい環境の変更を明示的に予測していますが、それらの変更に関する事前の知識はまだなく、大幅な改善が得られていると想定しています。経験的評価は、DeepMind ControlスイートやViZDoomのさまざまなシミュレーション環境、および継続的に変化する環境での実際のロボット操作タスクで実行され、キャリブレーションされていないカメラから観察されます。私たちの方法は、さまざまなタスクにわたって32環境のうち28環境で一般化を改善し、大部分の環境でドメインランダム化よりも優れています。ビデオはhttps://iclr2021submission.github.io/ICLR2021_Anonymized_PAD/で入手できます。,7.0,https://d3i71xaburhd42.cloudfront.net/798786f2d7f31b5361d700d3891a72e1096e5c8e/3-Figure1-1.png
My Body is a Cage: the Role of Morphology in Graph-Based Incompatible Control,"['Vitaly Kurin', 'Maximilian Igl', 'Tim Rocktäschel', 'Wendelin Boehmer', 'Shimon Whiteson']",https://openreview.net/forum?id=N3zUDGN5lO,"Multitask Reinforcement Learning is a promising way to obtain models with better performance, generalisation, data efficiency, and robustness. Most existing work is limited to compatible settings, where the state and action space dimensions are the same across tasks. Graph Neural Networks (GNN) are one way to address incompatible environments, because they can process graphs of arbitrary size. They also allow practitioners to inject biases encoded in the structure of the input graph. Existing work in graph-based continuous control uses the physical morphology of the agent to construct the input graph, i.e., encoding limb features as node labels and using edges to connect the nodes if their corresponded limbs are physically connected.
In this work, we present a series of ablations on existing methods that show that morphological information encoded in the graph does not improve their performance. Motivated by the hypothesis that any benefits GNNs extract from the graph structure are outweighed by difficulties they create for message passing, we also propose Amorpheus, a transformer-based approach. Further results show that, while Amorpheus ignores the morphological information that GNNs encode, it nonetheless substantially outperforms GNN-based methods.",マルチタスク強化学習は、パフォーマンス、一般化、データ効率、および堅牢性が向上したモデルを取得するための有望な方法です。ほとんどの既存の作業は互換性のある設定に制限されており、状態とアクションスペースの次元はタスク間で同じです。グラフニューラルネットワーク（GNN）は、任意のサイズのグラフを処理できるため、互換性のない環境に対処する1つの方法です。それらはまた、開業医が入力グラフの構造にエンコードされたバイアスを注入することを可能にします。グラフベースの連続制御の既存の作業では、エージェントの物理的形態を使用して入力グラフを作成します。つまり、手足の特徴をノードラベルとしてエンコードし、対応する手足が物理的に接続されている場合はエッジを使用してノードを接続します。この作業では、グラフにエンコードされた形態学的情報がそれらのパフォーマンスを改善しないことを示す既存の方法に関する一連のアブレーションを提示します。 GNNがグラフ構造から抽出する利点は、メッセージパッシングで生じる困難よりも重要であるという仮説に動機付けられて、トランスフォーマーベースのアプローチであるAmorpheusも提案します。さらなる結果は、AmorpheusがGNNがエンコードする形態学的情報を無視する一方で、それにもかかわらず、GNNベースの方法を大幅に上回っていることを示しています。,7.0,https://d3i71xaburhd42.cloudfront.net/85cb1d20ae5ba3f547dc76d2cc73677652900d9b/5-Figure1-1.png
Denoising Diffusion Implicit Models,"['Jiaming Song', 'Chenlin Meng', 'Stefano Ermon']",https://openreview.net/forum?id=St1giarCHLP,"Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps in order to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a particular Markovian diffusion process. We generalize DDPMs via a class of non-Markovian diffusion processes that lead to the same training objective. These non-Markovian processes can correspond to generative processes that are deterministic, giving rise to implicit models that produce high quality samples much faster. We empirically demonstrate that DDIMs can produce high quality samples $10 \times$ to $50 \times$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, perform semantically meaningful image interpolation directly in the latent space, and reconstruct observations with very low error. ",ノイズ除去拡散確率モデル（DDPM）は、敵対的なトレーニングなしで高品質の画像生成を実現しましたが、サンプルを生成するには、多くのステップでマルコフ連鎖をシミュレートする必要があります。サンプリングを加速するために、DDPMと同じトレーニング手順を使用した、より効率的な反復陰的確率モデルのクラスであるノイズ除去拡散陰的モデル（DDIM）を紹介します。 DDPMでは、生成プロセスは特定のマルコフ拡散プロセスの逆として定義されます。同じトレーニング目標につながる非マルコフ拡散プロセスのクラスを介してDDPMを一般化します。これらの非マルコフ過程は、決定論的である生成過程に対応することができ、高品質のサンプルをはるかに速く生成する暗黙のモデルを生み出します。 DDIMは、DDPMと比較して実時間で高品質のサンプルを10〜50速く生成でき、計算とサンプル品質のトレードオフを可能にし、潜在空間で直接意味的に意味のある画像補間を実行し、観測を再構築できることを経験的に示しています。非常に低いエラー。,7.0,https://d3i71xaburhd42.cloudfront.net/f335983826b0209f15421ce65f4adffd4be672f7/2-Figure1-1.png
Bayesian Few-Shot Classification with One-vs-Each PГіlya-Gamma Augmented Gaussian Processes,"['Jake Snell', 'Richard Zemel']",https://openreview.net/forum?id=lgNx56yZh8a,"Few-shot classification (FSC), the task of adapting a classifier to unseen classes given a small labeled dataset, is an important step on the path toward human-like machine learning. Bayesian methods are well-suited to tackling the fundamental issue of overfitting in the few-shot scenario because they allow practitioners to specify prior beliefs and update those beliefs in light of observed data. Contemporary approaches to Bayesian few-shot classification maintain a posterior distribution over model parameters, which is slow and requires storage that scales with model size. Instead, we propose a Gaussian process classifier based on a novel combination of Pólya-gamma augmentation and the one-vs-each softmax approximation that allows us to efficiently marginalize over functions rather than model parameters. We demonstrate improved accuracy and uncertainty quantification on both standard few-shot classification benchmarks and few-shot domain transfer tasks.",小さなラベル付きデータセットが与えられた場合に分類子を見えないクラスに適応させるタスクである少数ショット分類（FSC）は、人間のような機械学習への道の重要なステップです。ベイジアン法は、開業医が以前の信念を指定し、観察されたデータに照らしてそれらの信念を更新できるため、数ショットのシナリオでの過剰適合の基本的な問題に取り組むのに適しています。ベイズの数ショット分類への現代的なアプローチは、モデルパラメータ全体の事後分布を維持します。これは遅く、モデルサイズに比例するストレージを必要とします。代わりに、Polya-gamma拡張と1対各softmax近似の新しい組み合わせに基づくガウス過程分類器を提案します。これにより、モデルパラメーターではなく関数を効率的にマージナル化できます。標準の数ショット分類ベンチマークと数ショットドメイン転送タスクの両方で、精度と不確実性の定量化が向上していることを示します。,7.0,https://d3i71xaburhd42.cloudfront.net/2aeada5a75c3e5a6eb2e1589d6cd5da06215af8b/7-Figure1-1.png
Learning to Recombine and Resample Data For Compositional Generalization,"['Ekin Akyürek', 'Afra Feyza Akyürek', 'Jacob Andreas']",https://openreview.net/forum?id=PS3IMnScugk,"Flexible neural models outperform grammar- and automaton-based counterparts on a variety of sequence modeling tasks. However, neural models perform poorly in settings requiring compositional generalization beyond the training data---particularly to rare or unseen subsequences. Past work has found symbolic scaffolding (e.g. grammars or automata) essential in these settings. Here we present a family of learned data augmentation schemes that support a large category of compositional generalizations without appeal to latent symbolic structure. Our approach to data augmentation has two components: recombination of original training examples via a prototype-based generative model and resampling of generated examples to encourage extrapolation. Training an ordinary neural sequence model on a dataset augmented with recombined and resampled examples significantly improves generalization in two language processing problems---instruction following (SCAN) and morphological analysis (Sigmorphon 2018)---where our approach enables learning of new constructions and tenses from as few as eight initial examples.",柔軟なニューラルモデルは、さまざまなシーケンスモデリングタスクで、文法ベースおよびオートマトンベースのモデルよりも優れています。ただし、ニューラルモデルは、トレーニングデータを超えて、特にまれなサブシーケンスや目に見えないサブシーケンスに対して、構成の一般化を必要とする設定ではパフォーマンスが低下します。過去の研究では、これらの設定に象徴的な足場（文法やオートマトンなど）が不可欠であることがわかりました。ここでは、潜在的なシンボリック構造にアピールすることなく、構成の一般化の大規模なカテゴリをサポートする学習データ拡張スキームのファミリーを紹介します。データ拡張へのアプローチには、プロトタイプベースの生成モデルを介した元のトレーニング例の再結合と、外挿を促進するための生成された例のリサンプリングの2つのコンポーネントがあります。再結合および再サンプリングされた例で拡張されたデータセットで通常の神経シーケンスモデルをトレーニングすると、2つの言語処理問題の一般化が大幅に改善されます（SCAN）および形態素解析（Sigmorphon 2018）では、このアプローチにより、わずか8つの初期から新しい構造と緊張を学習できます例。,7.0,https://d3i71xaburhd42.cloudfront.net/ff144cd8f7c7ea3977583942ff3ad8260b07787c/4-Figure2-1.png
CaPC Learning: Confidential and Private Collaborative Learning,"['Christopher A. Choquette-Choo', 'Natalie Dullerud', 'Adam Dziedzic', 'Yunxiang Zhang', 'Somesh Jha', 'Nicolas Papernot', 'Xiao Wang']",https://openreview.net/forum?id=h2EbJ4_wMVq,"Machine learning benefits from large training datasets, which may not always be possible to collect by any single entity, especially when using privacy-sensitive data. In many contexts, such as healthcare and finance, separate parties may wish to collaborate and learn from each other's data but are prevented from doing so due to privacy regulations. Some regulations prevent explicit sharing of data between parties by joining datasets in a central location (confidentiality). Others also limit implicit sharing of data, e.g., through model predictions (privacy). There is currently no method that enables machine learning in such a setting, where both confidentiality and privacy need to be preserved, to prevent both explicit and implicit sharing of data. Federated learning only provides confidentiality, not privacy, since gradients shared still contain private information. Differentially private learning assumes unreasonably large datasets. Furthermore, both of these learning paradigms produce a central model whose architecture was previously agreed upon by all parties rather than enabling collaborative learning where each party learns and improves their own local model. We introduce Confidential and Private Collaborative (CaPC) learning, the first method provably achieving both confidentiality and privacy in a collaborative setting. We leverage secure multi-party computation (MPC), homomorphic encryption (HE), and other techniques in combination with privately aggregated teacher models. We demonstrate how CaPC allows participants to collaborate without having to explicitly join their training sets or train a central model. Each party is able to improve the accuracy and fairness of their model, even in settings where each party has a model that performs well on their own dataset or when datasets are not IID and model architectures are heterogeneous across parties. ",機械学習は、特にプライバシーに配慮したデータを使用する場合に、単一のエンティティで常に収集できるとは限らない大規模なトレーニングデータセットの恩恵を受けます。ヘルスケアや金融などの多くの状況では、別々の当事者が協力してお互いのデータから学びたいと思うかもしれませんが、プライバシー規制のためにそうすることはできません。一部の規制では、中央の場所でデータセットを結合することにより、当事者間でデータを明示的に共有することを禁止しています（機密性）。また、モデル予測（プライ​​バシー）などを通じて、データの暗黙的な共有を制限するものもあります。現在、データの明示的および暗黙的な共有の両方を防ぐために、機密性とプライバシーの両方を保持する必要があるこのような設定で機械学習を可能にする方法はありません。共有されるグラデーションにはまだ個人情報が含まれているため、統合学習はプライバシーではなく機密性のみを提供します。差分プライベート学習は、不当に大きなデータセットを想定しています。さらに、これらの学習パラダイムは両方とも、各当事者が独自のローカルモデルを学習および改善する共同学習を可能にするのではなく、アーキテクチャが以前にすべての当事者によって合意された中央モデルを生成します。機密およびプライベートコラボレーティブ（CaPC）学習を紹介します。これは、コラボレーティブ環境で機密性とプライバシーの両方を確実に達成する最初の方法です。安全なマルチパーティ計算（MPC）、準同型暗号化（HE）、およびその他の手法を、個人的に集約された教師モデルと組み合わせて活用します。 CaPCを使用すると、参加者がトレーニングセットに明示的に参加したり、中央モデルをトレーニングしたりすることなく、どのようにコラボレーションできるかを示します。各パーティは、各パーティが独自のデータセットで適切に機能するモデルを持っている場合や、データセットがIIDでなく、モデルアーキテクチャがパーティ間で異質である場合でも、モデルの精度と公平性を向上させることができます。,7.0,
On Self-Supervised Image Representations for GAN Evaluation,"['Stanislav Morozov', 'Andrey Voynov', 'Artem Babenko']",https://openreview.net/forum?id=NeRdBeTionN,"The embeddings from CNNs pretrained on Imagenet classification are de-facto standard image representations for assessing GANs via FID, Precision and Recall measures. Despite broad previous criticism of their usage for non-Imagenet domains, these embeddings are still the top choice in most of the GAN literature.

In this paper, we advocate the usage of the state-of-the-art self-supervised representations to evaluate GANs on the established non-Imagenet benchmarks. These representations, typically obtained via contrastive learning, are shown to provide better transfer to new tasks and domains, therefore, can serve as more universal embeddings of natural images. With extensive comparison of the recent GANs on the common datasets, we show that self-supervised representations produce a more reasonable ranking of models in terms of FID/Precision/Recall, while the ranking with classification-pretrained embeddings often can be misleading.",Imagenet分類で事前トレーニングされたCNNからの埋め込みは、FID、適合率、再現率の測定によってGANを評価するための事実上の標準画像表現です。 Imagenet以外のドメインでの使用についての以前の幅広い批判にもかかわらず、これらの埋め込みは、ほとんどのGAN文献で依然として最上位の選択肢です。このホワイトペーパーでは、確立された非ImagenetベンチマークでGANを評価するために、最先端の自己監視表現を使用することを推奨します。これらの表現は、通常、対照的な学習によって取得され、新しいタスクやドメインへのより良い転送を提供することが示されているため、自然画像のより普遍的な埋め込みとして機能します。共通データセットの最近のGANを広範囲に比較すると、自己教師あり表現がFID /適合率/再現率の観点からモデルのより合理的なランキングを生成する一方で、分類が事前にトレーニングされた埋め込みを使用したランキングは誤解を招く可能性があることがわかります。,7.0,
CPT: Efficient Deep Neural Network Training via Cyclic Precision,"['Yonggan Fu', 'Han Guo', 'Meng Li', 'Xin Yang', 'Yining Ding', 'Vikas Chandra', 'Yingyan Lin']",https://openreview.net/forum?id=87ZwsaQNHPZ,"Low-precision deep neural network (DNN) training has gained tremendous attention as reducing precision is one of the most effective knobs for boosting DNNs' training time/energy efficiency. In this paper, we attempt to explore low-precision training from a new perspective as inspired by recent findings in understanding DNN training: we conjecture that DNNs' precision might have a similar effect as the learning rate during DNN training, and advocate dynamic precision along the training trajectory for further boosting the time/energy efficiency of DNN training. Specifically, we propose Cyclic Precision Training (CPT) to cyclically vary the precision between two boundary values which can be identified using a simple precision range test within the first few training epochs. Extensive simulations and ablation studies on five datasets and ten models demonstrate that CPT's effectiveness is consistent across various models/tasks (including classification and language modeling). Furthermore, through experiments and visualization we show that CPT helps to (1) converge to a wider minima with a lower generalization error and (2) reduce training variance which we believe opens up a new design knob for simultaneously improving the optimization and efficiency of DNN training.",低精度のディープニューラルネットワーク（DNN）トレーニングは、精度の低下がDNNのトレーニング時間/エネルギー効率を高めるための最も効果的なノブの1つであるため、大きな注目を集めています。この論文では、DNNトレーニングを理解する上での最近の発見に触発された新しい視点から低精度トレーニングを探求しようとしています。DNNの精度はDNNトレーニング中の学習率と同様の効果があると推測し、動的精度を提唱します。 DNNトレーニングの時間/エネルギー効率をさらに高めるためのトレーニング軌道。具体的には、最初の数回のトレーニングエポック内で単純な精度範囲テストを使用して識別できる2つの境界値の間で精度を周期的に変化させるCyclic Precision Training（CPT）を提案します。 5つのデータセットと10のモデルに関する広範なシミュレーションとアブレーション研究は、CPTの有効性がさまざまなモデル/タスク（分類と言語モデリングを含む）にわたって一貫していることを示しています。さらに、実験と視覚化を通じて、CPTが（1）汎化誤差の少ないより広い最小値に収束し、（2）DNNの最適化と効率を同時に改善するための新しい設計ノブを開くと信じるトレーニング分散を減らすのに役立つことを示しますトレーニング。,7.0,https://d3i71xaburhd42.cloudfront.net/06e1766db61d3546616fb633a33adeacd38af471/3-Figure1-1.png
Proximal Gradient Descent-Ascent: Variable Convergence under KЕЃ Geometry,"['Ziyi Chen', 'Yi Zhou', 'Tengyu Xu', 'Yingbin Liang']",https://openreview.net/forum?id=LVotkZmYyDi,"The gradient descent-ascent (GDA) algorithm has been widely applied to solve minimax optimization problems. In order to achieve convergent policy parameters for minimax optimization, it is important that GDA generates convergent variable sequences rather than convergent sequences of function value or gradient norm. However, the variable convergence of GDA has been proved only under convexity geometries, and it is lack of understanding in general nonconvex minimax optimization. This paper fills such a gap by studying the convergence of a more general proximal-GDA for regularized nonconvex-strongly-concave minimax optimization. Specifically, we show that proximal-GDA admits a novel Lyapunov function, which monotonically decreases in the minimax optimization process and drives the variable sequences to a critical point. By leveraging this Lyapunov function and the KL geometry that parameterizes the local geometries of general nonconvex functions, we formally establish the variable convergence of proximal-GDA to a certain critical point $x^*$, i.e., $x_t\to x^*, y_t\to y^*(x^*)$. Furthermore, over the full spectrum of the KL-parameterized geometry, we show that proximal-GDA achieves different types of convergence rates ranging from sublinear convergence up to finite-step convergence, depending on the geometry associated with the KL parameter. This is the first theoretical result on the variable convergence for nonconvex minimax optimization. ",最急降下法（GDA）アルゴリズムは、ミニマックス最適化問題を解決するために広く適用されています。ミニマックス最適化のための収束ポリシーパラメーターを達成するために、GDAが関数値または勾配ノルムの収束シーケンスではなく収束変数シーケンスを生成することが重要です。ただし、GDAの可変収束は凸形状でのみ証明されており、一般的な非凸ミニマックス最適化では理解が不足しています。この論文は、正則化された非凸-強く凹のミニマックス最適化のためのより一般的な近位GDAの収束を研究することによってそのようなギャップを埋めます。具体的には、近位GDAが、ミニマックス最適化プロセスで単調に減少し、可変シーケンスを臨界点に駆動する新しいリアプノフ関数を認めることを示します。このリアプノフ関数と一般的な非凸関数のローカルジオメトリをパラメータ化するKLジオメトリを活用することにより、近位GDAの特定の臨界点x ^（*）、つまりx（t）x ^（*への可変収束を正式に確立します。 ）、y（t）y ^（*）（x ^（*））。さらに、KLパラメータ化されたジオメトリの全スペクトルにわたって、近位GDAが、KLパラメータに関連付けられたジオメトリに応じて、劣線形収束から有限ステップ収束までのさまざまなタイプの収束率を達成することを示します。これは、非凸ミニマックス最適化の変数収束に関する最初の理論的結果です。,7.0,
Meta-learning Symmetries by Reparameterization,"['Allan Zhou', 'Tom Knowles', 'Chelsea Finn']",https://openreview.net/forum?id=-QxT4mJdijq,"Many successful deep learning architectures are equivariant to certain transformations in order to conserve parameters and improve generalization: most famously, convolution layers are equivariant to shifts of the input. This approach only works when practitioners know the symmetries of the task and can manually construct an architecture with the corresponding equivariances. Our goal is an approach for learning equivariances from data, without needing to design custom task-specific architectures. We present a method for learning and encoding equivariances into networks by learning corresponding parameter sharing patterns from data. Our method can provably represent equivariance-inducing parameter sharing for any finite group of symmetry transformations. Our experiments suggest that it can automatically learn to encode equivariances to common transformations used in image processing tasks.",多くの成功した深層学習アーキテクチャは、パラメータを保存し、一般化を改善するために、特定の変換と同変です。最も有名なのは、畳み込み層が入力のシフトに対して同変であるということです。このアプローチは、実践者がタスクの対称性を知っており、対応する等分散を使用してアーキテクチャを手動で構築できる場合にのみ機能します。私たちの目標は、カスタムのタスク固有のアーキテクチャを設計する必要なしに、データから等分散を学習するためのアプローチです。データから対応するパラメータ共有パターンを学習することにより、等分散を学習してネットワークにエンコードする方法を示します。私たちの方法は、対称変換の有限群の同変を誘発するパラメータ共有を証明することができます。私たちの実験は、画像処理タスクで使用される一般的な変換への等分散をエンコードすることを自動的に学習できることを示唆しています。,7.0,
A Critique of Self-Expressive Deep Subspace Clustering,"['Benjamin David Haeffele', 'Chong You', 'Rene Vidal']",https://openreview.net/forum?id=FOyuZ26emy,"Subspace clustering is an unsupervised clustering technique designed to cluster data that is supported on a union of linear subspaces, with each subspace defining a cluster with dimension lower than the ambient space. Many existing formulations for this problem are based on exploiting the self-expressive property of linear subspaces, where any point within a subspace can be represented as linear combination of other points within the subspace. To extend this approach to data supported on a union of non-linear manifolds, numerous studies have proposed learning an appropriate kernel embedding of the original data using a neural network, which is regularized by a self-expressive loss function on the data in the embedded space to encourage a union of linear subspaces prior on the data in the embedded space. Here we show that there are a number of potential flaws with this approach which have not been adequately addressed in prior work. In particular, we show the optimization problem is often ill-posed in multiple ways, which can lead to a degenerate embedding of the data, which need not correspond to a union of subspaces at all. We validate our theoretical results experimentally and additionally repeat prior experiments reported in the literature, where we conclude that a significant portion of the previously claimed performance benefits can be attributed to an ad-hoc post processing step rather than the clustering model.",部分空間クラスタリングは、線形部分空間の和集合でサポートされるデータをクラスター化するように設計された教師なしクラスタリング手法であり、各部分空間は、周囲空間よりも小さい次元のクラスターを定義します。この問題の既存の定式化の多くは、線形部分空間の自己表現特性を利用することに基づいています。この場合、部分空間内の任意の点は、部分空間内の他の点の線形結合として表すことができます。このアプローチを非線形多様体の結合でサポートされるデータに拡張するために、多くの研究が、ニューラルネットワークを使用して元のデータの適切なカーネル埋め込みを学習することを提案しました。ニューラルネットワークは、埋め込みデータの自己表現損失関数によって正規化されます。埋め込み空間のデータの前に線形部分空間の結合を促進するための空間。ここでは、このアプローチには、以前の作業では適切に対処されていない潜在的な欠陥がいくつかあることを示します。特に、最適化問題は複数の方法で不適切であることが多く、部分空間の和集合にまったく対応する必要のないデータの縮退埋め込みにつながる可能性があることを示します。理論結果を実験的に検証し、さらに文献で報告されている以前の実験を繰り返します。ここでは、以前に主張されたパフォーマンス上の利点のかなりの部分が、クラスタリングモデルではなくアドホックな後処理ステップに起因すると結論付けています。,7.0,
Neurally Augmented ALISTA,"['Freya Behrens', 'Jonathan Sauder', 'Peter Jung']",https://openreview.net/forum?id=q_S44KLQ_Aa," It is well-established that many iterative sparse reconstruction algorithms can be unrolled to yield a learnable neural network for improved empirical performance. A prime example is learned ISTA (LISTA) where weights, step sizes and thresholds are learned from training data. Recently, Analytic LISTA (ALISTA) has been introduced, combining the strong empirical performance of a fully learned approach like LISTA, while retaining theoretical guarantees of classical compressed sensing algorithms and significantly reducing the number of parameters to learn. However, these parameters are trained to work in expectation, often leading to suboptimal reconstruction of individual targets.  In this work we therefore introduce Neurally Augmented ALISTA, in which an LSTM network is used to compute step sizes and thresholds individually for each target vector during reconstruction. This adaptive approach is theoretically motivated by revisiting the recovery guarantees of ALISTA. We show that our approach further improves empirical performance in sparse reconstruction, in particular outperforming existing algorithms by an increasing margin as the compression ratio becomes more challenging.",多くの反復スパース再構成アルゴリズムを展開して、経験的パフォーマンスを向上させるための学習可能なニューラルネットワークを生成できることは十分に確立されています。代表的な例は、学習されたISTA（LISTA）です。ここでは、重み、ステップサイズ、およびしきい値がトレーニングデータから学習されます。最近、Analytic LISTA（ALISTA）が導入されました。これは、LISTAのような完全に学習されたアプローチの強力な経験的パフォーマンスを組み合わせながら、従来の圧縮センシングアルゴリズムの理論的保証を保持し、学習するパラメーターの数を大幅に削減します。ただし、これらのパラメーターは期待どおりに機能するようにトレーニングされているため、個々のターゲットの再構築が最適ではないことがよくあります。したがって、この作業では、LSTMネットワークを使用して再構成中に各ターゲットベクトルのステップサイズとしきい値を個別に計算する、ニューラル拡張ALISTAを紹介します。この適応アプローチは、理論的にはALISTAの回復保証を再検討することによって動機付けられています。私たちのアプローチは、スパース再構成の経験的パフォーマンスをさらに改善し、特に圧縮率がより困難になるにつれてマージンを増やすことで既存のアルゴリズムを上回っていることを示します。,7.0,
Dataset Inference: Ownership Resolution in Machine Learning,"['Pratyush Maini', 'Mohammad Yaghini', 'Nicolas Papernot']",https://openreview.net/forum?id=hvdKKV2yt7T,"With increasingly more data and computation involved in their training,  machine learning models constitute valuable intellectual property. This has spurred interest in model stealing attacks, which are made more practical by advances in learning with partial, little, or no supervision. Existing defenses focus on inserting unique watermarks in the model's decision surface, but this is insufficient: since the watermarks are not sampled from the training distribution, they are not always preserved during model stealing. In this paper, we make the key observation that knowledge contained in the stolen model's training set is what is common to all stolen copies. The adversary's goal, irrespective of the attack employed, is always to extract this knowledge or its by-products. This gives the original model's owner a strong advantage over the adversary: model owners have access to the original training data. We thus introduce $\textit{dataset inference}$, the process of identifying whether a suspected model copy has private knowledge from the original model's dataset, as a defense against model stealing. We develop an approach for dataset inference that combines statistical testing with the ability to estimate the distance of multiple data points to the decision boundary. Our experiments on CIFAR10 and CIFAR100 show that model owners can claim with confidence greater than 99% that their model (or dataset as a matter of fact) was stolen, despite only exposing 50 of the stolen model's training points. Dataset inference defends against state-of-the-art attacks, even when the adversary is adaptive. Unlike prior work, it also does not require retraining or overfitting the defended model.",トレーニングに含まれるデータと計算がますます増えているため、機械学習モデルは貴重な知的財産を構成しています。これにより、モデルを盗む攻撃への関心が高まりました。モデルを盗む攻撃は、部分的、ほとんど、またはまったく監視なしの学習の進歩によってより実用的になります。既存の防御策は、モデルの決定面に一意の透かしを挿入することに重点を置いていますが、これでは不十分です。透かしはトレーニング分布からサンプリングされないため、モデルの盗用中に常に保持されるとは限りません。このホワイトペーパーでは、盗まれたモデルのトレーニングセットに含まれる知識が、すべての盗まれたコピーに共通するものであるという重要な観察を行います。攻撃の採用に関係なく、敵の目標は常にこの知識またはその副産物を抽出することです。これにより、元のモデルの所有者は、敵に対して強力な利点が得られます。モデルの所有者は、元のトレーニングデータにアクセスできます。したがって、モデルの盗難に対する防御策として、疑わしいモデルのコピーが元のモデルのデータセットからの個人的な知識を持っているかどうかを識別するプロセスであるデータセットの推論を紹介します。統計的検定と、決定境界までの複数のデータポイントの距離を推定する機能を組み合わせたデータセット推論のアプローチを開発します。 CIFAR10とCIFAR100での実験では、モデルの所有者は99を超える自信を持って主張できることが示されています,7.0,
Retrieval-Augmented Generation for Code Summarization via Hybrid GNN,"['Shangqing Liu', 'Yu Chen', 'Xiaofei Xie', 'Jing Kai Siow', 'Yang Liu']",https://openreview.net/forum?id=zv-typ1gPxA,"Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of the both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.65, 1.76 and 1.24 in terms of BLEU-4, ROUGE-L and METEOR.",ソースコードの要約は、コードの機能をよりよく理解するために、構造化コードスニペットから自然言語の要約を生成することを目的としています。ただし、ソースコードが複雑であり、ソースコードと自然言語の要約の間の言語のギャップがあるため、自動コード要約は困難です。以前のほとんどのアプローチは、検索ベース（検索データベースから見た同様の例を利用できるが、一般化パフォーマンスは低い）または生成ベースの方法（一般化パフォーマンスは優れているが、同様の例を利用できない）のいずれかに依存しています。この論文は、両方の世界の利点を組み合わせるための新しい検索拡張メカニズムを提案します。さらに、ソースコードのグローバルグラフ構造情報のキャプチャに関するグラフニューラルネットワーク（GNN）の制限を緩和するために、ソースコードの静的グラフ表現を補完する新しい注意ベースの動的グラフを提案し、GNNを渡すハイブリッドメッセージを設計します。ローカルとグローバルの両方の構造情報をキャプチャします。提案されたアプローチを評価するために、多様化した大規模なオープンソースCプロジェクト（データセット内の合計95k以上の固有の関数）からクロールされた、新しい挑戦的なベンチマークをリリースします。私たちの方法は最先端の性能を達成し、BLEU-4、ROUGE-L、METEORに関して既存の方法を1.65、1.76、1.24改善します。,7.0,
In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness,"['Sang Michael Xie', 'Ananya Kumar', 'Robbie Jones', 'Fereshte Khani', 'Tengyu Ma', 'Percy Liang']",https://openreview.net/forum?id=jznizqvr15J,"Consider a prediction setting where a few inputs (e.g., satelite images) are expensively annotated with the prediction targets (e.g., crop types), and many inputs are cheaply annotated with auxiliary information (e.g., climate information). How should we best leverage this auxiliary information for the prediction task? Empirically across three image and time-series datasets, and theoretically in a multi-task linear regression setting,  we show that (i) using auxiliary information as input features improves in-distribution error but can hurt out-of-distribution (OOD) error; while (ii) using auxiliary information as outputs of auxiliary tasks to pre-train a model improves OOD error. To get the best of both worlds, we introduce In-N-Out, which first trains a model with auxiliary inputs and uses it to pseudolabel all the in-distribution inputs, then pre-trains a model on OOD auxiliary outputs and fine-tunes this model with the pseudolabels (self-training). We show both theoretically and empirically that In-N-Out outperforms auxiliary inputs or outputs alone on both in-distribution and OOD error.",いくつかの入力（衛星画像など）に予測ターゲット（作物の種類など）の注釈が高く、多くの入力に補助情報（気候情報など）の注釈が安価に付けられている予測設定について考えてみます。この補助情報を予測タスクにどのように活用すればよいでしょうか。経験的に3つの画像および時系列データセットにわたって、理論的にはマルチタスク線形回帰設定で、（i）入力特徴として補助情報を使用すると、分布内エラーが改善されますが、分布外（OOD）エラーが発生する可能性があることを示します。 ; （ii）補助タスクの出力として補助情報を使用してモデルを事前トレーニングすると、OODエラーが改善されます。両方の世界を最大限に活用するために、In-N-Outを導入します。これは、最初に補助入力を使用してモデルをトレーニングし、それを使用してすべての分布内入力に疑似ラベルを付け、次にOOD補助出力でモデルを事前トレーニングして微調整します。疑似ラベルを使用したこのモデル（自己トレーニング）。 In-N-Outは、分布内エラーとOODエラーの両方で、補助入力または出力のみよりも優れていることを理論的および経験的に示しています。,7.0,
Iterated learning for emergent systematicity in VQA,"['Ankit Vani', 'Max Schwarzer', 'Yuchen Lu', 'Eeshan Dhekane', 'Aaron Courville']",https://openreview.net/forum?id=Pd_oMxH8IlF,"Although neural module networks have an architectural bias towards compositionality, they require gold standard layouts to generalize systematically in practice. When instead learning layouts and modules jointly, compositionality does not arise automatically and an explicit pressure is necessary for the emergence of layouts exhibiting the right structure. We propose to address this problem using iterated learning, a cognitive science theory of the emergence of compositional languages in nature that has primarily been applied to simple referential games in machine learning. Considering the layouts of module networks as samples from an emergent language, we use iterated learning to encourage the development of structure within this language. We show that the resulting layouts support systematic generalization in neural agents solving the more complex task of visual question-answering. Our regularized iterated learning method can outperform baselines without iterated learning on SHAPES-SyGeT (SHAPES Systematic Generalization Test), a new split of the SHAPES dataset we introduce to evaluate systematic generalization, and on CLOSURE, an extension of CLEVR also designed to test systematic generalization. We demonstrate superior performance in recovering ground-truth compositional program structure with limited supervision on both SHAPES-SyGeT and CLEVR.",ニューラルモジュールネットワークには構成性に対するアーキテクチャ上のバイアスがありますが、実際には体系的に一般化するにはゴールドスタンダードのレイアウトが必要です。代わりに、レイアウトとモジュールを一緒に学習する場合、構成性は自動的に発生せず、適切な構造を示すレイアウトの出現には明示的な圧力が必要です。機械学習の単純な参照ゲームに主に適用されてきた、自然界の構成言語の出現に関する認知科学理論である反復学習を使用して、この問題に対処することを提案します。モジュールネットワークのレイアウトを創発的な言語からのサンプルと見なし、反復学習を使用して、この言語内の構造の開発を促進します。結果として得られるレイアウトが、視覚的な質問応答のより複雑なタスクを解決する神経エージェントの体系的な一般化をサポートすることを示します。正規化された反復学習方法は、体系的な一般化を評価するために導入したSHAPESデータセットの新しい分割であるSHAPES-SyGeT（SHAPES Systematic Generalization Test）と、体系的な一般化をテストするように設計されたCLEVRの拡張であるCLOSUREで、反復学習なしでベースラインを上回ることができます。 。 SHAPES-SyGeTとCLEVRの両方の監視を制限して、グラウンドトゥルース構成プログラム構造を回復する際の優れたパフォーマンスを示します。,7.0,
EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS,"['Like Hui', 'Mikhail Belkin']",https://openreview.net/forum?id=hsFN92eQEla,"Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. 
We explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.
Indeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.

We argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that
training using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ",分類タスクの最新のニューラルアーキテクチャは、クロスエントロピー損失を使用してトレーニングされます。クロスエントロピー損失は、二乗損失よりも経験的に優れていると広く信じられています。この作品では、この信念が十分に根拠がない可能性があることを示す証拠を提供します。いくつかの主要なニューラルアーキテクチャと、NLP、自動音声認識（ASR）、およびコンピュータビジョンタスクの一連の標準ベンチマークデータセットを調査して、これらのアーキテクチャが、文献で報告されているものと同じハイパーパラメータ設定で、次の場合に同等以上のパフォーマンスを発揮することを示します。計算リソースを均等化した後でも、二乗損失でトレーニングされています。実際、二乗損失は、NLPおよびASR実験の大部分でより良い結果をもたらすことがわかります。クロスエントロピーは、コンピュータービジョンタスクにわずかな優位性があるように見えます。クロスエントロピー損失に対する明確な利点を示す説得力のある経験的または理論的証拠はほとんどないと私たちは主張します。実際、私たちの実験では、ほとんどすべての非ビジョンタスクのパフォーマンスは、二乗損失に切り替えることで、場合によっては大幅に改善できます。さらに、二乗損失を伴うトレーニングは、初期化のランダム性にあまり敏感ではないようです。分類に二乗損失を使用するトレーニングは、クロスエントロピーと同等の立場での現代の深層学習のベストプラクティスの一部である必要があると考えています。,7.0,
Leaky Tiling Activations: A Simple Approach to Learning Sparse Representations Online,"['Yangchen Pan', 'Kirby Banman', 'Martha White']",https://openreview.net/forum?id=zElset1Klrp,"Recent work has shown that sparse representations---where only a small percentage of units are active---can significantly reduce interference. Those works, however, relied on relatively complex regularization or meta-learning approaches, that have only been used offline in a pre-training phase. We design an activation function that naturally produces sparse representations, and so is more amenable to online training. The idea relies on the simple approach of binning, but overcomes the two key limitations of binning: zero gradients for the flat regions almost everywhere,  and lost precision---reduced discrimination---due to coarse aggregation. We introduce a Leaky Tiling Activation (LTA) that provides non-negligible gradients and produces overlap between bins that improves discrimination. We first show that LTA is robust under covariate shift in a synthetic online supervised problem, where we can vary the level of correlation and drift. Then we move to deep reinforcement learning setting and investigate both value-based and policy gradient algorithms that use neural networks with LTAs, in classic discrete control and Mujoco continuous control environments. We show that algorithms equipped with LTAs are able to learn a stable policy faster without needing target networks on most domains. ",最近の研究によると、アクティブなユニットの割合が少ないスパース表現では、干渉を大幅に減らすことができます。ただし、これらの作業は、トレーニング前のフェーズでオフラインでのみ使用されている、比較的複雑な正則化またはメタ学習アプローチに依存していました。スパース表現を自然に生成する活性化関数を設計しているため、オンライントレーニングに適しています。このアイデアは、ビニングの単純なアプローチに依存していますが、ビニングの2つの重要な制限を克服しています。ほとんどすべての場所で平坦な領域の勾配がゼロであり、粗い集約のために識別が失われます。無視できない勾配を提供し、識別を改善するビン間のオーバーラップを生成するLeaky Tiling Activation（LTA）を紹介します。最初に、LTAが、相関とドリフトのレベルを変化させることができる合成オンライン監視問題の共変量シフトの下で堅牢であることを示します。次に、深層強化学習設定に移動し、従来の離散制御およびMujoco連続制御環境で、LTAを使用したニューラルネットワークを使用する値ベースのアルゴリズムとポリシー勾配アルゴリズムの両方を調査します。 LTAを備えたアルゴリズムは、ほとんどのドメインでターゲットネットワークを必要とせずに、安定したポリシーをより速く学習できることを示しています。,7.0,
Individually Fair Gradient Boosting,"['Alexander Vargo', 'Fan Zhang', 'Mikhail Yurochkin', 'Yuekai Sun']",https://openreview.net/forum?id=JBAa9we1AL,"We consider the task of enforcing individual fairness in gradient boosting. Gradient boosting is a popular method for machine learning from tabular data, which arise often in applications where algorithmic fairness is a concern. At a high level, our approach is a functional gradient descent on a (distributionally) robust loss function that encodes our intuition of algorithmic fairness for the ML task at hand. Unlike prior approaches to individual fairness that only work with smooth ML models, our approach also works with non-smooth models such as decision trees. We show that our algorithm converges globally and generalizes. We also demonstrate the efficacy of our algorithm on three ML problems susceptible to algorithmic bias.",勾配ブースティングで個人の公平性を強化するタスクを検討します。勾配ブースティングは、表形式のデータから機械学習を行うための一般的な方法です。これは、アルゴリズムの公平性が懸念されるアプリケーションでよく発生します。大まかに言えば、私たちのアプローチは、目前のMLタスクのアルゴリズムの公平性の直感をエンコードする（分布的に）ロバストな損失関数の関数勾配降下法です。滑らかなMLモデルでのみ機能する個々の公平性に対する以前のアプローチとは異なり、私たちのアプローチは、決定木などの滑らかでないモデルでも機能します。私たちのアルゴリズムがグローバルに収束し、一般化することを示します。また、アルゴリズムのバイアスの影響を受けやすい3つのML問題に対するアルゴリズムの有効性を示します。,7.0,
A Good Image Generator Is What You Need for High-Resolution Video Synthesis,"['Yu Tian', 'Jian Ren', 'Menglei Chai', 'Kyle Olszewski', 'Xi Peng', 'Dimitris N. Metaxas', 'Sergey Tulyakov']",https://openreview.net/forum?id=6puCSjH3hwA,"Image and video synthesis are closely related areas aiming at generating content from noise. While rapid progress has been demonstrated in improving image-based models to handle large resolutions, high-quality renderings, and wide variations in image content, achieving comparable video generation results remains problematic. We present a framework that leverages contemporary image generators to render high-resolution videos. We frame the video synthesis problem as discovering a trajectory in the latent space of a pre-trained and fixed image generator. Not only does such a framework render high-resolution videos, but it also is an order of magnitude more computationally efficient. We introduce a motion generator that discovers the desired trajectory, in which content and motion are disentangled. With such a representation, our framework allows for a broad range of applications, including content and motion manipulation. Furthermore, we introduce a new task, which we call cross-domain video synthesis, in which the image and motion generators are trained on disjoint datasets belonging to different domains. This allows for generating moving objects for which the desired video data is not available. Extensive experiments on various datasets demonstrate the advantages of our methods over existing video generation techniques.",画像とビデオの合成は、ノイズからコンテンツを生成することを目的とした密接に関連した領域です。大きな解像度、高品質のレンダリング、および画像コンテンツの幅広いバリエーションを処理するための画像ベースのモデルの改善において急速な進歩が実証されていますが、同等のビデオ生成結果を達成することには問題があります。最新の画像ジェネレーターを活用して高解像度のビデオをレンダリングするフレームワークを紹介します。ビデオ合成の問題を、事前にトレーニングされ固定された画像ジェネレータの潜在空間での軌跡を発見するものとして組み立てます。このようなフレームワークは、高解像度のビデオをレンダリングするだけでなく、計算効率も桁違いに高くなります。コンテンツとモーションが解きほぐされた、目的の軌道を発見するモーションジェネレーターを紹介します。このような表現により、私たちのフレームワークは、コンテンツやモーション操作を含む幅広いアプリケーションを可能にします。さらに、クロスドメインビデオ合成と呼ばれる新しいタスクを導入します。このタスクでは、画像ジェネレーターとモーションジェネレーターが、異なるドメインに属する互いに素なデータセットでトレーニングされます。これにより、目的のビデオデータが利用できない移動オブジェクトを生成できます。さまざまなデータセットでの広範な実験は、既存のビデオ生成技術に対する私たちの方法の利点を示しています。,7.0,
Isotropy in the Contextual Embedding Space: Clusters and Manifolds,"['Xingyu Cai', 'Jiaji Huang', 'Yuchen Bian', 'Kenneth Church']",https://openreview.net/forum?id=xYGNO86OWDH,"The geometric properties of contextual embedding spaces for deep language models such as BERT and ERNIE, have attracted considerable attention in recent years. Investigations on the contextual embeddings demonstrate a strong anisotropic space such that most of the vectors fall within a narrow cone, leading to high cosine similarities.  It is surprising that these LMs are as successful as they are, given that most of their embedding vectors are as similar to one another as they are. In this paper, we argue that the isotropy indeed exists in the space, from a different but more constructive perspective. We identify isolated clusters and low dimensional manifolds in the contextual embedding space, and introduce tools to both qualitatively and quantitatively analyze them. We hope the study in this paper could provide insights towards a better understanding of the deep language models.",BERTやERNIEなどの深い言語モデルのコンテキスト埋め込みスペースの幾何学的特性は、近年かなりの注目を集めています。文脈埋め込みに関する調査は、ほとんどのベクトルが狭い円錐内に収まるような強い異方性空間を示しており、高い余弦の類似性につながります。それらの埋め込みベクトルのほとんどが互いに類似していることを考えると、これらのLMが同じように成功していることは驚くべきことです。この論文では、異なるがより建設的な観点から、等方性が実際に空間に存在することを主張します。コンテキスト埋め込みスペースで孤立したクラスターと低次元多様体を識別し、それらを定性的および定量的に分析するためのツールを紹介します。この論文の研究が、深い言語モデルのより良い理解に向けた洞察を提供することを願っています。,7.0,
Async-RED: A Provably Convergent Asynchronous Block Parallel Stochastic Method using Deep Denoising Priors,"['Yu Sun', 'Jiaming Liu', 'Yiran Sun', 'Brendt Wohlberg', 'Ulugbek Kamilov']",https://openreview.net/forum?id=9EsrXMzlFQY,"Regularization by denoising (RED) is a recently developed framework for solving inverse problems by integrating advanced denoisers as image priors. Recent work has shown its state-of-the-art performance when combined with pre-trained deep denoisers. However, current RED algorithms are inadequate for parallel processing on multicore systems. We address this issue by proposing a new{asynchronous RED (Async-RED) algorithm that enables asynchronous parallel processing of data, making it significantly faster than its serial counterparts for large-scale inverse problems. The computational complexity of Async-RED is further reduced by using a random subset of measurements at every iteration. We present a complete theoretical analysis of the algorithm by establishing its convergence under explicit assumptions on the data-fidelity and the denoiser. We validate Async-RED on image recovery using pre-trained deep denoisers as priors.",ノイズ除去による正則化（RED）は、高度なノイズ除去装置を画像の事前分布として統合することにより、逆問題を解決するために最近開発されたフレームワークです。最近の研究では、事前にトレーニングされたディープデノイザーと組み合わせた場合の最先端のパフォーマンスが示されています。ただし、現在のREDアルゴリズムは、マルチコアシステムでの並列処理には不十分です。この問題に対処するために、データの非同期並列処理を可能にする新しい{asynchronous RED（Async-RED）アルゴリズムを提案し、大規模な逆問題のシリアル対応よりも大幅に高速化します。 Async-REDの計算の複雑さは、反復ごとに測定値のランダムなサブセットを使用することでさらに軽減されます。データ忠実度とデノイザーに関する明示的な仮定の下で収束を確立することにより、アルゴリズムの完全な理論的分析を提示します。事前にトレーニングされたディープデノイザーを使用して、画像回復でAsync-REDを検証します。,7.0,https://d3i71xaburhd42.cloudfront.net/13df91191a54e860d24a86fac76920e6a22505c3/2-Figure1-1.png
More or Less: When and How to Build Convolutional Neural Network Ensembles,"['Abdul Wasay', 'Stratos Idreos']",https://openreview.net/forum?id=z5Z023VBmDZ,"Convolutional neural network models are applied to many tasks with rising complexity and data sizes. Researchers and practitioners seek to scale the representational power of these models by adding more parameters. Increasing parameters, though, requires additional critical resources such as memory and compute time leading to increased training and inference cost. Thus a consistent challenge is to obtain as high as possible accuracy within a parameter budget. As neural network designers navigate this complex landscape, they are guided by conventional wisdom. This comes from empirical studies of the design space. We identify a critical part of this design space that is not well-understood: That is how to decide between the alternatives of expanding a single convolutional network model or increasing the number of networks and using them together in an ensemble. We study this question in detail through extensive experimentation across various network architectures and data sets. Crucially, we provide a robust assessment, missing in previous studies, by fixing the number of parameters. We also consider a holistic set of metrics such as training time, inference time, and memory usage. Contrary to conventional wisdom, we show that when we perform a holistic and robust assessment, we uncover a wide design space, where ensembles not only provide better accuracy but also train faster, and deploy at a speed comparable to single convolutional networks with the same total number of parameters.",畳み込みニューラルネットワークモデルは、複雑さとデータサイズが増大する多くのタスクに適用されます。研究者と実践者は、パラメータを追加することにより、これらのモデルの表現力を拡大しようとしています。ただし、パラメータを増やすと、メモリや計算時間などの追加の重要なリソースが必要になり、トレーニングと推論のコストが増加します。したがって、一貫した課題は、パラメータバジェット内で可能な限り高い精度を取得することです。ニューラルネットワークの設計者がこの複雑な状況をナビゲートするとき、彼らは一般通念に導かれます。これは、デザインスペースの経験的研究から来ています。よく理解されていないこの設計空間の重要な部分を特定します。それは、単一の畳み込みネットワークモデルを拡張するか、ネットワークの数を増やしてそれらをアンサンブルで一緒に使用するかの選択肢を決定する方法です。さまざまなネットワークアーキテクチャとデータセットにわたる広範な実験を通じて、この質問を詳細に調査します。重要なのは、パラメーターの数を固定することにより、以前の研究にはなかった堅牢な評価を提供することです。また、トレーニング時間、推論時間、メモリ使用量など、全体的な一連の指標についても検討します。従来の常識に反して、全体的で堅牢な評価を実行すると、アンサンブルがより高い精度を提供するだけでなく、より高速にトレーニングし、同じ合計で単一の畳み込みネットワークに匹敵する速度で展開する広い設計空間を発見することを示しますパラメータの数。,7.0,
SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness,"['Mikhail Yurochkin', 'Yuekai Sun']",https://openreview.net/forum?id=DktZb97_Fx,"In this paper, we cast fair machine learning as invariant machine learning. We first formulate a version of individual fairness that enforces invariance on certain sensitive sets. We then design a transport-based regularizer that enforces this version of individual fairness and develop an algorithm to minimize the regularizer efficiently. Our theoretical results guarantee the proposed approach trains certifiably fair ML models. Finally, in the experimental studies we demonstrate improved fairness metrics in comparison to several recent fair training procedures on three ML tasks that are susceptible to algorithmic bias.",この論文では、公正な機械学習を不変の機械学習としてキャストします。最初に、特定の機密セットに不変性を強制する個々の公平性のバージョンを作成します。次に、このバージョンの個々の公平性を強制するトランスポートベースの正則化を設計し、正則化を効率的に最小化するアルゴリズムを開発します。私たちの理論的結果は、提案されたアプローチが確実に公正なMLモデルをトレーニングすることを保証します。最後に、実験的研究では、アルゴリズムのバイアスの影響を受けやすい3つのMLタスクに関する最近のいくつかの公正なトレーニング手順と比較して、改善された公平性メトリックを示しています。,7.0,https://d3i71xaburhd42.cloudfront.net/2c0f18df2f23207f2139140ab45819b0b23879be/3-Figure1-1.png
Geometry-Aware Gradient Algorithms for Neural Architecture Search,"['Liam Li', 'Mikhail Khodak', 'Nina Balcan', 'Ameet Talwalkar']",https://openreview.net/forum?id=MuSYkd1hxRP,"Recent state-of-the-art methods for neural architecture search (NAS) exploit gradient-based optimization by relaxing the problem into continuous optimization over architectures and shared-weights, a noisy process that remains poorly understood. We argue for the study of single-level empirical risk minimization to understand NAS with weight-sharing, reducing the design of NAS methods to devising optimizers and regularizers that can quickly obtain high-quality solutions to this problem. Invoking the theory of mirror descent, we present a geometry-aware framework that exploits the underlying structure of this optimization to return sparse architectural parameters, leading to simple yet novel algorithms that enjoy fast convergence guarantees and achieve state-of-the-art accuracy on the latest NAS benchmarks in computer vision. Notably, we exceed the best published results for both CIFAR and ImageNet on both the DARTS search space and NAS-Bench-201; on the latter we achieve near-oracle-optimal performance on CIFAR-10 and CIFAR-100. Together, our theory and experiments demonstrate a principled way to co-design optimizers and continuous relaxations of discrete NAS search spaces.",ニューラルアーキテクチャ検索（NAS）の最近の最先端の方法は、問題を緩和してアーキテクチャと共有重みの継続的な最適化を行うことにより、勾配ベースの最適化を活用します。これは、まだ十分に理解されていないノイズの多いプロセスです。ウェイトシェアリングを使用してNASを理解するための単一レベルの経験的リスク最小化の研究について議論し、NASメソッドの設計を、この問題の高品質なソリューションを迅速に取得できるオプティマイザーとレギュラーライザーを考案することに減らします。ミラー降下の理論を呼び出して、この最適化の基礎となる構造を活用してスパースなアーキテクチャパラメータを返すジオメトリ対応フレームワークを提示し、高速な収束保証を享受し、最新の精度を実現するシンプルでありながら斬新なアルゴリズムを実現します。コンピュータビジョンにおける最新のNASベンチマーク。特に、DARTS検索スペースとNAS-Bench-201の両方で、CIFARとImageNetの両方で公開されている最良の結果を上回っています。後者では、CIFAR-10およびCIFAR-100でほぼオラクルに最適なパフォーマンスを実現します。一緒に、私たちの理論と実験は、離散NAS検索スペースのオプティマイザーと継続的な緩和を共同設計するための原理的な方法を示しています。,7.0,https://d3i71xaburhd42.cloudfront.net/e4324ec48332c4866b003f52fb4f1b4510291059/13-Figure1-1.png
How Benign is Benign Overfitting ?,"['Amartya Sanyal', 'Puneet K. Dokania', 'Varun Kanade', 'Philip Torr']",https://openreview.net/forum?id=g-wu9TMPODo,"We investigate two causes for adversarial vulnerability in deep neural networks: bad data and (poorly) trained models. When trained with SGD, deep neural networks essentially achieve zero training error, even in the presence of label noise, while also exhibiting good generalization on natural test data, something referred to as benign overfitting (Bartlett et al., 2020; Chatterji & Long, 2020).  However, these models are vulnerable to adversarial attacks. We identify label noise as one of the causes for adversarial vulnerability, and provide theoretical and empirical evidence in support of this. Surprisingly, we find several instances of label noise in datasets such as MNIST and CIFAR, and that robustly trained models incur training error on some of these, i.e. they don’t fit the noise. However, removing noisy labels alone does not suffice to achieve adversarial robustness. We conjecture that in part sub-optimal representation learning is also responsible for adversarial vulnerability. By means of simple theoretical setups, we show how the choice of representation can drastically affect adversarial robustness.",ディープニューラルネットワークにおける敵対的な脆弱性の2つの原因を調査します。悪いデータと（不十分な）トレーニング済みモデルです。 SGDでトレーニングすると、ディープニューラルネットワークは、ラベルノイズが存在する場合でも、基本的にトレーニングエラーをゼロにします。また、良性の過剰適合と呼ばれる自然なテストデータで優れた一般化を示します（Bartlett et al。、2020; Chatterji＆Long、 2020）。ただし、これらのモデルは敵対的攻撃に対して脆弱です。ラベルノイズを敵対的な脆弱性の原因の1つとして特定し、これを裏付ける理論的および経験的証拠を提供します。驚いたことに、MNISTやCIFARなどのデータセットでラベルノイズのインスタンスがいくつか見つかりました。堅牢にトレーニングされたモデルでは、これらの一部でトレーニングエラーが発生します。つまり、ノイズに適合しません。ただし、ノイズの多いラベルを削除するだけでは、敵対的な堅牢性を実現するのに十分ではありません。部分的には、次善の表現学習も敵対的な脆弱性の原因であると推測します。単純な理論的設定によって、表現の選択が敵のロバスト性にどのように劇的に影響するかを示します。,7.0,https://d3i71xaburhd42.cloudfront.net/dfb6250ae1c8f4d0ec3e28ed84596f77704485ab/2-Figure1-1.png
Molecule Optimization by Explainable Evolution,"['Binghong Chen', 'Tianzhe Wang', 'Chengtao Li', 'Hanjun Dai', 'Le Song']",https://openreview.net/forum?id=jHefDGsorp5,"Optimizing molecules for desired properties is a fundamental yet challenging task in chemistry, material science and drug discovery. In this paper, we develop a novel algorithm for optimizing molecule properties via an Expectation Maximization~(EM)-like explainable evolutionary process. Our algorithm is designed to mimic human experts in the process of searching for desirable molecules and alternate between two stages: the first stage on explainable local search which identifies rationales, \ie{}, critical subgraph patterns accounting for desired molecular properties, and the second stage on molecule completion which explores the larger space of molecules containing good rationales. We test our method against various baselines on a real-world multi-property optimization task where each method is given the same number of queries to the property oracle. We show that our evolution-by-explanation algorithm is 79\% better than the best baseline in terms of a generic metric combining aspects such as success rate, novelty and diversity. Human expert evaluation on optimized molecules shows that 60\% of top molecules obtained from our methods are deemed as successful ones. ",分子を目的の特性に合わせて最適化することは、化学、材料科学、創薬において基本的でありながら困難な作業です。この論文では、期待値最大化（EM）のような説明可能な進化過程を介して分子特性を最適化するための新しいアルゴリズムを開発します。私たちのアルゴリズムは、望ましい分子を検索するプロセスで人間の専門家を模倣し、2つの段階を交互に繰り返すように設計されています：理論的根拠を特定する説明可能なローカル検索の最初の段階、望ましい分子特性を説明する重要なサブグラフパターン、および分子の完成の2番目の段階これは、優れた理論的根拠を含む分子のより大きな空間を探索します。各メソッドにプロパティoracleに対して同じ数のクエリが与えられる、実際のマルチプロパティ最適化タスクで、さまざまなベースラインに対してメソッドをテストします。説明による進化アルゴリズムは、成功率、新規性、多様性などの側面を組み合わせた一般的な指標の観点から、最良のベースラインよりも79％優れていることを示しています。最適化された分子に関する人間の専門家の評価は、私たちの方法から得られた上位分子の60％が成功したものと見なされることを示しています。,7.0,
Information-theoretic Probing Explains Reliance on Spurious Features,"['Charles Lovering', 'Rohan Jha', 'Tal Linzen', 'Ellie Pavlick']",https://openreview.net/forum?id=mNtmhaDkAr,"Most current NLP systems are based on a pre-train-then-fine-tune paradigm, in which a large neural network is first trained in a self-supervised way designed to encourage the network to extract broadly-useful linguistic features, and then fine-tuned for a specific task of interest. Recent work attempts to understand why this recipe works and explain when it fails. Currently, such analyses have produced two sets of apparently-contradictory results. Work that analyzes the representations that result from pre-training (via ""probing classifiers"") finds evidence that rich features of linguistic structure can be decoded with high accuracy, but work that analyzes model behavior after fine-tuning (via ""challenge sets"") indicates that decisions are often not based on such structure but rather on spurious heuristics specific to the training set. In this work, we test the hypothesis that the extent to which a feature influences a model's decisions can be predicted using a combination of two factors: The feature's ""extractability"" after pre-training (measured using information-theoretic probing techniques), and the ""evidence"" available during fine-tuning (defined as the feature's co-occurrence rate with the label). In experiments with both synthetic and natural language data, we find strong evidence (statistically significant correlations) supporting this hypothesis.",現在のほとんどのNLPシステムは、事前トレーニング、次に微調整のパラダイムに基づいています。このパラダイムでは、大規模なニューラルネットワークが、ネットワークが広く有用な言語的特徴を抽出するように設計された自己監視方式で最初にトレーニングされ、次に微調整されます。 -関心のある特定のタスクに合わせて調整。最近の研究では、このレシピが機能する理由を理解し、失敗した場合を説明しようとしています。現在、そのような分析は、明らかに矛盾する2セットの結果を生み出しています。事前トレーニング（「プロービング分類子」を介して）の結果の表現を分析する作業は、言語構造の豊富な機能を高精度でデコードできるという証拠を見つけますが、微調整後のモデルの動作を分析する作業（「チャレンジセット」を介して）多くの場合、決定はそのような構造に基づいているのではなく、トレーニングセットに固有の偽のヒューリスティックに基づいていることを示しています。この作業では、特徴がモデルの決定に影響を与える程度が、2つの要因の組み合わせを使用して予測できるという仮説をテストします。事前トレーニング後の特徴の「抽出可能性」（情報理論的プロービング手法を使用して測定）と微調整中に利用可能な「証拠」（ラベルとの機能の共起率として定義されます）。合成言語データと自然言語データの両方を使用した実験では、この仮説を裏付ける強力な証拠（統計的に有意な相関関係）が見つかりました。,7.0,
VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models,"['Zhisheng Xiao', 'Karsten Kreis', 'Jan Kautz', 'Arash Vahdat']",https://openreview.net/forum?id=5m3SEczOV8L,"Energy-based models (EBMs) have recently been successful in representing complex distributions of small images. However, sampling from them requires expensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high dimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate samples quickly and are equipped with a latent space that enables fast traversal of the data manifold. However, VAEs tend to assign high probability density to regions in data space outside the actual data distribution and often fail at generating sharp images. In this paper, we propose VAEBM, a symbiotic composition of a VAE and an EBM that offers the best of both worlds. VAEBM captures the overall mode structure of the data distribution using a state-of-the-art VAE and it relies on its EBM component to explicitly exclude non-data-like regions from the model and refine the image samples. Moreover, the VAE component in VAEBM allows us to speed up MCMC updates by reparameterizing them in the VAE's latent space. Our experimental results show that VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on several benchmark image datasets by a large margin. It can generate high-quality images as large as 256$\times$256 pixels with short MCMC chains. We also demonstrate that VAEBM provides complete mode coverage and performs well in out-of-distribution detection. ",エネルギーベースのモデル（EBM）は、最近、小さな画像の複雑な分布を表すことに成功しています。ただし、それらからのサンプリングには、高次元のピクセル空間でゆっくりと混合する高価なマルコフ連鎖モンテカルロ（MCMC）反復が必要です。 EBMとは異なり、変分オートエンコーダー（VAE）はサンプルを迅速に生成し、データ多様体の高速トラバーサルを可能にする潜在空間を備えています。ただし、VAEは、実際のデータ分布の外側のデータ空間内の領域に高い確率密度を割り当てる傾向があり、鮮明な画像の生成に失敗することがよくあります。本稿では、VAEとEBMの共生構成であるVAEBMを提案し、両方の長所を提供します。 VAEBMは、最先端のVAEを使用してデータ分布の全体的なモード構造をキャプチャし、EBMコンポーネントに依存して、モデルからデータに似ていない領域を明示的に除外し、画像サンプルを調整します。さらに、VAEBMのVAEコンポーネントを使用すると、VAEの潜在空間でMCMCの更新を再パラメーター化することにより、MCMCの更新を高速化できます。私たちの実験結果は、VAEBMがいくつかのベンチマーク画像データセットで生成品質において最先端のVAEおよびEBMを大幅に上回っていることを示しています。短いMCMCチェーンで256256ピクセルの高品質画像を生成できます。また、VAEBMが完全なモードカバレッジを提供し、分布外検出で良好に機能することも示します。,7.0,https://d3i71xaburhd42.cloudfront.net/eaba5e8665e2a8397b278cb473df7e31a240a598/3-Figure1-1.png
Does enhanced shape bias improve neural network robustness to common corruptions?,"['Chaithanya Kumar Mummadi', 'Ranjitha Subramaniam', 'Robin Hutmacher', 'Julien Vitay', 'Volker Fischer', 'Jan Hendrik Metzen']",https://openreview.net/forum?id=yUxUNaj2Sl,"Convolutional neural networks (CNNs) learn to extract representations of complex features, such as object shapes and textures to solve image recognition tasks. Recent work indicates that CNNs trained on ImageNet are biased towards features that encode textures and that these alone are sufficient to generalize to unseen test data from the same distribution as the training data but often fail to generalize to out-of-distribution data. It has been shown that augmenting the training data with different image styles decreases this texture bias in favor of increased shape bias while at the same time improving robustness to common corruptions, such as noise and blur. Commonly, this is interpreted as shape bias increasing corruption robustness. However, this relationship is only hypothesized. We perform a systematic study of different ways of composing inputs based on natural images, explicit edge information, and stylization. While stylization is essential for achieving high corruption robustness, we do not find a clear correlation between shape bias and robustness. We conclude that the data augmentation caused by style-variation  accounts for the improved corruption robustness and increased shape bias is only a byproduct.",畳み込みニューラルネットワーク（CNN）は、オブジェクトの形状やテクスチャなどの複雑な特徴の表現を抽出して、画像認識タスクを解決する方法を学習します。最近の研究によると、ImageNetでトレーニングされたCNNはテクスチャをエンコードする機能に偏っており、トレーニングデータと同じ分布からの見えないテストデータに一般化するにはこれらだけで十分ですが、分布外データに一般化できないことがよくあります。トレーニングデータをさまざまな画像スタイルで拡張すると、このテクスチャバイアスが減少し、形状バイアスが増加すると同時に、ノイズやブラーなどの一般的な破損に対する堅牢性が向上することが示されています。一般に、これは、破損の堅牢性を高める形状バイアスとして解釈されます。ただし、この関係は仮定されているだけです。自然画像、明示的なエッジ情報、およびスタイルに基づいて入力を構成するさまざまな方法の体系的な調査を実行します。高い破損の堅牢性を実現するには様式化が不可欠ですが、形状の偏りと堅牢性の間に明確な相関関係はありません。スタイルの変化によって引き起こされるデータの増大は、破損の堅牢性の向上と形状の偏りの増加を説明していると結論付けています。,7.0,
"Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation","['Jungo Kasai', 'Nikolaos Pappas', 'Hao Peng', 'James Cross', 'Noah Smith']",https://openreview.net/forum?id=KpfasTaLUpq,"During the recent years, much effort has been invested in non-autoregressive neural machine translation, which appears to be an efficient alternative to state-of-the-art autoregressive machine translation on modern GPUs. In contrast to the latter where generation is sequential, the former allows generation to be parallelized across target token positions. Non-autoregressive machine translation provides a tradeoff between translation quality and inference speed, but some of the latest models have achieved impressive tradeoffs compared to autoregressive baselines. In this work, we reexamine this tradeoff and argue that autoregressive baselines can be substantially sped up without loss in accuracy. Specifically, we study autoregressive models with encoders and decoders of varied depths. Our extensive experiments show that given a sufficiently deep encoder, a single-layer autoregressive decoder can substantially outperform strong non-autoregressive models with comparable inference speed. We show that the speed disadvantage for autoregressive baselines compared to non-autoregressive methods has been overestimated in three aspects: suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation. Our results establish a new protocol for future research toward fast, accurate machine translation. ",近年、非自己回帰ニューラル機械翻訳に多くの努力が注がれています。これは、最新のGPUでの最先端の自己回帰機械翻訳の効率的な代替手段のようです。生成が順次である後者とは対照的に、前者では、生成をターゲットトークンの位置間で並列化できます。非自己回帰機械翻訳は、翻訳品質と推論速度の間のトレードオフを提供しますが、最新モデルのいくつかは、自己回帰ベースラインと比較して印象的なトレードオフを達成しています。この作業では、このトレードオフを再検討し、自己回帰ベースラインを精度を損なうことなく大幅に高速化できると主張します。具体的には、さまざまな深さのエンコーダーとデコーダーを使用した自己回帰モデルを研究します。私たちの広範な実験は、十分に深いエンコーダーが与えられた場合、単層自己回帰デコーダーは、同等の推論速度で強力な非自己回帰モデルを大幅に上回ることができることを示しています。非自己回帰法と比較した自己回帰ベースラインの速度の不利な点は、次の3つの側面で過大評価されていることを示します。最適ではない層の割り当て、不十分な速度測定、知識の欠如。私たちの結果は、高速で正確な機械翻訳に向けた将来の研究のための新しいプロトコルを確立します。,7.0,
Multi-timescale Representation Learning in LSTM Language Models,"['Shivangi Mahto', 'Vy Ai Vo', 'Javier S. Turek', 'Alexander Huth']",https://openreview.net/forum?id=9ITXiTrAoT,"Language models must capture statistical dependencies between words at timescales ranging from very short to very long. Earlier work has demonstrated that dependencies in natural language tend to decay with distance between words according to a power law. However, it is unclear how this knowledge can be used for analyzing or designing neural network language models. In this work, we derived a theory for how the memory gating mechanism in long short-term memory (LSTM) language models can capture power law decay. We found that unit timescales within an LSTM, which are determined by the forget gate bias, should follow an Inverse Gamma distribution. Experiments then showed that LSTM language models trained on natural English text learn to approximate this theoretical distribution. Further, we found that explicitly imposing the theoretical distribution upon the model during training yielded better language model perplexity overall, with particular improvements for predicting low-frequency (rare) words. Moreover, the explicit multi-timescale model selectively routes information about different types of words through units with different timescales, potentially improving model interpretability. These results demonstrate the importance of careful, theoretically-motivated analysis of memory and timescale in language models.",言語モデルは、非常に短いものから非常に長いものまでのタイムスケールで、単語間の統計的依存関係をキャプチャする必要があります。以前の研究では、自然言語の依存関係は、べき法則に従って単語間の距離とともに減衰する傾向があることが示されています。ただし、この知識をニューラルネットワーク言語モデルの分析または設計にどのように使用できるかは不明です。この作業では、長短期記憶（LSTM）言語モデルのメモリゲーティングメカニズムがべき乗則の減衰をどのようにキャプチャできるかについての理論を導き出しました。忘れゲートバイアスによって決定されるLSTM内の単位タイムスケールは、逆ガンマ分布に従う必要があることがわかりました。次に、実験により、自然な英語のテキストでトレーニングされたLSTM言語モデルがこの理論的分布を近似することを学習することが示されました。さらに、トレーニング中にモデルに理論的分布を明示的に課すことで、言語モデルの全体的な混乱が改善され、低頻度（まれな）単語の予測が特に改善されることがわかりました。さらに、明示的なマルチタイムスケールモデルは、さまざまなタイプの単語に関する情報をさまざまなタイムスケールのユニットに選択的にルーティングし、モデルの解釈可能性を向上させる可能性があります。これらの結果は、言語モデルにおける記憶とタイムスケールの注意深く、理論的に動機付けられた分析の重要性を示しています。,7.0,https://d3i71xaburhd42.cloudfront.net/a833db6a27527fe5b85a3b161fc4317397e6b065/3-Figure1-1.png
Free Lunch for Few-shot Learning:  Distribution Calibration,"['Shuo Yang', 'Lu Liu', 'Min Xu']",https://openreview.net/forum?id=JWOiYxMG92s,"Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these few-sample classes by transferring statistics from the classes with sufficient examples. Then an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. We assume every dimension in the feature representation follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Our method can be built on top of off-the-shelf pretrained feature extractors and classification models without extra parameters. We show that a simple logistic regression classifier trained using the features sampled from our calibrated distribution can outperform the state-of-the-art accuracy on three datasets (~5% improvement on miniImageNet compared to the next best). The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation. ",限られた数のサンプルから学習することは困難です。学習したモデルは、少数のトレーニング例によって形成される偏った分布に基づいて簡単に過剰適合する可能性があるためです。このホワイトペーパーでは、十分な例を使用してクラスから統計を転送することにより、これらの少数サンプルクラスの分布を調整します。次に、適切な数の例をキャリブレーションされた分布からサンプリングして、分類器への入力を拡張できます。特徴表現のすべての次元がガウス分布に従うと仮定して、分布の平均と分散が、適切な数のサンプルで統計がより適切に推定される同様のクラスのそれから借用できるようにします。私たちの方法は、追加のパラメーターなしで、既成の事前トレーニング済みの特徴抽出器と分類モデルの上に構築できます。キャリブレーションされた分布からサンプリングされた特徴を使用してトレーニングされた単純なロジスティック回帰分類器が、3つのデータセットで最先端の精度を上回ることができることを示します（5,7.0,https://d3i71xaburhd42.cloudfront.net/01d08d2e68f25ec12ab940eb86e943263a76a6af/2-Figure1-1.png
Behavioral Cloning from Noisy Demonstrations,"['Fumihiro Sasaki', 'Ryota Yamashina']",https://openreview.net/forum?id=zrT3HcsWSAt,"We consider the problem of learning an optimal expert behavior policy given noisy demonstrations that contain observations from both optimal and non-optimal expert behaviors. Popular imitation learning algorithms, such as generative adversarial imitation learning, assume that (clear) demonstrations are given from optimal expert policies but not the non-optimal ones, and thus often fail to imitate the optimal expert behaviors given the noisy demonstrations. Prior works that address the problem require (1) learning policies through environment interactions in the same fashion as reinforcement learning, and (2) annotating each demonstration with confidence scores or rankings. However, such environment interactions and annotations in real-world settings take impractically long training time and a significant human effort. In this paper, we propose an imitation learning algorithm to address the problem without any environment interactions and annotations associated with the non-optimal demonstrations. The proposed algorithm learns ensemble policies with a generalized behavioral cloning (BC) objective function where we exploit another policy already learned by BC. Experimental results show that the proposed algorithm can learn behavior policies that are much closer to the optimal policies than ones learned by BC.",最適な専門家の行動と最適でない専門家の行動の両方からの観察を含む騒々しいデモンストレーションを前提として、最適な専門家の行動ポリシーを学習する問題を検討します。生成的敵対的模倣学習などの一般的な模倣学習アルゴリズムは、（明確な）デモンストレーションが最適な専門家のポリシーから与えられるが、最適でないものからは与えられないことを前提としているため、ノイズの多いデモンストレーションでは、最適な専門家の行動を模倣できないことがよくあります。この問題に対処する以前の作業では、（1）強化学習と同じ方法で環境の相互作用を通じてポリシーを学習し、（2）各デモンストレーションに信頼スコアまたはランキングで注釈を付ける必要があります。ただし、実際の設定でのこのような環境の相互作用と注釈には、非現実的に長いトレーニング時間と多大な人的労力がかかります。この論文では、非最適なデモンストレーションに関連する環境の相互作用や注釈なしで問題に対処するための模倣学習アルゴリズムを提案します。提案されたアルゴリズムは、BCによってすでに学習された別のポリシーを活用する一般化された行動クローニング（BC）目的関数を使用してアンサンブルポリシーを学習します。実験結果は、提案されたアルゴリズムが、BCによって学習されたものよりも最適なポリシーにはるかに近い行動ポリシーを学習できることを示しています。,7.0,
Explaining the Efficacy of  Counterfactually Augmented Data,"['Divyansh Kaushik', 'Amrith Setlur', 'Eduard H Hovy', 'Zachary Chase Lipton']",https://openreview.net/forum?id=HHiiQKWsOcV,"In attempts to produce machine learning models less reliant on spurious patterns in training data, researchers have recently proposed generating counterfactually augmented data through a human-in-the-loop process. As applied in NLP, given some documents and their (initial) labels, humans are tasked with revising the text to make a (given) counterfactual label applicable. Importantly, the instructions prohibit edits that are not necessary to flip the applicable label. Models trained on the augmented (original \emph{and} revised) data have been shown to rely less on semantically irrelevant words and to generalize better out of domain. While this work draws on causal thinking, casting edits as interventions and relying on human understanding to assess outcomes, the underlying causal model is not clear nor are the principles underlying the observed improvements in out-of-domain evaluation. In this paper, we explore a toy analog, using linear Gaussian models. Our analysis reveals interesting relationships between causal models, measurement noise, out-of-domain generalization, and reliance on spurious signals. Interestingly our analysis suggests that data corrupted by adding noise to causal features will degrade out-of-domain performance, while noise added to non-causal features may make models more robust out-of-domain. This analysis yields interesting insights that help to explain the efficacy of counterfactually augmented data. Finally, we present a large-scale empirical study that supports this hypothesis.",トレーニングデータの疑似パターンにあまり依存しない機械学習モデルを作成する試みにおいて、研究者は最近、ヒューマンインザループプロセスを通じて反事実的に拡張されたデータを生成することを提案しました。 NLPで適用されるように、いくつかのドキュメントとその（初期）ラベルが与えられると、人間は（与えられた）反事実的ラベルを適用可能にするためにテキストを修正する任務を負います。重要なのは、説明では、該当するラベルを反転するために必要のない編集を禁止していることです。拡張された（元のデータと改訂された）データでトレーニングされたモデルは、意味的に無関係な単語への依存度が低く、ドメイン外でより一般化することが示されています。この作業は因果的思考を利用し、介入として編集をキャス​​トし、結果を評価するために人間の理解に依存していますが、根底にある因果モデルは明確ではなく、ドメイン外評価で観察された改善の根底にある原則もありません。この論文では、線形ガウスモデルを使用して、おもちゃのアナログを探索します。私たちの分析は、因果モデル、測定ノイズ、ドメイン外の一般化、およびスプリアス信号への依存の間の興味深い関係を明らかにしています。興味深いことに、私たちの分析は、因果的特徴にノイズを追加することによって破損したデータはドメイン外のパフォーマンスを低下させる一方で、非因果的特徴にノイズを追加するとモデルがドメイン外でより堅牢になる可能性があることを示唆しています。この分析は、反事実的に増強されたデータの有効性を説明するのに役立つ興味深い洞察をもたらします。最後に、この仮説を裏付ける大規模な実証研究を紹介します。,7.0,https://d3i71xaburhd42.cloudfront.net/ddb801983301c4df0e5360d6cfa1b2d02162d7bc/3-Figure1-1.png
Linear Convergent Decentralized Optimization with Compression,"['Xiaorui Liu', 'Yao Li', 'Rongrong Wang', 'Jiliang Tang', 'Ming Yan']",https://openreview.net/forum?id=84gjULz1t5,"Communication compression has become a key strategy to speed up distributed optimization. However, existing decentralized algorithms with compression mainly focus on compressing DGD-type algorithms. They are unsatisfactory in terms of convergence rate, stability, and the capability to handle heterogeneous data. Motivated by primal-dual algorithms, this paper proposes the first \underline{L}in\underline{EA}r convergent \underline{D}ecentralized algorithm with compression, LEAD. Our theory describes the coupled dynamics of the inexact primal and dual update as well as compression error, and we provide the first consensus error bound in such settings without assuming bounded gradients. Experiments on convex problems validate our theoretical analysis, and empirical study on deep neural nets shows that LEAD is applicable to non-convex problems.",通信圧縮は、分散最適化を高速化するための重要な戦略になっています。ただし、圧縮を使用する既存の分散型アルゴリズムは、主にDGDタイプのアルゴリズムの圧縮に重点を置いています。それらは、収束率、安定性、および異種データを処理する機能の点で不十分です。 primal-dualアルゴリズムに動機付けられて、この論文は圧縮を伴う最初のinr収束分散アルゴリズムであるLEADを提案します。私たちの理論は、不正確なプライマルアップデートとデュアルアップデートの結合ダイナミクス、および圧縮エラーについて説明し、制限された勾配を想定せずに、そのような設定で制限された最初のコンセンサスエラーを提供します。凸問題に関する実験は、私たちの理論的分析を検証し、深いニューラルネットに関する経験的研究は、LEADが非凸問題に適用可能であることを示しています。,7.0,https://d3i71xaburhd42.cloudfront.net/2502dc4523fe70b02857cb58174dda314eb0a8bf/11-Figure1-1.png
Uncertainty Sets for Image Classifiers using Conformal Prediction,"['Anastasios Nikolas Angelopoulos', 'Stephen Bates', 'Michael Jordan', 'Jitendra Malik']",https://openreview.net/forum?id=eNdiU_DbM9,"Convolutional image classifiers can achieve high predictive accuracy, but quantifying their uncertainty remains an unresolved challenge, hindering their deployment in consequential settings. Existing uncertainty quantification techniques, such as Platt scaling, attempt to calibrate the network’s probability estimates, but they do not have formal guarantees. We present an algorithm that modifies any classifier to output a predictive set containing the true label with a user-specified probability, such as 90%. The algorithm is simple and fast like Platt scaling, but provides a formal finite-sample coverage guarantee for every model and dataset.
Our method modifies an existing conformal prediction algorithm to give more stable predictive sets by regularizing the small scores of unlikely classes after Platt scaling. In experiments on both Imagenet and Imagenet-V2 with ResNet-152 and other classifiers, our scheme outperforms existing approaches, achieving coverage with sets that are often factors of 5 to 10 smaller.",畳み込み画像分類器は高い予測精度を達成できますが、それらの不確実性を定量化することは未解決の課題であり、結果としての設定での展開を妨げます。プラットスケーリングなどの既存の不確実性定量化手法は、ネットワークの確率推定を較正しようとしますが、正式な保証はありません。 90などのユーザー指定の確率で真のラベルを含む予測セットを出力するように分類器を変更するアルゴリズムを提示します。この方法は、既存の共形予測アルゴリズムを変更して、プラットスケーリング。 ImagenetとImagenet-V2の両方でResNet-152と他の分類器を使用した実験では、私たちのスキームは既存のアプローチよりも優れており、多くの場合5〜10倍小さいセットでカバレッジを達成します。,7.0,
Zero-shot Synthesis with Group-Supervised Learning,"['Yunhao Ge', 'Sami Abu-El-Haija', 'Gan Xin', 'Laurent Itti']",https://openreview.net/forum?id=8wqCDnBmnrT,"Visual cognition of primates is superior to that of artificial neural networks in its ability to “envision” a visual object, even a newly-introduced one, in different attributes including pose, position, color, texture, etc.  To aid neural networks to envision objects with different attributes,  we propose a family of objective functions, expressed on groups of examples, as a novel learning framework that we term Group-Supervised Learning (GSL). GSL allows us to decompose inputs into a disentangled representation with swappable components, that can be recombined to synthesize new samples.  For instance, images of red boats&blue cars can be decomposed and recombined to synthesize novel images of red cars.   We propose an implementation based on auto-encoder, termed group-supervised zero-shot synthesis network (GZS-Net) trained with our learning framework, that can produce a high-quality red car even if no such example is witnessed during training. We test our model and learning framework on existing benchmarks, in addition, to the new dataset that we open-source. We qualitatively and quantitatively demonstrate that GZS-Net trained with GSL outperforms state-of-the-art methods",霊長類の視覚認識は、ポーズ、位置、色、テクスチャなどのさまざまな属性で、新しく導入されたものであっても、視覚オブジェクトを想像する能力において、人工ニューラルネットワークの視覚認識よりも優れています。さまざまな属性について、例のグループで表現された目的関数のファミリーを、グループ監視学習（GSL）と呼ばれる新しい学習フレームワークとして提案します。 GSLを使用すると、入力をスワップ可能なコンポーネントを使用して解きほぐされた表現に分解できます。これを再結合して、新しいサンプルを合成できます。たとえば、赤いボートと青い車の画像を分解して再結合し、赤い車の新しい画像を合成できます。学習フレームワークでトレーニングされたグループ監視ゼロショット合成ネットワーク（GZS-Net）と呼ばれるオートエンコーダーに基づく実装を提案します。これにより、トレーニング中にそのような例が見られなくても、高品質の赤い車を製造できます。オープンソースの新しいデータセットに加えて、既存のベンチマークでモデルと学習フレームワークをテストします。 GSLでトレーニングされたGZS-Netが最先端の方法よりも優れていることを定性的および定量的に示します,7.0,https://d3i71xaburhd42.cloudfront.net/df4d533ebdacd8bc2f047cd37b0352289b3c8bd5/3-Figure1-1.png
Unsupervised Audiovisual Synthesis via Exemplar Autoencoders,"['Kangle Deng', 'Aayush Bansal', 'Deva Ramanan']",https://openreview.net/forum?id=43VKWxg_Sqr,"We present an unsupervised approach that converts the input speech of any individual into audiovisual streams of potentially-infinitely many output speakers. Our approach builds on simple autoencoders that project out-of-sample data onto the distribution of the training set. We use exemplar autoencoders to learn the voice, stylistic prosody (emotions and ambiance), and visual appearance of a specific target exemplar speech. In contrast to existing methods, the proposed approach can be easily extended to an arbitrarily large number of speakers and styles using only 3 minutes of target audio-video data, without requiring any training data for the input speaker. To the best of our knowledge, we are the first work to demonstrate audiovisual synthesis from an audio signal. To do so, we learn audiovisual bottleneck representations that capture the structured linguistic content of speech. We outperform prior approaches on both audio and video synthesis, and present extensive qualitative analysis in supplementary material.",個人の入力音声を潜在的に無限に多くの出力スピーカーの視聴覚ストリームに変換する教師なしアプローチを提示します。私たちのアプローチは、サンプル外のデータをトレーニングセットの分布に投影する単純なオートエンコーダーに基づいています。エグザンプラオートエンコーダを使用して、特定のターゲットエグザンプラスピーチの音声、文体韻律（感情と雰囲気）、および視覚的外観を学習します。既存の方法とは対照的に、提案されたアプローチは、入力話者のトレーニングデータを必要とせずに、わずか3分のターゲットオーディオビデオデータを使用して、任意の数の話者およびスタイルに簡単に拡張できます。私たちの知る限り、私たちはオーディオ信号からの視聴覚合成を実証する最初の仕事です。そのために、音声の構造化された言語コンテンツをキャプチャする視聴覚ボトルネック表現を学習します。オーディオとビデオの両方の合成に関する以前のアプローチよりも優れており、補足資料で広範な定性分析を提示します。,7.0,https://d3i71xaburhd42.cloudfront.net/1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a/1-Figure1-1.png
Deep Equals Shallow for ReLU Networks in Kernel Regimes,"['Alberto Bietti', 'Francis Bach']",https://openreview.net/forum?id=aDjoksTpXOP,"Deep networks are often considered to be more expressive than shallow ones in terms of approximation. Indeed, certain functions can be approximated by deep networks provably more efficiently than by shallow ones, however, no tractable algorithms are known for learning such deep models. Separately, a recent line of work has shown that deep networks trained with gradient descent may behave like (tractable) kernel methods in a certain over-parameterized regime, where the kernel is determined by the architecture and initialization, and this paper focuses on approximation for such kernels. We show that for ReLU activations, the kernels derived from deep fully-connected networks have essentially the same approximation properties as their shallow two-layer counterpart, namely the same eigenvalue decay for the corresponding integral operator. This highlights the limitations of the kernel framework for understanding the benefits of such deep architectures. Our main theoretical result relies on characterizing such eigenvalue decays through differentiability properties of the kernel function, which also easily applies to the study of other kernels defined on the sphere.",深いネットワークは、近似の観点から、浅いネットワークよりも表現力が高いと見なされることがよくあります。確かに、特定の関数は、浅いものよりも確実に効率的に深いネットワークで近似できますが、そのような深いモデルを学習するための扱いやすいアルゴリズムは知られていません。これとは別に、最近の一連の作業では、勾配降下法でトレーニングされたディープネットワークが、特定の過剰パラメータ化されたレジームで（扱いやすい）カーネル法のように動作する可能性があることが示されています。カーネルはアーキテクチャと初期化によって決定されます。このホワイトペーパーでは、そのようなカーネル。 ReLUアクティベーションの場合、完全に接続された深いネットワークから派生したカーネルは、浅い2層の対応するものと本質的に同じ近似特性、つまり対応する積分演算子の同じ固有値減衰を持っていることを示します。これは、そのような深いアーキテクチャの利点を理解するためのカーネルフレームワークの制限を浮き彫りにします。私たちの主な理論的結果は、カーネル関数の微分可能性の特性を通じてそのような固有値の減衰を特徴づけることに依存しています。これは、球上で定義された他のカーネルの研究にも簡単に適用できます。,7.0,https://d3i71xaburhd42.cloudfront.net/f4a65b67dbd5d8fb7bd063e93c88622a6437f6a6/8-Figure1-1.png
Can a Fruit Fly Learn Word Embeddings?,"['Yuchen Liang', 'Chaitanya Ryali', 'Benjamin Hoover', 'Saket Navlakha', 'Leopold Grinberg', 'Mohammed J Zaki', 'Dmitry Krotov']",https://openreview.net/forum?id=xfmSoxdxFCG,"The mushroom body of the fruit fly brain is one of the best studied systems in neuroscience. At its core it consists of a population of Kenyon cells, which receive inputs from multiple sensory modalities. These cells are inhibited by the anterior paired lateral neuron, thus creating a sparse high dimensional representation of the inputs. In this work we study a mathematical formalization of this network motif and apply it to learning the correlational structure between words and their context in a corpus of unstructured text, a common natural language processing (NLP) task. We show that this network can learn semantic representations of words and can generate both static and context-dependent word embeddings. Unlike conventional methods (e.g., BERT, GloVe) that use dense representations for word embedding, our algorithm encodes semantic meaning of words and their context in the form of sparse binary hash codes. The quality of the learned representations is evaluated on word similarity analysis, word-sense disambiguation, and document classification. It is shown that not only can the fruit fly network motif achieve performance comparable to existing methods in NLP, but, additionally, it uses only a fraction of the computational resources (shorter training time and smaller memory footprint). ",ショウジョウバエの脳のキノコ体は、神経科学で最もよく研​​究されているシステムの1つです。その核となるのは、複数の感覚モダリティからの入力を受け取るケニオン細胞の集団で構成されています。これらの細胞は、前方の対になった外側ニューロンによって抑制されるため、入力のまばらな高次元表現が作成されます。この作業では、このネットワークモチーフの数学的形式化を研究し、一般的な自然言語処理（NLP）タスクである非構造化テキストのコーパスにおける単語とそのコンテキスト間の相関構造の学習に適用します。このネットワークが単語の意味表現を学習し、静的およびコンテキスト依存の両方の単語埋め込みを生成できることを示します。単語の埋め込みに密な表現を使用する従来の方法（BERT、GloVeなど）とは異なり、私たちのアルゴリズムは、単語の意味とそのコンテキストをスパースバイナリハッシュコードの形式でエンコードします。学習された表現の品質は、単語の類似性分析、語義の曖昧性解消、および文書分類で評価されます。ショウジョウバエのネットワークモチーフは、NLPの既存の方法に匹敵するパフォーマンスを達成できるだけでなく、計算リソースのごく一部しか使用しない（トレーニング時間の短縮とメモリフットプリントの削減）ことが示されています。,7.0,https://d3i71xaburhd42.cloudfront.net/d0c8f3198653e5bb44a4c61308cc5cefb63bb2df/2-Figure1-1.png
Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective,"['Muhammet Balcilar', 'Guillaume Renton', 'Pierre Héroux', 'Benoit Gaüzère', 'Sébastien Adam', 'Paul Honeine']",https://openreview.net/forum?id=-qh0M9XWxnv,"In the recent literature of Graph Neural Networks (GNN), the expressive power of models has been studied through their capability to distinguish if two given graphs are isomorphic or not. Since the graph isomorphism problem is NP-intermediate, and Weisfeiler-Lehman (WL) test can give sufficient but not enough evidence in polynomial time, the theoretical power of GNNs is usually evaluated by the equivalence of WL-test order, followed by an empirical analysis of the models on some reference inductive and transductive datasets. However, such analysis does not account the signal processing pipeline, whose capability is generally evaluated in the spectral domain. In this paper, we argue that a spectral analysis of GNNs behavior can provide a complementary point of view to go one step further in the understanding of GNNs. By bridging the gap between the spectral and spatial design of graph convolutions, we theoretically demonstrate some equivalence of the graph convolution process regardless it is designed in the spatial or the spectral domain. Using this connection, we managed to re-formulate most of the state-of-the-art graph neural networks into one common framework. This general framework allows to lead a spectral analysis of the most popular GNNs, explaining their performance and showing their limits according to spectral point of view. Our theoretical spectral analysis is confirmed by experiments on various graph databases. Furthermore, we demonstrate the necessity of high and/or band-pass filters on a graph dataset, while the majority of GNN is limited to only low-pass and inevitably it fails.",グラフニューラルネットワーク（GNN）の最近の文献では、モデルの表現力が、2つの与えられたグラフが同型であるかどうかを区別する機能を通じて研究されています。グラフ同型問題はNP中間であり、Weisfeiler-Lehman（WL）検定は多項式時間で十分ではあるが十分ではない証拠を与えることができるため、GNNの理論的検出力は通常、WL検定次数の等価性によって評価され、その後に経験的いくつかの参照帰納的およびトランスダクティブデータセットのモデルの分析。ただし、このような分析では、信号処理パイプラインは考慮されていません。信号処理パイプラインの機能は、通常、スペクトル領域で評価されます。この論文では、GNNの動作のスペクトル分析が、GNNの理解をさらに一歩進めるための補完的な視点を提供できると主張します。グラフ畳み込みのスペクトル設計と空間設計の間のギャップを埋めることにより、空間領域またはスペクトル領域で設計されているかどうかに関係なく、グラフ畳み込みプロセスのある程度の同等性を理論的に示します。この接続を使用して、最先端のグラフニューラルネットワークのほとんどを1つの共通のフレームワークに再定式化することができました。この一般的なフレームワークにより、最も人気のあるGNNのスペクトル分析を主導し、それらのパフォーマンスを説明し、スペクトルの観点に従って限界を示すことができます。私たちの理論的なスペクトル分析は、さまざまなグラフデータベースでの実験によって確認されています。さらに、グラフデータセットにハイフィルターやバンドパスフィルターが必要であることを示していますが、GNNの大部分はローパスのみに制限されており、必然的に失敗します。,7.0,
BUSTLE: Bottom-Up program Synthesis Through Learning-guided Exploration,"['Augustus Odena', 'Kensen Shi', 'David Bieber', 'Rishabh Singh', 'Charles Sutton', 'Hanjun Dai']",https://openreview.net/forum?id=yHeg4PbFHh,"Program synthesis is challenging largely because of the difficulty of search in a large space of programs. Human programmers routinely tackle the task of writing complex programs by writing sub-programs and then analyzing their intermediate results to compose them in appropriate ways. Motivated by this intuition, we present a new synthesis approach that leverages learning to guide a bottom-up search over programs. In particular, we train a model to prioritize compositions of intermediate values during search conditioned on a given set of input-output examples. This is a powerful combination because of several emergent properties. First, in bottom-up search, intermediate programs can be executed, providing semantic information to the neural network. Second, given the concrete values from those executions, we can exploit rich features based on recent work on property signatures. Finally, bottom-up search allows the system substantial flexibility in what order to generate the solution, allowing the synthesizer to build up a program from multiple smaller sub-programs. Overall, our empirical evaluation finds that the combination of learning  and bottom-up search is remarkably effective, even with simple supervised learning approaches. We demonstrate the effectiveness of our technique on two datasets, one from the SyGuS competition and one of our own creation.",プログラムの合成は、主に、プログラムの広いスペースでの検索が難しいために困難です。人間のプログラマーは、サブプログラムを作成し、その中間結果を分析して適切な方法で構成することにより、複雑なプログラムを作成するタスクに日常的に取り組んでいます。この直感に動機付けられて、学習を活用してプログラムのボトムアップ検索をガイドする新しい統合アプローチを紹介します。特に、特定の入出力例のセットを条件として、検索中に中間値の構成に優先順位を付けるようにモデルをトレーニングします。これは、いくつかの創発的な特性があるため、強力な組み合わせです。まず、ボトムアップ検索では、中間プログラムを実行して、ニューラルネットワークに意味情報を提供できます。次に、これらの実行からの具体的な値が与えられると、プロパティ署名に関する最近の作業に基づいて豊富な機能を活用できます。最後に、ボトムアップ検索により、システムはソリューションを生成する順序にかなりの柔軟性があり、シンセサイザーは複数の小さなサブプログラムからプログラムを構築できます。全体として、私たちの経験的評価では、単純な教師あり学習アプローチを使用した場合でも、学習とボトムアップ検索の組み合わせが非常に効果的であることがわかりました。 SyGuSコンペティションからのものと独自に作成したものの2つのデータセットで、この手法の有効性を示します。,7.0,
gradSim: Differentiable simulation for system identification and visuomotor control,"['J. Krishna Murthy', 'Miles Macklin', 'Florian Golemo', 'Vikram Voleti', 'Linda Petrini', 'Martin Weiss', 'Breandan Considine', 'Jérôme Parent-Lévesque', 'Kevin Xie', 'Kenny Erleben', 'Liam Paull', 'Florian Shkurti', 'Derek Nowrouzezahrai', 'Sanja Fidler']",https://openreview.net/forum?id=c_E8kFWfhp0,"In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.",この論文では、質量、摩擦、弾性などの物体の物理的特性をビデオシーケンスから直接推定する問題に取り組んでいます。このようなシステム同定の問題は、画像形成中に情報が失われるため、根本的に不適切です。この問題に対する現在の最善の解決策は、収集するのに労働集約的であり、変形可能な固体や布などの多くのシステムで作成することが不可能な正確な3Dラベルを必要とします。この作業では、微分可能なマルチフィジックスシミュレーションと微分可能なレンダリングを組み合わせてシーンダイナミクスと画像形成の進化を共同でモデル化することにより、3D監視への依存を克服するフレームワークであるgradSimを紹介します。この独自の組み合わせにより、ビデオシーケンス内のピクセルから、それらを生成した基礎となる物理属性へのバックプロパゲーションが可能になります。さらに、ダイナミクスとレンダリングエンジンにわたる統合された計算グラフにより、状態ベース（3D）の監視に依存することなく、困難な視覚運動制御タスクの学習が可能になり、正確な3Dラベルを必要とする手法と同等/それ以上のパフォーマンスが得られます。,7.0,
Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity,"['JangHyun Kim', 'Wonho Choo', 'Hosan Jeong', 'Hyun Oh Song']",https://openreview.net/forum?id=gvxJzw8kW4b,"While deep neural networks show great performance on fitting to the training distribution, improving the networks' generalization performance to the test distribution and robustness to the sensitivity to input perturbations still remain as a challenge. Although a number of mixup based augmentation strategies have been proposed to partially address them, it remains unclear as to how to best utilize the supervisory signal within each input data for mixup from the optimization perspective. We propose a new perspective on batch mixup and formulate the optimal construction of a batch of mixup data maximizing the data saliency measure of each individual mixup data and encouraging the supermodular diversity among the constructed mixup data. This leads to a novel discrete optimization problem minimizing the difference between submodular functions. We also propose an efficient modular approximation based iterative submodular minimization algorithm for efficient mixup computation per each minibatch suitable for minibatch based neural network training. Our experiments show the proposed method achieves the state of the art generalization, calibration, and weakly supervised localization results compared to other mixup methods. The source code is available at https://github.com/snu-mllab/Co-Mixup.",ディープニューラルネットワークはトレーニング分布へのフィッティングで優れたパフォーマンスを示しますが、ネットワークの一般化パフォーマンスをテスト分布に改善し、入力摂動に対する感度に対するロバスト性を改善することは依然として課題です。それらに部分的に対処するために、いくつかの混合ベースの増強戦略が提案されてきたが、最適化の観点から、混合のために各入力データ内の監視信号をどのように最適に利用するかについては不明である。バッチ混合に関する新しい視点を提案し、個々の混合データのデータ顕著性測定値を最大化し、構築された混合データ間の超モジュラー多様性を促進する混合データのバッチの最適な構築を定式化します。これは、劣モジュラ関数間の差を最小化する新しい離散最適化問題につながります。また、ミニバッチベースのニューラルネットワークトレーニングに適した各ミニバッチごとの効率的な混合計算のための効率的なモジュラー近似ベースの反復劣モジュラ最小化アルゴリズムを提案します。私たちの実験は、提案された方法が、他の混合方法と比較して、最先端の一般化、キャリブレーション、および弱く監視されたローカリゼーションの結果を達成することを示しています。ソースコードはhttps://github.com/snu-mllab/Co-Mixupで入手できます。,7.0,
Systematic generalisation with group invariant predictions,"['Faruk Ahmed', 'Yoshua Bengio', 'Harm van Seijen', 'Aaron Courville']",https://openreview.net/forum?id=b9PoimzZFJ,"We consider situations where the presence of dominant simpler correlations with the target variable in a training set can cause an SGD-trained neural network to be less reliant on more persistently-correlating complex features. When the non-persistent, simpler correlations correspond to non-semantic background factors, a neural network trained on this data can exhibit dramatic failure upon encountering systematic distributional shift, where the correlating background features are recombined with different objects. We perform an empirical study showing that group invariance methods across inferred partitionings of the training set can lead to significant improvements at such test-time situations. We suggest a new invariance penalty, showing with experiments on three synthetic datasets that it can perform better than alternatives. We find that even without assuming access to any systematic-shift validation sets, one can still find improvements over an ERM-trained reference model.",トレーニングセット内のターゲット変数との優勢で単純な相関の存在により、SGDでトレーニングされたニューラルネットワークがより永続的に相関する複雑な特徴に依存しなくなる可能性がある状況を検討します。非永続的で単純な相関が非セマンティックバックグラウンド要因に対応する場合、このデータでトレーニングされたニューラルネットワークは、相関するバックグラウンド機能がさまざまなオブジェクトと再結合される体系的な分布シフトに遭遇すると、劇的な障害を示す可能性があります。トレーニングセットの推定パーティション全体でのグループ不変法が、このようなテスト時の状況で大幅な改善につながる可能性があることを示す実証研究を実行します。新しい不変性ペナルティを提案し、3つの合成データセットでの実験で、他のデータセットよりもパフォーマンスが優れていることを示しています。体系的なシフト検証セットへのアクセスを想定していなくても、ERMでトレーニングされた参照モデルよりも改善されていることがわかります。,7.0,
The Intrinsic Dimension of Images and Its Impact on Learning,"['Phil Pope', 'Chen Zhu', 'Ahmed Abdelkader', 'Micah Goldblum', 'Tom Goldstein']",https://openreview.net/forum?id=XJk19XzGq2J,"It is widely believed that natural image data exhibits low-dimensional structure despite being embedded in a high-dimensional pixel space. This idea underlies a common intuition for the success of deep learning and has been exploited for enhanced regularization and adversarial robustness. In this work, we apply dimension estimation tools to popular datasets and investigate the role of low dimensional structure in neural network learning. We find that common natural image datasets indeed have very low intrinsic dimension relative to the high number of pixels in the images. Additionally, we find that low dimensional datasets are easier for neural networks to learn.  We validate our dimension estimation tools synthetic data generated by GANs in which we can manipulate intrinsic dimension.
",自然画像データは、高次元のピクセル空間に埋め込まれているにもかかわらず、低次元の構造を示すと広く信じられています。このアイデアは、ディープラーニングの成功に対する一般的な直感の根底にあり、強化された正則化と敵対的な堅牢性のために活用されています。この作業では、一般的なデータセットに次元推定ツールを適用し、ニューラルネットワーク学習における低次元構造の役割を調査します。一般的な自然画像データセットは、画像内のピクセル数が多いのに比べて、実際に内在次元が非常に低いことがわかります。さらに、低次元のデータセットはニューラルネットワークが学習しやすいことがわかりました。内在次元を操作できるGANによって生成された次元推定ツールの合成データを検証します。,7.0,
Spatio-Temporal Graph Scattering Transform,"['Chao Pan', 'Siheng Chen', 'Antonio Ortega']",https://openreview.net/forum?id=CF-ZIuSMXRz,"Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.",時空間グラフニューラルネットワークは、複数の相関時系列の処理で大きな経験的成功を収めていますが、十分な高品質のトレーニングデータがないため、実際のシナリオでは実用的でない場合があります。さらに、時空間グラフニューラルネットワークは理論的な解釈を欠いています。これらの問題に対処するために、時空間データを分析するための新しい数学的に設計されたフレームワークを発表しました。提案された時空間グラフ散乱変換（ST-GST）は、従来の散乱変換を時空間ドメインに拡張します。これは、時空間グラフウェーブレットと非線形活性化関数の反復アプリケーションを実行します。これは、トレーニングなしで時空間グラフ畳み込みネットワークのフォワードパスと見なすことができます。 ST-GSTのすべてのフィルター係数は数学的に設計されているため、トレーニングデータが限られている実際のシナリオに有望であり、提案されたST-GSTが入力の小さな摂動に対して安定していることを示す理論的分析も可能です。信号と構造。最後に、私たちの実験は、i）ST-GSTが時空間グラフ畳み込みネットワークを35増加することを示しています。,7.0,https://d3i71xaburhd42.cloudfront.net/29d22a4939e3497d5a9b6a3e1c47584854a46000/3-Figure1-1.png
Undistillable: Making A Nasty Teacher That CANNOT teach students,"['Haoyu Ma', 'Tianlong Chen', 'Ting-Kuei Hu', 'Chenyu You', 'Xiaohui Xie', 'Zhangyang Wang']",https://openreview.net/forum?id=0zvfm-nZqQs,"Knowledge Distillation (KD) is a widely used technique to transfer knowledge from pre-trained teacher models to  (usually more lightweight) student models. However, in certain situations, this technique is more of a curse than a blessing. For instance, KD poses a potential risk of exposing intellectual properties (IPs): even if a trained machine learning model is released in ``black boxes'' (e.g., as executable software or APIs without open-sourcing code), it can still be replicated by KD through imitating input-output behaviors. To prevent this unwanted effect of KD, this paper introduces and investigates a concept called Nasty Teacher: a specially trained teacher network that yields nearly the same performance as a normal one, but would significantly degrade the performance of student models learned by imitating it. We propose a simple yet effective algorithm to build the nasty teacher, called self-undermining knowledge distillation. Specifically, we aim to maximize the difference between the output of the nasty teacher and a normal pre-trained network. Extensive experiments on several datasets demonstrate that our method is effective on both standard KD and data-free KD, providing the desirable KD-immunity to model owners for the first time. We hope our preliminary study can draw more awareness and interest in this new practical problem of both social and legal importance.",知識蒸留（KD）は、事前にトレーニングされた教師モデルから（通常はより軽量な）学生モデルに知識を転送するために広く使用されている手法です。ただし、特定の状況では、このテクニックは祝福というよりは呪いです。たとえば、KDは知的財産（IP）を公開する潜在的なリスクをもたらします。トレーニングされた機械学習モデルがブラックボックスでリリースされた場合でも（たとえば、実行可能ソフトウェアまたはオープンソーシングコードのないAPIとして）、KDによって複製できます。入出力動作を模倣することによって。 KDのこの望ましくない影響を防ぐために、このペーパーではNasty Teacherと呼ばれる概念を紹介し、調査します。これは、通常のパフォーマンスとほぼ同じパフォーマンスをもたらすが、それを模倣することによって学習した学生モデルのパフォーマンスを大幅に低下させる、特別に訓練された教師ネットワークです。自己弱体化知識蒸留と呼ばれる、厄介な教師を構築するためのシンプルで効果的なアルゴリズムを提案します。具体的には、厄介な教師の出力と通常の事前トレーニング済みネットワークとの違いを最大化することを目指しています。いくつかのデータセットでの広範な実験は、私たちの方法が標準KDとデータフリーKDの両方で効果的であり、モデル所有者に初めて望ましいKD耐性を提供することを示しています。私たちの予備調査が、社会的および法的に重要なこの新しい実際的な問題について、より多くの認識と関心を引くことができることを願っています。,7.0,
When does preconditioning help or hurt generalization?,"['Shun-ichi Amari', 'Jimmy Ba', 'Roger Baker Grosse', 'Xuechen Li', 'Atsushi Nitanda', 'Taiji Suzuki', 'Denny Wu', 'Ji Xu']",https://openreview.net/forum?id=S724o4_WB3,"While second order optimizers such as natural gradient descent (NGD) often speed up optimization, their effect on generalization has been called into question. This work presents a more nuanced view on how the \textit{implicit bias} of optimizers affects the comparison of generalization properties. 
We provide an exact asymptotic bias-variance decomposition of the generalization error of preconditioned ridgeless regression in the overparameterized regime, and consider the inverse population Fisher information matrix (used in NGD) as a particular example. We determine the optimal preconditioner $\boldsymbol{P}$ for both the bias and variance, and find that the relative generalization performance of different optimizers depends on label noise and ``shape'' of the signal (true parameters): when the labels are noisy, the model is misspecified, or the signal is misaligned with the features, NGD can achieve lower risk; conversely, GD generalizes better under clean labels, a well-specified model, or aligned signal. 
Based on this analysis, we discuss several approaches to manage the bias-variance tradeoff, and the potential benefit of interpolating between first- and second-order updates. We then extend our analysis to regression in the reproducing kernel Hilbert space and demonstrate that preconditioning can lead to more efficient decrease in the population risk. Lastly, we empirically compare the generalization error of first- and second-order optimizers in neural network experiments, and observe robust trends matching our theoretical analysis. ",自然勾配降下法（NGD）などの2次オプティマイザーは最適化を高速化することがよくありますが、一般化への影響は疑問視されています。この作業は、オプティマイザーの暗黙のバイアスが一般化プロパティの比較にどのように影響するかについて、より微妙な見方を示します。過パラメータ化されたレジームにおける前処理付きリッジレス回帰の汎化誤差の正確な漸近偏りと分散分解を提供し、特定の例として逆母集団フィッシャー情報行列（NGDで使用）を検討します。バイアスと分散の両方に最適な前処理行列Pを決定し、さまざまなオプティマイザーの相対的な一般化パフォーマンスが、ラベルのノイズと信号の形状（真のパラメーター）に依存することを確認します。ラベルにノイズが多い場合、モデルが誤って指定されている場合、または信号が機能と一致していない場合、NGDはリスクを低く抑えることができます。逆に、GDは、クリーンなラベル、明確に指定されたモデル、または整列された信号の下でより一般化されます。この分析に基づいて、バイアス分散のトレードオフを管理するためのいくつかのアプローチと、1次更新と2次更新の間を補間することの潜在的な利点について説明します。次に、分析を再生核ヒルベルト空間での回帰に拡張し、前処理が人口リスクのより効率的な減少につながる可能性があることを示します。最後に、ニューラルネットワーク実験における1次および2次オプティマイザーの汎化誤差を経験的に比較し、理論的分析と一致するロバストな傾向を観察します。,7.0,https://d3i71xaburhd42.cloudfront.net/af4fe7104ef94619920df684b5731ebfd58ddca9/2-Figure1-1.png
Discovering a set of policies for the worst case reward,"['Tom Zahavy', 'Andre Barreto', 'Daniel J Mankowitz', 'Shaobo Hou', ""Brendan O'Donoghue"", 'Iurii Kemaev', 'Satinder Singh']",https://openreview.net/forum?id=PUkhWz65dy5,"We study the problem of how to construct a set of policies that can be composed together to solve a collection of reinforcement learning tasks. Each task is a different reward function defined as a linear combination of  known features. We consider a specific class of policy compositions which we call set improving policies (SIPs): given a set of policies and a set of tasks, a SIP is any composition of the former whose performance is at least as good as that of its constituents across all the tasks. We focus on the most conservative instantiation of SIPs, set-max policies (SMPs), so our analysis extends to any SIP. This includes known policy-composition operators like generalized policy improvement. Our main contribution is an algorithm that builds a set of policies in order to maximize the worst-case performance of the resulting SMP on the set of tasks. The algorithm works by successively adding new policies to the set. We show that the worst-case performance of the resulting SMP strictly improves at each iteration, and the algorithm only stops when there does not exist a policy that leads to improved performance. We empirically evaluate our algorithm on a grid world and also on a set of domains from the DeepMind control suite. We confirm our theoretical results regarding the monotonically improving performance of our algorithm. Interestingly, we also show empirically that the sets of policies computed by the algorithm are diverse, leading to different trajectories in the grid world and very distinct locomotion skills in the control suite.",強化学習タスクのコレクションを解決するために一緒に構成できる一連のポリシーをどのように構築するかという問題を研究します。各タスクは、既知の機能の線形結合として定義された異なる報酬関数です。セット改善ポリシー（SIP）と呼ばれる特定のクラスのポリシー構成を検討します。一連のポリシーと一連のタスクが与えられると、SIPは、パフォーマンスが少なくともその構成要素のパフォーマンスと同等である前者の任意の構成です。すべてのタスク。 SIPの最も保守的なインスタンス化であるset-maxポリシー（SMP）に焦点を当てているため、分析はすべてのSIPに拡張されます。これには、一般化されたポリシー改善などの既知のポリシー構成演算子が含まれます。私たちの主な貢献は、一連のタスクで結果として得られるSMPの最悪の場合のパフォーマンスを最大化するために、一連のポリシーを構築するアルゴリズムです。このアルゴリズムは、新しいポリシーをセットに連続して追加することで機能します。結果のSMPの最悪の場合のパフォーマンスは各反復で厳密に向上し、アルゴリズムはパフォーマンスの向上につながるポリシーが存在しない場合にのみ停止することを示します。グリッドの世界とDeepMindコントロールスイートの一連のドメインでアルゴリズムを経験的に評価します。アルゴリズムのパフォーマンスを単調に改善することに関する理論的な結果を確認します。興味深いことに、アルゴリズムによって計算されたポリシーのセットが多様であり、グリッドの世界でさまざまな軌道が発生し、コントロールスイートで非常に異なる移動スキルが得られることも経験的に示しています。,7.0,
Large Associative Memory Problem in Neurobiology and Machine Learning,"['Dmitry Krotov', 'John J. Hopfield']",https://openreview.net/forum?id=X4y_10OX-hX,"Dense Associative Memories or modern Hopfield networks permit storage and reliable  retrieval of an exponentially large (in the dimension of feature space) number of memories. At the same time, their naive implementation is non-biological, since it seemingly requires the existence of many-body synaptic junctions between the neurons. We show that these models are effective descriptions of a more microscopic (written in terms of biological degrees of freedom) theory that has additional (hidden) neurons and only requires two-body interactions between them. For this reason our proposed microscopic theory is a valid model of large associative memory with a degree of biological plausibility. The dynamics of our network and its reduced dimensional equivalent both minimize energy (Lyapunov) functions. When certain dynamical variables (hidden neurons) are integrated out from our microscopic theory, one can recover many of the models that were previously discussed in the literature, e.g. the model presented in “Hopfield Networks is All You Need” paper. We also provide an alternative derivation of the energy function and the update rule proposed in the aforementioned paper and clarify the relationships between various models of this class.",密な連想メモリまたは最新のホップフィールドネットワークにより、指数関数的に多数の（機能空間の次元で）メモリの保存と信頼性の高い検索が可能になります。同時に、ニューロン間に多体シナプス接合部が存在する必要があるように見えるため、それらのナイーブな実装は非生物学的です。これらのモデルは、追加の（隠された）ニューロンを持ち、それらの間の2体の相互作用のみを必要とする、より微視的な（生物学的自由度の観点から書かれた）理論の効果的な記述であることを示します。このため、提案された微視的理論は、ある程度の生物学的妥当性を備えた大きな連想記憶の有効なモデルです。私たちのネットワークのダイナミクスとその縮小された次元の同等物は両方ともエネルギー（リアプノフ）関数を最小化します。特定の動的変数（隠されたニューロン）が私たちの微視的理論から統合されると、以前に文献で議論されたモデルの多くを回復できます。たとえば、ホップフィールドネットワークで提示されたモデルは必要なすべての論文です。また、前述の論文で提案されたエネルギー関数と更新ルールの代替導出を提供し、このクラスのさまざまなモデル間の関係を明確にします。,7.0,https://d3i71xaburhd42.cloudfront.net/ae5cd049c5f5bc78b8e223fb49e6eae88f376c18/2-Figure1-1.png
BOIL: Towards Representation Change for Few-shot Learning,"['Jaehoon Oh', 'Hyungjun Yoo', 'ChangHwan Kim', 'Se-Young Yun']",https://openreview.net/forum?id=umIdUL8rMH,"Model Agnostic Meta-Learning (MAML) is one of the most representative of gradient-based meta-learning algorithms. MAML learns new tasks with a few data samples using inner updates from a meta-initialization point and learns the meta-initialization parameters with outer updates. It has recently been hypothesized that representation reuse, which makes little change in efficient representations, is the dominant factor in the performance of the meta-initialized model through MAML in contrast to representation change, which causes a significant change in representations. In this study, we investigate the necessity of representation change for the ultimate goal of few-shot learning, which is solving domain-agnostic tasks. To this aim, we propose a novel meta-learning algorithm, called BOIL (Body Only update in Inner Loop), which updates only the body (extractor) of the model and freezes the head (classifier) during inner loop updates. BOIL leverages representation change rather than representation reuse. A frozen head cannot achieve better results than even a random guessing classifier at the initial point of new tasks, and feature vectors (representations) have to move quickly to their corresponding frozen head vectors. We visualize this property using cosine similarity, CKA, and empirical results without the head. Although the inner loop updates purely hinge on representation change, BOIL empirically shows significant performance improvement over MAML, particularly on cross-domain tasks. The results imply that representation change in gradient-based meta-learning approaches is a critical component.",モデルにとらわれないメタ学習（MAML）は、勾配ベースのメタ学習アルゴリズムの最も代表的なものの1つです。 MAMLは、メタ初期化ポイントからの内部更新を使用していくつかのデータサンプルで新しいタスクを学習し、外部更新でメタ初期化パラメーターを学習します。最近、効率的な表現にほとんど変化をもたらさない表現の再利用が、表現に大きな変化をもたらす表現の変化とは対照的に、MAMLによるメタ初期化モデルのパフォーマンスの支配的な要因であるという仮説が立てられました。この研究では、ドメインにとらわれないタスクを解決するという、数回の学習という究極の目標のために、表現の変更の必要性を調査します。この目的のために、BOIL（Inner LoopのBodyOnly update）と呼ばれる新しいメタ学習アルゴリズムを提案します。これは、モデルの本体（エクストラクター）のみを更新し、内部ループの更新中にヘッド（分類子）をフリーズします。 BOILは、表現の再利用ではなく、表現の変更を活用します。凍結された頭部は、新しいタスクの初期点でランダムな推測分類器よりも優れた結果を達成することはできず、特徴ベクトル（表現）は対応する凍結された頭部ベクトルにすばやく移動する必要があります。コサイン類似度、CKA、およびヘッドなしの経験的結果を使用して、このプロパティを視覚化します。内側のループの更新は純粋に表現の変更に依存しますが、BOILは、特にクロスドメインタスクで、MAMLよりも大幅なパフォーマンスの向上を経験的に示しています。結果は、勾配ベースのメタ学習アプローチにおける表現の変化が重要な要素であることを示唆しています。,7.0,
Linear Mode Connectivity in Multitask and Continual Learning,"['Seyed Iman Mirzadeh', 'Mehrdad Farajtabar', 'Dilan Gorur', 'Razvan Pascanu', 'Hassan Ghasemzadeh']",https://openreview.net/forum?id=Fmg_fQYUejf,"Continual (sequential) training and multitask (simultaneous) training are often attempting to solve the same overall objective: to find a solution that performs well on all considered tasks. The main difference is in the training regimes, where continual learning can only have access to one task at a time, which for neural networks typically leads to catastrophic forgetting. That is, the solution found for a subsequent task does not perform well on the previous ones anymore. 
    However, the relationship between the different minima that the two training regimes arrive at is not well understood. What sets them apart? Is there a local structure that could explain the difference in performance achieved by the two different schemes? 
    Motivated by recent work showing that different minima of the same task are typically connected by very simple curves of low error, we investigate whether multitask and continual solutions are similarly connected. We empirically find that indeed such connectivity can be reliably achieved and, more interestingly, it can be done by a linear path, conditioned on having the same initialization for both. We thoroughly analyze this observation and discuss its significance for the continual learning process.
    Furthermore, we exploit this finding to propose an effective algorithm that constrains the sequentially learned minima to behave as the multitask solution.  We show that our method outperforms several state of the art continual learning algorithms on various vision benchmarks.",継続的（順次）トレーニングとマルチタスク（同時）トレーニングは、多くの場合、同じ全体的な目的を解決しようとしています。つまり、考慮されるすべてのタスクで適切に実行されるソリューションを見つけることです。主な違いは、継続的な学習が一度に1つのタスクにしかア​​クセスできないトレーニング体制にあります。これは、ニューラルネットワークの場合、通常、壊滅的な忘却につながります。つまり、後続のタスクで見つかったソリューションは、前のタスクではうまく機能しなくなりました。ただし、2つのトレーニング体制が到達する異なる最小値間の関係はよく理解されていません。それらを際立たせるものは何ですか？ 2つの異なるスキームによって達成されるパフォーマンスの違いを説明できるローカル構造はありますか？同じタスクの異なる最小値が通常、低エラーの非常に単純な曲線によって接続されていることを示す最近の研究に動機付けられて、マルチタスクと継続的なソリューションが同様に接続されているかどうかを調査します。実際、このような接続は確実に実現でき、さらに興味深いことに、両方に対して同じ初期化を行うことを条件として、線形パスによって実現できることが経験的にわかっています。この観察結果を徹底的に分析し、継続的な学習プロセスにおけるその重要性について説明します。さらに、この発見を利用して、順次学習される最小値がマルチタスクソリューションとして動作するように制約する効果的なアルゴリズムを提案します。私たちの方法が、さまざまなビジョンベンチマークでいくつかの最先端の継続的学習アルゴリズムよりも優れていることを示します。,7.0,https://d3i71xaburhd42.cloudfront.net/9e2084eda22a62be53f9d70ab6628fae7b400e1b/2-Figure1-1.png
Calibration tests beyond classification,"['David Widmann', 'Fredrik Lindsten', 'Dave Zachariah']",https://openreview.net/forum?id=-bxf89v3Nx,"Most supervised machine learning tasks are subject to irreducible prediction
errors. Probabilistic predictive models address this limitation by providing
probability distributions that represent a belief over plausible targets,
rather than point estimates. Such models can be a valuable tool in
decision-making under uncertainty, provided that the model output is
meaningful and interpretable. Calibrated models guarantee that the probabilistic
predictions are neither over- nor under-confident. In the machine learning literature,
different measures and statistical tests have been proposed and studied
for evaluating the calibration of classification models. For
regression problems, however, research has been focused on a weaker
condition of calibration based on predicted quantiles for real-valued targets.
In this paper, we propose the first framework that unifies calibration evaluation and
tests for probabilistic predictive models. It applies to any such model, including
classification and regression models of arbitrary dimension. Furthermore,
the framework generalizes existing measures and provides a more intuitive
reformulation of a recently proposed framework for calibration in
multi-class classification.",ほとんどの教師あり機械学習タスクは、既約の予測エラーの影響を受けます。確率的予測モデルは、点推定ではなく、もっともらしいターゲットに対する信念を表す確率分布を提供することにより、この制限に対処します。このようなモデルは、モデルの出力が意味があり、解釈可能であれば、不確実性の下での意思決定において貴重なツールになり得ます。キャリブレーションされたモデルは、確率的予測が過信でも過小でもないことを保証します。機械学習の文献では、分類モデルのキャリブレーションを評価するために、さまざまな測定値と統計的検定が提案され、研究されています。ただし、回帰問題の場合、実数値のターゲットの予測分位数に基づくキャリブレーションの条件が弱いことに研究が集中しています。この論文では、確率的予測モデルのキャリブレーション評価とテストを統合する最初のフレームワークを提案します。これは、任意の次元の分類および回帰モデルを含む、そのようなモデルに適用されます。さらに、フレームワークは既存の測定値を一般化し、マルチクラス分類でのキャリブレーションのために最近提案されたフレームワークのより直感的な再定式化を提供します。,7.0,
Graph Traversal with Tensor Functionals: A Meta-Algorithm for Scalable Learning,"['Elan Sopher Markowitz', 'Keshav Balasubramanian', 'Mehrnoosh Mirtaheri', 'Sami Abu-El-Haija', 'Bryan Perozzi', 'Greg Ver Steeg', 'Aram Galstyan']",https://openreview.net/forum?id=6DOZ8XNNfGN,"Graph Representation Learning (GRL) methods have impacted fields from chemistry to social science. However, their algorithmic implementations are specialized to specific use-cases e.g. ""message passing"" methods are run differently from ""node embedding"" ones. Despite their apparent differences, all these methods utilize the graph structure,  and therefore, their learning can be approximated with stochastic graph traversals.  We propose Graph Traversal via Tensor Functionals (GTTF), a unifying meta-algorithm framework for easing the implementation of diverse graph algorithms and enabling transparent and efficient scaling to large graphs.  GTTF is founded upon a data structure (stored as a sparse tensor) and a stochastic graph traversal algorithm (described using tensor operations). The algorithm is a functional that accept two functions, and can be specialized to obtain a variety of GRL models and objectives, simply by changing those two functions. We show for a wide class of methods, our algorithm learns in an unbiased fashion and, in expectation, approximates the learning as if the specialized implementations were run directly.
With these capabilities, we scale otherwise non-scalable methods to set state-of-the-art on large graph datasets while being more efficient than existing GRL libraries -- with only a handful of lines of code for each method specialization.",グラフ表現学習（GRL）手法は、化学から社会科学までの分野に影響を与えてきました。ただし、それらのアルゴリズムの実装は特定のユースケースに特化しています。たとえば、「メッセージパッシング」メソッドは「ノード埋め込み」メソッドとは異なる方法で実行されます。それらの明らかな違いにもかかわらず、これらの方法はすべてグラフ構造を利用しているため、それらの学習は確率的グラフ走査で近似できます。テンソル汎関数（GTTF）を介したグラフトラバーサルを提案します。これは、多様なグラフアルゴリズムの実装を容易にし、大きなグラフへの透過的かつ効率的なスケーリングを可能にする統合メタアルゴリズムフレームワークです。 GTTFは、データ構造（スパーステンソルとして格納）と確率的グラフ走査アルゴリズム（テンソル演算を使用して記述）に基づいています。このアルゴリズムは2つの関数を受け入れる関数であり、これら2つの関数を変更するだけで、さまざまなGRLモデルと目的を取得するように特化できます。幅広いクラスのメソッドについて示しますが、アルゴリズムは偏りのない方法で学習し、予想どおり、特殊な実装が直接実行されたかのように学習を近似します。これらの機能を使用して、スケーラブルではないメソッドをスケーリングして、大規模なグラフデータセットに最先端を設定すると同時に、メソッドの特殊化ごとに数行のコードしか持たない既存のGRLライブラリよりも効率的です。,7.0,
Neural ODE Processes,"['Alexander Norcliffe', 'Cristian Bodnar', 'Ben Day', 'Jacob Moss', 'Pietro Liò']",https://openreview.net/forum?id=27acGyyI1BY,"Neural Ordinary Differential Equations (NODEs) use a neural network to model the instantaneous rate of change in the state of a system. However, despite their apparent suitability for dynamics-governed time-series, NODEs present a few disadvantages. First, they are unable to adapt to incoming data-points, a fundamental requirement for real-time applications imposed by the natural direction of time. Second, time-series are often composed of a sparse set of measurements, which could be explained by many possible underlying dynamics. NODEs do not capture this uncertainty. To this end, we introduce Neural ODE Processes (NDPs), a new class of stochastic processes determined by a distribution over Neural ODEs. By maintaining an adaptive data-dependent distribution over the underlying ODE, we show that our model can successfully capture the dynamics of low-dimensional systems from just a few data-points. At the same time, we demonstrate that NDPs scale up to challenging high-dimensional time-series with unknown latent dynamics such as rotating MNIST digits.  ",ニューラル常微分方程式（NODE）は、ニューラルネットワークを使用して、システムの状態の瞬間的な変化率をモデル化します。ただし、ダイナミクスが支配する時系列に明らかに適しているにもかかわらず、NODEにはいくつかの欠点があります。まず、受信データポイントに適応できません。これは、時間の自然な方向によって課せられるリアルタイムアプリケーションの基本的な要件です。第2に、時系列は多くの場合、まばらな測定値のセットで構成されます。これは、考えられる多くの基礎となるダイナミクスによって説明できます。ノードはこの不確実性を捉えません。この目的のために、ニューラルODEプロセス（NDP）を紹介します。これは、ニューラルODE全体の分布によって決定される新しいクラスの確率過程です。基礎となるODE全体に適応性のあるデータ依存の分布を維持することにより、モデルがわずかなデータポイントから低次元システムのダイナミクスを正常にキャプチャできることを示します。同時に、NDPが、回転するMNIST桁など、未知の潜在的なダイナミクスを持つ挑戦的な高次元時系列にスケールアップすることを示します。,7.0,https://d3i71xaburhd42.cloudfront.net/f9dc6861bfe07c0db3d3bcb9d40c47efc816392a/3-Figure1-1.png
Towards Robustness Against Natural Language Word Substitutions,"['Xinshuai Dong', 'Hong Liu', 'Rongrong Ji', 'Anh Tuan Luu']",https://openreview.net/forum?id=ks5nebunVn_,"Robustness against word substitutions has a well-defined and widely acceptable form, i.e., using semantically similar words as substitutions, and thus it is considered as a fundamental stepping-stone towards broader robustness in natural language processing. Previous defense methods capture word substitutions in vector space by using either l_2-ball or hyper-rectangle, which results in perturbation sets that are not inclusive enough or unnecessarily large, and thus impedes mimicry of worst cases for robust training. In this paper, we introduce a novel Adversarial Sparse Convex Combination (ASCC) method. We model the word substitution attack space as a convex hull and leverages a regularization term to enforce perturbation towards an actual substitution, thus aligning our modeling better with the discrete textual space. Based on  ASCC method, we further propose ASCC-defense, which leverages ASCC to generate worst-case perturbations and incorporates adversarial training towards robustness. Experiments show that ASCC-defense outperforms the current state-of-the-arts in terms of robustness on two prevailing NLP tasks, i.e., sentiment analysis and natural language inference, concerning several attacks across multiple model architectures. Besides, we also envision a new class of defense towards robustness in NLP, where our robustly trained word vectors can be plugged into a normally trained model and enforce its robustness without applying any other defense techniques.",単語置換に対するロバスト性は、明確に定義され、広く受け入れられる形式を持っています。つまり、意味的に類似した単語を置換として使用するため、自然言語処理におけるより広範なロバスト性への基本的な足がかりと見なされます。以前の防御方法は、l_2-ballまたはhyper-rectangleのいずれかを使用してベクトル空間の単語置換をキャプチャします。これにより、十分に包括的でないか、不必要に大きい摂動セットが生成され、堅牢なトレーニングの最悪のケースの模倣が妨げられます。この論文では、新しい敵対的スパース凸結合（ASCC）法を紹介します。単語置換攻撃空間を凸包としてモデル化し、正則化項を利用して実際の置換に向けて摂動を強制することで、モデリングを離散テキスト空間とより適切に整合させます。 ASCC法に基づいて、ASCCを活用して最悪の場合の摂動を生成し、堅牢性に向けた敵対的なトレーニングを組み込んだASCC防御をさらに提案します。実験によると、ASCC防御は、複数のモデルアーキテクチャにわたるいくつかの攻撃に関して、2つの一般的なNLPタスク、つまり感情分析と自然言語推論の堅牢性の点で、現在の最先端技術よりも優れています。さらに、NLPの堅牢性に向けた新しいクラスの防御も想定しています。ここでは、堅牢にトレーニングされた単語ベクトルを通常のトレーニング済みモデルにプラグインして、他の防御手法を適用せずにその堅牢性を強化できます。,7.0,
Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels,"['Denis Yarats', 'Ilya Kostrikov', 'Rob Fergus']",https://openreview.net/forum?id=GY6-6sTvGaf,"We propose a simple data augmentation technique that can be applied to standard model-free reinforcement learning algorithms, enabling robust learning directly from pixels without the need for auxiliary losses or pre-training.  The approach leverages input perturbations commonly used in computer vision tasks to transform input examples, as well as regularizing the value function and policy.  Existing model-free approaches, such as Soft Actor-Critic (SAC), are not able to train deep networks effectively from image pixels. However, the addition of our augmentation method dramatically improves SAC’s performance, enabling it to reach state-of-the-art performance on the DeepMind control suite, surpassing model-based (Hafner et al., 2019; Lee et al., 2019; Hafner et al., 2018) methods and recently proposed contrastive learning (Srinivas et al., 2020).  Our approach, which we dub DrQ: Data-regularized Q, can be combined with any model-free reinforcement learning algorithm. We further demonstrate this by applying it to DQN and significantly improve its data-efficiency on the Atari 100k benchmark.",標準のモデルフリー強化学習アルゴリズムに適用できる単純なデータ拡張手法を提案します。これにより、補助損失や事前トレーニングを必要とせずに、ピクセルから直接堅牢な学習が可能になります。このアプローチは、コンピュータービジョンタスクで一般的に使用される入力摂動を活用して、入力例を変換し、値関数とポリシーを正規化します。 Soft Actor-Critic（SAC）などの既存のモデルフリーアプローチでは、画像ピクセルからディープネットワークを効果的にトレーニングすることはできません。ただし、拡張メソッドを追加すると、SACのパフォーマンスが劇的に向上し、モデルベースを超えて、DeepMindコントロールスイートで最先端のパフォーマンスに到達できるようになります（Hafner et al。、2019; Lee et al。、2019; Hafner et al。、2018）方法と最近提案された対照学習（Srinivas et al。、2020）。 DrQ：Data-regularized Qと名付けた私たちのアプローチは、モデルフリーの強化学習アルゴリズムと組み合わせることができます。これをDQNに適用することでさらに実証し、Atari100kベンチマークでのデータ効率を大幅に向上させます。,7.0,
How Does Mixup Help With Robustness and Generalization?,"['Linjun Zhang', 'Zhun Deng', 'Kenji Kawaguchi', 'Amirata Ghorbani', 'James Zou']",https://openreview.net/forum?id=8yKEo06dKNo,"Mixup is a popular data augmentation technique based on on convex combinations of pairs of examples and their labels. This simple technique has shown to substantially improve both the model's robustness as well as the generalization of the trained model. However,  it is not well-understood why such improvement occurs. In this paper, we provide theoretical analysis to demonstrate how using Mixup in training helps model robustness and generalization. For robustness, we show that minimizing the Mixup loss corresponds to approximately minimizing an upper bound of the adversarial loss. This explains why models obtained by Mixup training exhibits robustness to several kinds of adversarial attacks such as Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup augmentation corresponds to a specific type of data-adaptive regularization which reduces overfitting. Our analysis provides new insights and a framework to understand Mixup.
",Mixupは、例のペアとそのラベルの凸結合に基づく一般的なデータ拡張手法です。この単純な手法は、モデルの堅牢性とトレーニング済みモデルの一般化の両方を大幅に改善することを示しています。しかし、なぜそのような改善が起こるのかはよく理解されていません。このホワイトペーパーでは、トレーニングでMixupを使用すると、モデルの堅牢性と一般化にどのように役立つかを示す理論的分析を提供します。堅牢性については、ミックスアップ損失を最小化することが、敵対的損失の上限をほぼ最小化することに対応することを示します。これは、Mixupトレーニングによって取得されたモデルが、Fast Gradient Sign Method（FGSM）などのいくつかの種類の敵対的攻撃に対して堅牢性を示す理由を説明しています。一般化のために、Mixupの拡張が、過剰適合を減らす特定のタイプのデータ適応正則化に対応することを証明します。私たちの分析は、Mixupを理解するための新しい洞察とフレームワークを提供します。,7.0,https://d3i71xaburhd42.cloudfront.net/92ed2e34501903d922d74f28a012d6e337418fa4/2-Figure1-1.png
On the geometry of generalization and memorization in deep neural networks,"['Cory Stephenson', 'suchismita padhy', 'Abhinav Ganesh', 'Yue Hui', 'Hanlin Tang', 'SueYeon Chung']",https://openreview.net/forum?id=V8jrrnwGbuc,"Understanding how large neural networks avoid memorizing training data is key to explaining their high generalization performance. To examine the structure of when and where memorization occurs in a deep network, we use a recently developed replica-based mean field theoretic geometric analysis method. We find that all layers preferentially learn from examples which share features, and link this behavior to generalization performance. Memorization predominately occurs in the deeper layers, due to decreasing object manifolds’ radius and dimension, whereas early layers are minimally affected. This predicts that generalization can be restored by reverting the final few layer weights to earlier epochs before significant memorization occurred, which is confirmed by the experiments. Additionally, by studying generalization under different model sizes, we reveal the connection between the double descent phenomenon and the underlying model geometry. Finally, analytical analysis shows that networks avoid memorization early in training because close to initialization, the gradient contribution from permuted examples are small. These findings provide quantitative evidence for the structure of memorization across layers of a deep neural network, the drivers for such structure, and its connection to manifold geometric properties.
",大規模なニューラルネットワークがトレーニングデータの記憶を回避する方法を理解することは、それらの高い一般化パフォーマンスを説明するための鍵です。深いネットワークでいつどこで記憶が発生するかの構造を調べるために、最近開発されたレプリカベースの平均場理論的幾何学的分析法を使用します。すべてのレイヤーが機能を共有する例から優先的に学習し、この動作を一般化のパフォーマンスにリンクしていることがわかります。オブジェクトの多様体の半径と寸法が減少するため、暗記は主に深い層で発生しますが、初期の層への影響は最小限です。これは、重要な記憶が発生する前に、最後の数層の重みを以前のエポックに戻すことによって一般化を復元できることを予測しています。これは、実験によって確認されています。さらに、さまざまなモデルサイズでの一般化を研究することにより、二重降下現象と基礎となるモデルジオメトリとの関係を明らかにします。最後に、分析分析は、初期化に近く、並べ替えられた例からの勾配の寄与が小さいため、ネットワークがトレーニングの初期に記憶を回避することを示しています。これらの調査結果は、ディープニューラルネットワークのレイヤー全体の記憶の構造、そのような構造のドライバー、および多様体の幾何学的特性への接続の定量的証拠を提供します。,7.0,
"Learning Incompressible Fluid Dynamics from Scratch - Towards Fast, Differentiable Fluid Models that Generalize","['Nils Wandel', 'Michael Weinmann', 'Reinhard Klein']",https://openreview.net/forum?id=KUDUoRsEphu,"Fast and stable fluid simulations are an essential prerequisite for applications ranging from computer-generated imagery to computer-aided design in research and development. However, solving the partial differential equations of incompressible fluids is a challenging task and traditional numerical approximation schemes come at high computational costs. Recent deep learning based approaches promise vast speed-ups but do not generalize to new fluid domains, require fluid simulation data for training, or rely on complex pipelines that outsource major parts of the fluid simulation to traditional methods.

In this work, we propose a novel physics-constrained training approach that generalizes to new fluid domains, requires no fluid simulation data, and allows convolutional neural networks to map a fluid state from time-point t to a subsequent state at time t+dt in a single forward pass. This simplifies the pipeline to train and evaluate neural fluid models. After training, the framework yields models that are capable of fast fluid simulations and can handle various fluid phenomena including the Magnus effect and Kármán vortex streets. We present an interactive real-time demo to show the speed and generalization capabilities of our trained models. Moreover, the trained neural networks are efficient differentiable fluid solvers as they offer a differentiable update step to advance the fluid simulation in time. We exploit this fact in a proof-of-concept optimal control experiment. Our models significantly outperform a recent differentiable fluid solver in terms of computational speed and accuracy.",高速で安定した流体シミュレーションは、コンピューターで生成された画像から研究開発におけるコンピューター支援設計に至るまでのアプリケーションにとって不可欠な前提条件です。ただし、非圧縮性流体の偏微分方程式を解くことは困難な作業であり、従来の数値近似スキームには高い計算コストがかかります。最近のディープラーニングベースのアプローチは、大幅な高速化を約束しますが、新しい流体ドメインに一般化せず、トレーニングに流体シミュレーションデータを必要とし、流体シミュレーションの主要部分を従来の方法にアウトソーシングする複雑なパイプラインに依存します。この作業では、新しい流体ドメインに一般化し、流体シミュレーションデータを必要とせず、畳み込みニューラルネットワークが時点tから時間t + dtの後続の状態に流体状態をマッピングできるようにする新しい物理制約付きトレーニングアプローチを提案します。 1回のフォワードパスで。これにより、神経液モデルをトレーニングおよび評価するためのパイプラインが簡素化されます。トレーニング後、フレームワークは、高速流体シミュレーションが可能で、マグヌス効果やカルマン渦列などのさまざまな流体現象を処理できるモデルを生成します。トレーニング済みモデルの速度と一般化機能を示すために、インタラクティブなリアルタイムデモを紹介します。さらに、訓練されたニューラルネットワークは、流体シミュレーションを時間内に進めるための微分可能な更新ステップを提供するため、効率的な微分可能な流体ソルバーです。この事実を、概念実証の最適制御実験で活用します。私たちのモデルは、計算速度と精度の点で、最近の微分可能な流体ソルバーを大幅に上回っています。,7.0,
Understanding the role of importance weighting for deep learning,"['Da Xu', 'Yuting Ye', 'Chuanwei Ruan']",https://openreview.net/forum?id=_WnwtieRHxM,"The recent paper by Byrd & Lipton (2019), based on empirical observations, raises a major concern on the impact of importance weighting for the over-parameterized deep learning models. They observe that as long as the model can separate the training data, the impact of importance weighting diminishes as the training proceeds. Nevertheless, there lacks a rigorous characterization of this phenomenon. In this paper, we provide formal characterizations and theoretical justifications on the role of importance weighting with respect to the implicit bias of gradient descent and margin-based learning theory. We reveal both the optimization dynamics and generalization performance under deep learning models. Our work not only explains the various novel phenomenons observed for importance weighting in deep learning, but also extends to the studies where the weights are being optimized as part of the model, which applies to a number of topics under active research.",Byrd＆Lipton（2019）による最近の論文は、経験的観察に基づいており、パラメーターが多すぎる深層学習モデルの重要度の重み付けの影響について大きな懸念を提起しています。彼らは、モデルがトレーニングデータを分離できる限り、トレーニングが進むにつれて重要度の重み付けの影響が減少することを観察しています。それにもかかわらず、この現象の厳密な特徴づけはありません。この論文では、勾配降下法とマージンベースの学習理論の暗黙のバイアスに関する重要度の重み付けの役割に関する正式な特性評価と理論的正当化を提供します。深層学習モデルの下での最適化ダイナミクスと一般化パフォーマンスの両方を明らかにします。私たちの仕事は、深層学習における重要度の重み付けで観察されたさまざまな新しい現象を説明するだけでなく、モデルの一部として重みが最適化されている研究にも拡張されます。これは、活発な研究中の多くのトピックに適用されます。,7.0,
Contrastive Divergence Learning is a Time Reversal Adversarial Game,"['Omer Yair', 'Tomer Michaeli']",https://openreview.net/forum?id=MLSvqIHRidA,"Contrastive divergence (CD) learning is a classical method for fitting unnormalized statistical models to data samples. Despite its wide-spread use, the convergence properties of this algorithm are still not well understood. The main source of difficulty is an unjustified approximation which has been used to derive the gradient of the loss. In this paper, we present an alternative derivation of CD that does not require any approximation and sheds new light on the objective that is actually being optimized by the algorithm. Specifically, we show that CD is an adversarial learning procedure, where a discriminator attempts to classify whether a Markov chain generated from the model has been time-reversed. Thus, although predating generative adversarial networks (GANs) by more than a decade, CD is, in fact, closely related to these techniques. Our derivation settles well with previous observations, which have concluded that CD's update steps cannot be expressed as the gradients of any fixed objective function. In addition, as a byproduct, our derivation reveals a simple correction that can be used as an alternative to Metropolis-Hastings rejection, which is required when the underlying Markov chain is inexact (e.g., when using Langevin dynamics with a large step).",対照的発散（CD）学習は、正規化されていない統計モデルをデータサンプルに適合させるための古典的な方法です。広く使用されているにもかかわらず、このアルゴリズムの収束特性はまだよく理解されていません。困難の主な原因は、損失の勾配を導出するために使用されてきた不当な近似です。この論文では、近似を必要とせず、アルゴリズムによって実際に最適化されている目的に新たな光を当てるCDの代替派生を提示します。具体的には、CDが敵対的な学習手順であり、弁別子がモデルから生成されたマルコフ連鎖が時間反転されているかどうかを分類しようとすることを示します。したがって、生成的敵対的ネットワーク（GAN）よりも10年以上前から存在していますが、実際、CDはこれらの手法と密接に関連しています。 CDの更新ステップは、固定された目的関数の勾配として表現できないと結論付けた以前の観察結果と、私たちの導出はうまく一致しています。さらに、副産物として、私たちの導出は、メトロポリス-ヘイスティングス拒絶の代替として使用できる単純な修正を明らかにします。これは、基礎となるマルコフ連鎖が不正確な場合（たとえば、大きなステップでランジュバン動力学を使用する場合）に必要です。,7.0,https://d3i71xaburhd42.cloudfront.net/1a8104680a2b3c03109cbe33fda666876fc90e37/2-Figure1-1.png
Quantifying Differences in Reward Functions,"['Adam Gleave', 'Michael D Dennis', 'Shane Legg', 'Stuart Russell', 'Jan Leike']",https://openreview.net/forum?id=LwEQnp6CYev,"For many tasks, the reward function is too complex to be specified procedurally, and must instead be learned from user data. Prior work has evaluated learned reward functions by examining rollouts from a policy optimized for the learned reward. However, this method cannot distinguish between the learned reward function failing to reflect user preferences, and the reinforcement learning algorithm failing to optimize the learned reward. Moreover, the rollout method is highly sensitive to details of the environment the learned reward is evaluated in, which often differ in the deployment environment. To address these problems, we introduce the Equivalent-Policy Invariant Comparison (EPIC) distance to quantify the difference between two reward functions directly, without training a policy. We prove EPIC is invariant on an equivalence class of reward functions that always induce the same optimal policy. Furthermore, we find EPIC can be precisely approximated and is more robust than baselines to the choice of visitation distribution. Finally, we show that EPIC distance bounds the regret of optimal policies even under different transition dynamics, and confirm empirically that it predicts policy training success. Our source code is available at — double blind: supplementary material —.",多くのタスクでは、報酬関数は複雑すぎて手続き的に指定できず、代わりにユーザーデータから学習する必要があります。以前の作業では、学習した報酬用に最適化されたポリシーからのロールアウトを調べることにより、学習した報酬関数を評価しました。ただし、この方法では、ユーザーの好みを反映できない学習報酬関数と、学習報酬の最適化に失敗する強化学習アルゴリズムを区別できません。さらに、ロールアウト方法は、学習した報酬が評価される環境の詳細に非常に敏感であり、展開環境によって異なることがよくあります。これらの問題に対処するために、Equivalent-Policy Invariant Comparison（EPIC）距離を導入して、ポリシーをトレーニングせずに、2つの報酬関数間の差を直接定量化します。 EPICは、常に同じ最適なポリシーを誘発する同値類の報酬関数に対して不変であることを証明します。さらに、EPICは正確に概算でき、訪問分布の選択に対してベースラインよりも堅牢であることがわかります。最後に、EPIC距離が、さまざまな移行ダイナミクスの下でも最適なポリシーの後悔を制限することを示し、ポリシートレーニングの成功を予測することを経験的に確認します。私たちのソースコードは二重盲検で入手できます：補足資料。,7.0,https://d3i71xaburhd42.cloudfront.net/18f44e605082388ffc0a59b895ff70b01cfc0034/5-Figure1-1.png
"Signatory: differentiable computations of the signature and logsignature transforms, on both CPU and GPU","['Patrick Kidger', 'Terry Lyons']",https://openreview.net/forum?id=lqU2cs3Zca,"Signatory is a library for calculating and performing functionality related to the signature and logsignature transforms. The focus is on machine learning, and as such includes features such as CPU parallelism, GPU support, and backpropagation. To our knowledge it is the first GPU-capable library for these operations. Signatory implements new features not available in previous libraries, such as efficient precomputation strategies. Furthermore, several novel algorithmic improvements are introduced, producing substantial real-world speedups even on the CPU without parallelism. The library operates as a Python wrapper around C++, and is compatible with the PyTorch ecosystem. It may be installed directly via \texttt{pip}. Source code, documentation, examples, benchmarks and tests may be found at \url{https://github.com/[redacted]} (see supplementary material). The license is Apache-2.0.",Signatoryは、署名およびlogsignature変換に関連する機能を計算および実行するためのライブラリです。焦点は機械学習にあり、CPU並列処理、GPUサポート、バックプロパゲーションなどの機能が含まれています。私たちの知る限り、これはこれらの操作のための最初のGPU対応ライブラリです。署名者は、効率的な事前計算戦略など、以前のライブラリでは利用できなかった新機能を実装します。さらに、いくつかの新しいアルゴリズムの改善が導入され、並列処理のないCPUでも実際の速度が大幅に向上します。このライブラリは、C ++のPythonラッパーとして動作し、PyTorchエコシステムと互換性があります。 pipを介して直接インストールできます。ソースコード、ドキュメント、例、ベンチマーク、およびテストは、https：//github.com/ [編集済み]にあります（補足資料を参照）。ライセンスはApache-2.0です。,7.0,https://d3i71xaburhd42.cloudfront.net/f7285e2c409efc62518846102a3afd1291377b0a/8-Figure5.1-1.png
Non-asymptotic Confidence Intervals of Off-policy Evaluation:  Primal and Dual Bounds ,"['Yihao Feng', 'Ziyang Tang', 'na zhang', 'qiang liu']",https://openreview.net/forum?id=dKg5D1Z1Lm,"Off-policy evaluation remains a central challenge in applying reinforcement learning to real-world observational data. Constructing confidence intervals of off-policy estimators can be even more challenging. However, in high-stakes areas such as medical treatment, it is essential to provide rigorous confidence bounds, not just a point estimation, for safety concerns. In this work, we propose a novel approach to constructing non-asymptotic confidence intervals of off-policy evaluation. Our algorithm is highly flexible and can be applied to infinite-horizon reinforcement learning problems with behavior-agnostic data, consisting of dependent transition pairs collected in an arbitrary way. The key idea of our method is taking an optimization-based approach to confidence bounds through a new primal-dual lens, and leveraging a new tight concentration inequality applicable to dependent data. We further present empirical results that clearly demonstrate the advantages of our approach over existing methods. ",ポリシー外の評価は、強化学習を実際の観測データに適用する際の中心的な課題です。ポリシー外の推定量の信頼区間を構築することは、さらに困難な場合があります。ただし、医療などのリスクの高い分野では、安全上の懸念から、点推定だけでなく、厳密な信頼限界を提供することが不可欠です。この作業では、ポリシー外評価の非漸近信頼区間を構築するための新しいアプローチを提案します。私たちのアルゴリズムは非常に柔軟性があり、任意の方法で収集された依存遷移ペアで構成される、行動に依存しないデータを使用した無限ホライズン強化学習問題に適用できます。私たちの方法の重要なアイデアは、新しいプライマルデュアルレンズを介して信頼限界に最適化ベースのアプローチを取り、依存データに適用可能な新しいタイトな濃度の不平等を活用することです。さらに、既存の方法に対する私たちのアプローチの利点を明確に示す経験的結果を提示します。,7.0,
Vector-output ReLU Neural Network Problems are Copositive Programs: Convex Analysis of Two Layer Networks and Polynomial-time Algorithms,"['Arda Sahiner', 'Tolga Ergen', 'John M. Pauly', 'Mert Pilanci']",https://openreview.net/forum?id=fGF8qAqpXXG,"We describe the convex semi-infinite dual of the two-layer vector-output ReLU neural network training problem. This semi-infinite dual admits a finite dimensional representation, but its support is over a convex set which is difficult to characterize. In particular, we demonstrate that the non-convex neural network training problem is equivalent to a finite-dimensional convex copositive program. Our work is the first to identify this strong connection between the global optima of neural networks and those of copositive programs. We thus demonstrate how neural networks implicitly attempt to solve copositive programs via semi-nonnegative matrix factorization, and draw key insights from this formulation. We describe the first algorithms for provably finding the global minimum of the vector output neural network training problem, which are polynomial in the number of samples for a fixed data rank, yet exponential in the dimension. However, in the case of convolutional architectures, the computational complexity is exponential in only the filter size and polynomial in all other parameters. We describe the circumstances in which we can find the global optimum of this neural network training problem exactly with soft-thresholded SVD, and provide a copositive relaxation which is guaranteed to be exact for certain classes of problems, and which corresponds with the solution of Stochastic Gradient Descent in practice.",2層ベクトル出力ReLUニューラルネットワークトレーニング問題の凸型半無限双対について説明します。この半無限のデュアルは、有限の次元表現を認めますが、そのサポートは、特徴付けが難しい凸集合上にあります。特に、非凸型ニューラルネットワークトレーニング問題が有限次元の凸型共正プログラムと同等であることを示します。私たちの仕事は、ニューラルネットワークのグローバルな最適化と共陽性プログラムの最適化との間のこの強い関係を特定した最初のものです。したがって、ニューラルネットワークがセミ非負行列因子分解を介して共陽性プログラムを暗黙的に解決しようとする方法を示し、この定式化から重要な洞察を引き出します。ベクトル出力ニューラルネットワークトレーニング問題のグローバル最小値を証明可能に見つけるための最初のアルゴリズムについて説明します。これは、固定データランクのサンプル数では多項式でありながら、次元では指数関数的です。ただし、畳み込みアーキテクチャの場合、計算の複雑さは、他のすべてのパラメーターのフィルターサイズと多項式でのみ指数関数的になります。このニューラルネットワークトレーニング問題のグローバル最適値をソフトしきい値SVDで正確に見つけることができる状況を説明し、特定のクラスの問題に対して正確であることが保証され、確率的解法に対応する共正緩和を提供します。実際の勾配降下法。,7.0,https://d3i71xaburhd42.cloudfront.net/64f43269ae578931f74f0f22708eb6443df120e6/8-Figure1-1.png
Tomographic Auto-Encoder: Unsupervised Bayesian Recovery of Corrupted Data,"['Francesco Tonolini', 'Andreas Damianou', 'Pablo Garcia Moreno', 'Roderick Murray-Smith']",https://openreview.net/forum?id=YtMG5ex0ou,"We propose a new probabilistic method for unsupervised recovery of corrupted data. Given a large ensemble of degraded samples, our method recovers accurate posteriors of clean values, allowing the exploration of the manifold of possible reconstructed data and hence characterising the underlying uncertainty. In this set-ting, direct application of classical variational methods often gives rise to collapsed densities that do not adequately explore the solution space.  Instead, we derive our novel reduced entropy condition approximate inference method that results in rich posteriors.  We test our model in a data recovery task under the common setting of missing values and noise, demonstrating superior performance to existing variational methods for imputation and de-noising with different real data sets. We further show higher classification accuracy after imputation, proving the advantage of propagating uncertainty to downstream tasks with our model.",破損したデータの教師なし回復のための新しい確率的手法を提案します。劣化したサンプルの大規模なアンサンブルが与えられると、私たちの方法はクリーンな値の正確な事後確率を回復し、可能な再構築データの多様性の調査を可能にし、したがって根本的な不確実性を特徴付けます。この設定では、古典的な変分法を直接適用すると、密度が崩壊し、解空間を適切に探索できないことがよくあります。代わりに、豊富な事後確率をもたらす新しい縮小エントロピー条件近似推論法を導き出します。欠測値とノイズの一般的な設定の下でデータ回復タスクでモデルをテストし、さまざまな実データセットを使用した代入とノイズ除去の既存の変分法よりも優れたパフォーマンスを示します。さらに、代入後の分類精度が高いことを示し、モデルを使用して下流のタスクに不確定性を伝播する利点を証明します。,7.0,https://d3i71xaburhd42.cloudfront.net/f8d73165f7c27e36283621117fb6ecaa51f73d06/2-Figure1-1.png
PseudoSeg: Designing Pseudo Labels for Semantic Segmentation,"['Yuliang Zou', 'Zizhao Zhang', 'Han Zhang', 'Chun-Liang Li', 'Xiao Bian', 'Jia-Bin Huang', 'Tomas Pfister']",https://openreview.net/forum?id=-TwO99rbVRu,"Recent advances in semi-supervised learning (SSL) demonstrate that a combination of consistency regularization and pseudo-labeling can effectively improve image classification accuracy in the low-data regime. Compared to classification, semantic segmentation tasks require much more intensive labeling costs. Thus, these tasks greatly benefit from data-efficient training methods. However, structured outputs in segmentation render particular difficulties (e.g., designing pseudo-labeling and augmentation) to apply existing SSL strategies. To address this problem, we present a simple and novel re-design of pseudo-labeling to generate well-calibrated structured pseudo labels for training with unlabeled or weakly-labeled data. Our proposed pseudo-labeling strategy is network structure agnostic to apply in a one-stage consistency training framework. We demonstrate the effectiveness of the proposed pseudo-labeling strategy in both low-data and high-data regimes. Extensive experiments have validated that pseudo labels generated from wisely fusing diverse sources and strong data augmentation are crucial to consistency training for segmentation. The source code will be released.",半教師あり学習（SSL）の最近の進歩は、一貫性の正則化と疑似ラベリングの組み合わせにより、低データ領域での画像分類の精度を効果的に向上できることを示しています。分類と比較して、セマンティックセグメンテーションタスクははるかに集中的なラベリングコストを必要とします。したがって、これらのタスクは、データ効率の高いトレーニング方法から大きな恩恵を受けます。ただし、セグメンテーションの構造化された出力は、既存のSSL戦略を適用するのに特定の困難をもたらします（たとえば、疑似ラベリングと拡張の設計）。この問題に対処するために、疑似ラベルのシンプルで斬新な再設計を提示し、ラベルなしまたは弱ラベルのデータを使用してトレーニングするための、適切に調整された構造化疑似ラベルを生成します。私たちが提案する疑似ラベリング戦略は、ネットワーク構造にとらわれず、1段階の整合性トレーニングフレームワークに適用されます。低データと高データの両方の体制で提案された疑似ラベリング戦略の有効性を示します。広範な実験により、多様なソースを賢く融合して生成された疑似ラベルと強力なデータ拡張が、セグメンテーションの一貫性トレーニングに不可欠であることが検証されました。ソースコードが公開されます。,7.0,
Model-Based Visual Planning with Self-Supervised Functional Distances,"['Stephen Tian', 'Suraj Nair', 'Frederik Ebert', 'Sudeep Dasari', 'Benjamin Eysenbach', 'Chelsea Finn', 'Sergey Levine']",https://openreview.net/forum?id=UcoXdfrORC,"A generalist robot must be able to complete a variety of tasks in its environment. One appealing way to specify each task is in terms of a goal observation. However, learning goal-reaching policies with reinforcement learning remains a challenging problem, particularly when rewards are not provided and $\ell_2$ distances in pixel space are not meaningful. Learned dynamics models are a promising approach for learning about the environment without rewards or task-directed data, but planning to reach goals with such a model requires a notion of functional similarity between observations and goal states. We present a self-supervised method for model-based visual goal reaching, which uses both a visual dynamics model as well as a dynamical distance function learned using model-free reinforcement learning. This approach trains entirely using offline, unlabeled data, making it practical to scale to large and diverse datasets. On several challenging robotic manipulation tasks with only offline, unlabeled data, we find that our algorithm compares favorably to prior model-based and model-free reinforcement learning methods. In ablation experiments, we additionally identify important factors for learning effective distances.",ジェネラリストロボットは、その環境でさまざまなタスクを完了できる必要があります。各タスクを指定する魅力的な方法の1つは、目標の観察に関するものです。ただし、強化学習を使用して目標達成ポリシーを学習することは、特に報酬が提供されず、ピクセル空間でのl2距離が意味をなさない場合、依然として困難な問題です。学習したダイナミクスモデルは、報酬やタスク指向のデータなしで環境について学習するための有望なアプローチですが、そのようなモデルで目標を達成するための計画には、観測と目標状態の間の機能的類似性の概念が必要です。モデルベースの視覚的目標到達のための自己教師あり方法を提示します。これは、視覚的ダイナミクスモデルと、モデルフリー強化学習を使用して学習した動的距離関数の両方を使用します。このアプローチは、オフラインのラベルなしデータを完全に使用してトレーニングを行うため、大規模で多様なデータセットへのスケーリングが実用的です。オフラインのラベルなしデータのみを使用するいくつかの挑戦的なロボット操作タスクでは、私たちのアルゴリズムが以前のモデルベースおよびモデルフリーの強化学習方法と比べて遜色がないことがわかりました。アブレーション実験では、有効距離を学習するための重要な要素をさらに特定します。,7.0,https://d3i71xaburhd42.cloudfront.net/9a689727d040a6bf122f16ea50884d5cd5258321/2-Figure1-1.png
A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels,"['Leon Lang', 'Maurice Weiler']",https://openreview.net/forum?id=ajOrOhQOsYx,"Group equivariant convolutional networks (GCNNs) endow classical convolutional networks with additional symmetry priors, which can lead to a considerably improved performance. Recent advances in the theoretical description of GCNNs revealed that such models can generally be understood as performing convolutions with $G$-steerable kernels, that is, kernels that satisfy an equivariance constraint themselves. While the $G$-steerability constraint has been derived, it has to date only been solved for specific use cases - a general characterization of $G$-steerable kernel spaces is still missing. This work provides such a characterization for the practically relevant case of $G$ being any compact group. Our investigation is motivated by a striking analogy between the constraints underlying steerable kernels on the one hand and spherical tensor operators from quantum mechanics on the other hand. By generalizing the famous Wigner-Eckart theorem for spherical tensor operators, we prove that steerable kernel spaces are fully understood and parameterized in terms of 1) generalized reduced matrix elements, 2) Clebsch-Gordan coefficients, and 3) harmonic basis functions on homogeneous spaces.",グループ同変畳み込みネットワーク（GCNN）は、古典的な畳み込みネットワークに追加の対称性の事前分布を与えます。これにより、パフォーマンスが大幅に向上する可能性があります。 GCNNの理論的記述における最近の進歩により、そのようなモデルは一般に、Gステアリング可能なカーネル、つまり、それ自体が同変制約を満たすカーネルで畳み込みを実行するものとして理解できることが明らかになりました。 G-steerability制約が導出されましたが、これまでのところ、特定のユースケースでのみ解決されています。G-steerableカーネルスペースの一般的な特性はまだ欠落しています。この作業は、Gが任意のコンパクト群であるという実際に関連するケースにそのような特性を提供します。私たちの調査は、一方では操縦可能なカーネルの根底にある制約と、他方では量子力学からの球形テンソル演算子との間の顕著な類似性によって動機付けられています。球形テンソル演算子の有名なウィグナーエッカート定理を一般化することにより、操縦可能なカーネル空間が1）一般化された縮小行列要素、2）クレブシュ-ゴルダン係数、および3）等質空間の調和基底関数に関して完全に理解されパラメーター化されることを証明します。,7.0,
Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval,"['Lee Xiong', 'Chenyan Xiong', 'Ye Li', 'Kwok-Fung Tang', 'Jialin Liu', 'Paul N. Bennett', 'Junaid Ahmed', 'Arnold Overwikj']",https://openreview.net/forum?id=zeFrfgyZln,"Conducting text retrieval in a dense representation space has many intriguing advantages. Yet the end-to-end learned dense retrieval (DR) often underperforms  word-based sparse retrieval. In this paper, we first theoretically show the learning bottleneck of dense retrieval is due to the domination of uninformative negatives sampled locally in batch, which yield diminishing gradient norms, large stochastic gradient variances, and slow learning convergence. We then propose Approximate nearest neighbor Negative Contrastive Learning (ANCE), a learning mechanism that selects hard training negatives globally from the entire corpus, using an asynchronously updated ANN index. Our experiments demonstrate the effectiveness of ANCE on web search, question answering, and in a commercial search environment, showing ANCE dot-product retrieval nearly matches the accuracy of BERT-based cascade IR pipeline, while being 100x more efficient. We also empirically validate our theory that negative sampling with ANCE better approximates the oracle gradient-norm based importance sampling, thus improves the convergence of stochastic training.",密集した表現空間でテキスト検索を実行することには、多くの興味深い利点があります。それでも、エンドツーエンドの学習済み高密度検索（DR）は、単語ベースのスパース検索よりもパフォーマンスが低いことがよくあります。この論文では、最初に、密な検索の学習のボトルネックが、バッチでローカルにサンプリングされた情報のないネガティブの支配によるものであることを理論的に示します。これにより、勾配ノルムが減少し、確率的勾配分散が大きくなり、学習の収束が遅くなります。次に、非同期に更新されたANNインデックスを使用して、コーパス全体からハードトレーニングネガをグローバルに選択する学習メカニズムである近似最近傍ネガティブ対照学習（ANCE）を提案します。私たちの実験は、Web検索、質問応答、および商用検索環境でのANCEの有効性を示しており、ANCEドット積検索はBERTベースのカスケードIRパイプラインの精度とほぼ一致し、100倍効率的であることを示しています。また、ANCEを使用した負のサンプリングは、オラクルの勾配ノルムベースの重要度サンプリングをより適切に近似し、確率的トレーニングの収束を改善するという理論を経験的に検証します。,7.0,https://d3i71xaburhd42.cloudfront.net/c9b8593db099869fe7254aa1fa53f3c9073b0176/2-Figure1-1.png
Graph-Based Continual Learning,"['Binh Tang', 'David S. Matteson']",https://openreview.net/forum?id=HHSEKOnPvaO,"Despite significant advances, continual learning models still suffer from catastrophic forgetting when exposed to incrementally available data from non-stationary distributions. Rehearsal approaches alleviate the problem by maintaining and replaying a small episodic memory of previous samples, often implemented as an array of independent memory slots. In this work, we propose to augment such an array with a learnable random graph that captures pairwise similarities between its samples, and use it not only to learn new tasks but also to guard against forgetting. Empirical results on several benchmark datasets show that our model consistently outperforms recently proposed baselines for task-free continual learning.",大幅な進歩にもかかわらず、継続的な学習モデルは、非定常分布から段階的に利用可能なデータにさらされると、壊滅的な忘却に悩まされます。リハーサルアプローチは、以前のサンプルの小さなエピソード記憶を維持および再生することによって問題を軽減します。これは、多くの場合、独立したメモリスロットの配列として実装されます。この作業では、サンプル間のペアワイズ類似性をキャプチャする学習可能なランダムグラフでこのような配列を拡張し、新しいタスクを学習するだけでなく、忘却を防ぐためにも使用することを提案します。いくつかのベンチマークデータセットでの経験的結果は、私たちのモデルが、タスクフリーの継続学習のために最近提案されたベースラインを一貫して上回っていることを示しています。,7.0,https://d3i71xaburhd42.cloudfront.net/45a8b9a22a9794f2a586a4ffc006058625b7327e/2-Figure1-1.png
On the Universality of Rotation Equivariant Point Cloud Networks,"['Nadav Dym', 'Haggai Maron']",https://openreview.net/forum?id=6NFBvWlRXaG,"Learning functions on point clouds has applications in many fields, including computer vision, computer graphics, physics, and chemistry. Recently, there has been a growing interest in neural architectures that are invariant or equivariant to all three shape-preserving transformations of point clouds: translation, rotation, and permutation. In this paper, we present a first study of the approximation power of these architectures. We first derive two sufficient conditions for an equivariant architecture to have the universal approximation property, based on a novel characterization of the space of equivariant polynomials. We then use these conditions to show that two recently suggested models, Tensor field Networks and SE3-Transformers, are universal, and for devising two other novel universal architectures.",点群での学習機能は、コンピュータービジョン、コンピューターグラフィックス、物理学、化学など、多くの分野で応用されています。最近、点群の3つの形状保存変換（平行移動、回転、順列）すべてに対して不変または同変であるニューラルアーキテクチャへの関心が高まっています。この論文では、これらのアーキテクチャの近似力に関する最初の研究を紹介します。最初に、同変多項式の空間の新しい特性に基づいて、同変アーキテクチャが普遍近似特性を持つための2つの十分条件を導き出します。次に、これらの条件を使用して、最近提案された2つのモデル、テンソル場ネットワークとSE3-トランスフォーマーがユニバーサルであることを示し、他の2つの新しいユニバーサルアーキテクチャを考案します。,7.0,
"GAN ""Steerability"" without optimization ","['Nurit Spingarn', 'Ron Banner', 'Tomer Michaeli']",https://openreview.net/forum?id=zDy_nQCXiIj,"Recent research has shown remarkable success in revealing `""steering"" directions in the latent spaces of pre-trained GANs. These directions correspond to semantically meaningful image transformations (e.g., shift, zoom, color manipulations), and have the same interpretable effect across all categories that the GAN can generate. Some methods focus on user-specified transformations, while others discover transformations in an unsupervised manner. However, all existing techniques rely on an optimization procedure to expose those directions, and offer no control over the degree of allowed interaction between different transformations. In this paper, we show that ``""steering"" trajectories can be computed in closed form directly from the generator's weights without any form of training or optimization. This applies to user-prescribed geometric transformations, as well as to unsupervised discovery of more complex effects. Our approach allows determining both linear and nonlinear trajectories, and has many advantages over previous methods. In particular, we can control whether one transformation is allowed to come on the expense of another (e.g., zoom-in with or without allowing translation to keep the object centered). Moreover, we can determine the natural end-point of the trajectory, which corresponds to the largest extent to which a transformation can be applied without incurring degradation. Finally, we show how transferring attributes between images can be achieved without optimization, even across different categories.",最近の研究では、事前に訓練されたGANの潜在空間における「ステアリング」の方向を明らかにすることに目覚ましい成功を収めています。これらの方向は、意味的に意味のある画像変換（シフト、ズーム、色操作など）に対応し、GANが生成できるすべてのカテゴリで同じ解釈可能な効果があります。ユーザー指定の変換に焦点を当てる方法もあれば、教師なしの方法で変換を検出する方法もあります。ただし、既存のすべての手法は、これらの方向を明らかにするために最適化手順に依存しており、異なる変換間で許可される相互作用の程度を制御することはできません。この論文では、「ステアリング」軌道が、トレーニングや最適化の形式なしで、発電機の重みから直接閉じた形式で計算できることを示します。これは、ユーザーが指定した幾何学的変換、およびより複雑な効果の教師なし発見に適用されます。私たちのアプローチは、線形と非線形の両方の軌道を決定することを可能にし、以前の方法に比べて多くの利点があります。特に、ある変換が別の変換を犠牲にして許可されるかどうかを制御できます（たとえば、オブジェクトを中央に保持するための変換を許可するかどうかに関係なくズームインします）。さらに、軌道の自然な終点を決定できます。これは、劣化を招くことなく変換を適用できる最大の範囲に対応します。最後に、異なるカテゴリ間でも、最適化なしで画像間で属性を転送する方法を示します。,7.0,
Practical Real Time Recurrent Learning with a Sparse Approximation,"['Jacob Menick', 'Erich Elsen', 'Utku Evci', 'Simon Osindero', 'Karen Simonyan', 'Alex Graves']",https://openreview.net/forum?id=q3KSThy2GwB,"Recurrent neural networks are usually trained with backpropagation through time, which requires storing a complete history of network states, and prohibits updating the weights ""online"" (after every timestep). Real Time Recurrent Learning (RTRL) eliminates the need for history storage and allows for online weight updates, but does so at the expense of computational costs that are quartic in the state size. This renders RTRL training intractable for all but the smallest networks, even ones that are made highly sparse.
We introduce the Sparse n-step Approximation (SnAp) to the RTRL influence matrix. SnAp only tracks the influence of a parameter on hidden units that are reached by the computation graph within $n$ timesteps of the recurrent core. SnAp with $n=1$ is no more expensive than backpropagation but allows training on arbitrarily long sequences. We find that it substantially outperforms other RTRL approximations with comparable costs such as Unbiased Online Recurrent Optimization. For highly sparse networks, SnAp with $n=2$ remains tractable and can outperform backpropagation through time in terms of learning speed when updates are done online.",リカレントニューラルネットワークは通常、時間の経過に伴う逆伝播でトレーニングされます。これには、ネットワーク状態の完全な履歴を保存する必要があり、重みを「オンライン」で更新することは禁止されています（すべてのタイムステップの後）。 Real Time Recurrent Learning（RTRL）は、履歴ストレージの必要性を排除し、オンラインの重みの更新を可能にしますが、州のサイズで四次の計算コストを犠牲にして行います。これにより、RTRLトレーニングは、非常にスパースにされたネットワークであっても、最小のネットワークを除くすべてのネットワークで扱いにくくなります。スパースnステップ近似（SnAp）をRTRL影響行列に導入します。 SnApは、反復コアのnタイムステップ内に計算グラフが到達する非表示ユニットに対するパラメーターの影響のみを追跡します。 n = 1のSnApは、バックプロパゲーションよりもコストがかかりませんが、任意の長さのシーケンスでトレーニングできます。 Unbiased Online Recurrent Optimizationなどの同等のコストで、他のRTRL近似を大幅に上回っています。非常にスパースなネットワークの場合、n = 2のSnApは扱いやすく、更新がオンラインで行われる場合の学習速度の点で、時間の経過とともにバックプロパゲーションを上回る可能性があります。,7.0,
An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,"['Alexey Dosovitskiy', 'Lucas Beyer', 'Alexander Kolesnikov', 'Dirk Weissenborn', 'Xiaohua Zhai', 'Thomas Unterthiner', 'Mostafa Dehghani', 'Matthias Minderer', 'Georg Heigold', 'Sylvain Gelly', 'Jakob Uszkoreit', 'Neil Houlsby']",https://openreview.net/forum?id=YicbFdNTTy,"While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",Transformerアーキテクチャーは自然言語処理タスクの事実上の標準になっていますが、コンピュータービジョンへの適用は限られています。ビジョンでは、注意は畳み込みネットワークと組み合わせて適用されるか、全体的な構造を維持しながら畳み込みネットワークの特定のコンポーネントを置き換えるために使用されます。このCNNへの依存は不要であり、画像パッチのシーケンスに直接適用される純粋なトランスフォーマーは、画像分類タスクで非常にうまく機能することを示します。大量のデータについて事前にトレーニングし、複数の中規模または小規模の画像認識ベンチマーク（ImageNet、CIFAR-100、VTABなど）に転送すると、Vision Transformer（ViT）は最新の状態と比較して優れた結果を達成します。トレーニングに必要な計算リソースを大幅に削減しながら、畳み込みネットワークを構築します。,7.0,https://d3i71xaburhd42.cloudfront.net/7b15fa1b8d413fbe14ef7a97f651f47f5aff3903/3-Figure1-1.png
Neural gradients are near-lognormal: improved quantized  and sparse training,"['Brian Chmiel', 'Liad Ben-Uri', 'Moran Shkolnik', 'Elad Hoffer', 'Ron Banner', 'Daniel Soudry']",https://openreview.net/forum?id=EoFNy62JGd,"While training can mostly be accelerated by reducing the time needed to propagate neural gradients (loss gradients with respect to the intermediate neural layer outputs) back throughout the model, most previous works focus on the quantization/pruning of weights and activations. These methods are often not applicable to neural gradients, which have very different statistical properties. Distinguished from weights and activations, we find that the distribution of neural gradients is approximately lognormal. Considering this, we suggest two closed-form analytical methods to reduce the computational and memory burdens of neural gradients. The first method optimizes the floating-point format and scale of the gradients. The second method accurately sets sparsity thresholds for gradient pruning.  Each method achieves state-of-the-art results on ImageNet. To the best of our knowledge, this paper is the first to (1) quantize the gradients to 6-bit floating-point formats, or (2) achieve up to 85% gradient sparsity --- in each case without accuracy degradation.
Reference implementation accompanies the paper in the supplementary material.",トレーニングは、神経勾配（中間神経層出力に関する損失勾配）をモデル全体に​​伝播するために必要な時間を短縮することでほとんど加速できますが、これまでのほとんどの作業は、重みとアクティブ化の量子化/剪定に焦点を当てています。これらの方法は、統計的特性が大きく異なる神経勾配には適用できないことがよくあります。重みと活性化とは区別され、神経勾配の分布はほぼ対数正規であることがわかります。これを考慮して、神経勾配の計算とメモリの負担を軽減するために、2つの閉形式の解析方法を提案します。最初の方法は、浮動小数点形式とグラデーションのスケールを最適化します。 2番目の方法は、勾配剪定のスパース性しきい値を正確に設定します。それぞれの方法は、ImageNetで最先端の結果を達成します。私たちの知る限り、このペーパーは、（1）勾配を6ビット浮動小数点形式に量子化する、または（2）補足資料のペーパーに付随する最大85のリファレンス実装を実現する最初のものです。,7.0,
The inductive bias of ReLU networks on orthogonally separable data,"['Mary Phuong', 'Christoph H Lampert']",https://openreview.net/forum?id=krz7T0xU9Z_,"We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.
The proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.
",勾配流によって訓練された2層ReLUネットワークの誘導バイアスを研究します。学習しやすい（直交的に分離可能な）データセットのクラスを識別し、そのようなデータセットでトレーニングされたReLUネットワークが収束するソリューションを特徴付けます。ネットワーク幅に関係なく、ソリューションは2つの最大マージン分類器の組み合わせであることがわかります。1つは正のデータサブセットに対応し、もう1つは負のデータサブセットに対応します。この証明は、最近導入された極値セクターの概念に基づいており、直交分離可能性のコンテキストでいくつかのプロパティを証明します。特に、ある時点T以降のアクティブ化パターンの定常性を証明します。これにより、ReLUネットワークを線形サブネットワークのアンサンブルに縮小できます。,7.0,
Private Post-GAN Boosting,"['Marcel Neunhoeffer', 'Steven Wu', 'Cynthia Dwork']",https://openreview.net/forum?id=6isfR3JCbi,"Differentially private GANs have proven to be a promising approach for generating realistic synthetic data without compromising the privacy of individuals. Due to the privacy-protective noise introduced in the  training, the convergence of GANs becomes even more elusive, which often leads to poor utility in the output generator at the end of training. We propose Private post-GAN boosting (Private PGB), a differentially private method that combines samples produced by the sequence of generators obtained during GAN training to create a high-quality synthetic dataset. To that end, our method leverages the Private Multiplicative Weights method (Hardt and Rothblum, 2010) to reweight generated samples. We evaluate Private PGB on two dimensional toy data, MNIST images, US Census data and a standard machine learning prediction task. Our experiments show that Private PGB improves upon a standard private GAN approach across a collection of quality measures. We also provide a non-private variant of PGB that improves the data quality of standard GAN training.",差分プライベートGANは、個人のプライバシーを損なうことなく現実的な合成データを生成するための有望なアプローチであることが証明されています。トレーニングで導入されたプライバシー保護ノイズのために、GANの収束はさらにわかりにくくなり、トレーニングの最後に出力ジェネレーターの有用性が低下することがよくあります。プライベートポストGANブースティング（プライベートPGB）を提案します。これは、GANトレーニング中に取得されたジェネレーターのシーケンスによって生成されたサンプルを組み合わせて、高品質の合成データセットを作成する差分プライベートメソッドです。そのために、私たちの方法は、Private Multiplicative Weights法（Hardt and Rothblum、2010）を利用して、生成されたサンプルを再重み付けします。 2次元のおもちゃデータ、MNIST画像、米国国勢調査データ、および標準的な機械学習予測タスクでプライベートPGBを評価します。私たちの実験は、プライベートPGBが、品質測定のコレクション全体で標準のプライベートGANアプローチを改善することを示しています。また、標準のGANトレーニングのデータ品質を向上させるPGBの非プライベートバリアントも提供しています。,7.0,https://d3i71xaburhd42.cloudfront.net/34ceeaef8f0569ca107b72622c14cbec15bf778f/7-Figure1-1.png
A statistical theory of cold posteriors in deep neural networks,['Laurence Aitchison'],https://openreview.net/forum?id=Rd138pWXMvG,"To get Bayesian neural networks to perform comparably to standard neural networks it is usually necessary to artificially reduce uncertainty using a tempered or cold posterior. This is extremely concerning: if the prior is accurate, Bayes inference/decision theory is optimal, and any artificial changes to the posterior should harm performance. While this suggests that the prior may be at fault, here we argue that in fact, BNNs for image classification use the wrong likelihood. In particular, standard image benchmark datasets such as CIFAR-10 are carefully curated. We develop a generative model describing curation which gives a principled Bayesian account of cold posteriors, because the likelihood under this new generative model closely matches the tempered likelihoods used in past work.",ベイジアンニューラルネットワークを標準のニューラルネットワークと同等に機能させるには、通常、強化またはコールド事後確率を使用して不確実性を人為的に低減する必要があります。これは非常に懸念されます。事前確率が正確である場合、ベイズ推定/決定理論が最適であり、後方への人為的な変更はパフォーマンスに悪影響を与えるはずです。これは、事前分布に誤りがある可能性があることを示唆していますが、ここでは、実際、画像分類のBNNが誤った尤度を使用していると主張します。特に、CIFAR-10などの標準的な画像ベンチマークデータセットは慎重にキュレーションされています。この新しい生成モデルの下での尤度は、過去の作業で使用された緩和された尤度と厳密に一致するため、コールド事後確率の原理的なベイズの説明を与えるキュレーションを記述する生成モデルを開発します。,7.0,
Calibration of Neural Networks using Splines,"['Kartik Gupta', 'Amir Rahimi', 'Thalaiyasingam Ajanthan', 'Thomas Mensink', 'Cristian Sminchisescu', 'Richard Hartley']",https://openreview.net/forum?id=eQe8DEWNN2W,"Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures.",ニューラルネットワークのキャリブレーションは、ダウンストリームの意思決定が予測される確率に依存するセーフティクリティカルなアプリケーションでニューラルネットワークを使用する場合に最も重要です。キャリブレーションエラーの測定は、2つの経験分布を比較することになります。この作業では、主なアイデアがそれぞれの累積確率分布を比較することである、古典的なコルモゴロフ-スミルノフ（KS）統計テストに触発されたビニングフリーのキャリブレーション測定を紹介します。これから、スプラインを介した微分可能関数を使用して経験的累積分布を近似することにより、ネットワーク出力を実際の（キャリブレーションされた）クラス割り当て確率にマッピングする再キャリブレーション関数を取得します。スプラインフィッティングは、差し出されたキャリブレーションセットを使用して実行され、取得された再キャリブレーション関数は、見えないテストセットで評価されます。さまざまな画像分類データセットで既存のキャリブレーションアプローチに対してメソッドをテストしました。スプラインベースの再キャリブレーションアプローチは、KSエラーやその他の一般的に使用されるキャリブレーション測定で既存のメソッドよりも一貫して優れています。,7.0,https://d3i71xaburhd42.cloudfront.net/3ad55bd9f6b9cc125a354b121cc39ac69521b7e1/5-Figure1-1.png
Neural Pruning via Growing Regularization,"['Huan Wang', 'Can Qin', 'Yulun Zhang', 'Yun Fu']",https://openreview.net/forum?id=o966_Is_nPA,"Regularization has long been utilized to learn sparsity in deep neural network pruning. However, its role is mainly explored in the small penalty strength regime. In this work, we extend its application to a new scenario where the regularization grows large gradually to tackle two central problems of pruning: pruning schedule and weight importance scoring. (1) The former topic is newly brought up in this work, which we find critical to the pruning performance while receives little research attention. Specifically, we propose an L2 regularization variant with rising penalty factors and show it can bring significant accuracy gains compared with its
one-shot counterpart, even when the same weights are removed. (2) The growing penalty scheme also brings us an approach to exploit the Hessian information for more accurate pruning without knowing their specific values, thus not bothered by the common Hessian approximation problems. Empirically, the proposed algorithms are easy to implement and scalable to large datasets and networks in both structured and unstructured pruning. Their effectiveness is demonstrated with modern deep neural networks on the CIFAR and ImageNet datasets, achieving competitive results compared to many state-of-the-art algorithms.",正則化は、ディープニューラルネットワークの剪定におけるスパース性を学習するために長い間利用されてきました。ただし、その役割は主に小さなペナルティ強度体制で検討されています。この作業では、正則化が徐々に大きくなる新しいシナリオにアプリケーションを拡張して、剪定の2つの中心的な問題である剪定スケジュールと重みの重要度のスコアリングに取り組みます。 （1）前者のトピックは、この作業で新たに取り上げられます。これは、研究の注目をほとんど受けずに、剪定のパフォーマンスにとって重要であることがわかります。具体的には、ペナルティ係数が上昇するL2正則化バリアントを提案し、同じ重みが削除された場合でも、ワンショットの対応物と比較して大幅な精度の向上をもたらすことができることを示します。 （2）増大するペナルティスキームは、特定の値を知らなくても、より正確な剪定のためにヘッセ情報を利用するアプローチをもたらします。したがって、一般的なヘッセ近似問題に悩まされることはありません。経験的に、提案されたアルゴリズムは実装が簡単で、構造化および非構造化プルーニングの両方で大規模なデータセットとネットワークにスケーラブルです。それらの有効性は、CIFARおよびImageNetデータセットの最新のディープニューラルネットワークで実証されており、多くの最先端のアルゴリズムと比較して競争力のある結果を達成しています。,7.0,https://d3i71xaburhd42.cloudfront.net/400080a724d55bbdd3cfc1c54f0aae6af4ec7879/7-Figure1-1.png
ARMOURED: Adversarially Robust MOdels using Unlabeled data by REgularizing Diversity,"['Kangkang Lu', 'Cuong Manh Nguyen', 'Xun Xu', 'Kiran Chari', 'Yu Jing Goh', 'Chuan-Sheng Foo']",https://openreview.net/forum?id=JoCR4h9O3Ew,"Adversarial attacks pose a major challenge for modern deep neural networks. Recent advancements show that adversarially robust generalization requires a huge amount of labeled data for training. If annotation becomes a burden, can unlabeled data help bridge the gap? In this paper, we propose ARMOURED, an adversarially robust training method based on semi-supervised learning that consists of two components. The first component applies multi-view learning to simultaneously optimize multiple independent networks and utilizes unlabeled data to enforce labeling consistency. The second component reduces adversarial transferability among the networks via diversity regularizers inspired by determinantal point processes and entropy maximization. Experimental results show that under small perturbation budgets, ARMOURED is robust against strong adaptive adversaries. Notably, ARMOURED does not rely on generating adversarial samples during training. When used in combination with adversarial training, ARMOURED achieves state-of-the-art robustness against $\ell_\infty$ and $\ell_2$ attacks for a range of perturbation budgets, while maintaining high accuracy on clean samples. We demonstrate the robustness of ARMOURED on CIFAR-10 and SVHN datasets against state-of-the-art benchmarks in adversarial robust training.",敵対的攻撃は、現代のディープニューラルネットワークに大きな課題をもたらします。最近の進歩は、敵対的にロバストな一般化がトレーニングのために大量のラベル付きデータを必要とすることを示しています。注釈が負担になる場合、ラベルのないデータはギャップを埋めるのに役立ちますか？この論文では、2つのコンポーネントで構成される半教師あり学習に基づく敵対的にロバストなトレーニング方法であるARMOUREDを提案します。最初のコンポーネントは、マルチビュー学習を適用して複数の独立したネットワークを同時に最適化し、ラベルのないデータを利用してラベルの一貫性を強化します。 2番目のコンポーネントは、決定的な点過程とエントロピー最大化に触発されたダイバーシティレギュラライザーを介して、ネットワーク間の敵対的な転送可能性を低減します。実験結果は、小さな摂動予算の下で、ARMOREDは強力な適応敵に対して堅牢であることを示しています。特に、ARMOREDはトレーニング中に敵対的なサンプルを生成することに依存していません。 ARMOREDを敵対的なトレーニングと組み合わせて使用​​すると、クリーンなサンプルで高精度を維持しながら、さまざまな摂動バジェットに対してl（）およびl2攻撃に対する最先端の堅牢性を実現します。敵対的な堅牢なトレーニングで、最先端のベンチマークに対するCIFAR-10およびSVHNデータセットでのARMOREDの堅牢性を示します。,7.0,
Fast convergence of stochastic subgradient method under interpolation,"['Huang Fang', 'Zhenan Fan', 'Michael Friedlander']",https://openreview.net/forum?id=w2mYg3d0eot,"This paper studies the behaviour of the stochastic subgradient descent (SSGD) method applied to over-parameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, we prove that SSGD converges, respectively, with rates $O(1/\epsilon)$ and $O(\log(1/\epsilon))$ for convex and strongly-convex objectives when interpolation holds. These rates coincide with established rates for the stochastic gradient descent (SGD) method applied to smooth problems that also satisfy an interpolation condition. Our analysis provides a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nonsmooth machine learning models. We also prove that the rate $O(1/\epsilon)$ is optimal for the subgradient method in the convex and interpolation setting.",この論文は、内挿条件を満たす過剰パラメータ化された非平滑最適化問題に適用される確率的劣勾配降下法（SSGD）の振る舞いを研究します。経験的リスク最小化問題の複合構造を活用することにより、SSGDがそれぞれ、補間が成立する場合の凸型および強凸型の目的のレートO（1 /）およびO（log（1 /））で収束することを証明します。これらのレートは、補間条件を満たす滑らかな問題に適用される確率的勾配降下法（SGD）の確立されたレートと一致します。私たちの分析は、SGDとSSGDが滑らかな機械学習モデルと滑らかでない機械学習モデルをトレーニングするために同じように動作することがあるという経験的観察の部分的な説明を提供します。また、レートO（1 /）が凸および内挿設定の劣勾配法に最適であることを証明します。,7.0,
Hyperbolic Neural Networks++,"['Ryohei Shimizu', 'YUSUKE Mukuta', 'Tatsuya Harada']",https://openreview.net/forum?id=Ec85b0tUwbA,"Hyperbolic spaces, which have the capacity to embed tree structures without distortion owing to their exponential volume growth, have recently been applied to machine learning to better capture the hierarchical nature of data. In this study, we generalize the fundamental components of neural networks in a single hyperbolic geometry model, namely, the Poincaré ball model. This novel methodology constructs a multinomial logistic regression, fully-connected layers, convolutional layers, and attention mechanisms under a unified mathematical interpretation, without increasing the parameters. Experiments show the superior parameter efficiency of our methods compared to conventional hyperbolic components, and stability and outperformance over their Euclidean counterparts.",指数関数的なボリュームの増加により、歪みなしにツリー構造を埋め込むことができる双曲空間は、データの階層的性質をより適切にキャプチャするために、最近機械学習に適用されています。この研究では、ニューラルネットワークの基本的なコンポーネントを単一の双曲幾何学モデル、つまりポアンカレボールモデルに一般化します。この新しい方法論は、パラメーターを増やすことなく、統一された数学的解釈の下で、多項ロジスティック回帰、完全に接続された層、畳み込み層、および注意メカニズムを構築します。実験は、従来の双曲線コンポーネントと比較して、私たちの方法の優れたパラメータ効率、およびそれらのユークリッド対応物よりも安定性とアウトパフォーマンスを示しています。,7.0,https://d3i71xaburhd42.cloudfront.net/301fbcd41ae2263cbb320a48b50517885f7eeb5e/3-Figure1-1.png
Learning to Generate 3D Shapes with Generative Cellular Automata,"['Dongsu Zhang', 'Changwoon Choi', 'Jeonghwan Kim', 'Young Min Kim']",https://openreview.net/forum?id=rABUmU3ulQh,"In this work, we present a probabilistic 3D generative model, named Generative Cellular Automata, which is able to produce diverse and high quality shapes. We formulate the shape generation process as sampling from the transition kernel of a Markov chain, where the sampling chain eventually evolves to the full shape of the learned distribution. The transition kernel employs the local update rules of cellular automata, effectively reducing the search space in a high-resolution 3D grid space by exploiting the connectivity and sparsity of 3D shapes. Our progressive generation only focuses on the sparse set of occupied voxels and their neighborhood, thus enables the utilization of an expressive sparse convolutional network. We propose an effective training scheme to obtain the local homogeneous rule of generative cellular automata with sequences that are slightly different from the sampling chain but converge to the full shapes in the training data. Extensive experiments on probabilistic shape completion and shape generation demonstrate that our method achieves competitive performance against recent methods.",この作品では、多様で高品質の形状を生成できるGenerative CellularAutomataという名前の確率的3D生成モデルを紹介します。形状生成プロセスは、マルコフ連鎖の遷移カーネルからのサンプリングとして定式化されます。ここで、サンプリングチェーンは、最終的に学習された分布の完全な形状に進化します。遷移カーネルは、セルオートマトンのローカル更新ルールを採用しており、3D形状の接続性とスパース性を活用することで、高解像度の3Dグリッド空間の検索空間を効果的に削減します。私たちのプログレッシブ世代は、占有されたボクセルのまばらなセットとその近傍にのみ焦点を当てているため、表現力豊かなまばらな畳み込みネットワークの利用が可能になります。サンプリングチェーンとはわずかに異なるが、トレーニングデータの完全な形状に収束するシーケンスを持つ生成セルオートマトンのローカル均一ルールを取得するための効果的なトレーニングスキームを提案します。確率的形状完成と形状生成に関する広範な実験は、私たちの方法が最近の方法に対して競争力のあるパフォーマンスを達成することを示しています。,7.0,
Shapley explainability on the data manifold,"['Christopher Frye', 'Damien de Mijolla', 'Tom Begley', 'Laurence Cowton', 'Megan Stanley', 'Ilya Feige']",https://openreview.net/forum?id=OPyWRrcjVQw,"Explainability in AI is crucial for model development, compliance with regulation, and providing operational nuance to predictions. The Shapley framework for explainability attributes a model’s predictions to its input features in a mathematically principled and model-agnostic way. However, general implementations of Shapley explainability make an untenable assumption: that the model’s features are uncorrelated. In this work, we demonstrate unambiguous drawbacks of this assumption and develop two solutions to Shapley explainability that respect the data manifold. One solution, based on generative modelling, provides flexible access to data imputations; the other directly learns the Shapley value-function, providing performance and stability at the cost of flexibility. While “off-manifold” Shapley values can (i) give rise to incorrect explanations, (ii) hide implicit model dependence on sensitive attributes, and (iii) lead to unintelligible explanations in higher-dimensional data, on-manifold explainability overcomes these problems.
",AIの説明可能性は、モデル開発、規制への準拠、および予測に運用上のニュアンスを提供するために重要です。説明可能性のためのShapleyフレームワークは、数学的に原理的でモデルにとらわれない方法で、モデルの予測をその入力特徴に帰します。ただし、Shapleyの説明可能性の一般的な実装では、モデルの機能に相関関係がないという、受け入れがたい仮定があります。この作業では、この仮定の明確な欠点を示し、データ多様体を尊重するシャープレイの説明可能性に対する2つのソリューションを開発します。生成モデリングに基づく1つのソリューションは、データ代入への柔軟なアクセスを提供します。もう1つは、シャープレイ値関数を直接学習し、柔軟性を犠牲にしてパフォーマンスと安定性を提供します。多様体外のシャープレイ値は、（i）誤った説明を引き起こし、（ii）機密属性への暗黙のモデル依存を隠し、（iii）高次元データで理解できない説明をもたらす可能性がありますが、多様体上での説明可能性はこれらの問題を克服します。,7.0,
Iterative Empirical Game Solving via Single Policy Best Response,"['Max Smith', 'Thomas Anthony', 'Michael Wellman']",https://openreview.net/forum?id=R4aWTjmrEKM,"Policy-Space Response Oracles (PSRO) is a general algorithmic framework for learning policies in multiagent systems by interleaving empirical game analysis with deep reinforcement learning (DRL).
At each iteration, DRL is invoked to train a best response to a mixture of opponent policies.
The repeated application of DRL poses an expensive computational burden as we look to apply this algorithm to more complex domains.
We introduce two variations of PSRO designed to reduce the amount of simulation required during DRL training.
Both algorithms modify how PSRO adds new policies to the empirical game, based on learned responses to a single opponent policy.
The first, Mixed-Oracles, transfers knowledge from previous iterations of DRL, requiring training only against the opponent's newest policy.
The second, Mixed-Opponents, constructs a pure-strategy opponent by mixing existing strategy's action-value estimates, instead of their policies.
Learning against a single policy mitigates conflicting experiences on behalf of a learner facing an unobserved distribution of opponents.
We empirically demonstrate that these algorithms substantially reduce the amount of simulation during training required by PSRO, while producing equivalent or better solutions to the game.",Policy-Space Response Oracles（PSRO）は、経験的なゲーム分析と深層強化学習（DRL）をインターリーブすることにより、マルチエージェントシステムでポリシーを学習するための一般的なアルゴリズムフレームワークです。各反復で、DRLが呼び出され、さまざまな対戦相手のポリシーに対する最適な応答をトレーニングします。 DRLを繰り返し適用すると、このアルゴリズムをより複雑なドメインに適用しようとするため、計算量が多くなります。 DRLトレーニング中に必要なシミュレーションの量を減らすように設計されたPSROの2つのバリエーションを紹介します。どちらのアルゴリズムも、単一の対戦相手のポリシーに対する学習された応答に基づいて、PSROが経験的なゲームに新しいポリシーを追加する方法を変更します。最初のMixed-Oracleは、DRLの以前の反復から知識を転送し、対戦相手の最新のポリシーに対してのみトレーニングを必要とします。 2番目のMixed-Opponentsは、ポリシーではなく、既存の戦略のアクション値の見積もりを混合することにより、純粋な戦略の対戦相手を構築します。単一のポリシーに反して学習することで、観察されていない敵の分布に直面している学習者に代わって、矛盾する経験を軽減します。これらのアルゴリズムは、PSROが必要とするトレーニング中のシミュレーションの量を大幅に削減すると同時に、ゲームと同等以上のソリューションを生成することを経験的に示しています。,7.0,
BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction,"['Yuhang Li', 'Ruihao Gong', 'Xu Tan', 'Yang Yang', 'Peng Hu', 'Qi Zhang', 'Fengwei Yu', 'Wei Wang', 'Shi Gu']",https://openreview.net/forum?id=POWv6hDd9XH,"We study the challenging task of neural network quantization without end-to-end retraining, called Post-training Quantization (PTQ). PTQ usually requires a small subset of training data but produces less powerful quantized models than quantization-aware training (QAT). In this work, we propose a novel PTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to INT2 for the first time. BRECQ leverages the basic building blocks in neural networks and reconstructs them one-by-one. In a comprehensive theoretical study of the second-order error, we show that BRECQ achieves a good balance between cross-layer dependency and first-order approximation. To further employ the power of quantization, the mixed precision technique is incorporated in our framework by approximating the inter-layer and intra-layer sensitivity. Extensive experiments on various handcrafted and searched neural architectures are conducted for both image classification and object detection tasks. And for the first time we prove that, without bells and whistles, PTQ can attain 4-bit ResNet and MobileNetV2 comparable with QAT and enjoy 240x faster production of quantized models.",ポストトレーニング量子化（PTQ）と呼ばれる、エンドツーエンドの再トレーニングなしのニューラルネットワーク量子化の挑戦的なタスクを研究します。 PTQは通常、トレーニングデータの小さなサブセットを必要としますが、量子化対応トレーニング（QAT）よりも強力な量子化モデルを生成しません。この作業では、PTQのビット幅の制限を初めてINT2に押し下げる、BRECQと呼ばれる新しいPTQフレームワークを提案します。 BRECQは、ニューラルネットワークの基本的な構成要素を活用し、それらを1つずつ再構築します。 2次誤差の包括的な理論的研究では、BRECQがクロスレイヤー依存性と1次近似の間の良好なバランスを達成することを示しています。量子化の力をさらに活用するために、混合精度技術は、層間および層内の感度を近似することにより、フレームワークに組み込まれています。画像分類とオブジェクト検出タスクの両方について、さまざまな手作りおよび検索されたニューラルアーキテクチャに関する広範な実験が行われます。そして初めて、ベルやホイッスルなしで、PTQがQATに匹敵する4ビットのResNetおよびMobileNetV2を達成し、量子化モデルの240倍高速な生産を享受できることを証明しました。,7.0,
Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies,"['Dominik Schmidt', 'Georgia Koppe', 'Zahra Monfared', 'Max Beutelspacher', 'Daniel Durstewitz']",https://openreview.net/forum?id=_XYzwxPIQu6,"A main theoretical interest in biology and physics is to identify the nonlinear dynamical system (DS) that generated observed time series. Recurrent Neural Networks (RNN) are, in principle, powerful enough to approximate any underlying DS, but in their vanilla form suffer from the exploding vs. vanishing gradients problem. Previous attempts to alleviate this problem resulted either in more complicated, mathematically less tractable RNN architectures, or strongly limited the dynamical expressiveness of the RNN. 
Here we address this issue by suggesting a simple regularization scheme for vanilla RNN with ReLU activation which enables them to solve long-range dependency problems and express slow time scales, while retaining a simple mathematical structure which makes their DS properties partly analytically accessible. We prove two theorems that establish a tight connection between the regularized RNN dynamics and their gradients, illustrate on DS benchmarks that our regularization approach strongly eases the reconstruction of DS which harbor widely differing time scales, and show that our method is also en par with other long-range architectures like LSTMs on several tasks.",生物学と物理学の主な理論的関心は、観測された時系列を生成した非線形動的システム（DS）を特定することです。リカレントニューラルネットワーク（RNN）は、原則として、基礎となるDSを近似するのに十分強力ですが、バニラ形式では、勾配の爆発と消失の問題に悩まされます。この問題を軽減するための以前の試みは、より複雑で数学的に扱いにくいRNNアーキテクチャをもたらすか、RNNの動的な表現力を大幅に制限していました。ここでは、ReLUアクティベーションを使用したバニラRNNの単純な正則化スキームを提案することでこの問題に対処します。これにより、DSプロパティを部分的に分析的にアクセスできるようにする単純な数学的構造を維持しながら、長距離の依存関係の問題を解決し、遅い時間スケールを表現できます。正則化されたRNNダイナミクスとその勾配の間の緊密な関係を確立する2つの定理を証明し、DSベンチマークで、正則化アプローチが大きく異なる時間スケールを持つDSの再構築を大幅に容易にすることを示し、私たちの方法が他の方法と同等であることを示しますいくつかのタスクでのLSTMのような長距離アーキテクチャ。,7.0,
A Gradient Flow Framework For Analyzing Network Pruning,"['Ekdeep Singh Lubana', 'Robert Dick']",https://openreview.net/forum?id=rumv7QmLUue,"Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and is therefore appropriate for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.",最近のネットワークプルーニング方法は、トレーニングの早い段階でモデルをプルーニングすることに焦点を当てています。パラメータを削除した場合の影響を推定するために、これらの方法では、トレーニング済みモデルを剪定するために元々設計された重要度の尺度を使用します。トレーニングの早い段階でそれらを使用することの正当性が欠けているにもかかわらず、そのような手段は驚くほど低い精度の損失をもたらします。この動作をよりよく説明するために、勾配フローを使用して、モデルパラメータのノルムを通じて最先端の重要度の測定値を統合する一般的なフレームワークを開発します。このフレームワークを使用して、剪定尺度とモデルパラメータの進化との関係を決定し、トレーニングの早い段階で剪定モデルに関連するいくつかの結果を確立します。（i）マグニチュードベースの剪定は、損失の削減に最も貢献しないパラメータを削除し、モデルを作成します。マグニチュードに依存しない方法よりも速く収束します。 （ii）損失保存ベースの剪定は、一次モデルの進化のダイナミクスを保存するため、最小限のトレーニングを受けたモデルの剪定に適しています。 （iii）勾配ノルムベースの剪定は、2次モデルの進化のダイナミクスに影響を与えるため、剪定によって勾配ノルムを増やすと、パフォーマンスの低いモデルが生成される可能性があります。 CIFAR-10 / CIFAR-100でトレーニングされたいくつかのVGG-13、MobileNet-V1、およびResNet-56モデルでクレームを検証します。,7.0,
Interpretable Neural Architecture Search via Bayesian Optimisation with Weisfeiler-Lehman Kernels,"['Xingchen Wan', 'Binxin Ru', 'Xiaowen Dong', 'Michael Osborne']",https://openreview.net/forum?id=j9Rv7qdXjd,"Current neural architecture search (NAS) strategies focus only on finding a single, good, architecture. They offer little insight into why a specific network is performing well, or how we should modify the architecture if we want further improvements. We propose a Bayesian optimisation (BO) approach for NAS that combines the Weisfeiler-Lehman graph kernel with a Gaussian process surrogate. Our method not only optimises the architecture in a highly data-efficient manner, but also affords interpretability by discovering useful network features and their corresponding impact on the network performance. Moreover, our method is capable of capturing the topological structures of the architectures and is scalable to large graphs, thus making the high-dimensional and graph-like search spaces amenable to BO. We demonstrate empirically that our surrogate model is capable of identifying useful motifs which can guide the generation of new architectures. We finally show that our method outperforms existing NAS approaches to achieve the state of the art on both closed- and open-domain search spaces.",現在のニューラルアーキテクチャ検索（NAS）戦略は、単一の優れたアーキテクチャを見つけることにのみ焦点を当てています。特定のネットワークがうまく機能している理由や、さらに改善が必要な場合にアーキテクチャを変更する方法については、ほとんど洞察が得られません。 Weisfeiler-Lehmanグラフカーネルとガウス過程サロゲートを組み合わせたNASのベイズ最適化（BO）アプローチを提案します。私たちの方法は、データ効率の高い方法でアーキテクチャを最適化するだけでなく、有用なネットワーク機能とそれに対応するネットワークパフォーマンスへの影響を発見することで解釈可能性を提供します。さらに、私たちの方法は、アーキテクチャのトポロジ構造をキャプチャすることができ、大きなグラフにスケーラブルであるため、高次元でグラフのような検索空間をBOに適したものにします。私たちの代理モデルは、新しいアーキテクチャの生成を導くことができる有用なモチーフを特定できることを経験的に示しています。最後に、私たちの方法が既存のNASアプローチよりも優れており、クローズドドメインとオープンドメインの両方の検索スペースで最先端を実現していることを示します。,7.0,
Mathematical Reasoning via Self-supervised Skip-tree Training,"['Markus Norman Rabe', 'Dennis Lee', 'Kshitij Bansal', 'Christian Szegedy']",https://openreview.net/forum?id=YmqAnY0CMEy,"We demonstrate that self-supervised language modeling applied to mathematical formulas enables logical reasoning. To measure the logical reasoning abilities of language models, we formulate several evaluation (downstream) tasks, such as inferring types, suggesting missing assumptions and completing equalities. For training language models for formal mathematics, we propose a novel skip-tree task. We find that models trained on the skip-tree task show surprisingly strong mathematical reasoning abilities, and outperform models trained on standard skip-sequence tasks. We also analyze the models' ability to formulate new conjectures by measuring how often the predictions are provable and useful in other proofs.",数式に適用される自己教師あり言語モデリングが論理的推論を可能にすることを示します。言語モデルの論理的推論能力を測定するために、タイプの推測、欠落している仮定の提案、同等性の完成など、いくつかの評価（ダウンストリーム）タスクを定式化します。形式的数学の言語モデルをトレーニングするために、新しいスキップツリータスクを提案します。スキップツリータスクでトレーニングされたモデルは、驚くほど強力な数学的推論能力を示し、標準のスキップシーケンスタスクでトレーニングされたモデルよりも優れていることがわかります。また、予測が他の証明で証明可能で有用である頻度を測定することにより、新しい推測を定式化するモデルの能力を分析します。,7.0,
Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis,"['Bingchen Liu', 'Yizhe Zhu', 'Kunpeng Song', 'Ahmed Elgammal']",https://openreview.net/forum?id=1Fqg133qRaI,"Training Generative Adversarial Networks (GAN) on high-fidelity images usually requires large-scale GPU-clusters and a vast number of training images. In this paper, we study the few-shot image synthesis task for GAN with minimum computing cost. We propose a light-weight GAN structure that gains superior quality on $1024\times1024$ resolution. Notably, the model converges from scratch with just a few hours of training on a single RTX-2080 GPU; and has a consistent performance, even with less than 100 training samples. Two technique designs constitute our work, a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. With thirteen datasets covering a wide variety of image domains, we show our model's robustness and its superior performance compared to the state-of-the-art StyleGAN2.",忠実度の高い画像で敵対的生成ネットワーク（GAN）をトレーニングするには、通常、大規模なGPUクラスターと膨大な数のトレーニング画像が必要です。この論文では、最小の計算コストでGANの数ショットの画像合成タスクを研究します。 10241024の解像度で優れた品質を実現する軽量GAN構造を提案します。特に、モデルは単一のRTX-2080GPUでわずか数時間のトレーニングでゼロから収束します。トレーニングサンプルが100未満の場合でも、一貫したパフォーマンスが得られます。 2つの手法設計が私たちの仕事を構成します。スキップレイヤーチャネルワイズ励起モジュールと、機能エンコーダーとしてトレーニングされた自己監視型弁別器です。多種多様な画像ドメインをカバーする13のデータセットを使用して、最新のStyleGAN2と比較してモデルの堅牢性とその優れたパフォーマンスを示します。,7.0,https://d3i71xaburhd42.cloudfront.net/6c4fe31504d47b8547e47267c0cb4efa464f022b/1-Figure1-1.png
RODE: Learning Roles to Decompose Multi-Agent Tasks,"['Tonghan Wang', 'Tarun Gupta', 'Anuj Mahajan', 'Bei Peng', 'Shimon Whiteson', 'Chongjie Zhang']",https://openreview.net/forum?id=TTUVg6vkNjK,"Role-based learning holds the promise of achieving scalable multi-agent learning by decomposing complex tasks using roles. However, it is largely unclear how to efficiently discover such a set of roles. To solve this problem, we propose to first decompose joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. Learning a role selector based on action effects makes role discovery much easier because it forms a bi-level learning hierarchy -- the role selector searches in a smaller role space and at a lower temporal resolution, while role policies learn in significantly reduced primitive action-observation spaces. We further integrate information about action effects into the role policies to boost learning efficiency and policy generalization. By virtue of these advances, our method (1) outperforms the current state-of-the-art MARL algorithms on 10 of the 14 scenarios that comprise the challenging StarCraft II micromanagement benchmark and (2) achieves rapid transfer to new environments with three times the number of agents. Demonstrative videos are available at https://sites.google.com/view/rode-marl .",ロールベースの学習は、ロールを使用して複雑なタスクを分解することにより、スケーラブルなマルチエージェント学習を実現する可能性を秘めています。ただし、そのような一連の役割を効率的に発見する方法はほとんど不明です。この問題を解決するために、まず、環境や他のエージェントへの影響に応じてアクションをクラスタリングすることにより、共同アクションスペースを制限された役割のアクションスペースに分解することを提案します。アクション効果に基づいてロールセレクターを学習すると、ロールセレクターがより小さなロールスペースとより低い時間分解能で検索する2レベルの学習階層を形成するため、ロールディスカバリーがはるかに簡単になります。一方、ロールポリシーは、大幅に削減されたプリミティブアクション監視スペースで学習します。 。さらに、アクション効果に関する情報を役割ポリシーに統合して、学習効率とポリシーの一般化を促進します。これらの進歩により、私たちの方法は、（1）挑戦的なStarCraft IIマイクロマネジメントベンチマークを構成する14のシナリオのうち10で、現在の最先端のMARLアルゴリズムを上回り、（2）3倍の新しい環境への迅速な移行を実現します。エージェントの数。デモビデオはhttps://sites.google.com/view/rode-marlで入手できます。,7.0,https://d3i71xaburhd42.cloudfront.net/5764095b0186a3fc3832c1052aa14996a5927edc/3-Figure1-1.png
Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy,"['Zuyue Fu', 'Zhuoran Yang', 'Zhaoran Wang']",https://openreview.net/forum?id=pqZV_srUVmK,"We study the global convergence and global optimality of actor-critic, one of the most popular families of reinforcement learning algorithms. While most existing works on actor-critic employ bi-level or two-timescale updates, we focus on the more practical single-timescale setting, where the actor and critic are updated simultaneously. Specifically, in each iteration, the critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic. Moreover, we consider two function approximation settings where both the actor and critic are represented by linear or deep neural networks. For both cases, we prove that the actor sequence converges to a globally optimal policy at a sublinear $O(K^{-1/2})$ rate, where $K$ is the number of iterations. To the best of our knowledge, we establish the rate of convergence and global optimality of single-timescale actor-critic with linear function approximation for the first time. Moreover, under the broader scope of policy optimization with nonlinear function approximation, we prove that actor-critic with deep neural network finds the globally optimal policy at a sublinear rate for the first time. ",強化学習アルゴリズムの最も人気のあるファミリーの1つであるアクター批評家のグローバルな収束とグローバルな最適性を研究します。アクター批評家に関する既存の作品のほとんどは、2レベルまたは2タイムスケールの更新を採用していますが、アクターと評論家が同時に更新される、より実用的なシングルタイムスケール設定に焦点を当てています。具体的には、各反復で、アクターが批評家を使用して計算されたポリシー勾配方向に更新されている間に、ベルマン評価演算子を1回だけ適用することによって批評家の更新が取得されます。さらに、アクターと評論家の両方が線形またはディープニューラルネットワークによって表される2つの関数近似設定を検討します。どちらの場合も、アクターシーケンスが劣線形O（K ^（1/2））レートでグローバルに最適なポリシーに収束することを証明します。ここで、Kは反復回数です。私たちの知る限りでは、線形関数近似を使用して、単一タイムスケールのアクター批評家の収束率とグローバルな最適性を初めて確立します。さらに、非線形関数近似を使用したポリシー最適化のより広い範囲の下で、ディープニューラルネットワークを使用したアクター批評家が、劣線形レートでグローバルに最適なポリシーを初めて見つけることを証明します。,7.0,https://d3i71xaburhd42.cloudfront.net/062b29e02798fadd3effade0fff25852a56ff15d/19-Figure1-1.png
In Search of Lost Domain Generalization,"['Ishaan Gulrajani', 'David Lopez-Paz']",https://openreview.net/forum?id=lQdXeXDoWtI,"The goal of domain generalization algorithms is to predict well on distributions different from those seen during training.
While a myriad of domain generalization algorithms exist, inconsistencies in experimental conditions---datasets, network architectures, and model selection criteria---render fair comparisons difficult.
The goal of this paper is to understand how useful domain generalization algorithms are in realistic settings.
As a first step, we realize that model selection is non-trivial for domain generalization tasks, and we argue that algorithms without a model selection criterion remain incomplete.
Next we implement DomainBed, a testbed for domain generalization including seven benchmarks, fourteen algorithms, and three model selection criteria.
When conducting extensive experiments using DomainBed we find that when carefully implemented and tuned, ERM outperforms the state-of-the-art in terms of average performance.
Furthermore, no algorithm included in DomainBed outperforms ERM by more than one point when evaluated under the same experimental conditions.
We hope that the release of DomainBed, alongside contributions from fellow researchers, will streamline reproducible and rigorous advances in domain generalization.",ドメイン一般化アルゴリズムの目標は、トレーニング中に見られるものとは異なる分布を適切に予測することです。無数のドメイン一般化アルゴリズムが存在しますが、実験条件のデータセット、ネットワークアーキテクチャ、およびモデル選択基準の不一致により、公正な比較が困難になります。このホワイトペーパーの目的は、現実的な設定でドメイン一般化アルゴリズムがどれほど役立つかを理解することです。最初のステップとして、モデル選択はドメイン一般化タスクにとって自明ではないことを認識し、モデル選択基準のないアルゴリズムは不完全なままであると主張します。次に、7つのベンチマーク、14のアルゴリズム、および3つのモデル選択基準を含むドメイン一般化のテストベッドであるDomainBedを実装します。 DomainBedを使用して広範な実験を行ったところ、注意深く実装および調整した場合、ERMは平均パフォーマンスの点で最先端のパフォーマンスを上回っています。さらに、DomainBedに含まれているアルゴリズムは、同じ実験条件下で評価した場合、ERMを2ポイント以上上回っていません。 DomainBedのリリースが、他の研究者からの貢献とともに、ドメインの一般化における再現可能で厳密な進歩を合理化することを願っています。,7.0,https://d3i71xaburhd42.cloudfront.net/6a5efb990b6558c21d9fdded4884c00ba152cb7c/2-Table1-1.png
Random Feature Attention,"['Hao Peng', 'Nikolaos Pappas', 'Dani Yogatama', 'Roy Schwartz', 'Noah Smith', 'Lingpeng Kong']",https://openreview.net/forum?id=QtTKTdVrFBB,"Transformers are state-of-the-art models for a variety of sequence modeling tasks. At their core is an attention function which models pairwise interactions between the inputs at every timestep. While attention is powerful, it does not scale efficiently to long sequences due to its quadratic time and space complexity in the sequence length. We propose RFA, a linear time and space attention that uses random feature methods to approximate the softmax function, and explore its applications in transformers. RFA offers a straightforward way of learning with recency bias through an optional gating mechanism and can be used as a drop-in replacement for conventional softmax attention. Experiments on language modeling and machine translation demonstrate that RFA achieves similar or better performance compared to strong transformer baselines. In the machine translation experiment, RFA decodes twice as fast as a vanilla transformer. Compared to existing efficient transformer variants, RFA is competitive in terms of both accuracy and efficiency on three long text classification datasets. Our analysis shows that RFA’s efficiency gains are especially notable on long sequences, suggesting that RFA will be particularly useful in tasks that require working with large inputs, fast decoding speed, or low memory footprints. 
",トランスフォーマーは、さまざまなシーケンスモデリングタスク用の最先端のモデルです。その核となるのは、すべてのタイムステップでの入力間のペアワイズ相互作用をモデル化するアテンション関数です。注意は強力ですが、シーケンスの長さが2次の時間と空間で複雑になるため、長いシーケンスに効率的にスケーリングすることはできません。ソフトマックス関数を近似するためにランダムな特徴法を使用する線形時間および空間注意であるRFAを提案し、変圧器でのそのアプリケーションを調査します。 RFAは、オプションのゲーティングメカニズムを介して最新性バイアスを使用した簡単な学習方法を提供し、従来のソフトマックス注意のドロップイン代替として使用できます。言語モデリングと機械翻訳に関する実験は、RFAが強力な変圧器ベースラインと比較して同等またはそれ以上のパフォーマンスを達成することを示しています。機械翻訳の実験では、RFAはバニラトランスフォーマーの2倍の速度でデコードします。 RFAは、既存の効率的な変圧器のバリエーションと比較して、3つの長いテキスト分類データセットの精度と効率の両方の点で競争力があります。私たちの分析によると、RFAの効率の向上は長いシーケンスで特に顕著であり、RFAは、大きな入力、高速なデコード速度、または低いメモリフットプリントでの作業を必要とするタスクで特に役立つことを示唆しています。,7.0,
Disentangled Recurrent Wasserstein Autoencoder ,"['Jun Han', 'Martin Renqiang Min', 'Ligong Han', 'Xuan Zhang', 'Li Erran Li']",https://openreview.net/forum?id=O7ms4LFdsX,"Learning disentangled representations leads to interpretable models and facilitates data generation with style transfer, which has been extensively studied on static data such as images in an unsupervised learning framework. However, only a few works have explored unsupervised disentangled sequential representation learning due to challenges of generating sequential data. In this paper, we propose recurrent Wasserstein Autoencoder (R-WAE), a new framework for generative modeling of sequential data. R-WAE disentangles the representation of an input sequence into static and dynamic factors (i.e., time-invariant and time-varying parts). Our theoretical analysis shows that, R-WAE minimizes an upper bound of a penalized form of the Wasserstein distance between model distribution and sequential data distribution, and simultaneously maximizes the mutual information between input data and different disentangled latent factors, respectively. This is superior to (recurrent) VAE which does not explicitly enforce mutual information maximization between input data and disentangled latent representations. When the number of actions in sequential data is available as weak supervision information, R-WAE is extended to learn a categorical latent representation of actions to improve its disentanglement. Experiments on a variety of datasets show that our models outperform other baselines with the same settings in terms of disentanglement and unconditional video generation both quantitatively and qualitatively.",解きほぐされた表現を学習すると、解釈可能なモデルが得られ、教師なし学習フレームワークの画像などの静的データで広く研究されてきたスタイル転送によるデータ生成が容易になります。ただし、シーケンシャルデータを生成するという課題があるため、教師なし解きほぐされたシーケンシャル表現学習を調査した作品はごくわずかです。この論文では、シーケンシャルデータの生成モデリングのための新しいフレームワークであるリカレントワッサースタインオートエンコーダ（R-WAE）を提案します。 R-WAEは、入力シーケンスの表現を静的要因と動的要因（つまり、時不変部分と時不変部分）に解きほぐします。私たちの理論的分析は、R-WAEが、モデル分布と順次データ分布の間のワッサースタイン距離のペナルティ形式の上限を最小化し、同時に入力データと異なる解きほぐされた潜在因子の間の相互情報量をそれぞれ最大化することを示しています。これは、入力データと解きほぐされた潜在表現の間の相互情報量の最大化を明示的に強制しない（再発）VAEよりも優れています。シーケンシャルデータ内のアクションの数が弱い監視情報として利用できる場合、R-WAEは、アクションのカテゴリ別潜在表現を学習して、その解きほぐしを改善するように拡張されます。さまざまなデータセットでの実験により、私たちのモデルは、解きほぐしと無条件のビデオ生成の点で、同じ設定で他のベースラインよりも定量的および定性的に優れていることが示されています。,7.0,https://d3i71xaburhd42.cloudfront.net/072ad179f7ca9e5ee232e8fadd05d193bca79a8c/4-Figure1-1.png
Global optimality of softmax policy gradient with single hidden layer neural networks in the mean-field regime,"['Andrea Agazzi', 'Jianfeng Lu']",https://openreview.net/forum?id=bB2drc7DPuB,"We study the problem of policy optimization for infinite-horizon discounted Markov Decision Processes with softmax policy and nonlinear function approximation trained with policy gradient algorithms. We concentrate on the training dynamics in the mean-field regime, modeling e.g. the behavior of wide single hidden layer neural networks, when exploration is encouraged through entropy regularization. The dynamics of these models is established as a Wasserstein gradient flow of distributions in parameter space.  We further prove global optimality of the fixed points of this dynamics  under mild conditions on their initialization.",ソフトマックスポリシーとポリシー勾配アルゴリズムでトレーニングされた非線形関数近似を使用して、無限ホライズン割引マルコフ決定過程のポリシー最適化の問題を研究します。エントロピー正則化によって探索が促進される場合、平均場レジームでのトレーニングダイナミクスに集中します。たとえば、幅の広い単一の隠れ層ニューラルネットワークの動作をモデリングします。これらのモデルのダイナミクスは、パラメーター空間における分布のワッサースタイン勾配フローとして確立されます。さらに、初期化の穏やかな条件下で、このダイナミクスの不動点のグローバルな最適性を証明します。,7.0,https://d3i71xaburhd42.cloudfront.net/262851f264c6a0b10bad077289c52c4668156378/8-Figure1-1.png
IsarStep: a Benchmark for High-level Mathematical Reasoning,"['Wenda Li', 'Lei Yu', 'Yuhuai Wu', 'Lawrence C. Paulson']",https://openreview.net/forum?id=Pzj6fzU6wkj,"A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. We will make the dataset and models publicly available.",機械学習モデルの研究の進捗状況を測定および加速するには、明確に定義されたベンチマークが不可欠です。この論文では、高レベルの数学的推論のベンチマークを提示し、神経シーケンス間モデルの推論機能を研究します。私たちは、定理証明者の人間の専門家によって書かれた証明の最大のリポジトリから非合成データセットを構築します。このデータセットには、学部および研究レベルの数学およびコンピューターサイエンスの定理が幅広く含まれています。定義されたタスクでは、周囲の証明を前提として、欠落している中間命題を埋めるためにモデルが必要です。このタスクは、機械に人間が読める形式の証明を自動的に生成させるという長期的な目標の出発点を提供します。私たちの実験と分析は、タスクが挑戦的である間、神経モデルが重要な数学的推論を捕らえることができることを明らかにします。さらに、変圧器のベースラインを上回る階層型変圧器を設計します。データセットとモデルを公開します。,7.0,
Neural Topic Model via Optimal Transport,"['He Zhao', 'Dinh Phung', 'Viet Huynh', 'Trung Le', 'Wray Buntine']",https://openreview.net/forum?id=Oos98K9Lv-k,"Recently, Neural Topic Models (NTMs) inspired by variational autoencoders have obtained increasingly research interest due to their promising results on text analysis. However, it is usually hard for existing NTMs to achieve good document representation and coherent/diverse topics at the same time. Moreover, they often degrade their performance severely on short documents. The requirement of reparameterisation could also comprise their training quality and model flexibility. To address these shortcomings, we present a new neural topic model via the theory of optimal transport (OT). Specifically, we propose to learn the topic distribution of a document by directly minimising its OT distance to the document's word distributions. Importantly, the cost matrix of the OT distance models the weights between topics and words, which is constructed by the distances between topics and words in an embedding space. Our proposed model can be trained efficiently with a differentiable loss. Extensive experiments show that our framework significantly outperforms the state-of-the-art NTMs on discovering more coherent and diverse topics and deriving better document representations for both regular and short texts.",最近、変分オートエンコーダに触発されたニューラルトピックモデル（NTM）は、テキスト分析での有望な結果により、ますます研究の関心を集めています。ただし、通常、既存のNTMが、優れたドキュメント表現と一貫性のある/多様なトピックを同時に実現することは困難です。さらに、短いドキュメントではパフォーマンスが大幅に低下することがよくあります。再パラメータ化の要件には、トレーニングの品質とモデルの柔軟性も含まれる可能性があります。これらの欠点に対処するために、最適輸送（OT）の理論を介して新しいニューラルトピックモデルを提示します。具体的には、ドキュメントの単語分布までのOT距離を直接最小化することにより、ドキュメントのトピック分布を学習することを提案します。重要なことに、OT距離のコストマトリックスは、トピックと単語の間の重みをモデル化します。これは、埋め込みスペース内のトピックと単語の間の距離によって構築されます。提案されたモデルは、微分可能な損失で効率的にトレーニングできます。広範な実験により、私たちのフレームワークは、より一貫性のある多様なトピックを発見し、通常のテキストと短いテキストの両方でより優れたドキュメント表現を導き出すという点で、最先端のNTMを大幅に上回っています。,7.0,
Memory Optimization for Deep Networks,"['Aashaka Shah', 'Chao-Yuan Wu', 'Jayashree Mohan', 'Vijay Chidambaram', 'Philipp Kraehenbuehl']",https://openreview.net/forum?id=bnY0jm4l59,"Deep learning is slowly, but steadily, hitting a memory bottleneck. While the tensor computation in top-of-the-line GPUs increased by $32\times$ over the last five years, the total available memory only grew by $2.5\times$. This prevents researchers from exploring larger architectures, as training large networks requires more memory for storing intermediate outputs. In this paper, we present MONeT, an automatic framework that minimizes both the memory footprint and computational overhead of deep networks. MONeT jointly optimizes the checkpointing schedule and the implementation of various operators. MONeT is able to outperform all prior hand-tuned operations as well as automated checkpointing. MONeT reduces the overall memory requirement by $3\times$ for various PyTorch models, with a 9-16$\%$ overhead in computation. For the same computation cost, MONeT requires 1.2-1.8$\times$ less memory than current state-of-the-art automated checkpointing frameworks. Our code will be made publicly available upon acceptance.",ディープラーニングはゆっくりですが着実に行われ、記憶のボトルネックになっています。最上位のGPUでのテンソル計算は過去5年間で32増加しましたが、使用可能なメモリの合計は2.5しか増加しませんでした。これにより、大規模なネットワークをトレーニングするには中間出力を格納するためにより多くのメモリが必要になるため、研究者は大規模なアーキテクチャを探索できなくなります。このホワイトペーパーでは、ディープネットワークのメモリフットプリントと計算オーバーヘッドの両方を最小限に抑える自動フレームワークであるMONeTを紹介します。 MONeTは、チェックポイントのスケジュールとさまざまなオペレーターの実装を共同で最適化します。 MONeTは、自動チェックポイントだけでなく、以前のすべての手動調整操作よりも優れたパフォーマンスを発揮します。 MONeTは、さまざまなPyTorchモデルの全体的なメモリ要件を3削減し、計算のオーバーヘッドを9〜16％削減します。同じ計算コストで、MONeTは現在の最先端の自動チェックポインティングフレームワークよりも1.2〜1.8少ないメモリを必要とします。私たちのコードは、承認され次第公開されます。,7.0,https://d3i71xaburhd42.cloudfront.net/b5697ed0c72b318d291545871fbd3a7a6e59e3cf/2-Figure1-1.png
DeepAveragers: Offline Reinforcement Learning By Solving Derived Non-Parametric MDPs,"['Aayam Kumar Shrestha', 'Stefan Lee', 'Prasad Tadepalli', 'Alan Fern']",https://openreview.net/forum?id=eMP1j9efXtX,"We study an approach to offline reinforcement learning (RL) based on optimally solving  finitely-represented  MDPs  derived  from  a  static  dataset  of  experience. This approach can be applied on top of any learned representation and has the potential to easily support multiple solution objectives as well as zero-shot adjustment to changing environments and goals.  Our main contribution is to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate its solutions for offline RL.  DAC-MDPs are a non-parametric model that can leverage deep representations and account for limited data by introducing costs for exploiting under-represented parts of the model.  In theory, we show conditions that allow for lower-bounding the performance of DAC-MDP solutions. We also investigate the empirical behavior in a number of environments, including those with image-based observations. Overall, the experiments demonstrate that the framework can work in practice and scale to large complex offline RL problems.",経験の静的データセットから導出された有限表現のMDPを最適に解くことに基づいて、オフライン強化学習（RL）へのアプローチを研究します。このアプローチは、学習した表現の上に適用でき、変化する環境や目標に対するゼロショット調整だけでなく、複数のソリューション目標を簡単にサポートできる可能性があります。私たちの主な貢献は、コストMDP（DAC-MDP）を備えたディープアベレージャーを紹介し、オフラインRLのソリューションを調査することです。 DAC-MDPは、モデルの過小評価された部分を活用するためのコストを導入することにより、深い表現を活用し、限られたデータを説明できるノンパラメトリックモデルです。理論的には、DAC-MDPソリューションのパフォーマンスの下限を可能にする条件を示します。また、画像ベースの観察を含む多くの環境での経験的挙動を調査します。全体として、実験は、フレームワークが実際に機能し、大規模で複雑なオフラインRL問題に拡張できることを示しています。,6.8,https://d3i71xaburhd42.cloudfront.net/14e6502e4a63635ef01790471f45f369de72a1c0/2-Figure1-1.png
The geometry of integration in text classification RNNs,"['Kyle Aitken', 'Vinay Venkatesh Ramasesh', 'Ankush Garg', 'Yuan Cao', 'David Sussillo', 'Niru Maheswaranathan']",https://openreview.net/forum?id=42kiJ7n_8xO,"Despite the widespread application of recurrent neural networks (RNNs), a unified understanding of how RNNs solve particular tasks remains elusive.  In particular, it is unclear what dynamical patterns arise in trained RNNs, and how those pat-terns depend on the training dataset or task.  This work addresses these questions in the context of text classification, building on earlier work studying the dynamics of binary sentiment-classification networks (Maheswaranathan et al., 2019).  We study text-classification tasks beyond the binary case, exploring the dynamics ofRNNs trained on both natural and synthetic datasets.  These dynamics, which we find to be both interpretable and low-dimensional, share a common mechanism across architectures and datasets:  specifically, these text-classification networks use low-dimensional attractor manifolds to accumulate evidence for each class as they process the text.  The dimensionality and geometry of the attractor manifold are determined by the structure of the training dataset, with the dimensionality reflecting the number of scalar quantities the network remembers in order to classify.In categorical classification, for example, we show that this dimensionality is one less than the number of classes. Correlations in the dataset, such as those induced by ordering, can further reduce the dimensionality of the attractor manifold; we show how to predict this reduction using simple word-count statistics computed on the training dataset. To the degree that integration of evidence towards a decision is a common computational primitive, this work continues to lay the foundation for using dynamical systems techniques to study the inner workings of RNNs.",リカレントニューラルネットワーク（RNN）が広く適用されているにもかかわらず、RNNが特定のタスクをどのように解決するかについての統一された理解はとらえどころのないままです。特に、トレーニングされたRNNでどのような動的パターンが発生し、それらのパターンがトレーニングデータセットまたはタスクにどのように依存するかは不明です。この作業は、バイナリ感情分類ネットワークのダイナミクスを研究する以前の作業に基づいて、テキスト分類のコンテキストでこれらの質問に対処します（Maheswaranathan et al。、2019）。自然データセットと合成データセットの両方でトレーニングされたRNNのダイナミクスを調査し、バイナリの場合を超えてテキスト分類タスクを研究します。これらのダイナミクスは、解釈可能で低次元であることがわかり、アーキテクチャとデータセット間で共通のメカニズムを共有しています。具体的には、これらのテキスト分類ネットワークは、低次元のアトラクタマニホールドを使用して、テキストを処理するときに各クラスの証拠を蓄積します。アトラクタ多様体の次元とジオメトリは、トレーニングデータセットの構造によって決定されます。次元は、分類するためにネットワークが記憶するスカラー量の数を反映します。たとえば、カテゴリ分類では、この次元が1つ少ないことを示します。クラスの数より。順序付けによって引き起こされるようなデータセット内の相関は、アトラクタ多様体の次元をさらに減らす可能性があります。トレーニングデータセットで計算された単純な単語数統計を使用して、この削減を予測する方法を示します。意思決定に向けた証拠の統合が一般的な計算プリミティブである限り、この作業は、動的システム技術を使用してRNNの内部動作を研究するための基礎を築き続けています。,6.8,https://d3i71xaburhd42.cloudfront.net/a33afefa789b5f3f3f41e0e33f7e0271008799b0/3-Figure1-1.png
A Universal Representation Transformer Layer for Few-Shot Image Classification,"['Lu Liu', 'William L. Hamilton', 'Guodong Long', 'Jing Jiang', 'Hugo Larochelle']",https://openreview.net/forum?id=04cII6MumYV,"Few-shot classification aims to recognize unseen classes when presented with only a small number of samples. We consider the problem of multi-domain few-shot image classification, where unseen classes and examples come from diverse data sources. This problem has seen growing interest and has inspired the development of benchmarks such as Meta-Dataset. A key challenge in this multi-domain setting is to effectively integrate the feature representations from the diverse set of training domains. Here, we propose a Universal Representation Transformer (URT) layer, that meta-learns to leverage universal features for few-shot classification by dynamically re-weighting and composing the most appropriate domain-specific representations. In experiments, we show that URT sets a new state-of-the-art result on Meta-Dataset. Specifically, it achieves top-performance on the highest number of data sources compared to competing methods. We analyze variants of URT and present a visualization of the attention score heatmaps that sheds light on how the model performs cross-domain generalization.",少数のショットの分類は、少数のサンプルのみが提示されたときに、見えないクラスを認識することを目的としています。マルチドメインの数ショット画像分類の問題を検討します。ここでは、目に見えないクラスと例がさまざまなデータソースから取得されます。この問題への関心が高まり、メタデータセットなどのベンチマークの開発に影響を与えました。このマルチドメイン設定での重要な課題は、トレーニングドメインの多様なセットからの機能表現を効果的に統合することです。ここでは、Universal Representation Transformer（URT）レイヤーを提案します。これは、最も適切なドメイン固有の表現を動的に再重み付けして構成することにより、数ショットの分類にユニバーサル機能を活用することをメタ学習します。実験では、URTがメタデータセットに新しい最先端の結果を設定することを示します。具体的には、競合する方法と比較して、最大数のデータソースで最高のパフォーマンスを実現します。 URTのバリアントを分析し、モデルがクロスドメインの一般化を実行する方法に光を当てる注意スコアヒートマップの視覚化を提示します。,6.8,https://d3i71xaburhd42.cloudfront.net/6e1efe22d5696269aff7addcb438f77ff6cc2508/4-Figure1-1.png
FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,"['Yi Ren', 'Chenxu Hu', 'Xu Tan', 'Tao Qin', 'Sheng Zhao', 'Zhou Zhao', 'Tie-Yan Liu']",https://openreview.net/forum?id=piLPYqxtWuA,"Non-autoregressive text to speech (TTS) models such as FastSpeech can synthesize speech significantly faster than previous autoregressive models with comparable quality. The training of FastSpeech model relies on an autoregressive teacher model for duration prediction (to provide more information as input) and knowledge distillation (to simplify the data distribution in output), which can ease the one-to-many mapping problem (i.e., multiple speech variations correspond to the same text) in TTS. However, FastSpeech has several disadvantages: 1) the teacher-student distillation pipeline is complicated and time-consuming, 2) the duration extracted from the teacher model is not accurate enough, and the target mel-spectrograms distilled from teacher model suffer from information loss due to data simplification, both of which limit the voice quality. In this paper, we propose FastSpeech 2, which addresses the issues in FastSpeech and better solves the one-to-many mapping problem in TTS by 1) directly training the model with ground-truth target instead of the simplified output from teacher, and 2) introducing more variation information of speech (e.g., pitch, energy and more accurate duration) as conditional inputs. Specifically, we extract duration, pitch and energy from speech waveform and directly take them as conditional inputs in training and use predicted values in inference. We further design FastSpeech 2s, which is the first attempt to directly generate speech waveform from text in parallel, enjoying the benefit of fully end-to-end inference. Experimental results show that 1) FastSpeech 2 achieves a 3x training speed-up over FastSpeech, and FastSpeech 2s enjoys even faster inference speed; 2) FastSpeech 2 and 2s outperform FastSpeech in voice quality, and FastSpeech 2 can even surpass autoregressive models. Audio samples are available at https://fastspeech2.github.io/fastspeech2/.",FastSpeechなどの非自己回帰テキスト読み上げ（TTS）モデルは、同等の品質で以前の自己回帰モデルよりも大幅に高速に音声を合成できます。 FastSpeechモデルのトレーニングは、期間予測（入力としてより多くの情報を提供するため）と知識の蒸留（出力でのデータ分散を簡素化するため）の自己回帰教師モデルに依存しており、1対多のマッピング問題（つまり、複数音声のバリエーションは、TTSの同じテキストに対応します。ただし、FastSpeechにはいくつかの欠点があります。1）教師と生徒の蒸留パイプラインが複雑で時間がかかる、2）教師モデルから抽出された期間が十分に正確でない、教師モデルから抽出されたターゲットのメルスペクトログラムが情報損失に悩まされるデータが単純化されているため、どちらも音声品質を制限します。この論文では、FastSpeech 2を提案します。これは、FastSpeechの問題に対処し、1）教師からの単純化された出力ではなく、グラウンドトゥルースターゲットを使用してモデルを直接トレーニングすることにより、TTSの1対多のマッピング問題をより適切に解決します。 ）条件付き入力として、音声のより多くのバリエーション情報（ピッチ、エネルギー、より正確な持続時間など）を導入します。具体的には、音声波形から持続時間、ピッチ、エネルギーを抽出し、それらをトレーニングの条件付き入力として直接取得し、予測値を推論に使用します。さらに、FastSpeech 2sを設計します。これは、テキストから音声波形を並列に直接生成する最初の試みであり、完全なエンドツーエンドの推論の利点を享受しています。実験結果は、1）FastSpeech 2がFastSpeechの3倍のトレーニング速度を達成し、FastSpeech2sがさらに速い推論速度を享受することを示しています。 2）FastSpeech 2および2は、音声品質においてFastSpeechを上回り、FastSpeech2は自己回帰モデルを超えることさえできます。オーディオサンプルはhttps://fastspeech2.github.io/fastspeech2/で入手できます。,6.8,https://d3i71xaburhd42.cloudfront.net/125e3a560f8ca2262637fd4741bbf70cc6d6e235/4-Figure1-1.png
Learning to Represent Action Values as a Hypergraph on the Action Vertices,"['Arash Tavakoli', 'Mehdi Fatemi', 'Petar Kormushev']",https://openreview.net/forum?id=Xv_s64FiXTv,"Action values are ubiquitous in reinforcement learning (RL) methods, with the sample complexity of such methods relying heavily on how fast a good estimator for action value can be learned. By viewing this problem through the lens of representation learning, good representations of both state and action can facilitate action-value estimation. While advances in deep learning have seamlessly driven progress in learning state representations, given the specificity of the notion of agency to RL, little attention has been paid to learning action representations. We conjecture that leveraging the combinatorial structure of multidimensional action spaces is a key ingredient for learning good representations of action. To test this, we set forth the action hypergraph networks framework---a class of functions for learning action representations in multidimensional discrete action spaces with a structural inductive bias. Using this framework we realise an agent class based on a combination with deep Q-networks, which we dub hypergraph Q-networks. We show the effectiveness of our approach on a myriad of domains: illustrative prediction problems under minimal confounding effects, Atari 2600 games, and discretised physical control benchmarks.",アクション値は強化学習（RL）メソッドに遍在しており、そのようなメソッドのサンプルの複雑さは、アクション値の適切な推定量をどれだけ速く学習できるかに大きく依存しています。表現学習のレンズを通してこの問題を見ると、状態とアクションの両方を適切に表現することで、アクション値の推定が容易になります。ディープラーニングの進歩は、状態表現の学習の進歩をシームレスに推進してきましたが、RLに対するエージェンシーの概念の特異性を考えると、アクション表現の学習にはほとんど注意が払われていません。多次元アクションスペースの組み合わせ構造を活用することは、アクションの適切な表現を学習するための重要な要素であると推測します。これをテストするために、アクションハイパーグラフネットワークフレームワークを、構造的誘導バイアスを使用して多次元離散アクション空間でアクション表現を学習するための関数のクラスとして説明します。このフレームワークを使用して、ハイパーグラフQネットワークをダビングするディープQネットワークとの組み合わせに基づくエージェントクラスを実現します。最小限の交絡効果の下での例示的な予測問題、Atari 2600ゲーム、および離散化された物理制御ベンチマークなど、無数のドメインに対するアプローチの有効性を示します。,6.8,https://d3i71xaburhd42.cloudfront.net/f3d5640c2088037481c7ff4362e6072db3393872/3-Figure1-1.png
A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks,"['Nikunj Saunshi', 'Sadhika Malladi', 'Sanjeev Arora']",https://openreview.net/forum?id=vVjIW3sEc1s,"Autoregressive language models pretrained on large corpora have been successful at solving downstream tasks, even with zero-shot usage. However, there is little theoretical justification for their success. This paper considers the following questions: (1) Why should learning the distribution of natural language help with downstream classification tasks? (2) Why do features learned using language modeling help solve downstream tasks with linear classifiers? For (1), we hypothesize, and verify empirically, that classification tasks of interest can be reformulated as next word prediction tasks, thus making language modeling a meaningful pretraining task. For (2), we analyze properties of the cross-entropy objective to show that $\epsilon$-optimal language models in cross-entropy (log-perplexity) learn features that are $\mathcal{O}(\sqrt{\epsilon})$-good on natural linear classification tasks, thus demonstrating mathematically that doing well on language modeling can be beneficial for downstream tasks. We perform experiments to verify assumptions and validate theoretical results. Our theoretical insights motivate a simple alternative to the cross-entropy objective that performs well on some linear classification tasks.",大規模なコーパスで事前トレーニングされた自己回帰言語モデルは、ゼロショットの使用でも、ダウンストリームタスクの解決に成功しています。しかし、彼らの成功の理論的正当性はほとんどありません。このペーパーでは、次の質問について検討します。（1）自然言語の分布を学習することが、下流の分類タスクに役立つのはなぜですか。 （2）言語モデリングを使用して学習した機能が、線形分類器を使用したダウンストリームタスクの解決に役立つのはなぜですか？ （1）については、関心のある分類タスクを次の単語予測タスクとして再定式化できることを仮定し、経験的に検証します。これにより、言語モデリングが意味のある事前トレーニングタスクになります。 （2）については、クロスエントロピー目標のプロパティを分析して、クロスエントロピー（対数パープレキシティ）の最適な言語モデルが$ \ mathcal {O}（\ sqrt {\ epsilon}）$-である機能を学習することを示します。自然な線形分類タスクに適しているため、言語モデリングでうまくいくことが下流のタスクに役立つ可能性があることを数学的に示しています。仮定を検証し、理論的な結果を検証するために実験を行います。私たちの理論的洞察は、いくつかの線形分類タスクでうまく機能するクロスエントロピー目標の単純な代替案を動機付けます。,6.8,https://d3i71xaburhd42.cloudfront.net/01400290c7db96c4d665d1c29519c42ba47401e0/8-Figure1-1.png
Refining Deep Generative Models via Wasserstein Gradient Flows,"['Abdul Fatir Ansari', 'Ming Liang Ang', 'Harold Soh']",https://openreview.net/forum?id=Zbc-ue9p_rE,"Deep generative modeling has seen impressive advances in recent years, to the point where it is now commonplace to see simulated samples (e.g., images) that closely resemble real-world data. However, generation quality is generally inconsistent for any given model and can vary dramatically between samples. We introduce Discriminator Gradient $f$low (DG$f$low), a new technique that improves generated samples via the gradient flow of entropy-regularized $f$-divergences between the real and the generated data distributions. The gradient flow takes the form of a non-linear Fokker-Plank equation, which can be easily simulated by sampling from the equivalent McKean-Vlasov process. By refining inferior samples, our technique avoids wasteful sample rejection used by previous methods (DRS & MH-GAN). Compared to existing works that focus on specific GAN variants, we show our refinement approach can be applied to GANs with vector-valued critics and even other deep generative models such as VAEs and Normalizing Flows. Empirical results on multiple synthetic, image, and text datasets demonstrate that DG$f$low leads to significant improvement in the quality of generated samples for a variety of generative models, outperforming the state-of-the-art Discriminator Optimal Transport (DOT) and Discriminator Driven Latent Sampling (DDLS) methods.",ディープジェネレーティブモデリングは、近年、目覚ましい進歩を遂げており、実際のデータに非常によく似たシミュレートされたサンプル（画像など）を見ることが一般的になっています。ただし、生成品質は通常、特定のモデルで一貫性がなく、サンプル間で大幅に異なる可能性があります。実データ分布と生成データ分布の間のエントロピー正則化f発散の勾配フローを介して、生成されたサンプルを改善する新しい手法であるDiscriminator Gradient Flow（DGflow）を紹介します。勾配流は、非線形のフォッカープランク方程式の形式を取ります。これは、同等のマッキーン-ウラソフプロセスからサンプリングすることで簡単にシミュレートできます。劣ったサンプルを精製することにより、私たちの技術は、以前の方法（DRS＆MH-GAN）で使用されていた無駄なサンプル除去を回避します。特定のGANバリアントに焦点を当てた既存の作業と比較して、ベクトル値の批評家やVAEや正規化フローなどの他の深い生成モデルを使用するGANに洗練されたアプローチを適用できることを示します。複数の合成、画像、およびテキストデータセットの経験的結果は、DGflowがさまざまな生成モデルの生成サンプルの品質を大幅に改善し、最先端のDiscriminator Optimal Transport（DOT）およびDiscriminator DrivenLatentを上回っていることを示しています。サンプリング（DDLS）メソッド。,6.8,https://d3i71xaburhd42.cloudfront.net/36a4b0386b63bcb80d07f9c673f78ca3c31f7cd3/2-Figure1-1.png
Regularized Inverse Reinforcement Learning,"['Wonseok Jeon', 'Chen-Yang Su', 'Paul Barde', 'Thang Doan', 'Derek Nowrouzezahrai', 'Joelle Pineau']",https://openreview.net/forum?id=HgLO8yalfwc,"Inverse Reinforcement Learning (IRL) aims to facilitate a learner's ability to imitate expert behavior by acquiring reward functions that explain the expert's decisions. Regularized IRL applies strongly convex regularizers to the learner's policy in order to avoid the expert's behavior being rationalized by arbitrary constant rewards, also known as degenerate solutions. We propose tractable solutions, and practical methods to obtain them, for regularized IRL. Current methods are restricted to the maximum-entropy IRL framework, limiting them to Shannon-entropy regularizers, as well as proposing the solutions that are intractable in practice. We present theoretical backing for our proposed IRL method's applicability for both discrete and continuous controls, empirically validating our performance on a variety of tasks.  ",逆強化学習（IRL）は、専門家の決定を説明する報酬関数を取得することにより、学習者が専門家の行動を模倣する能力を促進することを目的としています。正則化されたIRLは、退化したソリューションとしても知られる任意の一定の報酬によって専門家の行動が合理化されるのを避けるために、学習者のポリシーに強く凸の正則化を適用します。正則化されたIRLのために、扱いやすいソリューションとそれらを取得するための実用的な方法を提案します。現在の方法は、最大エントロピーIRLフレームワークに制限されており、シャノンエントロピー正規化装置に限定されているだけでなく、実際には手に負えないソリューションを提案しています。提案されたIRLメソッドの離散制御と連続制御の両方への適用性の理論的裏付けを提示し、さまざまなタスクでのパフォーマンスを経験的に検証します。,6.8,https://d3i71xaburhd42.cloudfront.net/973fbe99e9b32f9da7e976e11141eec05ba577d3/5-Figure1-1.png
Lifelong Learning of Compositional Structures,"['Jorge A Mendez', 'ERIC EATON']",https://openreview.net/forum?id=ADWd4TJO13G,"A hallmark of human intelligence is the ability to construct self-contained chunks of knowledge and adequately reuse them in novel combinations for solving different yet structurally related problems. Learning such compositional structures has been a significant challenge for artificial systems, due to the combinatorial nature of the underlying search problem. To date, research into compositional learning has largely proceeded separately from work on lifelong or continual learning. We integrate these two lines of work to present a general-purpose framework for lifelong learning of compositional structures that can be used for solving a stream of related tasks. Our framework separates the learning process into two broad stages: learning how to best combine existing components in order to assimilate a novel problem, and learning how to adapt the set of existing components to accommodate the new problem. This separation explicitly handles the trade-off between the stability required to remember how to solve earlier tasks and the flexibility required to solve new tasks, as we show empirically in an extensive evaluation.",人間の知性の特徴は、自己完結型の知識の塊を構築し、それらを新しい組み合わせで適切に再利用して、異なるが構造的に関連する問題を解決する能力です。そのような構成構造を学ぶことは、根底にある探索問題の組み合わせの性質のために、人工システムにとって重要な課題でした。これまで、構成学習の研究は、生涯学習または継続学習の研究とは別に主に進められてきました。これらの2つの作業ラインを統合して、関連する一連のタスクを解決するために使用できる構成構造の生涯学習のための汎用フレームワークを提示します。私たちのフレームワークは、学習プロセスを2つの大きな段階に分けます。新しい問題を吸収するために既存のコンポーネントを最適に組み合わせる方法を学習する方法と、新しい問題に対応するために既存のコンポーネントのセットを適応させる方法を学習する方法です。この分離は、広範な評価で経験的に示したように、以前のタスクを解決する方法を覚えておくために必要な安定性と新しいタスクを解決するために必要な柔軟性の間のトレードオフを明示的に処理します。,6.8,
Hopper: Multi-hop Transformer for Spatiotemporal Reasoning,"['Honglu Zhou', 'Asim Kadav', 'Farley Lai', 'Alexandru Niculescu-Mizil', 'Martin Renqiang Min', 'Mubbasir Kapadia', 'Hans Peter Graf']",https://openreview.net/forum?id=MaZFq7bJif7,"This paper considers the problem of spatiotemporal object-centric reasoning in videos. Central to our approach is the notion of object permanence, i.e., the ability to reason about the location of objects as they move through the video while being occluded, contained or carried by other objects. Existing deep learning based approaches often suffer from spatiotemporal biases when applied to video reasoning problems. We propose Hopper, which uses a Multi-hop Transformer for reasoning object permanence in videos. Given a video and a localization query, Hopper reasons over image and object tracks to automatically hop over critical frames in an iterative fashion to predict the final position of the object of interest. We demonstrate the effectiveness of using a contrastive loss to reduce spatiotemporal biases. We evaluate over CATER dataset and find that Hopper achieves 73.2% Top-1 accuracy using just 1 FPS by hopping through just a few critical frames. We also demonstrate Hopper can perform long-term reasoning by building a CATER-h dataset that requires multi-step reasoning to localize objects of interest correctly.",この論文は、ビデオにおける時空間オブジェクト中心の推論の問題を考察します。私たちのアプローチの中心は、オブジェクトの永続性の概念です。つまり、オブジェクトが他のオブジェクトによって遮られたり、封じ込められたり、運ばれたりしながら、ビデオ内を移動するときにオブジェクトの位置を推論する機能です。既存の深層学習ベースのアプローチは、ビデオ推論の問題に適用されると、時空間バイアスに悩まされることがよくあります。ビデオ内のオブジェクトの永続性を推論するためにマルチホップトランスフォーマーを使用するホッパーを提案します。ビデオとローカリゼーションクエリが与えられると、ホッパーは画像とオブジェクトトラックを推論して、重要なフレームを反復的に自動的にホップし、対象のオブジェクトの最終的な位置を予測します。対照的な損失を使用して時空間バイアスを減らすことの有効性を示します。 CATERデータセットを評価したところ、Hopperが73.2を達成していることがわかりました。,6.75,
Optimal Regularization can Mitigate Double Descent,"['Preetum Nakkiran', 'Prayaag Venkat', 'Sham M. Kakade', 'Tengyu Ma']",https://openreview.net/forum?id=7R7fAoUygoa,"Recent empirical and theoretical studies have shown that many learning algorithms -- from linear regression to neural networks -- can have test performance that is non-monotonic in quantities such the sample size and model size. This striking phenomenon, often referred to as ""double descent"", has raised questions of if we need to re-think our current understanding of generalization. In this work, we study whether the double-descent phenomenon can be avoided by using optimal regularization. Theoretically, we prove that for certain linear regression models with isotropic data distribution, optimally-tuned $\ell_2$ regularization achieves monotonic test performance as we grow either the sample size or the model size.
We also demonstrate empirically that optimally-tuned $\ell_2$ regularization can mitigate double descent for more general models, including neural networks.
Our results suggest that it may also be informative to study the test risk scalings of various algorithms in the context of appropriately tuned regularization.",最近の経験的および理論的研究は、線形回帰からニューラルネットワークまでの多くの学習アルゴリズムが、サンプルサイズやモデルサイズなどの量で非単調なテストパフォーマンスを持つことができることを示しています。しばしば「二重降下」と呼ばれるこの印象的な現象は、一般化の現在の理解を再考する必要があるかどうかという疑問を提起しました。この作業では、最適な正則化を使用することにより、二重降下現象を回避できるかどうかを調べます。理論的には、等方性データ分布を持つ特定の線形回帰モデルの場合、サンプルサイズまたはモデルサイズのいずれかを増やすと、最適に調整されたl2正則化が単調なテストパフォーマンスを達成することを証明します。また、最適に調整されたl2正則化が、ニューラルネットワークを含むより一般的なモデルの二重降下を軽減できることを経験的に示します。私たちの結果は、適切に調整された正則化のコンテキストでさまざまなアルゴリズムのテストリスクスケーリングを研究することも有益である可能性があることを示唆しています。,6.75,
Robust early-learning: Hindering the memorization of noisy labels,"['Xiaobo Xia', 'Tongliang Liu', 'Bo Han', 'Chen Gong', 'Nannan Wang', 'Zongyuan Ge', 'Yi Chang']",https://openreview.net/forum?id=Eql5b1_hTE4,"The \textit{memorization effects} of deep networks show that they will first memorize training data with clean labels and then those with noisy labels. The \textit{early stopping} method therefore can be exploited for learning with noisy labels. However, the side effect brought by noisy labels will influence the memorization of clean labels before early stopping. In this paper, motivated by the \textit{lottery ticket hypothesis} which shows that only partial parameters are important for generalization, we find that only partial parameters are important for fitting clean labels and generalize well, which we term as \textit{critical parameters}; while the other parameters tend to fit noisy labels and cannot generalize well, which we term as \textit{non-critical parameters}. Based on this, we propose \textit{robust early-learning} to reduce the side effect of noisy labels before early stopping and thus enhance the memorization of clean labels. Specifically, in each iteration, we divide all parameters into the critical and non-critical ones, and then perform different update rules for different types of parameters. Extensive experiments on benchmark-simulated and real-world label-noise datasets demonstrate the superiority of the proposed method over the state-of-the-art label-noise learning methods.",深いネットワークの記憶効果は、最初にクリーンなラベルでトレーニングデータを記憶し、次にノイズの多いラベルでトレーニングデータを記憶することを示しています。したがって、早期停止方法は、ノイズの多いラベルを使用した学習に利用できます。ただし、ノイズの多いラベルによってもたらされる副作用は、早期停止前のクリーンなラベルの記憶に影響を与えます。この論文では、部分的なパラメータのみが一般化に重要であることを示す宝くじの仮説に動機付けられて、部分的なパラメータのみがクリーンなラベルをフィッティングし、よく一般化するために重要であることがわかります。これを重要なパラメータと呼びます。一方、他のパラメータはノイズの多いラベルに適合する傾向があり、一般化できません。これを重要ではないパラメータと呼びます。これに基づいて、早期停止前にノイズの多いラベルの副作用を減らし、クリーンなラベルの記憶を強化するための堅牢な早期学習を提案します。具体的には、各反復で、すべてのパラメーターをクリティカルパラメーターと非クリティカルパラメーターに分割し、パラメーターのタイプごとに異なる更新ルールを実行します。ベンチマークでシミュレートされた実世界のラベルノイズデータセットに関する広範な実験は、最先端のラベルノイズ学習方法に対する提案された方法の優位性を示しています。,6.75,
Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation,"['Emilio Parisotto', 'Russ Salakhutdinov']",https://openreview.net/forum?id=uR9LaO_QxF,"Many real-world applications such as robotics provide hard constraints on power and compute that limit the viable model complexity of Reinforcement Learning (RL) agents. Similarly, in many distributed RL settings, acting is done on un-accelerated hardware such as CPUs, which likewise restricts model size to prevent intractable experiment run times. These ""actor-latency"" constrained settings present a major obstruction to the scaling up of model complexity that has recently been extremely successful in supervised learning. To be able to utilize large model capacity while still operating within the limits imposed by the system during acting, we develop an ""Actor-Learner Distillation"" (ALD) procedure that leverages a continual form of distillation that transfers learning progress from a large capacity learner model to a small capacity actor model. As a case study, we develop this procedure in the context of partially-observable environments, where transformer models have had large improvements over LSTMs recently, at the cost of significantly higher computational complexity. With transformer models as the learner and LSTMs as the actor, we demonstrate in several challenging memory environments that using Actor-Learner Distillation largely recovers the clear sample-efficiency gains of the transformer learner model while maintaining the fast inference and reduced total training time of the LSTM actor model.",ロボット工学などの多くの実際のアプリケーションは、強化学習（RL）エージェントの実行可能なモデルの複雑さを制限する電力と計算に厳しい制約を提供します。同様に、多くの分散RL設定では、CPUなどの高速化されていないハードウェアで動作が実行されます。これにより、モデルサイズが制限され、手に負えない実験の実行時間が防止されます。これらの「アクター待ち時間」の制約された設定は、教師あり学習で最近非常に成功しているモデルの複雑さのスケールアップに対する大きな障害となります。演技中にシステムによって課せられた制限内で動作しながら大容量のモデルを利用できるようにするために、大容量の学習者から学習の進行状況を転送する継続的な形式の蒸留を活用する「アクター-学習者蒸留」（ALD）手順を開発します小容量のアクターモデルへのモデル。ケーススタディとして、この手順は、部分的に観察可能な環境のコンテキストで開発します。この環境では、計算が大幅に複雑になる代わりに、最近、トランスモデルがLSTMよりも大幅に改善されています。学習者としてのトランスフォーマーモデルとアクターとしてのLSTMを使用して、いくつかの困難なメモリ環境で、Actor-Learner Distillationを使用すると、トランスフォーマー学習者モデルの明確なサンプル効率の向上が大幅に回復すると同時に、 LSTMアクターモデル。,6.75,
Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforcement Learning,"['Valerie Chen', 'Abhinav Gupta', 'Kenneth Marino']",https://openreview.net/forum?id=Y87Ri-GNHYu,"Complex, multi-task problems have proven to be difficult to solve efficiently in a sparse-reward reinforcement learning setting. In order to be sample efficient, multi-task learning requires reuse and sharing of low-level policies. To facilitate the automatic decomposition of hierarchical tasks, we propose the use of step-by-step human demonstrations in the form of natural language instructions and action trajectories. We introduce a dataset of such demonstrations in a crafting-based grid world. Our model consists of a high-level language generator and low-level policy, conditioned on language. We find that human demonstrations help solve the most complex tasks. We also find that incorporating natural language allows the model to generalize to unseen tasks in a zero-shot setting and to learn quickly from a few demonstrations. Generalization is not only reflected in the actions of the agent, but also in the generated natural language instructions in unseen tasks. Our approach also gives our trained agent interpretable behaviors because it is able to generate a sequence of high-level descriptions of its actions.",複雑なマルチタスクの問題は、まばらな報酬の強化学習環境では効率的に解決するのが難しいことが証明されています。サンプルを効率的にするために、マルチタスク学習では、低レベルのポリシーの再利用と共有が必要です。階層的なタスクの自動分解を容易にするために、自然言語の指示とアクションの軌跡の形で段階的な人間のデモンストレーションの使用を提案します。クラフトベースのグリッドの世界でそのようなデモンストレーションのデータセットを紹介します。私たちのモデルは、言語を条件とした高水準言語ジェネレーターと低水準ポリシーで構成されています。人間によるデモンストレーションは、最も複雑なタスクの解決に役立つことがわかりました。また、自然言語を組み込むことで、モデルをゼロショット設定で目に見えないタスクに一般化し、いくつかのデモンストレーションからすばやく学習できることもわかりました。一般化は、エージェントのアクションだけでなく、目に見えないタスクで生成された自然言語の指示にも反映されます。私たちのアプローチは、そのアクションの高レベルの説明のシーケンスを生成できるため、トレーニングを受けたエージェントに解釈可能な動作も提供します。,6.75,https://d3i71xaburhd42.cloudfront.net/2c658528207fdfcc97389535859b2780bc16bf7a/2-Figure1-1.png
Linear Last-iterate Convergence in Constrained Saddle-point Optimization,"['Chen-Yu Wei', 'Chung-Wei Lee', 'Mengxiao Zhang', 'Haipeng Luo']",https://openreview.net/forum?id=dx11_7vm5_r,"Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) for saddle-point optimization have received growing attention due to their favorable last-iterate convergence. However, their behaviors for simple bilinear games over the probability simplex are still not fully understood --- previous analysis lacks explicit convergence rates, only applies to an exponentially small learning rate, or requires additional assumptions such as the uniqueness of the optimal solution.

In this work, we significantly expand the understanding of last-iterate convergence for OGDA and OMWU in the constrained setting. Specifically, for OMWU in bilinear games over the simplex, we show that when the equilibrium is unique, linear last-iterate convergence is achievable with a constant learning rate, which improves the result of (Daskalakis & Panageas, 2019) under the same assumption. We then significantly extend the results to more general objectives and feasible sets for the projected OGDA algorithm, by introducing a sufficient condition under which OGDA exhibits concrete last-iterate convergence rates with a constant learning rate. We show that bilinear games over any polytope satisfy this condition and OGDA converges exponentially fast even without the unique equilibrium assumption. Our condition also holds for strongly-convex-strongly-concave functions, recovering the result of (Hsieh et al., 2019). Finally, we provide experimental results to further support our theory. ",鞍点最適化のための楽観的最急降下法（OGDA）と楽観的乗法重み更新（OMWU）は、それらの好ましい最後の反復収束のためにますます注目を集めています。ただし、確率シンプレックスに対する単純な双線形ゲームの動作はまだ完全には理解されていません。以前の分析では、明示的な収束率がないか、指数関数的に小さい学習率にのみ適用されるか、最適解の一意性などの追加の仮定が必要です。この作業では、制約された設定でのOGDAとOMWUの最後の反復収束の理解を大幅に拡大します。具体的には、シンプレックス上の双線形ゲームのOMWUの場合、平衡が一意である場合、一定の学習率で線形の最後の反復収束が達成可能であり、同じ仮定の下で（Daskalakis＆Panageas、2019）の結果が改善されることを示します。次に、OGDAが一定の学習率で具体的な最後の反復収束率を示す十分条件を導入することにより、予測されたOGDAアルゴリズムのより一般的な目的と実行可能セットに結果を大幅に拡張します。ポリトープ上の双線形ゲームがこの条件を満たすことを示し、OGDAは、固有の平衡仮定がなくても指数関数的に速く収束します。私たちの条件は、強凸-強凹関数にも当てはまり、の結果を回復します（Hsieh et al。、2019）。最後に、私たちの理論をさらにサポートするための実験結果を提供します。,6.75,
Self-supervised Representation Learning with Relative Predictive Coding,"['Yao-Hung Hubert Tsai', 'Martin Q. Ma', 'Muqiao Yang', 'Han Zhao', 'Louis-Philippe Morency', 'Ruslan Salakhutdinov']",https://openreview.net/forum?id=068E_JSq9O,"This paper introduces Relative Predictive Coding (RPC), a new contrastive representation learning objective that maintains a good balance among training stability, minibatch size sensitivity, and downstream task performance. The key to the success of RPC is two-fold. First, RPC introduces the relative parameters to regularize the objective for boundedness and low variance. Second, RPC contains no logarithm and exponential score functions, which are the main cause of training instability in prior contrastive objectives. We empirically verify the effectiveness of RPC on benchmark vision and speech self-supervised learning tasks. Lastly, we relate RPC with mutual information (MI) estimation, showing RPC can be used to estimate MI with low variance. ",このホワイトペーパーでは、トレーニングの安定性、ミニバッチサイズの感度、およびダウンストリームタスクのパフォーマンスのバランスを維持する新しい対照表現学習目標であるRelative Predictive Coding（RPC）を紹介します。 RPCの成功の鍵は2つあります。まず、RPCは相対パラメーターを導入して、有界性と低分散の目的を正規化します。第2に、RPCには、対数関数と指数スコア関数が含まれていません。これらは、以前の対照的な目的でトレーニングが不安定になる主な原因です。ベンチマークビジョンと音声教師あり学習タスクに対するRPCの有効性を経験的に検証します。最後に、RPCを相互情報量（MI）推定と関連付け、RPCを使用して低分散でMIを推定できることを示します。,6.75,
IDF++: Analyzing and Improving Integer Discrete Flows for Lossless Compression,"['Rianne van den Berg', 'Alexey A. Gritsenko', 'Mostafa Dehghani', 'Casper Kaae Sønderby', 'Tim Salimans']",https://openreview.net/forum?id=MBOyiNnYthd,"In this paper we analyse and improve integer discrete flows for lossless compression. Integer discrete flows are a recently proposed class of models that learn invertible transformations for integer-valued random variables. Their discrete nature makes them particularly suitable for lossless compression with entropy coding schemes. We start by investigating a recent theoretical claim that states that invertible flows for discrete random variables are less flexible than their continuous counterparts. We refute this claim with a proof for integer discrete flows. Furthermore, we zoom in on the effect of gradient bias due to the straight-through estimator in integer discrete flows, and demonstrate that its influence is highly dependent on architecture choices and less prominent than previously thought. Finally, we show how different modifications to the architecture improve the performance of this model class for lossless compression.",この論文では、ロスレス圧縮のための整数離散フローを分析および改善します。整数離散フローは、整数値の確率変数の可逆変換を学習するモデルの最近提案されたクラスです。それらの離散的な性質により、エントロピーコーディングスキームを使用したロスレス圧縮に特に適しています。離散確率変数の可逆フローは、連続確率変数よりも柔軟性が低いという最近の理論的主張を調査することから始めます。この主張を整数離散フローの証明で反駁します。さらに、整数離散フローのストレートスルー推定量による勾配バイアスの影響にズームインし、その影響がアーキテクチャの選択に大きく依存し、以前に考えられていたほど目立たないことを示します。最後に、アーキテクチャへのさまざまな変更により、ロスレス圧縮のこのモデルクラスのパフォーマンスがどのように向上するかを示します。,6.75,
Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS,"['Lin Chen', 'Sheng Xu']",https://openreview.net/forum?id=vK9WrZ0QYQ,"We prove that the reproducing kernel Hilbert spaces (RKHS) of a deep neural tangent kernel and the Laplace kernel include the same set of functions, when both kernels are restricted to the sphere $\mathbb{S}^{d-1}$. Additionally, we prove that the exponential power kernel with a smaller power (making the kernel more non-smooth) leads to a larger RKHS, when it is restricted to the sphere $\mathbb{S}^{d-1}$ and when it is defined on the entire $\mathbb{R}^d$.",両方のカーネルが球S ^（d 1）に制限されている場合、ディープニューラルタンジェントカーネルとラプラスカーネルの再生核ヒルベルト空間（RKHS）に同じ関数のセットが含まれていることを証明します。さらに、球S ^（d 1）に制限され、R全体で定義されている場合、より小さなパワー（カーネルをより滑らかにしない）の指数パワーカーネルがより大きなRKHSにつながることを証明します。 ^（d）。,6.75,https://d3i71xaburhd42.cloudfront.net/754f1121da8290d5015cac701fd1e42de37fa49c/8-Figure1-1.png
Efficient Generalized Spherical CNNs,"['Oliver Cobb', 'Christopher G. R. Wallis', 'Augustine N. Mavor-Parker', 'Augustin Marignier', 'Matthew A. Price', ""Mayeul d'Avezac"", 'Jason McEwen']",https://openreview.net/forum?id=rWZz3sJfCkm,"Many problems across computer vision and the natural sciences require the analysis of spherical data, for which representations may be learned efficiently by encoding equivariance to rotational symmetries.  We present a generalized spherical CNN framework that encompasses various existing approaches and allows them to be leveraged alongside each other.  The only existing non-linear spherical CNN layer that is strictly equivariant has complexity $\mathcal{O}(C^2L^5)$, where $C$ is a measure of representational capacity and $L$ the spherical harmonic bandlimit.  Such a high computational cost often prohibits the use of strictly equivariant spherical CNNs.  We develop two new strictly equivariant layers with reduced complexity $\mathcal{O}(CL^4)$ and $\mathcal{O}(CL^3 \log L)$, making larger, more expressive models computationally feasible.  Moreover, we adopt efficient sampling theory to achieve further computational savings. We show that these developments allow the construction of more expressive hybrid models that achieve state-of-the-art accuracy and parameter efficiency on spherical benchmark problems.",コンピュータビジョンと自然科学にまたがる多くの問題は、球形データの分析を必要とします。そのため、回転対称性への同変写像をエンコードすることにより、表現を効率的に学習できます。さまざまな既存のアプローチを包含し、それらを互いに並行して活用できるようにする、一般化された球形CNNフレームワークを紹介します。厳密に同変である唯一の既存の非線形球面CNN層は、複雑さO（C2L5）を持ちます。ここで、Cは表現能力の尺度であり、Lは球面調和関数の帯域制限です。このような高い計算コストは​​、厳密に同変の球面CNNの使用を妨げることがよくあります。複雑さを低減した2つの新しい厳密に同変のレイヤーO（CL4）とO（CL3log L）を開発し、より大きく、より表現力豊かなモデルを計算上実行可能にします。さらに、効率的なサンプリング理論を採用して、さらに計算量を節約します。これらの開発により、球形ベンチマーク問題で最先端の精度とパラメーター効率を実現する、より表現力豊かなハイブリッドモデルの構築が可能になることを示します。,6.75,https://d3i71xaburhd42.cloudfront.net/cb27519fa1ce55b20c0dd4c0d8e7341244de0747/6-Figure1-1.png
Learning Structural Edits via Incremental Tree Transformations,"['Ziyu Yao', 'Frank F. Xu', 'Pengcheng Yin', 'Huan Sun', 'Graham Neubig']",https://openreview.net/forum?id=v9hAX77--cZ,"While most neural generative models generate outputs in a single pass, the human creative process is usually one of iterative building and refinement. Recent work has proposed models of editing processes, but these mostly focus on editing sequential data and/or only model a single editing pass. In this paper, we present a generic model for incremental editing of structured data (i.e. ''structural edits''). Particularly, we focus on tree-structured data, taking abstract syntax trees of computer programs as our canonical example. Our editor learns to iteratively generate tree edits (e.g. deleting or adding a subtree) and applies them to the partially edited data, thereby the entire editing process can be formulated as consecutive, incremental tree transformations. To show the unique benefits of modeling tree edits directly, we further propose a novel edit encoder for learning to represent edits, as well as an imitation learning method that allows the editor to be more robust. We evaluate our proposed editor on two source code edit datasets, where results show that, with the proposed edit encoder, our editor significantly improves accuracy over previous approaches that generate the edited program directly in one pass. Finally, we demonstrate that training our editor to imitate experts and correct its mistakes dynamically can further improve its performance.",ほとんどの神経生成モデルはシングルパスで出力を生成しますが、人間の創造的なプロセスは通常、反復的な構築と改良の1つです。最近の研究では、編集プロセスのモデルが提案されていますが、これらは主にシーケンシャルデータの編集に焦点を当てているか、単一の編集パスのみをモデル化しています。この論文では、構造化データの増分編集（つまり構造化編集）の一般的なモデルを紹介します。特に、コンピュータプログラムの抽象構文木を標準的な例として、ツリー構造のデータに焦点を当てます。私たちのエディターは、ツリー編集（サブツリーの削除や追加など）を繰り返し生成し、それらを部分的に編集されたデータに適用することを学習します。これにより、編集プロセス全体を連続した増分ツリー変換として定式化できます。ツリー編集を直接モデリングすることの独自の利点を示すために、編集を表現することを学習するための新しい編集エンコーダーと、エディターをより堅牢にする模倣学習方法をさらに提案します。 2つのソースコード編集データセットで提案されたエディターを評価します。結果は、提案された編集エンコーダーを使用すると、編集されたプログラムを1回のパスで直接生成する以前のアプローチよりも精度が大幅に向上することを示しています。最後に、専門家を模倣し、その間違いを動的に修正するようにエディターをトレーニングすることで、パフォーマンスをさらに向上できることを示します。,6.75,https://d3i71xaburhd42.cloudfront.net/1756376bf7cf0d0a7bec881d663b57907a361ecf/3-Figure1-1.png
Wasserstein Embedding for Graph Learning,"['Soheil Kolouri', 'Navid Naderializadeh', 'Gustavo K. Rohde', 'Heiko Hoffmann']",https://openreview.net/forum?id=AAes_3W-2z,"We present Wasserstein Embedding for Graph Learning (WEGL), a novel and fast framework for embedding entire graphs in a vector space, in which various machine learning models are applicable for graph-level prediction tasks. We leverage new insights on defining similarity between graphs as a function of the similarity between their node embedding distributions. Specifically, we use the Wasserstein distance to measure the dissimilarity between node embeddings of different graphs. Unlike prior work, we avoid pairwise calculation of distances between graphs and reduce the computational complexity from quadratic to linear in the number of graphs. WEGL calculates Monge maps from a reference distribution to each node embedding and, based on these maps, creates a fixed-sized vector representation of the graph. We evaluate our new graph embedding approach on various benchmark graph-property prediction tasks, showing state-of-the-art classification performance while having superior computational efficiency.",グラフ全体をベクトル空間に埋め込むための斬新で高速なフレームワークであるWassersteinEmbedding for Graph Learning（WEGL）を紹介します。このフレームワークでは、さまざまな機械学習モデルをグラフレベルの予測タスクに適用できます。ノード埋め込み分布間の類似性の関数としてグラフ間の類似性を定義する上で、新しい洞察を活用します。具体的には、ワッサースタイン距離を使用して、異なるグラフのノード埋め込み間の非類似度を測定します。以前の作業とは異なり、グラフ間の距離のペアワイズ計算を回避し、グラフの数の計算の複雑さを2次から線形に減らします。 WEGLは、参照分布から各ノード埋め込みへのMongeマップを計算し、これらのマップに基づいて、グラフの固定サイズのベクトル表現を作成します。さまざまなベンチマークグラフプロパティ予測タスクで新しいグラフ埋め込みアプローチを評価し、優れた計算効率を持ちながら、最先端の分類パフォーマンスを示します。,6.75,
Adversarial score matching and improved sampling for image generation,"['Alexia Jolicoeur-Martineau', 'Rémi Piché-Taillefer', 'Ioannis Mitliagkas', 'Remi Tachet des Combes']",https://openreview.net/forum?id=eLfqMl3z3lq,"Denoising Score Matching with Annealed Langevin Sampling (DSM-ALS) has recently found success in generative modeling. The approach works by first training a neural network to estimate the score of a distribution, and then using Langevin dynamics to sample from the data distribution assumed by the score network. Despite the convincing visual quality of samples, this method appears to perform worse than Generative Adversarial Networks (GANs) under the Fréchet Inception Distance, a standard metric for generative models. We show that this apparent gap vanishes when denoising the final Langevin samples using the score network.
In addition, we propose two improvements to DSM-ALS:  1) Consistent Annealed Sampling as a more stable alternative to Annealed Langevin Sampling, and 2) a hybrid training formulation, composed of both Denoising Score Matching and adversarial objectives. By combining these two techniques and exploring different network architectures, we elevate score matching methods and obtain results competitive with state-of-the-art image generation on CIFAR-10.",アニーリングされたランジュバンサンプリング（DSM-ALS）を使用したノイズ除去スコアマッチングは、最近、生成モデリングで成功を収めています。このアプローチは、最初にニューラルネットワークをトレーニングして分布のスコアを推定し、次にランジュバン動力学を使用してスコアネットワークによって想定されるデータ分布からサンプリングすることによって機能します。サンプルの説得力のある視覚的品質にもかかわらず、この方法は、生成モデルの標準メトリックであるフレシェ開始距離の下で、生成的敵対的ネットワーク（GAN）よりもパフォーマンスが悪いように見えます。スコアネットワークを使用して最終的なLangevinサンプルのノイズを除去すると、この明らかなギャップがなくなることを示します。さらに、DSM-ALSに2つの改善を提案します。1）アニーリングランジュバンサンプリングのより安定した代替手段としての一貫性アニーリングサンプリング、および2）ノイズ除去スコアマッチングと敵対目的の両方で構成されるハイブリッドトレーニング定式化。これら2つの手法を組み合わせ、さまざまなネットワークアーキテクチャを探索することで、スコアマッチング方法を向上させ、CIFAR-10での最先端の画像生成と競合する結果を取得します。,6.75,
Multi-Time Attention Networks for Irregularly Sampled Time Series,"['Satya Narayan Shukla', 'Benjamin Marlin']",https://openreview.net/forum?id=4c0J6lwQ4_,"Irregular sampling occurs in many time series modeling applications where it presents a significant challenge to standard deep learning models. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. In this paper, we propose a new deep learning framework for this setting that we call Multi-Time Attention Networks. Multi-Time Attention Networks learn an embedding of continuous time values and use an attention mechanism to produce a fixed-length representation of a time series containing a variable number of observations. We investigate the performance of our framework on interpolation and classification tasks using multiple datasets. Our results show that our approach performs as well or better than a range of baseline and recently proposed models while offering significantly faster training times than current state-of-the-art methods.",不規則なサンプリングは、多くの時系列モデリングアプリケーションで発生し、標準的な深層学習モデルに重大な課題をもたらします。この作業は、まばらで、不規則にサンプリングされ、多変量である電子健康記録の生理学的時系列データの分析によって動機付けられています。この論文では、マルチタイムアテンションネットワークと呼ばれる、この設定のための新しいディープラーニングフレームワークを提案します。マルチタイムアテンションネットワークは、連続時間値の埋め込みを学習し、アテンションメカニズムを使用して、可変数の観測値を含む時系列の固定長表現を生成します。複数のデータセットを使用して、補間および分類タスクでのフレームワークのパフォーマンスを調査します。私たちの結果は、私たちのアプローチが、現在の最先端の方法よりも大幅に速いトレーニング時間を提供しながら、ベースラインおよび最近提案されたモデルの範囲と同等またはそれ以上のパフォーマンスを発揮することを示しています。,6.75,
Getting a CLUE: A  Method for Explaining Uncertainty Estimates,"['Javier Antoran', 'Umang Bhatt', 'Tameem Adel', 'Adrian Weller', 'José Miguel Hernández-Lobato']",https://openreview.net/forum?id=XSLF1XFq5h,"Both uncertainty estimation and interpretability are important factors for trustworthy machine learning systems. However, there is little work at the intersection of these two areas. We address this gap by proposing a novel method for interpreting uncertainty estimates from differentiable probabilistic models, like Bayesian Neural Networks (BNNs). Our method, Counterfactual Latent Uncertainty Explanations (CLUE), indicates how to change an input, while keeping it on the data manifold, such that a BNN becomes more confident about the input's prediction. We validate CLUE through 1) a novel framework for evaluating counterfactual explanations of uncertainty, 2) a series of ablation experiments, and 3) a user study. Our experiments show that CLUE outperforms baselines and enables practitioners to better understand which input patterns are responsible for predictive uncertainty.",不確実性の推定と解釈可能性の両方が、信頼できる機械学習システムにとって重要な要素です。ただし、これら2つの領域の交差点ではほとんど作業がありません。ベイズニューラルネットワーク（BNN）のような微分可能な確率モデルからの不確実性推定を解釈するための新しい方法を提案することにより、このギャップに対処します。私たちの方法である反事実的潜在的不確実性の説明（CLUE）は、BNNが入力予測についてより自信を持つように、データ多様体に入力を保持しながら入力を変更する方法を示します。 CLUEは、1）不確実性の反事実的説明を評価するための新しいフレームワーク、2）一連のアブレーション実験、および3）ユーザー調査を通じて検証されます。私たちの実験は、CLUEがベースラインを上回り、どの入力パターンが予測の不確実性の原因であるかを実践者がよりよく理解できるようにすることを示しています。,6.75,
On Position Embeddings in BERT,"['Benyou Wang', 'Lifeng Shang', 'Christina Lioma', 'Xin Jiang', 'Hao Yang', 'Qun Liu', 'Jakob Grue Simonsen']",https://openreview.net/forum?id=onxoVA9FxMw,"Various Position Embeddings (PEs) have been proposed in Transformer based architectures~(e.g. BERT) to model word order. These are empirically-driven and perform well, but no formal framework exists to systematically study them. To address this, we present three properties of PEs that capture word distance in vector space:  translation invariance, monotonicity, and  symmetry. These properties formally capture the behaviour of PEs and allow us to reinterpret sinusoidal PEs in a principled way.
Moreover, we propose a new probing test (called `identical word probing') and  mathematical  indicators to quantitatively detect the general  attention patterns with respect to the above properties. An empirical evaluation of seven PEs (and their combinations) for classification (GLUE) and span prediction (SQuAD) shows that: (1) both  classification and span prediction benefit from  translation invariance and local monotonicity, while symmetry slightly decreases performance;
(2) The fully-learnable absolute PE performs better in classification, while relative PEs perform better in span prediction.  We contribute the first formal and quantitative analysis of desiderata for PEs, and  a principled discussion about their correlation to the performance of typical downstream tasks.",語順をモデル化するために、Transformerベースのアーキテクチャ（BERTなど）でさまざまな位置埋め込み（PE）が提案されています。これらは経験に基づいており、うまく機能しますが、体系的に研究するための正式なフレームワークは存在しません。これに対処するために、ベクトル空間で単語の距離をキャプチャするPEの3つのプロパティ、翻訳の不変性、単調性、対称性を示します。これらのプロパティは、PEの動作を正式にキャプチャし、正弦波PEを原則的な方法で再解釈できるようにします。さらに、上記の特性に関する一般的な注意パターンを定量的に検出するために、新しいプロービングテスト（同一単語プロービングと呼ばれる）と数学的指標を提案します。分類（GLUE）とスパン予測（SQuAD）の7つのPE（およびそれらの組み合わせ）の経験的評価は、次のことを示しています。 （2）完全に学習可能な絶対PEは分類で優れたパフォーマンスを発揮し、相対PEはスパン予測で優れたパフォーマンスを発揮します。 PEのdesiderataの最初の正式で定量的な分析、および典型的なダウンストリームタスクのパフォーマンスとの相関についての原則的な議論に貢献します。,6.75,
Creative Sketch Generation,"['Songwei Ge', 'Vedanuj Goswami', 'Larry Zitnick', 'Devi Parikh']",https://openreview.net/forum?id=gwnoVHIES05,"Sketching or doodling is a popular creative activity that people engage in. However, most existing work in automatic sketch understanding or generation has focused on sketches that are quite mundane. In this work, we introduce two datasets of creative sketches -- Creative Birds and Creative Creatures -- containing 10k sketches each along with part annotations. We propose DoodlerGAN -- a part-based Generative Adversarial Network (GAN) -- to generate unseen compositions of novel part appearances. Quantitative evaluations as well as human studies demonstrate that sketches generated by our approach are more creative and of higher quality than existing approaches. In fact, in Creative Birds, subjects prefer sketches generated by DoodlerGAN over those drawn by humans!",スケッチや落書きは、人々が従事する人気のある創造的な活動です。しかし、自動スケッチの理解または生成におけるほとんどの既存の作業は、非常にありふれたスケッチに焦点を合わせています。この作業では、クリエイティブスケッチの2つのデータセット、クリエイティブバードとクリエイティブクリーチャーを紹介します。各データセットには、パーツの注釈とともに10kのスケッチが含まれています。 DoodlerGANをパーツベースの生成的敵対的ネットワーク（GAN）として提案し、新しいパーツの外観の目に見えない構成を生成します。定量的評価と人間の研究は、私たちのアプローチによって生成されたスケッチが既存のアプローチよりも創造的で高品質であることを示しています。実際、Creative Birdsでは、被験者は人間が描いたスケッチよりもDoodlerGANが生成したスケッチを好みます。,6.75,
Saliency is a Possible Red Herring When Diagnosing Poor Generalization,"['Joseph D Viviano', 'Becks Simpson', 'Francis Dutil', 'Yoshua Bengio', 'Joseph Paul Cohen']",https://openreview.net/forum?id=c9-WeM-ceB,"Poor generalization is one symptom of models that learn to predict target variables using spuriously-correlated image features present only in the training distribution instead of the true image features that denote a class. It is often thought that this can be diagnosed visually using attribution (aka saliency) maps. We study if this assumption is correct. In some prediction tasks, such as for medical images, one may have some images with masks drawn by a human expert, indicating a region of the image containing relevant information to make the prediction. We study multiple methods that take advantage of such auxiliary labels, by training networks to ignore distracting features which may be found outside of the region of interest. This mask information is only used during training and has an impact on generalization accuracy depending on the severity of the shift between the training and test distributions. Surprisingly, while these methods improve generalization performance in the presence of a covariate shift, there is no strong correspondence between the correction of attribution towards the features a human expert have labelled as important and generalization performance. These results suggest that the root cause of poor generalization may not always be spatially defined, and raise questions about the utility of masks as 'attribution priors' as well as saliency maps for explainable predictions.",不十分な一般化は、クラスを表す真の画像特徴ではなく、トレーニング分布にのみ存在する偽相関画像特徴を使用してターゲット変数を予測することを学習するモデルの1つの症状です。これは、帰属（別名顕著性）マップを使用して視覚的に診断できるとよく考えられています。この仮定が正しいかどうかを調査します。医用画像などの一部の予測タスクでは、人間の専門家によって描かれたマスクを使用して、予測を行うための関連情報を含む画像の領域を示す画像がいくつかある場合があります。関心のある領域の外で見つかるかもしれない気を散らす特徴を無視するようにネットワークを訓練することによって、そのような補助ラベルを利用する複数の方法を研究します。このマスク情報はトレーニング中にのみ使用され、トレーニングとテストの分布間のシフトの重大度に応じて、一般化の精度に影響を与えます。驚くべきことに、これらの方法は共変量シフトの存在下で一般化パフォーマンスを改善しますが、人間の専門家が重要とラベル付けした機能への帰属の修正と一般化パフォーマンスの間に強い対応はありません。これらの結果は、不十分な一般化の根本原因が常に空間的に定義されているとは限らないことを示唆しており、説明可能な予測のための顕著性マップだけでなく、帰属の優先順位としてのマスクの有用性について疑問を投げかけています。,6.75,
Interpreting Knowledge Graph Relation Representation from Word Embeddings,"['Carl Allen', 'Ivana Balazevic', 'Timothy Hospedales']",https://openreview.net/forum?id=gLWj29369lW,"Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.",多くのモデルは、その低ランクの潜在構造を利用し、エンティティ間の既知の関係をエンコードし、未知の事実を推測できるようにすることで、知識グラフデータの表現を学習します。エンティティ間で関係が成立するかどうかを予測するために、埋め込みは通常、関係固有のマッピングに従って潜在空間で比較されます。それらの予測パフォーマンスは着実に改善されていますが、そのようなモデルがセマンティック情報の潜在的な構造をどのようにキャプチャするかは説明されていません。単語の埋め込みに関する最近の理論的理解に基づいて、知識グラフの関係を3つのタイプに分類し、それぞれについて、それらの表現の明示的な要件を導き出します。関係表現の経験的特性と主要な知識グラフ表現方法の相対的なパフォーマンスが私たちの分析によって正当化されることを示します。,6.75,
Efficient Reinforcement Learning in Factored MDPs with Application to Constrained RL,"['Xiaoyu Chen', 'Jiachen Hu', 'Lihong Li', 'Liwei Wang']",https://openreview.net/forum?id=fmtSg8591Q,"Reinforcement learning (RL) in episodic, factored Markov decision processes (FMDPs) is studied. We propose an algorithm called FMDP-BF, which leverages the factorization structure of FMDP.  The regret of FMDP-BF is shown to be exponentially smaller than that of optimal algorithms designed for non-factored MDPs, and improves on the best previous result for FMDPs~\citep{osband2014near} by a factor of $\sqrt{nH|\mathcal{S}_i|}$, where $|\mathcal{S}_i|$ is the cardinality of the factored state subspace, $H$ is the planning horizon and $n$ is the number of factored transition. To show the optimality of our bounds, we also provide a lower bound for FMDP, which indicates that our algorithm is near-optimal w.r.t. timestep $T$, horizon $H$ and factored state-action subspace cardinality. Finally, as an application, we study a new formulation of constrained RL, known as RL with knapsack constraints (RLwK), and provides the first sample-efficient algorithm based on FMDP-BF.",一時的な因数分解されたマルコフ決定過程（FMDP）における強化学習（RL）が研究されています。 FMDPの因数分解構造を利用するFMDP-BFと呼ばれるアルゴリズムを提案します。 FMDP-BFの後悔は、非因数分解MDP用に設計された最適アルゴリズムのそれよりも指数関数的に小さく、FMDPの以前の最良の結果を$ \ sqrt {nH | \ mathcal {S} i |の係数で改善することが示されています。 } $、ここで| S（i）|は因数分解された状態部分空間のカーディナリティ、Hは計画期間、nは因数分解された遷移の数です。境界の最適性を示すために、FMDPの下限も提供します。これは、アルゴリズムがタイムステップT、ホライズンH、および因数分解された状態アクション部分空間カーディナリティに対してほぼ最適であることを示します。最後に、アプリケーションとして、ナップザック制約付きRL（RLwK）として知られる制約付きRLの新しい定式化を研究し、FMDP-BFに基づく最初のサンプル効率の高いアルゴリズムを提供します。,6.75,
DynaTune: Dynamic Tensor Program Optimization in Deep Neural Network Compilation,"['Minjia Zhang', 'Menghao Li', 'Chi Wang', 'Mingqin Li']",https://openreview.net/forum?id=GTGb3M_KcUl,"Recently, the DL compiler, together with Learning to Compile has proven to be a powerful technique for optimizing deep learning models. However, existing methods focus on accelerating the convergence speed of the individual tensor operator rather than the convergence speed of the entire model, which results in long optimization time to obtain a desired latency.

In this paper, we present a new method called DynaTune, which provides significantly faster convergence speed to optimize a DNN model. In particular, we consider a Multi-Armed Bandit (MAB) model for the tensor program optimization problem. We use UCB to handle the decision-making of time-slot-based optimization, and we devise a Bayesian belief model that allows predicting the potential performance gain of each operator with uncertainty quantification, which guides the optimization process. We evaluate and compare DynaTune with the state-of-the-art DL compiler. The experiment results show that DynaTune is 1.2--2.4 times faster to achieve the same optimization quality for a range of models across different hardware architectures. ",最近、DLコンパイラは、Learning to Compileとともに、深層学習モデルを最適化するための強力な手法であることが証明されています。ただし、既存の方法では、モデル全体の収束速度ではなく、個々のテンソル演算子の収束速度を加速することに重点が置かれているため、最適化に時間がかかり、目的のレイテンシが得られます。この論文では、DNNモデルを最適化するために大幅に高速な収束速度を提供するDynaTuneと呼ばれる新しい方法を紹介します。特に、テンソルプログラム最適化問題の多腕バンディット（MAB）モデルを検討します。 UCBを使用してタイムスロットベースの最適化の意思決定を処理し、不確実性の定量化によって各オペレーターの潜在的なパフォーマンスの向上を予測できるベイズの信念モデルを考案します。これにより、最適化プロセスがガイドされます。 DynaTuneを評価し、最先端のDLコンパイラと比較します。実験結果は、DynaTuneが1.22.4倍高速であり、さまざまなハードウェアアーキテクチャにわたるさまざまなモデルで同じ最適化品質を達成することを示しています。,6.75,
Distilling Knowledge from Reader to Retriever for Question Answering,"['Gautier Izacard', 'Edouard Grave']",https://openreview.net/forum?id=NTEz-6wysdb,"The task of information retrieval is an important component of many natural language processing systems, such as open domain question answering. While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results. A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents. In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents. Our approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever. We evaluate our method on question answering, obtaining state-of-the-art results.",情報検索のタスクは、オープンドメインの質問応答など、多くの自然言語処理システムの重要なコンポーネントです。従来の方法は手作りの特徴に基づいていましたが、ニューラルネットワークに基づく連続表現は最近競争力のある結果を得ました。このような方法を使用する際の課題は、クエリとサポートドキュメントのペアに対応する、教師ありデータを取得してレトリーバーモデルをトレーニングすることです。この論文では、知識の蒸留に触発され、クエリとドキュメントの注釈付きペアを必要としない、ダウンストリームタスクのレトリーバーモデルを学習する手法を提案します。私たちのアプローチは、取得したドキュメントに基づいてタスクを解決するために使用されるリーダーモデルの注意スコアを活用して、取得者の合成ラベルを取得します。質問応答の方法を評価し、最先端の結果を取得します。,6.75,https://d3i71xaburhd42.cloudfront.net/66cbda3e730285cb572c4792edcef209af32c564/6-Table1-1.png
Uncertainty Estimation and Calibration with Finite-State Probabilistic RNNs,"['Cheng Wang', 'Carolin Lawrence', 'Mathias Niepert']",https://openreview.net/forum?id=9EKHN1jOlA,"Uncertainty quantification is crucial for building reliable and trustable machine learning systems. We propose to estimate uncertainty in recurrent neural networks (RNNs) via stochastic discrete state transitions over recurrent timesteps. The uncertainty of the model can be quantified by running a prediction several times, each time sampling from the recurrent state transition distribution, leading to potentially different results if the model is uncertain. Alongside uncertainty quantification, our proposed method offers several advantages in different settings. The proposed method can (1) learn deterministic and probabilistic automata from data, (2) improve the performance of out-of-distribution detection, (3) learn well-calibrated models on real-world classification tasks, and (4) control the exploration-exploitation trade-off in reinforcement learning. An implementation is supplementing the submission.",不確実性の定量化は、信頼できる信頼できる機械学習システムを構築するために重要です。リカレントタイムステップにわたる確率的離散状態遷移を介してリカレントニューラルネットワーク（RNN）の不確実性を推定することを提案します。モデルの不確実性は、繰り返しの状態遷移分布からサンプリングするたびに予測を数回実行することで定量化できます。モデルが不確実な場合は、結果が異なる可能性があります。不確実性の定量化に加えて、提案された方法は、さまざまな設定でいくつかの利点を提供します。提案された方法は、（1）データから決定論的および確率的オートマトンを学習し、（2）分布外検出のパフォーマンスを改善し、（3）実世界の分類タスクで適切に調整されたモデルを学習し、（4）強化学習における探索と探索のトレードオフ。実装は提出を補足しています。,6.75,https://d3i71xaburhd42.cloudfront.net/a83e36e203a4e90c2af814320092fc8f78f4ce28/2-Figure1-1.png
The Risks of Invariant Risk Minimization,"['Elan Rosenfeld', 'Pradeep Kumar Ravikumar', 'Andrej Risteski']",https://openreview.net/forum?id=BbNIbVPJ-42,"Invariant Causal Prediction (Peters et al., 2016) is a technique for out-of-distribution generalization which assumes that some aspects of the data distribution vary across the training set but that the underlying causal mechanisms remain constant. Recently, Arjovsky et al. (2019) proposed Invariant Risk Minimization (IRM), an objective based on this idea for learning deep, invariant features of data which are a complex function of latent variables; many alternatives have subsequently been suggested.  However, formal guarantees for all of these works are severely lacking.  In this paper,  we present the first analysis of classification under the IRM objective—as well as these recently proposed alternatives—under a fairly natural and general model. In the linear case, we show simple conditions under which the optimal solution succeeds or, more often, fails to recover the optimal invariant predictor. We furthermore present the very first results in the non-linear regime: we demonstrate that IRM can fail catastrophically unless the test data is sufficiently similar to the training distribution—this is precisely the issue that it was intended to solve. Thus, in this setting we find that IRM and its alternatives fundamentally do not improve over standard Empirical Risk Minimization.",不変因果予測（Peters et al。、2016）は、データ分布のいくつかの側面がトレーニングセット全体で異なるが、根本的な因果メカニズムは一定であると想定する、分布外の一般化の手法です。最近、Arjovsky等。 （2019）潜在変数の複雑な関数であるデータの深く不変の特徴を学習するためのこのアイデアに基づく目的である不変リスク最小化（IRM）を提案しました。その後、多くの代替案が提案されました。ただし、これらすべての作業に対する正式な保証は大幅に不足しています。この論文では、IRMの目的の下での分類の最初の分析と、かなり自然で一般的なモデルの下で最近提案されたこれらの代替案を提示します。線形の場合、最適解が成功するか、多くの場合、最適不変予測子の回復に失敗する単純な条件を示します。さらに、非線形レジームの最初の結果を示します。テストデータがトレーニング分布と十分に類似していない限り、IRMが壊滅的に失敗する可能性があることを示します。これは、まさに解決しようとした問題です。したがって、この設定では、IRMとその代替手段は、標準の経験的リスク最小化よりも根本的に改善されないことがわかります。,6.75,https://d3i71xaburhd42.cloudfront.net/1e76e2fbf27198986271a672f462dc38d790d00f/24-Figure1-1.png
Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization,"['Kaidi Cao', 'Yining Chen', 'Junwei Lu', 'Nikos Arechiga', 'Adrien Gaidon', 'Tengyu Ma']",https://openreview.net/forum?id=mEdwVCRJuX4,"Real-world large-scale datasets are heteroskedastic and imbalanced --- labels have varying levels of uncertainty and label distributions are long-tailed. Heteroskedasticity and imbalance challenge deep learning algorithms due to the difficulty of distinguishing among mislabeled, ambiguous, and rare examples. Addressing heteroskedasticity and imbalance simultaneously is under-explored. We propose a data-dependent regularization technique for heteroskedastic datasets that regularizes different regions of the input space differently. Inspired by the theoretical derivation of the optimal regularization strength in a one-dimensional nonparametric classification setting, our approach adaptively regularizes the data points in higher-uncertainty, lower-density regions more heavily. We test our method on several benchmark tasks, including a real-world heteroskedastic and imbalanced dataset, WebVision. Our experiments corroborate our theory and demonstrate a significant improvement over other methods in noise-robust deep learning. ",実世界の大規模データセットは不均一分散であり、不均衡なラベルにはさまざまなレベルの不確実性があり、ラベルの分布はロングテールです。不均一分散と不均衡は、誤ったラベルが付けられた、あいまいな、まれな例を区別することが難しいため、深層学習アルゴリズムに挑戦します。不均一分散と不均衡に同時に対処することは十分に検討されていません。入力空間のさまざまな領域を異なる方法で正規化する、不均一分散データセットのデータ依存の正則化手法を提案します。 1次元のノンパラメトリック分類設定における最適な正則化強度の理論的導出に触発されて、私たちのアプローチは、より不確実性が高く、密度の低い領域のデータポイントをより重く適応的に正則化します。実世界の不均一分散で不均衡なデータセットであるWebVisionを含む、いくつかのベンチマークタスクでメソッドをテストします。私たちの実験は私たちの理論を裏付け、ノイズに強い深層学習における他の方法に比べて大幅な改善を示しています。,6.75,https://d3i71xaburhd42.cloudfront.net/92b46eeed09d9ff130901b97af38b55e4f4bdc2d/2-Figure1-1.png
Representing Partial Programs with Blended Abstract Semantics,"['Maxwell Nye', 'Yewen Pu', 'Matthew Bowers', 'Jacob Andreas', 'Joshua B. Tenenbaum', 'Armando Solar-Lezama']",https://openreview.net/forum?id=mCtadqIxOJ,"Synthesizing programs from examples requires searching over a vast, combinatorial space of possible programs. In this search process, a key challenge is representing the behavior of a partially written program before it can be executed, to judge if it is on the right track and predict where to search next. We introduce a general technique for representing partially written programs in a program synthesis engine. We take inspiration from the technique of abstract interpretation, in which an approximate execution model is used to determine if an unfinished program will eventually satisfy a goal specification. Here we \emph{learn} an approximate execution model implemented as a modular neural network. By constructing compositional program representations that implicitly encode the interpretation semantics of the underlying programming language, we can represent partial programs using a flexible combination of concrete execution state and learned neural representations, using the learned approximate semantics when concrete semantics are not known (in unfinished parts of the program). We show that these hybrid neuro-symbolic representations enable execution-guided synthesizers to use more powerful language constructs, such as loops and higher-order functions, and can be used to synthesize programs more accurately for a given search budget than pure neural approaches in several domains.",例からプログラムを合成するには、可能なプログラムの広大な組み合わせ空間を検索する必要があります。この検索プロセスでの重要な課題は、部分的に作成されたプログラムを実行する前にその動作を表現し、プログラムが正しい方向に進んでいるかどうかを判断し、次に検索する場所を予測することです。プログラム合成エンジンで部分的に記述されたプログラムを表現するための一般的な手法を紹介します。抽象解釈の手法からインスピレーションを得ています。この手法では、近似実行モデルを使用して、未完成のプログラムが最終的に目標仕様を満たすかどうかを判断します。ここでは、モジュラーニューラルネットワークとして実装されたおおよその実行モデルを学習します。基礎となるプログラミング言語の解釈セマンティクスを暗黙的にエンコードする構成プログラム表現を構築することにより、具体的なセマンティクスが不明な場合（未完成部分）に学習した近似セマンティクスを使用して、具体的な実行状態と学習した神経表現の柔軟な組み合わせを使用して部分プログラムを表現できます。プログラムの）。これらのハイブリッドニューロシンボリック表現により、実行ガイドシンセサイザーがループや高階関数などのより強力な言語構造を使用できるようになり、いくつかの純粋なニューラルアプローチよりも特定の検索予算でプログラムをより正確に合成できることを示します。ドメイン。,6.75,https://d3i71xaburhd42.cloudfront.net/963f1c1f456969b466e3ce9ccf39c4fb2bdcc23f/2-Figure1-1.png
Pre-training Text-to-Text Transformers for Concept-centric Common Sense,"['Wangchunshu Zhou', 'Dong-Ho Lee', 'Ravi Kiran Selvam', 'Seyeon Lee', 'Xiang Ren']",https://openreview.net/forum?id=3k20LAiHYL2,"Pretrained language models (PTLM) have achieved impressive results in a range of natural language understanding (NLU) and generation (NLG) tasks that require a syntactic and semantic understanding of the text. However, current pre-training objectives such as masked token prediction (for BERT-style PTLMs) and masked span infilling (for T5-style PTLMs) do not explicitly model the relational and compositional commonsense knowledge about everyday concepts, which is crucial to many downstream tasks requiring commonsense reasoning. To augment PTLMs with common sense, we propose generative and contrastive objectives as intermediate self-supervised pre-training tasks between general pre-training and downstream task-specific fine-tuning. We also propose a joint training framework to unify generative and contrastive objectives so that these objectives can be more effective.
Our proposed objectives can pack more commonsense knowledge into the parameters of a pre-trained text-to-text transformer without relying on external knowledge bases, yielding better performance on both NLU and NLG tasks. We apply our method on a pre-trained T5 model in an intermediate task transfer learning fashion to train a concept-aware language model (CALM) and experiment with five commonsense benchmarks (four NLU tasks and one NLG task). Experimental results show that CALM outperforms baseline methods by a consistent margin.",事前トレーニングされた言語モデル（PTLM）は、テキストの構文的および意味的理解を必要とする一連の自然言語理解（NLU）および生成（NLG）タスクで印象的な結果を達成しました。ただし、マスクされたトークン予測（BERTスタイルのPTLMの場合）やマスクされたスパンの入力（T5スタイルのPTLMの場合）などの現在の事前トレーニングの目的は、日常の概念に関する関係および構成の常識知識を明示的にモデル化していないため、多くのダウンストリームにとって重要です。常識的な推論を必要とするタスク。常識を持ってPTLMを強化するために、一般的な事前トレーニングとダウンストリームのタスク固有の微調整の間の中間の自己教師あり事前トレーニングタスクとして生成的で対照的な目的を提案します。また、生成的で対照的な目的を統合して、これらの目的をより効果的にするための共同トレーニングフレームワークを提案します。私たちが提案する目的は、外部の知識ベースに依存することなく、事前にトレーニングされたテキストからテキストへのトランスフォーマーのパラメーターに常識的な知識を詰め込むことができ、NLUタスクとNLGタスクの両方でより良いパフォーマンスをもたらします。事前にトレーニングされたT5モデルに中間タスク転送学習方式でこの方法を適用して、概念認識言語モデル（CALM）をトレーニングし、5つの常識的なベンチマーク（4つのNLUタスクと1つのNLGタスク）を実験します。実験結果は、CALMが一貫したマージンでベースラインメソッドよりも優れていることを示しています。,6.75,https://d3i71xaburhd42.cloudfront.net/abaadb4c6affc4d874c4f59bfac60686e851cb5e/3-Figure1-1.png
Representation Balancing Offline Model-based Reinforcement Learning,"['Byung-Jun Lee', 'Jongmin Lee', 'Kee-Eung Kim']",https://openreview.net/forum?id=QpNz8r_Ri2Y,"One of the main challenges in offline and off-policy reinforcement learning is to cope with the distribution shift that arises from the mismatch between the target policy and the data collection policy. In this paper, we focus on a model-based approach, particularly on learning the representation for a robust model of the environment under the distribution shift, which has been first studied by Representation Balancing MDP (RepBM). Although this prior work has shown promising results, there are a number of shortcomings that still hinder its applicability to practical tasks. In particular, we address the curse of horizon exhibited by RepBM, rejecting most of the pre-collected data in long-term tasks. We present a new objective for model learning motivated by recent advances in the estimation of stationary distribution corrections. This effectively overcomes the aforementioned limitation of RepBM, as well as naturally extending to continuous action spaces and stochastic policies. We also present an offline model-based policy optimization using this new objective, yielding the state-of-the-art performance in a representative set of benchmark offline RL tasks.",オフラインおよびポリシー外の強化学習における主な課題の1つは、ターゲットポリシーとデータ収集ポリシーの不一致から生じる分散シフトに対処することです。このホワイトペーパーでは、モデルベースのアプローチに焦点を当てます。特に、Representation Balancing MDP（RepBM）によって最初に研究された、分布シフト下の環境の堅牢なモデルの表現の学習に焦点を当てます。この先行研究は有望な結果を示していますが、実際のタスクへの適用を妨げる多くの欠点があります。特に、RepBMが示す地平線の呪いに対処し、長期的なタスクで事前に収集されたデータのほとんどを拒否します。定常分布補正の推定における最近の進歩によって動機付けられたモデル学習の新しい目的を提示します。これにより、前述のRepBMの制限が効果的に克服されるだけでなく、継続的なアクションスペースや確率論的ポリシーに自然に拡張されます。また、この新しい目標を使用したオフラインモデルベースのポリシー最適化を提示し、ベンチマークオフラインRLタスクの代表的なセットで最先端のパフォーマンスを実現します。,6.75,
Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks,"['Yige Li', 'Xingjun Ma', 'Nodens Koren', 'Lingjuan Lyu', 'Xixiang Lyu', 'Bo Li']",https://openreview.net/forum?id=9l0K4OM-oXE,"Deep neural networks (DNNs) are known vulnerable to backdoor attacks, a training time attack that injects a trigger pattern into a small proportion of training data so as to control the model's prediction at the test time. Backdoor attacks are notably dangerous since they do not affect the model's performance on clean examples, yet can fool the model to make the incorrect prediction whenever the trigger pattern appears during testing. In this paper, we propose a novel defense framework Neural Attention Distillation (NAD) to erase backdoor triggers from backdoored DNNs. NAD utilizes a teacher network to guide the finetuning of the backdoored student network on a small clean subset of data such that the intermediate-layer attention of the student network aligns with that of the teacher network. The teacher network can be obtained by an independent finetuning process on the same clean subset. We empirically show, against 6 state-of-the-art backdoor attacks,  NAD can effectively erase the backdoor triggers using only 5\% clean training data without causing obvious performance degradation on clean examples.",ディープニューラルネットワーク（DNN）は、テスト時のモデル予測を制御するために、トレーニングデータのごく一部にトリガーパターンを注入するトレーニングタイムアタックであるバックドア攻撃に対して脆弱であることが知られています。バックドア攻撃は、クリーンな例でモデルのパフォーマンスに影響を与えないため、特に危険ですが、テスト中にトリガーパターンが表示されるたびに、モデルをだまして誤った予測を行う可能性があります。この論文では、バックドアされたDNNからバックドアトリガーを消去するための新しい防御フレームワークであるNeural Attention Distillation（NAD）を提案します。 NADは、教師ネットワークを利用して、学生ネットワークの中間層の注意が教師ネットワークの注意と一致するように、データの小さなクリーンなサブセットでバックドアの学生ネットワークの微調整をガイドします。教師ネットワークは、同じクリーンなサブセットでの独立した微調整プロセスによって取得できます。 6つの最先端のバックドア攻撃に対して、NADは、クリーンな例で明らかなパフォーマンスの低下を引き起こすことなく、わずか5％のクリーンなトレーニングデータを使用してバックドアトリガーを効果的に消去できることを経験的に示しています。,6.75,https://d3i71xaburhd42.cloudfront.net/4d4e5c0c691e42b7078208598d585caacc2e34c2/3-Figure1-1.png
INT: An Inequality Benchmark for Evaluating Generalization in Theorem Proving,"['Yuhuai Wu', 'Albert Jiang', 'Jimmy Ba', 'Roger Baker Grosse']",https://openreview.net/forum?id=O6LPudowNQm,"In learning-assisted theorem proving, one of the most critical challenges is to generalize to theorems unlike those seen at training time. In this paper, we introduce INT, an INequality Theorem proving benchmark designed to test agents’ generalization ability. INT is based on a theorem generator, which provides theoretically infinite data and allows us to measure 6 different types of generalization, each reflecting a distinct challenge, characteristic of automated theorem proving. In addition, provides a fast theorem proving environment with sequence-based and graph-based interfaces, conducive to performing learning-based research. We introduce base-lines with architectures including transformers and graph neural networks (GNNs)for INT. Using INT, we find that transformer-based agents achieve stronger test performance for most of the generalization tasks, despite having much larger out-of-distribution generalization gaps than GNNs. We further find that the addition of Monte Carlo Tree Search (MCTS) at test time helps to prove new theorems.",学習支援定理証明において、最も重要な課題の1つは、トレーニング時に見られるものとは異なり、定理に一般化することです。この論文では、エージェントの一般化能力をテストするために設計された不等式定理証明ベンチマークであるINTを紹介します。 INTは、理論的に無限のデータを提供し、自動定理証明の特徴である明確な課題をそれぞれ反映する6種類の一般化を測定できる定理ジェネレーターに基づいています。さらに、シーケンスベースおよびグラフベースのインターフェイスを備えた高速定理証明環境を提供し、学習ベースの研究の実行に役立ちます。 INT用のトランスフォーマーやグラフニューラルネットワーク（GNN）などのアーキテクチャーを備えたベースラインを紹介します。 INTを使用すると、トランスフォーマーベースのエージェントは、GNNよりもはるかに大きな配布外の一般化ギャップがあるにもかかわらず、ほとんどの一般化タスクでより強力なテストパフォーマンスを達成することがわかります。さらに、テスト時にモンテカルロ木探索（MCTS）を追加すると、新しい定理を証明するのに役立つことがわかります。,6.75,https://d3i71xaburhd42.cloudfront.net/016863a86189c4e8ccecf9a36c4406c439a8a84c/3-Figure1-1.png
When Optimizing  $f$-Divergence is Robust with Label Noise,"['Jiaheng Wei', 'Yang Liu']",https://openreview.net/forum?id=WesiCoRVQ15,"We show when maximizing a properly defined $f$-divergence measure (an extended definition of $f$-mutual information) with respect to a classifier's predictions and the supervised labels is robust with label noise. Leveraging its variational form, we derive a nice decoupling property for this particular $f$-divergence when label noise presents, where the divergence is shown to be a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise. The above derivation helps us analyze the robustness of this measure for different $f$-divergence functions. With established robustness, this family of $f$-divergence functions arises as useful metrics for the problem of learning with noisy labels, which do not require the specification of the labels' noise rate. When they are possibly not robust, we propose fixes to make them so. In addition to the analytical results, we present thorough experimental studies. ",分類器の予測に関して適切に定義されたf-発散測度（f-相互情報量の拡張定義）を最大化する場合を示し、監視対象のラベルはラベルノイズに対してロバストです。その変分形式を利用して、ラベルノイズが存在する場合、この特定のf発散の優れたデカップリング特性を導き出します。ここで、発散は、クリーンな分布で定義された変分差とノイズによって導入されたバイアス項の線形結合であることが示されます。 。上記の導出は、さまざまなf発散関数に対するこの測定のロバスト性を分析するのに役立ちます。確立されたロバスト性により、このf発散関数のファミリーは、ラベルのノイズ率の指定を必要としない、ノイズの多いラベルを使用した学習の問題に対する有用なメトリックとして発生します。堅牢でない可能性がある場合は、堅牢にするための修正を提案します。分析結果に加えて、徹底的な実験的研究を提示します。,6.75,https://d3i71xaburhd42.cloudfront.net/ab5a9ebf33fc6192889309193d1eb515916d82ca/7-Figure1-1.png
DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation,"['Alexandre Rame', 'Matthieu Cord']",https://openreview.net/forum?id=R2ZlTVPx0Gk,"Deep ensembles perform better than a single network thanks to the diversity among their members. Recent approaches regularize predictions to increase diversity; however, they also drastically decrease individual members’ performances. In this paper, we argue that learning strategies for deep ensembles need to tackle the trade-off between ensemble diversity and individual accuracies. Motivated by arguments from information theory and leveraging recent advances in neural estimation of conditional mutual information, we introduce a novel training criterion called DICE: it increases diversity by reducing spurious correlations among features. The main idea is that features extracted from pairs of members should only share information useful for target class prediction without being conditionally redundant. Therefore, besides the classification loss with information bottleneck, we adversarially prevent features from being conditionally predictable from each other. We manage to reduce simultaneous errors while protecting class information. We obtain state-of-the-art accuracy results on CIFAR-10/100: for example, an ensemble of 5 networks trained with DICE matches an ensemble of 7 networks trained independently. We further analyze the consequences on calibration, uncertainty estimation, out-of-distribution detection and online co-distillation.",ディープアンサンブルは、メンバー間の多様性のおかげで、単一のネットワークよりも優れたパフォーマンスを発揮します。最近のアプローチは、多様性を高めるために予測を正規化します。ただし、個々のメンバーのパフォーマンスも大幅に低下します。この論文では、深いアンサンブルの学習戦略は、アンサンブルの多様性と個々の精度の間のトレードオフに取り組む必要があると主張します。情報理論からの議論に動機付けられ、条件付き相互情報量の神経推定における最近の進歩を活用して、DICEと呼ばれる新しいトレーニング基準を導入します。これは、特徴間の疑似相関を減らすことによって多様性を高めます。主なアイデアは、メンバーのペアから抽出された特徴は、条件付きで冗長になることなく、ターゲットクラスの予測に役立つ情報のみを共有する必要があるということです。したがって、情報のボトルネックによる分類の損失に加えて、特徴が相互に条件付きで予測可能になるのを逆に防ぎます。クラス情報を保護しながら、同時エラーを減らすことができます。 CIFAR-10 / 100で最先端の精度の結果が得られます。たとえば、DICEでトレーニングされた5つのネットワークのアンサンブルは、独立してトレーニングされた7つのネットワークのアンサンブルと一致します。さらに、キャリブレーション、不確実性の推定、分布外の検出、およびオンライン共蒸留への影響を分析します。,6.75,https://d3i71xaburhd42.cloudfront.net/a3ec0076139420a34d2079a029b0836b890e5d3c/2-Figure1-1.png
Sparse Quantized Spectral Clustering,"['Zhenyu Liao', 'Romain Couillet', 'Michael W. Mahoney']",https://openreview.net/forum?id=pBqLS-7KYAF,"Given a large data matrix, sparsifying, quantizing, and/or performing other entry-wise nonlinear operations can have numerous benefits, ranging from speeding up iterative algorithms for core numerical linear algebra problems to providing nonlinear filters to design state-of-the-art neural network models. Here, we exploit tools from random matrix theory to make precise statements about how the eigenspectrum of a matrix changes under such nonlinear transformations. In particular, we show that very little change occurs in the informative eigenstructure, even under drastic sparsification/quantization, and consequently that very little downstream performance loss occurs when working with very aggressively sparsified or quantized spectral clustering problems.
We illustrate how these results depend on the nonlinearity, we characterize a phase transition beyond which spectral clustering becomes possible, and we show when such nonlinear transformations can introduce spurious non-informative eigenvectors.",大きなデータマトリックスが与えられた場合、スパース化、量子化、および/または他のエントリ単位の非線形演算の実行には、コア数値線形代数問題の反復アルゴリズムの高速化から、最先端の設計のための非線形フィルターの提供まで、多くの利点があります。ニューラルネットワークモデル。ここでは、ランダム行列理論のツールを利用して、このような非線形変換の下で行列の固有スペクトルがどのように変化するかについて正確なステートメントを作成します。特に、大幅なスパース化/量子化の下でも、有益な固有構造にほとんど変化が発生せず、その結果、非常に積極的にスパース化または量子化されたスペクトルクラスタリング問題を処理するときにダウンストリームのパフォーマンス損失がほとんど発生しないことを示します。これらの結果が非線形性にどのように依存するかを説明し、それを超えるとスペクトルクラスタリングが可能になる相転移を特徴付け、そのような非線形変換が偽の非情報固有ベクトルを導入できる場合を示します。,6.75,https://d3i71xaburhd42.cloudfront.net/7575c65c3e7f9a5161ea46dcf38d75d4da54ffa5/5-Figure1-1.png
Neural Thompson Sampling,"['Weitong ZHANG', 'Dongruo Zhou', 'Lihong Li', 'Quanquan Gu']",https://openreview.net/forum?id=tkAtoZkcUnm,"Thompson Sampling (TS) is one of the most effective algorithms for solving contextual multi-armed bandit problems. In this paper, we propose a new algorithm, called Neural Thompson Sampling, which adapts deep neural networks for both exploration and exploitation. At the core of our algorithm is a novel posterior distribution of the reward, where its mean is the neural network approximator, and its variance is built upon the neural tangent features of the corresponding neural network. We prove that, provided the underlying reward function is bounded, the proposed algorithm is guaranteed to achieve a cumulative regret of $O(T^{1/2})$, which matches the regret of other contextual bandit algorithms in terms of total round number $T$. Experimental comparisons with other benchmark bandit algorithms on various data sets corroborate our theory.",Thompson Sampling（TS）は、コンテキストに応じた多腕バンディット問題を解決するための最も効果的なアルゴリズムの1つです。この論文では、ニューラルトンプソンサンプリングと呼ばれる新しいアルゴリズムを提案します。これは、探索と活用の両方にディープニューラルネットワークを適応させます。私たちのアルゴリズムの中核は、報酬の新しい事後分布です。ここで、その平均はニューラルネットワーク近似器であり、その分散は、対応するニューラルネットワークのニューラルタンジェント特徴に基づいて構築されます。基礎となる報酬関数が制限されている場合、提案されたアルゴリズムは、合計ラウンド数Tに関して他のコンテキストバンディットアルゴリズムの後悔と一致するO（T ^（1/2））の累積後悔を達成することが保証されていることを証明します。 。さまざまなデータセットでの他のベンチマークバンディットアルゴリズムとの実験的比較は、私たちの理論を裏付けています。,6.75,https://d3i71xaburhd42.cloudfront.net/c60cc277673976839f665e245d2352728b7feb39/10-Figure1-1.png
LiftPool: Bidirectional ConvNet Pooling,"['Jiaojiao Zhao', 'Cees G. M. Snoek']",https://openreview.net/forum?id=kE3vd639uRW,"Pooling is a critical operation in convolutional neural networks for increasing receptive fields and improving robustness to input variations. Most existing pooling operations downsample the feature maps, which is a lossy process. Moreover, they are not invertible: upsampling a downscaled feature map can not recover the lost information in the downsampling. By adopting the philosophy of the classical Lifting Scheme from signal processing, we propose LiftPool for bidirectional pooling layers, including LiftDownPool and LiftUpPool. LiftDownPool decomposes a feature map into various downsized sub-bands, each of which contains correlated structures or details of the feature map. As the pooling function in LiftDownPool is perfectly invertible, by performing LiftDownPool backwards, a corresponding up-pooling layer LiftUpPool is able to generate a refined upsampled feature map using the detail sub-bands, which is useful for image-to-image translation challenges. Experiments show the proposed methods achieve better results on image classification and semantic segmentation, using various backbones. Moreover, LiftDownPool offers better robustness to input corruptions and perturbations. ",プーリングは、受容野を増やし、入力変動に対するロバスト性を向上させるための畳み込みニューラルネットワークにおける重要な操作です。ほとんどの既存のプーリング操作は、機能マップをダウンサンプリングしますが、これは損失の多いプロセスです。さらに、それらは可逆的ではありません。ダウンスケールされた特徴マップをアップサンプリングしても、ダウンサンプリングで失われた情報を回復することはできません。信号処理からの古典的なリフティングスキームの哲学を採用することにより、LiftDownPoolやLiftUpPoolを含む双方向プーリングレイヤー用のLiftPoolを提案します。 LiftDownPoolは、フィーチャマップをさまざまなダウンサイズのサブバンドに分解します。各サブバンドには、相関構造またはフィーチャマップの詳細が含まれています。 LiftDownPoolのプーリング関数は完全に反転可能であるため、LiftDownPoolを逆方向に実行することにより、対応するアッププーリングレイヤーLiftUpPoolは、詳細サブバンドを使用して洗練されたアップサンプリングされた特徴マップを生成できます。これは、画像から画像への変換の課題に役立ちます。実験は、提案された方法が、さまざまなバックボーンを使用して、画像分類とセマンティックセグメンテーションでより良い結果を達成することを示しています。さらに、LiftDownPoolは、入力の破損や摂動に対する堅牢性を向上させます。,6.75,
Rank the Episodes: A Simple Approach for Exploration in Procedurally-Generated Environments,"['Daochen Zha', 'Wenye Ma', 'Lei Yuan', 'Xia Hu', 'Ji Liu']",https://openreview.net/forum?id=MtEE0CktZht,"Exploration under sparse reward is a long-standing challenge of model-free reinforcement learning. The state-of-the-art methods address this challenge by introducing intrinsic rewards to encourage exploration in novel states or uncertain environment dynamics. Unfortunately, methods based on intrinsic rewards often fall short in procedurally-generated environments, where a different environment is generated in each episode so that the agent is not likely to visit the same state more than once. Motivated by how humans distinguish good exploration behaviors by looking into the entire episode, we introduce RAPID, a simple yet effective episode-level exploration method for procedurally-generated environments. RAPID regards each episode as a whole and gives an episodic exploration score from both per-episode and long-term views. Those highly scored episodes are treated as good exploration behaviors and are stored in a small ranking buffer. The agent then imitates the episodes in the buffer to reproduce the past good exploration behaviors. We demonstrate our method on several procedurally-generated MiniGrid environments, a first-person-view 3D Maze navigation task from MiniWorld, and several sparse MuJoCo tasks. The results show that RAPID significantly outperforms the state-of-the-art intrinsic reward strategies in terms of sample efficiency and final performance. The code is available at https://github.com/daochenzha/rapid",スパース報酬の下での探索は、モデルフリーの強化学習の長年の課題です。最先端の方法は、新しい状態や不確実な環境ダイナミクスでの探索を促進するために本質的な報酬を導入することにより、この課題に対処します。残念ながら、本質的な報酬に基づく方法は、手続き的に生成された環境では不十分なことがよくあります。この環境では、エピソードごとに異なる環境が生成されるため、エージェントが同じ状態に2回以上アクセスする可能性は低くなります。人間がエピソード全体を調べることで優れた探索行動を区別する方法に動機付けられて、手続き型生成環境向けのシンプルで効果的なエピソードレベルの探索方法であるRAPIDを紹介します。 RAPIDは各エピソードを全体として見なし、エピソードごとのビューと長期的なビューの両方からエピソードの探索スコアを提供します。これらの高得点のエピソードは、優れた探索行動として扱われ、小さなランキングバッファに保存されます。次に、エージェントはバッファ内のエピソードを模倣して、過去の良好な探索行動を再現します。手続き型で生成されたいくつかのMiniGrid環境、MiniWorldの一人称ビュー3D Mazeナビゲーションタスク、およびいくつかのスパースMuJoCoタスクでの方法を示します。結果は、RAPIDが、サンプルの効率と最終的なパフォーマンスの点で、最先端の本質的な報酬戦略を大幅に上回っていることを示しています。コードはhttps://github.com/daochenzha/rapidで入手できます。,6.75,https://d3i71xaburhd42.cloudfront.net/ca54e294f9d72af57f7d8af5697edda25cdd8495/2-Figure1-1.png
Categorical Normalizing Flows via Continuous Transformations,"['Phillip Lippe', 'Efstratios Gavves']",https://openreview.net/forum?id=-GLNZeVDuik,"Despite their popularity, to date, the application of normalizing flows on categorical data stays limited. The current practice of using dequantization to map discrete data to a continuous space is inapplicable as categorical data has no intrinsic order. Instead, categorical data have complex and latent relations that must be inferred, like the synonymy between words. In this paper, we investigate Categorical Normalizing Flows, that is normalizing flows for categorical data. By casting the encoding of categorical data in continuous space as a variational inference problem, we jointly optimize the continuous representation and the model likelihood. Using a factorized decoder, we introduce an inductive bias to model any interactions in the normalizing flow. As a consequence, we do not only simplify the optimization compared to having a joint decoder, but also make it possible to scale up to a large number of categories that is currently impossible with discrete normalizing flows. Based on Categorical Normalizing Flows, we propose GraphCNF a permutation-invariant generative model on graphs. GraphCNF implements a three step approach modeling the nodes, edges, and adjacency matrix stepwise to increase efficiency. On molecule generation, GraphCNF outperforms both one-shot and autoregressive flow-based state-of-the-art.
",それらの人気にもかかわらず、今日まで、カテゴリデータに対する正規化フローの適用は制限されたままです。離散データを連続空間にマッピングするために逆量子化を使用する現在の慣行は、カテゴリデータに固有の順序がないため適用できません。代わりに、カテゴリデータには、単語間の同義語のように、推測する必要のある複雑で潜在的な関係があります。この論文では、カテゴリデータのフローを正規化するカテゴリ正規化フローについて調査します。変分推論問題として連続空間でのカテゴリデータのエンコーディングをキャストすることにより、連続表現とモデル尤度を共同で最適化します。因数分解されたデコーダーを使用して、正規化フローの相互作用をモデル化するための誘導バイアスを導入します。その結果、ジョイントデコーダーを使用する場合に比べて最適化が簡素化されるだけでなく、離散正規化フローでは現在不可能な多数のカテゴリにスケールアップすることも可能になります。カテゴリ正規化フローに基づいて、GraphCNFをグラフ上の順列不変生成モデルとして提案します。 GraphCNFは、効率を高めるために、ノード、エッジ、および隣接行列を段階的にモデル化する3ステップのアプローチを実装します。分子生成において、GraphCNFは、ワンショットおよび自己回帰フローベースの最先端技術よりも優れています。,6.75,https://d3i71xaburhd42.cloudfront.net/6670ce9fa7dbc271612078f2b3f05c12e0281aeb/5-Figure1-1.png
Learning A Minimax Optimizer: A Pilot Study,"['Jiayi Shen', 'Xiaohan Chen', 'Howard Heaton', 'Tianlong Chen', 'Jialin Liu', 'Wotao Yin', 'Zhangyang Wang']",https://openreview.net/forum?id=nkIDwI6oO4_,"Solving continuous minimax optimization is of extensive practical interest, yet notoriously unstable and difficult. This paper introduces the learning to optimize (L2O) methodology to the minimax problems for the first time, and addresses its accompanying unique challenges. We first present Twin L2O, the first dedicated minimax L2O framework consisting of two LSTMs for updating min and max variables, respectively. That decoupled design is found to facilitate learning, particularly when the min and max variables are highly non-symmetric. Empirical experiments on a variety of minimax problems corroborates the effectiveness of Twin-L2O. We then discuss a crucial concern of Twin-L2O, i.e., its inevitably limited generalizability to unseen optimizees, and present two complementary strategies. Our first solution, Enhanced Twin-L2O, is empirically applicable for general minimax problems, by improving L2O training via leveraging curriculum learning. We extensively benchmark our algorithms on popular minimax problems, and compare against state-of-the-art minimax solvers. Our second alternative, called Safeguarded Twin L2O, is a preliminary theoretical exploration stating that under some strong assumptions, it is possible to theoretically establish the convergence of Twin-L2O on optimizing any unseen objective. Our codes and models will be publicly released upon acceptance.",継続的なミニマックス最適化を解くことは、実用上非常に重要ですが、不安定で困難なことで有名です。このホワイトペーパーでは、ミニマックス問題に最適化するための学習（L2O）手法を初めて紹介し、それに伴う固有の課題に対処します。最初に、最小変数と最大変数をそれぞれ更新するための2つのLSTMで構成される最初の専用ミニマックスL2OフレームワークであるツインL2Oを紹介します。この分離された設計は、特に最小変数と最大変数が非常に非対称である場合に、学習を容易にすることがわかります。さまざまなミニマックス問題に関する経験的実験は、Twin-L2Oの有効性を裏付けています。次に、Twin-L2Oの重大な懸念事項、つまり、目に見えない最適化に対する一般化可能性が必然的に制限されることについて説明し、2つの補完的な戦略を示します。私たちの最初のソリューションであるEnhancedTwin-L2Oは、カリキュラム学習を活用してL2Oトレーニングを改善することにより、一般的なミニマックス問題に経験的に適用できます。一般的なミニマックス問題についてアルゴリズムのベンチマークを広範囲に行い、最先端のミニマックスソルバーと比較します。 Safeguarded Twin L2Oと呼ばれる2番目の代替案は、いくつかの強力な仮定の下で、目に見えない目的の最適化に関するTwin-L2Oの収束を理論的に確立できることを示す予備的な理論的調査です。当社のコードとモデルは、承認され次第公開されます。,6.75,
Towards Resolving the Implicit Bias of Gradient Descent for Matrix Factorization: Greedy Low-Rank Learning,"['Zhiyuan Li', 'Yuping Luo', 'Kaifeng Lyu']",https://openreview.net/forum?id=AHOs7Sm5H7R,"Matrix factorization is a simple and natural test-bed to investigate the implicit regularization of gradient descent. Gunasekar et al. (2018) conjectured that gradient flow with infinitesimal initialization converges to the solution that minimizes the nuclear norm, but a series of recent papers argued that the language of norm minimization is not sufficient to give a full characterization for the implicit regularization. In this work, we provide theoretical and empirical evidence that for depth-2 matrix factorization, gradient flow with infinitesimal initialization is mathematically equivalent to a simple heuristic rank minimization algorithm, Greedy Low-Rank Learning, under some reasonable assumptions. This generalizes the rank minimization view from previous works to a much broader setting and enables us to construct counter-examples to refute the conjecture from Gunasekar et al. (2018). We also extend the results to the case where depth >= 3, and we show that the benefit of being deeper is that the above convergence has a much weaker dependence over initialization magnitude so that this rank minimization is more likely to take effect for initialization with practical scale.",行列因数分解は、勾配降下の暗黙の正則化を調査するための単純で自然なテストベッドです。グナセカール他（2018）は、微小初期化を伴う勾配流が核ノルムを最小化する解に収束すると推測しましたが、最近の一連の論文は、ノルム最小化の言語は暗黙の正則化の完全な特性を与えるのに十分ではないと主張しました。この作業では、深さ2の行列因数分解の場合、微小な初期化を伴う勾配フローが、いくつかの合理的な仮定の下で、単純なヒューリスティックランク最小化アルゴリズムである欲張り低ランク学習と数学的に同等であるという理論的および経験的証拠を提供します。これにより、以前の作品からのランク最小化ビューがはるかに広い設定に一般化され、Gunasekar etal。からの推測に反論するための反例を構築することができます。 （2018）。また、深さが3以上の場合にも結果を拡張し、より深くすることの利点は、上記の収束が初期化の大きさに対する依存性がはるかに弱いため、このランクの最小化が初期化に対して有効になる可能性が高いことを示します。実用的なスケール。,6.75,https://d3i71xaburhd42.cloudfront.net/27558603527494688876cbd0cf5af53af5127f4a/9-Figure1-1.png
HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark,"['Chaojian Li', 'Zhongzhi Yu', 'Yonggan Fu', 'Yongan Zhang', 'Yang Zhao', 'Haoran You', 'Qixuan Yu', 'Yue Wang', 'Cong Hao', 'Yingyan Lin']",https://openreview.net/forum?id=_0kaDkv3dVf,"HardWare-aware Neural Architecture Search (HW-NAS) has recently gained tremendous attention for automating the design of DNNs to be deployed into more resource-constrained daily life devices. Despite their promising performance, developing optimal HW-NAS solutions can be prohibitively challenging as it requires cross-disciplinary knowledge in the algorithm, micro-architecture, and device-specific compilation. First, to construct the hardware cost to be incorporated into the NAS process, existing works mostly adopt either pre-collected cost look-up tables or device-specific hardware cost models. The former can be time-consuming due to the needed learning about the device's compilation method and how to set up the measurement pipeline, while the latter is often a barrier for non-hardware experts like NAS researchers. Both of them limit the development of HW-NAS innovations and impose a barrier-to-entry to non-hardware experts. Second, similar to generic NAS, it can be notoriously difficult to benchmark HW-NAS algorithms due to the required significant computational resources and the differences in their adopted search space, hyperparameters, and hardware devices. To this end, we develop HW-NAS-Bench, the first public dataset for HW-NAS research which aims to democratize HW-NAS research to non-hardware experts and make HW-NAS research more reproducible and accessible. To design HW-NAS-Bench, we carefully collected the measured/estimated hardware performance (e.g., energy cost and latency) of all the networks in the search space of both NAS-Bench-201 and FBNet, considering six hardware devices that fall into three categories (i.e., commercial edge devices, FPGA, and ASIC). Furthermore, we provide a comprehensive analysis of the collected measurements in HW-NAS-Bench to provide insights for HW-NAS research. Finally, we demonstrate exemplary user cases when HW-NAS-Bench (1) allows non-hardware experts to perform HW-NAS by simply querying our pre-measured dataset and (2) verify that dedicated device-specific HW-NAS can indeed often provide optimal accuracy-cost trade-offs. The code is available at https://github.com/RICE-EIC/HW-NAS-Bench.",ハードウェア対応のニューラルアーキテクチャ検索（HW-NAS）は、リソースに制約のある日常のデバイスに展開されるDNNの設計を自動化することで、最近大きな注目を集めています。有望なパフォーマンスにもかかわらず、最適なHW-NASソリューションの開発は、アルゴリズム、マイクロアーキテクチャ、およびデバイス固有のコンパイルに関する学際的な知識を必要とするため、非常に困難な場合があります。まず、NASプロセスに組み込まれるハードウェアコストを構築するために、既存の作業では、ほとんどの場合、事前に収集されたコストルックアップテーブルまたはデバイス固有のハードウェアコストモデルのいずれかが採用されます。前者は、デバイスのコンパイル方法と測定パイプラインの設定方法についての学習が必要なため、時間がかかる可能性がありますが、後者は、NAS研究者などのハードウェア以外の専門家にとっては障壁となることがよくあります。どちらもHW-NASイノベーションの開発を制限し、ハードウェア以外の専門家に参入障壁を課します。第2に、一般的なNASと同様に、HW-NASアルゴリズムのベンチマークは、必要な大量の計算リソースと、採用されている検索スペース、ハイパーパラメーター、およびハードウェアデバイスの違いにより、悪名高いほど難しい場合があります。この目的のために、HW-NAS研究を非ハードウェアの専門家に民主化し、HW-NAS研究の再現性とアクセス性を高めることを目的とした、HW-NAS研究の最初の公開データセットであるHW-NAS-Benchを開発します。 HW-NAS-Benchを設計するために、NAS-Bench-201とFBNetの両方の検索スペースにあるすべてのネットワークの測定/推定ハードウェアパフォーマンス（エネルギーコストや遅延など）を慎重に収集しました。 3つのカテゴリ（つまり、商用エッジデバイス、FPGA、およびASIC）。さらに、HW-NAS-Benchで収集された測定値の包括的な分析を提供して、HW-NAS研究の洞察を提供します。最後に、HW-NAS-Benchが（1）ハードウェア以外の専門家が事前に測定されたデータセットにクエリを実行するだけでHW-NASを実行できるようにし、（2）専用のデバイス固有のHW-NASが実際に頻繁に実行できることを確認する場合のユーザーケースの例を示します。最適な精度とコストのトレードオフを提供します。コードはhttps://github.com/RICE-EIC/HW-NAS-Benchで入手できます。,6.75,
Modeling the Second Player in Distributionally Robust Optimization,"['Paul Michel', 'Tatsunori Hashimoto', 'Graham Neubig']",https://openreview.net/forum?id=ZDnzZrTqU9N,"Distributionally robust optimization (DRO) provides a framework for training machine learning models that are able to perform well on a collection of related data distributions (the ""uncertainty set""). This is done by solving a min-max game: the model is trained to minimize its maximum expected loss among all distributions in the uncertainty set. While careful design of the uncertainty set is critical to the success of the DRO procedure, previous work has been limited to relatively simple alternatives that keep the min-max optimization problem exactly tractable, such as $f$-divergence balls. In this paper, we argue instead for the use of neural generative models to characterize the worst-case distribution, allowing for more flexible and problem-specific selection of the uncertainty set. However, while simple conceptually, this approach poses a number of implementation and optimization challenges. To circumvent these issues, we propose a relaxation of the KL-constrained inner maximization objective that makes the DRO problem more amenable to gradient-based optimization of large scale generative models, and develop model selection heuristics to guide hyper-parameter search. On both toy settings and realistic NLP tasks, we find that the proposed approach yields models that are more robust than comparable baselines.",分布ロバスト最適化（DRO）は、関連するデータ分布のコレクション（「不確実性セット」）で適切に実行できる機械学習モデルをトレーニングするためのフレームワークを提供します。これは、最小-最大ゲームを解くことによって行われます。モデルは、不確実性セット内のすべての分布の中で最大の期待損失を最小化するようにトレーニングされます。不確実性セットの注意深い設計はDRO手順の成功にとって重要ですが、以前の作業は、f-発散ボールなど、最小-最大最適化問題を正確に扱いやすくする比較的単純な代替案に限定されていました。この論文では、代わりに、神経生成モデルを使用して最悪の場合の分布を特徴付け、不確実性セットのより柔軟で問題固有の選択を可能にすることを主張します。ただし、概念的には単純ですが、このアプローチには多くの実装と最適化の課題があります。これらの問題を回避するために、DRO問題を大規模生成モデルの勾配ベースの最適化により適したものにするKL制約付き内部最大化目的の緩和を提案し、ハイパーパラメーター検索をガイドするモデル選択ヒューリスティックを開発します。おもちゃの設定と現実的なNLPタスクの両方で、提案されたアプローチにより、同等のベースラインよりも堅牢なモデルが得られることがわかりました。,6.75,
Balancing Constraints and Rewards with Meta-Gradient D4PG,"['Dan A. Calian', 'Daniel J Mankowitz', 'Tom Zahavy', 'Zhongwen Xu', 'Junhyuk Oh', 'Nir Levine', 'Timothy Mann']",https://openreview.net/forum?id=TQt98Ya7UMP,"Deploying Reinforcement Learning (RL) agents to solve real-world applications often requires satisfying complex system constraints. Often the constraint thresholds are incorrectly set due to the complex nature of a system or the inability to verify the thresholds offline (e.g, no simulator or reasonable offline evaluation procedure exists). This results in solutions where a task cannot be solved without violating the constraints. However, in many real-world cases, constraint violations are undesirable yet they are not catastrophic, motivating the need for soft-constrained RL approaches. We present two soft-constrained RL approaches that utilize meta-gradients to find a good trade-off between expected return and minimizing constraint violations. We demonstrate the effectiveness of these approaches by showing that they consistently outperform the baselines across four different Mujoco domains.",実世界のアプリケーションを解決するために強化学習（RL）エージェントを展開するには、多くの場合、複雑なシステム制約を満たす必要があります。多くの場合、システムの複雑な性質や、しきい値をオフラインで検証できないために、制約のしきい値が正しく設定されていません（たとえば、シミュレーターや適切なオフライン評価手順が存在しない）。これにより、制約に違反せずにタスクを解決できないソリューションが得られます。ただし、実際の多くの場合、制約違反は望ましくありませんが、壊滅的ではないため、ソフト制約付きRLアプローチの必要性が高まります。メタ勾配を利用して、期待収益と制約違反の最小化の間の適切なトレードオフを見つける2つのソフト制約付きRLアプローチを紹介します。これらのアプローチが4つの異なるMujocoドメイン全体でベースラインを一貫して上回っていることを示すことにより、これらのアプローチの有効性を示します。,6.75,https://d3i71xaburhd42.cloudfront.net/fefdfccf6d25afd6b24b57bc329562fc49caef21/6-Figure1-1.png
Generalization bounds via distillation,"['Daniel Hsu', 'Ziwei Ji', 'Matus Telgarsky', 'Lan Wang']",https://openreview.net/forum?id=EGdFhBzmAwB,"This paper provides a suite of mathematical tools to bound the generalization error of networks that possess low-complexity distillations --- that is, when there exist simple networks whose softmax outputs approximately match those of the original network.  The primary contribution is the aforementioned bound, which upper bounds the test error of a network by the sum of its training error, the distillation error, and the complexity of the distilled network.  Supporting this, secondary contributions include: a generalization bound which can handle convolutions and skip connections, a generalization analysis of the compression step leading to a bound with small width- and depth-dependence via weight matrix stable ranks, and a sampling theorem to sparsify dense networks.  The bounds and their behavior are illustrated empirically on the standard mnist and cifar datasets.
",このホワイトペーパーでは、複雑度の低い蒸留を行うネットワークの汎化誤差を制限するための一連の数学的ツールを提供します。つまり、ソフトマックス出力が元のネットワークの出力とほぼ一致する単純なネットワークが存在する場合です。主な寄与は前述の限界であり、トレーニング誤差、蒸留誤差、および蒸留ネットワークの複雑さの合計によってネットワークのテスト誤差を上限とします。これをサポートする二次的な貢献には、畳み込みとスキップ接続を処理できる一般化境界、重み行列の安定ランクを介した幅と深さの依存性が小さい境界につながる圧縮ステップの一般化分析、および密な分散を行うためのサンプリング定理が含まれます。ネットワーク。境界とその動作は、標準のmnistおよびcifarデータセットで経験的に示されています。,6.75,
Long Range Arena : A Benchmark for Efficient Transformers ,"['Yi Tay', 'Mostafa Dehghani', 'Samira Abnar', 'Yikang Shen', 'Dara Bahri', 'Philip Pham', 'Jinfeng Rao', 'Liu Yang', 'Sebastian Ruder', 'Donald Metzler']",https://openreview.net/forum?id=qVyeW-grC2k,"Transformers do not scale very well to long sequence lengths largely because of quadratic self-attention complexity. In the recent months, a wide spectrum of efficient, fast Transformers have been proposed to tackle this problem, more often than not claiming superior or comparable model quality to vanilla Transformer models. To this date, there is no well-established consensus on how to evaluate this class of models. Moreover, inconsistent benchmarking on a wide spectrum of tasks and datasets makes it difficult to assess relative model quality amongst many models. This paper proposes a systematic and unified benchmark, Long Range Arena, specifically focused on evaluating model quality under long-context scenarios. Our benchmark is a suite of tasks consisting of sequences ranging from $1K$ to $16K$ tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. We systematically evaluate ten well-established long-range Transformer models (Reformers, Linformers, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on our newly proposed benchmark suite. Long Range Arena paves the way towards better understanding this class of efficient Transformer models, facilitates more research in this direction, and presents new challenging tasks to tackle.",トランスフォーマーは、主に2次の自己注意の複雑さのために、長いシーケンス長にうまくスケーリングしません。ここ数ヶ月、この問題に取り組むために、効率的で高速なトランスフォーマーが幅広く提案されており、バニラトランスフォーマーモデルよりも優れた、または同等のモデル品質を主張することがよくあります。現在まで、このクラスのモデルを評価する方法について確立されたコンセンサスはありません。さらに、広範囲のタスクとデータセットで一貫性のないベンチマークを行うと、多くのモデル間で相対的なモデルの品質を評価することが困難になります。このホワイトペーパーでは、体系的で統一されたベンチマークであるLong Range Arenaを提案します。特に、ロングコンテキストシナリオでのモデル品質の評価に焦点を当てています。私たちのベンチマークは、1Kから16Kトークンの範囲のシーケンスで構成される一連のタスクであり、テキスト、自然画像、合成画像、類似性、構造​​、視覚空間の推論を必要とする数式など、さまざまなデータ型とモダリティを網羅しています。新しく提案されたベンチマークスイートで、確立された10の長距離トランスフォーマーモデル（リフォーマー、リンフォーマー、リニアトランスフォーマー、シンクホーントランスフォーマー、パフォーマー、シンセサイザー、スパーストランスフォーマー、ロングフォーマー）を体系的に評価します。ロングレンジアリーナは、このクラスの効率的なTransformerモデルをよりよく理解するための道を開き、この方向でのより多くの研究を促進し、取り組むべき新しい挑戦的なタスクを提示します。,6.75,https://d3i71xaburhd42.cloudfront.net/7e9ff94476f41041c75e253e84f487db00e9c861/4-Figure1-1.png
MALI: A memory efficient and reverse accurate integrator for Neural ODEs,"['Juntang Zhuang', 'Nicha C Dvornek', 'sekhar tatikonda', 'James s Duncan']",https://openreview.net/forum?id=blfSjHeFM_e,"Neural ordinary differential equations (Neural ODEs) are a new family of deep-learning models with continuous depth. However, the numerical estimation of the gradient in the continuous case is not well solved: existing implementations of the adjoint method suffer from inaccuracy in reverse-time trajectory, while the naive method and the adaptive checkpoint adjoint method (ACA) have a memory cost that grows with integration time. In this project, based on the asynchronous leapfrog (ALF) solver, we propose the Memory-efficient ALF Integrator (MALI), which has a constant memory cost $w.r.t$ integration time similar to the adjoint method, and guarantees accuracy in reverse-time trajectory (hence accuracy in gradient estimation). We validate MALI in various tasks: on image recognition tasks, to our knowledge, MALI is the first to enable feasible training of a Neural ODE on ImageNet and outperform a well-tuned ResNet, while existing methods fail due to either heavy memory burden or inaccuracy; for time series modeling, MALI significantly outperforms the adjoint method; and for continuous generative models, MALI achieves new state-of-the-art performance.",ニューラル常微分方程式（ニューラルODE）は、連続的な深さを持つディープラーニングモデルの新しいファミリーです。ただし、連続の場合の勾配の数値推定は十分に解決されていません。隣接法の既存の実装では、逆時間の軌跡が不正確になりますが、ナイーブ法と適応チェックポイント隣接法（ACA）のメモリコストは統合時間とともに成長します。このプロジェクトでは、非同期リープフロッグ（ALF）ソルバーに基づいて、隣接法と同様の積分時間で一定のメモリコストを持ち、逆時間軌道の精度を保証するメモリ効率の高いALF積分器（MALI）を提案します（したがって、勾配推定の精度）。私たちはさまざまなタスクでMALIを検証します。画像認識タスクでは、私たちの知る限り、MALIはImageNetでニューラルODEの実行可能なトレーニングを可能にし、適切に調整されたResNetを上回りますが、既存の方法は重いメモリ負荷または不正確さのために失敗します;時系列モデリングの場合、MALIは随伴法を大幅に上回ります。また、連続生成モデルの場合、MALIは新しい最先端のパフォーマンスを実現します。,6.75,
Hierarchical Autoregressive Modeling for Neural Video Compression,"['Ruihan Yang', 'Yibo Yang', 'Joseph Marino', 'Stephan Mandt']",https://openreview.net/forum?id=TK_6nNb_C7q,"Recent work by Marino et al. (2020) showed improved performance in sequential density estimation by combining masked autoregressive flows with hierarchical latent variable models. We draw a connection between such autoregressive generative models and the task of lossy video compression. Specifically, we view recent neural video compression methods (Lu et al., 2019; Yang et al., 2020b; Agustssonet al., 2020) as instances of a generalized stochastic temporal autoregressive trans-form, and propose avenues for enhancement based on this insight. Comprehensive evaluations on large-scale video data show improved rate-distortion performance over both state-of-the-art neural and conventional video compression methods.",マリノらによる最近の作品。 （2020）は、マスクされた自己回帰フローを階層的潜在変数モデルと組み合わせることにより、順次密度推定のパフォーマンスが向上することを示しました。このような自己回帰生成モデルと不可逆ビデオ圧縮のタスクとの間に関係を描きます。具体的には、最近のニューラルビデオ圧縮法（Lu et al。、2019; Yang et al。、2020b; Agustssonet al。、2020）を一般化された確率的時間的自己回帰変換のインスタンスと見なし、これに基づいて強化する方法を提案します。洞察。大規模なビデオデータの包括的な評価は、最先端のニューラルおよび従来のビデオ圧縮方法の両方よりも改善されたレート歪み性能を示しています。,6.75,https://d3i71xaburhd42.cloudfront.net/8a5442824f73efb99ad14e7fedf30ff60eee0e8d/5-Figure1-1.png
Selective Classification Can Magnify Disparities Across Groups,"['Erik Jones', 'Shiori Sagawa', 'Pang Wei Koh', 'Ananya Kumar', 'Percy Liang']",https://openreview.net/forum?id=N0M_4BkQ05i,"Selective classification, in which models are allowed to abstain on uncertain predictions, is a natural approach to improving accuracy in settings where errors are costly but abstentions are manageable. In this paper, we find that while selective classification can improve average accuracies, it can simultaneously magnify existing accuracy disparities between various groups within a population, especially in the presence of spurious correlations. We observe this behavior consistently across five datasets from computer vision and NLP. Surprisingly, increasing the abstention rate can even decrease accuracies on some groups. To better understand when selective classification improves or worsens accuracy on a group, we study its margin distribution, which captures the model’s confidences over all predictions. For example, when the margin distribution is symmetric, we prove that whether selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage (i.e., without any abstentions) and whether the distribution satisfies a property we term left-log-concavity. Our analysis also shows that selective classification tends to magnify accuracy disparities that are present at full coverage. Fortunately, we find that it uniformly improves each group when applied to distributionally-robust models that achieve similar full-coverage accuracies across groups. Altogether, our results imply selective classification should be used with care and underscore the importance of models that perform equally well across groups at full coverage.",モデルが不確実な予測を棄権することを許可される選択的分類は、エラーがコストがかかるが棄権が管理可能な設定で精度を向上させるための自然なアプローチです。この論文では、選択的分類は平均精度を向上させることができる一方で、特に疑似相関が存在する場合に、母集団内のさまざまなグループ間の既存の精度の不一致を同時に拡大できることを発見しました。この動作は、コンピュータービジョンとNLPの5つのデータセットで一貫して観察されています。驚くべきことに、棄権率を上げると、一部のグループの精度が低下することさえあります。選択的分類がグループの精度を向上または悪化させる時期をよりよく理解するために、すべての予測に対するモデルの信頼度を取得するマージン分布を調べます。たとえば、マージン分布が対称である場合、選択的分類が精度を単調に改善するか悪化させるかは、完全なカバレッジでの精度（つまり、棄権なし）と、分布が左ログと呼ばれる特性を満たすかどうかによって完全に決定されることを証明します。凹面。私たちの分析はまた、選択的分類は、完全なカバレッジで存在する精度の不一致を拡大する傾向があることを示しています。幸い、グループ間で同様のフルカバレッジ精度を達成する分布ロバストモデルに適用すると、各グループが均一に改善されることがわかりました。全体として、私たちの結果は、選択的な分類を注意深く使用する必要があることを示唆しており、完全なカバレッジでグループ間で同等に機能するモデルの重要性を強調しています。,6.75,https://d3i71xaburhd42.cloudfront.net/63ffa7b8f87f9589bfb10323c9cb7f6d4e63ad08/2-Figure1-1.png
Learning Associative Inference Using Fast Weight Memory,"['Imanol Schlag', 'Tsendsuren Munkhdalai', 'Jürgen Schmidhuber']",https://openreview.net/forum?id=TuK6agbdt27,"Humans can quickly associate stimuli to solve problems in novel contexts. Our novel neural network model learns state representations of facts that can be composed to perform such associative inference. To this end, we augment the LSTM model with an associative memory, dubbed \textit{Fast Weight Memory} (FWM). Through differentiable operations at every step of a given input sequence, the LSTM \textit{updates and maintains} compositional associations stored in the rapidly changing FWM weights. Our model is trained end-to-end by gradient descent and yields excellent performance on compositional language reasoning problems, meta-reinforcement-learning for POMDPs, and small-scale word-level language modelling.",人間は刺激をすばやく関連付けて、新しい状況で問題を解決できます。私たちの新しいニューラルネットワークモデルは、連想推論などを実行するために構成できる事実の状態表現を学習します。この目的のために、高速重みメモリ（FWM）と呼ばれる連想メモリでLSTMモデルを拡張します。 LSTMは、特定の入力シーケンスのすべてのステップで微分可能な操作を行うことにより、急速に変化するFWMの重みに格納されている構成上の関連付けを更新および維持します。私たちのモデルは、勾配降下法によってエンドツーエンドでトレーニングされており、構成言語推論の問題、POMDPのメタ強化学習、および小規模な単語レベルの言語モデリングで優れたパフォーマンスを発揮します。,6.75,https://d3i71xaburhd42.cloudfront.net/5e11e806d24dd80ecf0f91e7aacedbba8d9fd6fc/3-Figure1-1.png
Randomized Ensembled Double Q-Learning: Learning Fast Without a Model,"['Xinyue Chen', 'Che Wang', 'Zijian Zhou', 'Keith W. Ross']",https://openreview.net/forum?id=AY8zfZm0tDd,"Using a high Update-To-Data (UTD) ratio, model-based methods have recently achieved much higher sample efficiency than previous model-free methods for continuous-action DRL benchmarks. In this paper, we introduce a simple model-free algorithm, Randomized Ensembled Double Q-Learning (REDQ), and show that its performance is just as good as, if not better than, a state-of-the-art model-based algorithm for the MuJoCo benchmark. Moreover, REDQ can achieve this performance using fewer parameters than the model-based method, and with less wall-clock run time. REDQ has three carefully integrated ingredients which allow it to achieve its high performance: (i) a UTD ratio $\gg 1$; (ii) an ensemble of Q functions; (iii) in-target minimization across a random subset of Q functions from the ensemble. Through carefully designed experiments, we provide a detailed analysis of REDQ and related model-free algorithms. To our knowledge, REDQ is the first successful model-free DRL algorithm for continuous-action spaces using a UTD ratio $\gg 1$. ",高いUpdate-To-Data（UTD）比を使用して、モデルベースのメソッドは最近、連続アクションDRLベンチマークの以前のモデルフリーメソッドよりもはるかに高いサンプル効率を達成しました。このホワイトペーパーでは、単純なモデルフリーアルゴリズムであるRandomized Ensembled Double Q-Learning（REDQ）を紹介し、そのパフォーマンスが最先端のモデルベースと同等かそれ以上であることを示します。 MuJoCoベンチマークのアルゴリズム。さらに、REDQは、モデルベースの方法よりも少ないパラメーターを使用して、より少ない実時間でこのパフォーマンスを実現できます。 REDQには、3つの慎重に統合された成分があり、その高性能を実現できます。（i）UTD比1。 （ii）Q関数のアンサンブル。 （iii）アンサンブルからのQ関数のランダムなサブセットにわたるターゲット内最小化。慎重に設計された実験を通じて、REDQおよび関連するモデルフリーアルゴリズムの詳細な分析を提供します。私たちの知る限り、REDQは、UTD比1を使用した連続アクション空間で最初に成功したモデルフリーDRLアルゴリズムです。,6.75,https://d3i71xaburhd42.cloudfront.net/736590f70e7f2dc464c1c62491cfa8adb4d718f3/3-Figure1-1.png
Rethinking Positional Encoding in Language Pre-training,"['Guolin Ke', 'Di He', 'Tie-Yan Liu']",https://openreview.net/forum?id=09-528y2Fgf,"In this work, we investigate the positional encoding methods used in language pre-training (e.g., BERT) and identify several problems in the existing formulations. First, we show that in the absolute positional encoding, the addition operation applied on positional embeddings and word embeddings brings mixed correlations between the two heterogeneous information resources. It may bring unnecessary randomness in the attention and further limit the expressiveness of the model.  Second, we question whether treating the position of the symbol \texttt{[CLS]} the same as other words is a reasonable design, considering its special role (the representation of the entire sentence) in the downstream tasks. Motivated from above analysis, we propose a new positional encoding method called \textbf{T}ransformer with \textbf{U}ntied \textbf{P}ositional \textbf{E}ncoding (TUPE). In the self-attention module, TUPE computes the word contextual correlation and positional correlation separately with different parameterizations and then adds them together. This design removes the mixed and noisy correlations over heterogeneous embeddings and offers more expressiveness by using different projection matrices. Furthermore, TUPE unties the \texttt{[CLS]} symbol from other positions, making it easier to capture information from all positions. Extensive experiments and ablation studies on GLUE benchmark demonstrate the effectiveness of the proposed method. Codes and models will be released.",この作業では、言語の事前トレーニング（BERTなど）で使用される位置エンコード方法を調査し、既存の定式化におけるいくつかの問題を特定します。まず、絶対位置エンコーディングでは、位置埋め込みと単語埋め込みに適用される加算演算が、2つの異種情報リソース間に混合相関をもたらすことを示します。それは注意に不必要なランダム性をもたらし、モデルの表現力をさらに制限する可能性があります。次に、記号[CLS]の位置を他の単語と同じように扱うことが、下流のタスクにおけるその特別な役割（文全体の表現）を考慮して、合理的な設計であるかどうかを疑問視します。上記の分析から動機付けられて、我々は、Untied Positional Encoding（TUPE）を備えたTransformerと呼ばれる新しい位置エンコーディング方法を提案します。自己注意モジュールでは、TUPEは単語の文脈相関と位置相関を異なるパラメーター化で別々に計算し、それらを足し合わせます。この設計は、異種の埋め込みに対する混合されたノイズの多い相関関係を取り除き、さまざまな射影行列を使用することでより表現力を提供します。さらに、TUPEは[CLS]シンボルを他の位置から切り離し、すべての位置からの情報を簡単に取得できるようにします。 GLUEベンチマークに関する広範な実験とアブレーション研究は、提案された方法の有効性を示しています。コードとモデルがリリースされます。,6.75,https://d3i71xaburhd42.cloudfront.net/8256f48f759cf85044db251cc512f965834945b3/2-Figure1-1.png
Mind the Gap when Conditioning Amortised Inference in Sequential Latent-Variable Models,"['Justin Bayer', 'Maximilian Soelch', 'Atanas Mirchev', 'Baris Kayalibay', 'Patrick van der Smagt']",https://openreview.net/forum?id=a2gqxKDvYys,"Amortised inference enables scalable learning of sequential latent-variable models (LVMs) with the evidence lower bound (ELBO).
In this setting, variational posteriors are often only partially conditioned. While the true posteriors depend, e.g., on the entire sequence of observations, approximate posteriors are only informed by past observations. This mimics the Bayesian filter---a mixture of smoothing posteriors. Yet, we show that the ELBO objective forces partially--conditioned amortised posteriors to approximate products of smoothing posteriors instead. Consequently, the learned generative model is compromised. We demonstrate these theoretical findings in three scenarios: traffic flow, handwritten digits, and aerial vehicle dynamics. Using fully-conditioned approximate posteriors, performance improves in terms of generative modelling and multi-step prediction.
",償却された推論により、証拠の下限（ELBO）を使用して順次潜在変数モデル（LVM）のスケーラブルな学習が可能になります。この設定では、変分事後確率は部分的にしか条件付けされていないことがよくあります。真の事後確率は、たとえば一連の観測全体に依存しますが、おおよその事後確率は過去の観測によってのみ通知されます。これは、スムージング事後確率のベイズフィルター混合を模倣します。それでも、ELBOの目的により、部分的に調整された償却事後確率が、代わりに平滑化事後確率の積に近似するように強制されることを示します。その結果、学習された生成モデルが損なわれます。これらの理論的発見を、交通の流れ、手書きの数字、および航空機のダイナミクスの3つのシナリオで示します。完全に調整された近似事後確率を使用すると、生成モデリングと多段階予測の観点からパフォーマンスが向上します。,6.75,https://d3i71xaburhd42.cloudfront.net/a86bbc845782a316b25137c45d9bd18c6ea05734/2-Figure1-1.png
Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization,"['Tatsuya Matsushima', 'Hiroki Furuta', 'Yutaka Matsuo', 'Ofir Nachum', 'Shixiang Gu']",https://openreview.net/forum?id=3hGNqpI4WS,"Most reinforcement learning (RL) algorithms assume online access to the environment, in which one may readily interleave updates to the policy with experience collection using that policy. However, in many real-world applications such as health, education, dialogue agents, and robotics, the cost or potential risk of deploying a new data-collection policy is high, to the point that it can become prohibitive to update the data-collection policy more than a few times during learning. With this view, we propose a novel concept of deployment efficiency, measuring the number of distinct data-collection policies that are used during policy learning. We observe that naïvely applying existing model-free offline RL algorithms recursively does not lead to a practical deployment-efficient and sample-efficient algorithm. We propose a novel model-based algorithm, Behavior-Regularized Model-ENsemble (BREMEN), that not only performs better than or comparably as the state-of-the-art dynamic-programming-based and concurrently-proposed model-based offline approaches on existing benchmarks, but can also effectively optimize a policy offline using 10-20 times fewer data than prior works. Furthermore, the recursive application of BREMEN achieves impressive deployment efficiency while maintaining the same or better sample efficiency, learning successful policies from scratch on simulated robotic environments with only 5-10 deployments, compared to typical values of hundreds to millions in standard RL baselines.",ほとんどの強化学習（RL）アルゴリズムは、環境へのオンラインアクセスを前提としています。この環境では、ポリシーの更新と、そのポリシーを使用したエクスペリエンスの収集を簡単にインターリーブできます。ただし、健康、教育、対話エージェント、ロボット工学などの多くの実際のアプリケーションでは、新しいデータ収集ポリシーを展開するコストまたは潜在的なリスクが高く、データ収集の更新が禁止される可能性があります。学習中に数回以上のポリシー。この観点から、ポリシーの学習中に使用される個別のデータ収集ポリシーの数を測定する、展開効率の新しい概念を提案します。既存のモデルフリーオフラインRLアルゴリズムを再帰的に単純に適用しても、実際の展開効率とサンプル効率の高いアルゴリズムにはつながらないことがわかります。新しいモデルベースのアルゴリズムであるBehavior-RegularizedModel-ENsemble（BREMEN）を提案します。これは、最先端の動的計画法ベースおよび同時に提案されているモデルベースのオフラインアプローチよりも優れているだけでなく、同等のパフォーマンスを発揮します。既存のベンチマークに基づいていますが、以前の作業の10〜20分の1のデータを使用して、オフラインでポリシーを効果的に最適化することもできます。さらに、BREMENの再帰的アプリケーションは、同じかそれ以上のサンプル効率を維持しながら、印象的な展開効率を実現し、標準のRLベースラインの数百から数百万の一般的な値と比較して、わずか5〜10の展開でシミュレートされたロボット環境で成功するポリシーを最初から学習します。,6.75,https://d3i71xaburhd42.cloudfront.net/79ebde314ab90d066cee3b82193ef05666323394/2-Figure1-1.png
UMEC: Unified model and embedding compression for efficient recommendation systems,"['Jiayi Shen', 'Haotao Wang', 'Shupeng Gui', 'Jianchao Tan', 'Zhangyang Wang', 'Ji Liu']",https://openreview.net/forum?id=BM---bH_RSh,"The recommendation system (RS) plays an important role in the content recommendation and retrieval scenarios. The core part of the system is the Ranking neural network, which is usually a bottleneck of whole system performance during online inference.  In this work, we propose a unified model and embedding compression (UMEC) framework to hammer an efficient neural network-based recommendation system.  Our framework jointly learns input feature selection and neural network compression together, and solve them as an end-to-end resource-constrained optimization problem using ADMM.  Our method outperforms other baselines in terms of neural network Flops, sparse embedding feature size and the number of sparse embedding features.  We evaluate our method on the public benchmark of DLRM, trained over the Kaggle Criteo dataset.",レコメンデーションシステム（RS）は、コンテンツのレコメンデーションと検索のシナリオで重要な役割を果たします。システムの中核部分はランキングニューラルネットワークです。これは通常、オンライン推論中のシステム全体のパフォーマンスのボトルネックです。この作業では、効率的なニューラルネットワークベースのレコメンデーションシステムを打ち出すために、統合モデルと埋め込み圧縮（UMEC）フレームワークを提案します。私たちのフレームワークは、入力特徴選択とニューラルネットワーク圧縮を一緒に学習し、ADMMを使用してエンドツーエンドのリソース制約付き最適化問題としてそれらを解決します。私たちの方法は、ニューラルネットワークフロップ、スパース埋め込み機能のサイズ、およびスパース埋め込み機能の数の点で、他のベースラインよりも優れています。 Kaggle Criteoデータセットでトレーニングされた、DLRMの公開ベンチマークでメソッドを評価します。,6.75,
An Unsupervised Deep Learning Approach for Real-World Image Denoising,"['Dihan Zheng', 'Sia Huat Tan', 'Xiaowen Zhang', 'Zuoqiang Shi', 'Kaisheng Ma', 'Chenglong Bao']",https://openreview.net/forum?id=tIjRAiFmU3y,"Designing an unsupervised image denoising approach in practical applications is a challenging task due to the complicated data acquisition process. In the real-world case, the noise distribution is so complex that the simplified additive white Gaussian (AWGN) assumption rarely holds, which significantly deteriorates the Gaussian denoisers' performance. To address this problem, we apply a deep neural network that maps the noisy image into a latent space in which the AWGN assumption holds, and thus any existing Gaussian denoiser is applicable. More specifically, the proposed neural network consists of the encoder-decoder structure and approximates the likelihood term in the Bayesian framework. Together with a Gaussian denoiser, the neural network can be trained with the input image itself and does not require any pre-training in other datasets. Extensive experiments on real-world noisy image datasets have shown that the combination of neural networks and Gaussian denoisers improves the performance of the original Gaussian denoisers by a large margin. In particular, the neural network+BM3D method significantly outperforms other unsupervised denoising approaches and is competitive with supervised networks such as DnCNN, FFDNet, and CBDNet.",実際のアプリケーションで教師なし画像ノイズ除去アプローチを設計することは、データ収集プロセスが複雑であるため、困難な作業です。実際のケースでは、ノイズ分布が非常に複雑であるため、単純化された加法性ホワイトガウス（AWGN）の仮定が成り立つことはめったになく、ガウスデノイザーのパフォーマンスが大幅に低下します。この問題に対処するために、ノイズの多い画像をAWGNの仮定が成り立つ潜在空間にマッピングするディープニューラルネットワークを適用します。したがって、既存のガウスデノイザーを適用できます。より具体的には、提案されたニューラルネットワークはエンコーダ-デコーダ構造で構成され、ベイズフレームワークの尤度項を近似します。ガウスデノイザーと一緒に、ニューラルネットワークは入力画像自体でトレーニングでき、他のデータセットでの事前トレーニングは必要ありません。実世界のノイズの多い画像データセットでの広範な実験により、ニューラルネットワークとガウスデノイザーの組み合わせにより、元のガウスデノイザーのパフォーマンスが大幅に向上することが示されています。特に、ニューラルネットワーク+ BM3D法は、他の教師なしノイズ除去アプローチを大幅に上回り、DnCNN、FFDNet、CBDNetなどの教師なしネットワークと競合します。,6.75,
Towards A Unified Understanding and Improving of Adversarial Transferability ,"['Xin Wang', 'Jie Ren', 'Shuyun Lin', 'Xiangming Zhu', 'Yisen Wang', 'Quanshi Zhang']",https://openreview.net/forum?id=X76iqnUbBjz,"In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.",この論文では、敵対的摂動内の相互作用を使用して、敵対的伝達可能性を説明および強化します。敵対的な伝達可能性と敵対的な摂動内の相互作用の間の負の相関関係を発見し、証明します。負の相関は、さまざまな入力を持つさまざまなDNNによってさらに検証されます。さらに、この負の相関関係は、現在の転送可能性を高める方法を理解するための統一された視点と見なすことができます。この目的のために、転送可能性を強化するいくつかの古典的な方法が、敵対的な摂動内の相互作用を本質的に減少させることを証明します。これに基づいて、攻撃プロセス中の相互作用に直接ペナルティを課すことを提案します。これにより、敵対者の転送可能性が大幅に向上します。論文が受理され次第、コードを公開します。,6.75,
Evaluations and Methods for Explanation through Robustness Analysis,"['Cheng-Yu Hsieh', 'Chih-Kuan Yeh', 'Xuanqing Liu', 'Pradeep Kumar Ravikumar', 'Seungyeon Kim', 'Sanjiv Kumar', 'Cho-Jui Hsieh']",https://openreview.net/forum?id=4dXmpCDGNp7,"Feature based explanations, that provide importance of each feature towards the model prediction, is arguably one of the most intuitive ways to explain a model. In this paper, we establish a novel set of evaluation criteria for such feature based explanations by robustness analysis. In contrast to existing evaluations which require us to specify some way to ``remove'' features that could inevitably introduces biases and artifacts, we make use of the subtler notion of smaller adversarial perturbations. By optimizing towards our proposed evaluation criteria, we obtain new explanations that are loosely necessary and sufficient for a prediction. We further extend the explanation to extract the set of features that would move the current prediction to a target class by adopting targeted adversarial attack for the robustness analysis. Through experiments across multiple domains and a human study, we validate the usefulness of our evaluation criteria and our derived explanations.",モデル予測に対する各機能の重要性を提供する機能ベースの説明は、間違いなく、モデルを説明するための最も直感的な方法の1つです。本論文では、ロバストネス分析により、そのような特徴に基づく説明のための新しい一連の評価基準を確立する。バイアスやアーティファクトを必然的に導入する可能性のある機能を削除する方法を指定する必要がある既存の評価とは対照的に、より小さな敵対的摂動の微妙な概念を利用します。提案された評価基準に向けて最適化することにより、予測に大まかに必要かつ十分な新しい説明が得られます。さらに説明を拡張して、ロバスト性分析にターゲットを絞った敵対的攻撃を採用することにより、現在の予測をターゲットクラスに移動する一連の機能を抽出します。複数のドメインにわたる実験と人間による研究を通じて、評価基準と導き出された説明の有用性を検証します。,6.75,https://d3i71xaburhd42.cloudfront.net/545a3169cb7ce37084b5e10a51e29c95f99ab51a/5-Figure1-1.png
RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs,"['Meng Qu', 'Junkun Chen', 'Louis-Pascal Xhonneux', 'Yoshua Bengio', 'Jian Tang']",https://openreview.net/forum?id=tGZu6DlbreV,"This paper studies learning logic rules for reasoning on knowledge graphs. Logic rules provide interpretable explanations when used for prediction as well as being able to generalize to other tasks, and hence are critical to learn. Existing methods either suffer from the problem of searching in a large search space (e.g., neural logic programming) or ineffective optimization due to sparse rewards (e.g., techniques based on reinforcement learning). To address these limitations, this paper proposes a probabilistic model called RNNLogic. RNNLogic treats logic rules as a latent variable, and simultaneously trains a rule generator as well as a reasoning predictor with logic rules. We develop an EM-based algorithm for optimization. In each iteration, the reasoning predictor is updated to explore some generated logic rules for reasoning. Then in the E-step, we select a set of high-quality rules from all generated rules with both the rule generator and reasoning predictor via posterior inference; and in the M-step, the rule generator is updated with the rules selected in the E-step. Experiments on four datasets prove the effectiveness of RNNLogic.",この論文は、知識グラフで推論するための学習論理規則を研究します。論理ルールは、予測に使用されるときに解釈可能な説明を提供するだけでなく、他のタスクに一般化できるため、学習することが重要です。既存の方法は、大きな探索空間での探索（たとえば、神経論理プログラミング）の問題、または疎な報酬（たとえば、強化学習に基づく手法）による効果のない最適化のいずれかに悩まされます。これらの制限に対処するために、この論文ではRNNLogicと呼ばれる確率モデルを提案します。 RNNLogicは、論理ルールを潜在変数として扱い、同時にルールジェネレーターと論理ルールを使用した推論予測子をトレーニングします。最適化のためのEMベースのアルゴリズムを開発します。各反復で、推論予測子が更新され、推論のために生成されたいくつかの論理ルールが調査されます。次に、Eステップで、生成されたすべてのルールから高品質のルールのセットを選択し、事後推論を介してルールジェネレーターと推論予測子の両方を使用します。 Mステップでは、ルールジェネレータはEステップで選択されたルールで更新されます。 4つのデータセットでの実験により、RNNLogicの有効性が証明されています。,6.75,https://d3i71xaburhd42.cloudfront.net/0ba25a14580cfd236d5abf8b7fb1544d5f9648b4/3-Figure1-1.png
Differentially Private Learning Needs Better Features (or Much More Data),"['Florian Tramer', 'Dan Boneh']",https://openreview.net/forum?id=YTWGvpFOQD-,"We demonstrate that differentially private machine learning has not yet reached its ''AlexNet moment'' on many canonical vision tasks: linear models trained on handcrafted features significantly outperform end-to-end deep neural networks for moderate privacy budgets.
To exceed the performance of handcrafted features, we show that private learning requires either much more private data, or access to features learned on public data from a similar domain.
Our work introduces simple yet strong baselines for differentially private learning that can inform the evaluation of future progress in this area.",差分プライベート機械学習は、多くの標準的なビジョンタスクでまだAlexNetの瞬間に到達していないことを示しています。手作りの機能でトレーニングされた線形モデルは、適度なプライバシー予算でエンドツーエンドのディープニューラルネットワークを大幅に上回っています。手作りの機能のパフォーマンスを超えるには、プライベート学習にははるかに多くのプライベートデータが必要であるか、同様のドメインのパブリックデータで学習された機能にアクセスする必要があることを示します。私たちの仕事は、この分野での将来の進歩の評価に情報を与えることができる差分プライベート学習のためのシンプルでありながら強力なベースラインを紹介します。,6.75,https://d3i71xaburhd42.cloudfront.net/f864273db01ce9b728c3c16b08a5f7b22b917efb/6-Figure1-1.png
Do not Let Privacy Overbill Utility:  Gradient Embedding Perturbation for Private Learning,"['Da Yu', 'Huishuai Zhang', 'Wei Chen', 'Tie-Yan Liu']",https://openreview.net/forum?id=7aogOj_VYO0,"The privacy leakage of the model about the training data can be bounded in the differential privacy mechanism. However, for meaningful privacy parameters, a differentially private model degrades the utility drastically when the model comprises a large number of trainable parameters.  In this paper, we propose an algorithm  \emph{Gradient Embedding Perturbation (GEP)} towards training differentially private deep models with decent accuracy. Specifically, in each gradient descent step, GEP first projects individual private gradient into a non-sensitive anchor subspace, producing a low-dimensional gradient embedding and a small-norm residual gradient. Then, GEP perturbs the low-dimensional embedding and the residual gradient separately according to the privacy budget. Such a decomposition permits a small perturbation variance, which greatly helps to break the dimensional barrier of private learning. With GEP, we achieve decent accuracy with low computational cost and modest privacy guarantee for deep models.  Especially, with privacy bound $\epsilon=8$, we achieve $74.9\%$ test accuracy on CIFAR10 and $95.1\%$ test accuracy on  SVHN, significantly improving over existing results.",トレーニングデータに関するモデルのプライバシー漏洩は、差分プライバシーメカニズムで制限される可能性があります。ただし、意味のあるプライバシーパラメータの場合、モデルにトレーニング可能なパラメータが多数含まれていると、差分プライベートモデルは効用を大幅に低下させます。この論文では、適切な精度で差分プライベートディープモデルをトレーニングするためのアルゴリズムGradient Embedding Perturbation（GEP）を提案します。具体的には、各勾配降下ステップで、GEPは最初に個々のプライベート勾配を感度の低いアンカー部分空間に投影し、低次元の勾配埋め込みと小さなノルムの残差勾配を生成します。次に、GEPは、プライバシーバジェットに従って、低次元の埋め込みと残余の勾配を別々に摂動させます。このような分解により、小さな摂動分散が可能になり、個人学習の次元の障壁を打ち破るのに大いに役立ちます。 GEPを使用すると、深いモデルに対して低い計算コストと適度なプライバシー保証でまともな精度を実現します。特に、プライバシーバウンド= 8の場合、CIFAR10で74.9％のテスト精度、SVHNで95.1％のテスト精度を達成し、既存の結果を大幅に改善します。,6.75,
Effective Abstract Reasoning with Dual-Contrast Network,"['Tao Zhuo', 'Mohan Kankanhalli']",https://openreview.net/forum?id=ldxlzGYWDmW,"Abstract reasoning is a challenging task in artificial intelligence. As a step towards improving the abstract reasoning capability of machines, we aim to solve Raven's Progressive Matrices (RPM) with neural networks, as RPM is highly correlated with human intelligence. Unlike previous methods that use auxiliary annotations or assume hidden rules to produce appropriate feature representation, we only use the ground truth answer of each question for model learning, since we aim for an intelligent agent to have a strong learning capability with a small amount of supervision. In the RPM problem formulation, the correct answer filled into the missing entry of the third row/column has to best satisfy the same rules shared between the first two rows/columns. We propose a simple yet effective Dual-Contrast Network (DCNet) to  exploit the inherent structure of RPM questions. Specifically, a rule contrast module is designed to compare the latent rules between the filled row/column and the first two rows/columns; a choice contrast module is designed to increase the relative differences between candidate choices. Experimental results on the RAVEN and PGM datasets show that DCNet outperforms the state-of-the-art methods by a large margin of 5.77%. Further experiments on few training samples and model generalization also show the effectiveness of our method.",抽象的推論は、人工知能における挑戦的なタスクです。機械の抽象的な推論能力を向上させるためのステップとして、RPMは人間の知能と高度に相関しているため、ニューラルネットワークを使用してRavens Progressive Matrices（RPM）を解決することを目指しています。補助アノテーションを使用したり、隠されたルールを想定して適切な特徴表現を生成する以前の方法とは異なり、モデル学習には各質問のグラウンドトゥルース回答のみを使用します。これは、インテリジェントエージェントが少量の監視で強力な学習機能を持つことを目的としているためです。 。 RPM問題の定式化では、3番目の行/列の欠落しているエントリに入力された正解は、最初の2つの行/列で共有される同じルールを最もよく満たす必要があります。 RPMの質問の固有の構造を活用するために、シンプルでありながら効果的なデュアルコントラストネットワーク（DCNet）を提案します。具体的には、ルールコントラストモジュールは、塗りつぶされた行/列と最初の2つの行/列の間の潜在的なルールを比較するように設計されています。選択コントラストモジュールは、候補の選択肢間の相対的な違いを増やすように設計されています。 RAVENおよびPGMデータセットの実験結果は、DCNetが最先端の方法を5.77の大幅なマージンで上回っていることを示しています。,6.75,
Parameter-based Value Functions,"['Francesco Faccio', 'Louis Kirsch', 'Jürgen Schmidhuber']",https://openreview.net/forum?id=tV6oBfuyLTQ,"Traditional off-policy actor-critic Reinforcement Learning (RL) algorithms learn value functions of a single target policy. However, when value functions are updated to track the learned policy, they forget potentially useful information about old policies. We introduce a class of value functions called Parameter-based Value Functions (PVFs) whose inputs include the policy parameters. They can generalize across different policies. PVFs can evaluate the performance of any policy given a state, a state-action pair, or a distribution over the RL agent's initial states. First we show how PVFs yield novel off-policy policy gradient theorems. Then we derive off-policy actor-critic algorithms based on PVFs trained by Monte Carlo or Temporal Difference methods. We show how learned PVFs can zero-shot learn new policies that outperform any policy seen during training. Finally our algorithms are evaluated on a selection of discrete and continuous control tasks using shallow policies and deep neural networks. Their performance is comparable to state-of-the-art methods.",従来のポリシー外のアクター批評家の強化学習（RL）アルゴリズムは、単一のターゲットポリシーの価値関数を学習します。ただし、学習したポリシーを追跡するために値関数が更新されると、古いポリシーに関する潜在的に有用な情報を忘れてしまいます。入力にポリシーパラメータが含まれるパラメータベースの値関数（PVF）と呼ばれる値関数のクラスを紹介します。それらは、異なるポリシー間で一般化できます。 PVFは、状態、状態とアクションのペア、またはRLエージェントの初期状態にわたる分布を指定して、任意のポリシーのパフォーマンスを評価できます。最初に、PVFがどのように新しい政策外の政策勾配定理を生み出すかを示します。次に、モンテカルロ法または時間差法によってトレーニングされたPVFに基づいて、ポリシー外のアクター批評アルゴリズムを導出します。学習したPVFが、トレーニング中に見られるポリシーよりも優れた新しいポリシーをゼロショットで学習する方法を示します。最後に、浅いポリシーと深いニューラルネットワークを使用して、離散的で連続的な制御タスクの選択についてアルゴリズムを評価します。それらの性能は、最先端の方法に匹敵します。,6.75,https://d3i71xaburhd42.cloudfront.net/ad2acaf20b631e990bcc0f06a365473414299690/10-Figure1-1.png
Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models,"['Zirui Wang', 'Yulia Tsvetkov', 'Orhan Firat', 'Yuan Cao']",https://openreview.net/forum?id=F1vEjWK-lH_,"Massively multilingual models subsuming tens or even hundreds of languages pose great challenges to multi-task optimization. While it is a common practice to apply a language-agnostic procedure optimizing a joint multilingual task objective, how to properly characterize and take advantage of its underlying problem structure for improving optimization efficiency remains under-explored. In this paper, we attempt to peek into the black-box of multilingual optimization through the lens of loss function geometry. We find that gradient similarity measured along the optimization trajectory is an important signal, which correlates well with not only language proximity but also the overall model performance. Such observation helps us to identify a critical limitation of existing gradient-based multi-task learning methods, and thus we derive a simple and scalable optimization procedure, named Gradient Vaccine, which encourages more geometrically aligned parameter updates for close tasks. Empirically, our method obtains significant model performance gains on multilingual machine translation and XTREME benchmark tasks for multilingual language models. Our work reveals the importance of properly measuring and utilizing language proximity in multilingual optimization, and has broader implications for multi-task learning beyond multilingual modeling.",数十または数百の言語を含む大規模な多言語モデルは、マルチタスクの最適化に大きな課題をもたらします。共同多言語タスクの目的を最適化する言語に依存しない手順を適用することは一般的な方法ですが、最適化の効率を改善するためにその根本的な問題構造を適切に特徴付けて活用する方法は未踏のままです。この論文では、損失関数ジオメトリのレンズを通して多言語最適化のブラックボックスを覗き見しようとしています。最適化の軌跡に沿って測定された勾配の類似性は重要な信号であり、言語の近接性だけでなく、モデル全体のパフォーマンスともよく相関していることがわかります。このような観察は、既存の勾配ベースのマルチタスク学習方法の重大な制限を特定するのに役立ちます。したがって、勾配ワクチンという名前のシンプルでスケーラブルな最適化手順を導き出します。これにより、近接タスクのパラメーターの更新がより幾何学的に調整されます。経験的に、私たちの方法は、多言語の機械翻訳と多言語言語モデルのXTREMEベンチマークタスクでモデルのパフォーマンスを大幅に向上させます。私たちの仕事は、多言語の最適化における言語の近接性を適切に測定して利用することの重要性を明らかにし、多言語モデリングを超えたマルチタスク学習に幅広い影響を及ぼします。,6.75,
Boost then Convolve: Gradient Boosting Meets Graph Neural Networks,"['Sergei Ivanov', 'Liudmila Prokhorenkova']",https://openreview.net/forum?id=ebS5NUfoMKL,"Graph neural networks (GNNs) are powerful models that have been successful in various graph representation learning tasks. Whereas gradient boosted decision trees (GBDT) often outperform other machine learning methods when faced with heterogeneous tabular data. But what approach should be used for graphs with tabular node features? Previous GNN models have mostly focused on networks with homogeneous sparse features and, as we show, are suboptimal in the heterogeneous setting. In this work, we propose a novel architecture that trains GBDT and GNN jointly to get the best of both worlds: the GBDT model deals with heterogeneous features, while GNN accounts for the graph structure. Our model benefits from end-to-end optimization by allowing new trees to fit the gradient updates of GNN. With an extensive experimental comparison to the leading GBDT and GNN models, we demonstrate a significant increase in performance on a variety of graphs with tabular features. The code is available: https://github.com/nd7141/bgnn.",グラフニューラルネットワーク（GNN）は、さまざまなグラフ表現学習タスクで成功している強力なモデルです。一方、勾配ブースト決定木（GBDT）は、異種の表形式データに直面した場合、他の機械学習方法よりも優れていることがよくあります。しかし、表形式のノード機能を備えたグラフにはどのようなアプローチを使用する必要がありますか？以前のGNNモデルは、主に同種のスパース機能を備えたネットワークに焦点を合わせており、私たちが示すように、異種の設定では最適ではありません。この作業では、GBDTとGNNを共同でトレーニングして、両方の世界を最大限に活用する新しいアーキテクチャを提案します。GBDTモデルは異種の機能を処理し、GNNはグラフ構造を考慮します。私たちのモデルは、新しいツリーがGNNの勾配更新に適合することを可能にすることにより、エンドツーエンドの最適化の恩恵を受けています。主要なGBDTおよびGNNモデルとの広範な実験的比較により、表形式の機能を備えたさまざまなグラフでパフォーマンスが大幅に向上することを示しています。コードはhttps://github.com/nd7141/bgnnで入手できます。,6.75,https://d3i71xaburhd42.cloudfront.net/07d38f062da2f13e3ff532d630aacc3e8dcaccca/3-Figure1-1.png
Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control,"['Zhuang Liu', 'Xuanlin Li', 'Bingyi Kang', 'Trevor Darrell']",https://openreview.net/forum?id=yr1mzrH3IC,"Deep Reinforcement Learning (Deep RL) has been receiving increasingly more attention  thanks to its encouraging performance on a variety of control tasks. Yet, conventional regularization techniques in training neural networks (e.g., $L_2$ regularization, dropout) have been largely ignored in RL methods, possibly because agents are typically trained and evaluated in the same environment, and because the deep RL community focuses more on high-level algorithm designs. In this work, we present the first comprehensive study of regularization techniques with multiple policy optimization algorithms on continuous control tasks. Interestingly, we find conventional regularization techniques on the policy networks can often bring large improvement, especially on harder tasks. Our findings are shown to be robust against training hyperparameter variations. We also compare these techniques with the more widely used entropy regularization. In addition, we study regularizing different components and find that only regularizing the policy network is typically the best. We further analyze why regularization may help generalization in RL from four perspectives - sample complexity, reward distribution, weight norm, and noise robustness. We hope our study provides guidance for future practices in regularizing policy optimization algorithms. Our code is available at https://github.com/anonymouscode114/iclr2021_rlreg .",Deep Reinforcement Learning（Deep RL）は、さまざまな制御タスクでのパフォーマンスを促進するため、ますます注目を集めています。それでも、ニューラルネットワークのトレーニングにおける従来の正則化手法（$ L_2 $正則化、ドロップアウトなど）は、RLメソッドではほとんど無視されてきました。これは、エージェントが通常同じ環境でトレーニングおよび評価され、深いRLコミュニティが高レベルのアルゴリズム設計。この作業では、連続制御タスクで複数のポリシー最適化アルゴリズムを使用した正則化手法の最初の包括的な研究を紹介します。興味深いことに、ポリシーネットワークでの従来の正則化手法は、特に困難なタスクで大きな改善をもたらすことがよくあります。私たちの調査結果は、ハイパーパラメータの変動のトレーニングに対して堅牢であることが示されています。また、これらの手法を、より広く使用されているエントロピー正則化と比較します。さらに、さまざまなコンポーネントの正規化を調査したところ、通常はポリシーネットワークの正規化のみが最適であることがわかりました。さらに、正則化がRLの一般化に役立つ理由を、サンプルの複雑さ、報酬の分布、重みのノルム、ノイズの堅牢性の4つの観点から分析します。私たちの研究が、ポリシー最適化アルゴリズムを正規化する際の将来の実践のためのガイダンスを提供することを願っています。私たちのコードはhttps://github.com/anonymouscode114/iclr2021_rlregで入手できます。,6.75,
"Few-Shot Learning via Learning the Representation, Provably","['Simon Shaolei Du', 'Wei Hu', 'Sham M. Kakade', 'Jason D. Lee', 'Qi Lei']",https://openreview.net/forum?id=pW2Q2xLwIMD,"This paper studies few-shot learning via representation learning, where one uses $T$ source tasks with $n_1$ data per task to learn a representation in order to reduce the sample complexity of a target task for which there is only $n_2 (\ll n_1)$ data. Specifically, we focus on the setting where there exists a good common representation between source and target, and our goal is to understand how much a sample size reduction is possible. First, we study the setting where this common representation is low-dimensional and provide a risk bound of $\tilde{O}(\frac{dk}{n_1T} + \frac{k}{n_2})$ on the target task for the linear representation class; here $d$ is the ambient input dimension and $k (\ll d)$ is the dimension of the representation. This result bypasses the $\Omega(\frac{1}{T})$ barrier under the i.i.d. task assumption, and can capture the desired property that all $n_1T$ samples from source tasks can be \emph{pooled} together for representation learning. We further extend this result to handle a general representation function class and obtain a similar result. Next, we consider the setting where the common representation may be high-dimensional but is capacity-constrained (say in norm); here, we again demonstrate the advantage of representation learning in both high-dimensional linear regression and neural networks, and show that representation learning can fully utilize all $n_1T$ samples from source tasks.",この論文では、表現学習による数ショット学習を研究します。ここでは、n2（n1）データしかないターゲットタスクのサンプルの複雑さを軽減するために、タスクごとにn1データのTソースタスクを使用して表現を学習します。具体的には、ソースとターゲットの間に良好な共通表現が存在する設定に焦点を当て、サンプルサイズの削減がどれだけ可能かを理解することを目標としています。最初に、この一般的な表現が低次元であり、ターゲットタスクに$ \ tilde {O}（\ frac {dk} {n1T} + \ frac {k} {n2}）$のリスク限界を提供する設定を調査します。線形表現クラスの場合。ここで、dは周囲の入力次元であり、k（d）は表現の次元です。この結果は、iidタスクの仮定の下で$ \ Omega（\ frac {1} {T}）$バリアをバイパスし、表現学習のためにソースタスクからのすべてのn1Tサンプルを一緒にプールできるという目的のプロパティをキャプチャできます。この結果をさらに拡張して、一般的な表現関数クラスを処理し、同様の結果を取得します。次に、一般的な表現が高次元である可能性があるが、容量に制約がある設定を検討します（たとえば標準で）。ここでも、高次元線形回帰とニューラルネットワークの両方で表現学習の利点を示し、表現学習がソースタスクからのすべてのn1Tサンプルを完全に利用できることを示します。,6.75,
Dual-mode ASR: Unify and Improve Streaming ASR with Full-context Modeling,"['Jiahui Yu', 'Wei Han', 'Anmol Gulati', 'Chung-Cheng Chiu', 'Bo Li', 'Tara N Sainath', 'Yonghui Wu', 'Ruoming Pang']",https://openreview.net/forum?id=Pz_dcqfcKW8,"Streaming automatic speech recognition (ASR) aims to emit each hypothesized word as quickly and accurately as possible, while full-context ASR waits for the completion of a full speech utterance before emitting completed hypotheses. In this work, we propose a unified framework, Dual-mode ASR, to train a single end-to-end ASR model with shared weights for both streaming and full-context speech recognition. We show that the latency and accuracy of streaming ASR significantly benefit from weight sharing and joint training of full-context ASR, especially with inplace knowledge distillation during the training. The Dual-mode ASR framework can be applied to recent state-of-the-art convolution-based and transformer-based ASR networks. We present extensive experiments with two state-of-the-art ASR networks, ContextNet and Conformer, on two datasets, a widely used public dataset LibriSpeech and a large-scale dataset MultiDomain. Experiments and ablation studies demonstrate that Dual-mode ASR not only simplifies the workflow of training and deploying streaming and full-context ASR models, but also significantly improves both emission latency and recognition accuracy of streaming ASR. With Dual-mode ASR, we achieve new state-of-the-art streaming ASR results on both LibriSpeech and MultiDomain in terms of accuracy and latency.",ストリーミング自動音声認識（ASR）は、各仮説単語を可能な限り迅速かつ正確に発することを目的としていますが、フルコンテキストASRは、完全な音声発話の完了を待ってから、完成した仮説を発します。この作業では、ストリーミングとフルコンテキスト音声認識の両方の重みを共有する単一のエンドツーエンドASRモデルをトレーニングするために、統合フレームワークであるデュアルモードASRを提案します。ストリーミングASRの遅延と精度は、特にトレーニング中のインプレース知識蒸留を使用して、フルコンテキストASRの重み共有と共同トレーニングから大幅に恩恵を受けることを示します。デュアルモードASRフレームワークは、最近の最先端の畳み込みベースおよび変圧器ベースのASRネットワークに適用できます。広く使用されているパブリックデータセットLibriSpeechと大規模データセットMultiDomainの2つのデータセットについて、2つの最先端のASRネットワークであるContextNetとConformerを使用した広範な実験を紹介します。実験とアブレーション研究は、デュアルモードASRが、ストリーミングおよびフルコンテキストASRモデルのトレーニングと展開のワークフローを簡素化するだけでなく、ストリーミングASRの放出待ち時間と認識精度の両方を大幅に改善することを示しています。デュアルモードASRを使用すると、精度と遅延の点でLibriSpeechとMultiDomainの両方で新しい最先端のストリーミングASR結果を実現できます。,6.75,https://d3i71xaburhd42.cloudfront.net/de9c16610ed1181710debba81d89a39dbde1fb50/2-Figure1-1.png
Learning to live with Dale's principle: ANNs with separate excitatory and inhibitory units,"['Jonathan Cornford', 'Damjan Kalajdzievski', 'Marco Leite', 'Amélie Lamarquette', 'Dimitri Michael Kullmann', 'Blake Aaron Richards']",https://openreview.net/forum?id=eU776ZYxEpz," The units in artificial neural networks (ANNs) can be thought of as abstractions of biological neurons, and ANNs are increasingly used in neuroscience research. However, there are many important differences between ANN units and real neurons. One of the most notable is the absence of Dale's principle, which ensures that biological neurons are either exclusively excitatory or inhibitory. Dale's principle is typically left out of ANNs because its inclusion impairs learning. This is problematic, because one of the great advantages of ANNs for neuroscience research is their ability to learn complicated, realistic tasks. Here, by taking inspiration from feedforward inhibitory interneurons in the brain we show that we can develop ANNs with separate populations of excitatory and inhibitory units that learn just as well as standard ANNs. We call these networks Dale's ANNs (DANNs). We present two insights that enable DANNs to learn well: (1) DANNs are related to normalization schemes, and can be initialized such that the inhibition centres and standardizes the excitatory activity, (2) updates to inhibitory neuron parameters should be scaled using corrections based on the Fisher Information matrix. These results demonstrate how ANNs that respect Dale's principle can be built without sacrificing learning performance, which is important for future work using ANNs as models of the brain. The results may also have interesting implications for how inhibitory plasticity in the real brain operates.",人工ニューラルネットワーク（ANN）のユニットは、生物学的ニューロンの抽象化と考えることができ、ANNは神経科学研究でますます使用されています。ただし、ANNユニットと実際のニューロンの間には多くの重要な違いがあります。最も注目すべきものの1つは、生物学的ニューロンが排他的に興奮性または抑制性のいずれかであることを保証するDales原理の欠如です。 Dalesの原則は、その包含が学習を損なうため、通常ANNから除外されます。神経科学研究におけるANNの大きな利点の1つは、複雑で現実的なタスクを学習できることであるため、これには問題があります。ここでは、脳内のフィードフォワード抑制性介在ニューロンからインスピレーションを得ることにより、標準のANNと同様に学習する興奮性ユニットと抑制性ユニットの別々の集団でANNを開発できることを示します。これらのネットワークをDalesANN（DANN）と呼びます。 DANNが十分に学習できるようにする2つの洞察を提示します：（1）DANNは正規化スキームに関連しており、抑制が興奮性活動を中心にして標準化するように初期化できます。（2）抑制性ニューロンパラメーターの更新は、補正に基づいてスケーリングする必要があります。フィッシャー情報マトリックス。これらの結果は、脳のモデルとしてANNを使用する将来の作業にとって重要な、学習パフォーマンスを犠牲にすることなく、Dalesの原則を尊重するANNを構築する方法を示しています。結果はまた、実際の脳の抑制性可塑性がどのように機能するかについて興味深い意味を持つかもしれません。,6.75,
A Temporal Kernel Approach for Deep Learning with Continuous-time Information,"['Da Xu', 'Chuanwei Ruan', 'Evren Korpeoglu', 'Sushant Kumar', 'Kannan Achan']",https://openreview.net/forum?id=whE31dn74cL,"Sequential deep learning models such as RNN, causal CNN and attention mechanism do not readily consume continuous-time information. Discretizing the temporal data, as we show, causes inconsistency even for simple continuous-time processes. Current approaches often handle time in a heuristic manner to be consistent with the existing deep learning architectures and implementations. In this paper, we provide a principled way to characterize continuous-time systems using deep learning tools. Notably, the proposed approach applies to all the major deep learning architectures and requires little modifications to the implementation. The critical insight is to represent the continuous-time system by composing neural networks with a temporal kernel, where we gain our intuition from the recent advancements in understanding deep learning with Gaussian process and neural tangent kernel. To represent the temporal kernel, we introduce the random feature approach and convert the kernel learning problem to spectral density estimation under reparameterization. We further prove the convergence and consistency results even when the temporal kernel is non-stationary, and the spectral density is misspecified. The simulations and real-data experiments demonstrate the empirical effectiveness of our temporal kernel approach in a broad range of settings.",RNN、因果CNN、注意メカニズムなどの順次深層学習モデルは、連続時間情報を容易に消費しません。私たちが示すように、時間データを離散化すると、単純な連続時間プロセスでも不整合が発生します。現在のアプローチでは、既存の深層学習のアーキテクチャと実装と一貫性を保つために、ヒューリスティックな方法で時間を処理することがよくあります。このホワイトペーパーでは、深層学習ツールを使用して連続時間システムを特徴付ける原理的な方法を提供します。特に、提案されたアプローチはすべての主要な深層学習アーキテクチャに適用され、実装にほとんど変更を加える必要はありません。重要な洞察は、時間カーネルでニューラルネットワークを構成することによって連続時間システムを表すことです。ここで、ガウス過程とニューラルタンジェントカーネルを使用した深層学習の理解における最近の進歩から直感を得ることができます。時間カーネルを表すために、ランダム特徴アプローチを導入し、カーネル学習問題を再パラメーター化の下でスペクトル密度推定に変換します。さらに、時間カーネルが非定常であり、スペクトル密度が誤って指定されている場合でも、収束と一貫性の結果を証明します。シミュレーションと実データ実験は、幅広い設定での時間的カーネルアプローチの経験的有効性を示しています。,6.75,
Wandering within a world: Online contextualized few-shot learning,"['Mengye Ren', 'Michael Louis Iuzzolino', 'Michael Curtis Mozer', 'Richard Zemel']",https://openreview.net/forum?id=oZIvHV04XgC,"We aim to bridge the gap between typical human and machine-learning environments by extending the standard framework of few-shot learning to an online, continual setting. In this setting, episodes do not have separate training and testing phases, and instead models are evaluated online while learning novel classes. As in real world, where the presence of spatiotemporal context helps us retrieve learned skills in the past, our online few-shot learning setting also features an underlying context that changes throughout time. Object classes are correlated within a context and inferring the correct context can lead to better performance. Building upon this setting, we propose a new few-shot learning dataset based on large scale indoor imagery that mimics the visual experience of an agent wandering within a world. Furthermore, we convert popular few-shot learning approaches into online versions and we also propose a new model named contextual prototypical memory that can make use of spatiotemporal contextual information from the recent past.",私たちは、数ショット学習の標準フレームワークをオンラインの継続的な設定に拡張することにより、典型的な人間と機械学習環境の間のギャップを埋めることを目指しています。この設定では、エピソードに個別のトレーニングフェーズとテストフェーズはなく、代わりにモデルは新しいクラスを学習しながらオンラインで評価されます。時空間コンテキストの存在が過去に学習したスキルを取得するのに役立つ現実の世界と同様に、オンラインの数ショットの学習設定には、時間の経過とともに変化する基本的なコンテキストも含まれています。オブジェクトクラスはコンテキスト内で相互に関連付けられており、正しいコンテキストを推測すると、パフォーマンスが向上する可能性があります。この設定に基づいて、世界をさまようエージェントの視覚体験を模倣する大規模な屋内画像に基づく新しい数ショットの学習データセットを提案します。さらに、人気のある数ショットの学習アプローチをオンラインバージョンに変換し、最近の時空間コンテキスト情報を利用できるコンテキストプロトタイプメモリという名前の新しいモデルも提案します。,6.75,https://d3i71xaburhd42.cloudfront.net/f66beb1d738e61afbea000e112258a6277a36ba4/2-Figure1-1.png
Domain-Robust Visual Imitation Learning with Mutual Information Constraints,"['Edoardo Cetin', 'Oya Celiktutan']",https://openreview.net/forum?id=QubpWYfdNry,"Human beings are able to understand objectives and learn by simply observing others perform a task. Imitation learning methods aim to replicate such capabilities, however, they generally depend on access to a full set of optimal states and actions taken with the agent's actuators and from the agent's point of view. In this paper, we introduce a new algorithm - called Disentangling Generative Adversarial Imitation Learning (DisentanGAIL) - with the purpose of bypassing such constraints. Our algorithm enables autonomous agents to learn directly from high dimensional observations of an expert performing a task, by making use of adversarial learning with a latent representation inside the discriminator network. Such latent representation is regularized through mutual information constraints to incentivize learning only features that encode information about the completion levels of the task being demonstrated. This allows to obtain a shared feature space to successfully perform imitation while disregarding the differences between the expert's and the agent's domains. Empirically, our algorithm is able to efficiently imitate in a diverse range of control problems including balancing, manipulation and locomotive tasks, while being robust to various domain differences in terms of both environment appearance and agent embodiment.",人間は、他の人がタスクを実行するのを観察するだけで、目的を理解し、学ぶことができます。模倣学習方法は、そのような機能を複製することを目的としていますが、一般に、エージェントアクチュエータを使用して、エージェントの観点から、最適な状態とアクションの完全なセットへのアクセスに依存します。この論文では、このような制約を回避することを目的として、新しいアルゴリズム（敵対的生成的模倣学習のもつれを解く（DisentanGAIL））を紹介します。私たちのアルゴリズムは、自律エージェントが、弁別器ネットワーク内の潜在的な表現による敵対的学習を利用することにより、タスクを実行する専門家の高次元の観察から直接学習することを可能にします。このような潜在的表現は、相互情報量の制約を通じて正規化され、実証されているタスクの完了レベルに関する情報をエンコードする機能のみを学習するように促します。これにより、エキスパートとエージェントドメインの違いを無視して、模倣を正常に実行するための共有機能スペースを取得できます。経験的に、私たちのアルゴリズムは、環境の外観とエージェントの実施形態の両方の点でさまざまなドメインの違いに対して堅牢でありながら、バランス調整、操作、および機関車のタスクを含むさまざまな制御問題を効率的に模倣できます。,6.75,
Empirical or Invariant Risk Minimization? A Sample Complexity Perspective,"['Kartik Ahuja', 'Jun Wang', 'Amit Dhurandhar', 'Karthikeyan Shanmugam', 'Kush R. Varshney']",https://openreview.net/forum?id=jrA5GAccy_,"Recently, invariant risk minimization (IRM) was proposed as a promising solution to address out-of-distribution (OOD) generalization. However, it is unclear when IRM should be preferred over the widely-employed empirical risk minimization (ERM) framework. In this work, we analyze both these frameworks from the perspective of sample complexity, thus taking a firm step towards answering this important question. We find that depending on the type of data generation mechanism, the two approaches might have very different finite sample and asymptotic behavior. For example, in the covariate shift setting we see that the two approaches not only arrive at the same asymptotic solution, but also have similar finite sample behavior with no clear winner. For other distribution shifts such as those involving confounders or anti-causal variables, however, the two approaches arrive at different asymptotic solutions where IRM is guaranteed to be close to the desired OOD solutions in the finite sample regime, while ERM is biased even asymptotically.  We further investigate how different factors --- the number of environments, complexity of the model, and IRM penalty weight ---  impact the sample complexity of IRM in relation to its distance from the OOD solutions. ",最近、不変リスク最小化（IRM）が、分布外（OOD）の一般化に対処するための有望なソリューションとして提案されました。ただし、広く採用されている経験的リスク最小化（ERM）フレームワークよりもIRMを優先する時期は不明です。この作業では、サンプルの複雑さの観点からこれら両方のフレームワークを分析し、この重要な質問に答えるための確固たる一歩を踏み出しました。データ生成メカニズムのタイプに応じて、2つのアプローチの有限サンプルと漸近的動作が大きく異なる可能性があることがわかりました。たとえば、共変量シフトの設定では、2つのアプローチが同じ漸近解に到達するだけでなく、明確な勝者がない同様の有限サンプル動作を持っていることがわかります。ただし、交絡因子や非因果変数を含むような他の分布シフトの場合、2つのアプローチは異なる漸近解に到達し、IRMは有限サンプルレジームで目的のOOD解に近いことが保証され、ERMは漸近的にもバイアスされます。さらに、環境の数、モデルの複雑さ、およびIRMペナルティの重みが、OODソリューションからの距離に関連してIRMのサンプルの複雑さにどのように影響するかを調査します。,6.75,https://d3i71xaburhd42.cloudfront.net/87193652fc0a0594076bc638d41a7ee0f07ff9fd/10-Figure1-1.png
Active Contrastive Learning of Audio-Visual Video Representations,"['Shuang Ma', 'Zhaoyang Zeng', 'Daniel McDuff', 'Yale Song']",https://openreview.net/forum?id=OMizHuea_HB,"Contrastive learning has been shown to produce generalizable representations of audio and visual data by maximizing the lower bound on the mutual information (MI) between different views of an instance. However, obtaining a tight lower bound requires a sample size exponential in MI and thus a large set of negative samples. We can incorporate more samples by building a large queue-based dictionary, but there are theoretical limits to performance improvements even with a large number of negative samples. We hypothesize that random negative sampling leads to a highly redundant dictionary that results in suboptimal representations for downstream tasks. In this paper, we propose an active contrastive learning approach that builds an actively sampled dictionary with diverse and informative items, which improves the quality of negative samples and improves performances on tasks where there is high mutual information in the data, e.g., video classification. Our model achieves state-of-the-art performance on challenging audio and visual downstream benchmarks including UCF101, HMDB51 and ESC50. ",対照学習は、インスタンスの異なるビュー間の相互情報量（MI）の下限を最大化することにより、オーディオおよびビジュアルデータの一般化可能な表現を生成することが示されています。ただし、厳密な下限を取得するには、MIで指数関数的なサンプルサイズが必要であるため、多数の負のサンプルが必要です。大規模なキューベースの辞書を作成することで、より多くのサンプルを組み込むことができますが、負のサンプルが多数ある場合でも、パフォーマンスの向上には理論上の制限があります。ランダムなネガティブサンプリングは非常に冗長な辞書につながり、その結果、ダウンストリームタスクの表現が最適ではなくなると仮定します。この論文では、多様で有益な項目でアクティブにサンプリングされた辞書を構築するアクティブな対照学習アプローチを提案します。これにより、ネガティブサンプルの品質が向上し、ビデオ分類などのデータに相互情報量が多いタスクのパフォーマンスが向上します。私たちのモデルは、UCF101、HMDB51、ESC50などの挑戦的なオーディオおよびビジュアルダウンストリームベンチマークで最先端のパフォーマンスを実現します。,6.75,
Learning Robust State Abstractions for Hidden-Parameter Block MDPs,"['Amy Zhang', 'Shagun Sodhani', 'Khimya Khetarpal', 'Joelle Pineau']",https://openreview.net/forum?id=fmOOI2a3tQP,"Many control tasks exhibit similar dynamics that can be modeled as having common latent structure. Hidden-Parameter Markov Decision Processes (HiP-MDPs) explicitly model this structure to improve sample efficiency in multi-task settings.
However, this setting makes strong assumptions on the observability of the state that limit its application in real-world scenarios with rich observation spaces.  In this work, we leverage ideas of common structure from the HiP-MDP setting, and extend it to enable robust state abstractions inspired by Block MDPs. We  derive instantiations of this new framework for  both multi-task reinforcement learning (MTRL) and  meta-reinforcement learning (Meta-RL) settings. Further, we provide transfer and generalization bounds based on task and state similarity, along with sample complexity bounds that depend on the aggregate number of samples across tasks, rather than the number of tasks, a significant improvement over prior work. To further demonstrate efficacy of the proposed method, we empirically compare and show improvement over multi-task and meta-reinforcement learning baselines.",多くの制御タスクは、共通の潜在構造を持つものとしてモデル化できる同様のダイナミクスを示します。隠れパラメータマルコフ決定過程（HiP-MDP）は、この構造を明示的にモデル化して、マルチタスク設定でのサンプル効率を向上させます。ただし、この設定では、状態の可観測性を強く想定しているため、観測スペースが豊富な実際のシナリオでの適用が制限されます。この作業では、HiP-MDP設定からの共通構造のアイデアを活用し、それを拡張して、ブロックMDPに触発された堅牢な状態の抽象化を可能にします。マルチタスク強化学習（MTRL）とメタ強化学習（Meta-RL）の両方の設定について、この新しいフレームワークのインスタンス化を導き出します。さらに、タスクと状態の類似性に基づく転送と一般化の境界、およびタスクの数ではなくタスク全体のサンプルの総数に依存するサンプルの複雑さの境界を提供し、以前の作業よりも大幅に改善します。提案された方法の有効性をさらに実証するために、我々は経験的に比較し、マルチタスクおよびメタ強化学習ベースラインに対する改善を示します。,6.75,
Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability,"['Jeremy Cohen', 'Simran Kaur', 'Yuanzhi Li', 'J Zico Kolter', 'Ameet Talwalkar']",https://openreview.net/forum?id=jh-rTtvkGeM,"We empirically demonstrate that full-batch gradient descent on neural network training objectives typically operates in a regime we call the Edge of Stability. In this regime, the leading eigenvalue of the training loss Hessian hovers just above the value $2 / \text{(step size)}$, and the training loss behaves non-monotonically over short timescales, yet consistently decreases over long timescales. Since this behavior is inconsistent with several widespread presumptions in the field of optimization, our findings raise questions as to whether these presumptions are relevant to neural network training. We hope that our findings will inspire future efforts aimed at rigorously understanding optimization at the Edge of Stability.",ニューラルネットワークのトレーニング目標でのフルバッチ勾配降下法は、通常、エッジオブスタビリティと呼ばれる体制で動作することを経験的に示しています。このレジームでは、トレーニング損失ヘッセ行列の主要な固有値は値2 /（ステップサイズ）のすぐ上にあり、トレーニング損失は短いタイムスケールでは非単調に動作しますが、長いタイムスケールでは一貫して減少します。この動作は、最適化の分野で広く普及しているいくつかの推定と矛盾しているため、これらの推定がニューラルネットワークのトレーニングに関連しているかどうかについて疑問が生じます。私たちの発見が、Edge ofStabilityでの最適化を厳密に理解することを目的とした将来の取り組みに刺激を与えることを願っています。,6.75,
Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking,"['Michael Sejr Schlichtkrull', 'Nicola De Cao', 'Ivan Titov']",https://openreview.net/forum?id=WznmQa42ZAx,"Graph neural networks (GNNs) have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs (e.g. syntactic trees or co-reference structures) contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected $L_0$ norm. We use our technique as an attribution method to analyze GNN models for two tasks -- question answering and semantic role labeling -- providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions.",グラフニューラルネットワーク（GNN）は、構造的誘導バイアスをNLPモデルに統合するための一般的なアプローチになっています。ただし、それらを解釈すること、特にグラフのどの部分（構文木や共参照構造など）が予測に寄与するかを理解することについては、ほとんど作業が行われていません。この作業では、不要なエッジを識別するGNNの予測を解釈するための事後的な方法を紹介します。トレーニングされたGNNモデルが与えられると、すべてのレイヤーのすべてのエッジについて、そのエッジをドロップできるかどうかを予測する単純な分類器を学習します。このような分類器は、確率的ゲートを使用し、予想されるL0ノルムを通じてスパース性を促進することにより、完全に微分可能な方法でトレーニングできることを示します。質問応答とセマンティックロールラベリングの2つのタスクのGNNモデルを分析するための帰属方法としてこの手法を使用し、これらのモデルの情報フローへの洞察を提供します。モデルのパフォーマンスを低下させることなくエッジの大部分をドロップできる一方で、モデルの予測を解釈するために残りのエッジを分析できることを示します。,6.75,
On the Critical Role of Conventions in Adaptive Human-AI Collaboration,"['Andy Shih', 'Arjun Sawhney', 'Jovana Kondic', 'Stefano Ermon', 'Dorsa Sadigh']",https://openreview.net/forum?id=8Ln-Bq0mZcy,"Humans can quickly adapt to new partners in collaborative tasks (e.g. playing basketball), because they understand which fundamental skills of the task (e.g. how to dribble, how to shoot) carry over across new partners. Humans can also quickly adapt to similar tasks with the same partners by carrying over conventions that they have developed (e.g. raising hand signals pass the ball), without learning to coordinate from scratch. To collaborate seamlessly with humans, AI agents should adapt quickly to new partners and new tasks as well. However, current approaches have not attempted to distinguish between the complexities intrinsic to a task and the conventions used by a partner, and more generally there has been little focus on leveraging conventions for adapting to new settings. In this work, we propose a learning framework that teases apart rule-dependent representation from convention-dependent representation in a principled way. We show that, under some assumptions, our rule-dependent representation is a sufficient statistic of the distribution over best-response strategies across partners. Using this separation of representations, our agents are able to adapt quickly to new partners, and to coordinate with old partners on new tasks in a zero-shot manner. We experimentally validate our approach on three collaborative tasks varying in complexity: a contextual multi-armed bandit, a block placing task, and the card game Hanabi.",人間は、タスクの基本的なスキル（ドリブルの方法、射撃の方法など）が新しいパートナーに引き継がれることを理解しているため、コラボレーションタスク（バスケットボールのプレーなど）で新しいパートナーにすばやく適応できます。人間はまた、ゼロから調整することを学ぶことなく、彼らが開発した慣習を引き継ぐことによって（例えば、手の信号を上げることはボールを通過させる）、同じパートナーとの同様のタスクに素早く適応することができます。人間とシームレスにコラボレーションするには、AIエージェントは新しいパートナーや新しいタスクにも迅速に適応する必要があります。ただし、現在のアプローチでは、タスクに固有の複雑さとパートナーが使用する規則を区別しようとはしておらず、より一般的には、新しい設定に適応するために規則を活用することにほとんど焦点が当てられていません。この作業では、原則的な方法でルール依存の表現を慣習依存の表現から切り離す学習フレームワークを提案します。いくつかの仮定の下で、ルールに依存する表現は、パートナー間のベストレスポンス戦略全体の分布の十分統計量であることを示します。この表現の分離を使用して、エージェントは新しいパートナーに迅速に適応し、ゼロショットの方法で新しいタスクについて古いパートナーと調整することができます。複雑さが異なる3つの共同タスク（コンテキストマルチアームバンディット、ブロック配置タスク、カードゲーム花火）に対するアプローチを実験的に検証します。,6.75,
Separation and Concentration in Deep Networks,"['John Zarka', 'Florentin Guth', 'Stéphane Mallat']",https://openreview.net/forum?id=8HhkbjrWLdE,"Numerical experiments demonstrate that deep neural network classifiers progressively separate class distributions around their mean, achieving linear separability on the training set, and increasing the Fisher discriminant ratio. We explain this mechanism with two types of operators. We prove that a rectifier without biases applied to sign-invariant tight frames can separate class means and increase Fisher ratios. On the opposite, a soft-thresholding on tight frames can reduce within-class variabilities while preserving class means. Variance reduction bounds are proved for Gaussian mixture models. For image classification, we show that separation of class means can be achieved with rectified wavelet tight frames that are not learned. It defines a scattering transform. Learning  $1 \times 1$ convolutional tight frames along scattering channels and applying a soft-thresholding reduces within-class variabilities. The resulting scattering network reaches the classification accuracy of ResNet-18 on CIFAR-10 and ImageNet, with fewer layers and no learned biases.",数値実験は、深層ニューラルネットワーク分類器が平均の周りのクラス分布を徐々に分離し、トレーニングセットで線形分離可能性を達成し、フィッシャー判別比を増加させることを示しています。このメカニズムを2種類の演算子で説明します。符号不変のタイトフレームにバイアスを適用しない整流器は、クラス平均を分離し、フィッシャー比を増加させることができることを証明します。反対に、タイトなフレームのソフトしきい値は、クラス平均を維持しながら、クラス内の変動を減らすことができます。分散減少限界は、ガウス混合モデルで証明されています。画像分類については、クラス平均の分離は、学習されていない修正されたウェーブレットタイトフレームで達成できることを示します。散乱変換を定義します。散乱チャネルに沿って11畳み込みタイトフレームを学習し、ソフトしきい値を適用すると、クラス内の変動が減少します。結果として得られる散乱ネットワークは、CIFAR-10およびImageNet上のResNet-18の分類精度に達し、レイヤーが少なく、学習されたバイアスがありません。,6.75,
Training independent subnetworks for robust prediction,"['Marton Havasi', 'Rodolphe Jenatton', 'Stanislav Fort', 'Jeremiah Zhe Liu', 'Jasper Snoek', 'Balaji Lakshminarayanan', 'Andrew Mingbo Dai', 'Dustin Tran']",https://openreview.net/forum?id=OGg9XnKxFAH,"Recent approaches to efficiently ensemble neural networks have shown that strong robustness and uncertainty performance  can be achieved with a negligible gain in parameters over the original network. However, these methods still require multiple forward passes for prediction, leading to a significant runtime cost. In this work, we show a surprising result:
the benefits of using multiple predictions can be achieved 'for free' under a single model's forward pass. In particular, we show that, using a multi-input multi-output (MIMO) configuration, one can utilize a single model's capacity to train multiple subnetworks that independently learn the task at hand. By ensembling the predictions made by the subnetworks, we improve model robustness without increasing compute. We observe a significant improvement in negative log-likelihood, accuracy, and calibration error on CIFAR10, CIFAR100,  ImageNet, and their out-of-distribution variants compared to previous methods.",ニューラルネットワークを効率的にアンサンブルするための最近のアプローチは、元のネットワークよりもパラメータの増加が無視できる程度で、強力な堅牢性と不確実性のパフォーマンスを達成できることを示しています。ただし、これらの方法では、予測のために複数のフォワードパスが必要であり、実行時にかなりのコストがかかります。この作業では、驚くべき結果を示します。複数の予測を使用する利点は、単一のモデルのフォワードパスで無料で達成できます。特に、多入力多出力（MIMO）構成を使用すると、単一のモデル容量を利用して、目前のタスクを独立して学習する複数のサブネットワークをトレーニングできることを示します。サブネットワークによって行われた予測をアンサンブルすることにより、計算を増やすことなくモデルの堅牢性を向上させます。以前の方法と比較して、CIFAR10、CIFAR100、ImageNet、およびそれらの分布外のバリアントで、負の対数尤度、精度、およびキャリブレーションエラーの大幅な改善が見られます。,6.75,https://d3i71xaburhd42.cloudfront.net/bfecbbf9733f535345b659c5a8cb40c16a5f1441/2-Figure1-1.png
On Graph Neural Networks versus Graph-Augmented MLPs,"['Zhengdao Chen', 'Lei Chen', 'Joan Bruna']",https://openreview.net/forum?id=tiqI7w64JG2,"From the angles of expressive power and learning, this work compares multi-layer Graph Neural Networks (GNNs) with a simplified alternative that we call Graph-Augmented Multi-Layer Perceptrons (GA-MLPs), which first augments node features with certain multi-hop operators on the graph and then applies an MLP in a node-wise fashion. From the perspective of graph isomorphism testing, we show both theoretically and numerically that GA-MLP with suitable operators can distinguish almost all non-isomorphic graphs, just like the Weifeiler-Lehman (WL) test. However, by viewing them as node-level functions and examining the equivalence classes that they induce on rooted graphs, we prove a separation in expressive power between GA-MLPs and GNNs that grows exponentially in depth. In particular, unlike GNNs, GA-MLPs are unable to count the number of attributed walks. We also demonstrate via community detection experiments that GA-MLPs can be limited by their choice of operator family, as compared to GNNs with higher flexibility in learning.",表現力と学習の観点から、この作業では、多層グラフニューラルネットワーク（GNN）を、グラフ拡張多層パーセプトロン（GA-MLP）と呼ばれる単純化された代替手段と比較します。これは、最初に特定のマルチでノード機能を拡張します。グラフ上で演算子をホップしてから、ノードごとにMLPを適用します。グラフ同型テストの観点から、適切な演算子を使用したGA-MLPは、Weifeiler-Lehman（WL）テストと同様に、ほぼすべての非同型グラフを区別できることを理論的および数値的に示します。ただし、それらをノードレベルの関数と見なし、それらがルートグラフで誘導する同値類を調べることにより、GA-MLPとGNNの間の表現力の分離が指数関数的に深くなることを証明します。特に、GNNとは異なり、GA-MLPは属性付きウォークの数をカウントできません。また、コミュニティ検出実験を通じて、GA-MLPは、学習の柔軟性が高いGNNと比較して、オペレーターファミリの選択によって制限される可能性があることを示しています。,6.75,
LEARNABLE EMBEDDING SIZES  FOR RECOMMENDER SYSTEMS,"['Siyi Liu', 'Chen Gao', 'Yihong Chen', 'Depeng Jin', 'Yong Li']",https://openreview.net/forum?id=vQzcqQWIS0q,"The embedding-based representation learning is commonly used in deep learning recommendation models to map the raw sparse features to dense vectors. The traditional embedding manner that assigns a uniform size to all features has two issues. First, the numerous features inevitably lead to a gigantic embedding table that causes a high memory usage cost. Second, it is likely to cause the over-fitting problem for those features that do not require too large representation capacity. Existing works that try to address the problem always cause a significant drop in recommendation performance or suffers from the limitation of unaffordable training time cost. In this paper, we proposed a novel approach, named PEP (short for Plug-in Embedding Pruning), to reduce the size of the embedding table while obviating a drop in accuracy and computational optimization. PEP prunes embedding parameter where the pruning threshold(s) can be adaptively learned from data. Therefore we can automatically obtain a mixed-dimension embedding-scheme by pruning redundant parameters for each feature. PEP is a general framework that can plug in various base recommendation models. Extensive experiments demonstrate it can efficiently cut down embedding parameters and boost the base model's performance. Specifically, it achieves strong recommendation performance while reducing 97-99% parameters. As for the computation cost, PEP only brings an additional 20-30% time cost compare with base models. ",埋め込みベースの表現学習は、深層学習の推奨モデルで一般的に使用され、生のスパース特徴を密なベクトルにマッピングします。すべての機能に均一なサイズを割り当てる従来の埋め込み方法には、2つの問題があります。まず、多数の機能が必然的に巨大な埋め込みテーブルにつながり、メモリ使用コストが高くなります。第2に、あまり大きな表現容量を必要としない機能では、過剰適合の問題が発生する可能性があります。この問題に対処しようとする既存の作業は、常に推奨パフォーマンスの大幅な低下を引き起こすか、手ごろな価格のトレーニング時間コストの制限に悩まされます。この論文では、精度の低下と計算の最適化を回避しながら、埋め込みテーブルのサイズを縮小するために、PEP（Plug-in Embedding Pruningの略）という名前の新しいアプローチを提案しました。 PEPは、データからプルーニングしきい値を適応的に学習できる埋め込みパラメーターをプルーニングします。したがって、各機能の冗長パラメーターを削除することにより、混合次元の埋め込みスキームを自動的に取得できます。 PEPは、さまざまな基本推奨モデルをプラグインできる一般的なフレームワークです。広範な実験により、埋め込みパラメーターを効率的に削減し、基本モデルのパフォーマンスを向上させることができることが実証されています。具体的には、97〜99を削減しながら、強力な推奨パフォーマンスを実現します。,6.75,https://d3i71xaburhd42.cloudfront.net/7a7e23b1973c6555958a3e4bcf1bcc96b9065c31/4-Figure1-1.png
GraphCodeBERT: Pre-training Code Representations with Data Flow,"['Daya Guo', 'Shuo Ren', 'Shuai Lu', 'Zhangyin Feng', 'Duyu Tang', 'Shujie LIU', 'Long Zhou', 'Nan Duan', 'Alexey Svyatkovskiy', 'Shengyu Fu', 'Michele Tufano', 'Shao Kun Deng', 'Colin Clement', 'Dawn Drain', 'Neel Sundaresan', 'Jian Yin', 'Daxin Jiang', 'Ming Zhou']",https://openreview.net/forum?id=jLoC4ez43PZ,"Pre-trained models for programming language have achieved dramatic empirical improvements on a variety of code-related tasks such as code search, code completion, code summarization, etc. However, existing pre-trained models regard a code snippet as a sequence of tokens, while ignoring the inherent structure of code, which provides crucial code semantics and would enhance the code understanding process. We present GraphCodeBERT, a pre-trained model for programming language that considers the inherent structure of code. Instead of taking syntactic-level structure of code like abstract syntax tree (AST), we use data flow in the pre-training stage, which is a semantic-level structure of code that encodes the relation of ""where-the-value-comes-from"" between variables. Such a semantic-level structure is neat and does not bring an unnecessarily deep hierarchy of AST, the property of which makes the model more efficient. We develop GraphCodeBERT based on Transformer. In addition to using the task of masked language modeling, we introduce two structure-aware pre-training tasks. One is to predict code structure edges, and the other is to align representations between source code and code structure. We implement the model in an efficient way with a graph-guided masked attention function to incorporate the code structure. We evaluate our model on four tasks, including code search, clone detection, code translation, and code refinement. Results show that code structure and newly introduced pre-training tasks can improve GraphCodeBERT and achieves state-of-the-art performance on the four downstream tasks. We further show that the model prefers structure-level attentions over token-level attentions in the task of code search.",プログラミング言語の事前トレーニング済みモデルは、コード検索、コード補完、コード要約などのさまざまなコード関連タスクで劇的な経験的改善を達成しました。ただし、既存の事前トレーニング済みモデルは、コードスニペットをトークンのシーケンスと見なします。重要なコードセマンティクスを提供し、コード理解プロセスを強化するコードの固有の構造を無視します。コードの固有の構造を考慮したプログラミング言語の事前トレーニング済みモデルであるGraphCodeBERTを紹介します。抽象構文木（AST）のようなコードの構文レベルの構造を採用する代わりに、トレーニング前の段階でデータフローを使用します。これは、「値が来る場所」の関係をエンコードするコードのセマンティックレベルの構造です。 -変数間の &quot;から。このようなセマンティックレベルの構造はきちんとしていて、ASTの不必要に深い階層をもたらさず、その特性によってモデルがより効率的になります。 TransformerをベースにしたGraphCodeBERTを開発しています。マスクされた言語モデリングのタスクを使用することに加えて、2つの構造を意識した事前トレーニングタスクを紹介します。 1つはコード構造のエッジを予測することであり、もう1つはソースコードとコード構造の間で表現を整列させることです。コード構造を組み込むためのグラフガイドマスクアテンション関数を使用して、効率的な方法でモデルを実装します。コード検索、クローン検出、コード変換、コード改良を含む4つのタスクでモデルを評価します。結果は、コード構造と新しく導入された事前トレーニングタスクがGraphCodeBERTを改善し、4つのダウンストリームタスクで最先端のパフォーマンスを達成できることを示しています。さらに、コード検索のタスクでは、モデルがトークンレベルの注意よりも構造レベルの注意を優先することを示します。,6.75,https://d3i71xaburhd42.cloudfront.net/021d5c2358b7270a9c7779d6905e0051c89b3a40/3-Figure1-1.png
Intraclass clustering: an implicit learning ability that regularizes DNNs,"['Simon Carbonnelle', 'Christophe De Vleeschouwer']",https://openreview.net/forum?id=tqOvYpjPax2,"Several works have shown that the regularization mechanisms underlying deep neural networks' generalization performances are still poorly understood. In this paper, we hypothesize that deep neural networks are regularized through their ability to extract meaningful clusters among the samples of a class. Since no explicit training mechanisms or supervision target such behaviour, this learning ability constitutes an implicit form of regularization. To support our hypothesis, we design four different measures of intraclass clustering, based on the neuron- and layer-level representations of the training data. We then show that these measures constitute accurate predictors of generalization performance across variations of a large set of hyperparameters (learning rate, batch size, optimizer, weight decay, dropout rate, data augmentation, network depth and width).",いくつかの研究は、ディープニューラルネットワークの一般化パフォーマンスの根底にある正則化メカニズムがまだ十分に理解されていないことを示しています。この論文では、深層ニューラルネットワークがクラ​​スのサンプル間で意味のあるクラスターを抽出する能力によって正則化されていると仮定します。明示的なトレーニングメカニズムや監督はそのような行動を対象としないため、この学習能力は暗黙的な形式の正則化を構成します。仮説をサポートするために、トレーニングデータのニューロンレベルおよびレイヤーレベルの表現に基づいて、クラス内クラスタリングの4つの異なる測定値を設計します。次に、これらの測定値が、ハイパーパラメータの大規模なセット（学習率、バッチサイズ、オプティマイザ、重みの減衰、ドロップアウト率、データの拡張、ネットワークの深さと幅）のバリエーション全体にわたる一般化パフォーマンスの正確な予測子を構成することを示します。,6.75,
Structured Prediction as Translation between Augmented Natural Languages,"['Giovanni Paolini', 'Ben Athiwaratkun', 'Jason Krone', 'Jie Ma', 'Alessandro Achille', 'RISHITA ANUBHAI', 'Cicero Nogueira dos Santos', 'Bing Xiang', 'Stefano Soatto']",https://openreview.net/forum?id=US-TP-xnXI,"We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. Our approach can match or outperform task-specific models on all tasks, and in particular achieves new state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while using the same architecture and hyperparameters for all tasks, and even when training a single model to solve all tasks at the same time (multi-task learning). Finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics.",ジョイントエンティティとリレーションの抽出、ネストされた名前付きエンティティの認識、リレーションの分類、セマンティックロールのラベル付け、イベントの抽出、共参照の解決、ダイアログの状態など、多くの構造化された予測言語タスクを解決するための新しいフレームワーク、拡張自然言語間の翻訳（TANL）を提案します追跡。タスク固有の識別分類器をトレーニングすることによって問題に取り組む代わりに、タスク関連情報を簡単に抽出できる拡張自然言語間の翻訳タスクとしてフレーム化します。私たちのアプローチは、すべてのタスクでタスク固有のモデルと一致またはそれを上回ることができ、特に、ジョイントエンティティと関係の抽出（CoNLL04、ADE、NYT、およびACE2005データセット）、関係の分類（FewRelおよびTACRED）、およびセマンティックロールラベリング（CoNLL-2005およびCoNLL-2012）。これは、すべてのタスクに同じアーキテクチャとハイパーパラメータを使用し、単一のモデルをトレーニングしてすべてのタスクを同時に解決する場合でも実現します（マルチタスク学習）。最後に、ラベルセマンティクスをより適切に使用することで、フレームワークが低リソース体制でのパフォーマンスを大幅に向上させることもできることを示します。,6.75,https://d3i71xaburhd42.cloudfront.net/a78668e47f666c79a0415ff3264598e6a05ce6ac/2-Figure1-1.png
Perceptual Adversarial Robustness: Generalizable Defenses Against Unforeseen Threat Models,"['Cassidy Laidlaw', 'Sahil Singla', 'Soheil Feizi']",https://openreview.net/forum?id=dFwBosAcJkN,"A key challenge in adversarial robustness is the lack of a precise mathematical characterization of human perception, used in the definition of adversarial attacks that are imperceptible to human eyes. Most current attacks and defenses try to get around this issue by considering restrictive adversarial threat models such as those bounded by $L_2$ or $L_\infty$ distance, spatial perturbations, etc. However, models that are robust against any of these restrictive threat models are still fragile against other threat models, i.e. they have poor generalization to unforeseen attacks. Moreover, even if a model is robust against the union of several restrictive threat models, it is still susceptible to other imperceptible adversarial examples that are not contained in any of the constituent threat models. To resolve these issues, we propose adversarial training against the set of all imperceptible adversarial examples. Since this set is intractable to compute without a human in the loop, we approximate it using deep neural networks. We call this threat model the neural perceptual threat model (NPTM); it includes adversarial examples with a bounded neural perceptual distance (a neural network-based approximation of the true perceptual distance) to natural images. Through an extensive perceptual study, we show that the neural perceptual distance correlates well with human judgements of perceptibility of adversarial examples, validating our threat model.

Under the NPTM, we develop novel perceptual adversarial attacks and defenses. Because the NPTM is very broad, we find that Perceptual Adversarial Training (PAT) against a perceptual attack gives robustness against many other types of adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against five diverse adversarial attacks: $L_2$, $L_\infty$, spatial, recoloring, and JPEG. We find that PAT achieves state-of-the-art robustness against the union of these five attacks—more than doubling the accuracy over the next best model—without training against any of them. That is, PAT generalizes well to unforeseen perturbation types. This is vital in sensitive applications where a particular threat model cannot be assumed, and to the best of our knowledge, PAT is the first adversarial defense with this property.

Code and data are available at https://github.com/cassidylaidlaw/perceptual-advex",敵対的ロバスト性における重要な課題は、人間の目には知覚できない敵対的攻撃の定義で使用される、人間の知覚の正確な数学的特性の欠如です。現在のほとんどの攻撃と防御は、L2またはL（）距離、空間的摂動などによって制限されるような制限的な敵対的脅威モデルを考慮してこの問題を回避しようとします。ただし、これらの制限的な脅威モデルのいずれに対しても堅牢なモデルは依然として脆弱です。他の脅威モデルに対して、つまり、予期しない攻撃に対する一般化が不十分です。さらに、モデルがいくつかの制限的な脅威モデルの結合に対して堅牢であっても、構成要素の脅威モデルのいずれにも含まれていない他の知覚できない敵対的な例の影響を受けやすくなります。これらの問題を解決するために、私たちはすべての知覚できない敵対的な例のセットに対して敵対的な訓練を提案します。このセットは、ループ内に人間がいなくても計算が難しいため、ディープニューラルネットワークを使用して近似します。この脅威モデルを神経知覚脅威モデル（NPTM）と呼びます。これには、自然画像に対するニューラル知覚距離（ニューラルネットワークベースの真の知覚距離の近似）が制限された敵対的な例が含まれています。広範な知覚研究を通じて、神経知覚距離が敵対的な例の知覚可能性の人間の判断とよく相関していることを示し、脅威モデルを検証します。 NPTMの下で、私たちは新しい知覚的敵対的攻撃と防御を開発します。 NPTMは非常に広いため、知覚攻撃に対する知覚敵対的トレーニング（PAT）は、他の多くのタイプの敵対的攻撃に対して堅牢性を提供することがわかります。 CIFAR-10およびImageNet-100でPATを、L2、L（）、空間、色の変更、およびJPEGの5つの多様な敵対的攻撃に対してテストします。 PATは、これら5つの攻撃の結合に対して最先端の堅牢性を実現し、それらのいずれに対してもトレーニングを行わなくても、次善のモデルの精度を2倍以上にすることがわかりました。つまり、PATは予期しない摂動タイプによく一般化されます。これは、特定の脅威モデルを想定できない機密性の高いアプリケーションでは不可欠であり、私たちの知る限り、PATはこのプロパティを使用した最初の敵対的防御です。コードとデータはhttps://github.com/cassidylaidlaw/perceptual-advexで入手できます。,6.75,
Group Equivariant Stand-Alone Self-Attention For Vision,"['David W. Romero', 'Jean-Baptiste Cordonnier']",https://openreview.net/forum?id=JkfYjnOEo6M,"We provide a general self-attention formulation to impose group equivariance to arbitrary symmetry groups. This is achieved by defining positional encodings that are invariant to the action of the group considered. Since the group acts on the positional encoding directly, group equivariant self-attention networks (GSA-Nets) are steerable by nature. Our experiments on vision benchmarks demonstrate consistent improvements of GSA-Nets over non-equivariant self-attention networks.",任意の対称群に群同変を課すための一般的な自己注意の定式化を提供します。これは、考慮されるグループのアクションに対して不変である位置エンコーディングを定義することによって実現されます。グループは位置エンコーディングに直接作用するため、グループ同変自己注意ネットワーク（GSA-Nets）は本質的に操作可能です。ビジョンベンチマークに関する私たちの実験は、非同変の自己注意ネットワークよりもGSA-Netが一貫して改善されていることを示しています。,6.75,https://d3i71xaburhd42.cloudfront.net/9dfce1cbcf0e98eec1ce2bf0bef27072e33ce369/2-Figure1-1.png
Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval,"['Wenhan Xiong', 'Xiang Li', 'Srini Iyer', 'Jingfei Du', 'Patrick Lewis', 'William Yang Wang', 'Yashar Mehdad', 'Scott Yih', 'Sebastian Riedel', 'Douwe Kiela', 'Barlas Oguz']",https://openreview.net/forum?id=EMHoBG0avc1,"We propose a simple and efficient multi-hop dense retrieval approach for answering complex open-domain questions, which achieves state-of-the-art performance on two multi-hop datasets, HotpotQA and multi-evidence FEVER. Contrary to previous work, our method does not require access to any corpus-specific information, such as inter-document hyperlinks or human-annotated entity markers, and can be applied to any unstructured text corpus. Our system also yields a much better efficiency-accuracy trade-off, matching the best published accuracy on HotpotQA while being 10 times faster at inference time.",HotpotQAとマルチエビデンスFEVERの2つのマルチホップデータセットで最先端のパフォーマンスを実現する、複雑なオープンドメインの質問に答えるためのシンプルで効率的なマルチホップ高密度検索アプローチを提案します。以前の作業とは異なり、この方法では、ドキュメント間のハイパーリンクや人間が注釈を付けたエンティティマーカーなど、コーパス固有の情報にアクセスする必要がなく、非構造化テキストコーパスに適用できます。私たちのシステムはまた、はるかに優れた効率と精度のトレードオフをもたらし、HotpotQAで公開されている最高の精度と一致し、推論時間で10倍高速になります。,6.75,https://d3i71xaburhd42.cloudfront.net/3684491d62db5c3e5602375271e4b339bbf416ee/2-Figure1-1.png
A Better Alternative to Error Feedback for Communication-Efficient Distributed Learning,"['Samuel Horváth', 'Peter Richtarik']",https://openreview.net/forum?id=vYVI1CHPaQg,"Modern large-scale machine learning applications require stochastic optimization algorithms to be implemented on distributed computing systems. A key bottleneck of such systems is the communication overhead for exchanging information across the workers, such as stochastic gradients. Among the many techniques proposed to remedy this issue, one of the most successful is the framework of compressed communication with error feedback (EF). EF remains the only known technique that can deal with the error induced by contractive compressors which are not unbiased, such as Top-$K$ or PowerSGD.  In this paper, we propose a new and theoretically and practically better alternative to EF for dealing with contractive compressors. In particular, we propose a construction which can transform any contractive compressor into an induced unbiased compressor. Following this transformation, existing methods able to work with unbiased compressors can be applied. We show that our approach leads to vast improvements over EF, including reduced memory requirements, better communication complexity guarantees and fewer assumptions. We further extend our results to federated learning with partial participation following an arbitrary distribution over the nodes and demonstrate the benefits thereof. We perform several numerical experiments which validate our theoretical findings.",最新の大規模な機械学習アプリケーションでは、分散コンピューティングシステムに確率的最適化アルゴリズムを実装する必要があります。このようなシステムの主なボトルネックは、確率的勾配など、ワーカー間で情報を交換するための通信オーバーヘッドです。この問題を解決するために提案された多くの手法の中で、最も成功したものの1つは、エラーフィードバック（EF）を使用した圧縮通信のフレームワークです。 EFは、Top-KやPowerSGDなど、偏りのない収縮型コンプレッサーによって引き起こされるエラーに対処できる唯一の既知の手法です。この論文では、収縮性コンプレッサーを扱うためのEFの新しい理論的かつ実用的に優れた代替案を提案します。特に、収縮圧縮機を誘導不偏圧縮機に変換できる構造を提案します。この変換に続いて、偏りのないコンプレッサーで動作できる既存の方法を適用できます。私たちのアプローチは、メモリ要件の削減、通信の複雑さの保証の向上、仮定の減少など、EFを大幅に改善することにつながることを示しています。さらに、ノード全体に任意に分散した後、部分的に参加する連合学習に結果を拡張し、その利点を示します。理論的発見を検証するいくつかの数値実験を実行します。,6.75,https://d3i71xaburhd42.cloudfront.net/0ffe2dde5dc78775bcf0c116661664845937b499/7-Figure1-1.png
Probabilistic Numeric Convolutional Neural Networks,"['Marc Anton Finzi', 'Roberto Bondesan', 'Max Welling']",https://openreview.net/forum?id=T1XmO8ScKim,"Continuous input signals like images and time series that are irregularly sampled or have missing values are challenging for existing deep learning methods. Coherently defined feature representations must depend on the values in unobserved regions of the input. Drawing from the work in probabilistic numerics, we propose Probabilistic Numeric Convolutional Neural Networks which represent features as Gaussian processes, providing a probabilistic description of discretization error. We then define a convolutional layer as the evolution of a PDE defined on this GP, followed by a nonlinearity. This approach also naturally admits steerable equivariant convolutions under e.g. the rotation group. In experiments we show that our approach yields a $3\times$ reduction of error from the previous state of the art on the SuperPixel-MNIST dataset and competitive performance on the medical time series dataset PhysioNet2012.",不規則にサンプリングされた、または値が欠落している画像や時系列などの連続入力信号は、既存の深層学習方法では困難です。コヒーレントに定義された特徴表現は、入力の観測されていない領域の値に依存する必要があります。確率的数値の研究から、特徴をガウス過程として表す確率的数値畳み込みニューラルネットワークを提案し、離散化誤差の確率的記述を提供します。次に、畳み込み層を、このGPで定義された偏微分方程式の進化として定義し、その後に非線形性を定義します。このアプローチはまた、例えば回転群の下での操縦可能な同変畳み込みも自然に認めます。実験では、私たちのアプローチにより、SuperPixel-MNISTデータセットの以前の最先端技術からのエラーが3減少し、医療時系列データセットPhysioNet2012の競争力のあるパフォーマンスが得られることを示しています。,6.75,https://d3i71xaburhd42.cloudfront.net/1f5a66f818d286c48d2c5e84f8ae35be4cb0ac47/3-Figure1-1.png
What Makes Instance Discrimination Good for Transfer Learning?,"['Nanxuan Zhao', 'Zhirong Wu', 'Rynson W. H. Lau', 'Stephen Lin']",https://openreview.net/forum?id=tC6iW2UUbJf,"Contrastive visual pretraining based on the instance discrimination pretext task has made significant progress. Notably, recent work on unsupervised pretraining has shown to surpass the supervised counterpart for finetuning downstream applications such as object detection and segmentation.   It comes as a surprise that image annotations would be better left unused for transfer learning.  In this work, we investigate the following problems: What makes instance discrimination pretraining good for transfer learning? What knowledge is actually learned and transferred from these models?  From this understanding of instance discrimination, how can we better exploit human annotation labels for pretraining? Our findings are threefold. First, what truly matters for the transfer is low-level and mid-level representations, not high-level representations.  Second, the intra-category invariance enforced by the traditional supervised model weakens transferability by increasing task misalignment. Finally, supervised pretraining can be strengthened by following an exemplar-based approach without explicit constraints among the instances within the same category.",インスタンス弁別口実タスクに基づく対照的な視覚的事前訓練は、大きな進歩を遂げました。特に、教師なし事前トレーニングに関する最近の作業は、オブジェクト検出やセグメンテーションなどのダウンストリームアプリケーションを微調整するための教師あり対応を上回っていることを示しています。転移学習のために画像注釈を未使用のままにしておく方がよいのは驚きです。この作業では、次の問題を調査します。インスタンス識別の事前トレーニングが転移学習に適している理由は何ですか。これらのモデルから実際にどのような知識が学習され、伝達されますか？インスタンスの識別に関するこの理解から、事前トレーニングのために人間の注釈ラベルをどのように活用できるでしょうか。私たちの調査結果は3つあります。まず、転送で本当に重要なのは、高レベルの表現ではなく、低レベルと中レベルの表現です。第2に、従来の教師ありモデルによって適用されるカテゴリ内の不変性は、タスクの不整合を増やすことによって転送可能性を弱めます。最後に、教師あり事前トレーニングは、同じカテゴリ内のインスタンス間の明示的な制約なしに、模範ベースのアプローチに従うことで強化できます。,6.75,https://d3i71xaburhd42.cloudfront.net/199d88fb9ec7430ca653f4c066b02aa7c3b4dd98/5-Figure1-1.png
How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?,"['Zixiang Chen', 'Yuan Cao', 'Difan Zou', 'Quanquan Gu']",https://openreview.net/forum?id=fgd7we_uZa6,"A recent line of research on deep learning focuses on the extremely over-parameterized setting, and shows that when the network width is larger than a high degree polynomial of the training sample size $n$ and the inverse of the target error $\epsilon^{-1}$, deep neural networks learned by (stochastic) gradient descent enjoy nice optimization and generalization guarantees. Very recently, it is shown that under certain margin assumptions on the training data, a polylogarithmic width condition suffices for two-layer ReLU networks to converge and generalize (Ji and Telgarsky, 2020). However, whether deep neural networks can be learned with such a mild over-parameterization is still an open question. In this work, we answer this question affirmatively and establish sharper learning guarantees for deep ReLU networks trained by (stochastic) gradient descent. In specific, under certain assumptions made in previous work, our optimization and generalization guarantees hold with network width polylogarithmic in $n$ and $\epsilon^{-1}$. Our results push the study of over-parameterized deep neural networks towards more practical settings.",ディープラーニングに関する最近の一連の研究は、非常にパラメーター化された設定に焦点を当てており、ネットワーク幅がトレーニングサンプルサイズnの高次多項式およびターゲットエラーの逆数^（1）よりも大きい場合、ディープ（確率的）勾配降下法によって学習されたニューラルネットワークは、優れた最適化と一般化の保証を享受します。ごく最近、トレーニングデータの特定のマージンの仮定の下で、2層ReLUネットワークが収束および一般化するために多対数幅条件で十分であることが示されています（JiおよびTelgarsky、2020）。ただし、このような穏やかな過剰パラメータ化でディープニューラルネットワークを学習できるかどうかは、未解決の問題です。この作業では、この質問に肯定的に答え、（確率的）勾配降下法によってトレーニングされた深いReLUネットワークのより鋭い学習保証を確立します。具体的には、前の作業で行われた特定の仮定の下で、最適化と一般化の保証は、nと^（1）のネットワーク幅の多対数で成り立ちます。私たちの結果は、パラメーターが多すぎるディープニューラルネットワークの研究をより実用的な設定に向けて推進しています。,6.75,
Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth,"['Thao Nguyen', 'Maithra Raghu', 'Simon Kornblith']",https://openreview.net/forum?id=KJNcAkY8tY4,"A key factor in the success of deep neural networks is the ability to scale models to improve performance by varying the architecture depth and width. This simple property of neural network design has resulted in highly effective architectures for a variety of tasks. Nevertheless, there is limited understanding of effects of depth and width on the learned representations. In this paper, we study this fundamental question. We begin by investigating how varying depth and width affects model hidden representations, finding a characteristic block structure in the hidden representations of larger capacity (wider or deeper) models. We demonstrate that this block structure arises when model capacity is large relative to the size of the training set, and is indicative of the underlying layers preserving and propagating the dominant principal component of their representations. This discovery has important ramifications for features learned by different models, namely, representations outside the block structure are often similar across architectures with varying widths and depths, but the block structure is unique to each model. We analyze the output predictions of different model architectures, finding that even when the overall accuracy is similar, wide and deep models exhibit distinctive error patterns and variations across classes.",ディープニューラルネットワークの成功の重要な要素は、アーキテクチャの深さと幅を変えることでパフォーマンスを向上させるためにモデルをスケーリングする機能です。ニューラルネットワーク設計のこの単純な特性により、さまざまなタスクに非常に効果的なアーキテクチャがもたらされました。それにもかかわらず、学習された表現に対する深さと幅の影響についての理解は限られています。この論文では、この基本的な質問を研究します。まず、深さと幅の変化がモデルの非表示表現にどのように影響するかを調査し、より大きな容量（より広いまたはより深い）モデルの非表示表現で特徴的なブロック構造を見つけます。このブロック構造は、モデルの容量がトレーニングセットのサイズに比べて大きい場合に発生し、その表現の主要な主成分を保持および伝播する下層を示していることを示します。この発見は、さまざまなモデルによって学習された機能に重要な影響を及ぼします。つまり、ブロック構造の外側の表現は、幅と深さが異なるアーキテクチャ間で類似していることがよくありますが、ブロック構造は各モデルに固有です。さまざまなモデルアーキテクチャの出力予測を分析し、全体的な精度が類似している場合でも、ワイドモデルとディープモデルがクラス間で特有のエラーパターンと変動を示すことを発見しました。,6.75,
Computational Separation Between Convolutional and Fully-Connected Networks,"['eran malach', 'Shai Shalev-Shwartz']",https://openreview.net/forum?id=hkMoYYEkBoI,"Convolutional neural networks (CNN) exhibit unmatched performance in a multitude of computer vision tasks. However, the advantage of using convolutional networks over fully-connected networks is not understood from a theoretical perspective. In this work, we show how convolutional networks can leverage locality in the data, and thus achieve a computational advantage over fully-connected networks. Specifically, we show a class of problems that can be efficiently solved using convolutional networks trained with gradient-descent, but at the same time is hard to learn using a polynomial-size fully-connected network.",畳み込みニューラルネットワーク（CNN）は、多数のコンピュータービジョンタスクで比類のないパフォーマンスを示します。ただし、完全に接続されたネットワークよりも畳み込みネットワークを使用する利点は、理論的な観点からは理解されていません。この作業では、畳み込みネットワークがデータの局所性を活用して、完全に接続されたネットワークよりも計算上の利点を実現する方法を示します。具体的には、勾配降下法でトレーニングされた畳み込みネットワークを使用して効率的に解決できる問題のクラスを示しますが、同時に、多項式サイズの完全接続ネットワークを使用して学習することは困難です。,6.75,https://d3i71xaburhd42.cloudfront.net/1e24ddc732a5a0187783b4a221a44e26def6d434/1-Figure1-1.png
Learning to Set Waypoints for Audio-Visual Navigation,"['Changan Chen', 'Sagnik Majumder', 'Ziad Al-Halah', 'Ruohan Gao', 'Santhosh Kumar Ramakrishnan', 'Kristen Grauman']",https://openreview.net/forum?id=cR91FAodFMe,"In audio-visual navigation, an agent intelligently travels through a complex, unmapped 3D environment using both sights and sounds to find a sound source (e.g., a phone ringing in another room). Existing models learn to act at a fixed granularity of agent motion and rely on simple recurrent aggregations of the audio observations. We introduce a reinforcement learning approach to audio-visual navigation with two key novel elements: 1) waypoints that are dynamically set and learned end-to-end within the navigation policy, and 2) an acoustic memory that provides a structured, spatially grounded record of what the agent has heard as it moves. Both new ideas capitalize on the synergy of audio and visual data for revealing the geometry of an unmapped space. We demonstrate our approach on two challenging datasets of real-world 3D scenes, Replica and Matterport3D. Our model improves the state of the art by a substantial margin, and our experiments reveal that learning the links between sights, sounds, and space is essential for audio-visual navigation.",視聴覚ナビゲーションでは、エージェントは、視覚と音声の両方を使用して複雑なマッピングされていない3D環境をインテリジェントに移動し、音源（たとえば、別の部屋で鳴っている電話）を見つけます。既存のモデルは、エージェントの動きの固定された粒度で動作することを学習し、音声観測の単純な反復集計に依存します。 2つの重要な新しい要素を使用した強化学習アプローチをオーディオビジュアルナビゲーションに導入します。1）ナビゲーションポリシー内でエンドツーエンドで動的に設定および学習されるウェイポイント、および2）構造化された空間的に接地されたレコードを提供する音響メモリエージェントが移動するときに聞いたことについて。どちらの新しいアイデアも、マッピングされていない空間のジオメトリを明らかにするために、オーディオデータとビジュアルデータの相乗効果を利用しています。実世界の3Dシーンの2つの挑戦的なデータセット、レプリカとMatterport3Dでのアプローチを示します。私たちのモデルは最先端技術を大幅に改善し、私たちの実験は、視覚、音、空間の間のリンクを学ぶことが視聴覚ナビゲーションに不可欠であることを明らかにしています。,6.75,
Activation-level uncertainty in deep neural networks,"['Pablo Morales-Alvarez', 'Daniel Hernández-Lobato', 'Rafael Molina', 'José Miguel Hernández-Lobato']",https://openreview.net/forum?id=UvBPbpvHRj-,"Current approaches for uncertainty estimation in deep learning often produce too confident results. Bayesian Neural Networks (BNNs) model uncertainty in the space of weights, which is usually high-dimensional and limits the quality of variational approximations. The more recent functional BNNs (fBNNs) address this only partially because, although the prior is specified in the space of functions, the posterior approximation is still defined in terms of stochastic weights. In this work we propose to move uncertainty from the weights (which are deterministic) to the activation function. Specifically, the activations are modelled with simple 1D Gaussian Processes (GP), for which a triangular kernel inspired by the ReLu non-linearity is explored. Our experiments show that activation-level stochasticity provides more reliable uncertainty estimates than BNN and fBNN, whereas it performs competitively in standard prediction tasks. We also study the connection with deep GPs, both theoretically and empirically. More precisely, we show that activation-level uncertainty requires fewer inducing points and is better suited for deep architectures.",深層学習における不確実性推定の現在のアプローチでは、自信がありすぎる結果が生じることがよくあります。ベイジアンニューラルネットワーク（BNN）は、重みの空間における不確実性をモデル化します。これは通常、高次元であり、変分近似の品質を制限します。最近の関数型BNN（fBNN）はこれに部分的にしか対処していません。これは、関数の空間で事前近似が指定されているにもかかわらず、事後近似が確率的重みで定義されているためです。この作業では、不確実性を重み（決定論的）から活性化関数に移動することを提案します。具体的には、アクティベーションは単純な1Dガウス過程（GP）でモデル化され、ReLuの非線形性に触発された三角形のカーネルが調査されます。私たちの実験は、活性化レベルの確率論がBNNやfBNNよりも信頼性の高い不確実性の推定値を提供するのに対し、標準的な予測タスクでは競争力があることを示しています。また、理論的にも経験的にも、深いGPとの関係を研究します。より正確には、アクティベーションレベルの不確実性は、必要な誘導ポイントが少なく、深いアーキテクチャに適していることを示しています。,6.75,
Semantic Re-tuning with Contrastive Tension,"['Fredrik Carlsson', 'Magnus Sahlgren', 'Evangelia Gogoulou', 'Amaru Cuba Gyllensten', 'Erik Ylipää Hellqvist']",https://openreview.net/forum?id=Ov_sMNau-PF,"Extracting semantically useful natural language sentence representations from pre-trained deep neural networks such as Transformers remains a challenge. We first demonstrate that pre-training objectives impose a significant task bias onto the final layers of models with a layer-wise survey of the Semantic Textual Similarity (STS) correlations for multiple common Transformer language models. We then propose a new self-supervised method called Contrastive Tension (CT) to counter such biases. CT frames the training objective as a noise-contrastive task between the final layer representations of two independent models, in turn making the final layer representations suitable for feature extraction. Results from multiple common unsupervised and supervised STS tasks indicate that CT outperforms previous State Of The Art (SOTA), and when combining CT with supervised data we improve upon previous SOTA results with large margins. ",トランスフォーマーなどの事前トレーニング済みのディープニューラルネットワークから意味的に有用な自然言語の文表現を抽出することは、依然として課題です。最初に、事前トレーニングの目的が、複数の一般的なTransformer言語モデルのセマンティックテキスト類似性（STS）相関のレイヤーごとの調査を使用して、モデルの最終レイヤーに重要なタスクバイアスを課すことを示します。次に、このようなバイアスに対抗するために、対照的張力（CT）と呼ばれる新しい自己監視法を提案します。 CTは、2つの独立したモデルの最終層表現間のノイズ対照タスクとしてトレーニング目標をフレーム化し、最終層表現を特徴抽出に適したものにします。複数の一般的な教師なしおよび教師ありSTSタスクの結果は、CTが以前の最先端（SOTA）を上回っていることを示しており、CTを教師ありデータと組み合わせると、以前のSOTAの結果を大幅に改善します。,6.75,
Estimating and Evaluating Regression Predictive Uncertainty in Deep Object Detectors,"['Ali Harakeh', 'Steven L. Waslander']",https://openreview.net/forum?id=YLewtnvKgR7,"Predictive uncertainty estimation is an essential next step for the reliable deployment of deep object detectors in safety-critical tasks. In this work, we focus on estimating predictive distributions for bounding box regression output with variance networks. We show that in the context of object detection, training variance networks with negative log likelihood (NLL) can lead to high entropy predictive distributions regardless of the correctness of the output mean. We propose to use the energy score as a non-local proper scoring rule and find that when used for training, the energy score leads to better calibrated and lower entropy predictive distributions than NLL. We also address the widespread use of non-proper scoring metrics for evaluating predictive distributions from deep object detectors by proposing an alternate evaluation approach founded on proper scoring rules. Using the proposed evaluation tools, we show that although variance networks can be used to produce high quality predictive distributions, ad-hoc approaches used by seminal object detectors for choosing regression targets during training do not provide wide enough data support for reliable variance learning. We hope that our work helps shift evaluation in probabilistic object detection to better align with predictive uncertainty evaluation in other machine learning domains. Code for all models, evaluation, and datasets is available at: https://github.com/asharakeh/probdet.git.",予測不確実性の推定は、セーフティクリティカルなタスクで深部物体検出器を確実に展開するための重要な次のステップです。この作業では、分散ネットワークを使用したバウンディングボックス回帰出力の予測分布の推定に焦点を当てます。オブジェクト検出のコンテキストでは、負の対数尤度（NLL）を使用して分散ネットワークをトレーニングすると、出力平均の正確さに関係なく、高いエントロピー予測分布につながる可能性があることを示します。エネルギースコアを非局所的な適切なスコアリングルールとして使用することを提案し、トレーニングに使用すると、エネルギースコアがNLLよりも適切に調整されたエントロピー予測分布につながることを発見します。また、適切なスコアリングルールに基づいた代替の評価アプローチを提案することにより、深部オブジェクト検出器からの予測分布を評価するための不適切なスコアリングメトリックの広範な使用に対処します。提案された評価ツールを使用して、分散ネットワークを使用して高品質の予測分布を生成できますが、トレーニング中に回帰ターゲットを選択するために精力的なオブジェクト検出器によって使用されるアドホックアプローチは、信頼できる分散学習のための十分なデータサポートを提供しないことを示します。私たちの仕事が、確率的オブジェクト検出のシフト評価が他の機械学習ドメインの予測不確実性評価とよりよく整合するのに役立つことを願っています。すべてのモデル、評価、およびデータセットのコードは、https：//github.com/asharakeh/probdet.gitで入手できます。,6.75,https://d3i71xaburhd42.cloudfront.net/f54db3e13253da12addd7fcac9bf0010a9b8b7e3/4-Figure1-1.png
Robust Reinforcement Learning on State Observations with Learned Optimal Adversary,"['Huan Zhang', 'Hongge Chen', 'Duane S Boning', 'Cho-Jui Hsieh']",https://openreview.net/forum?id=sCZbhBvqQaU,"We study the robustness of reinforcement learning (RL) with adversarially perturbed state observations, which aligns with the setting of many adversarial attacks to deep reinforcement learning (DRL) and is also important for rolling out real-world RL agent under unpredictable sensing noise. With a fixed agent policy, we demonstrate that an optimal adversary to perturb state observations can be found, which is guaranteed to obtain the worst case agent reward. For DRL settings, this leads to a novel empirical adversarial attack to RL agents via a learned adversary that is much stronger than previous ones. To enhance the robustness of an agent, we propose a framework of alternating training with learned adversaries (ATLA), which trains an adversary online together with the agent using policy gradient following the optimal adversarial attack framework. Additionally, inspired by the analysis of state-adversarial Markov decision process (SA-MDP), we show that past states and actions (history) can be useful for learning a robust agent, and we empirically find a LSTM based policy can be more robust under adversaries. Empirical evaluations on a few continuous control environments show that ATLA achieves state-of-the-art performance under strong adversaries. Our code is available at https://github.com/huanzhang12/ATLA_robust_RL.",強化学習（RL）のロバスト性を、敵対的に摂動された状態の観測で研究します。これは、深層強化学習（DRL）に対する多くの敵対的攻撃の設定と一致し、予測できないセンシングノイズの下で実際のRLエージェントを展開するためにも重要です。固定エージェントポリシーを使用して、状態の観測を混乱させる最適な敵を見つけることができることを示します。これにより、最悪の場合のエージェント報酬を確実に取得できます。 DRL設定の場合、これは、以前のものよりもはるかに強力な、学習された敵を介したRLエージェントへの新しい経験的敵対的攻撃につながります。エージェントの堅牢性を強化するために、学習した敵と交互にトレーニングするフレームワーク（ATLA）を提案します。これは、最適な敵攻撃フレームワークに従ってポリシー勾配を使用して、エージェントと一緒にオンラインで敵をトレーニングします。さらに、状態に敵対するマルコフ決定過程（SA-MDP）の分析に触発されて、過去の状態とアクション（履歴）が堅牢なエージェントの学習に役立つ可能性があることを示し、LSTMベースのポリシーがより堅牢になる可能性があることを経験的に見つけました敵の下で。いくつかの連続制御環境での経験的評価は、ATLAが強力な敵の下で最先端のパフォーマンスを達成することを示しています。私たちのコードはhttps://github.com/huanzhang12/ATLA_robust_RLで入手できます。,6.75,https://d3i71xaburhd42.cloudfront.net/1a627d2a169d71563109546da590a7cceb0b349a/2-Figure1-1.png
Towards Robust Neural Networks via Close-loop Control,"['Zhuotong Chen', 'Qianxiao Li', 'Zheng Zhang']",https://openreview.net/forum?id=2AL06y9cDE-,"Despite their success in massive engineering applications, deep neural networks are vulnerable to various perturbations due to their black-box nature. Recent study has shown that a deep neural network can misclassify the data even if the input data is perturbed by an imperceptible amount. In this paper, we address the robustness issue of neural networks by a novel close-loop control method from the perspective of dynamic systems. Instead of modifying the parameters in a fixed neural network architecture, a close-loop control process is added to generate control signals adaptively for the perturbed or corrupted data. We connect the robustness of neural networks with optimal control using the geometrical information of underlying data to design the control objective. The detailed analysis shows how the embedding manifolds of state trajectory affect error estimation of the proposed method. Our approach can simultaneously maintain the performance on clean data and improve the robustness against many types of data perturbations. It can also further improve the performance of robustly trained neural networks against different perturbations. To the best of our knowledge, this is the first work that improves the robustness of neural networks with close-loop control.",大規模なエンジニアリングアプリケーションでの成功にもかかわらず、ディープニューラルネットワークはブラックボックスの性質のためにさまざまな摂動に対して脆弱です。最近の研究では、入力データが知覚できない量で摂動された場合でも、ディープニューラルネットワークがデータを誤って分類する可能性があることが示されています。本論文では、動的システムの観点から、新しい閉ループ制御法によってニューラルネットワークのロバスト性の問題に対処します。固定ニューラルネットワークアーキテクチャのパラメータを変更する代わりに、閉ループ制御プロセスが追加され、摂動または破損したデータに適応して制御信号を生成します。ニューラルネットワークの堅牢性を、基礎となるデータの幾何学的情報を使用した最適制御と結び付けて、制御目標を設計します。詳細な分析は、状態軌道の埋め込み多様体が提案された方法の誤差推定にどのように影響するかを示しています。私たちのアプローチは、クリーンなデータのパフォーマンスを維持し、多くのタイプのデータ摂動に対する堅牢性を向上させることができます。また、さまざまな摂動に対して堅牢にトレーニングされたニューラルネットワークのパフォーマンスをさらに向上させることもできます。私たちの知る限り、これは閉ループ制御でニューラルネットワークの堅牢性を向上させる最初の作業です。,6.75,https://d3i71xaburhd42.cloudfront.net/b14771bee66631f380f49401b92e6cc8a6c5eafa/2-Figure1-1.png
Emergent Symbols through Binding in External Memory,"['Taylor Whittington Webb', 'Ishan Sinha', 'Jonathan Cohen']",https://openreview.net/forum?id=LSFCEb3GYU7,"A key aspect of human intelligence is the ability to infer abstract rules directly from high-dimensional sensory data, and to do so given only a limited amount of training experience. Deep neural network algorithms have proven to be a powerful tool for learning directly from high-dimensional data, but currently lack this capacity for data-efficient induction of abstract rules, leading some to argue that symbol-processing mechanisms will be necessary to account for this capacity. In this work, we take a step toward bridging this gap by introducing the Emergent Symbol Binding Network (ESBN), a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. Across a series of tasks, we show that this architecture displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples, and outperforms a number of other competitive neural network architectures.",ヒューマンインテリジェンスの重要な側面は、高次元の感覚データから直接抽象的なルールを推測する機能であり、限られた量のトレーニング経験しか与えられていない場合にそうすることができます。ディープニューラルネットワークアルゴリズムは、高次元データから直接学習するための強力なツールであることが証明されていますが、現在、抽象ルールをデータ効率的に誘導するためのこの能力が不足しているため、これを説明するにはシンボル処理メカニズムが必要であると主張する人もいます。容量。この作業では、可変バインディングと間接化の形式を可能にする外部メモリで拡張されたリカレントネットワークであるEmergent Symbol Binding Network（ESBN）を導入することにより、このギャップを埋めるための一歩を踏み出します。このバインディングメカニズムにより、シンボル処理機構を明示的に組み込む必要なしに、シンボルのような表現が学習プロセスを通じて出現し、ESBNは、ルールが適用される特定のエンティティから抽象化された方法でルールを学習できます。一連のタスク全体で、このアーキテクチャは、限られた数のトレーニング例のみを与えられた新しいエンティティへの学習ルールのほぼ完全な一般化を示し、他の多くの競合ニューラルネットワークアーキテクチャよりも優れていることを示します。,6.75,
Off-Dynamics Reinforcement Learning: Training for Transfer with Domain Classifiers,"['Benjamin Eysenbach', 'Shreyas Chaudhari', 'Swapnil Asawa', 'Sergey Levine', 'Ruslan Salakhutdinov']",https://openreview.net/forum?id=eqBwg3AcIAK,"We propose a simple, practical, and intuitive approach for domain adaptation in reinforcement learning. Our approach stems from the idea that the agent's experience in the source domain should look similar to its experience in the target domain. Building off of a probabilistic view of RL, we achieve this goal by compensating for the difference in dynamics by modifying the reward function. This modified reward function is simple to estimate by learning auxiliary classifiers that distinguish source-domain transitions from target-domain transitions. Intuitively, the agent is penalized for transitions that would indicate that the agent is interacting with the source domain, rather than the target domain. Formally, we prove that applying our method in the source domain is guaranteed to obtain a near-optimal policy for the target domain, provided that the source and target domains satisfy a lightweight assumption. Our approach is applicable to domains with continuous states and actions and does not require learning an explicit model of the dynamics. On discrete and continuous control tasks, we illustrate the mechanics of our approach and demonstrate its scalability to high-dimensional~tasks.",強化学習におけるドメイン適応のためのシンプルで実用的かつ直感的なアプローチを提案します。私たちのアプローチは、ソースドメインでのエージェントのエクスペリエンスがターゲットドメインでのエクスペリエンスと同じように見える必要があるという考えに基づいています。 RLの確率論的ビューに基づいて、報酬関数を変更することでダイナミクスの違いを補正することで、この目標を達成します。この変更された報酬関数は、ソースドメインの遷移とターゲットドメインの遷移を区別する補助分類子を学習することで簡単に見積もることができます。直感的には、エージェントは、エージェントがターゲットドメインではなく、ソースドメインと相互作用していることを示す遷移に対してペナルティが課せられます。正式には、ソースドメインとターゲットドメインが軽量の仮定を満たしている場合、ソースドメインにこの方法を適用すると、ターゲットドメインに対してほぼ最適なポリシーが得られることが保証されます。私たちのアプローチは、継続的な状態とアクションを持つドメインに適用可能であり、ダイナミクスの明示的なモデルを学習する必要はありません。離散的および連続的な制御タスクについて、アプローチのメカニズムを説明し、高次元タスクへのスケーラビリティを示します。,6.75,https://d3i71xaburhd42.cloudfront.net/b450b57c6afdece63287284d850ecdd973c4ec0c/2-Figure1-1.png
Data-Efficient Reinforcement Learning with Self-Predictive Representations,"['Max Schwarzer', 'Ankesh Anand', 'Rishab Goel', 'R Devon Hjelm', 'Aaron Courville', 'Philip Bachman']",https://openreview.net/forum?id=uCQfPZwRaUu,"While deep reinforcement learning excels at solving tasks where large amounts of data can be collected through virtually unlimited interaction with the environment, learning from limited interaction remains a key challenge. We posit that an agent can learn more efficiently if we augment reward maximization with self-supervised objectives based on structure in its visual input and sequential interaction with the environment. Our method, SPR, trains an agent to predict its own latent state representations multiple steps into the future. We compute target representations for future states using an encoder which is an exponential moving average of the agent's parameters and we make predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels. We further improve performance by adding data augmentation to the future prediction loss, which forces the agent's representations to be consistent across multiple views of an observation. Our full self-supervised objective, which combines future prediction and data augmentation, achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction, which represents a 55% relative improvement over the previous state-of-the-art. Notably, even in this limited data regime, SPR exceeds expert human scores on 7 out of 26 games.  We've made the code associated with this work available at https://anonymous.4open.science/r/b4b93ec6-6e5d-4f43-9b53-54bdf73bea95/.",深層強化学習は、環境との実質的に無制限の相互作用を通じて大量のデータを収集できるタスクの解決に優れていますが、限られた相互作用からの学習は依然として重要な課題です。エージェントは、視覚入力の構造と環境との順次の相互作用に基づいて、自己管理の目的で報酬の最大化を強化すると、より効率的に学習できると考えています。私たちの方法であるSPRは、エージェントをトレーニングして、将来の複数のステップで自身の潜在状態表現を予測します。エージェントパラメータの指数移動平均であるエンコーダを使用して将来の状態のターゲット表現を計算し、学習した遷移モデルを使用して予測を行います。この将来の予測目標は、それ自体で、ピクセルからのサンプル効率の高いディープRLの以前の方法よりも優れています。将来の予測損失にデータ拡張を追加することでパフォーマンスをさらに向上させます。これにより、エージェントの表現が観測の複数のビューにわたって一貫するようになります。将来の予測とデータ拡張を組み合わせた完全な自己監視目標は、環境相互作用の100kステップに制限された設定で、Atariで人間が正規化したスコアの中央値0.415を達成します。これは55を表します。,6.75,
Policy-Driven Attack: Learning to Query for Hard-label Black-box Adversarial Examples,"['Ziang Yan', 'Yiwen Guo', 'Jian Liang', 'Changshui Zhang']",https://openreview.net/forum?id=pzpytjk3Xb2,"To craft black-box adversarial examples, adversaries need to query the victim model and take proper advantage of its feedback. Existing black-box attacks generally suffer from high query complexity, especially when only the top-1 decision (i.e., the hard-label prediction) of the victim model is available. In this paper, we propose a novel hard-label black-box attack named Policy-Driven Attack, to reduce the query complexity. Our core idea is to learn promising search directions of the adversarial examples using a well-designed policy network in a novel reinforcement learning formulation, in which the queries become more sensible. Experimental results demonstrate that our method can significantly reduce the query complexity in comparison with existing state-of-the-art hard-label black-box attacks on various image classification benchmark datasets. Anonymous code and models for reproducing our results are available in the supplementary material.",ブラックボックスの敵対的な例を作成するには、敵対者は被害者モデルにクエリを実行し、そのフィードバックを適切に利用する必要があります。既存のブラックボックス攻撃は、特に被害者モデルの上位1つの決定（つまり、ハードラベル予測）しか利用できない場合、一般にクエリの複雑さが高くなります。このホワイトペーパーでは、クエリの複雑さを軽減するために、ポリシー駆動型攻撃という名前の新しいハードラベルブラックボックス攻撃を提案します。私たちの中心的なアイデアは、クエリがより賢明になる新しい強化学習の定式化で、適切に設計されたポリシーネットワークを使用して、敵対的な例の有望な検索方向を学習することです。実験結果は、さまざまな画像分類ベンチマークデータセットに対する既存の最先端のハードラベルブラックボックス攻撃と比較して、私たちの方法がクエリの複雑さを大幅に軽減できることを示しています。結果を再現するための匿名のコードとモデルは、補足資料で入手できます。,6.75,
Private Image Reconstruction from System Side Channels Using Generative Models,"['Yuanyuan Yuan', 'Shuai Wang', 'Junping Zhang']",https://openreview.net/forum?id=y06VOYLcQXa,"System side channels denote effects imposed on the underlying system and hardware when running a program, such as its accessed CPU cache lines. Side channel analysis (SCA) allows attackers to infer program secrets based on observed side channel signals. Given the ever-growing adoption of machine learning as a service (MLaaS), image analysis software on cloud platforms has been exploited by reconstructing private user images from system side channels. Nevertheless, to date, SCA is still highly challenging, requiring technical knowledge of victim software's internal operations. For existing SCA attacks, comprehending such internal operations requires heavyweight program analysis or manual efforts.

This research proposes an attack framework to reconstruct private user images processed by media software via system side channels. The framework forms an effective workflow by incorporating convolutional networks, variational autoencoders, and generative adversarial networks. Our evaluation of two popular side channels shows that the reconstructed images consistently match user inputs, making privacy leakage attacks more practical. We also show surprising results that even one-bit data read/write pattern side channels, which are deemed minimally informative, can be used to reconstruct quality images using our framework.",システムサイドチャネルは、アクセスされたCPUキャッシュラインなど、プログラムの実行時に基盤となるシステムとハードウェアに課せられる影響を示します。サイドチャネル分析（SCA）を使用すると、攻撃者は、観察されたサイドチャネル信号に基づいてプログラムの秘密を推測できます。サービスとしての機械学習（MLaaS）の採用が増え続けていることを考えると、クラウドプラットフォーム上の画像分析ソフトウェアは、システム側のチャネルからプライベートユーザーの画像を再構築することによって活用されてきました。それにもかかわらず、これまでのところ、SCAは依然として非常に困難であり、被害者のソフトウェアの内部操作に関する技術的な知識が必要です。既存のSCA攻撃の場合、そのような内部操作を理解するには、重いプログラム分析または手動の作業が必要です。この研究は、システムサイドチャネルを介してメディアソフトウェアによって処理されたプライベートユーザー画像を再構築するための攻撃フレームワークを提案します。このフレームワークは、畳み込みネットワーク、変分オートエンコーダー、および生成的敵対的ネットワークを組み込むことにより、効果的なワークフローを形成します。 2つの人気のあるサイドチャネルの評価は、再構築された画像が一貫してユーザー入力と一致し、プライバシー漏洩攻撃をより実用的にしていることを示しています。また、情報量が最小限であると見なされる1ビットデータの読み取り/書き込みパターンのサイドチャネルでも、フレームワークを使用して高品質の画像を再構築できるという驚くべき結果を示しています。,6.75,
Negative Data Augmentation ,"['Abhishek Sinha', 'Kumar Ayush', 'Jiaming Song', 'Burak Uzkent', 'Hongxia Jin', 'Stefano Ermon']",https://openreview.net/forum?id=Ovp8dvB8IBH,"Data augmentation is often used to enlarge datasets with synthetic samples generated in accordance with the underlying data distribution. To enable a wider range of augmentations, we explore negative data augmentation strategies (NDA) that intentionally create out-of-distribution samples. We show that such negative out-of-distribution samples provide information on the support of the data distribution,  and can be leveraged for generative modeling and representation learning. We introduce a new GAN training objective where we use NDA as an additional source of synthetic data for the discriminator. We prove that under suitable conditions, optimizing the resulting objective still recovers the true data distribution but can directly bias the generator towards avoiding samples that lack the desired structure. Empirically, models trained with our method achieve improved conditional/unconditional image generation along with improved anomaly detection capabilities. Further, we incorporate the same negative data augmentation strategy in a contrastive learning framework for self-supervised representation learning on images and videos, achieving improved performance on downstream image classification, object detection, and action recognition tasks. These results suggest that prior knowledge on what does not constitute valid data is an effective form of weak supervision across a range of unsupervised learning tasks.",データ拡張は、基礎となるデータ分布に従って生成された合成サンプルでデータセットを拡大するためによく使用されます。より広範囲の拡張を可能にするために、意図的に分布外のサンプルを作成するネガティブデータ拡張戦略（NDA）を調査します。このような負の分布外サンプルは、データ分布のサポートに関する情報を提供し、生成モデリングと表現学習に活用できることを示します。弁別器の合成データの追加ソースとしてNDAを使用する新しいGANトレーニング目標を紹介します。適切な条件下で、結果の目的を最適化しても真のデータ分布が回復するが、目的の構造を欠くサンプルを回避するようにジェネレーターに直接バイアスをかけることができることを証明します。経験的に、私たちの方法でトレーニングされたモデルは、改善された異常検出機能とともに、改善された条件付き/無条件の画像生成を実現します。さらに、同じネガティブデータ増強戦略を、画像とビデオの自己教師あり表現学習の対照的な学習フレームワークに組み込み、ダウンストリームの画像分類、オブジェクト検出、および行動認識タスクのパフォーマンスを向上させます。これらの結果は、有効なデータを構成しないものに関する事前の知識が、教師なし学習タスクの範囲全体にわたる弱い監督の効果的な形式であることを示唆しています。,6.75,
Learning Visual Representation from Human Interactions,"['Kiana Ehsani', 'Daniel Gordon', 'Thomas Hai Dang Nguyen', 'Roozbeh Mottaghi', 'Ali Farhadi']",https://openreview.net/forum?id=Qm8UNVCFdh,"Learning effective representations of visual data that generalize to a variety of downstream tasks has been a long quest for computer vision. Most representation learning approaches rely solely on visual data such as images or videos. In this paper, we explore a novel approach, where we use human interaction and attention cues to investigate whether we can learn better representations compared to visual-only representations. For this study, we collect a dataset of human interactions capturing body part movements and gaze in their daily lives. Our experiments show that our self-supervised representation that encodes interaction and attention cues outperforms a visual-only state-of-the-art method MoCo (He et al.,2020), on a variety of target tasks: scene classification (semantic), action recognition (temporal), depth estimation (geometric), dynamics prediction (physics) and walkable surface estimation (affordance).
",さまざまなダウンストリームタスクに一般化する視覚データの効果的な表現を学ぶことは、コンピュータビジョンの長い探求でした。ほとんどの表現学習アプローチは、画像やビデオなどの視覚データのみに依存しています。この論文では、人間の相互作用と注意の手がかりを使用して、視覚のみの表現と比較してより良い表現を学習できるかどうかを調査する、新しいアプローチを探ります。この研究では、身体の一部の動きを捉え、日常生活を注視する人間の相互作用のデータセットを収集します。私たちの実験は、相互作用と注意の手がかりをエンコードする私たちの自己監視表現が、さまざまなターゲットタスクで視覚のみの最先端の方法MoCo（He et al。、2020）よりも優れていることを示しています：シーン分類（セマンティック） 、アクション認識（時間的）、深度推定（幾何学的）、ダイナミクス予測（物理学）、歩行可能な表面推定（アフォーダンス）。,6.75,
Amending Mistakes Post-hoc in Deep Networks by Leveraging Class Hierarchies,"['Shyamgopal Karthik', 'Ameya Prabhu', 'Puneet K. Dokania', 'Vineet Gandhi']",https://openreview.net/forum?id=193sEnKY1ij,"There has been increasing interest in building deep hierarchy-aware classifiers, aiming to quantify and reduce the severity of mistakes and not just count the number of errors. The idea is to exploit the label hierarchy (e.g., WordNet ontology) and consider graph distances as a proxy for mistake severity. Surprisingly, on examining mistake-severity distributions of the top-1 prediction, we find that current state-of-the-art hierarchy-aware deep classifiers do not show practical improvement in making better mistakes than the standard cross-entropy baseline. In fact, they reduce the average mistake-severity metric by largely making additional low-severity or easily avoidable mistakes. This might explain the noticeable accuracy drop. 
To this end, we resort to the classical Conditional Risk Minimization (CRM) framework for hierarchy aware classification. Given a cost matrix and a reliable estimate of likelihoods (obtained from a trained network), CRM simply amends mistakes at inference time; it needs no extra parameters; it requires adding just one line of code to the standard cross-entropy baseline. It significantly outperforms the state-of-the-art and consistently obtains large reductions in the average hierarchical distance of top-k predictions across datasets, with very little loss in accuracy. Since CRM does not require retraining or fine-tuning of any hyperparameter, it can be used with any off-the-shelf cross-entropy trained model. ",エラーの数を数えるだけでなく、ミスの重大度を定量化して軽減することを目的として、階層を意識した深い分類器を構築することへの関心が高まっています。アイデアは、ラベル階層（WordNetオントロジーなど）を活用し、グラフの距離を間違いの重大度のプロキシと見なすことです。驚いたことに、トップ1予測のミスの重大度の分布を調べると、現在の最先端の階層を意識した深い分類器は、標準のクロスエントロピーベースラインよりも優れたミスを行う上で実際的な改善を示さないことがわかります。実際、これらは、重大度の低い、または簡単に回避できるミスを大幅に増やすことで、平均的なミスの重大度のメトリックを減らします。これは、顕著な精度の低下を説明している可能性があります。この目的のために、階層を意識した分類のために、古典的な条件付きリスク最小化（CRM）フレームワークに頼ります。コストマトリックスと信頼できる可能性の推定値（トレーニングされたネットワークから取得）が与えられると、CRMは推論時に間違いを修正するだけです。追加のパラメータは必要ありません。標準のクロスエントロピーベースラインに1行のコードを追加するだけで済みます。最先端のパフォーマンスを大幅に上回り、データセット全体の上位k予測の平均階層距離を一貫して大幅に短縮し、精度をほとんど損なうことはありません。 CRMはハイパーパラメータの再トレーニングや微調整を必要としないため、既成のクロスエントロピートレーニング済みモデルで使用できます。,6.75,
Symmetry-Aware Actor-Critic for 3D Molecular Design,"['Gregor N. C. Simm', 'Robert Pinsler', 'Gábor Csányi', 'José Miguel Hernández-Lobato']",https://openreview.net/forum?id=jEYKjPE1xYN,"Automating molecular design using deep reinforcement learning (RL) has the potential to greatly accelerate the search for novel materials. Despite recent progress on leveraging graph representations to design molecules, such methods are fundamentally limited by the lack of three-dimensional (3D) information. In light of this, we propose a novel actor-critic architecture for 3D molecular design that can generate molecular structures unattainable with previous approaches. This is achieved by exploiting the symmetries of the design process through a rotationally covariant state-action representation based on a spherical harmonics series expansion. We demonstrate the benefits of our approach on several 3D molecular design tasks, where we find that building in such symmetries significantly improves generalization and the quality of generated molecules.",深層強化学習（RL）を使用して分子設計を自動化すると、新しい材料の検索が大幅に加速する可能性があります。グラフ表現を利用して分子を設計する最近の進歩にもかかわらず、そのような方法は、3次元（3D）情報の欠如によって根本的に制限されています。これに照らして、以前のアプローチでは達成できなかった分子構造を生成できる3D分子設計のための新しいアクタークリティカルアーキテクチャを提案します。これは、球面調和関数の級数展開に基づく回転共変状態アクション表現を通じて、設計プロセスの対称性を活用することによって実現されます。いくつかの3D分子設計タスクでのアプローチの利点を示します。このような対称性を構築すると、一般化と生成された分子の品質が大幅に向上することがわかります。,6.67,https://d3i71xaburhd42.cloudfront.net/d11ac1bbfb9148ff177a9443b3700695fb5995e1/2-Figure1-1.png
Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time,"['Tolga Ergen', 'Mert Pilanci']",https://openreview.net/forum?id=0N8jUH4JMv6,"We study training of Convolutional Neural Networks (CNNs) with ReLU activations and introduce exact convex optimization formulations with a polynomial complexity with respect to the number of data samples, the number of neurons, and data dimension. More specifically, we develop a convex analytic framework utilizing semi-infinite duality to obtain equivalent convex optimization problems for several two- and three-layer CNN architectures. We first prove that two-layer CNNs can be globally optimized via an $\ell_2$ norm regularized convex program. We then show that three-layer CNN training problems are equivalent to an $\ell_1$ regularized convex program that encourages sparsity in the spectral domain. We also extend these results to multi-layer CNN architectures including three-layer networks with two ReLU layers and deeper circular convolutions with a single ReLU layer. Furthermore, we present extensions of our approach to different pooling methods, which elucidates the implicit architectural bias as convex regularizers.",ReLUアクティベーションを使用した畳み込みニューラルネットワーク（CNN）のトレーニングを研究し、データサンプルの数、ニューロンの数、およびデータ次元に関して多項式の複雑さを持つ正確な凸最適化の定式化を紹介します。より具体的には、半無限の双対性を利用して凸解析フレームワークを開発し、いくつかの2層および3層CNNアーキテクチャの同等の凸最適化問題を取得します。最初に、2層CNNがl2ノルム正則化凸計画を介してグローバルに最適化できることを証明します。次に、3層のCNNトレーニング問題が、スペクトル領域のスパース性を促進するl1正則化凸計画と同等であることを示します。また、これらの結果を、2つのReLU層を備えた3層ネットワークと1つのReLU層を備えたより深い巡回畳み込みを含む多層CNNアーキテクチャに拡張します。さらに、さまざまなプーリング方法へのアプローチの拡張を提示します。これにより、凸型レギュラライザーとしての暗黙のアーキテクチャバイアスが解明されます。,6.67,
Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning,"['Tianlong Chen', 'Zhenyu Zhang', 'Sijia Liu', 'Shiyu Chang', 'Zhangyang Wang']",https://openreview.net/forum?id=LXMSvPmsm0g,"The lottery ticket hypothesis demonstrates that a highly sparsified sub-network can be trained in isolation, given the appropriate weight initialization. This paper extends that hypothesis from one-shot task leaning, and demonstrate for the first time that such extremely compact and independently trainable sub-networks can be also identified in the lifelong learning scenario, which we call lifelong tickets. We show that the resulting lifelong ticket can further be leveraged to improve the performance of learning over continual tasks. However, it is highly non-trivial to conduct network pruning in the lifelong setting. Two critical roadblocks arise: i) As many tasks now arrive sequentially, finding tickets in a greedy weight pruning fashion will inevitably suffer from the intrinsic bias, that the earlier emerging tasks impact more; ii) As lifelong learning is consistently challenged by catastrophic forgetting, the compact network capacity of tickets might amplify the risk of forgetting. In view of those, we introduce two pruning options, e.g., top-down and bottom-up, for finding lifelong tickets. Compared to the top-down pruning that extends vanilla (iterative) pruning over sequential tasks, we show that the bottom-up one, which can dynamically shrink and (re-)expand model capacity, effectively avoids the undesirable excessive pruning in the early stage. We additionally introduce lottery teaching that further overcomes forgetting via knowledge distillation aided by external unlabeled data. Unifying those ingredients, we demonstrate the existence of very competitive lifelong tickets, e.g., achieving 3-8% of the dense model size with even higher accuracy, compared to strong class-incremental learning baselines on CIFAR-10/CIFAR-100/Tiny-ImageNet datasets.",宝くじの仮説は、適切な重みの初期化が与えられれば、高度にスパース化されたサブネットワークを分離してトレーニングできることを示しています。このホワイトペーパーでは、ワンショットタスク学習からの仮説を拡張し、このような非常にコンパクトで独立してトレーニング可能なサブネットワークが、生涯チケットと呼ばれる生涯学習シナリオでも識別できることを初めて示します。結果として得られる生涯チケットをさらに活用して、継続的なタスクでの学習のパフォーマンスを向上できることを示します。ただし、生涯にわたる設定でネットワークプルーニングを実行することは非常に重要です。 2つの重大な障害が発生します。i）多くのタスクが順番に到着するため、貪欲なウェイトプルーニング方式でチケットを見つけることは、必然的に固有のバイアスに悩まされ、以前に出現したタスクがより影響を及ぼします。 ii）生涯学習は壊滅的な忘却によって常に挑戦されているため、チケットのコンパクトなネットワーク容量は忘却のリスクを増幅させる可能性があります。これらを考慮して、生涯チケットを見つけるために、トップダウンとボトムアップなどの2つのプルーニングオプションを導入します。連続するタスクにわたってバニラ（反復）プルーニングを拡張するトップダウンプルーニングと比較して、モデル容量を動的に縮小および（再）拡張できるボトムアッププルーニングが、初期段階での望ましくない過度のプルーニングを効果的に回避することを示します。 。さらに、外部のラベルなしデータを利用した知識蒸留による忘却をさらに克服する宝くじ教育を紹介します。これらの成分を統合することで、非常に競争力のある生涯チケットの存在を示します。,6.67,
Hopfield Networks is All You Need,"['Hubert Ramsauer', 'Bernhard Schäfl', 'Johannes Lehner', 'Philipp Seidl', 'Michael Widrich', 'Lukas Gruber', 'Markus Holzleitner', 'Thomas Adler', 'David Kreil', 'Michael K Kopp', 'Günter Klambauer', 'Johannes Brandstetter', 'Sepp Hochreiter']",https://openreview.net/forum?id=tL89RnzIiCd,"We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension) many patterns, converges with one update, and has exponentially small retrieval errors.
It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule 
is equivalent to the attention mechanism used in transformers. This equivalence enabled a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging 
via metastable states. The new modern Hopfield networks can be integrated into deep learning architectures as layers with versatile functionalities for pooling, memory, association, and attention. We demonstrate the broad applicability of the Hopfield layers across various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded the best results
among different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets.",連続状態と対応する更新ルールを備えた最新のホップフィールドネットワークを紹介します。新しいホップフィールドネットワークは、指数関数的に（次元を使用して）多くのパターンを格納でき、1回の更新で収束し、指数関数的に小さい取得エラーがあります。エネルギー最小値（更新の固定小数点）には、（1）すべてのパターンのグローバル固定小数点平均、（2）パターンのサブセットの平均準安定状態、（3）単一パターンを格納する固定小数点の3種類があります。新しい更新ルールは、トランスフォーマーで使用されるアテンションメカニズムと同等です。この同等性により、トランスモデルのヘッドの特性評価が可能になりました。これらのヘッドは、第1層で、好ましくはグローバル平均化を実行し、上位層では準安定状態を介して部分平均化を実行します。新しい最新のホップフィールドネットワークは、プーリング、メモリ、関連付け、および注意のための多様な機能を備えたレイヤーとして、ディープラーニングアーキテクチャに統合できます。さまざまなドメインにわたるホップフィールドレイヤーの幅広い適用性を示します。ホップフィールド層は、考慮された複数インスタンスの学習問題の4つのうち3つ、および数十万のインスタンスによる免疫レパートリー分類の最新技術を改善しました。ディープラーニング手法が通常苦労する小さな分類タスクのUCIベンチマークコレクションでは、ホップフィールドレイヤーがさまざまな機械学習手法の中で最良の結果をもたらしました。最後に、ホップフィールドレイヤーは、2つのドラッグデザインデータセットで最先端を達成しました。,6.67,https://d3i71xaburhd42.cloudfront.net/804a6d7c23335bbca6eec3b7d3c8366dcbe395a5/3-Figure1-1.png
Uncertainty Estimation in Autoregressive Structured Prediction,"['Andrey Malinin', 'Mark Gales']",https://openreview.net/forum?id=jN5y-zb5Q7m,"Uncertainty estimation is important for ensuring safety and robustness of AI systems.  While most research in the area has focused on un-structured prediction tasks, limited work has investigated general uncertainty estimation approaches for structured prediction. Thus, this work aims to investigate uncertainty estimation for structured prediction tasks within a single unified and interpretable probabilistic ensemble-based framework.  We consider: uncertainty estimation for sequence data at the token-level and complete sequence-level; interpretations for, and applications of, various measures of uncertainty; and discuss both the theoretical and practical challenges associated with obtaining them. This work also provides baselines for token-level and sequence-level error detection, and sequence-level out-of-domain input detection on the WMT’14 English-French and WMT’17 English-German translation and LibriSpeech speech recognition datasets.",不確実性の推定は、AIシステムの安全性と堅牢性を確保するために重要です。この分野のほとんどの研究は非構造化予測タスクに焦点を合わせていますが、限られた研究では構造化予測の一般的な不確実性推定アプローチを調査しています。したがって、この作業は、単一の統一された解釈可能な確率的アンサンブルベースのフレームワーク内の構造化された予測タスクの不確実性推定を調査することを目的としています。トークンレベルおよび完全なシーケンスレベルでのシーケンスデータの不確実性の推定。不確実性のさまざまな尺度の解釈と適用。そして、それらの取得に関連する理論的および実際的な課題の両方について話し合います。この作業は、トークンレベルおよびシーケンスレベルのエラー検出、およびWMT14英語-フランス語およびWMT17英語-ドイツ語翻訳およびLibriSpeech音声認識データセットでのシーケンスレベルのドメイン外入力検出のベースラインも提供します。,6.67,
Average-case Acceleration for Bilinear Games and Normal Matrices,"['Carles Domingo-Enrich', 'Fabian Pedregosa', 'Damien Scieur']",https://openreview.net/forum?id=H0syOoy3Ash,"Advances in generative modeling and adversarial learning have given rise to renewed interest in smooth games. However, the absence of symmetry in the matrix of second derivatives poses challenges that are not present in the classical minimization framework. While a rich theory of average-case analysis has been developed for minimization problems, little is known in the context of smooth games. In this work we take a first step towards closing this gap by developing average-case optimal first-order methods for a subset of smooth games. 
We make the following three main contributions. First, we show that for zero-sum bilinear games the average-case optimal method is the optimal method for the minimization of the Hamiltonian. Second, we provide an explicit expression for the optimal method corresponding to normal matrices, potentially non-symmetric. Finally, we specialize it to matrices with eigenvalues located in a disk and show a provable speed-up compared to worst-case optimal algorithms. We illustrate our findings through benchmarks with a varying degree of mismatch with our assumptions.",生成モデリングと敵対的学習の進歩により、スムーズなゲームへの新たな関心が生まれました。ただし、二次導関数の行列に対称性がないことは、古典的な最小化フレームワークには存在しない課題をもたらします。最小化の問題については、平均ケース分析の豊富な理論が開発されていますが、スムーズなゲームのコンテキストではほとんど知られていません。この作業では、スムーズなゲームのサブセットに対して平均的なケースの最適な1次メソッドを開発することにより、このギャップを埋めるための第一歩を踏み出します。私たちは次の3つの主な貢献をします。まず、ゼロサム双線形ゲームの場合、平均ケース最適法がハミルトニアンの最小化に最適な方法であることを示します。次に、非対称の可能性がある正規行列に対応する最適な方法の明示的な式を提供します。最後に、それをディスクに配置された固有値を持つ行列に特化し、最悪の場合の最適なアルゴリズムと比較して証明可能なスピードアップを示します。仮定との不一致の程度が異なるベンチマークを通じて、調査結果を説明します。,6.67,https://d3i71xaburhd42.cloudfront.net/edc845f87b4ccdc97568410d157ed103c0a493d1/10-Figure1-1.png
Achieving Linear Speedup with Partial Worker Participation in Non-IID Federated Learning,"['Haibo Yang', 'Minghong Fang', 'Jia Liu']",https://openreview.net/forum?id=jDdzh5ul-d,"Federated learning (FL) is a distributed machine learning architecture that leverages a large number of workers to jointly learn a model with decentralized data. FL has received increasing attention in recent years thanks to its data privacy protection, communication efficiency and a linear speedup for convergence in training (i.e., convergence performance increases linearly with respect to the number of workers). However, existing studies on linear speedup for convergence are only limited to the assumptions of i.i.d. datasets across workers and/or full worker participation, both of which rarely hold in practice. So far, it remains an open question whether or not the linear speedup for convergence is achievable under non-i.i.d. datasets with partial worker participation in FL. In this paper, we show that the answer is affirmative. Specifically, we show that the federated averaging (FedAvg) algorithm (with two-sided learning rates) on non-i.i.d. datasets in non-convex settings achieves a convergence rate $\mathcal{O}(\frac{1}{\sqrt{mKT}} + \frac{1}{T})$ for full worker participation and a convergence rate $\mathcal{O}(\frac{1}{\sqrt{nKT}} + \frac{1}{T})$ for partial worker participation, where $K$ is the number of local steps, $T$ is the number of total communication rounds, $m$ is the total worker number and $n$ is the worker number in one communication round if for partial worker participation. Our results also reveal that the local steps in FL could help the convergence and show that the maximum number of local steps can be improved to $T/m$. We conduct extensive experiments on MNIST and CIFAR-10 to verify our theoretical results.",連合学習（FL）は、分散型の機械学習アーキテクチャであり、多数のワーカーを活用して、分散データを使用してモデルを共同で学習します。 FLは、データプライバシー保護、通信効率、トレーニングの収束の直線的な高速化（つまり、収束パフォーマンスがワーカー数に対して直線的に増加する）のおかげで、近年ますます注目を集めています。ただし、収束のための線形高速化に関する既存の研究は、労働者全体のiidデータセットの仮定および/または完全な労働者の参加に限定されており、どちらも実際にはほとんど成立しません。これまでのところ、FLに部分的に労働者が参加している非iidデータセットの下で、収束の線形高速化が達成可能かどうかは未解決の問題です。この論文では、答えが肯定的であることを示しています。具体的には、非凸設定の非iidデータセットでのフェデレーション平均（FedAvg）アルゴリズム（両側学習率を使用）が収束率$ \ mathcal {O}（\ frac {1} {\ sqrt { mKT}} + \ frac {1} {T}）$は、完全なワーカー参加と収束率$ \ mathcal {O}（\ frac {1} {\ sqrt {nKT}} + \ frac {1} {T} ）$部分労働者参加の場合、Kはローカルステップ数、Tは合計通信ラウンド数、mは合計労働者数、nは部分労働者参加の場合の1回の通信ラウンドの労働者数です。我々の結果はまた、FLのローカルステップが収束に役立つ可能性があることを明らかにし、ローカルステップの最大数をT / mに改善できることを示しています。 MNISTとCIFAR-10で広範な実験を行い、理論的な結果を検証します。,6.67,https://d3i71xaburhd42.cloudfront.net/433000baf18bb4403681fde5740bccd1fa2034a9/8-Figure1-1.png
Domain Generalization with MixStyle,"['Kaiyang Zhou', 'Yongxin Yang', 'Yu Qiao', 'Tao Xiang']",https://openreview.net/forum?id=6xHJ37MVxxp,"Though convolutional neural networks (CNNs) have demonstrated remarkable ability in learning discriminative features, they often generalize poorly to unseen domains. Domain generalization aims to address this problem by learning from a set of source domains a model that is generalizable to any unseen domain. In this paper, a novel approach is proposed based on probabilistically mixing instance-level feature statistics of training samples across source domains. Our method, termed MixStyle, is motivated by the observation that visual domain is closely related to image style (e.g., photo vs.~sketch images). Such style information is captured by the bottom layers of a CNN where our proposed style-mixing takes place. Mixing styles of training instances results in novel domains being synthesized implicitly, which increase the domain diversity of the source domains, and hence the generalizability of the trained model. MixStyle fits into mini-batch training perfectly and is extremely easy to implement. The effectiveness of MixStyle is demonstrated on a wide range of tasks including category classification, instance retrieval and reinforcement learning.",畳み込みニューラルネットワーク（CNN）は、識別機能を学習する際の優れた能力を示していますが、多くの場合、目に見えないドメインへの一般化は不十分です。ドメインの一般化は、ソースドメインのセットから、見えないドメインに一般化できるモデルを学習することで、この問題に対処することを目的としています。この論文では、ソースドメイン間でトレーニングサンプルのインスタンスレベルの特徴統計を確率的に混合することに基づいて、新しいアプローチを提案します。 MixStyleと呼ばれる私たちの方法は、視覚領域が画像スタイル（たとえば、写真とスケッチ画像）に密接に関連しているという観察に動機付けられています。このようなスタイル情報は、提案されたスタイルミキシングが行われるCNNの最下層によってキャプチャされます。トレーニングインスタンスのスタイルを混合すると、新しいドメインが暗黙的に合成され、ソースドメインのドメインの多様性が高まり、トレーニングされたモデルの一般化が可能になります。 MixStyleはミニバッチトレーニングに完全に適合し、実装が非常に簡単です。 MixStyleの有効性は、カテゴリ分類、インスタンス検索、強化学習などの幅広いタスクで実証されています。,6.67,
Partitioned Learned Bloom Filters,"['Kapil Vaidya', 'Eric Knorr', 'Michael Mitzenmacher', 'Tim Kraska']",https://openreview.net/forum?id=6BRLOfrMhW,"Bloom filters are space-efficient probabilistic data structures that are used to test whether an element is a member of a set, and may return false positives.  Recently, variations referred to as learned Bloom filters were developed that can provide improved performance in terms of the rate of false positives, by using a learned model for the represented set.  However, previous methods for learned Bloom filters do not take full advantage of the learned model.  Here we show how to frame the problem of optimal model utilization as an optimization problem, and using our framework derive algorithms that can achieve near-optimal performance in many cases.",ブルームフィルターは、要素がセットのメンバーであるかどうかをテストするために使用されるスペース効率の高い確率的データ構造であり、誤検出を返す可能性があります。最近、学習されたブルームフィルターと呼ばれるバリエーションが開発されました。これは、表現されたセットの学習されたモデルを使用することにより、誤検出率の観点からパフォーマンスを向上させることができます。ただし、学習済みブルームフィルターの以前の方法では、学習済みモデルを十分に活用できません。ここでは、最適化モデルの利用の問題を最適化問題として組み立てる方法を示し、フレームワークを使用して、多くの場合にほぼ最適なパフォーマンスを達成できるアルゴリズムを導き出します。,6.67,https://d3i71xaburhd42.cloudfront.net/88186837c8376d52c7164ad73c0e0bbc556b8fc1/3-Figure1-1.png
Improving Transformation Invariance in Contrastive Representation Learning,"['Adam Foster', 'Rattana Pukdee', 'Tom Rainforth']",https://openreview.net/forum?id=NomEDgIEBwE,"We propose methods to strengthen the invariance properties of representations obtained by contrastive learning. While existing approaches implicitly induce a degree of invariance as representations are learned, we look to more directly enforce invariance in the encoding process. To this end, we first introduce a training objective for contrastive learning that uses a novel regularizer to control how the representation changes under transformation. We show that representations trained with this objective perform better on downstream tasks and are more robust to the introduction of nuisance transformations at test time. Second, we propose a change to how test time representations are generated by introducing a feature averaging approach that combines encodings from multiple transformations of the original input, finding that this leads to across the board performance gains. Finally, we introduce the novel Spirograph dataset to explore our ideas in the context of a differentiable generative process with multiple downstream tasks, showing that our techniques for learning invariance are highly beneficial.",対照学習によって得られた表現の不変性特性を強化する方法を提案します。既存のアプローチは、表現が学習されるにつれて暗黙的にある程度の不変性を誘発しますが、エンコードプロセスで不変性をより直接的に強制することを目指しています。この目的のために、最初に、変換中に表現がどのように変化するかを制御するために新しい正則化を使用する対照学習のトレーニング目標を紹介します。この目的でトレーニングされた表現は、ダウンストリームタスクでより優れたパフォーマンスを発揮し、テスト時の迷惑な変換の導入に対してより堅牢であることを示します。次に、元の入力の複数の変換からのエンコーディングを組み合わせた機能平均化アプローチを導入することにより、テスト時間表現の生成方法の変更を提案します。これにより、全体的なパフォーマンスが向上することがわかります。最後に、新しいスピログラフデータセットを紹介して、複数のダウンストリームタスクを伴う微分​​可能な生成プロセスのコンテキストでアイデアを探索し、不変性を学習するための手法が非常に有益であることを示します。,6.67,https://d3i71xaburhd42.cloudfront.net/43a160b76a38d2aa913bc78fea2873e2b1bebc7d/6-Figure1-1.png
Robust Overfitting may be mitigated by properly learned smoothening,"['Tianlong Chen', 'Zhenyu Zhang', 'Sijia Liu', 'Shiyu Chang', 'Zhangyang Wang']",https://openreview.net/forum?id=qZzy5urZw9,"A recent study (Rice et al.,  2020) revealed overfitting to be a dominant phenomenon in adversarially robust training of deep networks, and that appropriate early-stopping of adversarial training (AT) could match the performance gains of most recent algorithmic improvements. This intriguing problem of robust overfitting motivates us to seek more remedies. As a pilot study, this paper investigates two empirical means to inject more learned smoothening during AT: one leveraging knowledge distillation and self-training to smooth the logits, the other performing stochastic weight averaging (Izmailov et al., 2018) to smooth the weights. Despite the embarrassing simplicity, the two approaches are surprisingly effective and hassle-free in mitigating robust overfitting. Experiments demonstrate that by plugging in them to AT, we can simultaneously boost the standard accuracy by 3.72%~6.68% and robust accuracy by 0.22%~2 .03%, across multiple datasets (STL-10, SVHN, CIFAR-10, CIFAR-100, and Tiny ImageNet), perturbation types ($\ell_{\infty}$ and $\ell_2$), and robustified methods (PGD, TRADES, and FSGM), establishing the new state-of-the-art bar in AT. We present systematic visualizations and analysis to dive into their possible working mechanisms. We also carefully exclude the possibility of gradient masking by evaluating our models' robustness against transfer attacks. We promise to publicly release our codes and pre-trained models.",最近の研究（Rice et al。、2020）は、深層ネットワークの敵対的にロバストなトレーニングでは過剰適合が支配的な現象であり、敵対的トレーニング（AT）の適切な早期停止が最新のアルゴリズム改善のパフォーマンス向上と一致する可能性があることを明らかにしました。堅牢な過剰適合というこの興味深い問題は、より多くの救済策を模索する動機になります。パイロット研究として、この論文では、AT中に学習した平滑化を注入するための2つの経験的手段を調査します。1つは知識蒸留と自己トレーニングを利用してロジットを平滑化し、もう1つは確率的重み平均化（Izmailov et al。、2018）を実行して重みを平滑化します。恥ずかしいほどの単純さにもかかわらず、2つのアプローチは驚くほど効果的で、堅牢な過剰適合を軽減するのに手間がかかりません。実験では、それらをATに接続することで、同時に標準精度を3.72上げることができることが示されています。,6.67,
Representation learning for improved interpretability and classification accuracy of clinical factors from EEG,"['Garrett Honke', 'Irina Higgins', 'Nina Thigpen', 'Vladimir Miskovic', 'Katie Link', 'Sunny Duan', 'Pramod Gupta', 'Julia Klawohn', 'Greg Hajcak']",https://openreview.net/forum?id=TVjLza1t4hI,"Despite extensive standardization, diagnostic interviews for mental health disorders encompass substantial subjective judgment. Previous studies have demonstrated that EEG-based neural measures can function as reliable objective correlates of depression, or even predictors of depression and its course. However, their clinical utility has not been fully realized because of 1) the lack of automated ways to deal with the inherent noise associated with EEG data at scale, and 2) the lack of knowledge of which aspects of the EEG signal may be markers of a clinical disorder. Here we adapt an unsupervised pipeline from the recent deep representation learning literature to address these problems by 1) learning a disentangled representation using $\beta$-VAE to denoise the signal, and 2) extracting interpretable features associated with a sparse set of clinical labels using a Symbol-Concept Association Network (SCAN). We demonstrate that our method is able to outperform the canonical hand-engineered baseline classification method on a number of factors, including participant age and depression diagnosis. Furthermore, our method recovers a representation that can be used to automatically extract denoised Event Related Potentials (ERPs) from novel, single EEG trajectories, and supports fast supervised re-mapping to various clinical labels, allowing clinicians to re-use a single EEG representation regardless of updates to the standardized diagnostic system. Finally, single factors of the learned disentangled representations often correspond to meaningful markers of clinical factors, as automatically detected by SCAN, allowing for human interpretability and post-hoc expert analysis of the recommendations made by the model.",広範な標準化にもかかわらず、メンタルヘルス障害の診断面接には、実質的な主観的判断が含まれます。以前の研究は、EEGベースの神経測定がうつ病の信頼できる客観的な相関関係として、あるいはうつ病とその経過の予測因子としてさえ機能できることを示しました。ただし、1）大規模なEEGデータに関連する固有のノイズを処理する自動化された方法がないこと、および2）EEG信号のどの側面がマーカーであるかについての知識がないため、それらの臨床的有用性は完全には実現されていません。臨床障害。ここでは、最近の深層表現学習文献からの教師なしパイプラインを適応させて、1）信号のノイズ除去に-VAEを使用して解きほぐされた表現を学習し、2）Symbol-を使用して臨床ラベルのまばらなセットに関連付けられた解釈可能な特徴を抽出します。コンセプトアソシエーションネットワーク（SCAN）。私たちの方法は、参加者の年齢やうつ病の診断など、多くの要因で、標準的な手作業によるベースライン分類方法よりも優れていることを示しています。さらに、私たちの方法は、新規の単一EEG軌道からノイズ除去された事象関連電位（ERP）を自動的に抽出するために使用できる表現を回復し、さまざまな臨床ラベルへの迅速な監視付き再マッピングをサポートし、臨床医が単一のEEG表現を再利用できるようにします標準化された診断システムの更新に関係なく。最後に、学習された解きほぐされた表現の単一の要因は、SCANによって自動的に検出されるように、臨床要因の意味のあるマーカーに対応することが多く、モデルによって行われた推奨事項の人間の解釈可能性と事後の専門家による分析を可能にします。,6.67,https://d3i71xaburhd42.cloudfront.net/723b7790853f03d13cdc5e2d4b18aef49d639dae/2-Figure1-1.png
Clustering-friendly Representation Learning via Instance Discrimination and Feature Decorrelation,"['Yaling Tao', 'Kentaro Takagi', 'Kouta Nakata']",https://openreview.net/forum?id=e12NDM7wkEY,"Clustering is one of the most fundamental tasks in machine learning. Recently, deep clustering has become a major trend in clustering techniques. Representation learning often plays an important role in the effectiveness of deep clustering, and thus can be a principal cause of performance degradation. In this paper, we propose a clustering-friendly representation learning method using instance discrimination and feature decorrelation. Our deep-learning-based representation learning method is motivated by the properties of classical spectral clustering. Instance discrimination learns similarities among data and feature decorrelation removes redundant correlation among features. We utilize an instance discrimination method in which learning individual instance classes leads to learning similarity among instances. Through detailed experiments and examination, we show that the approach can be adapted to learning a latent space for clustering. We design novel softmax-formulated decorrelation constraints for learning. In evaluations of image clustering using CIFAR-10 and ImageNet-10, our method achieves accuracy of 81.5% and 95.4%, respectively. We also show that the softmax-formulated constraints are compatible with various neural networks.",クラスタリングは、機械学習の最も基本的なタスクの1つです。最近、ディープクラスタリングがクラスタリング手法の主要なトレンドになっています。表現学習は、多くの場合、ディープクラスタリングの有効性に重要な役割を果たし、パフォーマンス低下の主な原因となる可能性があります。本論文では、インスタンス弁別と特徴非相関を用いたクラスタリングに適した表現学習法を提案する。私たちの深層学習ベースの表現学習方法は、古典的なスペクトルクラスタリングの特性によって動機付けられています。インスタンスの識別はデータ間の類似性を学習し、機能の無相関化により機能間の冗長な相関関係が削除されます。個々のインスタンスクラスを学習することでインスタンス間の類似性を学習するインスタンス識別方法を利用します。詳細な実験と調査を通じて、このアプローチがクラスタリングの潜在空間の学習に適応できることを示します。学習のための新しいソフトマックス定式化無相関制約を設計します。 CIFAR-10とImageNet-10を使用した画像クラスタリングの評価では、私たちの方法は81.5の精度を達成します,6.67,
Continual learning in recurrent neural networks,"['Benjamin Ehret', 'Christian Henning', 'Maria Cervera', 'Alexander Meulemans', 'Johannes Von Oswald', 'Benjamin F Grewe']",https://openreview.net/forum?id=8xeBUgD8u9,"While a diverse collection of continual learning (CL) methods has been proposed to prevent catastrophic forgetting, a thorough investigation of their effectiveness for processing sequential data with recurrent neural networks (RNNs) is lacking. Here, we provide the first comprehensive evaluation of established CL methods on a variety of sequential data benchmarks. Specifically, we shed light on the particularities that arise when applying weight-importance methods, such as elastic weight consolidation, to RNNs. In contrast to feedforward networks, RNNs iteratively reuse a shared set of weights and require working memory to process input samples. We show that the performance of weight-importance methods is not directly affected by the length of the processed sequences, but rather by high working memory requirements, which lead to an increased need for stability at the cost of decreased plasticity for learning subsequent tasks. We additionally provide theoretical arguments supporting this interpretation by studying linear RNNs. Our study shows that established CL methods can be successfully ported to the recurrent case, and that a recent regularization approach based on hypernetworks outperforms weight-importance methods, thus emerging as a promising candidate for CL in RNNs. Overall, we provide insights on the differences between CL in feedforward networks and RNNs, while guiding towards effective solutions to tackle CL on sequential data.",壊滅的な忘却を防ぐために継続学習（CL）手法の多様なコレクションが提案されていますが、リカレントニューラルネットワーク（RNN）でシーケンシャルデータを処理するためのそれらの有効性の徹底的な調査は不足しています。ここでは、さまざまなシーケンシャルデータベンチマークで確立されたCLメソッドの最初の包括的な評価を提供します。具体的には、弾性ウェイト統合などのウェイト重要度手法をRNNに適用するときに発生する特殊性に光を当てます。フィードフォワードネットワークとは対照的に、RNNは重みの共有セットを繰り返し再利用し、入力サンプルを処理するために作業メモリを必要とします。重み重要法のパフォーマンスは、処理されたシーケンスの長さによって直接影響を受けるのではなく、高い作業メモリ要件によって影響を受けることを示します。これにより、後続のタスクを学習するための可塑性が低下する代わりに、安定性の必要性が高まります。さらに、線形RNNを研究することにより、この解釈をサポートする理論的議論を提供します。私たちの研究は、確立されたCLメソッドをリカレントケースに正常に移植できること、およびハイパーネットワークに基づく最近の正則化アプローチが重み重要メソッドよりも優れていることを示しています。したがって、RNNのCLの有望な候補として浮上しています。全体として、フィードフォワードネットワークとRNNのCLの違いに関する洞察を提供すると同時に、シーケンシャルデータのCLに取り組むための効果的なソリューションを導きます。,6.67,
Sliced Kernelized Stein Discrepancy,"['Wenbo Gong', 'Yingzhen Li', 'José Miguel Hernández-Lobato']",https://openreview.net/forum?id=t0TaKv0Gx6Z,"Kernelized Stein discrepancy (KSD), though being extensively used in goodness-of-fit tests and model learning, suffers from the curse-of-dimensionality. We address this issue by proposing the sliced Stein discrepancy and its scalable and kernelized variants, which employs kernel-based test functions defined on the optimal one-dimensional projections. When applied to goodness-of-fit tests, extensive experiments show the proposed discrepancy significantly outperforms KSD and various baselines in high dimensions. For model learning, we show its advantages by training an independent component analysis when compared with existing Stein discrepancy baselines. We further propose a novel particle inference method called sliced Stein variational gradient descent (S-SVGD) which alleviates the mode-collapse issue of SVGD in training variational autoencoders.",カーネル化されたスタインの不一致（KSD）は、適合度テストやモデル学習で広く使用されていますが、次元の呪いに悩まされています。スライスされたスタインの不一致と、最適な1次元投影で定義されたカーネルベースのテスト関数を使用するスケーラブルでカーネル化されたバリアントを提案することで、この問題に対処します。適合度テストに適用すると、広範な実験により、提案された不一致がKSDおよび高次元のさまざまなベースラインを大幅に上回っていることを示しています。モデル学習では、既存のスタイン不一致ベースラインと比較した場合に、独立成分分析をトレーニングすることでその利点を示します。さらに、スライス型スタイン変分勾配降下法（S-SVGD）と呼ばれる新しい粒子推論法を提案します。これは、変分オートエンコーダーのトレーニングにおけるSVGDのモード崩壊の問題を軽減します。,6.67,https://d3i71xaburhd42.cloudfront.net/eba1f50ef2710385cd5e904ba24e97a270de83f6/5-Figure1-1.png
Learning Energy-Based Models by Diffusion Recovery Likelihood,"['Ruiqi Gao', 'Yang Song', 'Ben Poole', 'Ying Nian Wu', 'Diederik P Kingma']",https://openreview.net/forum?id=v_1Soh8QUNc,"While energy-based models (EBMs) exhibit a number of desirable properties, training and sampling on high-dimensional datasets remains challenging. Inspired by recent progress on diffusion probabilistic models, we present a diffusion recovery likelihood method to tractably learn and sample from a sequence of EBMs trained on increasingly noisy versions of a dataset. Each EBM is trained with recovery likelihood,  which maximizes the conditional distribution of the data at a certain noise level given their noisy versions at a higher noise level. Optimizing recovery likelihood is more tractable than marginal likelihood, as sampling from the conditional distributions is much easier than sampling from the marginal distributions. After training, synthesized images can be generated by the sampling process that initializes from Gaussian white noise distribution and progressively samples the conditional distributions at decreasingly lower noise levels.  Our method generates high fidelity samples on various image datasets. On unconditional CIFAR-10 our method achieves FID 9.60 and inception score 8.58, superior to the majority of GANs. Moreover, we demonstrate that unlike previous work on EBMs, our long-run MCMC samples from the conditional distributions do not diverge and still represent realistic images, allowing us to accurately estimate the normalized density of data even for high-dimensional datasets.",エネルギーベースのモデル（EBM）は多くの望ましい特性を示しますが、高次元データセットでのトレーニングとサンプリングは依然として困難です。拡散確率モデルの最近の進歩に触発されて、データセットのますますノイズの多いバージョンでトレーニングされたEBMのシーケンスから扱いやすく学習してサンプリングする拡散回復尤度法を提示します。各EBMは、回復の可能性でトレーニングされます。これにより、ノイズの多いバージョンがより高いノイズレベルである場合、特定のノイズレベルでのデータの条件付き分布が最大化されます。条件付き分布からのサンプリングは周辺分布からのサンプリングよりもはるかに簡単であるため、回復尤度の最適化は周辺尤度よりも扱いやすいです。トレーニング後、合成画像は、ガウスホワイトノイズ分布から初期化し、徐々に低いノイズレベルで条件付き分布を段階的にサンプリングするサンプリングプロセスによって生成できます。私たちの方法は、さまざまな画像データセットで忠実度の高いサンプルを生成します。無条件のCIFAR-10では、私たちの方法はFID 9.60と開始スコア8​​.58を達成し、GANの大部分よりも優れています。さらに、EBMに関する以前の作業とは異なり、条件付き分布からの長期MCMCサンプルは発散せず、現実的な画像を表すため、高次元のデータセットでも正規化されたデータ密度を正確に推定できます。,6.67,https://d3i71xaburhd42.cloudfront.net/90695f261c12265fb2694fe89cf390aad029a7dc/2-Figure1-1.png
Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning,"['Alihan Hüyük', 'Daniel Jarrett', 'Cem Tekin', 'Mihaela van der Schaar']",https://openreview.net/forum?id=unI5ucw_Jk,"Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker’s policy is challenging—with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision- making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning (“Interpole”) that jointly estimates an agent’s (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer’s disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, quantifying, and understanding human decision-making behavior.",観察されたデータから人間の行動を理解することは、意思決定における透明性と説明責任にとって重要です。意思決定者のポリシーのモデル化が困難であり、基礎となる州へのアクセスがなく、環境のダイナミクスに関する知識がなく、実際の実験が許可されていない、ヘルスケアなどの実際の設定を検討してください。私たちは、（1）設計により透明性を取り入れ、（2）部分的な可観測性に対応し、（3）完全にオフラインで動作する意思決定行動のデータ駆動型表現を学習することを望んでいます。これらの重要な基準を満たすために、エージェントの（バイアスの可能性がある）信念更新プロセスと（最適ではない可能性のある）信念アクションマッピングを共同で推定する、解釈可能なポリシー学習（Interpole）の新しいモデルベースのベイズ法を提案します。アルツハイマー病の診断の問題に関するシミュレーションデータと実世界データの両方での実験を通じて、人間の意思決定行動を監査、定量化、および理解するための調査デバイスとしてのアプローチの可能性を示します。,6.67,
Filtered Inner Product Projection for Multilingual Embedding Alignment,"['Vin Sachidananda', 'Ziyi Yang', 'Chenguang Zhu']",https://openreview.net/forum?id=A2gNouoXE7,"Due to widespread interest in machine translation and transfer learning, there are numerous algorithms for mapping multiple embeddings to a shared representation space. Recently, these algorithms have been studied in the setting of bilingual lexicon induction where one seeks to align the embeddings of a source and a target language such that translated word pairs lie close to one another in a common representation space. In this paper, we propose a method, Filtered Inner Product Projection (FIPP), for mapping embeddings to a common representation space. As semantic shifts are pervasive across languages and domains, FIPP first identifies the common geometric structure in both embeddings and then, only on the common structure, aligns the Gram matrices of these embeddings. FIPP is applicable even when the source and target embeddings are of differing dimensionalities. Additionally, FIPP provides computational benefits in ease of implementation and is faster to compute than current approaches. Following the baselines in Glavas et al. 2019, we evaluate FIPP both in the context of bilingual lexicon induction and downstream language tasks. We show that FIPP outperforms existing methods on the XLING BLI dataset for most language pairs while also providing robust performance across downstream tasks. ",機械翻訳と転移学習への関心が広まっているため、複数の埋め込みを共有表現空間にマッピングするためのアルゴリズムは多数あります。最近、これらのアルゴリズムは、翻訳された単語のペアが共通の表現空間で互いに近くにあるように、ソース言語とターゲット言語の埋め込みを整列させようとするバイリンガルレキシコン誘導の設定で研究されています。この論文では、埋め込みを共通の表現空間にマッピングするための方法、フィルター付き内積射影（FIPP）を提案します。セマンティックシフトは言語とドメイン全体に広がるため、FIPPは最初に両方の埋め込みで共通の幾何学的構造を識別し、次に共通の構造でのみ、これらの埋め込みのグラム行列を整列させます。 FIPPは、ソースとターゲットの埋め込みの次元が異なる場合でも適用できます。さらに、FIPPは、実装が容易な計算上の利点を提供し、現在のアプローチよりも計算が高速です。 Glavasらのベースラインに従う。 2019年、バイリンガルレキシコン誘導とダウンストリーム言語タスクの両方のコンテキストでFIPPを評価します。 FIPPは、ほとんどの言語ペアでXLING BLIデータセットの既存のメソッドよりも優れていると同時に、ダウンストリームタスク全体で堅牢なパフォーマンスを提供することを示しています。,6.67,https://d3i71xaburhd42.cloudfront.net/3c90693bd9ba6505fd1964937d208b4fd089f6ee/2-Figure1-1.png
Progressive Skeletonization: Trimming more fat from a network at initialization,"['Pau de Jorge', 'Amartya Sanyal', 'Harkirat Behl', 'Philip Torr', 'Grégory Rogez', 'Puneet K. Dokania']",https://openreview.net/forum?id=9GsFOUyUPi,"Recent studies have shown that skeletonization (pruning parameters) of networks at initialization provides all the practical benefits of sparsity both at inference and training time, while only marginally degrading their performance. However, we observe that beyond a certain level of sparsity (approx 95%), these approaches fail to preserve the network performance, and to our surprise, in many cases perform even worse than trivial random pruning. To this end, we propose an objective to find a skeletonized network with maximum foresight connection sensitivity (FORCE) whereby the trainability, in terms of connection sensitivity, of a pruned network is taken into consideration. We then propose two approximate procedures to maximize our objective (1) Iterative SNIP: allows parameters that were unimportant at earlier stages of skeletonization to become important at later stages; and (2) FORCE: iterative process that allows exploration by allowing already pruned parameters to resurrect at later stages of skeletonization. Empirical analysis on a large suite of experiments show that our approach, while providing at least as good performance as other recent approaches on moderate pruning levels, provide remarkably improved performance on high pruning levels (could remove up to 99.5% parameters while keeping the networks trainable).",最近の研究によると、初期化時のネットワークのスケルトン化（プルーニングパラメーター）は、推論時とトレーニング時の両方でスパース性のすべての実用的な利点を提供しますが、パフォーマンスはわずかに低下します。ただし、一定レベルのスパース性（約95）を超えると、,6.67,https://d3i71xaburhd42.cloudfront.net/86622b19a571fe994ac3f6ae1207703551aff763/2-Figure1-1.png
Contextual Dropout: An Efficient Sample-Dependent Dropout Module,"['XINJIE FAN', 'Shujian Zhang', 'Korawat Tanwisuth', 'Xiaoning Qian', 'Mingyuan Zhou']",https://openreview.net/forum?id=ct8_a9h1M,"Dropout has been demonstrated as a simple and effective module to not only regularize the training process of deep neural networks, but also provide the uncertainty estimation for prediction. However, the quality of uncertainty estimation is highly dependent on the dropout probabilities. Most current models use the same dropout distributions across all data samples due to its simplicity.  Despite the potential gains in the flexibility of modeling uncertainty, sample-dependent dropout, on the other hand, is less explored as it often encounters scalability issues or involves non-trivial model changes.  In this paper, we propose contextual dropout with an efficient structural design as a simple and scalable sample-dependent dropout module, which can be applied to a wide range of models at the expense of only slightly increased memory and computational cost. We learn the dropout probabilities with a variational objective, compatible with both Bernoulli dropout and Gaussian dropout. We apply the contextual dropout module to various models with applications to image classification and visual question answering and demonstrate the scalability of the method with large-scale datasets, such as ImageNet and VQA 2.0. Our experimental results show that the proposed method outperforms baseline methods in terms of both accuracy and quality of uncertainty estimation.",ドロップアウトは、ディープニューラルネットワークのトレーニングプロセスを正規化するだけでなく、予測のための不確実性の推定を提供するためのシンプルで効果的なモジュールとして実証されています。ただし、不確実性の推定の質は、ドロップアウトの確率に大きく依存します。現在のほとんどのモデルは、その単純さのために、すべてのデータサンプルにわたって同じドロップアウト分布を使用しています。モデリングの不確実性の柔軟性が向上する可能性があるにもかかわらず、サンプルに依存するドロップアウトは、スケーラビリティの問題に遭遇したり、重要なモデルの変更を伴うことが多いため、あまり検討されていません。この論文では、メモリと計算コストをわずかに増加させるだけで、幅広いモデルに適用できる、シンプルでスケーラブルなサンプル依存のドロップアウトモジュールとして、効率的な構造設計を備えたコンテキストドロップアウトを提案します。ベルヌーイドロップアウトとガウスドロップアウトの両方と互換性のある変分目的でドロップアウト確率を学習します。コンテキストドロップアウトモジュールをさまざまなモデルに適用し、画像分類と視覚的な質問応答へのアプリケーションを使用して、ImageNetやVQA2.0などの大規模データセットを使用したメソッドのスケーラビリティを示します。我々の実験結果は、提案された方法が不確実性推定の精度と品質の両方の点でベースライン方法よりも優れていることを示しています。,6.67,
Influence Estimation for Generative Adversarial Networks,"['Naoyuki Terashita', 'Hiroki Ohashi', 'Yuichi Nonaka', 'Takashi Kanemaru']",https://openreview.net/forum?id=opHLcXxYTC_,"Identifying harmful instances, whose absence in a training dataset improves model performance, is important for building better machine learning models. 
Although previous studies have succeeded in estimating harmful instances under supervised settings, they cannot be trivially extended to generative adversarial networks (GANs).
This is because previous approaches require that (1) the absence of a training instance directly affects the loss value and that (2) the change in the loss directly measures the harmfulness of the instance for the performance of a model. 
In GAN training, however, neither of the requirements is satisfied. 
This is because, (1) the generator’s loss is not directly affected by the training instances as they are not part of the generator's training steps, and (2) the values of GAN's losses normally do not capture the generative performance of a model.
To this end, (1) we propose an influence estimation method that uses the Jacobian of the gradient of the generator's loss with respect to the discriminator’s parameters (and vice versa) to trace how the absence of an instance in the discriminator’s training affects the generator’s parameters, and (2) we propose a novel evaluation scheme, in which we assess harmfulness of each training instance on the basis of how GAN evaluation metric (e.g., inception score) is expect to change due to the removal of the instance.
We experimentally verified that our influence estimation method correctly inferred the changes in GAN evaluation metrics.
Further, we demonstrated that the removal of the identified harmful instances effectively improved the model’s generative performance with respect to various GAN evaluation metrics.",トレーニングデータセットに存在しないことでモデルのパフォーマンスが向上する有害なインスタンスを特定することは、より優れた機械学習モデルを構築するために重要です。以前の研究では、監視された設定の下で有害なインスタンスを推定することに成功しましたが、それらを生成的敵対的ネットワーク（GAN）に簡単に拡張することはできません。これは、以前のアプローチでは、（1）トレーニングインスタンスがないことが損失値に直接影響し、（2）損失の変化がモデルのパフォーマンスに対するインスタンスの有害性を直接測定する必要があるためです。ただし、GANトレーニングでは、どちらの要件も満たされていません。これは、（1）ジェネレーターの損失は、ジェネレーターのトレーニングステップの一部ではないため、トレーニングインスタンスの影響を直接受けないためです。また、（2）GANの損失の値は、通常、モデルの生成パフォーマンスをキャプチャしません。この目的のために、（1）弁別器パラメーターに関するジェネレーター損失の勾配のヤコビアン（およびその逆）を使用して、弁別器トレーニングにインスタンスがないことがジェネレーターにどのように影響するかを追跡する影響推定方法を提案しますパラメータ、および（2）インスタンスの削除によってGAN評価メトリック（開始スコアなど）がどのように変化すると予想されるかに基づいて、各トレーニングインスタンスの有害性を評価する新しい評価スキームを提案します。影響推定方法がGAN評価指標の変化を正しく推測することを実験的に検証しました。さらに、特定された有害なインスタンスを削除することで、さまざまなGAN評価メトリックに関してモデルの生成パフォーマンスが効果的に向上することを示しました。,6.67,https://d3i71xaburhd42.cloudfront.net/9533e3e85c0c0b160e38b6fb193dc3ae1463fbef/7-Figure1-1.png
Directed Acyclic Graph Neural Networks,"['Veronika Thost', 'Jie Chen']",https://openreview.net/forum?id=JbuYF437WB6,"Graph-structured data ubiquitously appears in science and engineering. Graph neural networks (GNNs) are designed to exploit the relational inductive bias exhibited in graphs; they have been shown to outperform other forms of neural networks in scenarios where structure information supplements node features. The most common GNN architecture aggregates information from neighborhoods based on message passing. Its generality has made it broadly applicable. In this paper, we focus on a special, yet widely used, type of graphs---DAGs---and inject a stronger inductive bias---partial ordering---into the neural network design. We propose the directed acyclic graph neural network, DAGNN, an architecture that processes information according to the flow defined by the partial order. DAGNN can be considered a framework that entails earlier works as special cases (e.g., models for trees and models updating node representations recurrently), but we identify several crucial components that prior architectures lack. We perform comprehensive experiments, including ablation studies, on representative DAG datasets (i.e., source code, neural architectures, and probabilistic graphical models) and demonstrate the superiority of DAGNN over simpler DAG architectures as well as general graph architectures.",グラフ構造のデータは、科学と工学に遍在しています。グラフニューラルネットワーク（GNN）は、グラフに示されるリレーショナル誘導バイアスを活用するように設計されています。それらは、構造情報がノード機能を補足するシナリオで、他の形式のニューラルネットワークよりも優れていることが示されています。最も一般的なGNNアーキテクチャは、メッセージパッシングに基づいて近隣からの情報を集約します。その一般性により、広く適用できるようになりました。この論文では、特別でありながら広く使用されているタイプのグラフDAGに焦点を当て、ニューラルネットワーク設計に強い帰納的バイアス部分順序を注入します。半順序で定義されたフローに従って情報を処理するアーキテクチャである、有向非巡回グラフニューラルネットワークDAGNNを提案します。 DAGNNは、特殊なケースとして以前の作業を伴うフレームワークと見なすことができます（たとえば、ツリーのモデルやノード表現を繰り返し更新するモデル）が、以前のアーキテクチャには欠けているいくつかの重要なコンポーネントを特定します。代表的なDAGデータセット（つまり、ソースコード、ニューラルアーキテクチャ、確率的グラフィカルモデル）でアブレーション研究を含む包括的な実験を行い、より単純なDAGアーキテクチャや一般的なグラフアーキテクチャに対するDAGNNの優位性を示します。,6.67,https://d3i71xaburhd42.cloudfront.net/8d2cf786b76eefeb1bf4841245e4e6b15b16de92/3-Figure1-1.png
Reweighting Augmented Samples by Minimizing the Maximal Expected Loss,"['Mingyang Yi', 'Lu Hou', 'Lifeng Shang', 'Xin Jiang', 'Qun Liu', 'Zhi-Ming Ma']",https://openreview.net/forum?id=9G5MIc-goqB,"Data augmentation is an effective technique to improve the generalization of deep neural networks. However, previous data augmentation methods usually treat the augmented samples equally without considering their individual impacts on the model. To address this, for the augmented samples from the same training example, we propose to assign different weights to them. We construct the maximal expected loss which is the supremum over any reweighted loss on augmented samples. Inspired by adversarial training, we minimize this maximal expected loss (MMEL) and obtain a simple and interpretable closed-form solution: more attention should be paid to augmented samples with large loss values (i.e., harder examples). Minimizing this maximal expected loss enables the model to perform well under any reweighting strategy. The proposed method can generally be applied on top of any data augmentation methods. Experiments are conducted on both natural language understanding tasks with token-level data augmentation, and image classification tasks with commonly-used image augmentation techniques like random crop and horizontal flip. Empirical results show that the proposed method improves the generalization performance of the model.",データ拡張は、ディープニューラルネットワークの一般化を改善するための効果的な手法です。ただし、以前のデータ拡張方法では、通常、モデルへの個々の影響を考慮せずに、拡張されたサンプルを同等に扱います。これに対処するために、同じトレーニング例からの拡張サンプルについて、それらに異なる重みを割り当てることを提案します。増強されたサンプルの再重み付けされた損失の上限である最大期待損失を構築します。敵対的なトレーニングに触発されて、この最大期待損失（MMEL）を最小化し、単純で解釈可能な閉形式の解を取得します。大きな損失値を持つ拡張サンプル（つまり、より難しい例）にもっと注意を払う必要があります。この最大の期待損失を最小化することで、モデルはあらゆる再重み付け戦略の下でうまく機能することができます。提案された方法は、一般に、任意のデータ拡張方法の上に適用することができます。実験は、トークンレベルのデータ拡張を使用した自然言語理解タスクと、ランダムトリミングや水平反転などの一般的に使用される画像拡張技術を使用した画像分類タスクの両方で実施さ​​れます。経験的結果は、提案された方法がモデルの一般化性能を改善することを示しています。,6.67,
Identifying Physical Law of Hamiltonian Systems via Meta-Learning,"['Seungjun Lee', 'Haesang Yang', 'Woojae Seong']",https://openreview.net/forum?id=45NZvF1UHam,"Hamiltonian mechanics is an effective tool to represent many physical processes with concise yet well-generalized mathematical expressions. A well-modeled Hamiltonian makes it easy for researchers to analyze and forecast many related phenomena that are governed by the same physical law. However, in general, identifying a functional or shared expression of the Hamiltonian is very difficult. It requires carefully designed experiments and the researcher's insight that comes from years of experience. We propose that meta-learning algorithms can be potentially powerful data-driven tools for identifying the physical law governing Hamiltonian systems without any mathematical assumptions on the representation, but with observations from a set of systems governed by the same physical law. We show that a well meta-trained learner can identify the shared representation of the Hamiltonian by evaluating our method on several types of physical systems with various experimental settings.",ハミルトニアン力学は、簡潔でありながら一般化された数式で多くの物理プロセスを表現するための効果的なツールです。適切にモデル化されたハミルトニアンを使用すると、研究者は同じ物理法則に準拠する多くの関連する現象を簡単に分析および予測できます。ただし、一般に、ハミルトニアンの機能的または共有された表現を識別することは非常に困難です。それには、注意深く設計された実験と、長年の経験から得られる研究者の洞察が必要です。メタ学習アルゴリズムは、表現に関する数学的仮定なしで、同じ物理法則によって支配される一連のシステムからの観測を使用して、ハミルトン系を支配する物理法則を識別するための潜在的に強力なデータ駆動型ツールになる可能性があることを提案します。よくメタトレーニングされた学習者が、さまざまな実験設定でいくつかのタイプの物理システムでメソッドを評価することにより、ハミルトニアンの共有表現を識別できることを示します。,6.67,
Learning to Make Decisions via Submodular Regularization,"['Ayya Alieva', 'Aiden Aceves', 'Jialin Song', 'Stephen Mayo', 'Yisong Yue', 'Yuxin Chen']",https://openreview.net/forum?id=ac288vnG_7U,"Many sequential decision making tasks can be viewed as combinatorial optimization problems over a large number of actions. When the cost of evaluating an action is high, even a greedy algorithm, which iteratively picks the best action given the history, is prohibitive to run. In this paper, we aim to learn a greedy heuristic for sequentially selecting actions as a surrogate for invoking the expensive oracle when evaluating an action. In particular, we focus on a class of combinatorial problems that can be solved via submodular maximization (either directly on the objective function or via submodular surrogates). We introduce a data-driven optimization framework based on the submodular-norm loss, a novel loss function that encourages the resulting objective to exhibit diminishing returns. Our framework outputs a surrogate objective that is efficient to train, approximately submodular, and can be made permutation-invariant. The latter two properties allow us to prove strong approximation guarantees for the learned greedy heuristic. Furthermore, we show that our model can be easily integrated with modern deep imitation learning pipelines for sequential prediction tasks. We demonstrate the performance of our algorithm on a variety of batched and sequential optimization tasks, including set cover, active learning, and Bayesian optimization for protein engineering.",多くの順次意思決定タスクは、多数のアクションにわたる組み合わせ最適化の問題と見なすことができます。アクションを評価するコストが高い場合、履歴を指定して最適なアクションを繰り返し選択する欲張りアルゴリズムでさえ、実行するのは禁止されています。この論文では、アクションを評価するときに高価なオラクルを呼び出すための代理として、アクションを順次選択するための貪欲なヒューリスティックを学習することを目的としています。特に、劣モジュラ最大化を介して（目的関数に直接、または劣モジュラ代理を介して）解決できる組み合わせ問題のクラスに焦点を当てます。劣モジュラノルム損失に基づくデータ駆動型最適化フレームワークを紹介します。これは、結果として得られる目的が収穫逓減を示すように促す新しい損失関数です。私たちのフレームワークは、トレーニングに効率的で、ほぼ劣モジュラであり、順列不変にすることができる代理目的を出力します。後者の2つのプロパティにより、学習した欲張りヒューリスティックの強力な近似保証を証明できます。さらに、私たちのモデルは、順次予測タスクのための最新の深層模倣学習パイプラインと簡単に統合できることを示しています。集合被覆、能動学習、タンパク質工学のベイズ最適化など、さまざまなバッチおよび逐次最適化タスクでのアルゴリズムのパフォーマンスを示します。,6.67,
Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation,"['Justin Fu', 'Sergey Levine']",https://openreview.net/forum?id=FmMKSO4e8JK,"In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.",この作業では、固定されたポイントのセットでクエリのみが与えられた場合に関数を最大化する必要があるデータ駆動型最適化問題を検討します。この問題の設定は、材料、車両、ニューラルネットワークアーキテクチャの設計など、機能評価が複雑で費用のかかるプロセスである多くの分野で発生します。利用可能なデータは通常、入力の可能なスペースの小さな多様体のみをカバーするため、ナイーブオプティマイザーは推定モデルを簡単に利用できるため、主な課題は、不確実性と分布外の値について推論できるアルゴリズムを構築できることです。敵対的な入力を返します。不確実性と分布外の入力を処理するための原則的なアプローチを提供する正規化最尤（NML）推定量を活用することにより、MBO問題に取り組むことを提案します。標準的な定式化ではNMLは扱いにくいですが、大容量のニューラルネットワークモデルにメソッドをスケーリングできるようにする扱いやすい近似を提案します。私たちの方法は、化学、生物学、材料工学などのさまざまな分野で高次元の設計問題を効果的に最適化できることを示しています。,6.67,
A Block Minifloat Representation for Training Deep Neural Networks,"['Sean Fox', 'Seyedramin Rasoulinezhad', 'Julian Faraone', 'david boland', 'Philip Leong']",https://openreview.net/forum?id=6zaTwpNSsQ2,"Training Deep Neural Networks (DNN) with high efficiency can be difficult to achieve with native floating point representations and commercially available hardware. Specialized arithmetic with custom acceleration offers perhaps the most promising alternative. Ongoing research is trending towards narrow floating point representations, called minifloats, that pack more operations for a given silicon area and consume less power. In this paper, we introduce Block Minifloat (BM), a new spectrum of minifloat formats capable of training DNNs end-to-end with only 4-8 bit weight, activation and gradient tensors. While standard floating point representations have two degrees of freedom, via the exponent and mantissa, BM exposes the exponent bias as an additional field for optimization. Crucially, this enables training with fewer exponent bits, yielding dense integer-like hardware for fused multiply-add (FMA) operations. For ResNet trained on ImageNet, 6-bit BM achieves almost no degradation in floating point accuracy with FMA units that are $4.1\times(23.9\times)$ smaller and consume $2.3\times(16.1\times)$ less energy than FP8 (FP32). Furthermore, our 8-bit BM format matches floating-point accuracy while delivering a higher computational density and faster expected training times.",ネイティブの浮動小数点表現と市販のハードウェアでは、高効率でディープニューラルネットワーク（DNN）をトレーニングするのは難しい場合があります。カスタムアクセラレーションを使用した特殊な演算は、おそらく最も有望な代替手段を提供します。進行中の研究は、ミニフロートと呼ばれる狭い浮動小数点表現に向かっています。これは、特定のシリコン領域に対してより多くの操作をパックし、より少ない電力を消費します。このホワイトペーパーでは、ブロックミニフロート（BM）を紹介します。これは、わずか4〜8ビットの重み、アクティブ化、および勾配テンソルでDNNをエンドツーエンドでトレーニングできる新しいミニフロート形式のスペクトルです。標準の浮動小数点表現には、指数と仮数を介して2つの自由度がありますが、BMは、最適化のための追加フィールドとして指数バイアスを公開します。重要なことに、これにより、より少ない指数ビットでのトレーニングが可能になり、融合積和（FMA）演算用の高密度の整数のようなハードウェアが生成されます。 ImageNetでトレーニングされたResNetの場合、6ビットBMは、FP8（FP32）よりも4.1（23.9）小さく、消費エネルギーが2.3（16.1）少ないFMAユニットで、浮動小数点精度の低下をほとんど達成しません。さらに、当社の8ビットBM形式は浮動小数点精度と一致し、より高い計算密度とより速い予想トレーニング時間を提供します。,6.67,
Efficient Conformal Prediction via Cascaded Inference with Expanded Admission,"['Adam Fisch', 'Tal Schuster', 'Tommi S. Jaakkola', 'Regina Barzilay']",https://openreview.net/forum?id=tnSo6VRLmT,"In this paper, we present a novel approach for conformal prediction (CP), in which we aim to identify a set of promising prediction candidates---in place of a single prediction. This set is guaranteed to contain a correct answer with high probability, and is well-suited for many open-ended classification tasks. In the standard CP paradigm, the predicted set can often be unusably large and also costly to obtain. This is particularly pervasive in settings where the correct answer is not unique, and the number of total possible answers is high. We first expand the CP correctness criterion to allow for additional, inferred ""admissible"" answers, which can substantially reduce the size of the predicted set while still providing valid performance guarantees. Second, we amortize costs by conformalizing prediction cascades, in which we aggressively prune implausible labels early on by using progressively stronger classifiers---again, while still providing valid performance guarantees. We demonstrate the empirical effectiveness of our approach for multiple applications in natural language processing and computational chemistry for drug discovery.",この論文では、単一の予測の代わりに有望な予測候補のセットを特定することを目的とした、共形予測（CP）の新しいアプローチを紹介します。このセットには、高い確率で正解が含まれることが保証されており、多くのオープンエンドの分類タスクに適しています。標準のCPパラダイムでは、予測されたセットは多くの場合、使用できないほど大きく、取得にコストがかかる可能性があります。これは、正解が一意ではなく、可能な回答の総数が多い設定で特によく見られます。最初にCPの正しさの基準を拡張して、追加の推測された「許容可能な」回答を可能にします。これにより、有効なパフォーマンス保証を提供しながら、予測セットのサイズを大幅に削減できます。次に、予測カスケードをコンフォーマル化することでコストを償却します。このカスケードでは、有効なパフォーマンス保証を提供しながら、段階的に強力な分類子を使用して、妥当性の低いラベルを早期に積極的に削除します。自然言語処理および創薬のための計算化学における複数のアプリケーションに対する私たちのアプローチの経験的有効性を示します。,6.67,
A unifying view on implicit bias in training linear neural networks,"['Chulhee Yun', 'Shankar Krishnan', 'Hossein Mobahi']",https://openreview.net/forum?id=ZsZM-4iMQkH,"We study the implicit bias of gradient flow (i.e., gradient descent with infinitesimal step size) on linear neural network training. We propose a tensor formulation of neural networks that includes fully-connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks. With this formulation, we can identify the convergence direction of the network parameters as singular vectors of a tensor defined by the network. For $L$-layer linear tensor networks that are orthogonally decomposable, we show that gradient flow on separable classification finds a stationary point of the $\ell_{2/L}$ max-margin problem in a ""transformed"" input space defined by the network. For underdetermined regression, we prove that gradient flow finds a global minimum which minimizes a norm-like function that interpolates between weighted $\ell_1$ and $\ell_2$ norms in the transformed input space. Our theorems subsume existing results in the literature while removing standard convergence assumptions. We also provide experiments that corroborate our analysis.",線形ニューラルネットワークトレーニングで勾配流の暗黙のバイアス（つまり、微小ステップサイズの勾配降下）を研究します。特殊なケースとして、完全接続、対角、畳み込みネットワークを含むニューラルネットワークのテンソル定式化を提案し、線形テンソルネットワークと呼ばれる定式化の線形バージョンを調査します。この定式化により、ネットワークパラメータの収束方向をネットワークによって定義されたテンソルの特異ベクトルとして特定できます。直交分解可能なL層線形テンソルネットワークの場合、分離可能な分類の勾配流が、ネットワークによって定義された「変換された」入力空間でl（2 / L）最大マージン問題の停留点を見つけることを示します。劣決定回帰の場合、勾配フローが、変換された入力空間の重み付きl1ノルムとl2ノルムの間を補間するノルムのような関数を最小化するグローバル最小値を見つけることを証明します。私たちの定理は、標準的な収束の仮定を削除しながら、文献の既存の結果を包含しています。また、分析を裏付ける実験も提供しています。,6.67,https://d3i71xaburhd42.cloudfront.net/f831c0695b211798235a1ed0d04ff0d98ce3f0be/2-Figure1-1.png
Learning with Instance-Dependent Label Noise: A Sample Sieve Approach,"['Hao Cheng', 'Zhaowei Zhu', 'Xingyu Li', 'Yifei Gong', 'Xing Sun', 'Yang Liu']",https://openreview.net/forum?id=2VXyy9mIyU3,"Human-annotated labels are often prone to noise, and the presence of such noise will degrade the performance of the resulting deep neural network (DNN) models. Much of the literature (with several recent exceptions) of learning with noisy labels focuses on the case when the label noise is independent from features. Practically, annotations errors tend to be instance-dependent and often depend on the difficulty levels of recognizing a certain task. Applying existing results from instance-independent settings would require a significant amount of estimation of noise rates. Therefore, learning with instance-dependent label noise remains a challenge. In this paper, we propose CORES$^{2}$ (COnfidence REgularized Sample Sieve), which progressively sieves out corrupted samples. The implementation of CORES$^{2}$  does not require specifying noise rates and yet we are able to provide theoretical guarantees of CORES$^{2}$ in filtering out the corrupted examples. This high-quality sample sieve allows us to treat clean examples and the corrupted ones separately in training a DNN solution, and such a separation is shown to be advantageous in the instance-dependent noise setting. We demonstrate the performance of CORES$^{2}$ on CIFAR10 and CIFAR100 datasets with synthetic instance-dependent label noise and Clothing1M with real-world human noise. As of independent interests, our sample sieve provides a generic machinery for anatomizing noisy dataset and provides flexible interface for various robust training techniques to further improve the performance.",人間が注釈を付けたラベルはノイズが発生しやすいことが多く、そのようなノイズが存在すると、結果として得られるディープニューラルネットワーク（DNN）モデルのパフォーマンスが低下します。ノイズの多いラベルを使用した学習に関する文献の多く（最近のいくつかの例外を除く）は、ラベルのノイズが特徴から独立している場合に焦点を当てています。実際には、注釈エラーはインスタンスに依存する傾向があり、特定のタスクを認識する難易度に依存することがよくあります。インスタンスに依存しない設定からの既存の結果を適用するには、かなりの量のノイズ率の推定が必要になります。したがって、インスタンスに依存するラベルノイズを使用した学習は依然として課題です。この論文では、破損したサンプルを徐々にふるいにかけるCORES2（COnfidence REgularized Sample Sieve）を提案します。 CORES2の実装では、ノイズレートを指定する必要はありませんが、破損した例を除外する際にCORES2の理論的保証を提供できます。この高品質のサンプルふるいにより、DNNソリューションのトレーニングでクリーンな例と破損した例を別々に処理できます。このような分離は、インスタンスに依存するノイズ設定で有利であることが示されています。合成インスタンス依存のラベルノイズを使用したCIFAR10およびCIFAR100データセットと、実際の人間のノイズを使用したClothing1MでのCORES2のパフォーマンスを示します。独立した関心として、私たちのサンプルふるいは、ノイズの多いデータセットを解剖するための一般的な機械を提供し、パフォーマンスをさらに向上させるためのさまざまな堅牢なトレーニング手法のための柔軟なインターフェイスを提供します。,6.67,https://d3i71xaburhd42.cloudfront.net/599ed9357448d8c55e2dc7f4f12224d5c6dd1fcc/4-Figure1-1.png
Understanding and Improving Lexical Choice in Non-Autoregressive Translation,"['Liang Ding', 'Longyue Wang', 'Xuebo Liu', 'Derek F. Wong', 'Dacheng Tao', 'Zhaopeng Tu']",https://openreview.net/forum?id=ZTFeSBIX9C,"Knowledge distillation (KD) is essential for training non-autoregressive translation (NAT) models by reducing the complexity of the raw data with an autoregressive teacher model. In this study, we empirically show that as a side effect of this training, the lexical choice errors on low-frequency words are propagated to the NAT model from the teacher model. To alleviate this problem, we propose to expose the raw data to NAT models to restore the useful information of low-frequency words, which are missed in the distilled data. To this end, we introduce an extra Kullback-Leibler divergence term derived by comparing the lexical choice of NAT model and that embedded in the raw data. Experimental results across language pairs and model architectures demonstrate the effectiveness and universality of the proposed approach.  Extensive analyses confirm our claim that our approach improves performance by reducing the lexical choice errors on low-frequency words.  Encouragingly, our approach pushes the SOTA NAT performance on the WMT14 English-German and WMT16 Romanian-English datasets up to 27.8 and 33.8 BLEU points, respectively. The codes and models will be released.",知識蒸留（KD）は、自己回帰教師モデルを使用して生データの複雑さを軽減することにより、非自己回帰翻訳（NAT）モデルをトレーニングするために不可欠です。この研究では、このトレーニングの副作用として、低頻度の単語の字句選択エラーが教師モデルからNATモデルに伝播されることを経験的に示しています。この問題を軽減するために、生データをNATモデルに公開して、抽出されたデータでは欠落している低頻度の単語の有用な情報を復元することを提案します。この目的のために、NATモデルの字句の選択と生データに埋め込まれているものを比較することによって導出された追加のカルバックライブラー発散項を導入します。言語ペアとモデルアーキテクチャ全体の実験結果は、提案されたアプローチの有効性と普遍性を示しています。広範な分析により、私たちのアプローチが低頻度の単語の字句選択エラーを減らすことによってパフォーマンスを改善するという私たちの主張が確認されます。心強いことに、私たちのアプローチは、WMT14英語-ドイツ語およびWMT16ルーマニア語-英語データセットでのSOTA NATパフォーマンスを、それぞれ27.8および33.8BLEUポイントまで押し上げます。コードとモデルがリリースされます。,6.67,
Varying Coefficient Neural Network with Functional Targeted Regularization for Estimating Continuous Treatment Effects,"['Lizhen Nie', 'Mao Ye', 'qiang liu', 'Dan Nicolae']",https://openreview.net/forum?id=RmB-88r9dL,"Motivated by the rising abundance of observational data with continuous treatments, we investigate the problem of estimating the average dose-response curve (ADRF). Available parametric methods are limited in their model space, and previous attempts in leveraging neural network to enhance model expressiveness relied on partitioning continuous treatment into blocks and using separate heads for each block; this however produces in practice discontinuous ADRFs. Therefore, the question of how to adapt the structure and training of neural network to estimate ADRF remains open. This paper makes two important contributions. First, we propose a novel varying coefficient neural network (VCNet) that improves model expressiveness while preserving continuity of the estimated ADRF. Second, to improve finite sample performance, we generalize targeted regularization to obtain a doubly robust estimator of the whole ADRF curve.",継続的な治療による観察データの増加に動機付けられて、平均用量反応曲線（ADRF）を推定する問題を調査します。利用可能なパラメトリック手法はモデル空間で制限されており、ニューラルネットワークを活用してモデルの表現力を高める以前の試みは、連続治療をブロックに分割し、ブロックごとに別々のヘッドを使用することに依存していました。ただし、これにより実際には不連続なADRFが生成されます。したがって、ADRFを推定するためにニューラルネットワークの構造とトレーニングをどのように適応させるかという問題は未解決のままです。この論文は2つの重要な貢献をしています。まず、推定されたADRFの連続性を維持しながら、モデルの表現力を向上させる新しい可変係数ニューラルネットワーク（VCNet）を提案します。次に、有限サンプルのパフォーマンスを向上させるために、ターゲットを絞った正則化を一般化して、ADRF曲線全体の二重にロバストな推定量を取得します。,6.67,
Autoregressive Dynamics Models for Offline Policy Evaluation and Optimization,"['Michael R Zhang', 'Thomas Paine', 'Ofir Nachum', 'Cosmin Paduraru', 'George Tucker', 'ziyu wang', 'Mohammad Norouzi']",https://openreview.net/forum?id=kmqjgSNXby,"Standard dynamics models for continuous control make use of feedforward computation to predict the conditional distribution of next state and reward given current state and action using a multivariate Gaussian with a diagonal covariance structure. This modeling choice assumes that different dimensions of the next state and reward are conditionally independent given the current state and action and} may be driven by the fact that fully observable physics-based simulation environments entail deterministic transition dynamics. In this paper, we challenge this conditional independence assumption and propose a family of expressive autoregressive dynamics models that generate different dimensions of the next state and reward sequentially conditioned on previous dimensions. We demonstrate that autoregressive dynamics models indeed outperform standard feedforward models in log-likelihood on heldout transitions. Furthermore, we compare different model-based and model-free off-policy evaluation (OPE) methods on RL Unplugged, a suite of offline MuJoCo datasets, and find that autoregressive dynamics models consistently outperform all baselines, achieving a new state-of-the-art. Finally, we show that autoregressive dynamics models are useful for offline policy optimization by serving as a way to enrich the replay buffer through data augmentation and improving performance using model-based planning.

",連続制御の標準ダイナミクスモデルは、フィードフォワード計算を利用して、次の状態の条件付き分布を予測し、対角共分散構造を持つ多変量ガウスを使用して、現在の状態とアクションが与えられた場合に報酬を与えます。このモデリングの選択は、現在の状態とアクションを考えると、次の状態と報酬のさまざまな次元が条件付きで独立していることを前提としています。}完全に観察可能な物理ベースのシミュレーション環境は、決定論的な遷移ダイナミクスを伴うという事実によって駆動される可能性があります。この論文では、この条件付き独立性の仮定に挑戦し、次の状態のさまざまな次元を生成し、前の次元に順次条件付けられた報酬を与える表現型自己回帰ダイナミクスモデルのファミリーを提案します。自己回帰ダイナミクスモデルは、ホールドアウト遷移で対数尤度で標準フィードフォワードモデルよりも実際に優れていることを示します。さらに、オフラインMuJoCoデータセットのスイートであるRL Unpluggedでさまざまなモデルベースおよびモデルフリーのオフポリシー評価（OPE）手法を比較し、自己回帰ダイナミクスモデルがすべてのベースラインを一貫して上回り、新しい最先端技術を実現していることを確認します。 -アート。最後に、自己回帰ダイナミクスモデルが、データの拡張を通じて再生バッファーを強化し、モデルベースの計画を使用してパフォーマンスを向上させる方法として機能することにより、オフラインポリシーの最適化に役立つことを示します。,6.67,
Online Adversarial Purification based on Self-supervised Learning,"['Changhao Shi', 'Chester Holtz', 'Gal Mishne']",https://openreview.net/forum?id=_i3ASPp12WS,"Deep neural networks are known to be vulnerable to adversarial examples, where a perturbation in the input space leads to an amplified shift in the latent network representation. In this paper, we combine canonical supervised learning with self-supervised representation learning, and present Self-supervised Online Adversarial Purification (SOAP), a novel defense strategy that uses a self-supervised loss to purify adversarial examples at test-time. Our approach leverages the label-independent nature of self-supervised signals and counters the adversarial perturbation with respect to the self-supervised tasks. SOAP yields competitive robust accuracy against state-of-the-art adversarial training and purification methods, with considerably less training complexity. In addition, our approach is robust even when adversaries are given the knowledge of the purification defense strategy. To the best of our knowledge, our paper is the first that generalizes the idea of using self-supervised signals to perform online test-time purification.",ディープニューラルネットワークは、入力空間の摂動が潜在的なネットワーク表現の増幅されたシフトにつながる敵対的な例に対して脆弱であることが知られています。この論文では、正規の教師あり学習と自己教師あり表現学習を組み合わせ、自己教師あり損失を使用してテスト時に敵対者の例を浄化する新しい防御戦略である自己教師ありオンライン敵対的浄化（SOAP）を紹介します。私たちのアプローチは、自己監視信号のラベルに依存しない性質を活用し、自己監視タスクに関する敵対的な摂動に対抗します。 SOAPは、トレーニングの複雑さを大幅に軽減しながら、最先端の敵対的なトレーニングおよび浄化方法に対して競争力のある堅牢な精度を実現します。さらに、敵が浄化防御戦略の知識を与えられた場合でも、私たちのアプローチは堅牢です。私たちの知る限り、私たちの論文は、自己監視信号を使用してオンラインテスト時間の浄化を実行するという考えを一般化した最初の論文です。,6.67,
Differentiable Segmentation of Sequences,"['Erik Scharwächter', 'Jonathan Lennartz', 'Emmanuel Müller']",https://openreview.net/forum?id=4T489T4yav,"Segmented models are widely used to describe non-stationary sequential data with discrete change points. Their estimation usually requires solving a mixed discrete-continuous optimization problem, where the segmentation is the discrete part and all other model parameters are continuous. A number of estimation algorithms have been developed that are highly specialized for their specific model assumptions. The dependence on non-standard algorithms makes it hard to integrate segmented models in state-of-the-art deep learning architectures that critically depend on gradient-based optimization techniques. In this work, we formulate a relaxed variant of segmented models that enables joint estimation of all model parameters, including the segmentation, with gradient descent. We build on recent advances in learning continuous warping functions and propose a novel family of warping functions based on the two-sided power (TSP) distribution. TSP-based warping functions are differentiable, have simple closed-form expressions, and can represent segmentation functions exactly. Our formulation includes the important class of segmented generalized linear models as a special case, which makes it highly versatile. We use our approach to model the spread of COVID-19 with Poisson regression, apply it on a change point detection task, and learn classification models with concept drift. The experiments show that our approach effectively learns all these tasks with standard algorithms for gradient descent.",セグメント化されたモデルは、離散的な変化点を持つ非定常シーケンシャルデータを記述するために広く使用されています。それらの推定には通常、セグメンテーションが離散部分であり、他のすべてのモデルパラメーターが連続である混合離散連続最適化問題を解く必要があります。特定のモデルの仮定に高度に特化した多くの推定アルゴリズムが開発されています。非標準アルゴリズムへの依存により、セグメント化されたモデルを、勾配ベースの最適化手法に大きく依存する最先端の深層学習アーキテクチャに統合することが困難になります。この作業では、セグメント化を含むすべてのモデルパラメータの最急降下法による共同推定を可能にする、セグメント化されたモデルの緩和されたバリアントを作成します。連続ワーピング関数の学習における最近の進歩に基づいて、両側パワー（TSP）分布に基づくワーピング関数の新しいファミリを提案します。 TSPベースのワーピング関数は微分可能であり、単純な閉形式の式を持ち、セグメンテーション関数を正確に表すことができます。私たちの定式化には、特別な場合として、セグメント化された一般化線形モデルの重要なクラスが含まれているため、非常に用途が広くなっています。ポアソン回帰を使用してCOVID-19の広がりをモデル化し、変化点検出タスクに適用して、概念ドリフトを使用した分類モデルを学習するために、私たちのアプローチを使用します。実験は、私たちのアプローチが勾配降下法の標準アルゴリズムを使用してこれらすべてのタスクを効果的に学習することを示しています。,6.67,
R-GAP: Recursive Gradient Attack on Privacy,"['Junyi Zhu', 'Matthew B. Blaschko']",https://openreview.net/forum?id=RSU17UoKfJF,"Federated learning frameworks have been regarded as a promising approach to break the dilemma between demands on privacy and the promise of learning from large collections of distributed data. Many such frameworks only ask collaborators to share their local update of a common model, i.e. gradients with respect to locally stored data, instead of exposing their raw data to other collaborators. However, recent optimization-based gradient attacks show that raw data can often be accurately recovered from gradients. It has been shown that minimizing the Euclidean distance between true gradients and those calculated from estimated data is often effective in fully recovering private data. However, there is a fundamental lack of theoretical understanding of how and when gradients can lead to unique recovery of original data. Our research fills this gap by providing a closed-form recursive procedure to recover data from gradients in deep neural networks. We name it Recursive Gradient Attack on Privacy (R-GAP). Experimental results demonstrate that R-GAP  works as well as or even better than optimization-based approaches at a fraction of the computation under certain conditions. Additionally, we propose a Rank Analysis method, which can be used to estimate the risk of gradient attacks inherent in certain network architectures, regardless of whether an optimization-based or closed-form-recursive attack is used. Experimental results demonstrate the utility of the rank analysis towards improving the network's security. Source code is available for download from https://github.com/JunyiZhu-AI/R-GAP.",統合学習フレームワークは、プライバシーの要求と分散データの大規模なコレクションからの学習の約束との間のジレンマを打破するための有望なアプローチと見なされてきました。このようなフレームワークの多くは、生データを他の共同編集者に公開するのではなく、共同編集者に共通モデルのローカル更新、つまりローカルに保存されたデータに関する勾配を共有するように要求するだけです。ただし、最近の最適化ベースの勾配攻撃は、生データが勾配から正確に復元できることが多いことを示しています。真の勾配と推定データから計算された勾配との間のユークリッド距離を最小化することは、プライベートデータを完全に回復するのにしばしば効果的であることが示されています。ただし、勾配が元のデータの一意の回復につながる可能性がある方法と時期についての理論的な理解は根本的に不足しています。私たちの研究は、ディープニューラルネットワークの勾配からデータを回復するための閉じた形式の再帰的手順を提供することにより、このギャップを埋めます。これをRecursiveGradient Attack on Privacy（R-GAP）と名付けます。実験結果は、R-GAPが、特定の条件下での計算の一部で、最適化ベースのアプローチと同等またはそれ以上に機能することを示しています。さらに、最適化ベースの攻撃と閉じた形式の再帰的攻撃のどちらが使用されているかに関係なく、特定のネットワークアーキテクチャに固有の勾配攻撃のリスクを推定するために使用できるランク分析方法を提案します。実験結果は、ネットワークセキュリティの向上に向けたランク分析の有用性を示しています。ソースコードはhttps://github.com/JunyiZhu-AI/R-GAPからダウンロードできます。,6.67,
You Only Need Adversarial Supervision for Semantic Image Synthesis,"['Edgar Schönfeld', 'Vadim Sushko', 'Dan Zhang', 'Juergen Gall', 'Bernt Schiele', 'Anna Khoreva']",https://openreview.net/forum?id=yvQKLaqNE6M,"Despite their recent successes, GAN models for semantic image synthesis still suffer from poor image quality when trained with only adversarial supervision. Historically, additionally employing the VGG-based perceptual loss has helped to overcome this issue, significantly improving the synthesis quality, but at the same time limiting the progress of GAN models for semantic image synthesis. In this work, we propose a novel, simplified GAN model, which needs only adversarial supervision to achieve high quality results. We re-design the discriminator as a semantic segmentation network, directly using the given semantic label maps as the ground truth for training. By providing stronger supervision to the discriminator as well as to the generator through spatially- and semantically-aware discriminator feedback, we are able to synthesize images of higher fidelity with better alignment to their input label maps, making the use of the perceptual loss superfluous. Moreover, we enable high-quality multi-modal image synthesis through global and local sampling of a 3D noise tensor injected into the generator, which allows complete or partial image change. We show that images synthesized by our model are more diverse and follow the color and texture distributions of real images more closely. We achieve an average improvement of $6$ FID and $5$ mIoU points over the state of the art across different datasets using only adversarial supervision.",最近の成功にもかかわらず、セマンティック画像合成のGANモデルは、敵対的監視のみでトレーニングした場合、依然として画質が低下します。歴史的に、VGGベースの知覚損失を追加で採用することで、この問題を克服し、合成品質を大幅に向上させると同時に、セマンティック画像合成のGANモデルの進歩を制限してきました。この作業では、高品質の結果を達成するために敵対的監視のみを必要とする、斬新で単純化されたGANモデルを提案します。与えられたセマンティックラベルマップをトレーニングのグラウンドトゥルースとして直接使用して、ディスクリミネーターをセマンティックセグメンテーションネットワークとして再設計します。空間的および意味的に認識されたディスクリミネーターフィードバックを通じて、ディスクリミネーターとジェネレーターに強力な監視を提供することにより、入力ラベルマップとの整合性が高く、知覚損失を不必要に利用して、より忠実な画像を合成できます。さらに、ジェネレーターに注入された3Dノイズテンソルのグローバルおよびローカルサンプリングを通じて高品質のマルチモーダル画像合成を可能にし、完全または部分的な画像変更を可能にします。モデルによって合成された画像はより多様であり、実際の画像の色とテクスチャの分布により厳密に従うことを示します。敵対的な監視のみを使用して、さまざまなデータセット全体で最先端技術よりも平均6FIDおよび5mIoUポイントの改善を達成しています。,6.67,
Learning Value Functions in Deep Policy Gradients using Residual Variance,"['Yannis Flet-Berliac', 'reda ouhamma', 'odalric-ambrym maillard', 'Philippe Preux']",https://openreview.net/forum?id=NX1He-aFO_F,"Policy gradient algorithms have proven to be successful in diverse decision making and control tasks. However, these methods suffer from high sample complexity and instability issues. In this paper, we address these challenges by providing a different approach for training the critic in the actor-critic framework. Our work builds on recent studies indicating that traditional actor-critic algorithms do not succeed in fitting the true value function, calling for the need to identify a better objective for the critic. In our method, the critic uses a new state-value (resp. state-action-value) function approximation that learns the value of the states (resp. state-action pairs) relative to their mean value rather than the absolute value as in conventional actor-critic. We prove the theoretical consistency of the new gradient estimator and observe dramatic empirical improvement across a variety of continuous control tasks and algorithms. Furthermore, we validate our method in tasks with sparse rewards, where we provide experimental evidence and theoretical insights.",ポリシー勾配アルゴリズムは、さまざまな意思決定および制御タスクで成功することが証明されています。ただし、これらの方法には、サンプルの複雑さと不安定性の問題があります。この論文では、アクター批評家の枠組みで批評家を訓練するための異なるアプローチを提供することにより、これらの課題に対処します。私たちの仕事は、伝統的な俳優批評家のアルゴリズムが真の価値関数の適合に成功しないことを示し、批評家のより良い目的を特定する必要があることを示す最近の研究に基づいています。私たちの方法では、批評家は新しい状態値（または状態-アクション-値）関数近似を使用して、絶対値ではなく平均値に対する状態（または状態-アクションのペア）の値を学習します。従来の俳優批評家。新しい勾配推定器の理論的一貫性を証明し、さまざまな連続制御タスクとアルゴリズムにわたって劇的な経験的改善を観察します。さらに、実験的証拠と理論的洞察を提供する、報酬がまばらなタスクでメソッドを検証します。,6.67,
LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition,"['Valeriia Cherepanova', 'Micah Goldblum', 'Harrison Foley', 'Shiyuan Duan', 'John P Dickerson', 'Gavin Taylor', 'Tom Goldstein']",https://openreview.net/forum?id=hJmtwocEqzc,"Facial recognition systems are increasingly deployed by private corporations, government agencies, and contractors for consumer services and mass surveillance programs alike.  These systems are typically built by scraping social media profiles for user images.  Adversarial perturbations have been proposed for bypassing facial recognition systems.  However, existing methods fail on full-scale systems and commercial APIs.  We develop our own adversarial filter that accounts for the entire image processing pipeline and is demonstrably effective against industrial-grade pipelines that include face detection and large scale databases.  Additionally, we release an easy-to-use webtool that significantly degrades the accuracy of Amazon Rekognition and the Microsoft Azure Face Recognition API, reducing the accuracy of each to below 1%.",顔認識システムは、消費者サービスや大量監視プログラムのために、民間企業、政府機関、請負業者によってますます展開されています。これらのシステムは通常、ユーザー画像のソーシャルメディアプロファイルをスクレイピングすることによって構築されます。顔認識システムをバイパスするために、敵対的な摂動が提案されてきた。ただし、既存の方法は、本格的なシステムや商用APIでは失敗します。私たちは、画像処理パイプライン全体を占める独自の敵対的フィルターを開発し、顔検出や大規模データベースを含む産業グレードのパイプラインに対して明らかに効果的です。さらに、AmazonRekognitionとMicrosoftAzure Face Recognition APIの精度を大幅に低下させ、それぞれの精度を1未満に下げる、使いやすいWebツールをリリースします。,6.67,
Information Laundering for Model Privacy,"['Xinran Wang', 'Yu Xiang', 'Jun Gao', 'Jie Ding']",https://openreview.net/forum?id=dyaIRud1zXg,"In this work, we propose information laundering, a novel framework for enhancing model privacy. Unlike data privacy that concerns the protection of raw data information, model privacy aims to protect an already-learned model that is to be deployed for public use. The private model can be obtained from general learning methods, and its deployment means that it will return a deterministic or random response for a given input query. An information-laundered model consists of probabilistic components that deliberately maneuver the intended input and output for queries to the model, so the model's adversarial acquisition is less likely. Under the proposed framework, we develop an information-theoretic principle to quantify the fundamental tradeoffs between model utility and privacy leakage and derive the optimal design.",この作業では、モデルのプライバシーを強化するための新しいフレームワークである情報ロンダリングを提案します。生データ情報の保護に関係するデータプライバシーとは異なり、モデルプライバシーは、公用に展開される学習済みのモデルを保護することを目的としています。プライベートモデルは、一般的な学習方法から取得できます。その展開は、特定の入力クエリに対して決定論的またはランダムな応答を返すことを意味します。情報洗浄モデルは、モデルへのクエリの意図された入力と出力を意図的に操作する確率的コンポーネントで構成されているため、モデルの敵対的獲得の可能性は低くなります。提案されたフレームワークの下で、モデルの効用とプライバシーの漏えいの間の基本的なトレードオフを定量化し、最適な設計を導き出すための情報理論の原則を開発します。,6.67,https://d3i71xaburhd42.cloudfront.net/d2212a1c37fad937fe807dbbb44fe78396ddfd3a/2-Figure1-1.png
SEDONA: Search for Decoupled Neural Networks toward Greedy Block-wise Learning,"['Myeongjang Pyeon', 'Jihwan Moon', 'Taeyoung Hahn', 'Gunhee Kim']",https://openreview.net/forum?id=XLfdzwNKzch,"Backward locking and update locking are well-known sources of inefficiency in backpropagation that prevent from concurrently updating layers. Several works have recently suggested using local error signals to train network blocks asynchronously to overcome these limitations. However, they often require numerous iterations of trial-and-error to find the best configuration for local training, including how to decouple network blocks and which auxiliary networks to use for each block. In this work, we propose a differentiable search algorithm named SEDONA to automate this process. Experimental results show that our algorithm can consistently discover transferable decoupled architectures for VGG and ResNet variants, and significantly outperforms the ones trained with end-to-end backpropagation and other state-of-the-art greedy-leaning methods in CIFAR-10, Tiny-ImageNet and ImageNet. Thanks to improved parallelism by local training, we also report up to 2× speedup over backpropagation in total training time.",後方ロックと更新ロックは、レイヤーを同時に更新することを妨げるバックプロパゲーションの非効率性のよく知られた原因です。最近、いくつかの研究で、ローカルエラー信号を使用してネットワークブロックを非同期にトレーニングし、これらの制限を克服することが提案されています。ただし、ネットワークブロックを分離する方法や、各ブロックに使用する補助ネットワークなど、ローカルトレーニングに最適な構成を見つけるには、試行錯誤を何度も繰り返す必要があります。この作業では、このプロセスを自動化するために、SEDONAという名前の微分可能な検索アルゴリズムを提案します。実験結果は、私たちのアルゴリズムがVGGおよびResNetバリアントの転送可能な分離アーキテクチャを一貫して検出でき、CIFAR-10、Tinyのエンドツーエンドバックプロパゲーションおよびその他の最先端の貪欲学習手法でトレーニングされたアーキテクチャを大幅に上回っていることを示しています。 -ImageNetおよびImageNet。ローカルトレーニングによる並列処理の改善のおかげで、合計トレーニング時間でバックプロパゲーションよりも最大2スピードアップしたことも報告しています。,6.67,
SEED: Self-supervised Distillation For Visual Representation,"['Zhiyuan Fang', 'Jianfeng Wang', 'Lijuan Wang', 'Lei Zhang', 'Yezhou Yang', 'Zicheng Liu']",https://openreview.net/forum?id=AHm3dbp7D1D,"This paper is concerned with self-supervised learning for small models. The problem is motivated by our empirical studies that while the widely used contrastive self-supervised learning method has shown great progress on large model training, it does not work well for small models. To address this problem, we propose a new learning paradigm, named $\textbf{SE}$lf-Sup$\textbf{E}$rvised $\textbf{D}$istillation (${\large S}$EED), where we leverage a larger network (as Teacher) to transfer its representational knowledge into a smaller architecture (as Student) in a self-supervised fashion. Instead of directly learning from unlabeled data, we train a student encoder to mimic the similarity score distribution inferred by a teacher over a set of instances. We show that ${\large S}$EED dramatically boosts the performance of small networks on downstream tasks. Compared with self-supervised baselines, ${\large S}$EED improves the top-1 accuracy from 42.2% to 67.6% on EfficientNet-B0 and from 36.3% to 68.2% on MobileNet-v3-Large on the ImageNet-1k dataset. ",この論文は、小さなモデルの自己教師あり学習に関するものです。この問題は、広く使用されている対照的な自己教師あり学習方法が大規模モデルのトレーニングで大きな進歩を示している一方で、小規模モデルではうまく機能しないという実証研究によって動機付けられています。この問題に対処するために、SElf-SupErvised Distillation（$ {\ large S} $ EED）という名前の新しい学習パラダイムを提案します。このパラダイムでは、（教師として）より大きなネットワークを活用して、その表現知識を（学生として）より小さなアーキテクチャに転送します。 ）自己管理方式で。ラベルのないデータから直接学習する代わりに、一連のインスタンスで教師が推測した類似度スコアの分布を模倣するように学生エンコーダーをトレーニングします。 $ {\ large S} $ EEDが、ダウンストリームタスクでの小規模ネットワークのパフォーマンスを劇的に向上させることを示します。自己教師ありベースラインと比較して、$ {\ large S} $ EEDはトップ1の精度を42.2から向上させます,6.67,https://d3i71xaburhd42.cloudfront.net/b46a3fa8b93037964c881e986d7f3e959f8617a7/1-Figure1-1.png
"Physics-aware, probabilistic model order reduction with guaranteed stability","['Sebastian Kaltenbach', 'Phaedon Stelios Koutsourelakis']",https://openreview.net/forum?id=vyY0jnWG-tK,"Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.
We target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.
Approaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. 
The generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.
We demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.",高次元、細粒度、マルチスケール動的システムからの（少量の）時系列データが与えられた場合、細粒度を予測する効果的で低次元の粗粒度動的モデルを学習するための生成フレームワークを提案します。グレインシステムの長期的な進化だけでなく、さまざまな初期条件下でのその動作の進化。物理的アプリケーション（分子動力学、エージェントベースモデルなど）で発生する細粒度モデルを対象としています。そのダイナミクスは非常に非定常ですが、平衡への移行は、ブルートではほとんどアクセスできない未知の遅いプロセスによって支配されます。力のシミュレーション。ドメイン知識に基づくアプローチは、時間的に遅い機能を特定する際に物理的な洞察に大きく依存しており、学習したダイナミクスの長期的な安定性を強制することができません。一方、純粋に統計的なフレームワークは解釈可能性に欠けており、ドメイン知識を注入できないため、大量の高価なシミュレーションデータ（長くて複数の軌道）に依存しています。提案された生成フレームワークは、潜在的で遅いプロセスの複素平面での柔軟な事前確率と、データへの依存を減らし、誘導バイアスを吹き込む物理学に動機付けられた潜在変数の中間層を採用することによって、前述の目的を達成します。既存のスキームとは対照的に、それは、きめ細かい記述からの射影演算子の事前定義を必要とせず、次元削減とモデル推定のタスクに同時に対処します。トレーニングデータに含まれていない現象の確率的で長期的な予測が生成される粒子ダイナミクスのマルチスケール物理システムで、その有効性と精度を示します。,6.6,https://d3i71xaburhd42.cloudfront.net/7869928bc7c5809b05760367acc2eb5fd2a0e8c7/2-Figure1-1.png
Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data,"['Jonathan Pilault', 'Amine El hattami', 'Christopher Pal']",https://openreview.net/forum?id=de11dbHzAMF,"Multi-Task Learning (MTL) networks have emerged as a promising method for transferring learned knowledge across different tasks. However, MTL must deal with challenges such as: overfitting to low resource tasks, catastrophic forgetting, and negative task transfer, or learning interference. Often, in Natural Language Processing (NLP), a separate model per task is needed to obtain the best performance. However, many fine-tuning approaches are both parameter inefficient, i.e., potentially involving one new model per task, and highly susceptible to losing knowledge acquired during pretraining. We propose a novel Transformer based Adapter consisting of a new conditional attention mechanism as well as a set of task-conditioned modules that facilitate weight sharing. Through this construction, we achieve more efficient parameter sharing and mitigate forgetting by keeping half of the weights of a pretrained model fixed. We also use a new multi-task data sampling strategy to mitigate the negative effects of data imbalance across tasks. Using this approach, we are able to surpass single task fine-tuning methods while being parameter and data efficient (using around 66% of the data). Compared to other BERT Large methods on GLUE, our 8-task model surpasses other Adapter methods by 2.8% and our 24-task model outperforms by 0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger variant of our single multi-task model approach performs competitively across 26 NLP tasks and yields state-of-the-art results on a number of test and development sets.",マルチタスク学習（MTL）ネットワークは、学習した知識をさまざまなタスク間で転送するための有望な方法として登場しました。ただし、MTLは、リソースの少ないタスクへの過剰適合、壊滅的な忘却、負のタスク転送、学習干渉などの課題に対処する必要があります。多くの場合、自然言語処理（NLP）では、最高のパフォーマンスを得るには、タスクごとに個別のモデルが必要です。ただし、多くの微調整アプローチは、両方ともパラメーターが非効率的です。つまり、タスクごとに1つの新しいモデルが含まれる可能性があり、事前トレーニング中に取得した知識を失う可能性が非常に高くなります。新しい条件付き注意メカニズムと、重みの共有を容易にするタスク条件付きモジュールのセットで構成される、新しいTransformerベースのアダプターを提案します。この構造により、事前にトレーニングされたモデルの重みの半分を固定することで、より効率的なパラメーター共有を実現し、忘却を軽減します。また、新しいマルチタスクデータサンプリング戦略を使用して、タスク間のデータの不均衡による悪影響を軽減します。このアプローチを使用すると、パラメーターとデータの効率を高めながら、単一タスクの微調整方法を超えることができます（約66を使用）,6.6,https://d3i71xaburhd42.cloudfront.net/e1449a88c166d7c4f95c5eb294c77a127749bdc0/2-Figure1-1.png
Impact of Representation Learning in Linear Bandits,"['Jiaqi Yang', 'Wei Hu', 'Jason D. Lee', 'Simon Shaolei Du']",https://openreview.net/forum?id=edJ_HipawCa,"We study how representation learning can improve the efficiency of bandit problems. We study the setting where we play $T$ linear bandits with dimension $d$ concurrently, and these $T$ bandit tasks share a common $k (\ll d)$ dimensional linear representation. For the finite-action setting, we present a new algorithm which achieves $\widetilde{O}(T\sqrt{kN} + \sqrt{dkNT})$ regret, where $N$ is the number of rounds we play for each bandit. When $T$ is sufficiently large, our algorithm significantly outperforms the naive algorithm (playing $T$ bandits independently) that achieves $\widetilde{O}(T\sqrt{d N})$ regret. We also provide an $\Omega(T\sqrt{kN} + \sqrt{dkNT})$ regret lower bound, showing that our algorithm is minimax-optimal up to poly-logarithmic factors.  Furthermore, we extend our algorithm to the infinite-action setting and obtain a corresponding regret bound which demonstrates the benefit of representation learning in certain regimes. We also present experiments on synthetic and real-world data to illustrate our theoretical findings and demonstrate the effectiveness of our proposed algorithms.",表現学習がどのようにバンディット問題の効率を改善できるかを研究します。次元dでT線形バンディットを同時に再生する設定を研究します。これらのTバンディットタスクは、共通のk（d）次元線形表現を共有します。有限アクション設定の場合、$ \ widetilde {O}（T \ sqrt {kN} + \ sqrt {dkNT}）$後悔を実現する新しいアルゴリズムを提示します。ここで、Nは各盗賊に対してプレイするラウンド数です。 Tが十分に大きい場合、私たちのアルゴリズムは、$ \ widetilde {O}（T \ sqrt {d N}）$の後悔を達成するナイーブアルゴリズム（Tバンディットを独立して再生する）を大幅に上回ります。また、$ \ Omega（T \ sqrt {kN} + \ sqrt {dkNT}）$後悔の下限を提供します。これは、アルゴリズムが多対数因子までミニマックス最適であることを示しています。さらに、アルゴリズムを無限アクション設定に拡張し、特定のレジームでの表現学習の利点を示す対応する後悔の限界を取得します。また、合成データと実世界のデータに関する実験を提示して、理論的な発見を説明し、提案されたアルゴリズムの有効性を示します。,6.6,
Learning Safe Multi-agent Control with Decentralized Neural Barrier Certificates,"['Zengyi Qin', 'Kaiqing Zhang', 'Yuxiao Chen', 'Jingkai Chen', 'Chuchu Fan']",https://openreview.net/forum?id=P6_q1BRxY8Q,"We study the multi-agent safe control problem where agents should avoid collisions to static obstacles and collisions with each other while reaching their goals. Our core idea is to learn the multi-agent control policy jointly with  learning the control barrier functions as safety certificates. We propose a novel joint-learning framework that can be implemented in a decentralized fashion, with generalization guarantees for certain function classes. Such a decentralized framework can adapt to an arbitrarily large number of agents. Building upon this framework, we further improve the scalability by  incorporating neural network architectures  that are invariant to the quantity and permutation of neighboring agents. In addition, we propose a new spontaneous policy refinement method to further enforce the certificate condition during testing. We provide extensive experiments to demonstrate that our method significantly outperforms other leading multi-agent control approaches in terms of maintaining safety and completing original tasks. Our approach also shows exceptional generalization capability in that the control policy can be trained with 8 agents in one scenario, while being used on other scenarios with up to 1024 agents in complex multi-agent environments and dynamics.",エージェントが目標を達成しながら、静的な障害物への衝突や相互の衝突を回避する必要があるマルチエージェントの安全制御問題を研究します。私たちのコアアイデアは、安全証明書としての制御バリア機能の学習と共同でマルチエージェント制御ポリシーを学習することです。特定の関数クラスの一般化が保証された、分散型の方法で実装できる新しい共同学習フレームワークを提案します。このような分散型フレームワークは、任意の数のエージェントに適応できます。このフレームワークに基づいて、隣接するエージェントの量と順列に不変のニューラルネットワークアーキテクチャを組み込むことにより、スケーラビリティをさらに向上させます。さらに、テスト中に証明書の条件をさらに適用するために、新しい自発的なポリシーの改良方法を提案します。安全性の維持と元のタスクの完了に関して、私たちの方法が他の主要なマルチエージェント制御アプローチを大幅に上回っていることを実証するために、広範な実験を提供します。私たちのアプローチは、複雑なマルチエージェント環境とダイナミクスで最大1024のエージェントを使用する他のシナリオで使用しながら、制御ポリシーを1つのシナリオで8つのエージェントでトレーニングできるという優れた一般化機能も示しています。,6.6,https://d3i71xaburhd42.cloudfront.net/133dd31096fb36803e65001ba106767b2be65bd0/5-Figure1-1.png
Text Generation by Learning from Off-Policy Demonstrations,"['Richard Yuanzhe Pang', 'He He']",https://openreview.net/forum?id=RovX-uQ1Hua,"Current approaches to text generation largely rely on autoregressive models and maximum likelihood estimation. This paradigm leads to (i) diverse but low-quality samples due to mismatched learning objective and evaluation metric (likelihood vs. quality) and (ii) exposure bias due to mismatched history distributions (gold vs. model-generated). To alleviate these problems, we frame text generation as a reinforcement learning (RL) problem with expert demonstrations (i.e., the training data), where the goal is to maximize quality given model-generated histories. Prior RL approaches to generation often face optimization issues due to the large action space and sparse reward. We propose GOLD (generation by off-policy learning from demonstrations): an easy-to-optimize algorithm that learns from the off-policy demonstrations by importance weighting. According to both automatic and human evaluation, models trained by GOLD outperforms those trained by MLE and policy gradient on summarization, question generation, and machine translation. Further, they are less sensitive to decoding algorithms and alleviate exposure bias.",テキスト生成への現在のアプローチは、自己回帰モデルと最尤推定に大きく依存しています。このパラダイムは、（i）学習目的と評価指標の不一致（可能性と品質）による多様であるが低品質のサンプル、および（ii）履歴分布の不一致（ゴールドとモデル生成）による露出バイアスにつながります。これらの問題を軽減するために、テキスト生成を強化学習（RL）問題としてフレーム化し、専門家によるデモンストレーション（つまり、トレーニングデータ）を行います。目標は、モデルで生成された履歴の品質を最大化することです。生成に対する以前のRLアプローチは、アクションスペースが大きく、報酬が少ないため、最適化の問題に直面することがよくあります。 GOLD（デモンストレーションからのポリシー外学習による生成）を提案します。これは、重要度の重み付けによってポリシー外デモンストレーションから学習する、最適化が容易なアルゴリズムです。自動評価と人間による評価の両方によると、GOLDによってトレーニングされたモデルは、要約、質問の生成、および機械翻訳に関してMLEおよびポリシー勾配によってトレーニングされたモデルよりも優れています。さらに、それらはデコードアルゴリズムに対する感度が低く、露出バイアスを軽減します。,6.6,https://d3i71xaburhd42.cloudfront.net/3ee38da21d8cf9cb7d4077b729e57f68e9c8d671/7-Figure1-1.png
Large Scale Image Completion via Co-Modulated Generative Adversarial Networks,"['Shengyu Zhao', 'Jonathan Cui', 'Yilun Sheng', 'Yue Dong', 'Xiao Liang', 'Eric I-Chao Chang', 'Yan Xu']",https://openreview.net/forum?id=sSjqmfsk95O,"Numerous task-specific variants of conditional generative adversarial networks have been developed for image completion. Yet, a serious limitation remains that all existing algorithms tend to fail when handling large-scale missing regions. To overcome this challenge, we propose a generic new approach that bridges the gap between image-conditional and recent modulated unconditional generative architectures via co-modulation of both conditional and stochastic style representations. Also, due to the lack of good quantitative metrics for image completion, we propose the new Paired/Unpaired Inception Discriminative Score (P-IDS/U-IDS), which robustly measures the perceptual fidelity of inpainted images compared to real images via linear separability in a feature space. Experiments demonstrate superior performance in terms of both quality and diversity over state-of-the-art methods in free-form image completion and easy generalization to image-to-image translation.",条件付き生成的敵対的ネットワークの多数のタスク固有のバリアントが、画像の完成のために開発されました。それでも、大規模な欠落領域を処理する場合、既存のすべてのアルゴリズムが失敗する傾向があるという重大な制限が残っています。この課題を克服するために、条件付きスタイル表現と確率的スタイル表現の両方の共変調を介して、画像条件付きと最近の変調された無条件生成アーキテクチャ間のギャップを埋める一般的な新しいアプローチを提案します。また、画像完成のための優れた定量的指標がないため、線形分離可能性を介して実際の画像と比較して、修復された画像の知覚忠実度を確実に測定する新しいペア/アンペア開始識別スコア（P-IDS / U-IDS）を提案します。フィーチャースペースで。実験は、自由形式の画像補完と画像から画像への変換への容易な一般化において、最先端の方法よりも品質と多様性の両方の点で優れたパフォーマンスを示しています。,6.6,
BERTology Meets Biology: Interpreting Attention in Protein Language Models,"['Jesse Vig', 'Ali Madani', 'Lav R. Varshney', 'Caiming Xiong', 'richard socher', 'Nazneen Rajani']",https://openreview.net/forum?id=YWtLZvLmud7,"Transformer architectures have proven to learn useful representations for protein classification and generation tasks. However, these representations present challenges in interpretability. In this work, we demonstrate a set of methods for analyzing protein Transformer models through the lens of attention. We show that attention: (1) captures the folding structure of proteins, connecting amino acids that are far apart in the underlying sequence, but spatially close in the three-dimensional structure, (2) targets binding sites, a key functional component of proteins, and (3) focuses on progressively more complex biophysical properties with increasing layer depth. We find this behavior to be consistent across three Transformer architectures (BERT, ALBERT, XLNet) and two distinct protein datasets. We also present a three-dimensional visualization of the interaction between attention and protein structure. Code for visualization and analysis is available at \url{[supplementary-material]}.",Transformerアーキテクチャは、タンパク質の分類および生成タスクに役立つ表現を学習することが証明されています。ただし、これらの表現は解釈可能性に課題を提示します。この作業では、注目のレンズを通してタンパク質Transformerモデルを分析するための一連の方法を示します。注意：（1）タンパク質のフォールディング構造をキャプチャし、基になる配列では遠く離れているが、3次元構造では空間的に近いアミノ酸を接続します。（2）タンパク質の重要な機能コンポーネントである結合部位をターゲットにします。 、および（3）層の深さが増すにつれて、次第に複雑な生物物理学的特性に焦点を当てます。この動作は、3つのTransformerアーキテクチャ（BERT、ALBERT、XLNet）と2つの異なるタンパク質データセット間で一貫していることがわかります。また、注意とタンパク質構造の間の相互作用の3次元視覚化を提示します。視覚化と分析のコードは、[補足資料]で入手できます。,6.6,
NBDT: Neural-Backed Decision Tree,"['Alvin Wan', 'Lisa Dunlap', 'Daniel Ho', 'Jihan Yin', 'Scott Lee', 'Suzanne Petryk', 'Sarah Adel Bargal', 'Joseph E. Gonzalez']",https://openreview.net/forum?id=mCLVeEpplNE,"Machine learning applications such as finance and medicine demand accurate and justifiable predictions, barring most deep learning methods from use. In response, previous work combines decision trees with deep learning, yielding models that (1) sacrifice interpretability for accuracy or (2) sacrifice accuracy for interpretability. We forgo this dilemma by jointly improving accuracy and interpretability using Neural-Backed Decision Trees (NBDTs). NBDTs replace a neural network's final linear layer with a differentiable sequence of decisions and a surrogate loss. This forces the model to learn high-level concepts and lessens reliance on highly-uncertain decisions, yielding (1) accuracy: NBDTs match or outperform modern neural networks on CIFAR, ImageNet and better generalize to unseen classes by up to 16%. Furthermore, our surrogate loss improves the original model's accuracy by up to 2%. NBDTs also afford (2) interpretability: improving human trustby clearly identifying model mistakes and assisting in dataset debugging. Code and pretrained NBDTs are at https://github.com/alvinwan/neural-backed-decision-trees.",金融や医学などの機械学習アプリケーションでは、正確で正当な予測が必要であり、ほとんどのディープラーニング手法を使用できません。これに応じて、以前の作業では、決定木と深層学習を組み合わせて、（1）解釈可能性を犠牲にして正確性を犠牲にする、または（2）解釈可能性を犠牲にして解釈可能性を高めるモデルを作成しました。 Neural-Backed Decision Trees（NBDT）を使用して精度と解釈可能性を共同で改善することにより、このジレンマを回避します。 NBDTは、ニューラルネットワークの最終線形層を微分可能な一連の決定と代理損失に置き換えます。これにより、モデルは高レベルの概念を学習し、非常に不確実な決定への依存を減らし、（1）精度を実現します。NBDTはCIFAR、ImageNetの最新のニューラルネットワークと一致するか、それを上回り、最大16まで見えないクラスに一般化されます。,6.6,https://d3i71xaburhd42.cloudfront.net/7bf30c4aca93ef60e7173e107b04f2566797ad49/19-Figure3.1-1.png
Pruning Neural Networks at Initialization: Why Are We Missing the Mark?,"['Jonathan Frankle', 'Gintare Karolina Dziugaite', 'Daniel Roy', 'Michael Carbin']",https://openreview.net/forum?id=Ig-VyQc-MLK,"Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.",最近の研究では、初期化時にニューラルネットワークを剪定する可能性が検討されています。そのための提案を評価します：SNIP（Lee et al。、2019）、GraSP（Wang et al。、2020）、SynFlow（Tanaka et al。、2020）、およびマグニチュード剪定。これらの方法は、ランダム剪定の些細なベースラインを上回っていますが、トレーニング後のマグニチュード剪定の精度を下回っています。その理由を理解するよう努めています。トレーニング後の剪定とは異なり、これらのメソッドが各レイヤー内で剪定する重みをランダムにシャッフルしたり、新しい初期値をサンプリングしたりすると、精度が維持または向上することを示します。そのため、これらの方法で行われる重みごとの剪定の決定は、剪定する重みの割合の層ごとの選択に置き換えることができます。このプロパティは、基になるプルーニングヒューリスティック、初期化時にプルーニングしたいという要望、またはその両方に関する幅広い課題を示唆しています。,6.5,https://d3i71xaburhd42.cloudfront.net/547eb8481ea4fcb146e4a3108d8f7ba4380e1798/2-Figure1-1.png
Exemplary Natural Images Explain CNN Activations Better than State-of-the-Art Feature Visualization,"['Judy Borowski', 'Roland Simon Zimmermann', 'Judith Schepers', 'Robert Geirhos', 'Thomas S. A. Wallis', 'Matthias Bethge', 'Wieland Brendel']",https://openreview.net/forum?id=QO9-y8also-,"Feature visualizations such as synthetic maximally activating images are a widely used explanation method to better understand the information processing of convolutional neural networks (CNNs). At the same time, there are concerns that these visualizations might not accurately represent CNNs' inner workings. Here, we measure how much extremely activating images help humans to predict CNN activations.
Using a well-controlled psychophysical paradigm, we compare the informativeness of synthetic images by Olah et al. (2017) with a simple baseline visualization, namely exemplary natural images that also strongly activate a specific feature map. Given either synthetic or natural reference images, human participants choose which of two query images leads to strong positive activation. The experiment is designed to maximize participants' performance, and is the first to probe \emph{intermediate} instead of final layer representations. We find that synthetic images indeed provide helpful information about feature map activations ($82\pm4\%$ accuracy; chance would be $50\%$). However, natural images---originally intended to be a baseline---outperform these synthetic images by a wide margin ($92\pm2\%$ accuracy). Additionally, participants are faster and more confident for natural images, whereas subjective impressions about the interpretability of the feature visualizations by Olah et al. (2017) are mixed. The higher informativeness of natural images holds across most layers, for both expert and lay participants as well as for hand- and randomly-picked feature visualizations. Even if only a single reference image is given, synthetic images provide less information than natural images ($65\pm5\%$ vs. $73\pm4\%$). In summary, synthetic images from a popular feature visualization method are significantly less informative for assessing CNN activations than natural images. We argue that visualization methods should improve over this simple baseline.",合成の最大限に活性化する画像などの特徴の視覚化は、畳み込みニューラルネットワーク（CNN）の情報処理をよりよく理解するために広く使用されている説明方法です。同時に、これらの視覚化がCNNの内部動作を正確に表していない可能性があるという懸念があります。ここでは、極端に活性化する画像が、人間がCNNの活性化を予測するのにどの程度役立つかを測定します。十分に制御された精神物理学的パラダイムを使用して、Olahらによる合成画像の有益性を比較します。 （2017）単純なベースラインの視覚化、つまり特定の機能マップを強力にアクティブ化する模範的な自然画像を使用します。合成または自然の参照画像が与えられた場合、人間の参加者は、2つのクエリ画像のどちらが強力なポジティブアクティベーションにつながるかを選択します。この実験は、参加者のパフォーマンスを最大化するように設計されており、最終的なレイヤー表現ではなく中間層を最初に調査します。合成画像は、実際に特徴マップのアクティブ化に関する有用な情報を提供することがわかりました（82 4％の精度、確率は50％）。ただし、元々ベースラインとなることを目的とした自然画像は、これらの合成画像よりも大幅に優れています（92 2％の精度）。さらに、参加者は自然な画像に対してより速く、より自信を持っていますが、Olah etal。による特徴の視覚化の解釈可能性についての主観的な印象。 （2017）はまちまちです。自然画像のより高い情報量は、専門家と一般の参加者の両方、および手作業とランダムに選択された機能の視覚化の両方で、ほとんどのレイヤーにわたって保持されます。参照画像が1つしかない場合でも、合成画像は自然画像よりも情報が少なくなります（65 5％対73 4％）。要約すると、一般的な特徴の視覚化手法からの合成画像は、自然画像よりもCNNの活性化を評価するための情報が大幅に少なくなります。視覚化手法は、この単純なベースラインよりも改善されるべきであると私たちは主張します。,6.5,https://d3i71xaburhd42.cloudfront.net/86d30784eb5a1f5de77a767b5a1230b2a3bfddb9/2-Figure1-1.png
Neural networks with late-phase weights,"['Johannes Von Oswald', 'Seijin Kobayashi', 'Joao Sacramento', 'Alexander Meulemans', 'Christian Henning', 'Benjamin F Grewe']",https://openreview.net/forum?id=C0qJUx5dxFb,"The largely successful method of training neural networks is to learn their weights using some variant of stochastic gradient descent (SGD). Here, we show that the solutions found by SGD can be further improved by ensembling a subset of the weights in late stages of learning. At the end of learning, we obtain back a single model by taking a spatial average in weight space. To avoid incurring increased computational costs, we investigate a family of low-dimensional late-phase weight models which interact multiplicatively with the remaining parameters. Our results show that augmenting standard models with late-phase weights improves generalization in established benchmarks such as CIFAR-10/100, ImageNet and enwik8. These findings are complemented with a theoretical analysis of a noisy quadratic problem which provides a simplified picture of the late phases of neural network learning.",ニューラルネットワークをトレーニングする主に成功した方法は、確率的勾配降下法（SGD）のいくつかの変形を使用してそれらの重みを学習することです。ここでは、学習の後期段階で重みのサブセットをアンサンブルすることにより、SGDによって検出されたソリューションをさらに改善できることを示します。学習の最後に、重み空間の空間平均をとることにより、単一のモデルを取得します。計算コストの増加を回避するために、残りのパラメーターと乗法的に相互作用する低次元の後期重みモデルのファミリーを調査します。私たちの結果は、後期の重みで標準モデルを拡張すると、CIFAR-10 / 100、ImageNet、enwik8などの確立されたベンチマークの一般化が改善されることを示しています。これらの調査結果は、ニューラルネットワーク学習の後期の簡略化された図を提供するノイズの多い二次問題の理論的分析によって補完されます。,6.5,
Uncertainty in Gradient Boosting via Ensembles,"['Andrey Malinin', 'Liudmila Prokhorenkova', 'Aleksei Ustimenko']",https://openreview.net/forum?id=1Jv6b0Zq3qi,"For many practical, high-risk applications, it is essential to quantify uncertainty in a model's predictions to avoid costly mistakes. While predictive uncertainty is widely studied for neural networks, the topic seems to be under-explored for models based on gradient boosting. However, gradient boosting often achieves state-of-the-art results on tabular data. This work examines a probabilistic ensemble-based framework for deriving uncertainty estimates in the predictions of gradient boosting classification and regression models. We conducted experiments on a range of synthetic and real datasets and investigated the applicability of ensemble approaches to gradient boosting models that are themselves ensembles of decision trees. Our analysis shows that ensembles of gradient boosting models successfully detect anomaly inputs while having limited ability to improve the predicted total uncertainty. Importantly, we also propose a concept of a virtual ensemble to get the benefits of an ensemble via only one gradient boosting model, which significantly reduces complexity.",多くの実用的でリスクの高いアプリケーションでは、コストのかかるミスを回避するために、モデル予測の不確実性を定量化することが不可欠です。予測の不確実性はニューラルネットワークについて広く研究されていますが、このトピックは勾配ブースティングに基づくモデルについては十分に検討されていないようです。ただし、勾配ブースティングは、多くの場合、表形式のデータで最先端の結果を達成します。この作業では、勾配ブースティング分類および回帰モデルの予測で不確実性の推定値を導出するための確率的アンサンブルベースのフレームワークを調べます。さまざまな合成データセットと実際のデータセットで実験を行い、それ自体が決定木のアンサンブルである勾配ブースティングモデルへのアンサンブルアプローチの適用可能性を調査しました。私たちの分析は、勾配ブースティングモデルのアンサンブルが異常入力を正常に検出する一方で、予測される全体的な不確実性を改善する能力が限られていることを示しています。重要なのは、1つの勾配ブースティングモデルのみを介してアンサンブルの利点を得る仮想アンサンブルの概念も提案することです。これにより、複雑さが大幅に軽減されます。,6.5,
Interactive Weak Supervision: Learning Useful Heuristics for Data Labeling,"['Benedikt Boecking', 'Willie Neiswanger', 'Eric Xing', 'Artur Dubrawski']",https://openreview.net/forum?id=IDFQI9OY6K,"Obtaining large annotated datasets is critical for training successful machine learning models and it is often a bottleneck in practice. Weak supervision offers a promising alternative for producing labeled datasets without ground truth annotations by generating probabilistic labels using multiple noisy heuristics. This process can scale to large datasets and has demonstrated state of the art performance in diverse domains such as healthcare and e-commerce. One practical issue with learning from user-generated heuristics is that their creation requires creativity, foresight, and domain expertise from those who hand-craft them, a process which can be tedious and subjective. We develop the first framework for interactive weak supervision in which a method proposes heuristics and learns from user feedback given on each proposed heuristic. Our experiments demonstrate that only a small number of feedback iterations are needed to train models that achieve highly competitive test set performance without access to ground truth training labels. We conduct user studies, which show that users are able to effectively provide feedback on heuristics and that test set results track the performance of simulated oracles.",大きな注釈付きデータセットを取得することは、機械学習モデルを成功させるために重要であり、実際にはボトルネックになることがよくあります。弱い監視は、複数のノイズの多いヒューリスティックを使用して確率的ラベルを生成することにより、グラウンドトゥルースアノテーションなしでラベル付きデータセットを生成するための有望な代替手段を提供します。このプロセスは大規模なデータセットに拡張でき、ヘルスケアやeコマースなどのさまざまなドメインで最先端のパフォーマンスを実証しています。ユーザー生成ヒューリスティックから学習する際の実際的な問題の1つは、それらの作成には、それらを手作りする人からの創造性、先見性、およびドメインの専門知識が必要であるということです。このプロセスは、退屈で主観的なものになる可能性があります。メソッドがヒューリスティックを提案し、提案された各ヒューリスティックで与えられたユーザーフィードバックから学習する、インタラクティブな弱い監視のための最初のフレームワークを開発します。私たちの実験は、グラウンドトゥルーストレーニングラベルにアクセスせずに非常に競争力のあるテストセットのパフォーマンスを達成するモデルをトレーニングするために必要なフィードバックの反復回数が少ないことを示しています。ユーザー調査を実施します。これは、ユーザーがヒューリスティックに関するフィードバックを効果的に提供できること、およびテストセットの結果がシミュレートされたオラクルのパフォーマンスを追跡することを示しています。,6.5,https://d3i71xaburhd42.cloudfront.net/c50ac3bb4fbed9c92de1afb88bdb889716b6d469/2-Figure1-1.png
ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations,"['Rishabh Tiwari', 'Udbhav Bamba', 'Arnav Chavan', 'Deepak Gupta']",https://openreview.net/forum?id=xCxXwTzx4L1,"Structured pruning methods are among the effective strategies for extracting small resource-efficient convolutional neural networks from their dense counterparts with minimal loss in accuracy. However, most existing methods still suffer from one or more limitations, that include 1) the need for training the dense model from scratch with pruning-related parameters embedded in the architecture, 2) requiring model-specific hyperparameter settings, 3) inability to include budget-related constraint in the training process, and 4) instability under scenarios of extreme pruning. In this paper, we present ChipNet, a deterministic pruning strategy that employs continuous Heaviside function and a novel crispness loss to identify a highly sparse network out of an existing dense network. Our choice of continuous Heaviside function is inspired by the field of design optimization, where the material distribution task is posed as a continuous optimization problem, but only discrete values (0 or 1) are practically feasible and expected as final outcomes. Our approach's flexible design facilitates its use with different choices of budget constraints while maintaining stability for very low target budgets. Experimental results show that ChipNet outperforms state-of-the-art structured pruning methods by remarkable margins of up to 16.1% in terms of accuracy. Further, we show that the masks obtained with ChipNet are transferable across datasets. For certain cases, it was observed that masks transferred from a model trained on feature-rich teacher dataset provide better performance on the student dataset than those obtained by directly pruning on the student data itself.",構造化された剪定方法は、精度の低下を最小限に抑えながら、密度の高い対応物からリソース効率の高い畳み込みニューラルネットワークを抽出するための効果的な戦略の1つです。ただし、ほとんどの既存の方法には、1）アーキテクチャに組み込まれたプルーニング関連のパラメータを使用して高密度モデルを最初からトレーニングする必要がある、2）モデル固有のハイパーパラメータ設定が必要である、3）含めることができないなど、1つ以上の制限があります。トレーニングプロセスにおける予算関連の制約、および4）極端な剪定のシナリオでの不安定性。この論文では、ChipNetを紹介します。これは、継続的なヘヴィサイド関数と新しい鮮明度の損失を使用して、既存の密なネットワークから非常にまばらなネットワークを識別する決定論的剪定戦略です。連続ヘヴィサイド関数の選択は、材料分布タスクが連続最適化問題として提起される設計最適化の分野に触発されていますが、離散値（0または1）のみが実際に実行可能であり、最終結果として期待されます。私たちのアプローチの柔軟な設計は、非常に低い目標予算の安定性を維持しながら、予算制約のさまざまな選択肢での使用を容易にします。実験結果は、ChipNetが最先端の構造化された剪定方法よりも最大16.1という顕著なマージンで優れていることを示しています。,6.5,
Learning Long-term Visual Dynamics with Region Proposal Interaction Networks,"['Haozhi Qi', 'Xiaolong Wang', 'Deepak Pathak', 'Yi Ma', 'Jitendra Malik']",https://openreview.net/forum?id=_X_4Akcd8Re,"Learning long-term dynamics models is the key to understanding physical common sense. Most existing approaches on learning dynamics from visual input sidestep long-term predictions by resorting to rapid re-planning with short-term models. This not only requires such models to be super accurate but also limits them only to tasks where an agent can continuously obtain feedback and take action at each step until completion. In this paper, we aim to leverage the ideas from success stories in visual recognition tasks to build object representations that can capture inter-object and object-environment interactions over a long range. To this end, we propose Region Proposal Interaction Networks (RPIN), which reason about each object's trajectory in a latent region-proposal feature space. Thanks to the simple yet effective object representation, our approach outperforms prior methods by a significant margin both in terms of prediction quality and their ability to plan for downstream tasks, and also generalize well to novel environments. Results are available at https://sites.google.com/view/iclr21-rpin.",長期的なダイナミクスモデルを学ぶことは、物理的な常識を理解するための鍵です。視覚入力からダイナミクスを学習するための既存のアプローチのほとんどは、短期モデルを使用した迅速な再計画に頼ることにより、長期予測を回避します。これには、そのようなモデルが非常に正確である必要があるだけでなく、エージェントが継続的にフィードバックを取得し、完了するまで各ステップでアクションを実行できるタスクのみに制限されます。この論文では、視覚認識タスクのサクセスストーリーからのアイデアを活用して、オブジェクト間およびオブジェクトと環境の相互作用を長期間にわたってキャプチャできるオブジェクト表現を構築することを目指しています。この目的のために、我々は、潜在的な領域提案特徴空間における各オブジェクトの軌道について推論する領域提案相互作用ネットワーク（RPIN）を提案します。シンプルでありながら効果的なオブジェクト表現のおかげで、私たちのアプローチは、予測品質とダウンストリームタスクを計画する能力の両方の点で、以前の方法を大幅に上回り、新しい環境にも一般化できます。結果はhttps://sites.google.com/view/iclr21-rpinで入手できます。,6.5,
Scaling the Convex Barrier with Active Sets,"['Alessandro De Palma', 'Harkirat Behl', 'Rudy R Bunel', 'Philip Torr', 'M. Pawan Kumar']",https://openreview.net/forum?id=uQfOy7LrlTR,"Tight and efficient neural network bounding is of critical importance for the scaling of neural network verification systems. A number of efficient specialised dual solvers for neural network bounds have been presented recently, but they are often too loose to verify more challenging properties. This lack of tightness is linked to the weakness of the employed relaxation, which is usually a linear program of size linear in the number of neurons. While a tighter linear relaxation for piecewise linear activations exists, it comes at the cost of exponentially many constraints and thus currently lacks an efficient customised solver. We alleviate this deficiency via a novel dual algorithm that realises the full potential of the new relaxation by operating on a small active set of dual variables. Our method recovers the strengths of the new relaxation in the dual space: tightness and a linear separation oracle. At the same time, it shares the benefits of previous dual approaches for weaker relaxations: massive parallelism, GPU implementation, low cost per iteration and valid bounds at any time. As a consequence, we obtain better bounds than off-the-shelf solvers in only a fraction of their running time and recover the speed-accuracy trade-offs of looser dual solvers if the computational budget is small. We demonstrate that this results in significant formal verification speed-ups.",厳密で効率的なニューラルネットワークの境界は、ニューラルネットワーク検証システムのスケーリングにとって非常に重要です。最近、ニューラルネットワーク境界用の効率的な特殊なデュアルソルバーがいくつか発表されましたが、それらは緩すぎて、より困難な特性を検証できないことがよくあります。このタイトさの欠如は、採用されたリラクゼーションの弱さに関連しています。これは通常、ニューロンの数が線形である線形計画法です。区分的線形アクティベーションのより厳密な線形緩和が存在しますが、指数関数的に多くの制約が発生するため、現在、効率的なカスタマイズされたソルバーが不足しています。デュアル変数の小さなアクティブセットを操作することにより、新しい緩和の可能性を最大限に実現する新しいデュアルアルゴリズムを介して、この欠陥を軽減します。私たちの方法は、双対空間における新しい緩和の強みであるタイトネスと線形分離オラクルを回復します。同時に、それは、より弱い緩和のための以前の二重アプローチの利点を共有します：大規模な並列処理、GPU実装、反復あたりの低コスト、およびいつでも有効な境界。結果として、実行時間のごく一部で既成のソルバーよりも優れた境界を取得し、計算バジェットが小さい場合は、より緩いデュアルソルバーの速度と精度のトレードオフを回復します。これにより、フォーマル検証が大幅に高速化されることを示しています。,6.5,
Continuous Wasserstein-2 Barycenter Estimation without Minimax Optimization,"['Alexander Korotin', 'Lingxiao Li', 'Justin Solomon', 'Evgeny Burnaev']",https://openreview.net/forum?id=3tFAs5E-Pe,"Wasserstein barycenters provide a geometric notion of the weighted average of probability measures based on optimal transport. In this paper, we present a scalable algorithm to compute Wasserstein-2 barycenters given sample access to the input measures, which are not restricted to being discrete. While past approaches rely on entropic or quadratic regularization, we employ input convex neural networks and cycle-consistency regularization to avoid introducing bias. As a result, our approach does not resort to minimax optimization. We provide theoretical analysis on error bounds as well as empirical evidence of the effectiveness of the proposed approach in low-dimensional qualitative scenarios and high-dimensional quantitative experiments.",ワッサースタイン重心は、最適な輸送に基づく確率測度の加重平均の幾何学的概念を提供します。この論文では、離散に限定されない入力メジャーへのサンプルアクセスが与えられた場合にWasserstein-2重心を計算するためのスケーラブルなアルゴリズムを提示します。過去のアプローチはエントロピーまたは二次正則化に依存していますが、バイアスの導入を回避するために、入力凸型ニューラルネットワークとサイクル整合性正則化を採用しています。結果として、私たちのアプローチはミニマックス最適化に頼っていません。エラー範囲に関する理論的分析と、低次元の定性的シナリオおよび高次元の定量的実験における提案されたアプローチの有効性の経験的証拠を提供します。,6.5,https://d3i71xaburhd42.cloudfront.net/07b49f8751b0b0e9116a473bd6519f226e614363/8-Figure1-1.png
Scalable Bayesian Inverse Reinforcement Learning,"['Alex James Chan', 'Mihaela van der Schaar']",https://openreview.net/forum?id=4qR3coiNaIv,"Bayesian inference over the reward presents an ideal solution to the ill-posed nature of the inverse reinforcement learning problem. Unfortunately current methods generally do not scale well beyond the small tabular setting due to the need for an inner-loop MDP solver, and even non-Bayesian methods that do themselves scale often require extensive interaction with the environment to perform well, being inappropriate for high stakes or costly applications such as healthcare. In this paper we introduce our method, Auto-encoded Variational Reward Imitation Learning (AVRIL), that addresses both of these issues by jointly learning an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces alongside an appropriate policy in a completely offline manner through a variational approach to said latent reward. Applying our method to real medical data alongside classic control simulations, we demonstrate Bayesian reward inference in environments beyond the scope of current methods, as well as task performance competitive with focused offline imitation learning algorithms.",報酬に対するベイズ推定は、逆強化学習問題の不適切な性質に対する理想的な解決策を提示します。残念ながら、現在の方法は、内部ループMDPソルバーが必要なため、一般に小さな表形式を超えて拡張することはできません。また、拡張する非ベイジアン方法でさえ、うまく機能するために環境との広範な相互作用を必要とすることが多く、高には不適切です。賭け金またはヘルスケアなどの費用のかかるアプリケーション。この論文では、完全にオフラインで適切なポリシーとともに任意に複雑な状態空間にスケーリングする報酬の近似事後分布を共同で学習することにより、これらの問題の両方に対処する方法、自動エンコード変分報酬模倣学習（AVRIL）を紹介します。上記の潜在的な報酬への変分アプローチによる方法。従来の制御シミュレーションと一緒に実際の医療データに私たちの方法を適用して、現在の方法の範囲を超えた環境でのベイズ報酬推論、および焦点を絞ったオフライン模倣学習アルゴリズムと競合するタスクパフォ​​ーマンスを示します。,6.5,
Meta Back-Translation,"['Hieu Pham', 'Xinyi Wang', 'Yiming Yang', 'Graham Neubig']",https://openreview.net/forum?id=3jjmdp7Hha,"Back-translation is an effective strategy to improve the performance of Neural Machine Translation~(NMT) by generating pseudo-parallel data. However, several recent works have found that better translation quality in the pseudo-parallel data does not necessarily lead to a better final translation model, while lower-quality but diverse data often yields stronger results instead.
In this paper we propose a new way to generate pseudo-parallel data for back-translation that directly optimizes the final model performance.  Specifically, we propose a meta-learning framework where the back-translation model learns to match the forward-translation model's gradients on the development data with those on the pseudo-parallel data. In our evaluations in both the standard datasets WMT En-De'14 and WMT En-Fr'14, as well as a multilingual translation setting, our method leads to significant improvements over strong baselines. ",逆翻訳は、疑似並列データを生成することでニューラル機械翻訳（NMT）のパフォーマンスを向上させる効果的な戦略です。ただし、最近のいくつかの研究では、疑似パラレルデータの翻訳品質が向上しても、必ずしも最終的な翻訳モデルが向上するとは限らないことがわかっています。一方、品質は低いが多様なデータでは、代わりに強力な結果が得られることがよくあります。この論文では、最終的なモデルのパフォーマンスを直接最適化する逆変換用の疑似並列データを生成する新しい方法を提案します。具体的には、バックトランスレーションモデルが開発データのフォワードトランスレーションモデルの勾配を疑似パラレルデータの勾配と一致させることを学習するメタ学習フレームワークを提案します。標準データセットWMTEn-De14とWMTEn-Fr14の両方、および多言語翻訳設定での評価では、この方法により、強力なベースラインよりも大幅に改善されました。,6.5,
"Symmetry, Conservation Laws, and Learning Dynamics in Neural Networks","['Daniel Kunin', 'Javier Sagastuy-Brena', 'Surya Ganguli', 'Daniel LK Yamins', 'Hidenori Tanaka']",https://openreview.net/forum?id=q8qLAbQBupm,"Predicting the dynamics of neural network parameters during training is one of the key challenges in building a theoretical foundation for deep learning. A central obstacle is that the motion of a network in high-dimensional parameter space undergoes discrete finite steps along complex stochastic gradients derived from real-world datasets. We circumvent this obstacle through a unifying theoretical framework based on intrinsic symmetries embedded in a network's architecture that are present for any dataset. We show that any such symmetry imposes stringent geometric constraints on gradients and Hessians, leading to an associated conservation law in the continuous-time limit of stochastic gradient descent (SGD), akin to Noether's theorem in physics. We further show that finite learning rates used in practice can actually break these symmetry induced conservation laws. We apply tools from finite difference methods to derive modified gradient flow, a differential equation that better approximates the numerical trajectory taken by SGD at finite learning rates. We combine modified gradient flow with our framework of symmetries to derive exact integral expressions for the dynamics of certain parameter combinations. We empirically validate our analytic predictions for learning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting symmetry, our work demonstrates that we can analytically describe the learning dynamics of various parameter combinations at finite learning rates and batch sizes for state of the art architectures trained on any dataset.",トレーニング中のニューラルネットワークパラメータのダイナミクスを予測することは、深層学習の理論的基盤を構築する上での重要な課題の1つです。中心的な障害は、高次元のパラメータ空間でのネットワークの動きが、実世界のデータセットから導出された複雑な確率的勾配に沿って離散的な有限ステップを経ることです。データセットに存在するネットワークアーキテクチャに埋め込まれた固有の対称性に基づく統一された理論的フレームワークを通じて、この障害を回避します。このような対称性は、勾配とヘッセ行列に厳しい幾何学的制約を課し、物理学のネーターの定理に似た確率的勾配降下（SGD）の連続時間制限に関連する保存則をもたらすことを示します。さらに、実際に使用される有限の学習率が、これらの対称性によって引き起こされる保存則を実際に破ることができることを示します。有限差分法のツールを適用して、修正された勾配流を導出します。これは、有限学習率でSGDがとる数値軌道をより適切に近似する微分方程式です。修正された勾配フローを対称性のフレームワークと組み合わせて、特定のパラメーターの組み合わせのダイナミクスの正確な積分式を導き出します。 TinyImageNetでトレーニングされたVGG-16での学習ダイナミクスの分析的予測を経験的に検証します。全体として、対称性を活用することにより、私たちの仕事は、任意のデータセットでトレーニングされた最先端のアーキテクチャの有限の学習率とバッチサイズで、さまざまなパラメーターの組み合わせの学習ダイナミクスを分析的に記述できることを示しています。,6.5,
Discovering Autoregressive Orderings with Variational Inference,"['Xuanlin Li', 'Brandon Trabucco', 'Dong Huk Park', 'Yang Gao', 'Michael Luo', 'Sheng Shen', 'Trevor Darrell']",https://openreview.net/forum?id=jP1vTH3inC,"The predominant approach for language modeling is to encode a sequence of tokens from left to right, but this eliminates a source of information: the order by which the sequence was naturally generated. One strategy to recover this information is to decode both the content and location of tokens. Prior work supervises content and location with hand-designed loss functions or bootstraps from a predefined ordering. These approaches require domain-specific insight. We address this limitation with an unsupervised learner that discovers high-quality autoregressive orders without domain-specific prior. Our learner is a neural network that performs variational inference with the autoregressive order as a latent variable. The corresponding ELBO is not differentiable, so we develop a practical algorithm for end-to-end optimization using policy gradients. Strong empirical results with our solution on image captioning and code generation suggest that our algorithm is capable of discovering various autoregressive orders for different sequences that are competitive with or better than fixed orders.",言語モデリングの主なアプローチは、トークンのシーケンスを左から右にエンコードすることですが、これにより、情報源、つまりシーケンスが自然に生成された順序が排除されます。この情報を回復するための1つの戦略は、トークンの内容と場所の両方をデコードすることです。以前の作業では、事前定義された順序から手動で設計された損失関数またはブートストラップを使用して、コンテンツと場所を監視します。これらのアプローチには、ドメイン固有の洞察が必要です。ドメイン固有の事前情報なしで高品質の自己回帰注文を発見する教師なし学習者を使用して、この制限に対処します。私たちの学習者は、潜在変数として自己回帰次数を使用して変分推論を実行するニューラルネットワークです。対応するELBOは微分可能ではないため、ポリシー勾配を使用してエンドツーエンドの最適化のための実用的なアルゴリズムを開発します。画像のキャプションとコード生成に関するソリューションの強力な経験的結果は、アルゴリズムが、固定次数と競合するか、それよりも優れているさまざまなシーケンスのさまざまな自己回帰次数を検出できることを示しています。,6.5,
Task-Agnostic Morphology Evolution,"['Donald Joseph Hejna III', 'Pieter Abbeel', 'Lerrel Pinto']",https://openreview.net/forum?id=CGQ6ENUMX6,"Deep reinforcement learning primarily focuses on learning behavior, usually overlooking the fact that an agent's function is largely determined by form. So, how should one go about finding a morphology fit for solving tasks in a given environment? Current approaches that co-adapt morphology and behavior use a specific task's reward as a signal for morphology optimization. However, this often requires expensive policy optimization and results in task-dependent morphologies that are not built to generalize. In this work, we propose a new approach, Task-Agnostic Morphology Evolution (TAME), to alleviate both of these issues. Without any task or reward specification, TAME evolves morphologies by only applying randomly sampled action primitives on a population of agents. This is accomplished using an information-theoretic objective that efficiently ranks agents by their ability to reach diverse states in the environment and the causality of their actions. Finally, we empirically demonstrate that across 2D, 3D, and manipulation environments TAME can evolve morphologies that match the multi-task performance of those learned with task supervised algorithms. Our code and videos can be found at https://sites.google.com/view/task-agnostic-evolution .
",深層強化学習は、主に学習行動に焦点を当てており、通常、エージェントの機能は主にフォームによって決定されるという事実を見落としています。では、特定の環境でタスクを解決するのに適した形態を見つけるにはどうすればよいでしょうか。形態と行動を共適応させる現在のアプローチは、形態最適化のシグナルとして特定のタスク報酬を使用します。ただし、これには多くの場合、コストのかかるポリシーの最適化が必要であり、一般化するように構築されていないタスク依存の形態が発生します。この作業では、これらの問題の両方を軽減するために、新しいアプローチであるタスクにとらわれない形態進化（TAME）を提案します。タスクや報酬の指定がない場合、TAMEは、ランダムにサンプリングされたアクションプリミティブをエージェントの母集団に適用するだけで、形態を進化させます。これは、環境内のさまざまな状態に到達する能力とアクションの因果関係によってエージェントを効率的にランク付けする情報理論の目的を使用して実現されます。最後に、2D、3D、および操作環境全体でTAMEが、タスク監視アルゴリズムで学習したマルチタスクパフォ​​ーマンスに一致する形態を進化させることができることを経験的に示します。私たちのコードとビデオはhttps://sites.google.com/view/task-agnostic-evolutionで見つけることができます。,6.5,
Set Prediction without Imposing Structure as Conditional Density Estimation,"['David W Zhang', 'Gertjan J. Burghouts', 'Cees G. M. Snoek']",https://openreview.net/forum?id=04ArenGOz3,"Set prediction is about learning to predict a collection of unordered variables with unknown interrelations. Training such models with set losses imposes the structure of a metric space over sets. We focus on stochastic and underdefined cases, where an incorrectly chosen loss function leads to implausible predictions. Example tasks include conditional point-cloud reconstruction and predicting future states of molecules. In this paper we propose an alternative to training via set losses, by viewing learning as conditional density estimation. Our learning framework fits deep energy-based models and approximates the intractable likelihood with gradient-guided sampling. Furthermore, we propose a stochastically augmented prediction algorithm that enables multiple predictions, reflecting the possible variations in the target set. We empirically demonstrate on a variety of datasets the capability to learn multi-modal densities and produce multiple plausible predictions. Our approach is competitive with previous set prediction models on standard benchmarks. More importantly, it extends the family of addressable tasks beyond those that have unambiguous predictions.",セット予測とは、相互関係が不明な順序付けられていない変数のコレクションを予測することを学習することです。セット損失を使用してこのようなモデルをトレーニングすると、セットに距離空間の構造が課せられます。確率的で過小定義されたケースに焦点を当てます。この場合、誤って選択された損失関数は、信じがたい予測につながります。タスクの例には、条件付き点群の再構築と分子の将来の状態の予測が含まれます。この論文では、学習を条件付き密度推定と見なすことにより、セット損失によるトレーニングの代替案を提案します。私たちの学習フレームワークは、深いエネルギーベースのモデルに適合し、勾配誘導サンプリングで扱いにくい可能性を概算します。さらに、ターゲットセットの可能な変動を反映して、複数の予測を可能にする確率的に拡張された予測アルゴリズムを提案します。さまざまなデータセットで、マルチモーダル密度を学習し、複数のもっともらしい予測を生成する機能を経験的に示します。私たちのアプローチは、標準ベンチマークで以前に設定された予測モデルと競合します。さらに重要なことは、アドレス可能なタスクのファミリーを、明確な予測を持つタスクを超えて拡張することです。,6.5,https://d3i71xaburhd42.cloudfront.net/9da628bd954e2250ec3a8aec9670eab096575c2d/5-Figure1-1.png
"MultiModalQA: complex question answering over text, tables and images","['Alon Talmor', 'Ori Yoran', 'Amnon Catav', 'Dan Lahav', 'Yizhong Wang', 'Akari Asai', 'Gabriel Ilharco', 'Hannaneh Hajishirzi', 'Jonathan Berant']",https://openreview.net/forum?id=ee6W5UgQLa,"When answering complex questions, people can seamlessly combine information from visual, textual and tabular sources. 
While interest in models that reason over multiple pieces of evidence has surged in recent years, there has been relatively little work on question answering models that reason across multiple modalities.
In this paper, we present MultiModalQA (MMQA): a challenging question answering dataset that requires joint reasoning over text, tables and images. 
We create MMQA using a new framework for generating complex multi-modal questions at scale, harvesting tables from Wikipedia, and attaching images and text paragraphs using entities that appear in each table. We then define a formal language that allows us to take questions that can be answered from a single modality, and combine them to generate cross-modal questions. Last, crowdsourcing workers take these automatically generated questions and rephrase them into more fluent language.
We create 26,878 questions through this procedure, and empirically demonstrate the necessity of a multi-modal multi-hop approach to solve our task: our multi-hop model, ImplicitDecomp, achieves an average F1 of 51.1 over cross-modal questions, substantially outperforming a strong baseline that achieves 42.9 F1, but still lags significantly behind human performance, which is at 85.2 F1.","複雑な質問に答えるとき、人々は視覚的、テキスト的、表形式の情報源からの情報をシームレスに組み合わせることができます。近年、複数の証拠を推論するモデルへの関心が高まっていますが、複数のモダリティを推論する質問応答モデルに関する作業は比較的少ないです。このホワイトペーパーでは、MultiModalQA（MMQA）を紹介します。これは、テキスト、表、画像の共同推論を必要とする、やりがいのある質問応答データセットです。複雑なマルチモーダル質問を大規模に生成し、ウィキペディアからテーブルを収集し、各テーブルに表示されるエンティティを使用して画像とテキスト段落を添付するための新しいフレームワークを使用してMMQAを作成します。次に、単一のモダリティから回答できる質問を取得し、それらを組み合わせてクロスモーダル質問を生成できる形式言語を定義します。最後に、クラウドソーシングワーカーは、これらの自動的に生成された質問を受け取り、より流暢な言語に言い換えます。この手順で26,878の質問を作成し、タスクを解決するためのマルチモーダルマルチホップアプローチの必要性を経験的に示します。マルチホップモデルであるImplicitDecompは、クロスモーダル質問に対して平均F1 51.1を達成し、実質的に42.9 F1を達成する強力なベースラインですが、それでも85.2F1である人間のパフォーマンスよりも大幅に遅れています。",6.5,
Return-Based Contrastive Representation Learning for Reinforcement  Learning,"['Guoqing Liu', 'Chuheng Zhang', 'Li Zhao', 'Tao Qin', 'Jinhua Zhu', 'Li Jian', 'Nenghai Yu', 'Tie-Yan Liu']",https://openreview.net/forum?id=_TM6rT7tXke,"Recently, various auxiliary tasks have been proposed to accelerate representation learning and improve sample efficiency in deep reinforcement learning (RL). However, existing auxiliary tasks do not take the characteristics of RL problems into consideration and are unsupervised. By leveraging returns, the most important feedback signals in RL, we propose a novel auxiliary task that forces the learnt representations to discriminate state-action pairs with different returns. Our auxiliary loss is theoretically justified to learn representations that capture the structure of a new form of state-action abstraction, under which state-action pairs with similar return distributions are aggregated together. Empirically, our algorithm outperforms strong baselines on complex tasks in Atari games and DeepMind Control suite, and achieves even better performance when combined with existing auxiliary tasks.",最近、表現学習を加速し、深層強化学習（RL）のサンプル効率を向上させるために、さまざまな補助タスクが提案されています。ただし、既存の補助タスクはRL問題の特性を考慮しておらず、監視されていません。 RLで最も重要なフィードバック信号であるリターンを活用することにより、学習した表現に異なるリターンを持つ状態とアクションのペアを区別させる新しい補助タスクを提案します。私たちの補助損失は、理論的には、同様のリターン分布を持つ状態アクションのペアが一緒に集約される、新しい形式の状態アクション抽象化の構造をキャプチャする表現を学習することで正当化されます。経験的に、私たちのアルゴリズムは、AtariゲームとDeepMind Controlスイートの複雑なタスクの強力なベースラインを上回り、既存の補助タスクと組み合わせるとさらに優れたパフォーマンスを実現します。,6.5,
Learning Parametrised Graph Shift Operators,"['George Dasoulas', 'Johannes F. Lutzeyer', 'Michalis Vazirgiannis']",https://openreview.net/forum?id=0OlrLvrsHwQ,"In many domains data is currently represented as graphs and therefore, the graph representation of this data becomes increasingly important in machine learning. Network data is, implicitly or explicitly, always represented using a graph shift operator (GSO) with the most common choices being the adjacency, Laplacian matrices and their normalisations. In this paper, a novel parametrised GSO (PGSO) is proposed, where specific parameter values result in the most commonly used GSOs and message-passing operators in graph neural network (GNN) frameworks. The PGSO is suggested as a replacement of the standard GSOs that are used in state-of-the-art GNN architectures and the optimisation of the PGSO parameters is seamlessly included in the model training. It is proved that the PGSO has real eigenvalues and a set of real eigenvectors independent of the parameter values and spectral bounds on the PGSO are derived. PGSO parameters are shown to adapt to the sparsity of the graph structure in a study on stochastic blockmodel networks, where they are found to automatically replicate the GSO regularisation found in the literature. On several real-world datasets the accuracy of state-of-the-art GNN architectures is improved by the inclusion of the PGSO in both node- and graph-classification tasks. ",現在、多くのドメインでデータはグラフとして表されているため、このデータのグラフ表現は機械学習においてますます重要になっています。ネットワークデータは、暗黙的または明示的に、常にグラフシフト演算子（GSO）を使用して表されます。最も一般的な選択肢は、隣接行列、ラプラシアン行列、およびそれらの正規化です。この論文では、特定のパラメータ値がグラフニューラルネットワーク（GNN）フレームワークで最も一般的に使用されるGSOとメッセージパッシング演算子をもたらす、新しいパラメータ化されたGSO（PGSO）を提案します。 PGSOは、最先端のGNNアーキテクチャで使用される標準GSOの代替として提案されており、PGSOパラメーターの最適化はモデルトレーニングにシームレスに含まれています。 PGSOが実固有値を持ち、パラメーター値に依存しない実固有ベクトルのセットとPGSOのスペクトル境界が導出されることが証明されています。 PGSOパラメーターは、確率的ブロックモデルネットワークに関する研究でグラフ構造のスパース性に適応することが示されています。PGSOパラメーターは、文献にあるGSO正則化を自動的に複製することがわかっています。いくつかの実際のデータセットでは、ノード分類タスクとグラフ分類タスクの両方にPGSOを含めることで、最先端のGNNアーキテクチャの精度が向上しています。,6.5,https://d3i71xaburhd42.cloudfront.net/853b45c883d8ef4d105c092598d4f147ceac1770/6-Figure1-1.png
Revisiting Locally Supervised Learning: an Alternative to End-to-end Training,"['Yulin Wang', 'Zanlin Ni', 'Shiji Song', 'Le Yang', 'Gao Huang']",https://openreview.net/forum?id=fAbkE6ant2,"Due to the need to store the intermediate activations for back-propagation, end-to-end (E2E) training of deep networks usually suffers from high GPUs memory footprint. This paper aims to address this problem by revisiting the locally supervised learning, where a network is split into gradient-isolated modules and trained with local supervision. We experimentally show that simply training local modules with E2E loss tends to collapse task-relevant information at early layers, and hence hurts the performance of the full model. To avoid this issue, we propose an information propagation (InfoPro) loss, which encourages local modules to preserve as much useful information as possible, while progressively discard task-irrelevant information. As InfoPro loss is difficult to compute in its original form, we derive a feasible upper bound as a surrogate optimization objective, yielding a simple but effective algorithm. In fact, we show that the proposed method boils down to minimizing the combination of a reconstruction loss and a normal cross-entropy/contrastive term. Extensive empirical results on five datasets (i.e., CIFAR, SVHN, STL-10, ImageNet and Cityscapes) validate that InfoPro is capable of achieving competitive performance with less than 40% memory footprint compared to E2E training, while allowing using training data with higher-resolution or larger batch sizes under the same GPU memory constraint. Our method also enables training local modules asynchronously for potential training acceleration.",バックプロパゲーションのために中間アクティベーションを保存する必要があるため、ディープネットワークのエンドツーエンド（E2E）トレーニングは、通常、GPUメモリフットプリントが高いという問題があります。このホワイトペーパーでは、ネットワークを勾配分離モジュールに分割し、ローカル教師あり学習でトレーニングする、ローカル教師あり学習を再検討することで、この問題に対処することを目的としています。 E2E損失を使用してローカルモジュールをトレーニングするだけでは、初期のレイヤーでタスク関連の情報が崩壊する傾向があり、したがって、完全なモデルのパフォーマンスが低下することを実験的に示します。この問題を回避するために、情報伝播（InfoPro）損失を提案します。これにより、ローカルモジュールは、タスクに関係のない情報を徐々に破棄しながら、できるだけ多くの有用な情報を保持するようになります。 InfoProの損失を元の形式で計算するのは難しいため、代理最適化の目的として実行可能な上限を導き出し、シンプルで効果的なアルゴリズムを生成します。実際、提案された方法は、再構成損失と通常のクロスエントロピー/対照項の組み合わせを最小限に抑えることに要約されることを示しています。 5つのデータセット（つまり、CIFAR、SVHN、STL-10、ImageNet、Cityscapes）での広範な経験的結果は、InfoProが40未満で競争力のあるパフォーマンスを達成できることを検証しています。,6.5,https://d3i71xaburhd42.cloudfront.net/32a81aef8063274b1d8cc770a7f6dcfd8efe5336/2-Figure1-1.png
Contrastive Learning with Hard Negative Samples,"['Joshua David Robinson', 'Ching-Yao Chuang', 'Suvrit Sra', 'Stefanie Jegelka']",https://openreview.net/forum?id=CR1XOQ0UTh-,"We consider the question: how can you sample good negative examples for contrastive learning? We argue that, as with metric learning, learning contrastive representations benefits from hard negative samples (i.e., points that are difficult to distinguish from an anchor point). The key challenge toward using hard negatives is that contrastive methods must remain unsupervised, making it infeasible to adopt existing negative sampling strategies that use label information. In response, we develop a new class of unsupervised methods for selecting hard negative samples where the user can control the amount of hardness. A limiting case of this sampling results in a representation that tightly clusters each class, and pushes different classes as far apart as possible. The proposed method improves downstream performance across multiple modalities, requires only few additional lines of code to implement, and introduces no computational overhead.
",私たちは質問を検討します：対照学習のための良い否定的な例をどのようにサンプリングできますか？メトリック学習と同様に、対照表現の学習は、ハードネガティブサンプル（つまり、アンカーポイントと区別するのが難しいポイント）から恩恵を受けると主張します。ハードネガを使用する際の主な課題は、対照的な方法を監視されないままにする必要があるため、ラベル情報を使用する既存のネガティブサンプリング戦略を採用することが不可能になることです。それに応じて、ユーザーが硬度の量を制御できるハードネガティブサンプルを選択するための新しいクラスの教師なしメソッドを開発します。このサンプリングの限定的なケースでは、各クラスを緊密にクラスター化し、異なるクラスを可能な限り離して表現します。提案された方法は、複数のモダリティにわたるダウンストリームパフォーマンスを改善し、実装するために必要な追加のコード行はわずかであり、計算のオーバーヘッドは発生しません。,6.5,
WrapNet:  Neural Net Inference with Ultra-Low-Precision Arithmetic,"['Renkun Ni', 'Hong-min Chu', 'Oscar Castaneda', 'Ping-yeh Chiang', 'Christoph Studer', 'Tom Goldstein']",https://openreview.net/forum?id=3SqrRe8FWQ-,"Low-precision neural networks represent both weights and activations with few bits, drastically reducing the multiplication complexity. Nonetheless, these products are accumulated using high-precision (typically 32-bit) additions, an operation that dominates the arithmetic complexity of inference when using extreme quantization (e.g., binary weights). To further optimize inference, we propose WrapNet that adapts neural networks to use low-precision (8-bit) additions in the accumulators, achieving classification accuracy comparable to their 32-bit counterparts. We achieve resilience to low-precision accumulation by inserting a cyclic activation layer, as well as an overflow penalty regularizer. We demonstrate the efficacy of our approach on both software and hardware platforms.",低精度のニューラルネットワークは、重みとアクティベーションの両方を数ビットで表し、乗算の複雑さを大幅に軽減します。それにもかかわらず、これらの積は、高精度（通常は32ビット）の加算を使用して累積されます。これは、極端な量子化（たとえば、バイナリの重み）を使用する場合の推論の算術的複雑さを支配する演算です。推論をさらに最適化するために、アキュムレータで低精度（8ビット）の加算を使用するようにニューラルネットワークを適応させ、32ビットの対応物に匹敵する分類精度を実現するWrapNetを提案します。サイクリックアクティベーションレイヤーとオーバーフローペナルティ正則化を挿入することにより、低精度の累積に対する復元力を実現します。ソフトウェアとハ​​ードウェアの両方のプラットフォームでのアプローチの有効性を示します。,6.5,https://d3i71xaburhd42.cloudfront.net/0708626d48d23a85aceca9e58963332079ff55b8/4-Figure1-1.png
"Heating up decision boundaries: isocapacitory saturation, adversarial scenarios and generalization bounds","['Bogdan Georgiev', 'Lukas Franken', 'Mayukh Mukherjee']",https://openreview.net/forum?id=UwGY2qjqoLD,"In the present work we study classifiers' decision boundaries via Brownian motion processes in ambient data space and associated probabilistic techniques. Intuitively, our ideas correspond to placing a heat source at the decision boundary and observing how effectively the sample points warm up. We are largely motivated by the search for a soft measure that sheds further light on the decision boundary's geometry. En route, we  bridge aspects of potential theory and geometric analysis (Maz'ya 2011, Grigor'Yan and Saloff-Coste 2002) with active fields of ML research such as adversarial examples and generalization bounds. First, we focus on the geometric behavior of decision boundaries in the light of adversarial attack/defense mechanisms. Experimentally, we observe a certain capacitory trend over different adversarial defense strategies: decision boundaries locally become flatter as measured by isoperimetric inequalities (Ford et al 2019); however, our more sensitive heat-diffusion metrics  extend this analysis and further reveal that some non-trivial geometry invisible to plain distance-based methods is still preserved. Intuitively, we provide evidence that the decision boundaries nevertheless retain many persistent ""wiggly and fuzzy"" regions on a finer scale.
Second, we show how Brownian hitting probabilities translate to soft generalization bounds which are in turn connected to compression and noise stability (Arora et al 2018), and these bounds are significantly stronger if the decision boundary has controlled geometric features.",現在の作業では、周囲データ空間でのブラウン運動プロセスと関連する確率的手法を介して分類器の決定境界を研究します。直感的に、私たちのアイデアは、決定境界に熱源を配置し、サンプルポイントがどれほど効果的にウォームアップするかを観察することに対応しています。私たちは主に、意思決定境界のジオメトリにさらに光を当てるソフトメジャーの検索に動機付けられています。途中で、ポテンシャル理論と幾何学的分析（Mazya 2011、GrigorYan、Saloff-Coste 2002）の側面を、敵対的な例や一般化の限界などのML研究の活発な分野と橋渡しします。まず、敵対的な攻撃/防御メカニズムに照らして、決定境界の幾何学的な振る舞いに焦点を当てます。実験的に、さまざまな敵対的防御戦略にわたって特定のコンデンサー傾向を観察します。等周定理の不等式によって測定されるように、決定境界は局所的に平坦になります（Ford et al2019）。ただし、より感度の高い熱拡散メトリックはこの分析を拡張し、単純な距離ベースの方法では見えないいくつかの重要なジオメトリがまだ保持されていることをさらに明らかにします。直感的には、決定境界がそれにもかかわらず、より細かいスケールで多くの永続的な「波状でぼやけた」領域を保持しているという証拠を提供します。次に、ブラウン運動の確率が、圧縮とノイズの安定性に関連するソフトな一般化の境界にどのように変換されるかを示します（Arora et al 2018）。決定境界が幾何学的特徴を制御している場合、これらの境界は大幅に強くなります。,6.5,https://d3i71xaburhd42.cloudfront.net/329c246b5916c6d0fa066fbfd3586fa02a9c4ab7/2-Figure1-1.png
Spatial Dependency Networks: Neural Layers for Improved Generative Image Modeling,"['Đorđe Miladinović', 'Aleksandar Stanić', 'Stefan Bauer', 'Jürgen Schmidhuber', 'Joachim M. Buhmann']",https://openreview.net/forum?id=I4c4K9vBNny,"How to improve generative modeling by better exploiting spatial regularities and coherence in images? To answer this question, we introduce a novel neural layer for building image generators (decoders) and apply it to variational autoencoders (VAEs). Our spatial dependency networks (SDNs) compute feature maps in a spatially coherent way, utilizing a sequential gating-based mechanism to distribute contextual information across 2-D maps. Different SDN layers of a deep neural network represent spatial dependencies at different levels of abstraction. Augmenting the decoder of a hierarchical VAE by spatial dependencies considerably improves density estimation over baseline convolutional architectures and the state-of-the-art among the models within the same class. We show that SDN can be applied to large images by synthesizing samples of high quality and coherence. In a vanilla VAE setting, we find that a powerful SDN decoder also improves learning disentangled representations, indicating that neural architectures play an important role in this task. Our results suggest favoring SDNs over convolutional networks in various VAE settings.",画像の空間的規則性と一貫性をより有効に活用することにより、生成モデリングを改善するにはどうすればよいですか？この質問に答えるために、画像ジェネレーター（デコーダー）を構築するための新しいニューラルレイヤーを導入し、それを変分オートエンコーダー（VAE）に適用します。私たちの空間依存性ネットワーク（SDN）は、空間的にコヒーレントな方法で特徴マップを計算し、シーケンシャルゲーティングベースのメカニズムを利用して、コンテキスト情報を2Dマップ全体に分散します。ディープニューラルネットワークのさまざまなSDNレイヤーは、さまざまな抽象化レベルでの空間依存性を表します。空間依存性によって階層VAEのデコーダーを拡張すると、ベースライン畳み込みアーキテクチャーおよび同じクラス内のモデル間の最先端の密度推定が大幅に向上します。高品質でコヒーレンスのあるサンプルを合成することにより、SDNを大きな画像に適用できることを示します。バニラVAE設定では、強力なSDNデコーダーも解きほぐされた表現の学習を改善することがわかり、ニューラルアーキテクチャがこのタスクで重要な役割を果たすことを示しています。私たちの結果は、さまざまなVAE設定で畳み込みネットワークよりもSDNを優先することを示唆しています。,6.5,
Adaptive Universal Generalized PageRank Graph Neural Network,"['Eli Chien', 'Jianhao Peng', 'Pan Li', 'Olgica Milenkovic']",https://openreview.net/forum?id=n6jl7fLxrP,"In many important graph data processing applications the acquired information includes both node features and observations of the graph topology. Graph neural networks (GNNs) are designed to exploit both sources of evidence but they do not optimally trade-off their utility and integrate them in a manner that is also universal. Here, universality refers to independence on homophily or heterophily graph assumptions. We address these issues by introducing a new Generalized PageRank (GPR) GNN architecture that adaptively learns the GPR weights so as to jointly optimize node feature and topological information extraction, regardless of the extent to which the node labels are homophilic or heterophilic. Learned GPR weights automatically adjust to the node label pattern, irrelevant on the type of initialization, and thereby guarantee excellent learning performance for label patterns that are usually hard to handle. Furthermore, they allow one to avoid feature over-smoothing, a process which renders feature information nondiscriminative, without requiring the network to be shallow. Our accompanying theoretical analysis of the GPR-GNN method is facilitated by novel synthetic benchmark datasets generated by the so-called contextual stochastic block model. We also compare the performance of our GNN architecture with that of several state-of-the-art GNNs on the problem of node-classification, using well-known benchmark homophilic and heterophilic datasets. The results demonstrate that GPR-GNN offers significant performance improvement compared to existing techniques on both synthetic and benchmark data.",多くの重要なグラフデータ処理アプリケーションでは、取得された情報には、ノードの機能とグラフトポロジの観測の両方が含まれます。グラフニューラルネットワーク（GNN）は、両方の証拠ソースを活用するように設計されていますが、それらの有用性を最適にトレードオフして、普遍的な方法で統合することはありません。ここで、普遍性とは、ホモフィリーまたはヘテロフィリーグラフの仮定に対する独立性を指します。これらの問題に対処するために、GPRの重みを適応的に学習する新しいGeneralized PageRank（GPR）GNNアーキテクチャを導入して、ノードラベルの同種親和性または異好性の程度に関係なく、ノードの特徴とトポロジ情報の抽出を共同で最適化します。学習されたGPRの重みは、初期化のタイプに関係なく、ノードのラベルパターンに自動的に調整されるため、通常は処理が難しいラベルパターンの優れた学習パフォーマンスが保証されます。さらに、ネットワークを浅くすることなく、機能情報を無差別にするプロセスである機能の過度の平滑化を回避できます。 GPR-GNN法の付随する理論的分析は、いわゆるコンテキスト確率ブロックモデルによって生成された新しい合成ベンチマークデータセットによって促進されます。また、よく知られているベンチマークの同種親和性および異好性データセットを使用して、ノード分類の問題に関するGNNアーキテクチャのパフォーマンスをいくつかの最先端のGNNのパフォーマンスと比較します。結果は、GPR-GNNが、合成データとベンチマークデータの両方で既存の手法と比較して大幅なパフォーマンスの向上を提供することを示しています。,6.5,
What Should Not Be Contrastive in Contrastive Learning,"['Tete Xiao', 'Xiaolong Wang', 'Alexei A Efros', 'Trevor Darrell']",https://openreview.net/forum?id=CZ8Y3NzuVzO,"Recent self-supervised contrastive methods have been able to produce impressive transferable visual representations by learning to be invariant to different data augmentations. However, these methods implicitly assume a particular set of representational invariances (e.g., invariance to color), and can perform poorly when a downstream task violates this assumption (e.g., distinguishing red vs. yellow cars). We introduce a contrastive learning framework which does not require prior knowledge of specific, task-dependent invariances. Our model learns to capture varying and invariant factors for visual representations by constructing separate embedding spaces, each of which is invariant to all but one augmentation. We use a multi-head network with a shared backbone which captures information across each augmentation and alone outperforms all baselines on downstream tasks. We further find that the concatenation of the invariant and varying spaces performs best across all tasks we investigate, including coarse-grained, fine-grained, and few-shot downstream classification tasks, and various data corruptions.",最近の自己監視対照法は、さまざまなデータ拡張に対して不変であることを学習することにより、印象的な転送可能な視覚表現を生成することができました。ただし、これらのメソッドは、特定の表現の不変性（たとえば、色の不変性）を暗黙的に想定しており、ダウンストリームタスクがこの想定に違反している場合（たとえば、赤と黄色の車の区別）、パフォーマンスが低下する可能性があります。特定のタスク依存の不変性に関する事前の知識を必要としない対照的な学習フレームワークを紹介します。私たちのモデルは、それぞれが1つの拡張を除いてすべて不変である個別の埋め込みスペースを構築することにより、視覚的表現の変化する不変の要因をキャプチャすることを学習します。共有バックボーンを備えたマルチヘッドネットワークを使用します。このネットワークは、各拡張全体で情報をキャプチャし、ダウンストリームタスクのすべてのベースラインを単独で上回ります。さらに、不変で変化するスペースの連結は、粗粒度、細粒度、および数ショットのダウンストリーム分類タスクやさまざまなデータの破損など、調査するすべてのタスクで最高のパフォーマンスを発揮することがわかりました。,6.5,https://d3i71xaburhd42.cloudfront.net/c3a0059e69a10c8fe70efab423761e378fdab74b/2-Figure1-1.png
Deep Repulsive Clustering of Ordered Data Based on Order-Identity Decomposition,"['Seon-Ho Lee', 'Chang-Su Kim']",https://openreview.net/forum?id=Yz-XtK5RBxB,"We propose the deep repulsive clustering (DRC) algorithm of ordered data for effective order learning. First, we develop the order-identity decomposition (ORID) network to divide the information of an object instance into an order-related feature and an identity feature. Then, we group object instances into clusters according to their identity features using a repulsive term. Moreover, we estimate the rank of a test instance, by comparing it with references within the same cluster. Experimental results on facial age estimation, aesthetic score regression, and historical color image classification show that the proposed algorithm can cluster ordered data effectively and also yield excellent rank estimation performance.",効果的な順序学習のために、順序データの深反発クラスタリング（DRC）アルゴリズムを提案します。まず、オブジェクトインスタンスの情報を注文関連機能とID機能に分割するために、注文ID分解（ORID）ネットワークを開発します。次に、反発項を使用して、アイデンティティ機能に従ってオブジェクトインスタンスをクラスターにグループ化します。さらに、同じクラスター内の参照と比較することにより、テストインスタンスのランクを推定します。顔の年齢推定、美的スコア回帰、および履歴カラー画像分類に関する実験結果は、提案されたアルゴリズムが順序付けられたデータを効果的にクラスター化し、優れたランク推定パフォーマンスをもたらすことを示しています。,6.5,
Lipschitz Recurrent Neural Networks,"['N. Benjamin Erichson', 'Omri Azencot', 'Alejandro Queiruga', 'Liam Hodgkinson', 'Michael W. Mahoney']",https://openreview.net/forum?id=-N7PBXqOUJZ,"Viewing recurrent neural networks (RNNs) as continuous-time dynamical systems, we propose a recurrent unit that describes the hidden state's evolution with two parts: a well-understood linear component plus a Lipschitz nonlinearity. This particular functional form facilitates stability analysis of the long-term behavior of the recurrent unit using tools from nonlinear systems theory. In turn, this enables architectural design decisions before experimentation. Sufficient conditions for global stability of the recurrent unit are obtained, motivating a novel scheme for constructing hidden-to-hidden matrices. Our experiments demonstrate that the Lipschitz RNN can outperform existing recurrent units on a range of benchmark tasks, including computer vision, language modeling and speech prediction tasks. Finally, through Hessian-based analysis we demonstrate that our Lipschitz recurrent unit is more robust with respect to input and parameter perturbations as compared to other continuous-time RNNs.",リカレントニューラルネットワーク（RNN）を連続時間の動的システムと見なして、よく理解されている線形コンポーネントとリプシッツ非線形性の2つの部分で隠れた状態の進化を記述するリカレントユニットを提案します。この特定の関数形式は、非線形システム理論のツールを使用して、再発ユニットの長期的な動作の安定性分析を容易にします。これにより、実験前にアーキテクチャ設計を決定できます。反復ユニットのグローバルな安定性のための十分条件が得られ、隠れから隠された行列を構築するための新しいスキームを動機付けます。私たちの実験は、Lipschitz RNNが、コンピュータービジョン、言語モデリング、音声予測タスクなど、さまざまなベンチマークタスクで既存のリカレントユニットよりも優れていることを示しています。最後に、ヘッセ行列ベースの分析を通じて、リプシッツ回帰ユニットが、他の連続時間RNNと比較して、入力およびパラメーターの摂動に関してより堅牢であることを示します。,6.5,https://d3i71xaburhd42.cloudfront.net/bbc89fa342c06cf2216884238c531b1f6434e61d/5-Figure1-1.png
"Factorizing Declarative and Procedural Knowledge in Structured, Dynamical Environments","['Anirudh Goyal', 'Alex Lamb', 'Phanideep Gampa', 'Philippe Beaudoin', 'Charles Blundell', 'Sergey Levine', 'Yoshua Bengio', 'Michael Curtis Mozer']",https://openreview.net/forum?id=VVdmjgu7pKM,"Modeling a structured, dynamic environment like a video game requires keeping track of the objects and their states (declarative knowledge) as well as predicting how objects behave (procedural knowledge). Black-box models with a monolithic hidden state often fail to apply procedural knowledge consistently and uniformly, i.e., they lack systematicity. For example, in a video game, correct prediction of one enemy's trajectory does not ensure correct prediction of another's. We address this issue via an architecture that factorizes declarative and procedural knowledge and that imposes modularity within each form of knowledge. The architecture consists of active modules called object files that maintain the state of a single object and invoke passive external knowledge sources called schemata that prescribe state updates. To use a video game as an illustration, two enemies of the same type will share schemata but will have separate object files to encode their distinct state (e.g., health, position). We propose to use attention to determine which object files to update, the selection of schemata, and the propagation of information between object files. The resulting architecture is a drop-in replacement conforming to the same input-output interface as normal recurrent networks (e.g., LSTM, GRU) yet achieves substantially better generalization on environments that have multiple object tokens of the same type, including a challenging intuitive physics benchmark.
",ビデオゲームのような構造化された動的な環境をモデル化するには、オブジェクトとその状態を追跡し（宣言的知識）、オブジェクトの動作を予測する（手続き的知識）必要があります。モノリシックな隠れた状態のブラックボックスモデルは、手続き的知識を一貫して均一に適用できないことがよくあります。つまり、体系性に欠けています。たとえば、ビデオゲームでは、ある敵の軌道を正しく予測しても、別の敵の軌道を正しく予測することはできません。この問題は、宣言的知識と手続き的知識を要素化し、知識の各形式にモジュール性を課すアーキテクチャを介して対処します。このアーキテクチャは、単一のオブジェクトの状態を維持し、状態の更新を規定するスキーマと呼ばれるパッシブな外部ナレッジソースを呼び出すオブジェクトファイルと呼ばれるアクティブモジュールで構成されています。ビデオゲームを例として使用するために、同じタイプの2人の敵はスキーマを共有しますが、それらの異なる状態（たとえば、健康、位置）をエンコードするために別々のオブジェクトファイルを持ちます。注意を使用して、更新するオブジェクトファイル、スキーマの選択、およびオブジェクトファイル間の情報の伝播を決定することを提案します。結果として得られるアーキテクチャは、通常のリカレントネットワーク（LSTM、GRUなど）と同じ入出力インターフェイスに準拠するドロップイン置換ですが、挑戦的な直感的な物理学を含む、同じタイプの複数のオブジェクトトークンを持つ環境で大幅に優れた一般化を実現します基準。,6.5,
Learning with AMIGo: Adversarially Motivated Intrinsic Goals,"['Andres Campero', 'Roberta Raileanu', 'Heinrich Kuttler', 'Joshua B. Tenenbaum', 'Tim Rocktäschel', 'Edward Grefenstette']",https://openreview.net/forum?id=ETBc_MIMgoX,"A key challenge for reinforcement learning (RL) consists of learning in environments with sparse extrinsic rewards. In contrast to current RL methods, humans are able to learn new skills with little or no reward by using various forms of intrinsic motivation. We propose AMIGo, a novel agent incorporating a goal-generating teacher that proposes Adversarially Motivated Intrinsic Goals to train a goal-conditioned student'' policy in the absence of (or alongside) environment reward. Specifically, through a simple but effective ``constructively adversarial'' objective, the teacher learns to propose increasingly challenging---yet achievable---goals that allow the student to learn general skills for acting in a new environment, independent of the task to be solved. We show that our method generates a natural curriculum of self-proposed goals which ultimately allows the agent to solve challenging procedurally-generated tasks where other forms of intrinsic motivation and state-of-the-art RL methods fail.",強化学習（RL）の重要な課題は、外因性の報酬がまばらな環境での学習です。現在のRL手法とは対照的に、人間はさまざまな形の固有の動機付けを使用することにより、報酬がほとんどまたはまったくない新しいスキルを学ぶことができます。私たちはAMIGoを提案します。これは、環境報酬がない場合（または環境報酬と一緒に）に目標条件付きの学生ポリシーをトレーニングするために、敵対的に動機付けられた内在的目標を提案する目標生成教師を組み込んだ新しいエージェントです。具体的には、シンプルで効果的な建設的な敵対的目標を通じて、教師は、解決すべき課題とは無関係に、生徒が新しい環境で行動するための一般的なスキルを学ぶことを可能にする、ますます挑戦的でありながら達成可能な目標を提案することを学びます。私たちの方法は、自己提案された目標の自然なカリキュラムを生成し、最終的には、他の形式の本質的な動機付けや最先端の​​RL方法が失敗する、手続き的に生成された困難なタスクをエージェントが解決できることを示します。,6.5,https://d3i71xaburhd42.cloudfront.net/e2f5b8472656491c6e280b90b1305ec46d505b4f/2-Figure1-1.png
Layer-adaptive Sparsity for the Magnitude-based Pruning,"['Jaeho Lee', 'Sejun Park', 'Sangwoo Mo', 'Sungsoo Ahn', 'Jinwoo Shin']",https://openreview.net/forum?id=H6ATjJ0TKdf,"Recent discoveries on neural network pruning reveal that, with a carefully chosen layerwise sparsity, a simple magnitude-based pruning achieves state-of-the-art tradeoff between sparsity and performance. However, without a clear consensus on ``how to choose,'' the layerwise sparsities are mostly selected algorithm-by-algorithm, often resorting to handcrafted heuristics or an extensive hyperparameter search. To fill this gap, we propose a novel importance score for global pruning, coined layer-adaptive magnitude-based pruning (LAMP) score; the score is a rescaled version of weight magnitude that incorporates the model-level $\ell_2$ distortion incurred by pruning, and does not require any hyperparameter tuning or heavy computation. Under various image classification setups, LAMP consistently outperforms popular existing schemes for layerwise sparsity selection. Furthermore, we observe that LAMP continues to outperform baselines even in weight-rewinding setups, while the connectivity-oriented layerwise sparsity (the strongest baseline overall) performs worse than a simple global magnitude-based pruning in this case.",ニューラルネットワークの剪定に関する最近の発見は、慎重に選択された層ごとのスパース性により、単純なマグニチュードベースの剪定がスパース性とパフォーマンスの間の最先端のトレードオフを達成することを明らかにしています。ただし、選択方法に関する明確なコンセンサスがない場合、レイヤーごとのスパース性は、ほとんどの場合、アルゴリズムごとに選択され、多くの場合、手作りのヒューリスティックまたは広範なハイパーパラメーター検索に頼ります。このギャップを埋めるために、グローバルプルーニング、造語層適応マグニチュードベースプルーニング（LAMP）スコアの新しい重要度スコアを提案します。スコアは、剪定によって発生するモデルレベルのl2歪みを組み込んだ重みの大きさの再スケーリングされたバージョンであり、ハイパーパラメータの調整や大量の計算を必要としません。さまざまな画像分類設定の下で、LAMPは、レイヤーごとのスパース性選択のための一般的な既存のスキームを一貫して上回っています。さらに、LAMPは、ウェイト巻き戻しの設定でもベースラインを上回り続けますが、この場合、接続指向のレイヤーワイズスパース性（全体として最も強いベースライン）は、単純なグローバルマグニチュードベースのプルーニングよりもパフォーマンスが低下します。,6.5,
"On InstaHide, Phase Retrieval, and Sparse Matrix Factorization","['Sitan Chen', 'Xiaoxiao Li', 'Zhao Song', 'Danyang Zhuo']",https://openreview.net/forum?id=AhElGnhU2BV,"In this work, we examine the security of InstaHide, a scheme recently proposed by \cite{hsla20} for preserving the security of private datasets in the context of distributed learning. To generate a synthetic training example to be shared among the distributed learners, InstaHide takes a convex combination of private feature vectors and randomly flips the sign of each entry of the resulting vector with probability 1/2. A salient question is whether this scheme is secure in any provable sense, perhaps under a plausible complexity-theoretic assumption. 

The answer to this turns out to be quite subtle and closely related to the average-case complexity of a multi-task, missing-data version of the classic problem of phase retrieval that is interesting in its own right. Motivated by this connection, under the standard distributional assumption that the public/private feature vectors are isotropic Gaussian, we design an algorithm that can actually recover a private vector using only the public vectors and a sequence of synthetic vectors generated by InstaHide.",この作業では、分散学習のコンテキストでプライベートデータセットのセキュリティを維持するために最近提案されたスキームであるInstaHideのセキュリティを調べます。分散学習者間で共有される合成トレーニングの例を生成するために、InstaHideはプライベート特徴ベクトルの凸結合を取り、結果のベクトルの各エントリの符号を確率1/2でランダムに反転します。重要な問題は、おそらくもっともらしい複雑さ理論の仮定の下で、このスキームが証明可能な意味で安全であるかどうかです。これに対する答えは非常に微妙であり、それ自体が興味深い位相回復の古典的な問題のマルチタスク、欠測データバージョンの平均的なケースの複雑さに密接に関連していることがわかります。この接続に動機付けられて、パブリック/プライベート特徴ベクトルが等方性ガウス分布であるという標準的な分布の仮定の下で、パブリックベクトルとInstaHideによって生成された合成ベクトルのシーケンスのみを使用してプライベートベクトルを実際に復元できるアルゴリズムを設計します。,6.5,https://d3i71xaburhd42.cloudfront.net/7a9074a58c73061beac981899069182a39ccec30/20-Figure1-1.png
GANs Can Play Lottery Tickets Too,"['Xuxi Chen', 'Zhenyu Zhang', 'Yongduo Sui', 'Tianlong Chen']",https://openreview.net/forum?id=1AoMhc_9jER,"Deep generative adversarial networks (GANs) have gained growing popularity in numerous scenarios, while usually suffer from high parameter complexities for resource-constrained real-world applications. However, the compression of GANs has less been explored. A few works show that heuristically applying compression techniques normally leads to unsatisfactory results, due to the notorious training instability (of GANs). In parallel, the lottery ticket hypothesis shows prevailing success on discriminative models, in locating sparse matching subnetworks capable of training in isolation to full model performance. In this work, we for the first time study the existence of such trainable matching subnetworks in deep GANs. For a range of GANs, we certainly find matching subnetworks at 67%-74% sparsity. We observe that with or without pruning discriminator has a minor effect on the existence and quality of matching subnetworks, while the initialization used in the discriminator plays a significant role. We then show the powerful transferability of these subnetworks to unseen tasks. Furthermore, extensive experimental results demonstrate that our found subnetworks substantially outperform previous state-of-the-art GAN compression approaches in both image generation (e.g. SNGAN) and image-to-image translation GANs (e.g. CycleGAN).",深い生成的敵対的ネットワーク（GAN）は、多くのシナリオで人気が高まっていますが、通常、リソースに制約のある実際のアプリケーションではパラメーターが複雑になります。ただし、GANの圧縮についてはあまり検討されていません。いくつかの研究は、（GANの）悪名高いトレーニングの不安定性のために、ヒューリスティックに圧縮技術を適用すると、通常、不十分な結果につながることを示しています。並行して、宝くじの仮説は、完全なモデルのパフォーマンスとは別にトレーニングできるスパースマッチングサブネットワークを見つけることで、識別モデルでの一般的な成功を示しています。この作業では、ディープGANにおけるこのようなトレーニング可能なマッチングサブネットワークの存在を初めて調査します。さまざまなGANについて、一致するサブネットワークが67にあることは確かです。,6.5,
Meta Attention Networks: Meta-Learning Attention to Modulate Information Between Recurrent Independent Mechanisms,"['Kanika Madan', 'Nan Rosemary Ke', 'Anirudh Goyal', 'Bernhard Schölkopf', 'Yoshua Bengio']",https://openreview.net/forum?id=Lc28QAB4ypz,"Decomposing knowledge into interchangeable pieces promises a generalization advantage when there are changes in distribution. A learning agent interacting with the environment is likely to be faced with situations requiring novel combinations of existing pieces of knowledge. We hypothesize that such a decomposition of knowledge is particularly relevant for being able to generalize in a systematic way to out of distribution changes. To study these ideas, we propose a particular training framework in which we assume that the pieces of knowledge an agent needs, as well as its reward function are stationary and can be re-used across tasks. The attention mechanisms dynamically select which modules should be adapted, and the parameters of the \textit{selected} modules are changed quickly as a learner is confronted with variations in what it experiences, while the parameters of the attention mechanisms act as slowly changing meta-parameters. We focus on pieces of knowledge captured by an ensemble of  modules sparsely communicating with each other via a bottleneck of attention. We find that meta-learning the  modular aspects of the proposed system greatly help in achieving faster learning, in experiments with a reinforcement learning setup involving navigation in a partially observed grid world with image-level input.  We also find that reversing the role of parameters and meta-parameters does not work nearly as well, suggesting a particular role for fast adaptation of the dynamically selected modules.",知識を交換可能な部分に分解することは、分布に変化がある場合に一般化の利点を約束します。環境と相互作用する学習エージェントは、既存の知識の新しい組み合わせを必要とする状況に直面する可能性があります。このような知識の分解は、分布の変化を体系的に一般化できることに特に関連していると仮定します。これらのアイデアを研究するために、エージェントが必要とする知識の断片とその報酬機能が固定されており、タスク間で再利用できると想定する特定のトレーニングフレームワークを提案します。注意メカニズムはどのモジュールを適応させるかを動的に選択し、選択されたモジュールのパラメーターは、学習者が経験するものの変化に直面するとすぐに変更され、注意メカニズムのパラメーターはゆっくりと変化するメタパラメーターとして機能します。私たちは、注意のボトルネックを介して互いにまばらに通信するモジュールのアンサンブルによってキャプチャされた知識の断片に焦点を当てます。提案されたシステムのモジュール式の側面をメタ学習することは、画像レベルの入力で部分的に観察されたグリッド世界でのナビゲーションを含む強化学習セットアップの実験で、より高速な学習を達成するのに大いに役立つことがわかります。また、パラメーターとメタパラメーターの役割を逆にすることもほとんど機能しないことがわかり、動的に選択されたモジュールを迅速に適応させるための特定の役割を示唆しています。,6.5,
Generalized Variational Continual Learning,"['Noel Loo', 'Siddharth Swaroop', 'Richard E Turner']",https://openreview.net/forum?id=_IM-AfFhna9,"Continual learning deals with training models on new tasks and datasets in an online fashion. One strand of research has used probabilistic regularization for continual learning, with two of the main approaches in this vein being Online Elastic Weight Consolidation (Online EWC) and Variational Continual Learning (VCL). VCL employs variational inference, which in other settings has been improved empirically by applying likelihood-tempering. We show that applying this modification to VCL recovers Online EWC as a limiting case, allowing for interpolation between the two approaches. We term the general algorithm Generalized VCL (GVCL). In order to mitigate the observed overpruning effect of VI, we take inspiration from a common multi-task architecture, neural networks with task-specific FiLM layers, and find that this addition leads to significant performance gains, specifically for variational methods. In the small-data regime, GVCL strongly outperforms existing baselines. In larger datasets, GVCL with FiLM layers outperforms or is competitive with existing baselines in terms of accuracy, whilst also providing significantly better calibration.",継続学習では、新しいタスクとデータセットに関するトレーニングモデルをオンラインで扱います。研究の1つのストランドは、継続的な学習に確率的正則化を使用しており、この静脈の2つの主要なアプローチは、オンライン弾性重量統合（オンラインEWC）と変分継続学習（VCL）です。 VCLは変分推論を採用していますが、他の設定では、尤度テンパリングを適用することで経験的に改善されています。この変更をVCLに適用すると、オンラインEWCが限定的なケースとして回復し、2つのアプローチ間の補間が可能になることを示します。一般的なアルゴリズムをGeneralizedVCL（GVCL）と呼びます。 VIの観察されたオーバープルーニング効果を軽減するために、一般的なマルチタスクアーキテクチャ、タスク固有のFiLMレイヤーを備えたニューラルネットワークからインスピレーションを得て、この追加により、特に変分法のパフォーマンスが大幅に向上することがわかりました。小規模データ体制では、GVCLは既存のベースラインを大幅に上回っています。大規模なデータセットでは、FiLMレイヤーを備えたGVCLは、精度の点で既存のベースラインよりも優れているか、競合していますが、大幅に優れたキャリブレーションも提供します。,6.5,https://d3i71xaburhd42.cloudfront.net/6b41ca9988f832737430b24bdcf37000e1af62ea/5-Figure1-1.png
HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients,"['Enmao Diao', 'Jie Ding', 'Vahid Tarokh']",https://openreview.net/forum?id=TNkPBBYFkXg,"Federated Learning (FL) is a method of training machine learning models on private data distributed over a large number of possibly heterogeneous clients such as mobile phones and IoT devices. In this work, we propose a new federated learning framework named HeteroFL to address heterogeneous clients equipped with very different computation and communication capabilities. Our solution can enable the training of heterogeneous local models with varying computation complexities and still produce a single global inference model. For the first time, our method challenges the underlying assumption of existing work that local models have to share the same architecture as the global model. We demonstrate several strategies to enhance FL training and conduct extensive empirical evaluations, including five computation complexity levels of three model architecture on three datasets. We show that adaptively distributing subnetworks according to clients' capabilities is both computation and communication efficient.",Federated Learning（FL）は、携帯電話やIoTデバイスなど、異種の可能性のある多数のクライアントに分散されたプライベートデータで機械学習モデルをトレーニングする方法です。この作業では、非常に異なる計算および通信機能を備えた異種クライアントに対処するために、HeteroFLという名前の新しいフェデレーション学習フレームワークを提案します。私たちのソリューションは、さまざまな計算の複雑さを持つ異種ローカルモデルのトレーニングを可能にし、それでも単一のグローバル推論モデルを生成できます。初めて、私たちの方法は、ローカルモデルがグローバルモデルと同じアーキテクチャを共有する必要があるという既存の作業の根本的な仮定に挑戦します。 FLトレーニングを強化し、3つのデータセットに対する3つのモデルアーキテクチャの5つの計算の複雑さのレベルを含む、広範な経験的評価を実施するためのいくつかの戦略を示します。クライアントの機能に応じてサブネットワークを適応的に分散することは、計算と通信の両方の効率が高いことを示しています。,6.5,
WaveGrad: Estimating Gradients for Waveform Generation,"['Nanxin Chen', 'Yu Zhang', 'Heiga Zen', 'Ron J Weiss', 'Mohammad Norouzi', 'William Chan']",https://openreview.net/forum?id=NsMLjcFaO8O,"This paper introduces WaveGrad, a conditional model for waveform generation which estimates gradients of the data density. The model is built on prior work on score matching and diffusion probabilistic models. It starts from a Gaussian white noise signal and iteratively refines the signal via a gradient-based sampler conditioned on the mel-spectrogram.
WaveGrad offers a natural way to trade inference speed for sample quality by adjusting the number of refinement steps, and bridges the gap between non-autoregressive and autoregressive models in terms of audio quality.
We find that it can generate high fidelity audio samples using as few as six iterations.
Experiments reveal WaveGrad to generate high fidelity audio, outperforming adversarial non-autoregressive baselines and matching a strong likelihood-based autoregressive baseline using fewer sequential operations.  Audio samples are available at https://wavegrad-iclr2021.github.io/.",本稿では、データ密度の勾配を推定する波形生成の条件付きモデルであるWaveGradを紹介します。このモデルは、スコアマッチングと拡散確率モデルに関する以前の作業に基づいて構築されています。ガウスホワイトノイズ信号から始まり、メルスペクトログラムを条件とするグラジエントベースのサンプラーを介して信号を繰り返し調整します。 WaveGradは、リファインメントステップの数を調整することにより、推論速度をサンプル品質と交換する自然な方法を提供し、オーディオ品質に関して非自己回帰モデルと自己回帰モデルの間のギャップを埋めます。わずか6回の反復で、忠実度の高いオーディオサンプルを生成できることがわかりました。実験により、WaveGradは忠実度の高いオーディオを生成し、敵対的な非自己回帰ベースラインを上回り、より少ない順次操作を使用して強い尤度ベースの自己回帰ベースラインと一致することが明らかになりました。オーディオサンプルはhttps://wavegrad-iclr2021.github.io/で入手できます。,6.5,
Language-Agnostic Representation Learning of Source Code from Structure and Context,"['Daniel Zügner', 'Tobias Kirschstein', 'Michele Catasta', 'Jure Leskovec', 'Stephan Günnemann']",https://openreview.net/forum?id=Xh5eMZVONGF,"Source code (Context) and its parsed abstract syntax tree (AST; Structure) are two complementary representations of the same computer program. Traditionally, designers of machine learning models have relied predominantly either on Structure or Context. We propose a new model, which jointly learns on Context and Structure of source code. In contrast to previous approaches, our model uses only language-agnostic features, i.e., source code and features that can be computed directly from the AST. Besides obtaining state-of-the-art on monolingual code summarization on all five programming languages considered in this work, we propose the first multilingual code summarization model. We show that jointly training on non-parallel data from multiple programming languages improves results on all individual languages, where the strongest gains are on low-resource languages. Remarkably, multilingual training only from Context does not lead to the same improvements, highlighting the benefits of combining Structure and Context for representation learning on code.",ソースコード（コンテキスト）とその解析された抽象構文ツリー（AST;構造）は、同じコンピュータープログラムの2つの補完的な表現です。従来、機械学習モデルの設計者は、主に構造またはコンテキストのいずれかに依存してきました。ソースコードのコンテキストと構造を共同で学習する新しいモデルを提案します。以前のアプローチとは対照的に、私たちのモデルは言語に依存しない機能、つまりソースコードとASTから直接計算できる機能のみを使用します。この作業で検討した5つのプログラミング言語すべてで最新の単一言語コード要約を取得することに加えて、最初の多言語コード要約モデルを提案します。複数のプログラミング言語からの非並列データを共同でトレーニングすると、リソースの少ない言語で最も大きなメリットが得られるすべての個々の言語での結果が向上することを示します。注目すべきことに、コンテキストからの多言語トレーニングだけでは同じ改善にはつながらず、コードでの表現学習のために構造とコンテキストを組み合わせる利点が強調されています。,6.5,
BiPointNet: Binary Neural Network for Point Clouds,"['Haotong Qin', 'Zhongang Cai', 'Mingyuan Zhang', 'Yifu Ding', 'Haiyu Zhao', 'Shuai Yi', 'Xianglong Liu', 'Hao Su']",https://openreview.net/forum?id=9QLRCVysdlO,"To alleviate the resource constraint for real-time point cloud applications that run on edge devices, in this paper we present BiPointNet, the first model binarization approach for efficient deep learning on point clouds. We first discover that the immense performance drop of binarized models for point clouds mainly stems from two challenges: aggregation-induced feature homogenization that leads to a degradation of information entropy, and scale distortion that hinders optimization and invalidates scale-sensitive structures. With theoretical justifications and in-depth analysis, our BiPointNet introduces Entropy-Maximizing Aggregation (EMA) to modulate the distribution before aggregation for the maximum information entropy, and Layer-wise Scale Recovery (LSR) to efficiently restore feature representation capacity. Extensive experiments show that BiPointNet outperforms existing binarization methods by convincing margins, at the level even comparable with the full precision counterpart. We highlight that our techniques are generic, guaranteeing significant improvements on various fundamental tasks and mainstream backbones, e.g., BiPointNet gives an impressive 14.7× speedup and 18.9× storage saving on real-world resource-constrained devices.",エッジデバイスで実行されるリアルタイムポイントクラウドアプリケーションのリソース制約を緩和するために、このホワイトペーパーでは、ポイントクラウドでの効率的なディープラーニングのための最初のモデル2値化アプローチであるBiPointNetを紹介します。最初に、点群の2値化モデルのパフォーマンスの大幅な低下は、主に2つの課題に起因することを発見しました。情報エントロピーの低下につながる集約による特徴の均質化と、最適化を妨げ、スケールに敏感な構造を無効にするスケールの歪みです。理論的な正当化と詳細な分析により、BiPointNetは、エントロピー最大化集約（EMA）を導入して、最大の情報エントロピーを集約する前に分布を変調し、レイヤーワイズスケールリカバリ（LSR）を導入して、特徴表現能力を効率的に復元します。広範な実験により、BiPointNetは、完全な精度の対応物と同等のレベルで、説得力のあるマージンによって既存の2値化方法よりも優れていることが示されています。私たちの手法は一般的であり、さまざまな基本的なタスクと主流のバックボーンの大幅な改善を保証します。たとえば、BiPointNetは、実際のリソースに制約のあるデバイスで14.7の高速化と18.9のストレージ節約を実現します。,6.5,https://d3i71xaburhd42.cloudfront.net/cb6d59c675fc05d6fd8d0aedc50b04f31ca13d36/2-Figure1-1.png
Meta-Learning of Structured Task Distributions in Humans and Machines,"['Sreejan Kumar', 'Ishita Dasgupta', 'Jonathan Cohen', 'Nathaniel Daw', 'Thomas Griffiths']",https://openreview.net/forum?id=--gvHfE3Xf5,"In recent years, meta-learning, in which a model is trained on a family of tasks (i.e. a task distribution), has emerged as an approach to training neural networks to perform tasks that were previously assumed to require structured representations, making strides toward closing the gap between humans and machines. However, we argue that evaluating meta-learning remains a challenge, and can miss whether meta-learning actually uses the structure embedded within the tasks. These meta-learners might therefore still be significantly different from humans learners. To demonstrate this difference, we first define a new meta-reinforcement learning task in which a structured task distribution is generated using a compositional grammar. We then introduce a novel approach to constructing a ""null task distribution"" with the same statistical complexity as this structured task distribution but without the explicit rule-based structure used to generate the structured task. We train a standard meta-learning agent, a recurrent network trained with model-free reinforcement learning, and compare it with human performance across the two task distributions. We find a double dissociation in which humans do better in the structured task distribution whereas agents do better in the null task distribution -- despite comparable statistical complexity. This work highlights that multiple strategies can achieve reasonable meta-test performance, and that careful construction of control task distributions is a valuable way to understand which strategies meta-learners acquire, and how they might differ from humans. ",近年、モデルがタスクのファミリー（つまりタスク分散）でトレーニングされるメタ学習が、以前は構造化された表現が必要であると想定されていたタスクを実行するようにニューラルネットワークをトレーニングするアプローチとして登場しました。人間と機械の間のギャップを埋めます。ただし、メタ学習の評価は依然として課題であり、メタ学習が実際にタスクに埋め込まれた構造を使用しているかどうかを見逃す可能性があると主張します。したがって、これらのメタ学習者は、人間の学習者とはまだ大幅に異なる可能性があります。この違いを示すために、最初に、構造化されたタスク分布が構成文法を使用して生成される新しいメタ強化学習タスクを定義します。次に、この構造化タスク分布と同じ統計的複雑さで、構造化タスクの生成に使用される明示的なルールベースの構造を使用せずに、「ヌルタスク分布」を構築するための新しいアプローチを紹介します。標準のメタ学習エージェント、モデルフリー強化学習でトレーニングされたリカレントネットワークをトレーニングし、2つのタスク分布全体で人間のパフォーマンスと比較します。統計的な複雑さが同等であるにもかかわらず、人間は構造化されたタスクの分布で優れているのに対し、エージェントはヌルのタスクの分布で優れているという二重の解離が見つかります。この作業は、複数の戦略が妥当なメタテストのパフォーマンスを達成できること、および制御タスクの分布を注意深く構築することが、メタ学習者が取得する戦略と、それらが人間とどのように異なるかを理解するための貴重な方法であることを強調しています。,6.5,
A Trainable Optimal Transport Embedding for Feature Aggregation,"['Grégoire Mialon', 'Dexiong Chen', ""Alexandre d'Aspremont"", 'Julien Mairal']",https://openreview.net/forum?id=ZK6vTvb84s,"We address the problem of learning on large sets of features, motivated by the need of performing pooling operations in long biological sequences of varying sizes, with long-range dependencies, and possibly few labeled data. To address this challenging task, we introduce a parametrized embedding that aggregates the features from a given set according to the optimal transport plan between the set and a trainable reference. Our approach scales to large datasets and allows end-to-end training of the reference, while also providing a simple unsupervised learning mechanism with small computational cost. Our aggregation technique admits two useful interpretations: it may be seen as a mechanism related to attention layers in neural networks, yet that requires less data, or it may be seen as a scalable surrogate of a classical optimal transport-based kernel. We experimentally demonstrate the effectiveness of our approach on biological sequences, achieving state-of-the-art results for protein fold recognition and detection of chromatin profiles tasks, and, as a proof of concept, we show promising results for processing natural language sequences. We provide an open-source implementation of our embedding that can be used alone or as a module in larger learning models.",さまざまなサイズの長い生物学的シーケンスで、長距離の依存関係があり、ラベル付けされたデータがほとんどない場合にプール操作を実行する必要性に動機付けられた、機能の大規模なセットでの学習の問題に対処します。この困難なタスクに対処するために、セットとトレーニング可能な参照の間の最適な輸送計画に従って、特定のセットからの機能を集約するパラメーター化された埋め込みを導入します。私たちのアプローチは、大規模なデータセットに拡張し、参照のエンドツーエンドのトレーニングを可能にすると同時に、小さな計算コストで単純な教師なし学習メカニズムを提供します。私たちの集約手法は、2つの有用な解釈を認めています。それは、ニューラルネットワークの注意層に関連するメカニズムと見なされる可能性がありますが、必要なデータは少なくなります。または、古典的な最適なトランスポートベースのカーネルのスケーラブルな代理と見なされる可能性があります。生物学的配列に対するアプローチの有効性を実験的に示し、タンパク質の折り畳み認識とクロマチンプロファイルタスクの検出に関する最先端の結果を達成し、概念実証として、自然言語配列の処理に有望な結果を示します。埋め込みのオープンソース実装を提供します。これは、単独で使用することも、より大きな学習モデルのモジュールとして使用することもできます。,6.5,https://d3i71xaburhd42.cloudfront.net/8ed6ed82c7a8ce90c0f6e693a1087952cf0c4a4a/6-Figure1-1.png
Convex Potential Flows: Universal Probability Distributions with Optimal Transport and Convex Optimization,"['Chin-Wei Huang', 'Ricky T. Q. Chen', 'Christos Tsirigotis', 'Aaron Courville']",https://openreview.net/forum?id=te7PVH1sPxJ,"Flow-based models are powerful tools for designing probabilistic models with tractable density. This paper introduces Convex Potential Flows (CP-Flow), a natural and efficient parameterization of invertible models inspired by the optimal transport (OT) theory. CP-Flows are the gradient map of a strongly convex neural potential function. The convexity implies invertibility and allows us to resort to convex optimization to solve the convex conjugate for efficient inversion. To enable maximum likelihood training, we derive a new gradient estimator of the log-determinant of the Jacobian, which involves solving an inverse-Hessian vector product using the conjugate gradient method. The gradient estimator has constant-memory cost, and can be made effectively unbiased by reducing the error tolerance level of the convex optimization routine. Theoretically, we prove that CP-Flows are universal density approximators and are optimal in the OT sense. Our empirical results show that CP-Flow performs competitively on standard benchmarks of density estimation and variational inference.",フローベースのモデルは、扱いやすい密度の確率モデルを設計するための強力なツールです。このホワイトペーパーでは、最適輸送（OT）理論に触発された可逆モデルの自然で効率的なパラメーター化である凸ポテンシャルフロー（CP-Flow）を紹介します。 CP-Flowは、強く凸の神経ポテンシャル関数の勾配マップです。凸性は可逆性を意味し、効率的な反転のために凸共役を解くために凸最適化に頼ることができます。最尤法のトレーニングを可能にするために、共役勾配法を使用して逆ヘッセベクトル積を解くことを含む、ヤコビアンの対数決定子の新しい勾配推定量を導出します。勾配推定器には一定のメモリコストがあり、凸最適化ルーチンのエラー許容レベルを下げることで効果的にバイアスをかけることができません。理論的には、CP-Flowが普遍的な密度近似器であり、OTの意味で最適であることを証明します。私たちの経験的結果は、CP-Flowが密度推定と変分推論の標準ベンチマークで競争力を持って機能することを示しています。,6.5,https://d3i71xaburhd42.cloudfront.net/7156cef2a8f1425928224bd7ff39b6958b5fda8c/3-Figure1-1.png
Meta-learning with negative learning rates,['Alberto Bernacchia'],https://openreview.net/forum?id=60j5LygnmD,"Deep learning models require a large amount of data to perform well. When data is scarce for a target task, we can transfer the knowledge gained by training on similar tasks to quickly learn the target. A successful approach is meta-learning, or ""learning to learn"" a distribution of tasks, where ""learning"" is represented by an outer loop, and ""to learn"" by an inner loop of gradient descent. However, a number of recent empirical studies argue that the inner loop is unnecessary and more simple models work equally well or even better. We study the performance of MAML as a function of the learning rate of the inner loop, where zero learning rate implies that there is no inner loop. Using random matrix theory and exact solutions of linear models, we calculate an algebraic expression for the test loss of MAML applied to mixed linear regression and nonlinear regression with overparameterized models. Surprisingly, while the optimal learning rate for adaptation is positive, we find that the optimal learning rate for training is always negative, a setting that has never been considered before. Therefore, not only does the performance increase by decreasing the learning rate to zero, as suggested by recent work, but it can be increased even further by decreasing the learning rate to negative values. These results help clarify under what circumstances meta-learning performs best. 
",ディープラーニングモデルを適切に実行するには、大量のデータが必要です。ターゲットタスクのデータが不足している場合は、同様のタスクのトレーニングで得られた知識を転送して、ターゲットをすばやく学習できます。成功するアプローチは、メタ学習、つまりタスクの分散を「学習すること」です。「学習」は外側のループで表され、「学習する」は最急降下法の内側のループで表されます。ただし、最近の多くの経験的研究では、内部ループは不要であり、より単純なモデルでも同等またはそれ以上に機能すると主張しています。内側ループの学習率の関数としてMAMLのパフォーマンスを調査します。ここで、学習率がゼロの場合は、内側ループがないことを意味します。ランダム行列理論と線形モデルの正確な解を使用して、パラメーター化されたモデルを使用した混合線形回帰と非線形回帰に適用されるMAMLのテスト損失の代数式を計算します。驚いたことに、適応のための最適な学習率は正ですが、トレーニングのための最適な学習率は常に負であり、これまで考慮されたことのない設定であることがわかりました。したがって、最近の研究で示唆されているように、学習率をゼロに下げることでパフォーマンスが向上するだけでなく、学習率を負の値に下げることでさらにパフォーマンスを向上させることができます。これらの結果は、どのような状況でメタ学習が最も効果的かを明らかにするのに役立ちます。,6.5,https://d3i71xaburhd42.cloudfront.net/c5f1fde96d119638e61acf834ee980ac16c26560/3-Figure1-1.png
Learning Task-General Representations with Generative Neuro-Symbolic Modeling,"['Reuben Feinman', 'Brenden M. Lake']",https://openreview.net/forum?id=qzBUIzq5XR2,"People can learn rich, general-purpose conceptual representations from only raw perceptual inputs. Current machine learning approaches fall well short of these human standards, although different modeling traditions often have complementary strengths. Symbolic models can capture the compositional and causal knowledge that enables flexible generalization, but they struggle to learn from raw inputs, relying on strong abstractions and simplifying assumptions. Neural network models can learn directly from raw data, but they struggle to capture compositional and causal structure and typically must retrain to tackle new tasks. We bring together these two traditions to learn generative models of concepts that capture rich compositional and causal structure, while learning from raw data. We develop a generative neuro-symbolic (GNS) model of handwritten character concepts that uses the control flow of a probabilistic program, coupled with symbolic stroke primitives and a symbolic image renderer, to represent the causal and compositional processes by which characters are formed. The distributions of parts (strokes), and correlations between parts, are modeled with neural network subroutines, allowing the model to learn directly from raw data and express nonparametric statistical relationships. We apply our model to the Omniglot challenge of human-level concept learning, using a background set of alphabets to learn an expressive prior distribution over character drawings. In a subsequent evaluation, our GNS model uses probabilistic inference to learn rich conceptual representations from a single training image that generalize to 4 unique tasks, succeeding where previous work has fallen short.",人々は、生の知覚入力だけから、豊かで汎用的な概念表現を学ぶことができます。現在の機械学習アプローチは、これらの人間の基準をはるかに下回っていますが、さまざまなモデリングの伝統には補完的な長所があることがよくあります。シンボリックモデルは、柔軟な一般化を可能にする構成的および因果的知識を取り込むことができますが、強力な抽象化と単純化された仮定に依存して、生の入力から学ぶのに苦労します。ニューラルネットワークモデルは生データから直接学習できますが、構成的および因果的構造をキャプチャするのに苦労し、通常、新しいタスクに取り組むために再トレーニングする必要があります。これらの2つの伝統を組み合わせて、生データから学習しながら、豊富な構成および因果構造をキャプチャする概念の生成モデルを学習します。確率的プログラムの制御フローをシンボリックストロークプリミティブおよびシンボリックイメージレンダラーと組み合わせて使用​​して、文字が形成される原因および構成プロセスを表す、手書き文字概念の生成的ニューロシンボリック（GNS）モデルを開発します。パーツの分布（ストローク）、およびパーツ間の相関は、ニューラルネットワークサブルーチンでモデル化され、モデルが生データから直接学習し、ノンパラメトリック統計関係を表現できるようにします。モデルを人間レベルの概念学習のOmniglotチャレンジに適用し、アルファベットの背景セットを使用して、文字の描画に対する表現力豊かな事前分布を学習します。その後の評価では、GNSモデルは確率的推論を使用して、4つの固有のタスクに一般化される単一のトレーニング画像から豊富な概念表現を学習し、前の作業が不足している場合に成功します。,6.5,https://d3i71xaburhd42.cloudfront.net/27ad6a5a17a75d1879f47a21a6d07f56ce87cab9/2-Figure1-1.png
Collective Robustness Certificates,"['Jan Schuchardt', 'Aleksandar Bojchevski', 'Johannes Klicpera', 'Stephan Günnemann']",https://openreview.net/forum?id=ULQdiUTHe3y,"In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that  we have a single shared input.  We propose the first collective robustness certificate which computes the number of predictions which are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to  fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the number of average certifiable feature perturbations from $7$ to $351$.",ノード分類、画像セグメンテーション、固有表現抽出などのタスクでは、単一の入力、つまりそれぞれ単一のグラフ、画像、またはドキュメントに基づいて、複数の予測（ラベルのベクトル）を同時に出力する分類器があります。既存の敵対的ロバスト性証明書は、各予測を個別に考慮しているため、そのようなタスクに対して過度に悲観的です。彼らは、私たちが単一の共有入力を持っているという事実を無視して、敵が異なる摂動入力を使用して異なる予測を攻撃できると暗黙のうちに想定しています。摂動下で安定したままであることが同時に保証される、つまり攻撃されない予測の数を計算する最初の集合的ロバスト性証明書を提案します。グラフニューラルネットワークに焦点を当て、それらの局所性プロパティ（摂動は近接した予測にのみ影響します）を活用して、複数の単一ノード証明書を大幅に強力な集合証明書に融合します。たとえば、Citeseerデータセットでは、ノード分類の集合証明書により、認証可能な特徴の摂動の平均数が7から351に増加します。,6.5,
Contextual Transformation Networks for Online Continual Learning,"['Quang Pham', 'Chenghao Liu', 'Doyen Sahoo', 'Steven HOI']",https://openreview.net/forum?id=zx_uX-BO7CH,"Continual learning methods with fixed architectures rely on a single network to learn models that can perform well on all tasks.
As a result, they often only accommodate common features of those tasks but neglect each task's specific features. On the other hand, dynamic architecture methods can have a separate network for each task, but they are too expensive to train and not scalable in practice, especially in online settings.
To address this problem, we propose a novel online continual learning method named ``Contextual Transformation Networks” (CTN) to efficiently model the \emph{task-specific features} while enjoying neglectable complexity overhead compared to other fixed architecture methods. 
Moreover, inspired by the Complementary Learning Systems (CLS) theory, we propose a novel dual memory design and an objective to train CTN that can address both catastrophic forgetting and knowledge transfer simultaneously. 
Our extensive experiments show that CTN is competitive with a large scale dynamic architecture network and consistently outperforms other fixed architecture methods under the same standard backbone. We will release our implementation upon acceptance.",固定アーキテクチャを使用した継続的な学習方法は、単一のネットワークに依存して、すべてのタスクで適切に実行できるモデルを学習します。その結果、それらは多くの場合、それらのタスクの共通機能のみに対応し、各タスクの特定の機能を無視します。一方、動的アーキテクチャの方法では、タスクごとに個別のネットワークを使用できますが、トレーニングするにはコストがかかりすぎ、特にオンライン設定では実際にはスケーラブルではありません。この問題に対処するために、Contextual Transformation Networks（CTN）という名前の新しいオンライン継続学習方法を提案し、他の固定アーキテクチャ方法と比較して無視できる複雑さのオーバーヘッドを享受しながら、タスク固有の機能を効率的にモデル化します。さらに、Complementary Learning Systems（CLS）理論に触発されて、新しいデュアルメモリ設計と、壊滅的な忘却と知識の伝達の両方に同時に対処できるCTNをトレーニングする目的を提案します。私たちの広範な実験は、CTNが大規模な動的アーキテクチャネットワークと競合し、同じ標準バックボーンの下で他の固定アーキテクチャ手法を一貫して上回っていることを示しています。承認次第、実装をリリースします。,6.5,
Are Neural Nets Modular? Inspecting Functional Modularity Through Differentiable Weight Masks,"['Róbert Csordás', 'Sjoerd van Steenkiste', 'Jürgen Schmidhuber']",https://openreview.net/forum?id=7uVcpu-gMD,"Neural networks (NNs) whose subnetworks implement reusable functions are expected to offer numerous advantages, including compositionality through efficient recombination of functional building blocks, interpretability, preventing catastrophic interference, etc. Understanding if and how NNs are modular could provide insights into how to improve them. Current inspection methods, however, fail to link modules to their functionality. In this paper, we present a novel method based on learning binary weight masks to identify individual weights and subnets responsible for specific functions. Using this powerful tool, we contribute an extensive study of emerging modularity in NNs that covers several standard architectures and datasets. We demonstrate how common NNs fail to reuse submodules and offer new insights into the related issue of systematic generalization on language tasks.",サブネットワークが再利用可能な機能を実装するニューラルネットワーク（NN）は、機能ビルディングブロックの効率的な再結合による構成性、解釈可能性、壊滅的な干渉の防止など、多くの利点を提供することが期待されます。NNがモジュール化されているかどうか、およびどのようにモジュール化されているかを理解することで、それらを改善する方法についての洞察を得ることができます。 。ただし、現在の検査方法では、モジュールをその機能にリンクできません。この論文では、特定の機能に関与する個々の重みとサブネットを識別するために、バイナリ重みマスクの学習に基づく新しい方法を提示します。この強力なツールを使用して、いくつかの標準アーキテクチャとデータセットをカバーするNNの新たなモジュール性の広範な研究に貢献します。一般的なNNがサブモジュールの再利用に失敗する方法を示し、言語タスクの体系的な一般化の関連する問題に対する新しい洞察を提供します。,6.5,https://d3i71xaburhd42.cloudfront.net/649c758b0e59ddedaae37a3757e8eabdba664e5a/3-Figure1-1.png
Learning Neural Event Functions for Ordinary Differential Equations,"['Ricky T. Q. Chen', 'Brandon Amos', 'Maximilian Nickel']",https://openreview.net/forum?id=kW_zpEmMLdP,"The existing Neural ODE formulation relies on an explicit knowledge of the termination time.  We extend Neural ODEs to implicitly defined termination criteria modeled by neural event functions,  which can be chained together and differentiated through. Neural Event ODEs are capable of modeling discrete (instantaneous) changes in a continuous-time system, without prior knowledge of when these changes should occur or how many such changes should exist. We test our approach in modeling hybrid discrete- and continuous- systems such as switching dynamical systems and collision in multi-body systems, and we propose simulation-based training of point processes with applications in discrete control.",既存のニューラルODEの定式化は、終了時間の形式知に依存しています。ニューラルODEを、ニューラルイベント関数によってモデル化された暗黙的に定義された終了基準に拡張します。これは、チェーン化して区別することができます。ニューラルイベントODEは、これらの変更がいつ発生するか、またはそのような変更がいくつ存在するかを事前に知らなくても、連続時間システムの離散（瞬間）変更をモデル化できます。動的システムの切り替えやマルチボディシステムでの衝突など、離散システムと連続システムのハイブリッドのモデリングにおけるアプローチをテストし、離散制御のアプリケーションを使用したポイントプロセスのシミュレーションベースのトレーニングを提案します。,6.5,https://d3i71xaburhd42.cloudfront.net/8d0df11476d9828aefa6a4a1d772b2359d77ac8b/2-Figure1-1.png
Learning continuous-time PDEs from sparse data with graph neural networks,"['Valerii Iakovlev', 'Markus Heinonen', 'Harri Lähdesmäki']",https://openreview.net/forum?id=aUX5Plaq7Oy,"The behavior of many dynamical systems follow complex, yet still unknown partial differential equations (PDEs). While several machine learning methods have been proposed to learn PDEs directly from data, previous methods are limited to discrete-time approximations or make the limiting assumption of the observations arriving at regular grids. We propose a general continuous-time differential model for dynamical systems whose governing equations are parameterized by message passing graph neural networks. The model admits arbitrary space and time discretizations, which removes constraints on the locations of observation points and time intervals between the observations. The model is trained with continuous-time adjoint method enabling efficient neural PDE inference. We demonstrate the model's ability to work with unstructured grids, arbitrary time steps, and noisy observations. We compare our method with existing approaches on several well-known physical systems that involve first and higher-order PDEs with state-of-the-art predictive performance.",多くの動的システムの動作は、複雑でありながら未知の偏微分方程式（PDE）に従います。データから直接偏微分方程式を学習するためにいくつかの機械学習方法が提案されていますが、以前の方法は離散時間近似に限定されるか、通常のグリッドに到達する観測値を限定的に仮定します。メッセージパッシンググラフニューラルネットワークによって支配方程式がパラメータ化される動的システムの一般的な連続時間微分モデルを提案します。モデルは、任意の空間と時間の離散化を許可します。これにより、観測点の位置と観測間の時間間隔の制約がなくなります。モデルは、効率的なニューラルPDE推論を可能にする連続時間随伴法でトレーニングされます。非構造格子、任意の時間ステップ、およびノイズの多い観測値を処理するモデルの機能を示します。私たちの方法を、最先端の予測性能を備えた一次および高次の偏微分方程式を含むいくつかのよく知られた物理システムでの既存のアプローチと比較します。,6.5,https://d3i71xaburhd42.cloudfront.net/88ea19692e567d6273f2b066dfd987af1b60cc75/3-Figure1-1.png
Mastering Atari with Discrete World Models,"['Danijar Hafner', 'Timothy P Lillicrap', 'Mohammad Norouzi', 'Jimmy Ba']",https://openreview.net/forum?id=0oabwyZbOu,"Intelligent agents need to generalize from past experience to achieve goals in complex environments. World models facilitate such generalization and allow learning behaviors from imagined outcomes to increase sample-efficiency. While learning world models from image inputs has recently become feasible for some tasks, modeling Atari games accurately enough to derive successful behaviors has remained an open challenge for many years. We introduce DreamerV2, a reinforcement learning agent that learns behaviors purely from predictions in the compact latent space of a powerful world model. The world model uses discrete representations and is trained separately from the policy. DreamerV2 constitutes the first agent that achieves human-level performance on the Atari benchmark of 55 tasks by learning behaviors inside a separately trained world model. With the same computational budget and wall-clock time, DreamerV2 reaches 200M frames and exceeds the final performance of the top single-GPU agents IQN and Rainbow.",インテリジェントエージェントは、複雑な環境で目標を達成するために、過去の経験から一般化する必要があります。世界モデルは、そのような一般化を容易にし、想像された結果から行動を学習してサンプル効率を高めることを可能にします。画像入力から世界モデルを学習することが最近いくつかのタスクで実行可能になりましたが、成功した動作を導き出すのに十分正確にAtariゲームをモデル化することは、長年にわたって未解決の課題であり続けています。強力な世界モデルのコンパクトな潜在空間での予測から純粋に行動を学習する強化学習エージェント、DreamerV2を紹介します。ワールドモデルは離散表現を使用し、ポリシーとは別にトレーニングされます。 DreamerV2は、個別にトレーニングされた世界モデル内で行動を学習することにより、55タスクのAtariベンチマークで人間レベルのパフォーマンスを達成する最初のエージェントを構成します。同じ計算バジェットと実時間で、DreamerV2は2億フレームに達し、トップシングルGPUエージェントIQNとRainbowの最終パフォーマンスを上回ります。,6.5,https://d3i71xaburhd42.cloudfront.net/8dc2dc6f93ba5141a45cc7697b70078e63c335b0/1-Figure1-1.png
Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space Navigation,"['Peiye Zhuang', 'Oluwasanmi O Koyejo', 'Alex Schwing']",https://openreview.net/forum?id=HOFxeCutxZR,"Controllable semantic image editing enables a user to change entire image attributes with few clicks, e.g., gradually making a summer scene look like it was taken in winter. Classic approaches for this task use a Generative Adversarial Net (GAN) to learn a latent space and suitable latent-space transformations. However, current approaches often suffer from attribute edits which are entangled, global image identity changes, and diminished photo-realism. To address these concerns, we learn multiple attribute transformations simultaneously, we integrate attribute regression into the training of transformation functions, apply a content loss and an adversarial loss that encourage the maintenance of image identity and photo-realism. Beyond global transformations, we explore local edits that can succeed in failure cases of global directions. We propose quantitative evaluation strategies for measuring controllable editing performance, unlike prior work which primarily focuses on qualitative evaluation. Our model permits better control for both single- and multiple-attribute editing, while also preserving image identity and realism during transformation. We provide empirical results for both real and synthetic images, highlighting that our model achieves state-of-the-art performance for targeted image manipulation. ",制御可能なセマンティック画像編集により、ユーザーは数回クリックするだけで画像属性全体を変更できます。たとえば、夏のシーンを冬のシーンのように徐々に変更できます。このタスクの従来のアプローチでは、Generative Adversarial Net（GAN）を使用して、潜在空間と適切な潜在空間変換を学習します。ただし、現在のアプローチでは、属性の編集が絡み合ったり、グローバルな画像IDが変更されたり、フォトリアリズムが低下したりすることがよくあります。これらの懸念に対処するために、複数の属性変換を同時に学習し、属性回帰を変換関数のトレーニングに統合し、画像のアイデンティティとフォトリアリズムの維持を促進するコンテンツ損失と敵対的損失を適用します。グローバルな変革を超えて、グローバルな方向性の失敗事例で成功する可能性のあるローカル編集を探求します。主に定性的評価に焦点を当てた以前の研究とは異なり、制御可能な編集パフォーマンスを測定するための定量的評価戦略を提案します。私たちのモデルでは、変換中の画像のアイデンティティとリアリズムを維持しながら、単一属性と複数属性の両方の編集をより適切に制御できます。実際の画像と合成画像の両方について経験的な結果を提供し、私たちのモデルがターゲット画像操作の最先端のパフォーマンスを達成していることを強調しています。,6.5,https://d3i71xaburhd42.cloudfront.net/3cdac7e1a3904a9458f55694d1dc6e6374659a02/2-Figure1-1.png
A Hypergradient Approach to Robust Regression without Correspondence,"['Yujia Xie', 'Yixiu Mao', 'Simiao Zuo', 'Hongteng Xu', 'Xiaojing Ye', 'Tuo Zhao', 'Hongyuan Zha']",https://openreview.net/forum?id=l35SB-_raSQ,"We consider a regression problem, where the correspondence between input data and output data is not accessible. Such shuffled data is commonly observed. For example, in flow cytometry, the measuring instruments are unable to preserve the correspondence between the samples and the measurements. Existing works for this problem generally focus on small number of data and/or linear case. In this work, we propose a novel computational framework (ROBOT) for the shuffled regression problem that can handle large-scale data and complex models more effectively than previous methods. To facilitate this, we consider the interaction between the regression parameter and the data correspondence parameter by building an end-to-end training framework using differentiable programming techniques. As an extension, ROBOT can also be applied to the robust correspondence setting, where the input data and the output data are not exactly aligned. Numerical experiments show that ROBOT achieves better performance than existing methods in both linear and nonlinear regression tasks, including real-world applications such as flow cytometry and multi-object tracking. ",入力データと出力データの間の対応にアクセスできない回帰問題を検討します。このようなシャッフルされたデータは一般的に観察されます。たとえば、フローサイトメトリーでは、測定機器はサンプルと測定値の間の対応を維持することができません。この問題に対する既存の作業は、通常、少数のデータや線形の場合に焦点を当てています。この作業では、大規模なデータと複雑なモデルを以前の方法よりも効果的に処理できる、シャッフル回帰問題の新しい計算フレームワーク（ROBOT）を提案します。これを容易にするために、微分可能なプログラミング手法を使用してエンドツーエンドのトレーニングフレームワークを構築することにより、回帰パラメーターとデータ対応パラメーターの間の相互作用を検討します。拡張機能として、ROBOTは、入力データと出力データが正確に位置合わせされていない堅牢な対応設定にも適用できます。数値実験によると、ROBOTは、フローサイトメトリーやマルチオブジェクトトラッキングなどの実際のアプリケーションを含む、線形回帰タスクと非線形回帰タスクの両方で、既存の方法よりも優れたパフォーマンスを実現します。,6.5,https://d3i71xaburhd42.cloudfront.net/fcc4d9d8eae15729ceecd737f60d440f0adac9ed/8-Figure1-1.png
Efficient Continual Learning with Modular Networks and Task-Driven Priors,"['Tom Veniat', 'Ludovic Denoyer', 'MarcAurelio Ranzato']",https://openreview.net/forum?id=EKV158tSfwv,"Existing literature in Continual Learning (CL) has focused on overcoming catastrophic forgetting, the inability of the learner to recall how to perform tasks observed in the past. There are however other desirable properties of a CL system, such as the ability to transfer knowledge from previous tasks and to scale memory and compute sub-linearly with the number of tasks. Since most current benchmarks focus only on forgetting using short streams of tasks, we first propose a new suite of benchmarks to probe CL algorithms across these new axes. Finally, we introduce a new modular architecture, whose modules represent atomic skills that can be composed to perform a certain task. Learning a task reduces to figuring out which past modules to re-use, and which new modules to instantiate to solve the current task. Our learning algorithm leverages a task-driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks. 
Our experiments show that this modular architecture and learning algorithm perform competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks we introduce in this work.",継続学習（CL）の既存の文献は、壊滅的な忘却、過去に観察されたタスクの実行方法を学習者が思い出せないことを克服することに焦点を当てています。ただし、CLシステムには、前のタスクから知識を転送したり、メモリをスケーリングしたり、タスクの数に応じてサブリニアに計算したりする機能など、他にも望ましい特性があります。現在のほとんどのベンチマークは、タスクの短いストリームの使用を忘れることにのみ焦点を当てているため、最初に、これらの新しい軸全体でCLアルゴリズムをプローブするための新しいベンチマークスイートを提案します。最後に、新しいモジュラーアーキテクチャを紹介します。そのモジュールは、特定のタスクを実行するために構成できるアトミックスキルを表します。タスクを学習することは、どの過去のモジュールを再利用するか、そしてどの新しいモジュールをインスタンス化して現在のタスクを解決するかを理解することになります。私たちの学習アルゴリズムは、モジュールを組み合わせるためのすべての可能な方法の指数検索スペースよりもタスク駆動型の事前設定を活用して、タスクの長いストリームで効率的な学習を可能にします。私たちの実験は、このモジュラーアーキテクチャと学習アルゴリズムが、広く使用されているCLベンチマークで競争力を発揮し、この作業で導入するより困難なベンチマークで優れたパフォーマンスを発揮することを示しています。,6.5,
On Statistical Bias In Active Learning: How and When to Fix It,"['Sebastian Farquhar', 'Yarin Gal', 'Tom Rainforth']",https://openreview.net/forum?id=JiYq3eqTKY,"Active learning is a powerful tool when labelling data is expensive, but it introduces a bias because the training data no longer follows the population distribution. We formalize this bias and investigate the situations in which it can be harmful and sometimes even helpful. We further introduce novel corrective weights to remove bias when doing so is beneficial. Through this, our work not only provides a useful mechanism that can improve the active learning approach, but also an explanation for the empirical successes of various existing approaches which ignore this bias. In particular, we show that this bias can be actively helpful when training overparameterized models---like neural networks---with relatively modest dataset sizes.",アクティブラーニングは、データのラベル付けに費用がかかる場合に強力なツールですが、トレーニングデータが人口分布に従わなくなったため、バイアスが発生します。私たちはこのバイアスを形式化し、それが有害であり、時には役立つ可能性がある状況を調査します。さらに、バイアスを取り除くことが有益な場合に、バイアスを取り除くための新しい修正ウェイトを導入します。これにより、私たちの仕事は、能動的学習アプローチを改善できる有用なメカニズムを提供するだけでなく、このバイアスを無視するさまざまな既存のアプローチの経験的成功の説明も提供します。特に、このバイアスは、比較的控えめなデータセットサイズのニューラルネットワークなどのパラメーター化されたモデルをトレーニングするときに積極的に役立つ可能性があることを示しています。,6.5,https://d3i71xaburhd42.cloudfront.net/df141b3a25671859d292d245efc90c5f2a891a95/7-Figure1-1.png
Is Label Smoothing Truly Incompatible with Knowledge Distillation: An Empirical Study,"['Zhiqiang Shen', 'Zechun Liu', 'Dejia Xu', 'Zitian Chen', 'Kwang-Ting Cheng', 'Marios Savvides']",https://openreview.net/forum?id=PObuuGVrGaZ,"This work aims to empirically clarify a recently discovered perspective that label smoothing is incompatible with knowledge distillation. We begin by introducing the behind motivation on how this incompatibility is raised, i.e., label smoothing erases relative information between teacher logits. We provide a novel connection on how label smoothing affects distributions of semantically similar and dissimilar classes. Then we propose a metric to quantitatively measure the degree of erased information in sample's representation. After that, we study its one-sidedness and imperfection of the incompatibility view through massive analyses, visualizations and comprehensive experiments on Image Classification, Binary Networks, and Neural Machine Translation. Finally, we broadly discuss several circumstances wherein label smoothing will indeed lose its effectiveness.",この作業は、ラベルの平滑化が知識の蒸留と両立しないという最近発見された視点を経験的に明らかにすることを目的としています。まず、この非互換性がどのように発生するかについての背後にある動機を紹介します。つまり、ラベルの平滑化により、教師のロジット間の相対情報が消去されます。ラベルの平滑化が意味的に類似および非類似のクラスの分布にどのように影響するかについて、新しい関係を提供します。次に、サンプル表現で消去された情報の程度を定量的に測定するためのメトリックを提案します。その後、画像分類、バイナリネットワーク、ニューラル機械翻訳に関する大規模な分析、視覚化、包括的な実験を通じて、非互換性ビューの一方的な側面と不完全性を調査します。最後に、ラベルの平滑化が実際にその効果を失ういくつかの状況について広く説明します。,6.5,
DOP: Off-Policy Multi-Agent Decomposed Policy Gradients,"['Yihan Wang', 'Beining Han', 'Tonghan Wang', 'Heng Dong', 'Chongjie Zhang']",https://openreview.net/forum?id=6FqKiVAdI3Y,"Multi-agent policy gradient (MAPG) methods recently witness vigorous progress. However, there is a significant performance discrepancy between MAPG methods and state-of-the-art multi-agent value-based approaches. In this paper, we investigate causes that hinder the performance of MAPG algorithms and present a multi-agent decomposed policy gradient method (DOP). This method introduces the idea of value function decomposition into the multi-agent actor-critic framework. Based on this idea, DOP supports efficient off-policy learning and addresses the issue of centralized-decentralized mismatch and credit assignment in both discrete and continuous action spaces. We formally show that DOP critics have sufficient representational capability to guarantee convergence. In addition, empirical evaluations on the StarCraft II micromanagement benchmark and multi-agent particle environments demonstrate that DOP significantly outperforms both state-of-the-art value-based and policy-based multi-agent reinforcement learning algorithms. Demonstrative videos are available at https://sites.google.com/view/dop-mapg/.",マルチエージェントポリシーグラディエント（MAPG）メソッドは、最近活発な進歩を遂げています。ただし、MAPGメソッドと最先端のマルチエージェント値ベースのアプローチの間には、パフォーマンスに大きな違いがあります。この論文では、MAPGアルゴリズムのパフォーマンスを妨げる原因を調査し、マルチエージェント分解ポリシー勾配法（DOP）を提示します。このメソッドは、値関数分解のアイデアをマルチエージェントアクター批評家フレームワークに導入します。このアイデアに基づいて、DOPは効率的なポリシー外学習をサポートし、離散アクションスペースと連続アクションスペースの両方で集中型分散型の不一致とクレジット割り当ての問題に対処します。 DOP評論家が収束を保証するのに十分な表現能力を持っていることを正式に示します。さらに、StarCraft IIマイクロマネジメントベンチマークとマルチエージェント粒子環境での経験的評価は、DOPが最先端の価値ベースとポリシーベースのマルチエージェント強化学習アルゴリズムの両方を大幅に上回っていることを示しています。デモビデオはhttps://sites.google.com/view/dop-mapg/で入手できます。,6.5,https://d3i71xaburhd42.cloudfront.net/98e171da2dbbaa632d8ab710b1ca32f18da0cf55/3-Figure1-1.png
Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition,"['Yangming Li', 'lemao liu', 'Shuming Shi']",https://openreview.net/forum?id=5jRVa89sZk,"In many scenarios, named entity recognition (NER) models severely suffer from unlabeled entity problem, where the entities of a sentence may not be fully annotated. Through empirical studies performed on synthetic datasets, we find two causes of the performance degradation. One is the reduction of annotated entities and the other is treating unlabeled entities as negative instances. The first cause has less impact than the second one and can be mitigated by adopting pretraining language models. The second cause seriously misguides a model in training and greatly affects its performances. Based on the above observations, we propose a general approach that is capable of eliminating the misguidance brought by unlabeled entities. The core idea is using negative sampling to keep the probability of training with unlabeled entities at a very low level. Experiments on synthetic datasets and real-world datasets show that our model is robust to unlabeled entity problem and surpasses prior baselines. On well annotated datasets, our model is competitive with state-of-the-art method.",多くのシナリオでは、名前付きエンティティ認識（NER）モデルは、文のエンティティに完全に注釈が付けられていない可能性がある、ラベルのないエンティティの問題に深刻な問題を抱えています。合成データセットで実行された経験的研究を通じて、パフォーマンス低下の2つの原因が見つかりました。 1つは注釈付きエンティティの削減であり、もう1つはラベルなしエンティティをネガティブインスタンスとして扱うことです。最初の原因は2番目の原因よりも影響が少なく、事前トレーニング言語モデルを採用することで軽減できます。 2番目の原因は、トレーニングでモデルを深刻に誤解させ、そのパフォーマンスに大きく影響します。上記の観察に基づいて、ラベルのないエンティティによってもたらされる誤解を排除することができる一般的なアプローチを提案します。中心的なアイデアは、ネガティブサンプリングを使用して、ラベルのないエンティティを使用したトレーニングの確率を非常に低いレベルに保つことです。合成データセットと実際のデータセットでの実験は、私たちのモデルがラベルのないエンティティの問題に対してロバストであり、以前のベースラインを超えていることを示しています。十分に注釈が付けられたデータセットでは、私たちのモデルは最先端の方法と競合します。,6.5,https://d3i71xaburhd42.cloudfront.net/f3015127b02b1ba8d5dd166e02a5c47098e1f7fb/3-Figure1-1.png
Chaos of Learning Beyond Zero-sum and Coordination via Game Decompositions,"['Yun Kuen Cheung', 'Yixin Tao']",https://openreview.net/forum?id=a3wKPZpGtCF,"It is of primary interest for ML to understand how agents learn and interact dynamically in competitive environments and games (e.g. GANs). But this has been a difficult task, as irregular behaviors are commonly observed in such systems. This can be explained theoretically, for instance, by the works of Cheung and Piliouras (COLT 2019; NeurIPS 2020), which showed that in two-person zero-sum games, if agents employ one of the most well-known learning algorithms, Multiplicative Weights Update (MWU), then Lyapunov chaos occurs everywhere in the payoff space. In this paper, we study how persistent chaos can occur in the more general normal game settings, where the agents might have the motivation to coordinate (which is not true for zero-sum games) and the number of agents can be arbitrary.

We characterize bimatrix games where MWU, its optimistic variant (OMWU) or Follow-the-Regularized-Leader (FTRL) algorithms are Lyapunov chaotic almost everywhere in the payoff space. Technically, our characterization is derived by extending the volume-expansion argument of Cheung and Piliouras via the canonical game decomposition into zero-sum and coordination components. Interestingly, the two components induce opposite volume-changing behaviors, so the overall behavior can be analyzed by comparing the strengths of the components against each other. The comparison is done via our new notion of ""matrix domination"" or via a linear program. For multi-player games, we present a local equivalence of volume change between general games and graphical games, which is used to perform volume and chaos analyses of MWU and OMWU in potential games.",MLにとって、エージェントが競争の激しい環境やゲーム（GANなど）で動的に学習および相互作用する方法を理解することが最も重要です。しかし、このようなシステムでは不規則な動作が一般的に観察されるため、これは困難な作業でした。これは、たとえば、Cheung and Piliouras（COLT 2019; NeurIPS 2020）の作品によって理論的に説明できます。これは、2人のゼロサムゲームで、エージェントが最もよく知られている学習アルゴリズムの1つであるMultiplicativeを使用する場合にウェイトアップデート（MWU）を実行すると、リアプノフカオスがペイオフスペースのいたるところに発生します。この論文では、エージェントが調整する動機を持ち（ゼロサムゲームには当てはまらない）、エージェントの数が任意である、より一般的な通常のゲーム設定で永続的なカオスがどのように発生するかを研究します。 MWU、その楽観的バリアント（OMWU）、またはFollow-the-Regularized-Leader（FTRL）アルゴリズムが、ペイオフスペースのほとんどすべての場所でリアプノフカオスであるバイマトリックスゲームを特徴づけます。技術的には、私たちの特性は、CheungとPiliourasのボリューム拡張引数を、正規のゲーム分解を介してゼロサムと調整コンポーネントに拡張することによって導き出されます。興味深いことに、2つのコンポーネントは反対のボリューム変更動作を引き起こすため、コンポーネントの強度を相互に比較することで、全体的な動作を分析できます。比較は、「マトリックス支配」の新しい概念または線形計画法を介して行われます。マルチプレイヤーゲームの場合、一般的なゲームとグラフィカルゲームの間のボリューム変化のローカル等価性を示します。これは、潜在的なゲームでMWUとOMWUのボリュームとカオスの分析を実行するために使用されます。,6.5,
Meta-Learning with Neural Tangent Kernels,"['Yufan Zhou', 'Zhenyi Wang', 'Jiayi Xian', 'Changyou Chen', 'Jinhui Xu']",https://openreview.net/forum?id=Ti87Pv5Oc8,"  Model Agnostic Meta Learning (MAML) has emerged as a standard framework for meta learning, where a meta-model is learned with the ability of fast adapting to new tasks. However, as a double-looped optimization problem, MAML needs to differentiate through the whole inner-loop optimization path for every outer-loop training step, which may lead to both computational inefficiency and sub-optimal solutions. In this paper, we generalize MAML to allow meta learning to be defined in function spaces, and propose the first meta-learning paradigm in the Reproducing Kernel Hilbert Space (RKHS) induced by the meta model's Neural Tangent Kernel (NTK). Within this paradigm, we introduce two meta learning algorithms in RKHS, which no longer need an explicit inner-loop adaptation as in the MAML framework. We achieve this goal by 1) replacing the adaptation with a fast-adaptive regularizer in the RKHS; and 2) solving the adaptation analytically based on the NTK theory. Extensive experimental studies demonstrate the superiority of our paradigm in both efficiency and quality of solutions compared to related meta-learning algorithms. Another interesting feature of our proposed methods is that they are much more robust to adversarial attacks and out-of-distribution adaptation than existing approaches, as demonstrated by our experiments.",モデルにとらわれないメタ学習（MAML）は、メタ学習の標準フレームワークとして登場しました。メタモデルは、新しいタスクにすばやく適応する機能を備えて学習されます。ただし、二重ループ最適化問題として、MAMLは、すべての外部ループトレーニングステップの内部ループ最適化パス全体を区別する必要があります。これにより、計算の非効率性と次善のソリューションの両方が発生する可能性があります。この論文では、MAMLを一般化して、メタ学習を関数空間で定義できるようにし、メタモデルNeural Tangent Kernel（NTK）によって誘発される再生核ヒルベルト空間（RKHS）の最初のメタ学習パラダイムを提案します。このパラダイム内で、RKHSに2つのメタ学習アルゴリズムを導入します。これらは、MAMLフレームワークのように明示的な内部ループ適応を必要としなくなりました。この目標を達成するには、1）RKHSで適応を高速適応正則化に置き換えます。 2）NTK理論に基づいて適応を分析的に解く。広範な実験的研究は、関連するメタ学習アルゴリズムと比較して、ソリューションの効率と品質の両方におけるパラダイムの優位性を示しています。提案された方法のもう1つの興味深い特徴は、実験で示されているように、既存のアプローチよりも敵対的攻撃や分散外適応に対してはるかに堅牢であることです。,6.5,
Dynamic Tensor Rematerialization,"['Marisa Kirisame', 'Steven Lyubomirsky', 'Altan Haan', 'Jennifer Brennan', 'Mike He', 'Jared Roesch', 'Tianqi Chen', 'Zachary Tatlock']",https://openreview.net/forum?id=Vfs_2RnOD0H,"Checkpointing enables training deep learning models under restricted memory budgets by freeing intermediate activations from memory and recomputing them on demand. Previous checkpointing techniques statically plan these recomputations offline and assume static computation graphs. We demonstrate that a simple online algorithm can achieve comparable performance by introducing Dynamic Tensor Rematerialization (DTR), a greedy online algorithm for checkpointing that is extensible and general, is parameterized by eviction policy, and supports dynamic models. We prove that DTR can train an $N$-layer linear feedforward network on an $\Omega(\smash{\sqrt{N}})$ memory budget with only $\mathcal{O}(N)$ tensor operations. DTR closely matches the performance of optimal static checkpointing in simulated experiments. We incorporate a DTR prototype into PyTorch just by interposing on tensor allocations and operator calls and collecting lightweight metadata on tensors.",チェックポインティングにより、メモリから中間アクティベーションを解放し、オンデマンドで再計算することにより、制限されたメモリバジェットの下でディープラーニングモデルをトレーニングできます。以前のチェックポインティング手法では、これらの再計算をオフラインで静的に計画し、静的な計算グラフを想定しています。拡張可能で一般的なチェックポインティング用の貪欲なオンラインアルゴリズムであるDynamicTensor Rematerialization（DTR）を導入することにより、単純なオンラインアルゴリズムが同等のパフォーマンスを達成できることを示します。これは、エビクションポリシーによってパラメーター化され、動的モデルをサポートします。 DTRが$ \ Omega（\ smash {\ sqrt {N}}）$メモリバジェットでO（N）テンソル演算のみでN層線形フィードフォワードネットワークをトレーニングできることを証明します。 DTRは、シミュレートされた実験における最適な静的チェックポイントのパフォーマンスと厳密に一致します。テンソルの割り当てとオペレーターの呼び出しに介入し、テンソルで軽量のメタデータを収集するだけで、DTRプロトタイプをPyTorchに組み込みます。,6.5,https://d3i71xaburhd42.cloudfront.net/3c55dd7b8da5c7b47e91b2e749c264f50d007cd4/2-Figure1-1.png
Training GANs with Stronger Augmentations via Contrastive Discriminator,"['Jongheon Jeong', 'Jinwoo Shin']",https://openreview.net/forum?id=eo6U4CAwVmg,"Recent works in Generative Adversarial Networks (GANs) are actively revisiting various data augmentation techniques as an effective way to prevent discriminator overfitting. It is still unclear, however, that which augmentations could actually improve GANs, and in particular, how to apply a wider range of augmentations in training. In this paper, we propose a novel way to address these questions by incorporating a recent contrastive representation learning scheme into the discriminator, coined ContraD. This ""fusion"" enables discriminators to work with much stronger augmentations without catastrophic forgetting, which can significantly improve GAN training. Even better, we observe that the contrastive learning itself also benefits from GAN training, i.e., keeping discriminative features between real and fake samples, suggesting a strong coherence between the two worlds: a good contrastive representation is also good for GAN discriminators, and vice versa. Our experimental results show that GAN with ContraD consistently improves FID scores compared to other recent techniques using data augmentations, still maintaining highly discriminative features in the discriminator in terms of the linear evaluation. Finally, as a byproduct, we show that our GANs trained in an unsupervised manner (without labels) can induce many conditional generative models via a simple latent sampling, leveraging the learned features of ContraD.",Generative Adversarial Networks（GAN）の最近の研究では、弁別器の過剰適合を防ぐ効果的な方法として、さまざまなデータ拡張手法を積極的に再検討しています。ただし、どの拡張機能が実際にGANを改善できるか、特に、トレーニングでより広範囲の拡張機能をどのように適用するかはまだ不明です。この論文では、最近の対照表現学習スキームを弁別器であるContraDに組み込むことにより、これらの質問に対処する新しい方法を提案します。この「融合」により、識別器は壊滅的な忘却なしにはるかに強力な増強を行うことができ、GANトレーニングを大幅に改善できます。さらに良いことに、対照学習自体もGANトレーニングの恩恵を受けています。つまり、実際のサンプルと偽のサンプルの識別機能を維持し、2つの世界間の強い一貫性を示唆しています。優れた対照表現はGAN識別者にも適しています。逆もまた同様です。 。私たちの実験結果は、ContraDを使用したGANは、データ拡張を使用する他の最近の手法と比較して、一貫してFIDスコアを改善し、線形評価の観点から識別器の高度な識別機能を維持していることを示しています。最後に、副産物として、教師なし方法（ラベルなし）でトレーニングされたGANが、ContraDの学習された機能を活用して、単純な潜在サンプリングを介して多くの条件付き生成モデルを誘導できることを示します。,6.5,
Grounding Physical Object and Event Concepts Through Dynamic Visual Reasoning,"['Zhenfang Chen', 'Jiayuan Mao', 'Jiajun Wu', 'Kwan-Yee Kenneth Wong', 'Joshua B. Tenenbaum', 'Chuang Gan']",https://openreview.net/forum?id=bhCDO_cEGCz,"We study the problem of dynamic visual reasoning on raw videos. This is a challenging problem; currently, state-of-the-art models often require dense supervision on physical object properties and events from simulation, which are impractical to obtain in real life. In this paper, we present the Dynamic Concept Learner (DCL), a unified framework that grounds physical objects and events from video and language. DCL first adopts a trajectory extractor to track each object over time and to represent it as a latent, object-centric feature vector. Building upon this object-centric representation, DCL learns to approximate the dynamic interaction among objects using graph networks. DCL further incorporates a semantic parser to parse question into semantic programs and, finally, a program executor to run the program to answer the question, levering the learned dynamics model. After training, DCL can detect and associate objects across the frames, ground visual properties and physical events, understand the causal relationship between events, make future and counterfactual predictions, and leverage these extracted presentations for answering queries. DCL achieves state-of-the-art performance on CLEVRER, a challenging causal video reasoning dataset, even without using ground-truth attributes and collision labels from simulations for training. We further test DCL on a newly proposed video-retrieval and event localization dataset derived from CLEVRER, showing its strong generalization capacity.",生のビデオで動的な視覚的推論の問題を研究します。これは難しい問題です。現在、最先端のモデルでは、シミュレーションからの物理オブジェクトのプロパティとイベントを綿密に監視する必要がありますが、これらは実際の生活では取得できません。このホワイトペーパーでは、ビデオと言語から物理的なオブジェクトとイベントを基盤とする統合フレームワークであるDynamic Concept Learner（DCL）を紹介します。 DCLは、最初に軌道抽出器を採用して、時間の経過とともに各オブジェクトを追跡し、それを潜在的なオブジェクト中心の特徴ベクトルとして表現します。このオブジェクト中心の表現に基づいて、DCLはグラフネットワークを使用してオブジェクト間の動的な相互作用を概算することを学習します。 DCLはさらに、質問を構文解析するセマンティックパーサーをセマンティックプログラムに組み込み、最後に、学習したダイナミクスモデルを活用して、プログラムを実行して質問に回答するプログラムエグゼキューターを組み込みます。トレーニング後、DCLは、フレーム全体のオブジェクト、地上の視覚的プロパティ、および物理的イベントを検出して関連付け、イベント間の因果関係を理解し​​、将来および反事実的な予測を行い、これらの抽出されたプレゼンテーションを利用してクエリに回答できます。 DCLは、トレーニング用のシミュレーションからのグラウンドトゥルース属性と衝突ラベルを使用しなくても、挑戦的な因果ビデオ推論データセットであるCLEVRERで最先端のパフォーマンスを実現します。さらに、CLEVRERから派生した新しく提案されたビデオ検索およびイベントローカリゼーションデータセットでDCLをテストし、その強力な一般化能力を示します。,6.5,
Learning Deep Features in Instrumental Variable Regression,"['Liyuan Xu', 'Yutian Chen', 'Siddarth Srinivasan', 'Nando de Freitas', 'Arnaud Doucet', 'Arthur Gretton']",https://openreview.net/forum?id=sy4Kg_ZQmS7,"Instrumental variable (IV) regression is a standard strategy for learning causal relationships between confounded treatment and outcome variables from observational data by utilizing an instrumental variable, which affects the outcome only through the treatment. In classical IV regression, learning proceeds in two stages: stage 1 performs linear regression from the instrument to the treatment; and stage 2 performs linear regression from the treatment to the outcome, conditioned on the instrument. We propose a novel method, deep feature instrumental variable regression (DFIV), to address the case where relations between instruments, treatments, and outcomes may be nonlinear. In this case, deep neural nets are trained to define informative nonlinear features on the instruments and treatments. We propose an alternating training regime for these features to ensure good end-to-end performance when composing stages 1 and 2, thus obtaining highly flexible feature maps in a computationally efficient manner. DFIV outperforms recent state-of-the-art methods on challenging IV benchmarks, including settings involving high dimensional image data. DFIV also exhibits competitive performance in off-policy policy evaluation for reinforcement learning, which can be understood as an IV regression task.",操作変数（IV）回帰は、治療を通じてのみ結果に影響を与える操作変数を利用することにより、交絡治療と結果変数の間の因果関係を観察データから学習するための標準的な戦略です。古典的なIV回帰では、学習は2つの段階で進行します。段階1は、機器から治療への線形回帰を実行します。ステージ2は、機器を条件として、治療から結果への線形回帰を実行します。機器、治療、および結果の間の関係が非線形である可能性がある場合に対処するために、新しい方法である深層操作変数回帰（DFIV）を提案します。この場合、ディープニューラルネットは、機器と治療に関する有益な非線形機能を定義するようにトレーニングされています。ステージ1と2を構成するときに優れたエンドツーエンドのパフォーマンスを確保し、計算効率の高い方法で柔軟性の高い特徴マップを取得するために、これらの特徴の交互のトレーニング体制を提案します。 DFIVは、高次元の画像データを含む設定など、挑戦的なIVベンチマークで最近の最先端の方法よりも優れています。 DFIVは、強化学習のポリシー外のポリシー評価でも競争力のあるパフォーマンスを示します。これは、IV回帰タスクとして理解できます。,6.5,https://d3i71xaburhd42.cloudfront.net/31dbeeb665e1482d51652e462c1830f4966667cc/5-Figure2-1.png
Knowledge distillation via softmax regression representation learning,"['Jing Yang', 'Brais Martinez', 'Adrian Bulat', 'Georgios Tzimiropoulos']",https://openreview.net/forum?id=ZzwDy_wiWv,"This paper addresses the problem of model compression via knowledge distillation. We advocate for a method that optimizes the output feature of the penultimate layer of the student network and hence is directly related to representation learning. Previous distillation methods which typically impose direct feature matching between the student and the teacher do not take into account the classification problem at hand. On the contrary, our distillation method decouples representation learning and classification and utilizes the teacher's pre-trained classifier to train the student's penultimate layer feature. In particular, for the same input image, we wish the teacher's and student's feature to produce the same output when passed through the teacher's classifier which is achieved with a simple $L_2$ loss. Our method is extremely simple to implement and straightforward to train and is shown to consistently outperform previous state-of-the-art methods over a large set of experimental settings including different (a) network architectures, (b) teacher-student capacities, (c) datasets, and (d) domains.",この論文は、知識蒸留によるモデル圧縮の問題に取り組んでいます。学生ネットワークの最後から2番目の層の出力機能を最適化する方法を提唱します。したがって、表現学習に直接関係します。通常、生徒と教師の間に直接的な特徴のマッチングを課す以前の蒸留方法は、目前の分類問題を考慮していません。それどころか、私たちの蒸留法は、表現学習と分類を切り離し、教師が事前に訓練した分類器を利用して、生徒の最後から2番目の層の特徴を訓練します。特に、同じ入力画像の場合、教師と生徒の機能が教師分類器を通過したときに同じ出力を生成することを望みます。これは、単純なL2損失で実現されます。私たちの方法は、実装が非常に簡単で、トレーニングが簡単で、さまざまな（a）ネットワークアーキテクチャ、（b）教師と生徒の能力、（b）を含む多数の実験設定で、以前の最先端の方法を一貫して上回っています。 c）データセット、および（d）ドメイン。,6.5,
Deep Networks and the Multiple Manifold Problem,"['Sam Buchanan', 'Dar Gilboa', 'John Wright']",https://openreview.net/forum?id=O-6Pm_d_Q-,"We study the multiple manifold problem, a binary classification task modeled on applications in machine vision, in which a deep fully-connected neural network is trained to separate two low-dimensional submanifolds of the unit sphere. We provide an analysis of the one-dimensional case, proving for a simple manifold configuration that when the network depth $L$ is large relative to certain geometric and statistical properties of the data, the network width $n$ grows as a sufficiently large polynomial in $L$, and the number of i.i.d. samples from the manifolds is polynomial in $L$, randomly-initialized gradient descent rapidly learns to classify the two manifolds perfectly with high probability. Our analysis demonstrates concrete benefits of depth and width in the context of a practically-motivated model problem: the depth acts as a fitting resource, with larger depths corresponding to smoother networks that can more readily separate the class manifolds, and the width acts as a statistical resource, enabling concentration of the randomly-initialized network and its gradients. The argument centers around the ""neural tangent kernel"" of Jacot et al. and its role in the nonasymptotic analysis of training overparameterized neural networks; to this literature, we contribute essentially optimal rates of concentration for the neural tangent kernel of deep fully-connected ReLU networks, requiring width $n \geq L\,\mathrm{poly}(d_0)$ to achieve uniform concentration of the initial kernel over a $d_0$-dimensional submanifold of the unit sphere $\mathbb{S}^{n_0-1}$, and a nonasymptotic framework for establishing generalization of networks trained in the ""NTK regime"" with structured data. The proof makes heavy use of martingale concentration to optimally treat statistical dependencies across layers of the initial random network. This approach should be of use in establishing similar results for other network architectures.",マシンビジョンのアプリケーションをモデルにしたバイナリ分類タスクである複数多様体問題を研究します。この問題では、完全に接続された深いニューラルネットワークが、単位球の2つの低次元部分多様体を分離するようにトレーニングされます。 1次元の場合の分析を提供し、ネットワークの深さLがデータの特定の幾何学的および統計的特性に比べて大きい場合、ネットワークの幅nがLの十分に大きな多項式として成長するという単純な多様体構成を証明します。多様体からのiidサンプルの数はLの多項式であり、ランダムに初期化された最急降下法は、2つの多様体を高い確率で完全に分類することを迅速に学習します。私たちの分析は、実際に動機付けられたモデル問題のコンテキストでの深さと幅の具体的な利点を示しています。深さはフィッティングリソースとして機能し、深さが大きいほど、クラス多様体をより簡単に分離できるより滑らかなネットワークに対応し、幅は統計リソース。ランダムに初期化されたネットワークとその勾配の集中を可能にします。議論は、Jacotらの「神経接線カーネル」を中心にしています。過剰パラメータ化ニューラルネットワークのトレーニングの非漸近分析におけるその役割。この文献に、完全に接続された深いReLUネットワークの神経接線カーネルに本質的に最適な濃度率を提供します。単位球のd0次元部分多様体全体で初期カーネルの均一な濃度を達成するには、幅n L poly（d0）が必要です。 S ^（n0 1）、および構造化データを使用して「NTKレジーム」でトレーニングされたネットワークの一般化を確立するための非漸近フレームワーク。この証明は、マルチンゲール濃度を多用して、初期ランダムネットワークのレイヤー全体の統計的依存関係を最適に処理します。このアプローチは、他のネットワークアーキテクチャで同様の結果を確立するのに役立つはずです。,6.5,https://d3i71xaburhd42.cloudfront.net/f846570357da9a7cf5e4c77d9e62a20ad138f058/4-Figure1-1.png
Rapid Task-Solving in Novel Environments,"['Samuel Ritter', 'Ryan Faulkner', 'Laurent Sartran', 'Adam Santoro', 'Matthew Botvinick', 'David Raposo']",https://openreview.net/forum?id=F-mvpFpn_0q,"We propose the challenge of rapid task-solving in novel environments (RTS), wherein an agent must solve a series of tasks as rapidly as possible in an unfamiliar environment. An effective RTS agent must balance between exploring the unfamiliar environment and solving its current task, all while building a model of the new environment over which it can plan when faced with later tasks. While modern deep RL agents exhibit some of these abilities in isolation, none are suitable for the full RTS challenge. To enable progress toward RTS, we introduce two challenge domains: (1) a minimal RTS challenge called the Memory\&Planning Game and (2) One-Shot StreetLearn Navigation, which introduces scale and complexity from real-world data. We demonstrate that state-of-the-art deep RL agents fail at RTS in both domains, and that this failure is due to an inability to plan over gathered knowledge. We develop Episodic Planning Networks (EPNs) and show that deep-RL agents with EPNs excel at RTS, outperforming the nearest baseline by factors of 2-3 and learning to navigate held-out StreetLearn maps within a single episode. We show that EPNs learn to execute a value iteration-like planning algorithm and that they generalize to situations beyond their training experience.",エージェントが不慣れな環境で可能な限り迅速に一連のタスクを解決する必要がある、新しい環境（RTS）での迅速なタスク解決の課題を提案します。効果的なRTSエージェントは、なじみのない環境の探索と現在のタスクの解決のバランスを取りながら、後のタスクに直面したときに計画できる新しい環境のモデルを構築する必要があります。最新のディープRLエージェントは、これらの機能の一部を単独で示しますが、完全なRTSチャレンジに適したものはありません。 RTSに向けた進歩を可能にするために、2つのチャレンジドメインを導入します。（1）Memory＆Planning Gameと呼ばれる最小限のRTSチャレンジと、（2）実世界のデータからスケールと複雑さを導入するOne-Shot StreetLearnNavigationです。最先端のディープRLエージェントが両方のドメインのRTSで失敗すること、およびこの失敗は収集された知識を計画できないことが原因であることを示します。エピソード計画ネットワーク（EPN）を開発し、EPNを使用するdeep-RLエージェントがRTSで優れており、最も近いベースラインを2〜3倍上回り、1つのエピソード内で保持されているStreetLearnマップをナビゲートすることを学習します。 EPNが価値反復のような計画アルゴリズムを実行することを学び、トレーニング経験を超えた状況に一般化することを示します。,6.5,https://d3i71xaburhd42.cloudfront.net/6f505f9b8611ea5d1fcf4405a6abb42e0c0c27f1/2-Figure1-1.png
Topology-Aware Segmentation Using Discrete Morse Theory,"['Xiaoling Hu', 'Yusu Wang', 'Li Fuxin', 'Dimitris Samaras', 'Chao Chen']",https://openreview.net/forum?id=LGgdb4TS4Z,"In the segmentation of fine-scale structures from natural and biomedical images, per-pixel accuracy is not the only metric of concern. Topological correctness, such as vessel connectivity and membrane closure, is crucial for downstream analysis tasks. In this paper, we propose a new approach to train deep image segmentation networks for better topological accuracy. In particular, leveraging the power of discrete Morse theory (DMT), we identify global structures, including 1D skeletons and 2D patches, which are important for topological accuracy. Trained with a novel loss based on these global structures, the network performance is significantly improved especially near topologically challenging locations (such as weak spots of connections and membranes). On diverse datasets, our method achieves superior performance on both the DICE score and topological metrics.",自然画像や生物医学画像からの微細構造のセグメンテーションでは、ピクセルごとの精度だけが問題となる指標ではありません。血管の接続性や膜の閉鎖などのトポロジーの正確さは、下流の分析タスクにとって非常に重要です。この論文では、より良いトポロジー精度のために深い画像セグメンテーションネットワークを訓練するための新しいアプローチを提案します。特に、離散モース理論（DMT）の力を活用して、トポロジーの精度にとって重要な1Dスケルトンや2Dパッチなどのグローバル構造を特定します。これらのグローバル構造に基づいた新しい損失でトレーニングされたネットワークパフォーマンスは、特にトポロジ的に困難な場所（接続や膜の弱点など）の近くで大幅に改善されます。多様なデータセットで、私たちの方法は、DICEスコアとトポロジーメトリックの両方で優れたパフォーマンスを実現します。,6.5,
Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics,"['Vinay Venkatesh Ramasesh', 'Ethan Dyer', 'Maithra Raghu']",https://openreview.net/forum?id=LhY8QdUGSuw,"Catastrophic forgetting is a recurring challenge to developing versatile deep learning models. Despite its ubiquity, there is limited understanding of its connections to neural network (hidden) representations and task semantics. In this paper, we address this important knowledge gap. Through quantitative analysis of neural representations, we find that deeper layers are disproportionately responsible for forgetting, with sequential training resulting in an erasure of earlier task representational subspaces. Methods to mitigate forgetting stabilize these deeper layers, but show diversity on precise effects, with some increasing feature reuse while others store task representations orthogonally, preventing interference. These insights also enable the development of an analytic argument and empirical picture relating forgetting to task semantic similarity, where we find that maximal forgetting occurs for task sequences with intermediate similarity.",壊滅的な忘却は、多目的な深層学習モデルを開発するための繰り返しの課題です。その遍在性にもかかわらず、ニューラルネットワーク（非表示）表現およびタスクセマンティクスへの接続についての理解は限られています。このホワイトペーパーでは、この重要な知識のギャップに対処します。神経表現の定量分析を通じて、より深い層が忘却に不釣り合いに責任があることがわかり、順次トレーニングにより、以前のタスク表現部分空間が消去されます。忘却を軽減する方法は、これらのより深い層を安定させますが、正確な効果に多様性を示し、機能の再利用を増やすものもあれば、タスク表現を直交して保存して干渉を防ぐものもあります。これらの洞察はまた、忘却をタスクの意味的類似性に関連付ける分析的議論と経験的図の開発を可能にします。そこでは、中間の類似性を持つタスクシーケンスで最大の忘却が発生することがわかります。,6.5,https://d3i71xaburhd42.cloudfront.net/1dddfe2c8c3cce6ae7c18f7ecb89fbe664057269/4-Figure1-1.png
NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation,"['Angtian Wang', 'Adam Kortylewski', 'Alan Yuille']",https://openreview.net/forum?id=pmj131uIL9H,"3D pose estimation is a challenging but important task in computer vision. In this work, we show that standard deep learning approaches to 3D pose estimation are not robust to partial occlusion. Inspired by the robustness of generative vision models to partial occlusion, we propose to integrate deep neural networks with 3D generative representations of objects into a unified neural architecture that we term NeMo. In particular, NeMo learns a generative model of neural feature activations at each vertex on a dense 3D mesh. Using differentiable rendering we estimate the 3D object pose by minimizing the reconstruction error between NeMo and the feature representation of the target image. To avoid local optima in the reconstruction loss, we train the feature extractor to maximize the distance between the individual feature representations on the mesh using contrastive learning. Our extensive experiments on PASCAL3D+, occluded-PASCAL3D+ and ObjectNet3D show that NeMo is much more robust to partial occlusion compared to standard deep networks, while retaining competitive performance on non-occluded data. Interestingly, our experiments also show that NeMo performs reasonably well even when the mesh representation only crudely approximates the true object geometry with a cuboid, hence revealing that the detailed 3D geometry is not needed for accurate 3D pose estimation.",3Dポーズ推定は、コンピュータビジョンにおいて挑戦的ですが、重要なタスクです。この作業では、3Dポーズ推定への標準的な深層学習アプローチが部分的な閉塞に対してロバストではないことを示します。部分的閉塞に対する生成的ビジョンモデルの堅牢性に触発されて、深層ニューラルネットワークをオブジェクトの3D生成的表現と統合して、NeMoと呼ばれる統合ニューラルアーキテクチャにすることを提案します。特に、NeMoは、密な3Dメッシュ上の各頂点での神経機能の活性化の生成モデルを学習します。微分可能なレンダリングを使用して、NeMoとターゲット画像の特徴表現との間の再構成エラーを最小化することにより、3Dオブジェクトのポーズを推定します。再構成損失の局所的な最適化を回避するために、対照学習を使用してメッシュ上の個々の特徴表現間の距離を最大化するように特徴抽出器をトレーニングします。 PASCAL3D +、オクルージョンされたPASCAL3D +、およびObjectNet3Dに関する広範な実験では、NeMoは、オクルージョンされていないデータで競争力のあるパフォーマンスを維持しながら、標準のディープネットワークと比較して部分的なオクルージョンに対してはるかに堅牢であることが示されています。興味深いことに、私たちの実験では、メッシュ表現が直方体で実際のオブジェクトジオメトリを大まかに近似している場合でも、NeMoが適度に良好に機能することも示されています。したがって、正確な3Dポーズ推定には詳細な3Dジオメトリは必要ありません。,6.5,https://d3i71xaburhd42.cloudfront.net/02200d454717ffea6c1daf64d635ab945d4fa140/2-Figure1-1.png
MoVie: Revisiting Modulated Convolutions for Visual Counting and Beyond,"['Duy Kien Nguyen', 'Vedanuj Goswami', 'Xinlei Chen']",https://openreview.net/forum?id=8e6BrwU6AjQ,"This paper focuses on visual counting, which aims to predict the number of occurrences given a natural image and a query (e.g. a question or a category). Unlike most prior works that use explicit, symbolic models which can be computationally expensive and limited in generalization, we propose a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. Following the design of residual bottleneck, we call our method MoVie, short for Modulated conVolutional bottlenecks. Notably, MoVie reasons implicitly and holistically and only needs a single forward-pass during inference. Nevertheless, MoVie showcases strong performance for counting: 1) advancing the state-of-the-art on counting-specific VQA tasks while being more efficient; 2) outperforming prior-art on difficult benchmarks like COCO for common object counting; 3) helped us secure the first place of 2020 VQA challenge when integrated as a module for ‘number’ related questions in generic VQA models. Finally, we show evidence that modulated convolutions such as MoVie can serve as a general mechanism for reasoning tasks beyond counting.",このホワイトペーパーでは、自然な画像とクエリ（質問やカテゴリなど）が与えられた場合の発生数を予測することを目的とした視覚的なカウントに焦点を当てています。計算コストが高く、一般化が制限される可能性のある明示的なシンボリックモデルを使用する以前のほとんどの作品とは異なり、クエリと画像をローカルで融合する変調畳み込みを再検討することにより、シンプルで効果的な代替案を提案します。残留ボトルネックの設計に続いて、ModulatedconVolutionalボトルネックの略でメソッドをMoVieと呼びます。特に、MoVieは暗黙的かつ全体的に推論し、推論中に1回のフォワードパスのみを必要とします。それにもかかわらず、MoVieは、カウントの強力なパフォーマンスを示しています。1）より効率的でありながら、カウント固有のVQAタスクに関する最先端技術を進歩させる。 2）一般的なオブジェクトのカウントに関するCOCOのような難しいベンチマークで従来技術を上回っています。 3）一般的なVQAモデルの数値関連の質問のモジュールとして統合された場合、2020VQAチャレンジの最初の場所を確保するのに役立ちました。最後に、MoVieなどの変調された畳み込みが、カウント以外のタスクを推論するための一般的なメカニズムとして機能できるという証拠を示します。,6.5,https://d3i71xaburhd42.cloudfront.net/53cd3ae141da562a7e2006fc881dd0b9682801c9/2-Figure1-1.png
PC2WF: 3D Wireframe Reconstruction from Raw Point Clouds,"['Yujia Liu', ""Stefano D'Aronco"", 'Konrad Schindler', 'Jan Dirk Wegner']",https://openreview.net/forum?id=8X2eaSZxTP,"We introduce PC2WF, the first end-to-end trainable deep network architecture to convert a 3D point cloud into a wireframe model. The network takes as input an unordered set of 3D points sampled from the surface of some object, and outputs a wireframe of that object, i.e., a sparse set of corner points linked by line segments. Recovering the wireframe is a challenging task, where the numbers of both vertices and edges are different for every instance, and a-priori unknown. Our architecture gradually builds up the model: It starts by encoding the points into feature vectors. Based on those features, it identifies a pool of candidate vertices, then prunes those candidates to a final set of corner vertices and refines their locations. Next, the corners are linked with an exhaustive set of candidate edges, which is again pruned to obtain the final wireframe. All steps are trainable, and errors can be backpropagated through the entire sequence. We validate the proposed model on a publicly available synthetic dataset, for which the ground truth wireframes are accessible, as well as on a new real-world dataset. Our model produces wireframe abstractions of good quality and outperforms several baselines.",3Dポイントクラウドをワイヤーフレームモデルに変換する最初のエンドツーエンドのトレーニング可能なディープネットワークアーキテクチャであるPC2WFを紹介します。ネットワークは、あるオブジェクトの表面からサンプリングされた順序付けられていない3Dポイントのセットを入力として受け取り、そのオブジェクトのワイヤーフレーム、つまり線分でリンクされたまばらなコーナーポイントのセットを出力します。ワイヤーフレームの回復は困難な作業であり、頂点とエッジの両方の数がインスタンスごとに異なり、事前に不明です。私たちのアーキテクチャは徐々にモデルを構築します。それは、点を特徴ベクトルにエンコードすることから始まります。これらの機能に基づいて、候補頂点のプールを識別し、それらの候補をコーナー頂点の最終セットにプルーニングして、それらの位置を調整します。次に、コーナーは候補エッジの完全なセットにリンクされ、最終的なワイヤーフレームを取得するために再び剪定されます。すべてのステップはトレーニング可能であり、エラーはシーケンス全体に逆伝播する可能性があります。提案されたモデルは、グラウンドトゥルースワイヤーフレームにアクセスできる公開されている合成データセットと、新しい実世界のデータセットで検証します。私たちのモデルは、高品質のワイヤーフレーム抽象化を生成し、いくつかのベースラインを上回ります。,6.5,
Benchmarks for Deep Off-Policy Evaluation,"['Justin Fu', 'Mohammad Norouzi', 'Ofir Nachum', 'George Tucker', 'ziyu wang', 'Alexander Novikov', 'Mengjiao Yang', 'Michael R Zhang', 'Yutian Chen', 'Aviral Kumar', 'Cosmin Paduraru', 'Sergey Levine', 'Thomas Paine']",https://openreview.net/forum?id=kWSeGEeHvF8,"Off-policy evaluation (OPE) holds the promise of being able to leverage large, offline datasets for both obtaining and selecting complex policies for decision making. The ability to perform evaluation offline is particularly important in many real-world domains, such as healthcare, recommender systems, or robotics, where online data collection is an expensive and potentially dangerous process. Being able to accurately evaluate and select high-performing policies without requiring online interaction could yield significant benefits in safety, time, and cost for these applications. While many OPE methods have been proposed in recent years, comparing results between works is difficult because there is currently a lack of a comprehensive and unified benchmark. Moreover, it is difficult to measure how far algorithms have progressed, due to the lack of challenging evaluation tasks. In order to address this gap, we propose a new benchmark for off-policy evaluation which includes tasks on a range of challenging, high-dimensional control problems, with wide selections of datasets and policies for performing policy selection. The goal of of our benchmark is to provide a standardized measure of progress that is motivated from a set of principles designed to challenge and test the limits of existing OPE methods. We perform a comprehensive evaluation of state-of-the-art algorithms, and we will provide open-source access to all data and code to foster future research in this area.",オフポリシー評価（OPE）は、意思決定のための複雑なポリシーの取得と選択の両方に、大規模なオフラインデータセットを活用できる可能性を秘めています。オフラインで評価を実行する機能は、ヘルスケア、レコメンダーシステム、ロボット工学など、オンラインデータ収集が高価で​​潜在的に危険なプロセスである多くの実際のドメインで特に重要です。オンラインでのやり取りを必要とせずに高性能のポリシーを正確に評価および選択できると、これらのアプリケーションの安全性、時間、およびコストに大きなメリットがもたらされる可能性があります。近年、多くのOPE手法が提案されていますが、現在、包括的で統一されたベンチマークが不足しているため、作業間の結果を比較することは困難です。さらに、困難な評価タスクがないため、アルゴリズムがどこまで進んだかを測定することは困難です。このギャップに対処するために、ポリシー選択を実行するためのデータセットとポリシーの幅広い選択を伴う、さまざまな困難で高次元の制御問題に関するタスクを含む、ポリシー外評価の新しいベンチマークを提案します。私たちのベンチマークの目標は、既存のOPEメソッドの限界に挑戦してテストするように設計された一連の原則から動機付けられた進歩の標準化された尺度を提供することです。最先端のアルゴリズムの包括的な評価を行い、この分野での将来の研究を促進するために、すべてのデータとコードへのオープンソースアクセスを提供します。,6.5,
Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis,"['Rafael Valle', 'Kevin J. Shih', 'Ryan Prenger', 'Bryan Catanzaro']",https://openreview.net/forum?id=Ig53hpHxS4,"In this paper we propose Flowtron: an autoregressive flow-based generative network for text-to-speech synthesis with style transfer and speech variation. Flowtron borrows insights from Autoregressive Flows and revamps Tacotron in order to provide high-quality and expressive mel-spectrogram synthesis. Flowtron is optimized by maximizing the likelihood of the training data, which makes training simple and stable. Flowtron learns an invertible mapping of data to a latent space that can be used to modulate many aspects of speech synthesis (timbre, expressivity, accent). Our mean opinion scores (MOS) show that Flowtron matches state-of-the-art TTS models in terms of speech quality. We provide results on speech variation, interpolation over time between samples and style transfer between seen and unseen speakers. Code and pre-trained models are publicly available.",この論文では、Flowtronを提案します。これは、スタイル転送と音声バリエーションを使用したテキスト読み上げ合成のための自己回帰フローベースの生成ネットワークです。 Flowtronは、自己回帰フローから洞察を借りて、高品質で表現力豊かなメルスペクトログラム合成を提供するためにTacotronを刷新します。 Flowtronは、トレーニングデータの可能性を最大化することで最適化され、トレーニングをシンプルかつ安定させます。 Flowtronは、音声合成の多くの側面（音色、表現力、アクセント）を変調するために使用できる潜在空間へのデータの可逆マッピングを学習します。私たちの平均オピニオン評点（MOS）は、Flowtronが音声品質の点で最先端のTTSモデルと一致することを示しています。音声の変化、サンプル間の時間の経過に伴う補間、および見えている話者と見えていない話者の間のスタイル転送に関する結果を提供します。コードと事前トレーニング済みモデルは公開されています。,6.5,https://d3i71xaburhd42.cloudfront.net/f18bd3e4ac8a50dfce2d863a8dc0eba259ab9ce4/4-Figure1-1.png
Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding,"['Sana Tonekaboni', 'Danny Eytan', 'Anna Goldenberg']",https://openreview.net/forum?id=8qDwejCuCN,"Time series are often complex and rich in information but sparsely labeled and therefore challenging to model. In this paper, we propose a self-supervised framework for learning robust and generalizable representations for time series. Our approach, called Temporal Neighborhood Coding (TNC), takes advantage of the local smoothness of a signal's generative process to define neighborhoods in time with stationary properties. Using a debiased contrastive objective, our framework learns time series representations by ensuring that in the encoding space, the distribution of signals from within a neighborhood is distinguishable from the distribution of non-neighboring signals. Our motivation stems from the medical field, where the ability to model the dynamic nature of time series data is especially valuable for identifying, tracking, and predicting the underlying patients' latent states in settings where labeling data is practically impossible. We compare our method to recently developed unsupervised representation learning approaches and demonstrate superior performance on clustering and classification tasks for multiple datasets.",多くの場合、時系列は複雑で情報が豊富ですが、ラベルがまばらであるため、モデル化が困難です。この論文では、時系列のロバストで一般化可能な表現を学習するための自己教師ありフレームワークを提案します。 Temporal Neighborhood Coding（TNC）と呼ばれる私たちのアプローチは、信号生成プロセスの局所的な滑らかさを利用して、定常特性に合わせて近隣を定義します。偏りのない対照的な目的を使用して、私たちのフレームワークは、エンコード空間で、近隣内からの信号の分布が非近隣信号の分布と区別できるようにすることで、時系列表現を学習します。私たちの動機は、時系列データの動的な性質をモデル化する機能が、データのラベル付けが事実上不可能な状況で、基礎となる患者の潜在状態を識別、追跡、および予測するために特に価値がある医療分野に由来します。私たちの方法を最近開発された教師なし表現学習アプローチと比較し、複数のデータセットのクラスタリングおよび分類タスクで優れたパフォーマンスを示します。,6.5,
Noise or Signal: The Role of Image Backgrounds in Object Recognition,"['Kai Yuanqing Xiao', 'Logan Engstrom', 'Andrew Ilyas', 'Aleksander Madry']",https://openreview.net/forum?id=gl3D-xY7wLq,"We assess the tendency of state-of-the-art object recognition models to depend on signals from image backgrounds. We create a toolkit for disentangling foreground and background signal on ImageNet images, and find that (a) models can achieve non-trivial accuracy by relying on the background alone, (b) models often misclassify images even in the presence of correctly classified foregrounds--up to 88% of the time with adversarially chosen backgrounds, and (c) more accurate models tend to depend on backgrounds less. Our analysis of backgrounds brings us closer to understanding which correlations machine learning models use, and how they determine models' out of distribution performance.
",最先端の物体認識モデルが画像の背景からの信号に依存する傾向を評価します。 ImageNet画像の前景と背景の信号を解きほぐすためのツールキットを作成し、（a）モデルは背景のみに依存することで重要な精度を達成できること、（b）モデルは正しく分類された前景が存在する場合でも画像を誤分類することが多いことを発見しました。 88,6.5,https://d3i71xaburhd42.cloudfront.net/5c63fc87400a4d3afea63ab8a068a47249f815c2/2-Figure1-1.png
The role of Disentanglement in Generalisation,"['Milton Llera Montero', 'Casimir JH Ludwig', 'Rui Ponte Costa', 'Gaurav Malhotra', 'Jeffrey Bowers']",https://openreview.net/forum?id=qbH974jKUVy,"Combinatorial generalisation — the ability to understand and produce novel combinations of familiar elements — is a core capacity of human intelligence that current AI systems struggle with. Recently, it has been suggested that learning disentangled representations may help address this problem. It is claimed that such representations should be able to capture the compositional structure of the world which can then be combined to support combinatorial generalisation. In this study, we systematically tested how the degree of disentanglement affects various forms of generalisation, including two forms of combinatorial generalisation that varied in difficulty. We trained three classes of variational autoencoders (VAEs) on two datasets on an unsupervised task by excluding combinations of generative factors during training. At test time we ask the models to reconstruct the missing combinations in order to measure generalisation performance. Irrespective of the degree of disentanglement, we found that the models supported only weak combinatorial generalisation. We obtained the same outcome when we directly input perfectly disentangled representations as the latents, and when we tested a model on a more complex task that explicitly required independent generative factors to be controlled. While learning disentangled representations does improve interpretability and sample efficiency in some downstream tasks, our results suggest that they are not sufficient for supporting more difficult forms of generalisation.",組み合わせの一般化身近な要素の新しい組み合わせを理解して生成する能力は、現在のAIシステムが苦労している人間の知性の中核的な能力です。最近、解きほぐされた表現を学ぶことがこの問題に対処するのに役立つかもしれないことが示唆されました。そのような表現は、組み合わせの一般化をサポートするために組み合わせることができる世界の構成構造をキャプチャできるはずであると主張されています。この研究では、解きほぐしの程度が、難易度が異なる2つの形式の組み合わせ一般化を含む、さまざまな形式の一般化にどのように影響するかを体系的にテストしました。トレーニング中に生成要因の組み合わせを除外することにより、教師なしタスクの2つのデータセットで3つのクラスの変分オートエンコーダー（VAE）をトレーニングしました。テスト時に、一般化のパフォーマンスを測定するために、欠落している組み合わせを再構築するようにモデルに依頼します。解きほぐしの程度に関係なく、モデルは弱い組み合わせの一般化のみをサポートしていることがわかりました。潜在的なものとして完全に解きほぐされた表現を直接入力したとき、および制御する独立した生成因子を明示的に必要とするより複雑なタスクでモデルをテストしたときに、同じ結果が得られました。解きほぐされた表現を学習することで、一部のダウンストリームタスクの解釈可能性とサンプル効率が向上しますが、私たちの結果は、より難しい形式の一般化をサポートするには不十分であることを示唆しています。,6.5,
Open Question Answering over Tables and Text,"['Wenhu Chen', 'Ming-Wei Chang', 'Eva Schlinger', 'William Yang Wang', 'William W. Cohen']",https://openreview.net/forum?id=MmCRswl1UYl,"In open question answering (QA), the answer to a question is produced by retrieving and then analyzing documents that might contain answers to the question.  Most open QA systems have considered only retrieving information from unstructured text.  Here we consider for the first time open QA over {\em both} tabular and textual data and present a new large-scale dataset \emph{Open Table-and-Text Question Answering} (OTT-QA) to evaluate performance on this task. Most questions in OTT-QA require multi-hop inference across tabular data and unstructured text, and the evidence required to answer a question can be distributed in different ways over these two types of input, making evidence retrieval challenging---our baseline model using an iterative retriever and BERT-based reader achieves an exact match score less than 10\%. We then propose two novel techniques to address the challenge of retrieving and aggregating evidence for OTT-QA. The first technique is to use ``early fusion'' to group multiple highly relevant tabular and textual units into a fused block, which provides more context for the retriever to search for.  The second technique is to use a cross-block reader to model the cross-dependency between multiple retrieved evidence with global-local sparse attention. Combining these two techniques improves the score significantly, to above 27\%.",未解決の質問応答（QA）では、質問に対する回答は、質問に対する回答が含まれている可能性のあるドキュメントを取得して分析することによって生成されます。ほとんどのオープンQAシステムは、非構造化テキストからの情報の取得のみを検討しています。ここでは、表形式とテキスト形式の両方のデータに対するオープンQAを初めて検討し、このタスクのパフォーマンスを評価するための新しい大規模データセットのオープンテーブルとテキストの質問応答（OTT-QA）を提示します。 OTT-QAのほとんどの質問は、表形式のデータと非構造化テキストにわたるマルチホップ推論を必要とし、質問に回答するために必要な証拠は、これら2種類の入力にさまざまな方法で分散できるため、反復検索を使用したベースラインモデルでは、証拠の検索が困難になります。 BERTベースのリーダーは、10％未満の完全一致スコアを達成します。次に、OTT-QAの証拠を取得して集約するという課題に対処するための2つの新しい手法を提案します。最初の手法は、初期の融合を使用して、関連性の高い複数の表形式およびテキスト単位を融合ブロックにグループ化することです。これにより、レトリーバーが検索するコンテキストが増えます。 2番目の手法は、クロスブロックリーダーを使用して、グローバルローカルのまばらな注意を払って複数の取得された証拠間の相互依存関係をモデル化することです。これら2つの手法を組み合わせると、スコアが27％を超えるまで大幅に向上します。,6.5,https://d3i71xaburhd42.cloudfront.net/aa587df44d1e9e0ebc564e5742dc7592f9800a7d/2-Figure1-1.png
LEAF: A Learnable Frontend for Audio Classification,"['Neil Zeghidour', 'Olivier Teboul', 'Félix de Chaumont Quitry', 'Marco Tagliasacchi']",https://openreview.net/forum?id=jM76BCb6F9m,"Mel-filterbanks are fixed, engineered audio features which emulate human perception and have been used through the history of audio understanding up to today. However, their undeniable qualities are counterbalanced by the fundamental limitations of handmade representations. In this work we show that we can train a single learnable frontend that outperforms mel-filterbanks on a wide range of audio signals, including speech, music, audio events and animal sounds, providing a general-purpose learned frontend for audio classification. To do so, we introduce a new principled, lightweight, fully learnable architecture that can be used as a drop-in replacement of mel-filterbanks. Our system learns all operations of audio features extraction, from filtering to pooling, compression and normalization, and can be integrated into any neural network at a negligible parameter cost. We perform multi-task training on eight diverse audio classification tasks, and show consistent improvements of our model over mel-filterbanks and previous learnable alternatives. Moreover, our system outperforms the current state-of-the-art learnable frontend on Audioset, with orders of magnitude fewer parameters.",Mel-filterbanksは、人間の知覚をエミュレートする固定の設計されたオーディオ機能であり、今日までのオーディオ理解の歴史を通じて使用されてきました。しかし、それらの否定できない性質は、手作りの表現の基本的な制限によって相殺されます。この作業では、音声、音楽、オーディオイベント、動物の音など、さまざまなオーディオ信号でメルフィルターバンクよりも優れた単一の学習可能なフロントエンドをトレーニングして、オーディオ分類用の汎用学習フロントエンドを提供できることを示します。そのために、メルフィルターバンクのドロップイン代替として使用できる、新しい原理的で軽量で完全に学習可能なアーキテクチャを紹介します。私たちのシステムは、フィルタリングからプーリング、圧縮、正規化まで、オーディオ特徴抽出のすべての操作を学習し、無視できるパラメータコストで任意のニューラルネットワークに統合できます。 8つの多様なオーディオ分類タスクでマルチタスクトレーニングを実行し、メルフィルターバンクや以前の学習可能な代替案よりもモデルが一貫して改善されていることを示しています。さらに、私たちのシステムは、Audiosetの現在の最先端の学習可能なフロントエンドよりも優れており、パラメーターが桁違いに少なくなっています。,6.5,https://d3i71xaburhd42.cloudfront.net/1192660d960d44ae7416a3b7562e87c5f338d691/2-Figure1-1.png
Combining Ensembles and Data Augmentation Can Harm Your Calibration,"['Yeming Wen', 'Ghassen Jerfel', 'Rafael Muller', 'Michael W Dusenberry', 'Jasper Snoek', 'Balaji Lakshminarayanan', 'Dustin Tran']",https://openreview.net/forum?id=g11CZSghXyY,"Ensemble methods which average over multiple neural network predictions are a simple approach to improve a model’s calibration and robustness. Similarly, data augmentation techniques, which encode prior information in the form of invariant feature transformations, are effective for improving calibration and robustness. In this paper, we show a surprising pathology: combining ensembles and data augmentation can harm model calibration. This leads to a trade-off in practice, whereby improved accuracy by combining the two techniques comes at the expense of calibration. On the other hand, selecting only one of the techniques ensures good uncertainty estimates at the expense of accuracy. We investigate this pathology and identify a compounding under-confidence among methods which marginalize over sets of weights and data augmentation techniques which soften labels. Finally, we propose a simple correction, achieving the best of both worlds with significant accuracy and calibration gains over using only ensembles or data augmentation individually. Applying the correction produces new state-of-the art in uncertainty calibration and robustness across CIFAR-10, CIFAR-100, and ImageNet.",複数のニューラルネットワーク予測を平均化するアンサンブル手法は、モデルのキャリブレーションと堅牢性を向上させるための簡単なアプローチです。同様に、不変の特徴変換の形で事前情報をエンコードするデータ拡張技術は、キャリブレーションとロバスト性を改善するのに効果的です。このホワイトペーパーでは、驚くべき病理を示します。アンサンブルとデータ拡張を組み合わせると、モデルのキャリブレーションに悪影響を与える可能性があります。これは実際にはトレードオフにつながり、2つの手法を組み合わせることで精度が向上すると、キャリブレーションが犠牲になります。一方、手法を1つだけ選択すると、精度が犠牲になりますが、不確実性の見積もりが確実になります。この病状を調査し、重みのセットを無視する方法と、ラベルを柔らかくするデータ拡張手法の間で、複合的な自信不足を特定します。最後に、単純な修正を提案し、アンサンブルまたはデータ拡張のみを個別に使用するよりも、大幅な精度とキャリブレーションゲインで両方の長所を実現します。補正を適用すると、CIFAR-10、CIFAR-100、およびImageNet全体で不確実性のキャリブレーションと堅牢性に関する新しい最先端技術が生まれます。,6.5,https://d3i71xaburhd42.cloudfront.net/8c76b4f7a77523e88a32d5d798b03bbf615cb12f/4-Figure1-1.png
Fourier Neural Operator for Parametric Partial Differential Equations,"['Zongyi Li', 'Nikola Borislavov Kovachki', 'Kamyar Azizzadenesheli', 'Burigede liu', 'Kaushik Bhattacharya', 'Andrew Stuart', 'Anima Anandkumar']",https://openreview.net/forum?id=c8P9NQVtmnO,"The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces.  Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.",ニューラルネットワークの古典的な開発は、主に有限次元のユークリッド空間間のマッピングの学習に焦点を合わせてきました。最近、これは関数空間間のマッピングを学習する神経演算子に一般化されました。偏微分方程式（PDE）の場合、ニューラルオペレーターは、関数のパラメトリック依存性から解へのマッピングを直接学習します。したがって、方程式の1つのインスタンスを解く古典的な方法とは対照的に、偏微分方程式のファミリー全体を学習します。この作業では、フーリエ空間で積分カーネルを直接パラメーター化することにより、新しいニューラルオペレーターを定式化し、表現力豊かで効率的なアーキテクチャーを可能にします。バーガース方程式、ダーシーフロー、ナビエ-ストークス方程式の実験を行います。フーリエニューラル演算子は、ゼロショット超解像で乱流をモデル化する最初のMLベースの方法です。従来のPDEソルバーと比較して最大3桁高速です。さらに、固定解像度で以前の学習ベースのソルバーと比較して優れた精度を実現します。,6.5,
Combining Label Propagation and Simple Models out-performs Graph Neural Networks,"['Qian Huang', 'Horace He', 'Abhay Singh', 'Ser-Nam Lim', 'Austin Benson']",https://openreview.net/forum?id=8E1-f3VhX1o,"Graph Neural Networks (GNNs) are now a predominant technique for learning over graphs.  However, there is relatively little understanding of why GNNs are successful and whether they are necessary for good performance. Here, we show that for many standard transductive node classification benchmarks, we can ex-ceed or match the performance of state-of-the-art GNNs by combining shallow multilayer perceptrons models (that ignore the graph structure entirely) with two simple postprocessings for correlation in the label structure: (i) an “error correlation” that spreads residual errors in training data to correct errors in test data and(ii) an “prediction correlation” that smooths the predictions on the test data. These correlations are implemented via simple modifications to standard label propagation techniques developed in early graph-based semi-supervised learning methods.  Our approach achieves state-of-the-art performance across a wide variety of benchmarks, with just a small fraction of the parameters and orders of magnitude faster runtime compared to highly-parameterized GNNs (for instance, we exceed the best known GNN performance on the OGB-Products dataset with >100x fewer parameters and >100x faster training time). The performance of our methods highlights how directly incorporating label information into the learning algorithm (as was done in traditional techniques) yields easy and substantial performance gains, and we argue that GNNs have been approximating this idea, albeit implicitly. We also incorporate label correlation into SOTA GNN models, providing modest gains.",グラフニューラルネットワーク（GNN）は、現在、グラフを学習するための主要な手法です。ただし、GNNが成功する理由と、GNNが良好なパフォーマンスに必要かどうかについては比較的ほとんど理解されていません。ここでは、多くの標準的なトランスダクティブノード分類ベンチマークについて、浅い多層パーセプトロンモデル（グラフ構造を完全に無視する）と2つの単純な後処理を組み合わせることで、最先端のGNNのパフォーマンスを超えるか一致させることができることを示します。ラベル構造の相関：（i）トレーニングデータの残留エラーを拡散してテストデータのエラーを修正するエラー相関、および（ii）テストデータの予測を平滑化する予測相関。これらの相関関係は、初期のグラフベースの半教師あり学習方法で開発された標準的なラベル伝播手法への簡単な変更によって実装されます。私たちのアプローチは、さまざまなベンチマークで最先端のパフォーマンスを実現し、パラメーターのごく一部と、高度にパラメーター化されたGNNと比較して実行時間を桁違いに高速化します（たとえば、で最もよく知られているGNNパフォーマンスを超えていますパラメータが100倍以上少なく、トレーニング時間が100倍以上速いOGB-Productsデータセット）。私たちの方法のパフォーマンスは、ラベル情報を学習アルゴリズムに直接組み込むことで（従来の手法で行われたように）、簡単で実質的なパフォーマンスの向上をもたらす方法を強調しています。GNNは、暗黙的ではありますが、このアイデアを近似していると主張します。また、ラベル相関をSOTA GNNモデルに組み込み、適度なゲインを提供します。,6.5,https://d3i71xaburhd42.cloudfront.net/f1e5e65941617604923225cc4bf464e370fcae67/2-Figure1-1.png
Improving VAEs' Robustness to Adversarial Attack,"['Matthew JF Willetts', 'Alexander Camuto', 'Tom Rainforth', 'S Roberts', 'Christopher C Holmes']",https://openreview.net/forum?id=-Hs_otp2RB,"Variational autoencoders (VAEs) have recently been shown to be vulnerable to adversarial attacks, wherein they are fooled into reconstructing a chosen target image. However, how to defend against such attacks remains an open problem. We make significant advances in addressing this issue by introducing methods for producing adversarially robust VAEs. Namely, we first demonstrate that methods proposed to obtain disentangled latent representations produce VAEs that are more robust to these attacks. However, this robustness comes at the cost of reducing the quality of the reconstructions. We ameliorate this by applying disentangling methods to hierarchical VAEs. The resulting models produce high--fidelity autoencoders that are also adversarially robust. We confirm their capabilities on several different datasets and with current state-of-the-art VAE adversarial attacks, and also show that they increase the robustness of downstream tasks to attack.",変分オートエンコーダー（VAE）は、敵対的攻撃に対して脆弱であることが最近示されています。敵対的攻撃では、選択されたターゲット画像の再構築に騙されます。ただし、そのような攻撃からどのように防御するかは、未解決の問題のままです。敵対的に堅牢なVAEを作成する方法を導入することにより、この問題への対処を大幅に進歩させます。つまり、解きほぐされた潜在表現を取得するために提案された方法が、これらの攻撃に対してより堅牢なVAEを生成することを最初に示します。ただし、この堅牢性には、再構築の品質が低下するという犠牲が伴います。階層型VAEにもつれを解く方法を適用することにより、これを改善します。結果として得られるモデルは、非常に堅牢な高忠実度のオートエンコーダを生成します。いくつかの異なるデータセットと現在の最先端のVAE敵対的攻撃でそれらの機能を確認し、攻撃に対するダウンストリームタスクの堅牢性を向上させることも示しています。,6.5,
Local Search Algorithms for Rank-Constrained Convex Optimization,"['Kyriakos Axiotis', 'Maxim Sviridenko']",https://openreview.net/forum?id=tH6_VWZjoq,"We propose greedy and local search algorithms for rank-constrained convex optimization, namely solving $\underset{\mathrm{rank}(A)\leq r^*}{\min}\, R(A)$ given a convex function $R:\mathbb{R}^{m\times n}\rightarrow \mathbb{R}$ and a parameter $r^*$. These algorithms consist of repeating two steps: (a) adding a new rank-1 matrix to $A$ and (b) enforcing the rank constraint on $A$. We refine and improve the theoretical analysis of Shalev-Shwartz et al. (2011), and show that if the rank-restricted condition number of $R$ is $\kappa$, a solution $A$ with rank $O(r^*\cdot \min\{\kappa \log \frac{R(\mathbf{0})-R(A^*)}{\epsilon}, \kappa^2\})$ and $R(A) \leq R(A^*) + \epsilon$ can be recovered, where $A^*$ is the optimal solution. This significantly generalizes associated results on sparse convex optimization, as well as rank-constrained convex optimization for smooth functions. We then introduce new practical variants of these algorithms that have superior runtime and recover better solutions in practice. We demonstrate the versatility of these methods on a wide range of applications involving matrix completion and robust principal component analysis.
",ランク制約付き凸最適化のための欲張り探索アルゴリズムと局所探索アルゴリズムを提案します。つまり、凸関数Rが与えられた場合に$ \ underset {\ mathrm {rank}（A）\ leq r ^ *} {\ min} \、R（A）$を解きます。 ：R ^（mn）Rおよびパラメーターr ^（*）。これらのアルゴリズムは、（a）新しいランク1行列をAに追加すること、および（b）Aにランク制約を適用することの2つのステップを繰り返すことで構成されます。Shalev-Shwartzらの理論的分析を改良および改善します。 （2011）、そしてRのランク制限条件数がである場合、ランク$ O（r ^ * \ cdot \ min \ {\ kappa \ log \ frac {R（\ mathbf {0}）の解A -R（A ^ *）} {\ epsilon}、\ kappa ^ 2 \}）$およびR（A）R（A ^（*））+を回復できます。ここで、A ^（*）が最適解です。これにより、スパース凸最適化に関連する結果と、滑らかな関数のランク制約付き凸最適化が大幅に一般化されます。次に、優れたランタイムを持ち、実際により優れたソリューションを回復する、これらのアルゴリズムの新しい実用的なバリアントを紹介します。行列補完と堅牢な主成分分析を含む幅広いアプリケーションで、これらのメソッドの多様性を示します。,6.5,https://d3i71xaburhd42.cloudfront.net/39dce697171b3f03575de54e970e48b50c96bbb9/6-Figure1-1.png
Improved Estimation of Concentration Under $\ell_p$-Norm Distance Metrics Using Half Spaces,"['Jack Prescott', 'Xiao Zhang', 'David Evans']",https://openreview.net/forum?id=BUlyHkzjgmA,"Concentration of measure has been argued to be the fundamental cause of adversarial vulnerability. Mahloujifar et al. (2019) presented an empirical way to measure the concentration of a data distribution using samples, and employed it to find lower bounds on intrinsic robustness for several benchmark datasets. However, it remains unclear whether these lower bounds are tight enough to provide a useful approximation for the intrinsic robustness of a dataset. To gain a deeper understanding of the concentration of measure phenomenon, we first extend the Gaussian Isoperimetric Inequality to non-spherical Gaussian measures and arbitrary $\ell_p$-norms ($p \geq 2$). We leverage these theoretical insights to design a method that uses half-spaces to estimate the concentration of any empirical dataset under $\ell_p$-norm distance metrics. Our proposed algorithm is more efficient than Mahloujifar et al. (2019)'s, and experiments on synthetic datasets and image benchmarks demonstrate that it is able to find much tighter intrinsic robustness bounds. These tighter estimates provide further evidence that rules out intrinsic dataset concentration as a possible explanation for the adversarial vulnerability of state-of-the-art classifiers.",対策の集中は、敵対的な脆弱性の根本的な原因であると主張されてきました。 Mahloujifar etal。 （2019）は、サンプルを使用してデータ分布の濃度を測定する経験的な方法を提示し、それを使用して、いくつかのベンチマークデータセットの固有のロバスト性の下限を見つけました。ただし、これらの下限がデータセットの本質的な堅牢性の有用な近似を提供するのに十分に厳しいかどうかは不明なままです。測度の集中現象をより深く理解するために、最初にガウス等値不等式を非球形のガウス測度と任意のl（p）ノルム（p 2）に拡張します。これらの理論的洞察を活用して、半空間を使用してl（p）-ノルム距離メトリックの下での経験的データセットの濃度を推定する方法を設計します。私たちが提案するアルゴリズムは、Mahloujifar etalよりも効率的です。 （2019）、および合成データセットと画像ベンチマークでの実験は、それがはるかに厳しい固有のロバスト性の限界を見つけることができることを示しています。これらのより厳密な見積もりは、最先端の分類器の敵対的な脆弱性の考えられる説明として、固有のデータセットの集中を除外するさらなる証拠を提供します。,6.5,
FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders,"['Pengyu Cheng', 'Weituo Hao', 'Siyang Yuan', 'Shijing Si', 'Lawrence Carin']",https://openreview.net/forum?id=N6JECD-PI5w,"Pretrained text encoders, such as BERT, have been applied increasingly in various natural language processing (NLP) tasks, showing significant performance gains. However, recent studies have demonstrated the existence of social bias in these pretrained NLP models. Although prior works have made progress on word-level debiasing, improved sentence-level fairness of pretrained encoders still lacks exploration. In this paper, we proposed the first neural debiasing method for a pretrained sentence encoder, which transforms the pretrained encoder outputs into debiased representations via a fair filter (FairFil) network. To learn the FairFil, we introduced a contrastive learning framework that not only minimizes the correlation between filtered embeddings and bias words but also preserves rich semantic information of the original sentences. On real-world datasets, our FairFil effectively reduces the bias degree of pretrained text encoders, while continuously showing desirable performance on downstream tasks. Moreover, our post-hoc method does not require any retraining of the text encoders, which further enlarges FairFil's application scenarios.",BERTなどの事前トレーニング済みテキストエンコーダーは、さまざまな自然言語処理（NLP）タスクにますます適用されており、パフォーマンスが大幅に向上しています。ただし、最近の研究では、これらの事前トレーニング済みNLPモデルに社会的バイアスが存在することが示されています。以前の研究は単語レベルのバイアス除去に関して進歩を遂げましたが、事前に訓練されたエンコーダーの改善された文レベルの公平性はまだ調査に欠けています。この論文では、事前訓練されたセンテンスエンコーダの最初のニューラルデバイアス方法を提案しました。これは、事前訓練されたエンコーダ出力を、フェアフィルタ（FairFil）ネットワークを介してバイアス除去された表現に変換します。 FairFilを学習するために、フィルタリングされた埋め込みとバイアスワード間の相関を最小限に抑えるだけでなく、元の文の豊富な意味情報を保持する対照的な学習フレームワークを導入しました。実際のデータセットでは、FairFilは、事前にトレーニングされたテキストエンコーダーのバイアス度を効果的に低減すると同時に、ダウンストリームタスクで望ましいパフォーマンスを継続的に示します。さらに、私たちの事後方法では、テキストエンコーダーの再トレーニングが不要であるため、FairFilsアプリケーションのシナリオがさらに拡大します。,6.5,
Viewmaker Networks: Learning Views for Unsupervised Representation Learning,"['Alex Tamkin', 'Mike Wu', 'Noah Goodman']",https://openreview.net/forum?id=enoVQWLsfyL,"Many recent methods for unsupervised representation learning involve training models to be invariant to different ""views,"" or augmented versions of an input. However, designing these views requires considerable human expertise and experimentation, hindering widespread adoption of unsupervised representation learning methods across domains and modalities. To address this, we propose viewmaker networks: generative models which learn to produce input-dependent views for contrastive learning. We train these networks jointly with the main network to produce adversarial $\ell_p$ perturbations for an input, which yields challenging yet faithful views without extensive human tuning. Our learned views enable comparable transfer accuracy to the the well-studied SimCLR augmentations when applied on CIFAR-10, while significantly outperforming baseline augmentations in speech (+9% absolute) and IMU sensor (+17% absolute) domains. We also show how viewmaker views can be combined with SimCLR views to improve robustness to common image corruptions. Our method provides a roadmap for reducing the amount of expertise and effort needed for unsupervised learning, potentially extending its benefits to a much wider set of domains.",教師なし表現学習の最近の方法の多くは、さまざまな「ビュー」または入力の拡張バージョンに対して不変であるようにモデルをトレーニングすることを含みます。ただし、これらのビューを設計するには、かなりの人間の専門知識と実験が必要であり、ドメインやモダリティ全体で教師なし表現学習方法を広く採用することはできません。これに対処するために、ビューメーカーネットワークを提案します。対照的な学習のために入力に依存するビューを生成することを学習する生成モデルです。これらのネットワークをメインネットワークと共同でトレーニングして、入力に対して敵対的なl（p）摂動を生成します。これにより、人間による広範な調整なしで、挑戦的でありながら忠実なビューが生成されます。私たちが学んだ見解は、CIFAR-10に適用した場合、十分に研究されたSimCLR増強に匹敵する転送精度を可能にし、音声のベースライン増強を大幅に上回ります（+9,6.5,https://d3i71xaburhd42.cloudfront.net/c511eee7f7107f75fe92285f034c1ef0a8de59cb/1-Figure1-1.png
Neural Approximate Sufficient Statistics for Implicit Models,"['Yanzhi Chen', 'Dinghuai Zhang', 'Michael U. Gutmann', 'Aaron Courville', 'Zhanxing Zhu']",https://openreview.net/forum?id=SRDuJssQud,"We consider the fundamental problem of how to automatically construct summary statistics for likelihood-free inference where the evaluation of likelihood function is intractable but sampling / simulating data from the model is possible. The idea is to frame the task of constructing sufficient statistics as learning mutual information maximizing representation of the data. This representation is computed by a deep neural network trained by a joint statistic-posterior learning strategy. We apply our approach to both traditional approximate Bayesian computation and recent neural-likelihood methods, boosting their performance on a wide range of tasks. ",尤度関数の評価が困難であるが、モデルからのデータのサンプリング/シミュレーションが可能である場合に、尤度のない推論のための要約統計量を自動的に構築する方法の基本的な問題を検討します。アイデアは、データの表現を最大化する相互情報量を学習することとして、十分統計量を構築するタスクを組み立てることです。この表現は、統計と事後の共同学習戦略によってトレーニングされたディープニューラルネットワークによって計算されます。従来の近似ベイズ計算と最近の最尤法の両方にアプローチを適用し、幅広いタスクでのパフォーマンスを向上させます。,6.5,https://d3i71xaburhd42.cloudfront.net/9dfe5d4fe11d5a708e9988e9a1464fd8afe3b797/6-Figure1-1.png
Revisiting Dynamic Convolution via Matrix Decomposition,"['Yunsheng Li', 'Yinpeng Chen', 'Xiyang Dai', 'mengchen liu', 'Dongdong Chen', 'Ye Yu', 'Lu Yuan', 'Zicheng Liu', 'Mei Chen', 'Nuno Vasconcelos']",https://openreview.net/forum?id=YwpZmcAehZ,"Recent research in dynamic convolution shows substantial performance boost for efficient CNNs, due to the adaptive aggregation of K static convolution kernels.It has two limitations: (a) it increases the number of convolutional weights by K-times, and (b) the joint optimization of dynamic attention and static convolution kernels is challenging.  In this paper, we revisit it from a new perspective of matrix decomposition and reveal the key issue is that dynamic convolution applies dynamic attentions over channel groups after projecting into a higher dimensional intermediate space.   To address this issue,  we propose dynamic channel fusion to replace dynamic attentions over channel groups.  Dynamic channel fusion not only enables significant dimension reduction of the intermediate space, but also mitigates the joint optimization difficulty. As a result, our method is easier to train and requires significantly fewer parameters without sacrificing accuracy.",動的畳み込みに関する最近の研究では、K個の静的畳み込みカーネルの適応型集約により、効率的なCNNのパフォーマンスが大幅に向上することが示されています.2つの制限があります：（a）畳み込みの重みの数をK倍に増やす、および（b）ジョイント動的注意と静的畳み込みカーネルの最適化は困難です。この論文では、行列分解の新しい観点からそれを再検討し、重要な問題は、動的畳み込みが高次元の中間空間に投影した後、チャネルグループに動的な注意を適用することであることを明らかにします。この問題に対処するために、チャネルグループに対する動的な注意を置き換える動的チャネル融合を提案します。動的チャネル融合により、中間スペースの大幅な次元削減が可能になるだけでなく、ジョイントの最適化の難しさが軽減されます。その結果、私たちの方法はトレーニングが簡単で、精度を犠牲にすることなく必要なパラメーターが大幅に少なくなります。,6.5,
Batch Reinforcement Learning Through Continuation Method,"['Yijie Guo', 'Shengyu Feng', 'Nicolas Le Roux', 'Ed Chi', 'Honglak Lee', 'Minmin Chen']",https://openreview.net/forum?id=po-DLlBuAuz,"Many real-world applications of reinforcement learning (RL) require the agent to learn from a fixed set of trajectories, without collecting new interactions.  Policy optimization under this setting is extremely challenging as: 1) the geometry of the objective function is hard to optimize efficiently; 2) the shift of data distributions causes high noise in the value estimation. In this work, we propose a simple yet effective policy iteration approach to batch RL using global optimization techniques known as continuation.  By constraining the difference between the learned policy and the behavior policy that generates the fixed trajectories, and continuously relaxing the constraint, our method 1) helps the agent escape local optima; 2) reduces the error in policy evaluation in the optimization procedure.   We present results on a variety of control tasks, game environments, and a recommendation task to empirically demonstrate the efficacy of our proposed method.",強化学習（RL）の実際のアプリケーションの多くは、エージェントが新しい相互作用を収集することなく、固定された一連の軌道から学習する必要があります。この設定でのポリシーの最適化は、次のように非常に困難です。1）目的関数のジオメトリを効率的に最適化するのが難しい。 2）データ分布のシフトは、値の推定で高いノイズを引き起こします。この作業では、継続と呼ばれるグローバル最適化手法を使用して、バッチRLへのシンプルで効果的なポリシー反復アプローチを提案します。学習されたポリシーと固定軌道を生成する動作ポリシーの違いを制約し、制約を継続的に緩和することにより、私たちの方法は1）エージェントが局所最適を逃れるのを助けます。 2）最適化手順でのポリシー評価のエラーを減らします。提案された方法の有効性を経験的に実証するために、さまざまな制御タスク、ゲーム環境、および推奨タスクに関する結果を提示します。,6.5,
 Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning,"['Ruozi Huang', 'Huang Hu', 'Wei Wu', 'Kei Sawada', 'Mi Zhang', 'Daxin Jiang']",https://openreview.net/forum?id=xGZG2kS5bFk,"Dancing to music is one of human's innate abilities since ancient times. In machine learning research, however, synthesizing dance movements from music is a challenging problem. Recently, researchers synthesize human motion sequences through autoregressive models like recurrent neural network (RNN). Such an approach often generates short sequences due to an accumulation of prediction errors that are fed back into the neural network. This problem becomes even more severe in the long motion sequence generation. Besides, the consistency between dance and music in terms of style, rhythm and beat is yet to be taken into account during modeling. In this paper, we formalize the music-driven dance generation as a sequence-to-sequence learning problem and devise a novel seq2seq architecture to efficiently process long sequences of music features and capture the fine-grained correspondence between music and dance. Furthermore, we propose a novel curriculum learning strategy to alleviate error accumulation of autoregressive models in long motion sequence generation, which gently changes the training process from a fully guided teacher-forcing scheme using the previous ground-truth movements, towards a less guided autoregressive scheme mostly using the generated movements instead. Extensive experiments show that our approach significantly outperforms the existing state-of-the-arts on automatic metrics and human evaluation. We also make a demo video in the supplementary material to demonstrate the superior performance of our proposed approach.",音楽に合わせて踊ることは、古くから人間の生来の能力の1つです。ただし、機械学習の研究では、音楽からダンスの動きを合成することは難しい問題です。最近、研究者はリカレントニューラルネットワーク（RNN）のような自己回帰モデルを介して人間のモーションシーケンスを合成します。このようなアプローチでは、ニューラルネットワークにフィードバックされる予測エラーの蓄積により、短いシーケンスが生成されることがよくあります。この問題は、ロングモーションシーケンスの生成ではさらに深刻になります。その上、スタイル、リズム、ビートの面でのダンスと音楽の一貫性は、モデリング中にまだ考慮されていません。この論文では、音楽駆動型ダンス生成をシーケンス間学習問題として形式化し、音楽機能の長いシーケンスを効率的に処理し、音楽とダンスの間のきめ細かい対応をキャプチャするための新しいseq2seqアーキテクチャを考案します。さらに、ロングモーションシーケンス生成における自己回帰モデルのエラー蓄積を軽減するための新しいカリキュラム学習戦略を提案します。これにより、トレーニングプロセスが、以前のグラウンドトゥルースの動きを使用した完全にガイドされた教師強制スキームから、ガイドの少ない自己回帰スキームに穏やかに変更されます。ほとんどの場合、代わりに生成された動きを使用します。広範な実験により、私たちのアプローチは、自動メトリックと人間による評価に関して、既存の最先端技術を大幅に上回っています。また、提案されたアプローチの優れたパフォーマンスを示すために、補足資料でデモビデオを作成します。,6.5,
New Bounds For Distributed Mean Estimation and Variance Reduction,"['Peter Davies', 'Vijaykrishna Gurunanthan', 'Niusha Moshrefi', 'Saleh Ashkboos', 'Dan Alistarh']",https://openreview.net/forum?id=t86MwoUCCNe," We consider the problem of distributed mean estimation (DME), in which $n$ machines are each given a local $d$-dimensional vector $\mathbf x_v \in \mathbb R^d$, and must cooperate to estimate the mean of their inputs $\mathbf \mu = \frac 1n\sum_{v = 1}^n \mathbf x_v$, while minimizing total communication cost. DME is a fundamental construct in distributed machine learning, and there has been considerable work on variants of this problem, especially in the context of distributed variance reduction for stochastic gradients in parallel SGD. Previous work typically assumes an upper bound on the norm of the input vectors, and achieves an error bound in terms of this norm. However, in many real applications, the input vectors are concentrated around the correct output $\mathbf \mu$, but $\mathbf \mu$ itself has large norm. In such cases, previous output error bounds perform poorly. 
            In this paper, we show that output error bounds need not depend on input norm. We provide a method of quantization which allows distributed mean estimation to be performed with solution quality dependent only on the distance between inputs, not on input norm, and show an analogous result for distributed variance reduction. The technique is based on a new connection with lattice theory. We also provide lower bounds showing that the communication to error trade-off of our algorithms is asymptotically optimal. As the lattices achieving optimal bounds under $\ell_2$-norm can be computationally impractical, we also present an extension which leverages  easy-to-use cubic lattices, and is loose only up to a logarithmic factor in $d$. We show experimentally that our method yields practical improvements for common applications, relative to prior approaches.  ",n台のマシンにそれぞれローカルd次元ベクトルX（v）R ^（d）が与えられ、入力の平均を推定するために協力する必要がある分散平均推定（DME）の問題を検討します$ \ mathbf \ mu = \ frac 1n \ sum {v = 1} ^ n \ mathbf xv $、通信コストの合計を最小限に抑えます。 DMEは分散型機械学習の基本的な構成要素であり、特に並列SGDの確率的勾配の分散分散減少のコンテキストで、この問題の変形についてかなりの作業が行われています。以前の作業は通常、入力ベクトルのノルムの上限を想定しており、このノルムに関してエラー限界を達成しています。ただし、多くの実際のアプリケーションでは、入力ベクトルは正しい出力に集中していますが、それ自体には大きなノルムがあります。このような場合、以前の出力エラー範囲のパフォーマンスは低下します。この論文では、出力誤差範囲が入力基準に依存する必要がないことを示します。入力ノルムではなく、入力間の距離のみに依存する解の品質で分散平均推定を実行できる量子化の方法を提供し、分散分散の減少について同様の結果を示します。この手法は、格子理論との新しい関係に基づいています。また、アルゴリズムのエラートレードオフへの通信が漸近的に最適であることを示す下限も提供します。 l2ノルムの下で最適な境界を達成する格子は計算上非現実的である可能性があるため、使いやすい立方格子を活用し、dの対数係数までしか緩くない拡張も提示します。以前のアプローチと比較して、私たちの方法が一般的なアプリケーションの実用的な改善をもたらすことを実験的に示します。,6.5,
CopulaGNN: Towards Integrating Representational and Correlational Roles of Graphs in Graph Neural Networks,"['Jiaqi Ma', 'Bo Chang', 'Xuefei Zhang', 'Qiaozhu Mei']",https://openreview.net/forum?id=XI-OJ5yyse,"Graph-structured data are ubiquitous. However, graphs encode diverse types of information and thus play different roles in data representation. In this paper, we distinguish the \textit{representational} and the \textit{correlational} roles played by the graphs in node-level prediction tasks, and we investigate how Graph Neural Network (GNN) models can effectively leverage both types of information. Conceptually, the representational information provides guidance for the model to construct better node features; while the correlational information indicates the correlation between node outcomes conditional on node features. Through a simulation study, we find that many popular GNN models are incapable of effectively utilizing the correlational information. By leveraging the idea of the copula, a principled way to describe the dependence among multivariate random variables, we offer a general solution. The proposed Copula Graph Neural Network (CopulaGNN) can take a wide range of GNN models as base models and utilize both representational and correlational information stored in the graphs. Experimental results on two types of regression tasks verify the effectiveness of the proposed method.",グラフ構造のデータはいたるところにあります。ただし、グラフはさまざまな種類の情報をエンコードするため、データ表現においてさまざまな役割を果たします。このホワイトペーパーでは、ノードレベルの予測タスクでグラフが果たす表現的役割と相関的役割を区別し、グラフニューラルネットワーク（GNN）モデルが両方のタイプの情報を効果的に活用する方法を調査します。概念的には、表現情報は、モデルがより優れたノード機能を構築するためのガイダンスを提供します。一方、相関情報は、ノードの機能を条件とするノードの結果間の相関を示します。シミュレーション研究を通じて、多くの人気のあるGNNモデルが相関情報を効果的に利用できないことがわかりました。多変量確率変数間の依存関係を記述する原理的な方法であるコピュラのアイデアを活用することにより、一般的なソリューションを提供します。提案されたコピュラグラフニューラルネットワーク（CopulaGNN）は、ベースモデルとして幅広いGNNモデルを採用し、グラフに格納された表現情報と相関情報の両方を利用できます。 2種類の回帰タスクの実験結果は、提案された方法の有効性を検証します。,6.5,https://d3i71xaburhd42.cloudfront.net/7e2cffd6341939869a3e48c78e06c738d18f7d60/4-Figure1-1.png
A Discriminative Gaussian Mixture Model with Sparsity,"['Hideaki Hayashi', 'Seiichi Uchida']",https://openreview.net/forum?id=-_Zp7r2-cGK,"In probabilistic classification, a discriminative model based on the softmax function has a potential limitation in that it assumes unimodality for each class in the feature space. The mixture model can address this issue, although it leads to an increase in the number of parameters. We propose a sparse classifier based on a discriminative GMM, referred to as a sparse discriminative Gaussian mixture (SDGM). In the SDGM, a GMM-based discriminative model is trained via sparse Bayesian learning. Using this sparse learning framework, we can simultaneously remove redundant Gaussian components and reduce the number of parameters used in the remaining components during learning; this learning method reduces the model complexity, thereby improving the generalization capability. Furthermore, the SDGM can be embedded into neural networks (NNs), such as convolutional NNs, and can be trained in an end-to-end manner. Experimental results demonstrated that the proposed method outperformed the existing softmax-based discriminative models.",確率的分類では、ソフトマックス関数に基づく識別モデルには、特徴空間内の各クラスの単峰性を想定するという潜在的な制限があります。混合モデルは、パラメーターの数の増加につながりますが、この問題に対処できます。スパース識別ガウス混合（SDGM）と呼ばれる、識別GMMに基づくスパース分類器を提案します。 SDGMでは、GMMベースの識別モデルがスパースベイズ学習を介してトレーニングされます。このスパース学習フレームワークを使用すると、冗長なガウスコンポーネントを同時に削除し、学習中に残りのコンポーネントで使用されるパラメーターの数を減らすことができます。この学習方法により、モデルの複雑さが軽減され、一般化機能が向上します。さらに、SDGMは、畳み込みNNなどのニューラルネットワーク（NN）に組み込むことができ、エンドツーエンドの方法でトレーニングできます。実験結果は、提案された方法が既存のソフトマックスベースの識別モデルよりも優れていることを示した。,6.5,
Tilted Empirical Risk Minimization,"['Tian Li', 'Ahmad Beirami', 'Maziar Sanjabi', 'Virginia Smith']",https://openreview.net/forum?id=K5YasWXZT3O,"Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.",経験的リスク最小化（ERM）は通常、平均損失でうまく機能するように設計されており、外れ値に敏感な推定量、一般化が不十分、またはサブグループを不当に扱う可能性があります。多くの方法がこれらの問題に個別に対処することを目的としていますが、この作業では、統一されたフレームワーク傾斜の経験的リスク最小化（TERM）を通じてそれらを調査します。特に、傾斜と呼ばれるハイパーパラメータを使用してERMを直接拡張することにより、個々の損失の影響を柔軟に調整できることを示します。結果として得られるフレームワークのいくつかの解釈を提供します。TERMが外れ値の影響をそれぞれ増加または減少させて、公平性または堅牢性を実現できることを示します。一般化に役立つ分散減少特性があります。そして、超量子法の滑らかな近似と見なすことができます。 TERMを解くためのバッチ的で確率的な一次最適化手法を開発し、一般的な代替案と比較して問題を効率的に解くことができることを示します。最後に、TERMは、サブグループ間の公平性の強化、外れ値の影響の軽減、クラスの不均衡の処理など、多数のアプリケーションに使用できることを示します。 TERMは、これらの個々の問題に合わせて調整された既存のソリューションと競合するだけでなく、外れ値への対処と公平性の促進など、まったく新しいアプリケーションを可能にすることもできます。,6.5,https://d3i71xaburhd42.cloudfront.net/1f6de95137e96872274eedae1beb1bd55f03c57a/2-Figure1-1.png
Primal Wasserstein Imitation Learning,"['Robert Dadashi', 'Leonard Hussenot', 'Matthieu Geist', 'Olivier Pietquin']",https://openreview.net/forum?id=TtYSU29zgR,"Imitation Learning (IL) methods seek to match the behavior of an agent with that of an expert. In the present work, we propose a new IL method based on a conceptually simple algorithm: Primal Wasserstein Imitation Learning (PWIL), which ties to the primal form of the Wasserstein distance between the expert and the agent state-action distributions. We present a reward function which is derived offline, as opposed to recent adversarial IL algorithms that learn a reward function through interactions with the environment, and which requires little fine-tuning. We show that we can recover expert behavior on a variety of continuous control tasks (beyond locomotion) of the MuJoCo domain in a sample efficient manner in terms of agent interactions and of expert interactions with the environment. Finally, we show that the behavior of the agent we train matches the behavior of the expert with the Wasserstein distance, rather than the commonly used proxy of performance.",模倣学習（IL）メソッドは、エージェントの動作を専門家の動作と一致させようとします。本研究では、概念的に単純なアルゴリズムに基づく新しいILメソッドを提案します。PrimalWassersteinImitationLearning（PWIL）は、エキスパートとエージェントの状態アクション分布の間のワッサースタイン距離の主要な形式に関連付けられます。環境との相互作用を通じて報酬関数を学習し、微調整をほとんど必要としない最近の敵対的なILアルゴリズムとは対照的に、オフラインで導出される報酬関数を提示します。エージェントの相互作用および環境との専門家の相互作用の観点から、サンプル効率的な方法で、MuJoCoドメインのさまざまな継続的な制御タスク（移動を超えて）で専門家の行動を回復できることを示します。最後に、トレーニングするエージェントの動作が、一般的に使用されるパフォーマンスのプロキシではなく、エキスパートの動作とワッサースタイン距離と一致することを示します。,6.5,https://d3i71xaburhd42.cloudfront.net/25287b593d2642b1627b96a79c5ff8d3c8ec1f5c/4-Figure1-1.png
MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning,"['Nanyi Fei', 'Zhiwu Lu', 'Tao Xiang', 'Songfang Huang']",https://openreview.net/forum?id=D3PcGLdMx0,"Most recent few-shot learning (FSL) approaches are based on episodic training whereby each episode samples few training instances (shots) per class to imitate the test condition. However, this strict adhering to test condition has a negative side effect, that is, the trained model is susceptible to the poor sampling of few shots. In this work, for the first time, this problem is addressed by exploiting inter-episode relationships. Specifically, a novel meta-learning via modeling episode-level relationships (MELR) framework is proposed. By sampling two episodes containing the same set of classes for meta-training, MELR is designed to ensure that the meta-learned model is robust against the presence of poorly-sampled shots in the meta-test stage. This is achieved through two key components: (1) a Cross-Episode Attention Module (CEAM) to improve the ability of alleviating the effects of poorly-sampled shots, and (2) a Cross-Episode Consistency Regularization (CECR) to enforce that the two classifiers learned from the two episodes are consistent even when there are unrepresentative instances. Extensive experiments for non-transductive standard FSL on two benchmarks show that our MELR achieves 1.0%-5.0% improvements over the baseline (i.e., ProtoNet) used for FSL in our model and outperforms the latest competitors under the same settings.",最新の数ショット学習（FSL）アプローチは、エピソードトレーニングに基づいており、各エピソードは、テスト条件を模倣するために、クラスごとにいくつかのトレーニングインスタンス（ショット）をサンプリングします。ただし、この厳密なテスト条件の順守にはマイナスの副作用があります。つまり、トレーニングされたモデルは、数ショットのサンプリングが不十分になりやすいということです。この作業では、初めて、この問題はエピソード間の関係を利用することによって対処されます。具体的には、エピソードレベルの関係（MELR）フレームワークのモデリングによる新しいメタ学習が提案されています。 MELRは、メタトレーニング用に同じクラスのセットを含む2つのエピソードをサンプリングすることにより、メタテスト段階でのサンプリングが不十分なショットの存在に対してメタ学習モデルが堅牢であることを保証するように設計されています。これは、2つの主要なコンポーネントによって実現されます。（1）不十分にサンプリングされたショットの影響を軽減する能力を向上させるクロスエピソードアテンションモジュール（CEAM）、および（2）それを実施するクロスエピソード整合性正則化（CECR） 2つのエピソードから学習した2つの分類子は、代表的でないインスタンスがある場合でも一貫しています。 2つのベンチマークでの非トランスダクティブ標準FSLの広範な実験は、MELRが1.0を達成することを示しています,6.5,
MoPro: Webly Supervised Learning with Momentum Prototypes,"['Junnan Li', 'Caiming Xiong', 'Steven Hoi']",https://openreview.net/forum?id=0-EYBhgw80y,"We propose a webly-supervised representation learning method that does not suffer from the annotation unscalability of supervised learning, nor the computation unscalability of self-supervised learning. Most existing works on webly-supervised representation learning adopt a vanilla supervised learning method without accounting for the prevalent noise in the training data, whereas most prior methods in learning with label noise are less effective for real-world large-scale noisy data. We propose momentum prototypes (MoPro), a simple contrastive learning method that achieves online label noise correction, out-of-distribution sample removal, and representation learning. MoPro achieves state-of-the-art performance on WebVision, a weakly-labeled noisy dataset. MoPro also shows superior performance when the pretrained model is transferred to down-stream image classification and detection tasks. It outperforms the ImageNet supervised pretrained model by +10.5 on 1-shot classification on VOC, and outperforms the best self-supervised pretrained model by +17.3 when finetuned on 1% of ImageNet labeled samples. Furthermore, MoPro is more robust to distribution shifts. ",教師あり学習の注釈の非スケーリング性や、自己教師あり学習の計算の非スケーリング性に悩まされない、ウェブで監視された表現学習方法を提案します。ウェブ上で監視された表現学習に関する既存のほとんどの研究は、トレーニングデータの一般的なノイズを考慮せずに、バニラ教師あり学習方法を採用していますが、ラベルノイズを使用した学習のほとんどの従来の方法は、実際の大規模なノイズの多いデータにはあまり効果的ではありません。運動量プロトタイプ（MoPro）を提案します。これは、オンラインラベルノイズ補正、分布外サンプル除去、および表現学習を実現する単純な対照学習方法です。 MoProは、弱くラベル付けされたノイズの多いデータセットであるWebVisionで最先端のパフォーマンスを実現します。 MoProは、事前トレーニングされたモデルがダウンストリームの画像分類および検出タスクに転送されるときにも優れたパフォーマンスを示します。これは、VOCでの1ショット分類でImageNet教師あり事前トレーニングモデルを+10.5だけ上回り、1で微調整すると、最高の自己教師あり事前トレーニングモデルを+17.3上回ります。,6.5,https://d3i71xaburhd42.cloudfront.net/1cb29798801b315d6287aae1093f5432f54673dc/2-Figure1-1.png
Overfitting for Fun and Profit: Instance-Adaptive Data Compression,"['Ties van Rozendaal', 'Iris AM Huijben', 'Taco Cohen']",https://openreview.net/forum?id=oFp8Mx_V5FL,"Neural data compression has been shown to outperform classical methods in terms of $RD$ performance, with results still improving rapidly.
At a high level, neural compression is based on an autoencoder that tries to reconstruct the input instance from a (quantized) latent representation, coupled with a prior that is used to losslessly compress these latents.
Due to limitations on model capacity and imperfect optimization and generalization, such models will suboptimally compress test data in general.
However, one of the great strengths of learned compression is that if the test-time data distribution is known and relatively low-entropy (e.g. a camera watching a static scene, a dash cam in an autonomous car, etc.), the model can easily be finetuned or adapted to this distribution, leading to improved $RD$ performance.
In this paper we take this concept to the extreme, adapting the full model to a single video, and sending model updates (quantized and compressed using a parameter-space prior) along with the latent representation. Unlike previous work, we finetune not only the encoder/latents but the entire model, and - during finetuning - take into account both the effect of model quantization and the additional costs incurred by sending the model updates. We evaluate an image compression model on I-frames (sampled at 2 fps) from videos of the Xiph dataset, and demonstrate that full-model adaptation improves $RD$ performance by ~1 dB, with respect to encoder-only finetuning.",ニューラルデータの圧縮は、RDパフォーマンスの点で従来の方法よりも優れていることが示されていますが、結果は依然として急速に向上しています。高レベルでは、ニューラル圧縮は、（量子化された）潜在表現から入力インスタンスを再構築しようとするオートエンコーダに基づいており、これらの潜在を無損失で圧縮するために使用される事前表現と組み合わされています。モデルの容量に制限があり、最適化と一般化が不完全であるため、このようなモデルは一般にテストデータを最適に圧縮しません。ただし、学習された圧縮の大きな強みの1つは、テスト時間のデータ分布が既知であり、エントロピーが比較的低い場合（たとえば、静止シーンを監視するカメラ、自動運転車のダッシュカムなど）、モデルは次のことができることです。この分布に簡単に微調整または適合させることができるため、RDのパフォーマンスが向上します。このホワイトペーパーでは、この概念を極限まで追求し、モデル全体を単一のビデオに適合させ、潜在的な表現とともにモデルの更新（事前のパラメーター空間を使用して量子化および圧縮）を送信します。以前の作業とは異なり、エンコーダー/レイテンシーだけでなくモデル全体を微調整し、微調整中に、モデルの量子化の影響と、モデルの更新を送信することによって発生する追加コストの両方を考慮に入れます。 XiphデータセットのビデオからIフレーム（2 fpsでサンプリング）の画像圧縮モデルを評価し、エンコーダーのみの微調整に関して、フルモデルの適応によりRDパフォーマンスが1dB向上することを示します。,6.5,
Towards Understanding and Improving Dropout in Game Theory,"['Hao Zhang', 'Sen Li', 'YinChao Ma', 'Mingjie Li', 'Yichen Xie', 'Quanshi Zhang']",https://openreview.net/forum?id=Jacdvfjicf7,"This paper aims to understand and improve the utility of the dropout operation from the perspective of game-theoretical interactions. We prove that dropout can suppress the strength of interactions between input variables of deep neural networks (DNNs). The theoretical proof is also verified by various experiments. Furthermore, we find that such interactions were strongly related to the over-fitting problem in deep learning. So, the utility of dropout can be regarded as decreasing interactions to alleviating the significance of over-fitting. Based on this understanding, we propose the interaction loss to further improve the utility of dropout. Experimental results on various DNNs and datasets have shown that the interaction loss can effectively improve the utility of dropout and boost the performance of DNNs.",この論文は、ゲーム理論的相互作用の観点から、ドロップアウト操作の有用性を理解し、改善することを目的としています。ドロップアウトがディープニューラルネットワーク（DNN）の入力変数間の相互作用の強さを抑制できることを証明します。理論的な証明は、さまざまな実験によっても検証されます。さらに、そのような相互作用は、深層学習における過剰適合問題と強く関連していることがわかります。したがって、ドロップアウトの有用性は、過剰適合の重要性を軽減するための相互作用を減らすと見なすことができます。この理解に基づいて、ドロップアウトの効用をさらに改善するための相互作用損失を提案します。さまざまなDNNおよびデータセットでの実験結果は、相互作用の損失がドロップアウトの有用性を効果的に改善し、DNNのパフォーマンスを向上させることができることを示しています。,6.5,
Graph Coarsening with Neural Networks,"['Chen Cai', 'Dingkang Wang', 'Yusu Wang']",https://openreview.net/forum?id=uxpzitPEooJ,"As large scale-graphs become increasingly more prevalent, it poses significant computational challenges to process, extract and analyze large graph data. Graph coarsening is one popular technique to reduce the size of a graph while maintaining essential properties. Despite rich graph coarsening literature, there is only limited exploration of data-driven method in the field. In this work, we leverage the recent progress of deep learning on graphs for graph coarsening. We first propose a framework for measuring the quality of coarsening algorithm and show that depending on the goal, we need to carefully choose the Laplace operator on the coarse graph and associated projection/lift operators. Motivated by the observation that the current choice of edge weight for the coarse graph may be sub-optimal, we parametrize the weight assignment map with graph neural networks and train it to improve the coarsening quality in an unsupervised way. Through extensive experiments on both synthetic and real networks, we demonstrate that our method significantly improves common graph coarsening methods under various metrics, reduction ratios, graph sizes, and graph types. It generalizes to graphs of larger size (more than $25\times$ of training graphs), adaptive to different losses (both differentiable and non-differentiable), and scales to much larger graphs than previous work.",大規模なグラフがますます普及するにつれて、大規模なグラフデータを処理、抽出、分析するための計算上の大きな課題が発生します。グラフの粗大化は、重要なプロパティを維持しながらグラフのサイズを縮小するための一般的な手法の1つです。豊富なグラフ粗大化の文献にもかかわらず、この分野でのデータ駆動型手法の調査は限られています。この作業では、グラフの粗大化のためにグラフの深層学習の最近の進歩を活用します。最初に、粗大化アルゴリズムの品質を測定するためのフレームワークを提案し、目標に応じて、粗いグラフ上のラプラス演算子と関連する投影/リフト演算子を慎重に選択する必要があることを示します。粗いグラフのエッジ重みの現在の選択が最適ではない可能性があるという観察に動機付けられて、グラフニューラルネットワークを使用して重み割り当てマップをパラメーター化し、教師なしの方法で粗大化の品質を改善するようにトレーニングします。合成ネットワークと実際のネットワークの両方での広範な実験を通じて、私たちの方法が、さまざまなメトリック、縮小率、グラフサイズ、およびグラフタイプの下で一般的なグラフ粗大化方法を大幅に改善することを示します。これは、より大きなサイズのグラフ（25を超えるトレーニンググラフ）に一般化され、さまざまな損失（微分可能と微分不可能の両方）に適応し、以前の作業よりもはるかに大きなグラフにスケーリングします。,6.5,
TropEx: An Algorithm for Extracting Linear Terms in Deep Neural Networks,"['Martin Trimmel', 'Henning Petzka', 'Cristian Sminchisescu']",https://openreview.net/forum?id=IqtonxWI0V3,"Deep neural networks with rectified linear (ReLU) activations are piecewise linear functions, where hyperplanes partition the input space into an astronomically high number of linear regions. Previous work focused on counting linear regions to measure the network's expressive power and on analyzing geometric properties of the hyperplane configurations. In contrast, we aim to understand the impact of the linear terms on network performance, by examining the information encoded in their coefficients. To this end, we derive TropEx, a nontrivial tropical algebra-inspired algorithm to systematically extract linear terms based on data. Applied to convolutional and fully-connected networks, our algorithm uncovers significant differences in how the different networks utilize linear regions for generalization. This underlines the importance of systematic linear term exploration, to better understand generalization in neural networks trained with complex data sets.",正規化線形（ReLU）アクティベーションを使用したディープニューラルネットワークは区分的線形関数であり、超平面が入力空間を天文学的に多数の線形領域に分割します。以前の作業は、ネットワークの表現力を測定するための線形領域のカウントと、超平面構成の幾何学的特性の分析に焦点を当てていました。対照的に、係数にエンコードされた情報を調べることにより、線形項がネットワークパフォーマンスに与える影響を理解することを目指しています。この目的のために、データに基づいて線形項を体系的に抽出する、自明ではない熱帯代数に着想を得たアルゴリズムであるTropExを導出します。畳み込みネットワークと完全に接続されたネットワークに適用されると、私たちのアルゴリズムは、さまざまなネットワークが一般化のために線形領域を利用する方法の大きな違いを明らかにします。これは、複雑なデータセットでトレーニングされたニューラルネットワークの一般化をよりよく理解するために、体系的な線形項探索の重要性を強調しています。,6.5,
Byzantine-Resilient Non-Convex Stochastic Gradient Descent,"['Dan Alistarh', 'Zeyuan Allen-Zhu', 'Faeze Ebrahimianghazani', 'Jerry Li']",https://openreview.net/forum?id=PbEHqvFtcS,"We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. Our algorithm is practical: it improves upon the performance of prior methods when training deep neural networks, it is relatively lightweight, and is the first method to withstand two recently-proposed Byzantine attacks. ",m台のマシンが独立して確率的勾配を計算し、それらのローカル目的関数を共同で最適化するために協力できる、敵対者に強い確率的分散最適化を研究します。ただし、マシンの一部はビザンチンであり、任意の敵対的な方法で動作する可能性があります。困難な非凸の場合には、この手順の変形を検討します。私たちの主な結果は、新しいアルゴリズムSafeguardSGDです。これは、鞍点を確実に回避し、非凸対物レンズのおおよその極小値を見つけることができます。アルゴリズムは新しい濃度フィルタリング手法に基づいており、そのサンプルと時間計算量の境界は、ビザンチンマシンが存在しない場合の確率的分散設定で最もよく知られている理論的境界と一致します。私たちのアルゴリズムは実用的です。ディープニューラルネットワークをトレーニングするときに以前の方法のパフォーマンスを改善し、比較的軽量で、最近提案された2つのビザンチン攻撃に耐える最初の方法です。,6.5,
A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima,"['Zeke Xie', 'Issei Sato', 'Masashi Sugiyama']",https://openreview.net/forum?id=wXgk_iCiYGo,"Stochastic Gradient Descent (SGD) and its variants are mainstream methods for training deep networks in practice. SGD is known to find a flat minimum that often generalizes well. However, it is mathematically unclear how deep learning can select a flat minimum among so many minima. To answer the question quantitatively, we develop a density diffusion theory (DDT) to reveal how minima selection quantitatively depends on the minima sharpness and the hyperparameters. To the best of our knowledge, we are the first to theoretically and empirically prove that, benefited from the Hessian-dependent covariance of stochastic gradient noise, SGD favors flat minima exponentially more than sharp minima, while Gradient Descent (GD) with injected white noise favors flat minima only polynomially more than sharp minima. We also reveal that either a small learning rate or large-batch training requires exponentially many iterations to escape from minima in terms of the ratio of the batch size and learning rate. Thus, large-batch training cannot search flat minima efficiently in a realistic computational time.",確率的勾配降下法（SGD）とその変形は、実際にディープネットワークをトレーニングするための主流の方法です。 SGDは、よく一般化されるフラットな最小値を見つけることが知られています。ただし、ディープラーニングが非常に多くの最小値の中からフラットな最小値を選択する方法は数学的に不明です。質問に定量的に答えるために、密度拡散理論（DDT）を開発して、最小値の選択が最小値のシャープネスとハイパーパラメーターにどのように定量的に依存するかを明らかにします。私たちの知る限り、確率的勾配降下法のヘッセ依存共分散の恩恵を受けて、SGDは鋭い最小値よりも指数関数的に平坦な最小値を優先し、勾配降下法（GD）はホワイトノイズが注入されていることを理論的および経験的に証明した最初の人です。シャープな最小値よりも、ポリノミアル的にのみフラットな最小値を優先します。また、小さな学習率または大規模なバッチトレーニングのいずれかでは、バッチサイズと学習率の比率の観点から最小値から逃れるために指数関数的に多くの反復が必要であることも明らかにします。したがって、大規模なバッチトレーニングでは、現実的な計算時間でフラットな最小値を効率的に検索することはできません。,6.5,
GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing,"['Tao Yu', 'Chien-Sheng Wu', 'Xi Victoria Lin', 'bailin wang', 'Yi Chern Tan', 'Xinyi Yang', 'Dragomir Radev', 'richard socher', 'Caiming Xiong']",https://openreview.net/forum?id=kyaIeYj4zZ,"We present GraPPa, an effective pre-training approach for table semantic parsing that learns a compositional inductive bias in the joint representations of textual and tabular data. We construct synthetic question-SQL pairs over high-quality tables via a synchronous context-free grammar (SCFG). We pre-train our model on the synthetic data to inject important structural properties commonly found in semantic parsing into the pre-training language model. To maintain the model's ability to represent real-world data, we also include masked language modeling (MLM) on several existing table-related datasets to regularize our pre-training process.  Our proposed pre-training strategy is much data-efficient. When incorporated with strong base semantic parsers, GraPPa achieves new state-of-the-art results on four popular fully supervised and weakly supervised table semantic parsing tasks.",GraPPaを紹介します。これは、テキストデータと表データの共同表現における構成的誘導バイアスを学習するテーブルセマンティック解析の効果的な事前トレーニングアプローチです。同期文脈自由文法（SCFG）を介して、高品質のテーブル上に合成の質問とSQLのペアを構築します。合成データでモデルを事前トレーニングして、セマンティック解析で一般的に見られる重要な構造プロパティを事前トレーニング言語モデルに注入します。実世界のデータを表すモデルの機能を維持するために、いくつかの既存のテーブル関連データセットにマスク言語モデリング（MLM）を含めて、事前トレーニングプロセスを正規化します。提案されている事前トレーニング戦略は、データ効率が非常に高くなっています。強塩基セマンティックパーサーと統合すると、GraPPaは、4つの一般的な完全監視および弱監視テーブルセマンティック解析タスクで新しい最先端の結果を実現します。,6.5,
Knowledge Distillation as Semiparametric Inference,"['Tri Dao', 'Govinda M Kamath', 'Vasilis Syrgkanis', 'Lester Mackey']",https://openreview.net/forum?id=m4UCf24r0Y,"A popular approach to model compression is to train an inexpensive student model to mimic the class probabilities of a highly accurate but cumbersome teacher model. Surprisingly, this two-step knowledge distillation process often leads to higher accuracy than training the student directly on labeled data. To explain and enhance this phenomenon, we cast knowledge distillation as a semiparametric inference problem with the optimal student model as the target, the unknown Bayes class probabilities as nuisance, and the teacher probabilities as a plug-in nuisance estimate. By adapting modern semiparametric tools, we derive several new guarantees for the prediction error of standard distillation and develop several enhancements with improved guarantees. We validate our findings empirically on both tabular data and image data and observe consistent improvements from our knowledge distillation enhancements.
",モデル圧縮の一般的なアプローチは、安価な学生モデルをトレーニングして、非常に正確で面倒な教師モデルのクラス確率を模倣することです。驚いたことに、この2段階の知識蒸留プロセスは、ラベル付けされたデータで直接学生をトレーニングするよりも高い精度につながることがよくあります。この現象を説明および強化するために、最適な学生モデルをターゲットとして、未知のベイズクラスの確率を迷惑として、教師の確率をプラグインの迷惑推定として、知識蒸留をセミパラメトリック推論問題としてキャストします。最新のセミパラメトリックツールを採用することにより、標準蒸留の予測誤差に対するいくつかの新しい保証を導き出し、保証を改善したいくつかの機能強化を開発します。表形式のデータと画像データの両方で経験的に調査結果を検証し、知識蒸留の強化による一貫した改善を観察します。,6.5,
Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning,"['Aviral Kumar', 'Rishabh Agarwal', 'Dibya Ghosh', 'Sergey Levine']",https://openreview.net/forum?id=O9bnihsFfXU,"We identify a fundamental implicit under-parameterization phenomenon in value-based deep RL methods that use bootstrapping: when value functions, approximated using deep neural networks, are trained with gradient descent using iterated regression onto target values generated by previous instances of the value network, more gradient updates decrease the expressivity of the current value network. We characterize this loss of expressivity via a rank collapse of the learned value network features and show that it corresponds to a drop in performance. We demonstrate this phenomenon on popular domains including Atari and Gym benchmarks and in both offline and online RL settings. We formally analyze this phenomenon and show that it results from a pathological interaction between bootstrapping and gradient-based optimization. Finally, we show that mitigating implicit under- parameterization by controlling rank collapse improves performance.",ブートストラッピングを使用する値ベースのディープRLメソッドで、基本的な暗黙のパラメーター不足現象を特定します。ディープニューラルネットワークを使用して近似された値関数が、値ネットワークの以前のインスタンスによって生成されたターゲット値への反復回帰を使用して勾配降下法でトレーニングされる場合、勾配の更新が増えると、現在の値のネットワークの表現力が低下します。学習価値ネットワーク機能のランク崩壊を介してこの表現力の喪失を特徴づけ、それがパフォーマンスの低下に対応することを示します。この現象は、AtariやGymのベンチマークなどの一般的なドメイン、およびオフラインとオンラインの両方のRL設定で示されます。この現象を正式に分析し、ブートストラップと勾配ベースの最適化の間の病理学的相互作用に起因することを示します。最後に、ランクの崩壊を制御することによって暗黙的なパラメーター不足を軽減すると、パフォーマンスが向上することを示します。,6.5,
On the Universality of the Double Descent Peak in Ridgeless Regression,['David Holzmüller'],https://openreview.net/forum?id=0IO5VdnSAaH,"We prove a non-asymptotic distribution-independent lower bound for the expected mean squared generalization error caused by label noise in ridgeless linear regression. Our lower bound generalizes a similar known result to the overparameterized (interpolating) regime. In contrast to most previous works, our analysis applies to a broad class of input distributions with almost surely full-rank feature matrices, which allows us to cover various types of deterministic or random feature maps. Our lower bound is asymptotically sharp and implies that in the presence of label noise, ridgeless linear regression does not perform well around the interpolation threshold for any of these feature maps. We analyze the imposed assumptions in detail and provide a theory for analytic (random) feature maps. Using this theory, we can show that our assumptions are satisfied for input distributions with a (Lebesgue) density and feature maps given by random deep neural networks with analytic activation functions like sigmoid, tanh, softplus or GELU. As further examples, we show that feature maps from random Fourier features and polynomial kernels also satisfy our assumptions. We complement our theory with further experimental and analytic results.",リッジレス線形回帰のラベルノイズによって引き起こされる予想される平均二乗汎化誤差の非漸近分布に依存しない下限を証明します。私たちの下限は、パラメータが過剰な（補間）レジームと同様の既知の結果を一般化します。以前のほとんどの作品とは対照的に、私たちの分析は、ほぼ確実にフルランクの特徴行列を持つ幅広いクラスの入力分布に適用されます。これにより、さまざまなタイプの決定論的またはランダムな特徴マップをカバーできます。私たちの下限は漸近的に鋭く、ラベルノイズが存在する場合、リッジレス線形回帰はこれらの特徴マップのいずれの補間しきい値付近でもうまく機能しないことを意味します。課せられた仮定を詳細に分析し、分析（ランダム）特徴マップの理論を提供します。この理論を使用して、（ルベーグ）密度の入力分布と、シグモイド、タン、ソフトプラス、GELUなどの分析的活性化関数を使用したランダムディープニューラルネットワークによって与えられる特徴マップについて、仮定が満たされていることを示すことができます。さらなる例として、ランダムフーリエ特徴と多項式カーネルからの特徴マップも私たちの仮定を満たしていることを示します。理論をさらに実験的および分析的な結果で補完します。,6.5,
Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning,"['Rishabh Agarwal', 'Marlos C. Machado', 'Pablo Samuel Castro', 'Marc G Bellemare']",https://openreview.net/forum?id=qda7-sVg84,"Reinforcement learning methods trained on few environments rarely learn policies that generalize to unseen environments. To improve generalization, we incorporate the inherent sequential structure in reinforcement learning into the representation learning process. This approach is orthogonal to recent approaches, which rarely exploit this structure explicitly. Specifically, we introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. We also present a contrastive representation learning procedure to embed any state similarity metric, which we instantiate with PSM to obtain policy similarity embeddings (PSEs). We demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite.",いくつかの環境でトレーニングされた強化学習方法は、目に見えない環境に一般化するポリシーを学習することはめったにありません。一般化を改善するために、強化学習に固有の順次構造を表現学習プロセスに組み込みます。このアプローチは、この構造を明示的に利用することはめったにない最近のアプローチと直交しています。具体的には、状態間の行動の類似性を測定するための理論的に動機付けられたポリシー類似性メトリック（PSM）を紹介します。 PSMは、これらの州と将来の州の最適なポリシーが類似している州に高い類似性を割り当てます。また、PSMを使用してインスタンス化してポリシー類似性埋め込み（PSE）を取得する、状態類似性メトリックを埋め込むための対照表現学習手順も示します。 PSEが、疑似相関を伴うLQR、ピクセルからのジャンプタスク、Distracting DM Control Suiteなど、さまざまなベンチマークの一般化を改善することを示します。,6.5,https://d3i71xaburhd42.cloudfront.net/7428f65393c19a6ca6381693767cb4f643a49a5c/1-Figure1-1.png
DARTS-: Robustly Stepping out of Performance Collapse Without Indicators,"['Xiangxiang Chu', 'Xiaoxing Wang', 'Bo Zhang', 'Shun Lu', 'Xiaolin Wei', 'Junchi Yan']",https://openreview.net/forum?id=KLH36ELmwIB,"Despite the fast development of differentiable architecture search (DARTS), it suffers from a standing instability issue regarding searching performance, which extremely limits its application. Existing robustifying methods draw clues from the outcome instead of finding out the causing factor. Various indicators such as Hessian eigenvalues are proposed as a signal of performance collapse, and the searching should be stopped once an indicator reaches a preset threshold.
However, these methods tend to easily reject good architectures if thresholds are inappropriately set, let alone the searching is intrinsically noisy. In this paper, we undertake a more subtle and direct approach to resolve the collapse. 
We first demonstrate that skip connections with a learnable architectural coefficient can easily recover from a disadvantageous state and become dominant.  We conjecture that skip connections profit too much from this privilege, hence causing the collapse for the derived model. Therefore, we propose to factor out this benefit with an auxiliary skip connection, ensuring a fairer competition for all operations. Extensive experiments on various datasets verify that our approach can substantially improve the robustness of DARTS. Our code is available at https://github.com/Meituan-AutoML/DARTS-",微分可能アーキテクチャ検索（DARTS）の急速な発展にもかかわらず、検索パフォーマンスに関する永続的な不安定性の問題に悩まされており、そのアプリケーションが極端に制限されています。既存のロバスト化方法は、原因となる要因を見つけるのではなく、結果から手がかりを引き出します。パフォーマンス崩壊のシグナルとして、ヘッセ固有値などのさまざまなインジケーターが提案されています。インジケーターが事前設定されたしきい値に達したら、検索を停止する必要があります。ただし、これらの方法は、しきい値が不適切に設定されている場合、検索が本質的にノイズが多いことは言うまでもなく、優れたアーキテクチャを簡単に拒否する傾向があります。このホワイトペーパーでは、崩壊を解決するために、より微妙で直接的なアプローチを採用しています。最初に、学習可能なアーキテクチャ係数を使用したスキップ接続が、不利な状態から簡単に回復し、支配的になる可能性があることを示します。スキップ接続はこの特権からあまりにも多くの利益を得るので、派生モデルの崩壊を引き起こすと推測します。したがって、補助スキップ接続を使用してこの利点を考慮に入れ、すべての操作でより公平な競争を確保することを提案します。さまざまなデータセットでの広範な実験により、私たちのアプローチがDARTSの堅牢性を大幅に向上できることが確認されています。私たちのコードはhttps://github.com/Meituan-AutoML/DARTS-で入手できます。,6.5,https://d3i71xaburhd42.cloudfront.net/10daddaa1e1ed27e88b08b1c124d800de865c5e3/2-Figure1-1.png
Adapting to Reward Progressivity via Spectral Reinforcement Learning,"['Michael Dann', 'John Thangarajah']",https://openreview.net/forum?id=dyjPVUc2KB,"In this paper we consider reinforcement learning tasks with progressive rewards; that is, tasks where the rewards tend to increase in magnitude over time. We hypothesise that this property may be problematic for value-based deep reinforcement learning agents, particularly if the agent must first succeed in relatively unrewarding regions of the task in order to reach more rewarding regions. To address this issue, we propose Spectral DQN, which decomposes the reward into frequencies such that the high frequencies only activate when large rewards are found. This allows the training loss to be balanced so that it gives more even weighting across small and large reward regions. In two domains with extreme reward progressivity, where standard value-based methods struggle significantly, Spectral DQN is able to make much farther progress. Moreover, when evaluated on a set of six standard Atari games that do not overtly favour the approach, Spectral DQN remains more than competitive: While it underperforms one of the benchmarks in a single game, it comfortably surpasses the benchmarks in three games. These results demonstrate that the approach is not overfit to its target problem, and suggest that Spectral DQN may have advantages beyond addressing reward progressivity.",この論文では、進歩的な報酬を伴う強化学習タスクについて考察します。つまり、報酬が時間の経過とともに大きくなる傾向があるタスクです。特に、エージェントがよりやりがいのある領域に到達するために、タスクの比較的やりがいのない領域で最初に成功する必要がある場合、このプロパティは価値ベースの深層強化学習エージェントにとって問題になる可能性があると仮定します。この問題に対処するために、スペクトルDQNを提案します。これは、報酬を周波数に分解して、大きな報酬が見つかった場合にのみ高周波数がアクティブになるようにします。これにより、トレーニングの損失のバランスをとることができるため、大小の報酬領域全体でより均等な重み付けが可能になります。標準的な価値ベースの方法が大幅に苦労している極端な報酬の進歩性を持つ2つのドメインでは、SpectralDQNははるかに進歩することができます。さらに、このアプローチをあからさまに支持しない6つの標準Atariゲームのセットで評価した場合、Spectral DQNは競争力を超えたままです。1つのゲームのベンチマークの1つを下回りますが、3つのゲームのベンチマークを快適に上回ります。これらの結果は、アプローチがそのターゲット問題に過剰適合していないことを示しており、SpectralDQNには報酬の進行性に対処する以上の利点がある可能性があることを示唆しています。,6.5,
Removing Undesirable Feature Contributions Using Out-of-Distribution Data,"['Saehyung Lee', 'Changhwa Park', 'Hyungyu Lee', 'Jihun Yi', 'Jonghyun Lee', 'Sungroh Yoon']",https://openreview.net/forum?id=eIHYL6fpbkA,"Several data augmentation methods deploy unlabeled-in-distribution (UID) data to bridge the gap between the training and inference of neural networks. However, these methods have clear limitations in terms of availability of UID data and dependence of algorithms on pseudo-labels. Herein, we propose a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. We show how to improve generalization theoretically using OOD data in each learning scenario and complement our theoretical analysis with experiments on CIFAR-10, CIFAR-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view. We also present the advantages of the proposed method through comparison with other data augmentation methods, which can be used in the absence of UID data. Furthermore, we demonstrate that the proposed method can further improve the existing state-of-the-art adversarial training.",いくつかのデータ拡張方法は、ニューラルネットワークのトレーニングと推論の間のギャップを埋めるために、ラベルなし配布（UID）データを展開します。ただし、これらの方法には、UIDデータの可用性と、アルゴリズムの疑似ラベルへの依存性に関して明確な制限があります。ここでは、上記の問題のない分布外（OOD）データを使用することにより、敵対的学習と標準学習の両方の一般化を改善するためのデータ拡張方法を提案します。各学習シナリオでOODデータを使用して理論的に一般化を改善する方法を示し、CIFAR-10、CIFAR-100、およびImageNetのサブセットでの実験で理論的分析を補完します。結果は、人間の観点からはほとんど相関がないように見える画像データ間でも、望ましくない特徴が共有されていることを示しています。また、UIDデータがない場合に使用できる他のデータ拡張方法との比較を通じて、提案された方法の利点を示します。さらに、提案された方法が既存の最先端の敵対的訓練をさらに改善できることを実証します。,6.5,https://d3i71xaburhd42.cloudfront.net/8abd079082a2b7fac9c689f459ccb813811ac7c1/8-Figure1-1.png
Efficient Certified Defenses Against Patch Attacks on Image Classifiers,"['Jan Hendrik Metzen', 'Maksym Yatsura']",https://openreview.net/forum?id=hr-3PMvDpil,"Adversarial patches pose a realistic threat model for physical world attacks on autonomous systems via their perception component. Autonomous systems in safety-critical domains such as automated driving should thus contain a fail-safe fallback component that combines certifiable robustness against patches with efficient inference while maintaining high performance on clean inputs. We propose BagCert, a novel combination of model architecture and certification procedure that allows efficient certification. We derive a loss that enables end-to-end optimization of certified robustness against patches of different sizes and locations. On CIFAR10, BagCert certifies 10.000 examples in 43 seconds on a single GPU and obtains 86% clean and 60% certified accuracy against 5x5 patches.",敵対的なパッチは、知覚コンポーネントを介した自律システムへの物理的な世界攻撃の現実的な脅威モデルをもたらします。したがって、自動運転などのセーフティクリティカルドメインの自律システムには、クリーンな入力で高いパフォーマンスを維持しながら、パッチに対する認証可能な堅牢性と効率的な推論を組み合わせたフェイルセーフフォールバックコンポーネントが含まれている必要があります。効率的な認証を可能にするモデルアーキテクチャと認証手順の新しい組み合わせであるBagCertを提案します。さまざまなサイズと場所のパッチに対する認定された堅牢性のエンドツーエンドの最適化を可能にする損失を導き出します。 CIFAR10では、BagCertは単一のGPUで43秒で10.000の例を認証し、86を取得します,6.5,
Conservative Safety Critics for Exploration,"['Homanga Bharadhwaj', 'Aviral Kumar', 'Nicholas Rhinehart', 'Sergey Levine', 'Florian Shkurti', 'Animesh Garg']",https://openreview.net/forum?id=iaO86DUuKi,"Safe exploration presents a major challenge in reinforcement learning (RL): when active data collection requires deploying partially trained policies, we must ensure that these policies avoid catastrophically unsafe regions, while still enabling trial and error learning. In this paper, we target the problem of safe exploration in RL, by learning a conservative safety estimate of environment states through a critic, and provably upper bound the likelihood of catastrophic failures at every training iteration. We theoretically characterize the tradeoff between safety and policy improvement, show that the safety constraints are satisfied with high probability during training, derive provable convergence guarantees for our approach which is no worse asymptotically then standard RL, and empirically demonstrate the efficacy of the proposed approach on a suite of challenging navigation, manipulation, and locomotion tasks. Our results demonstrate that the proposed approach can achieve competitive task performance, while incurring significantly lower catastrophic failure rates during training as compared to prior methods. Videos are at this URL https://sites.google.com/view/safe-exploration/",安全な探索は強化学習（RL）の大きな課題です。アクティブなデータ収集で部分的にトレーニングされたポリシーを展開する必要がある場合、試行錯誤の学習を可能にしながら、これらのポリシーが壊滅的に危険な領域を回避するようにする必要があります。この論文では、批評家を通じて環境状態の保守的な安全性の推定値を学習することにより、RLでの安全な探査の問題を対象とし、トレーニングの反復ごとに壊滅的な失敗の可能性を確実に上限とします。安全性とポリシー改善の間のトレードオフを理論的に特徴付け、トレーニング中に安全性制約が高い確率で満たされることを示し、標準RLよりも漸近的に悪化しないアプローチの証明可能な収束保証を導き出し、提案されたアプローチの有効性を実証的に実証します。やりがいのあるナビゲーション、操作、および移動タスクのスイート。私たちの結果は、提案されたアプローチが、以前の方法と比較して、トレーニング中に大幅に低い壊滅的な失敗率を被りながら、競争力のあるタスクパフォ​​ーマンスを達成できることを示しています。ビデオはこのURLにありますhttps://sites.google.com/view/safe-exploration/,6.5,https://d3i71xaburhd42.cloudfront.net/a334f9897a330abddf99cfec0b5a70f751e9497b/2-Figure1-1.png
Spatially Structured Recurrent Modules,"['Nasim Rahaman', 'Anirudh Goyal', 'Muhammad Waleed Gondal', 'Manuel Wuthrich', 'Stefan Bauer', 'Yash Sharma', 'Yoshua Bengio', 'Bernhard Schölkopf']",https://openreview.net/forum?id=5l9zj5G7vDY,"Capturing the structure of a data-generating process by means of appropriate inductive biases can help in learning models that generalise well and are robust to changes in the input distribution. While methods that harness spatial and temporal structures find broad application, recent work has demonstrated the potential of models that leverage sparse and modular structure using an ensemble of sparingly interacting modules. In this work, we take a step towards dynamic models that are capable of simultaneously exploiting both modular and spatiotemporal structures. To this end, we model the dynamical system as a collection of autonomous but sparsely interacting sub-systems that interact according to a learned topology which is informed by the spatial structure of the underlying system. This gives rise to a class of models that are well suited for capturing the dynamics of systems that only offer local views into their state, along with corresponding spatial locations of those views. On the tasks of video prediction from cropped frames and multi-agent world modelling from partial observations in the challenging Starcraft2 domain, we find our models to be more robust to the number of available views and better capable of generalisation to novel tasks without additional training than strong baselines that perform equally well or better on the training distribution. ",適切な誘導バイアスを使用してデータ生成プロセスの構造をキャプチャすると、一般化が進み、入力分布の変化に対してロバストなモデルの学習に役立ちます。空間的および時間的構造を利用する方法は幅広い用途がありますが、最近の研究では、相互作用の少ないモジュールのアンサンブルを使用して、スパースおよびモジュラー構造を活用するモデルの可能性が実証されています。この作業では、モジュラー構造と時空間構造の両方を同時に活用できる動的モデルに向けた一歩を踏み出します。この目的のために、動的システムを、基礎となるシステムの空間構造によって通知される学習されたトポロジに従って相互作用する、自律的であるがまばらに相互作用するサブシステムのコレクションとしてモデル化します。これにより、ローカルビューのみを状態に提供するシステムのダイナミクスを、それらのビューの対応する空間位置とともにキャプチャするのに適したモデルのクラスが作成されます。トリミングされたフレームからのビデオ予測と、挑戦的なStarcraft2ドメインでの部分的な観察からのマルチエージェント世界モデリングのタスクでは、モデルが利用可能なビューの数に対してより堅牢であり、追加のトレーニングなしで新しいタスクに一般化できることがわかります。トレーニング分布で同等またはそれ以上のパフォーマンスを発揮する強力なベースライン。,6.5,https://d3i71xaburhd42.cloudfront.net/ffcea46f57ef1f5f65686e2424976e1af8689e78/2-Figure1-1.png
Deciphering and Optimizing Multi-Task Learning: a Random Matrix Approach,"['Malik Tiomoko', 'Hafiz Tiomoko Ali', 'Romain Couillet']",https://openreview.net/forum?id=Cri3xz59ga,"This article provides theoretical insights into the inner workings of multi-task and transfer learning methods, by studying the tractable least-square support vector machine multi-task learning (LS-SVM MTL) method, in the limit of large ($p$) and numerous ($n$) data. By a random matrix analysis applied to a Gaussian mixture data model, the performance of MTL LS-SVM is shown to converge, as $n,p\to\infty$, to a deterministic limit involving simple (small-dimensional) statistics of the data.

We prove (i) that the standard MTL LS-SVM algorithm is in general strongly biased and may dramatically fail (to the point that individual single-task LS-SVMs may outperform the MTL approach, even for quite resembling tasks): our analysis provides a simple method to correct these biases, and that we reveal (ii) the sufficient statistics at play in the method, which can be efficiently estimated, even for quite small datasets. The latter result is exploited to automatically optimize the hyperparameters without resorting to any cross-validation procedure. 

Experiments on popular datasets demonstrate that our improved MTL LS-SVM method is computationally-efficient and outperforms sometimes much more elaborate state-of-the-art multi-task and transfer learning techniques.",この記事では、扱いやすい最小二乗サポートベクターマシンマルチタスク学習（LS-SVM MTL）法を、大規模（p）および多数の限界で研究することにより、マルチタスクおよび転移学習法の内部動作に関する理論的洞察を提供します。 （n）データ。ガウス混合データモデルに適用されるランダム行列分析により、MTL LS-SVMのパフォーマンスは、n、pとして、データの単純な（小次元）統計を含む決定論的限界に収束することが示されています。 （i）標準のMTL LS-SVMアルゴリズムは一般に強くバイアスされており、劇的に失敗する可能性があることを証明します（個々の単一タスクLS-SVMは、タスクに非常に似ている場合でも、MTLアプローチよりも優れている可能性があります）。これらのバイアスを修正するための簡単な方法であり、（ii）非常に小さなデータセットであっても、効率的に推定できる方法で十分な統計が行われていることを明らかにします。後者の結果は、相互検証手順に頼ることなく、ハイパーパラメータを自動的に最適化するために利用されます。人気のあるデータセットでの実験は、私たちの改良されたMTL LS-SVM法が計算効率が高く、時にははるかに精巧な最先端のマルチタスクおよび転移学習技術よりも優れていることを示しています。,6.5,
Fully Unsupervised Diversity Denoising with Convolutional Variational Autoencoders,"['Mangal Prakash', 'Alexander Krull', 'Florian Jug']",https://openreview.net/forum?id=agHLCOBM5jP,"Deep Learning based methods have emerged as the indisputable leaders for virtually all image restoration tasks. Especially in the domain of microscopy images, various content-aware image restoration (CARE) approaches are now used to improve the interpretability of acquired data. Naturally, there are limitations to what can be restored in corrupted images, and like for all inverse problems, many potential solutions exist, and one of them must be chosen. Here, we propose DivNoising, a denoising approach based on fully convolutional variational autoencoders (VAEs), overcoming the problem of having to choose a single solution by predicting a whole distribution of denoised images. First we introduce a principled way of formulating the unsupervised denoising problem within the VAE framework by explicitly incorporating imaging noise models into the decoder. Our approach is fully unsupervised, only requiring noisy images and a suitable description of the imaging noise distribution. We show that such a noise model can either be measured, bootstrapped from noisy data, or even co-learned during training. If desired, consensus predictions can be inferred from a set of DivNoising predictions, leading to competitive results with other unsupervised methods and, on occasion, even with the supervised state-of-the-art. DivNoising samples from the posterior enable a plethora of useful applications. We are (i) showing denoising results for 13 datasets, (ii) discussing how optical character recognition (OCR) applications can benefit from diverse predictions, and are (iii) demonstrating how instance cell segmentation improves when using diverse DivNoising predictions.",ディープラーニングベースの方法は、事実上すべての画像復元タスクの議論の余地のないリーダーとして浮上しています。特に顕微鏡画像の分野では、取得したデータの解釈可能性を向上させるために、さまざまなコンテンツ認識画像復元（CARE）アプローチが現在使用されています。当然、破損したイメージで復元できるものには制限があり、すべての逆問題と同様に、多くの潜在的な解決策が存在し、そのうちの1つを選択する必要があります。ここでは、完全畳み込み変分オートエンコーダー（VAE）に基づくノイズ除去アプローチであるDivNoisingを提案し、ノイズ除去された画像の分布全体を予測することで単一のソリューションを選択する必要があるという問題を克服します。最初に、イメージングノイズモデルをデコーダに明示的に組み込むことにより、VAEフレームワーク内で教師なしノイズ除去問題を定式化する原理的な方法を紹介します。私たちのアプローチは完全に監視されておらず、ノイズの多い画像とイメージングノイズ分布の適切な説明のみが必要です。このようなノイズモデルは、測定、ノイズの多いデータからのブートストラップ、またはトレーニング中に共同学習することができることを示しています。必要に応じて、一連のDivNoising予測からコンセンサス予測を推測できます。これにより、他の監視されていない方法や、場合によっては監視されている最先端の方法との競争力のある結果が得られます。後部からのDivNoisingサンプルは、多数の有用なアプリケーションを可能にします。 （i）13のデータセットのノイズ除去結果を示し、（ii）光学式文字認識（OCR）アプリケーションが多様な予測からどのように利益を得ることができるかについて説明し、（iii）多様なDivNoising予測を使用した場合にインスタンスセルのセグメンテーションがどのように改善されるかを示します。,6.5,
Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNNs,"['Jonathan Frankle', 'David J. Schwab', 'Ari S. Morcos']",https://openreview.net/forum?id=vYeQQ29Tbvx,"A wide variety of deep learning techniques from style transfer to multitask learning rely on training affine transformations of features. Most prominent among these is the popular feature normalization technique BatchNorm, which normalizes activations and then subsequently applies a learned affine transform. In this paper, we aim to understand the role and expressive power of affine parameters used to transform features in this way. To isolate the contribution of these parameters from that of the learned features they transform, we investigate the performance achieved when training only these parameters in BatchNorm and freezing all weights at their random initializations. Doing so leads to surprisingly high performance considering the significant limitations that this style of training imposes. For example, sufficiently deep ResNets reach 82% (CIFAR-10) and 32% (ImageNet, top-5) accuracy in this configuration, far higher than when training an equivalent number of randomly chosen parameters elsewhere in the network. BatchNorm achieves this performance in part by naturally learning to disable around a third of the random features. Not only do these results highlight the expressive power of affine parameters in deep learning, but - in a broader sense - they characterize the expressive power of neural networks constructed simply by shifting and rescaling random features.",スタイル転送からマルチタスク学習までの多種多様な深層学習手法は、機能のアフィン変換のトレーニングに依存しています。これらの中で最も顕著なのは、アクティベーションを正規化し、その後、学習したアフィン変換を適用する、人気のある機能正規化手法BatchNormです。この論文では、このように特徴を変換するために使用されるアフィンパラメータの役割と表現力を理解することを目的としています。これらのパラメーターの寄与を、それらが変換する学習済み機能の寄与から分離するために、BatchNormでこれらのパラメーターのみをトレーニングし、ランダムな初期化ですべての重みをフリーズしたときに達成されるパフォーマンスを調査します。そうすることで、このスタイルのトレーニングが課す重大な制限を考慮すると、驚くほど高いパフォーマンスが得られます。たとえば、十分に深いResNetは82に達します,6.5,https://d3i71xaburhd42.cloudfront.net/84ef2cf4f73bb4eae7ae63fbca04a4d774b75ac7/1-Figure1-1.png
In Defense of Pseudo-Labeling: An Uncertainty-Aware Pseudo-label Selection Framework for Semi-Supervised Learning,"['Mamshad Nayeem Rizve', 'Kevin Duarte', 'Yogesh S Rawat', 'Mubarak Shah']",https://openreview.net/forum?id=-ODN6SbiUU,"The recent research in semi-supervised learning (SSL) is mostly dominated by consistency regularization based methods which achieve strong performance. However, they heavily rely on domain-specific data augmentations, which are not easy to generate for all data modalities. Pseudo-labeling (PL) is a general SSL approach that does not have this constraint but performs relatively poorly in its original formulation. We argue that PL underperforms due to the erroneous high confidence predictions from poorly calibrated models; these predictions generate many incorrect pseudo-labels, leading to noisy training. We propose an uncertainty-aware pseudo-label selection (UPS) framework which improves pseudo labeling accuracy by drastically reducing the amount of noise encountered in the training process. Furthermore, UPS generalizes the pseudo-labeling process, allowing for the creation of negative pseudo-labels; these negative pseudo-labels can be used for multi-label classification as well as negative learning to improve the single-label classification. We achieve strong performance when compared to recent SSL methods on the CIFAR-10 and CIFAR-100 datasets. Also, we demonstrate the versatility of our method on the video dataset UCF-101 and the multi-label dataset Pascal VOC.",半教師あり学習（SSL）の最近の研究は、強力なパフォーマンスを実現する整合性正則化ベースの方法によって主に支配されています。ただし、ドメイン固有のデータ拡張に大きく依存しており、すべてのデータモダリティに対して生成するのは簡単ではありません。疑似ラベリング（PL）は、この制約がない一般的なSSLアプローチですが、元の定式化では比較的パフォーマンスが低くなります。キャリブレーションが不十分なモデルからの誤った高信頼性予測が原因で、PLのパフォーマンスが低下すると主張します。これらの予測は多くの誤った疑似ラベルを生成し、ノイズの多いトレーニングにつながります。トレーニングプロセスで発生するノイズの量を大幅に削減することで疑似ラベルの精度を向上させる、不確実性を意識した疑似ラベル選択（UPS）フレームワークを提案します。さらに、UPSは疑似ラベル付けプロセスを一般化し、負の疑似ラベルの作成を可能にします。これらのネガティブ疑似ラベルは、マルチラベル分類だけでなく、シングルラベル分類を改善するためのネガティブ学習にも使用できます。 CIFAR-10およびCIFAR-100データセットの最近のSSLメソッドと比較すると、強力なパフォーマンスを実現しています。また、ビデオデータセットUCF-101とマルチラベルデータセットPascalVOCでのメソッドの多様性を示します。,6.5,https://d3i71xaburhd42.cloudfront.net/a21792db1c8d80c1d1f8525dab4959cc60b8e0ea/5-Figure1-1.png
C-Learning: Learning to Achieve Goals via Recursive Classification,"['Benjamin Eysenbach', 'Ruslan Salakhutdinov', 'Sergey Levine']",https://openreview.net/forum?id=tc5qisoB-C,"We study the problem of predicting and controlling the future state distribution of an autonomous agent. This problem, which can be viewed as a reframing of goal-conditioned reinforcement learning (RL), is centered around learning a conditional probability density function over future states. Instead of directly estimating this density function, we indirectly estimate this density function by training a classifier to predict whether an observation comes from the future. Via Bayes' rule, predictions from our classifier can be transformed into predictions over future states. Importantly, an off-policy variant of our algorithm allows us to predict the future state distribution of a new policy, without collecting new experience. This variant allows us to optimize functionals of a policy's future state distribution, such as the density of reaching a particular goal state. While conceptually similar to Q-learning, our work lays a principled foundation for goal-conditioned RL as density estimation, providing justification for goal-conditioned methods used in prior work. This foundation makes hypotheses about Q-learning, including the optimal goal-sampling ratio, which we confirm experimentally. Moreover, our proposed method is competitive with prior goal-conditioned RL methods.",自律エージェントの将来の状態分布を予測および制御する問題を研究します。この問題は、目標条件付き強化学習（RL）の再構成と見なすことができ、将来の状態で条件付き確率密度関数を学習することに集中しています。この密度関数を直接推定する代わりに、観測が将来から来るかどうかを予測するように分類器をトレーニングすることにより、この密度関数を間接的に推定します。ベイズの定理を介して、分類器からの予測を将来の状態の予測に変換できます。重要なのは、アルゴリズムのポリシー外のバリアントにより、新しい経験を収集することなく、新しいポリシーの将来の状態分布を予測できることです。このバリアントを使用すると、特定の目標状態に到達する密度など、ポリシーの将来の状態分布の機能を最適化できます。概念的にはQ学習に似ていますが、私たちの作業は、密度推定としての目標条件付きRLの原理的な基盤を築き、以前の作業で使用された目標条件付きメソッドの正当化を提供します。この基盤は、実験的に確認した最適な目標サンプリング比など、Q学習に関する仮説を立てます。さらに、提案された方法は、以前の目標条件付きRL方法と競合します。,6.4,https://d3i71xaburhd42.cloudfront.net/f0901642e339d17b3eb66daae112f5d62556c637/7-Figure1-1.png
Risk-Averse Offline Reinforcement Learning,"['Núria Armengol Urpí', 'Sebastian Curi', 'Andreas Krause']",https://openreview.net/forum?id=TBIzh9b5eaz,"Training Reinforcement Learning (RL) agents in high-stakes applications might be too prohibitive due to the risk associated to exploration. Thus, the agent can only use data previously collected by safe policies. While previous work considers optimizing the average performance using offline data, we focus on optimizing a risk-averse criteria, namely the CVaR. In particular, we present the Offline Risk-Averse Actor-Critic (O-RAAC), a model-free RL algorithm that is able to learn risk-averse policies in a fully offline setting. We show that O-RAAC learns policies with higher CVaR than risk-neutral approaches in different robot control tasks. Furthermore, considering risk-averse criteria guarantees distributional robustness of the average performance with respect to particular distribution shifts. We demonstrate empirically that in the presence of natural distribution-shifts, O-RAAC learns policies with good average performance. 
",ハイステークスアプリケーションで強化学習（RL）エージェントをトレーニングすることは、探索に関連するリスクのために法外すぎる可能性があります。したがって、エージェントは、安全なポリシーによって以前に収集されたデータのみを使用できます。以前の作業ではオフラインデータを使用して平均パフォーマンスを最適化することを検討していますが、リスク回避的な基準、つまりCVaRの最適化に焦点を当てています。特に、完全にオフラインの設定でリスク回避的なポリシーを学習できるモデルフリーのRLアルゴリズムであるOffline Risk-Averse Actor-Critic（O-RAAC）を紹介します。 O-RAACは、さまざまなロボット制御タスクにおいて、リスク中立アプローチよりもCVaRが高いポリシーを学習することを示します。さらに、リスク回避的な基準を考慮することで、特定の分布シフトに関する平均パフォーマンスの分布の堅牢性が保証されます。自然な分布シフトが存在する場合、O-RAACは良好な平均パフォーマンスでポリシーを学習することを経験的に示します。,6.4,
Temporally-Extended Оµ-Greedy Exploration,"['Will Dabney', 'Georg Ostrovski', 'Andre Barreto']",https://openreview.net/forum?id=ONBPHFZ7zG4,"Recent work on exploration in reinforcement learning (RL) has led to a series of increasingly complex solutions to the problem. This increase in complexity often comes at the expense of generality. Recent empirical studies suggest that, when applied to a broader set of domains, some sophisticated exploration methods are outperformed by simpler counterparts, such as ε-greedy. In this paper we propose an exploration algorithm that retains the simplicity of ε-greedy while reducing dithering. We build on a simple hypothesis: the main limitation of ε-greedy exploration is its lack of temporal persistence, which limits its ability to escape local optima. We propose a temporally extended form of ε-greedy that simply repeats the sampled action for a random duration. It turns out that, for many duration distributions, this suffices to improve exploration on a large set of domains. Interestingly, a class of distributions inspired by ecological models of animal foraging behaviour yields particularly strong performance.",強化学習（RL）の探索に関する最近の研究により、この問題に対する一連のますます複雑な解決策がもたらされました。この複雑さの増加は、一般性を犠牲にしてもたらされることがよくあります。最近の経験的研究は、より広範なドメインのセットに適用された場合、いくつかの洗練された探索方法は、-greedyなどのより単純な対応方法よりも優れていることを示唆しています。この論文では、ディザリングを減らしながら、-greedyの単純さを保持する探索アルゴリズムを提案します。単純な仮説に基づいて構築します。欲張り探索の主な制限は、時間的持続性の欠如であり、局所的な最適点から逃れる能力を制限します。サンプリングされたアクションをランダムな期間だけ繰り返す、時間的に拡張された形式の-greedyを提案します。多くの期間分布では、これで大規模なドメインセットの探索を改善するのに十分であることがわかります。興味深いことに、動物の採餌行動の生態系モデルに触発された分布のクラスは、特に強力なパフォーマンスをもたらします。,6.4,
LambdaNetworks: Modeling long-range Interactions without Attention,['Irwan Bello'],https://openreview.net/forum?id=xTJEN-ggl1b,"We present a framework for capturing long-range interactions between an input and structured contextual information (e.g. a pixel surrounded by other pixels). Our method, called the lambda layer, captures such interactions by transforming available contexts into linear functions,  termed lambdas,  and applying these linear functions to each input separately.  Lambda layers may be implemented to model content and position-based interactions in global, local or masked contexts.  As they bypass the need for expensive attention maps, lambda layers can routinely be applied to inputs of length in the thousands, enabling their applications to long sequences or high-resolution images. The resulting neural network architectures, LambdaNetworks, are computationally efficient and simple to implement using direct calls to operations available in modern neural network libraries.  Experiments on ImageNet classification and COCO object detection  and  instance  segmentation  demonstrate  that  LambdaNetworks  significantly  outperform  their  convolutional  and  attentional  counterparts  while  being more computationally efficient. Finally, we introduce LambdaResNets, a family of LambdaNetworks, that considerably improve the speed-accuracy tradeoff of image classification models. LambdaResNets reach state-of-the-art accuracies on ImageNet while being ∼4.5x faster than the popular EfficientNets on modern machine learning accelerators.",入力と構造化されたコンテキスト情報（たとえば、他のピクセルに囲まれたピクセル）の間の長距離の相互作用をキャプチャするためのフレームワークを提示します。ラムダレイヤーと呼ばれる私たちの方法は、利用可能なコンテキストをラムダと呼ばれる線形関数に変換し、これらの線形関数を各入力に個別に適用することで、このような相互作用をキャプチャします。 Lambdaレイヤーは、グローバル、ローカル、またはマスクされたコンテキストでコンテンツと位置ベースのインタラクションをモデル化するために実装できます。高価なアテンションマップの必要性を回避するため、ラムダレイヤーは数千の長さの入力に日常的に適用でき、長いシーケンスや高解像度画像への適用が可能になります。結果として得られるニューラルネットワークアーキテクチャであるLambdaNetworksは、計算効率が高く、最新のニューラルネットワークライブラリで利用可能な操作への直接呼び出しを使用して実装するのが簡単です。 ImageNet分類とCOCOオブジェクト検出およびインスタンスセグメンテーションに関する実験は、LambdaNetworksが、より計算効率が高く、畳み込みおよび注意の対応物を大幅に上回っていることを示しています。最後に、LambdaNetworksのファミリーであるLambdaResNetsを紹介します。これは、画像分類モデルの速度と精度のトレードオフを大幅に改善します。 LambdaResNetsは、ImageNetで最先端の精度に到達すると同時に、最新の機械学習アクセラレーターで人気のあるEfficientNetsよりも4.5倍高速です。,6.4,
Auxiliary Learning by Implicit Differentiation,"['Aviv Navon', 'Idan Achituve', 'Haggai Maron', 'Gal Chechik', 'Ethan Fetaya']",https://openreview.net/forum?id=n7wIfYPdVet,"Training neural networks with auxiliary tasks is a common practice for improving the performance on a main task of interest.
Two main challenges arise in this multi-task learning setting: (i) designing useful auxiliary tasks; and (ii) combining auxiliary tasks into a single coherent loss. Here, we propose a novel framework, AuxiLearn, that targets both challenges based on implicit differentiation. First, when useful auxiliaries are known, we propose learning a network that combines all losses into a single coherent objective function. This network can learn non-linear interactions between auxiliary tasks. Second, when no useful auxiliary task is known, we describe how to learn a network that generates a meaningful, novel auxiliary task. Evaluation of AuxiLearn in a series of tasks and domains, including image segmentation and learning with attributes in the low data regime, shows consistent improvement in accuracy compared to competing methods.",補助タスクを使用してニューラルネットワークをトレーニングすることは、関心のある主要なタスクのパフォーマンスを向上させるための一般的な方法です。このマルチタスク学習環境では、2つの主な課題が発生します。（i）有用な補助タスクの設計。 （ii）補助タスクを単一のコヒーレント損失に結合する。ここでは、暗黙の微分に基づいて両方の課題を対象とする新しいフレームワーク、AuxiLearnを提案します。まず、有用な助動詞がわかっている場合、すべての損失を単一のコヒーレント目的関数に結合するネットワークを学習することを提案します。このネットワークは、補助タスク間の非線形相互作用を学習できます。次に、有用な補助タスクがわからない場合は、意味のある新しい補助タスクを生成するネットワークを学習する方法について説明します。画像のセグメンテーションや低データ体制での属性を使用した学習など、一連のタスクとドメインでのAuxiLearnの評価は、競合する方法と比較して、一貫した精度の向上を示しています。,6.4,https://d3i71xaburhd42.cloudfront.net/06edfca6bbabe1389d136d0118a89188966906d8/2-Figure1-1.png
Model-based micro-data reinforcement learning: what are the crucial model properties and which model to choose?,"['Balázs Kégl', 'Gabriel Hurtado', 'Albert Thomas']",https://openreview.net/forum?id=p5uylG94S68,"We contribute to micro-data model-based reinforcement learning (MBRL) by rigorously comparing popular generative models using a fixed (random shooting) control agent. We find that on an environment that requires multimodal posterior predictives, mixture density nets outperform all other models by a large margin. When multimodality is not required, our surprising finding is that we do not need probabilistic posterior predictives: deterministic models may perform optimally but only if they are trained with a probabilistic goal, allowing heteroscedasticity at training time. Our hypothesis is that heteroscedasticity somehow alleviates long-term error accumulation which often hinders the performance of MBRL. At the methodological side, we design metrics and an experimental protocol which can be used to evaluate the various models, predicting their asymptotic performance when using them on the control problem. Using this framework, we improve the state-of-the-art sample complexity of MBRL on Acrobot by two to four folds, using an aggressive training schedule which is outside of the hyperparameter interval usually considered.",固定（ランダムシューティング）制御エージェントを使用して一般的な生成モデルを厳密に比較することにより、マイクロデータモデルベースの強化学習（MBRL）に貢献します。マルチモーダル事後予測を必要とする環境では、混合密度ネットが他のすべてのモデルよりも大幅に優れていることがわかります。マルチモダリティが必要ない場合、驚くべき発見は、確率的事後予測が必要ないことです。決定論的モデルは、確率的目標でトレーニングされている場合にのみ最適に実行され、トレーニング時に不均一分散が可能になります。私たちの仮説は、不均一分散が、MBRLのパフォーマンスを妨げることが多い長期的なエラーの蓄積を何らかの形で軽減するというものです。方法論の側面では、さまざまなモデルを評価するために使用できるメトリックと実験プロトコルを設計し、制御問題でそれらを使用するときの漸近的パフォーマンスを予測します。このフレームワークを使用して、通常考えられるハイパーパラメータ間隔の外側にある積極的なトレーニングスケジュールを使用して、AcrobotでのMBRLの最先端のサンプルの複雑さを2〜4倍改善します。,6.4,
Net-DNF: Effective Deep Modeling of Tabular Data,"['Gal Elidan', 'Liran Katzir', 'Ran El-Yaniv']",https://openreview.net/forum?id=73WTGs96kho,"A challenging open question in deep learning is how to handle tabular data. Unlike domains such as image and natural language processing, where deep architectures prevail, there is still no widely accepted neural architecture that dominates tabular data. As a step toward bridging this gap, we present Net-DNF a novel generic architecture whose inductive bias elicits models whose structure corresponds to logical Boolean formulas in disjunctive normal form (DNF) over affine soft-threshold decision terms. Net-DNFs also promote localized decisions that are taken over small subsets of the features. We present an extensive experiments showing that Net-DNFs significantly and consistently outperform fully connected networks over tabular data. With relatively few hyperparameters, Net-DNFs open the door to practical end-to-end handling of tabular data using neural networks. We present ablation studies, which justify the design choices of Net-DNF including the inductive bias elements, namely, Boolean formulation, locality, and feature selection. 
",ディープラーニングでの挑戦的な未解決の質問は、表形式のデータをどのように処理するかです。深いアーキテクチャが普及している画像や自然言語処理などのドメインとは異なり、表形式のデータを支配する広く受け入れられているニューラルアーキテクチャはまだありません。このギャップを埋めるためのステップとして、Net-DNFに新しい汎用アーキテクチャを提示します。その誘導バイアスは、アフィンソフトスレッショルド決定項で選言標準形（DNF）の論理ブール式に対応する構造を持つモデルを引き出します。 Net-DNFは、機能の小さなサブセットに対して行われるローカライズされた決定も促進します。 Net-DNFが、表形式のデータを介して完全に接続されたネットワークよりも大幅かつ一貫して優れていることを示す広範な実験を紹介します。ハイパーパラメータが比較的少ないため、Net-DNFは、ニューラルネットワークを使用した表形式データの実用的なエンドツーエンド処理への扉を開きます。誘導バイアス要素、すなわちブール定式化、局所性、および特徴選択を含むNet-DNFの設計選択を正当化するアブレーション研究を提示します。,6.33,
Bypassing the Ambient Dimension: Private SGD with Gradient Subspace Identification,"['Yingxue Zhou', 'Steven Wu', 'Arindam Banerjee']",https://openreview.net/forum?id=7dpmlkBuJFC,"Differentially private SGD (DP-SGD) is one of the most popular methods for solving differentially private empirical risk minimization (ERM). Due to its noisy perturbation on each gradient update, the error rate of DP-SGD scales with the ambient dimension $p$, the number of parameters in the model. Such dependence can be problematic for over-parameterized models where $p \gg n$, the number of training samples. Existing lower bounds on private ERM show that such dependence on $p$ is inevitable in the worst case. In this paper, we circumvent the dependence on the ambient dimension by leveraging a low-dimensional structure of gradient space in deep networks---that is, the stochastic gradients for deep nets usually stay in a low dimensional subspace in the training process. We propose Projected DP-SGD that performs noise reduction by projecting the noisy gradients to a low-dimensional subspace, which is given by the top gradient eigenspace on a small public dataset. We provide a general sample complexity analysis on the public dataset for the gradient subspace identification problem and demonstrate that under certain low-dimensional assumptions the public sample complexity only grows logarithmically in $p$. Finally, we provide a theoretical analysis and empirical evaluations to show that our method can substantially improve the accuracy of DP-SGD in the high privacy regime (corresponding to low privacy loss $\epsilon$).

",差分プライベートSGD（DP-SGD）は、差分プライベートの経験的リスク最小化（ERM）を解決するための最も一般的な方法の1つです。勾配の更新ごとにノイズの多い摂動があるため、DP-SGDのエラー率は、モデル内のパラメーターの数である周囲次元pに比例します。このような依存性は、トレーニングサンプルの数であるpnがパラメータ化されたモデルでは問題になる可能性があります。プライベートERMの既存の下限は、最悪の場合、このようなpへの依存が避けられないことを示しています。この論文では、深いネットワークの勾配空間の低次元構造を活用することにより、周囲次元への依存を回避します。つまり、深いネットの確率的勾配は、通常、トレーニングプロセスで低次元の部分空間にとどまります。ノイズの多い勾配を低次元の部分空間に投影することによってノイズリダクションを実行するProjectedDP-SGDを提案します。これは、小さなパブリックデータセットの上部勾配固有空間によって与えられます。勾配部分空間識別問題の公開データセットに関する一般的なサンプルの複雑さの分析を提供し、特定の低次元の仮定の下で、公開サンプルの複雑さがpで対数的にのみ増加することを示します。最後に、理論的分析と経験的評価を提供して、私たちの方法が高プライバシー体制（低プライバシー損失に対応）でDP-SGDの精度を大幅に改善できることを示します。,6.33,https://d3i71xaburhd42.cloudfront.net/fb09a39893e8d079cff7e9eef79184863ccf4cad/3-Figure1-1.png
FedMix: Approximation of Mixup under Mean Augmented Federated Learning,"['Tehrim Yoon', 'Sumin Shin', 'Sung Ju Hwang', 'Eunho Yang']",https://openreview.net/forum?id=Ogga20D2HO-,"Federated learning (FL) allows edge devices to collectively learn a model without directly sharing data within each device, thus preserving privacy and eliminating the need to store data globally. While there are promising results under the assumption of independent and identically distributed (iid) local data, current state-of-the-art algorithms suffer a performance degradation as the heterogeneity of local data across clients increases. To resolve this issue, we propose a simple framework, \emph{Mean Augmented Federated Learning (MAFL)}, where clients send and receive \emph{averaged} local data, subject to the privacy requirements of target applications. Under our framework, we propose a new augmentation algorithm, named \emph{FedMix}, which is inspired by a phenomenal yet simple data augmentation method, Mixup, but does not require local raw data to be directly shared among devices. Our method shows greatly improved performance in the standard benchmark datasets of FL, under highly non-iid federated settings, compared to conventional algorithms.",フェデレーテッドラーニング（FL）を使用すると、エッジデバイスは、各デバイス内でデータを直接共有することなくモデルを集合的に学習できるため、プライバシーが保護され、データをグローバルに保存する必要がなくなります。独立した同一分布の（iid）ローカルデータを想定した場合、有望な結果が得られますが、現在の最先端のアルゴリズムでは、クライアント間のローカルデータの不均一性が増すため、パフォーマンスが低下します。この問題を解決するために、ターゲットアプリケーションのプライバシー要件に従って、クライアントが平均化されたローカルデータを送受信する単純なフレームワークであるMean Augmented Federated Learning（MAFL）を提案します。私たちのフレームワークの下で、FedMixという名前の新しい拡張アルゴリズムを提案します。これは、驚異的でありながらシンプルなデータ拡張方法であるMixupに触発されていますが、ローカルの生データをデバイス間で直接共有する必要はありません。私たちの方法は、従来のアルゴリズムと比較して、高度に非iidのフェデレーション設定の下で、FLの標準ベンチマークデータセットで大幅に改善されたパフォーマンスを示しています。,6.33,
Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms,"['Maruan Al-Shedivat', 'Jennifer Gillenwater', 'Eric Xing', 'Afshin Rostamizadeh']",https://openreview.net/forum?id=GFsU8a0sGB,"Federated learning is typically approached as an optimization problem, where the goal is to minimize a global loss function by distributing computation across client devices that possess local data and specify different parts of the global objective.  We present an alternative perspective and formulate federated learning as a posterior inference problem, where the goal is to infer a global posterior distribution by having client devices each infer the posterior of their local data.  While exact inference is often intractable, this perspective provides a principled way to search for global optima in federated settings.  Further, starting with the analysis of federated quadratic objectives, we develop a computation- and communication-efficient approximate posterior inference algorithm—federated posterior averaging (FedPA).  Our algorithm uses MCMC for approximate inference of local posteriors on the clients and efficiently communicates their statistics to the server, where the latter uses them to refine a global estimate of the posterior mode.  Finally, we show that FedPA generalizes federated averaging (FedAvg), can similarly benefit from adaptive optimizers, and yields state-of-the-art results on four realistic and challenging benchmarks, converging faster, to better optima.",連合学習は通常、最適化問題としてアプローチされます。目標は、ローカルデータを所有し、グローバル目標のさまざまな部分を指定するクライアントデバイス間で計算を分散することにより、グローバル損失関数を最小化することです。代替の視点を提示し、事後推論問題として連合学習を定式化します。目標は、クライアントデバイスにそれぞれローカルデータの事後確率を推論させることにより、グローバルな事後分布を推論することです。正確な推論はしばしば手に負えないものですが、この視点は、フェデレーション設定でグローバルな最適化を検索するための原則的な方法を提供します。さらに、連合二次目的の分析から始めて、計算および通信効率の高い近似事後推論アルゴリズム連合事後平均（FedPA）を開発します。私たちのアルゴリズムは、MCMCを使用してクライアント上のローカル事後確率を概算し、サーバーに統計を効率的に伝達します。サーバーはそれらを使用して事後モードのグローバル推定を調整します。最後に、FedPAがフェデレーション平均（FedAvg）を一般化し、同様にアダプティブオプティマイザーの恩恵を受け、4つの現実的でやりがいのあるベンチマークで最先端の結果をもたらし、より速く収束し、より最適になることを示します。,6.33,
ECONOMIC HYPERPARAMETER OPTIMIZATION WITH BLENDED SEARCH STRATEGY,"['Chi Wang', 'Qingyun Wu', 'Silu Huang', 'Amin Saied']",https://openreview.net/forum?id=VbLH04pRA3,"We study the problem of using low cost to search for hyperparameter configurations in a large search space with heterogeneous evaluation cost and model quality.
We propose a blended search strategy to combine the strengths of global and local search, and prioritize them on the fly with the goal of minimizing the total cost spent in finding good configurations. Our approach demonstrates robust performance for tuning both tree-based models and deep neural networks on a large AutoML benchmark, as well as superior performance in model quality, time, and resource consumption for a production NLP model fine-tuning task.",低コストを使用して、評価コストとモデル品質が不均一な大規模な検索空間でハイパーパラメータ構成を検索する問題を調査します。グローバル検索とローカル検索の長所を組み合わせ、適切な構成を見つけるために費やされる総コストを最小限に抑えることを目的として、その場で優先順位を付ける混合検索戦略を提案します。私たちのアプローチは、大規模なAutoMLベンチマークでツリーベースのモデルとディープニューラルネットワークの両方を調整するための堅牢なパフォーマンスと、本番NLPモデルの微調整タスクのモデル品質、時間、およびリソース消費における優れたパフォーマンスを示しています。,6.33,
Robust Pruning at Initialization,"['Soufiane Hayou', 'Jean-Francois Ton', 'Arnaud Doucet', 'Yee Whye Teh']",https://openreview.net/forum?id=vXj_ucZQ4hA,"Overparameterized Neural Networks (NN) display state-of-the-art performance. However, there is a growing need for smaller, energy-efficient, neural networks to be able to use machine learning applications on devices with limited computational resources. A popular approach consists of using pruning techniques. While these techniques have traditionally focused on pruning pre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et al. (2018) has shown promising results when pruning at initialization. However, for Deep NNs, such procedures remain unsatisfactory as the resulting pruned networks can be difficult to train and, for instance, they do not prevent one layer from being fully pruned. In this paper, we provide a comprehensive theoretical analysis of Magnitude and Gradient based pruning at initialization and training of sparse architectures.  This allows us to propose novel principled approaches which we validate experimentally on a variety of NN architectures.",オーバーパラメーター化されたニューラルネットワーク（NN）は、最先端のパフォーマンスを表示します。ただし、限られた計算リソースを持つデバイスで機械学習アプリケーションを使用できるようにするために、より小さく、エネルギー効率の高いニューラルネットワークの必要性が高まっています。一般的なアプローチは、剪定技術を使用することです。これらの手法は、従来、事前にトレーニングされたNNの剪定に焦点を合わせてきましたが（LeCun et al。、1990; Hassibi et al。、1993）、Lee etal。 （2018）は、初期化時に剪定するときに有望な結果を示しています。ただし、Deep NNの場合、結果としてプルーニングされたネットワークのトレーニングが困難になる可能性があり、たとえば、1つのレイヤーが完全にプルーニングされるのを妨げることはないため、このような手順は不十分なままです。このホワイトペーパーでは、スパースアーキテクチャの初期化とトレーニングにおけるマグニチュードと勾配ベースのプルーニングの包括的な理論的分析を提供します。これにより、さまざまなNNアーキテクチャで実験的に検証する新しい原理的なアプローチを提案できます。,6.33,
OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning,"['Anurag Ajay', 'Aviral Kumar', 'Pulkit Agrawal', 'Sergey Levine', 'Ofir Nachum']",https://openreview.net/forum?id=V69LGwJ0lIN,"Reinforcement learning (RL) has achieved impressive performance in a variety of online settings in which an agent's ability to query the environment for transitions and rewards is effectively unlimited. However, in many practical applications, the situation is reversed: an agent may have access to large amounts of undirected offline experience data, while access to the online environment is severely limited. In this work, we focus on this offline setting. Our main insight is that, when presented with offline data composed of a variety of behaviors, an effective way to leverage this data is to extract a continuous space of recurring and temporally extended primitive behaviors before using these primitives for downstream task learning. Primitives extracted in this way serve two purposes: they delineate the behaviors that are supported by the data from those that are not, making them useful for avoiding distributional shift in offline RL; and they provide a degree of temporal abstraction, which reduces the effective horizon yielding better learning in theory, and improved offline RL in practice. In addition to benefiting offline policy optimization, we show that performing offline primitive learning in this way can also be leveraged for improving few-shot imitation learning as well as exploration and transfer in online RL on a variety of benchmark domains. Visualizations are available at https://sites.google.com/view/opal-iclr",強化学習（RL）は、さまざまなオンライン設定で優れたパフォーマンスを実現しました。エージェントは、環境に遷移と報酬を照会する機能が事実上無制限です。ただし、多くの実際のアプリケーションでは、状況が逆になります。エージェントは、オンライン環境へのアクセスが厳しく制限されている一方で、大量の無向オフラインエクスペリエンスデータにアクセスできる場合があります。この作業では、このオフライン設定に焦点を当てます。私たちの主な洞察は、さまざまな動作で構成されるオフラインデータが提示された場合、このデータを活用する効果的な方法は、これらのプリミティブをダウンストリームのタスク学習に使用する前に、繰り返し発生する時間的に拡張されたプリミティブ動作の連続空間を抽出することです。この方法で抽出されたプリミティブは、2つの目的を果たします。データによってサポートされている動作をサポートされていない動作から描写し、オフラインRLの分布シフトを回避するのに役立ちます。そして、それらはある程度の時間的抽象化を提供し、それは理論的にはより良い学習をもたらす有効な地平線を減らし、実際にはオフラインRLを改善します。オフラインポリシーの最適化のメリットに加えて、この方法でオフラインプリミティブ学習を実行することで、さまざまなベンチマークドメインでのオンラインRLの探索と転送だけでなく、数ショットの模倣学習を改善できることを示します。視覚化はhttps://sites.google.com/view/opal-iclrで利用できます,6.33,https://d3i71xaburhd42.cloudfront.net/12268decc6bece1de26b064b46697273659c9db9/2-Figure1-1.png
Efficient Wasserstein Natural Gradients for Reinforcement Learning,"['Ted Moskovitz', 'Michael Arbel', 'Ferenc Huszar', 'Arthur Gretton']",https://openreview.net/forum?id=OHgnfSrn2jv,"A novel optimization approach is proposed for application to policy gradient methods and evolution strategies for reinforcement learning (RL). The procedure uses a computationally efficient \emph{Wasserstein natural gradient} (WNG) descent that takes advantage of the geometry induced by a Wasserstein penalty to speed optimization. This method follows the recent theme in RL of including divergence penalties in the objective to establish trust regions. Experiments on challenging tasks demonstrate improvements in both computational cost and performance over advanced baselines. 
",強化学習（RL）のポリシー勾配法と進化戦略に適用するための新しい最適化アプローチが提案されています。この手順では、計算効率の高いWasserstein自然勾配（WNG）降下を使用します。これは、Wassersteinペナルティによって引き起こされるジオメトリを利用して最適化を高速化します。この方法は、信頼領域を確立する目的で発散ペナルティを含めるというRLの最近のテーマに従います。やりがいのあるタスクの実験は、高度なベースラインよりも計算コストとパフォーマンスの両方が向上していることを示しています。,6.33,https://d3i71xaburhd42.cloudfront.net/edbc8cc99d467610aa9ba8eb86d896a4ba679946/3-Figure1-1.png
BREEDS: Benchmarks for Subpopulation Shift,"['Shibani Santurkar', 'Dimitris Tsipras', 'Aleksander Madry']",https://openreview.net/forum?id=mQPBmvyAuk,"We develop a methodology for assessing the robustness of models to subpopulation shift---specifically, their ability to generalize to novel data subpopulations that were not observed during training. Our approach leverages the class structure underlying existing datasets to control the data subpopulations that comprise the training and test distributions. This enables us to synthesize realistic distribution shifts whose sources can be precisely controlled and characterized, within existing large-scale datasets. Applying this methodology to the ImageNet dataset, we create a suite of subpopulation shift benchmarks of varying granularity. We then validate that the corresponding shifts are tractable by obtaining human baselines for them. Finally, we utilize these benchmarks to measure the sensitivity of standard model architectures as well as the effectiveness of off-the-shelf train-time robustness interventions.",サブポピュレーションシフトに対するモデルの堅牢性、特にトレーニング中に観察されなかった新しいデータサブポピュレーションに一般化する能力を評価するための方法論を開発します。私たちのアプローチは、既存のデータセットの基礎となるクラス構造を活用して、トレーニングとテストの分布を構成するデータサブポピュレーションを制御します。これにより、既存の大規模データセット内で、ソースを正確に制御および特性化できる現実的な分布シフトを合成できます。この方法論をImageNetデータセットに適用して、さまざまな粒度のサブポピュレーションシフトベンチマークのスイートを作成します。次に、対応するシフトが人間のベースラインを取得することによって扱いやすいことを検証します。最後に、これらのベンチマークを利用して、標準モデルアーキテクチャの感度と、既成の列車時間の堅牢性介入の有効性を測定します。,6.33,https://d3i71xaburhd42.cloudfront.net/767c6702045f2290012a259744db9edb4d55bcb8/3-Figure1-1.png
Learning to Sample with Local and Global Contexts  in Experience Replay Buffer,"['Youngmin Oh', 'Kimin Lee', 'Jinwoo Shin', 'Eunho Yang', 'Sung Ju Hwang']",https://openreview.net/forum?id=gJYlaqL8i8,"Experience replay, which enables the agents to remember and reuse experience from the past, has played a significant role in the success of off-policy reinforcement learning (RL). To utilize the experience replay efficiently, the existing sampling methods allow selecting out more meaningful experiences by imposing priorities on them based on certain metrics (e.g. TD-error). However, they may result in sampling highly biased, redundant transitions since they compute the sampling rate for each transition independently, without consideration of its importance in relation to other transitions. In this paper, we aim to address the issue by proposing a new learning-based sampling method that can compute the relative importance of transition. To this end, we design a novel permutation-equivariant neural architecture that takes contexts from not only features of each transition (local) but also those of others (global) as inputs. We validate our framework, which we refer to as Neural Experience Replay Sampler (NERS), on multiple benchmark tasks for both continuous and discrete control tasks and show that it can significantly improve the performance of various off-policy RL methods. Further analysis confirms that the improvements of the sample efficiency indeed are due to sampling diverse and meaningful transitions by NERS that considers both local and global contexts.",エージェントが過去の経験を記憶して再利用できるようにする経験リプレイは、ポリシー外強化学習（RL）の成功に重要な役割を果たしてきました。エクスペリエンスの再生を効率的に利用するために、既存のサンプリング方法では、特定のメトリック（TDエラーなど）に基づいて優先順位を課すことにより、より意味のあるエクスペリエンスを選択できます。ただし、他の遷移との関連での重要性を考慮せずに、各遷移のサンプリングレートを個別に計算するため、バイアスの大きい冗長な遷移をサンプリングする可能性があります。この論文では、遷移の相対的な重要性を計算できる新しい学習ベースのサンプリング方法を提案することにより、この問題に対処することを目指しています。この目的のために、各遷移の特徴（ローカル）だけでなく他の遷移の特徴（グローバル）からのコンテキストを入力として受け取る、新しい順列同変ニューラルアーキテクチャを設計します。 Neural Experience Replay Sampler（NERS）と呼ばれるフレームワークを、連続制御タスクと離散制御タスクの両方の複数のベンチマークタスクで検証し、さまざまなポリシー外のRLメソッドのパフォーマンスを大幅に向上できることを示します。さらなる分析により、サンプル効率の改善は、ローカルとグローバルの両方のコンテキストを考慮したNERSによる多様で意味のある遷移のサンプリングによるものであることが確認されています。,6.33,https://d3i71xaburhd42.cloudfront.net/49f54e261633cd53034d85f777b393f41001c289/2-Figure1-1.png
PAC Confidence Predictions for Deep Neural Network Classifiers,"['Sangdon Park', 'Shuo Li', 'Osbert Bastani', 'Insup Lee']",https://openreview.net/forum?id=Qk-Wq5AIjpq,"A key challenge for deploying deep neural networks (DNNs) in safety critical settings is the need to provide rigorous ways to quantify their uncertainty. In this paper, we propose a novel algorithm for constructing predicted classification confidences for DNNs that comes with provable correctness guarantees. Our approach uses Clopper-Pearson confidence intervals for the Binomial distribution in conjunction with the histogram binning approach to calibrated prediction. In addition, we demonstrate how our predicted confidences can be used to enable downstream guarantees in two settings: (i) fast DNN inference, where we demonstrate how to compose a fast but inaccurate DNN with an accurate but slow DNN in a rigorous way to improve performance without sacrificing accuracy, and (ii) safe planning, where we guarantee safety when using a DNN to predict whether a given action is safe based on visual observations. In our experiments, we demonstrate that our approach can be used to provide guarantees for state-of-the-art DNNs.",セーフティクリティカルな設定でディープニューラルネットワーク（DNN）を展開するための重要な課題は、それらの不確実性を定量化するための厳密な方法を提供する必要があることです。この論文では、証明可能な正確性の保証が付いているDNNの予測された分類信頼度を構築するための新しいアルゴリズムを提案します。私たちのアプローチでは、二項分布のC​​lopper-Pearson信頼区間を、キャリブレーションされた予測へのヒストグラムビニングアプローチと組み合わせて使用​​します。さらに、予測された信頼度を使用して、2つの設定でダウンストリーム保証を有効にする方法を示します。（i）高速DNN推論。ここでは、高速であるが不正確なDNNを、正確であるが遅いDNNで厳密な方法で構成して改善する方法を示します。精度を犠牲にすることなくパフォーマンスを実現し、（ii）安全な計画。DNNを使用して、視覚的な観察に基づいて特定のアクションが安全かどうかを予測する際の安全性を保証します。私たちの実験では、私たちのアプローチを使用して、最先端のDNNを保証できることを示しています。,6.33,https://d3i71xaburhd42.cloudfront.net/e412714711e5f952d4e7d0d7a39d6834c7ba6212/5-Figure1-1.png
Gradient Origin Networks,"['Sam Bond-Taylor', 'Chris G. Willcocks']",https://openreview.net/forum?id=0O_cQfw6uEh,"This paper proposes a new type of generative model that is able to quickly learn a latent representation without an encoder. This is achieved using empirical Bayes to calculate the expectation of the posterior, which is implemented by initialising a latent vector with zeros, then using the gradient of the log-likelihood of the data with respect to this zero vector as new latent points. The approach has similar characteristics to autoencoders, but with a simpler architecture, and is demonstrated in a variational autoencoder equivalent that permits sampling. This also allows implicit representation networks to learn a space of implicit functions without requiring a hypernetwork, retaining their representation advantages across datasets. The experiments show that the proposed method converges faster, with significantly lower reconstruction error than autoencoders, while requiring half the parameters.",この論文は、エンコーダなしで潜在表現を迅速に学習することができる新しいタイプの生成モデルを提案します。これは、経験的ベイズを使用して後部の期待値を計算することで実現されます。これは、潜在ベクトルをゼロで初期化し、このゼロベクトルに関するデータの対数尤度の勾配を新しい潜在点として使用することで実装されます。このアプローチは、オートエンコーダーと同様の特性を備えていますが、アーキテクチャーが単純であり、サンプリングを可能にする同等のバリエーションのオートエンコーダーで示されています。これにより、暗黙の表現ネットワークは、ハイパーネットワークを必要とせずに暗黙の関数の空間を学習し、データセット全体で表現の利点を維持できます。実験は、提案された方法がオートエンコーダよりも大幅に低い再構成誤差でより速く収束する一方で、半分のパラメータを必要とすることを示しています。,6.33,https://d3i71xaburhd42.cloudfront.net/21972ce99a442a5bae9d29d0673052d933b5fb1f/2-Figure1-1.png
HyperGrid Transformers: Towards A Single Model for Multiple Tasks,"['Yi Tay', 'Zhe Zhao', 'Dara Bahri', 'Donald Metzler', 'Da-Cheng Juan']",https://openreview.net/forum?id=hiq1rHO8pNT,"Achieving state-of-the-art performance on natural language understanding tasks typically relies on fine-tuning a fresh model for every task. Consequently, this approach leads to a higher overall parameter cost, along with higher technical maintenance for serving multiple models. Learning a single multi-task model that is able to do well for all the tasks has been a challenging and yet attractive proposition. In this paper, we propose HyperGrid Transformers, a new Transformer architecture that leverages task-conditioned hyper networks for controlling its feed-forward layers. Specifically, we propose a decomposable hypernetwork that learns grid-wise projections that help to specialize regions in weight matrices for different tasks. In order to construct the proposed hypernetwork, our method learns the interactions and composition between a global (task-agnostic) state and a local task-specific state. We conduct an extensive set of experiments on GLUE/SuperGLUE. On the SuperGLUE test set, we match the performance of the state-of-the-art while being $16$ times more parameter efficient. Our method helps bridge the gap between fine-tuning and multi-task learning approaches.",自然言語理解タスクで最先端のパフォーマンスを達成するには、通常、すべてのタスクの新しいモデルを微調整する必要があります。その結果、このアプローチは、複数のモデルにサービスを提供するためのより高い技術的メンテナンスとともに、より高い全体的なパラメータコストにつながります。すべてのタスクをうまく実行できる単一のマルチタスクモデルを学ぶことは、挑戦的でありながら魅力的な提案でした。このホワイトペーパーでは、フィードフォワード層を制御するためにタスク条件付きハイパーネットワークを活用する新しいトランスフォーマーアーキテクチャであるHyperGridトランスフォーマーを提案します。具体的には、さまざまなタスクの重み行列の領域を特殊化するのに役立つグリッド単位の射影を学習する分解可能なハイパーネットワークを提案します。提案されたハイパーネットワークを構築するために、私たちの方法は、グローバル（タスクにとらわれない）状態とローカルタスク固有の状態の間の相互作用と構成を学習します。 GLUE / SuperGLUEで広範な実験を行っています。 SuperGLUEテストセットでは、最先端のパフォーマンスに匹敵すると同時に、パラメーターの効率が16倍高くなっています。私たちの方法は、微調整とマルチタスク学習アプローチの間のギャップを埋めるのに役立ちます。,6.33,
Sparse encoding for more-interpretable feature-selecting representations in probabilistic matrix factorization,"['Joshua C Chang', 'Patrick Fletcher', 'Jungmin Han', 'Ted L Chang', 'Shashaank Vattikuti', 'Ayah Zirikly', 'Bart Desmet', 'Carson C Chow']",https://openreview.net/forum?id=D_KeYoqCYC,"Dimensionality reduction methods for count data are critical to a wide range of applications in medical informatics and other fields where model interpretability is paramount. For such data, hierarchical Poisson matrix factorization (HPF) and other sparse probabilistic non-negative matrix factorization (NMF) methods are considered to be interpretable generative models. They consist of sparse transformations for decoding their learned representations into predictions. However, sparsity in representation decoding does not necessarily imply sparsity in the encoding of representations from the original data features.  HPF is often incorrectly interpreted in the literature as if it possesses encoder sparsity. The distinction between decoder sparsity and encoder sparsity is subtle but important. Due to the lack of encoder sparsity, HPF does not possess the column-clustering property of classical NMF -- the factor loading matrix does not sufficiently define how each factor is formed from the original features. We address this deficiency by self-consistently enforcing encoder sparsity, using a generalized additive model  (GAM), thereby allowing one to relate each representation coordinate to a subset of the original data features. In doing so, the method also gains the ability to perform feature selection. We demonstrate our method on simulated data and give an example of how encoder sparsity is of practical use in a concrete application of representing inpatient comorbidities in Medicare patients.",カウントデータの次元削減方法は、モデルの解釈可能性が最優先される医療情報学やその他の分野での幅広いアプリケーションにとって重要です。このようなデータの場合、階層型ポアソン行列因数分解（HPF）およびその他のスパース確率的非負行列因子分解（NMF）法は、解釈可能な生成モデルと見なされます。それらは、学習した表現を予測にデコードするためのスパース変換で構成されています。ただし、表現のデコードのスパース性は、元のデータ特徴からの表現のエンコードのスパース性を必ずしも意味しません。 HPFは、エンコーダのスパース性を備えているかのように、文献で誤って解釈されることがよくあります。デコーダーのスパース性とエンコーダーのスパース性の違いは微妙ですが重要です。エンコーダーのスパース性がないため、HPFは従来のNMFの列クラスタリング特性を備えていません。因子負荷行列は、各因子が元の特徴からどのように形成されるかを十分に定義していません。一般化された加法モデル（GAM）を使用して、エンコーダのスパース性を自己無撞着に適用することでこの欠陥に対処します。これにより、各表現座標を元のデータ特徴のサブセットに関連付けることができます。そうすることで、メソッドは特徴選択を実行する機能も取得します。シミュレートされたデータで私たちの方法を示し、メディケア患者の入院患者の併存疾患を表す具体的なアプリケーションでエンコーダのスパース性がどのように実用的であるかの例を示します。,6.33,https://d3i71xaburhd42.cloudfront.net/302c5388dfc37671ce109d65349a3c8cf0746788/3-Figure1-1.png
Trusted Multi-View Classification,"['Zongbo Han', 'Changqing Zhang', 'Huazhu Fu', 'Joey Tianyi Zhou']",https://openreview.net/forum?id=OOsR8BzCnl5,"Multi-view classification (MVC) generally focuses on improving classification accuracy by using information from different views, typically integrating them into a unified comprehensive representation for downstream tasks. However, it is also crucial to dynamically assess the quality of a view for different samples in order to provide reliable uncertainty estimations, which indicate whether predictions can be trusted. To this end, we propose a novel multi-view classification method, termed trusted multi-view classification, which provides a new paradigm for multi-view learning by dynamically integrating different views at an evidence level. The algorithm jointly utilizes multiple views to promote both classification reliability (uncertainty estimation during testing) and robustness (out-of-distribution-awareness during training) by integrating evidence from each view. To achieve this, the Dirichlet distribution is used to model the distribution of the class probabilities, parameterized with evidence from different views and integrated with the Dempster-Shafer theory. The unified learning framework induces accurate uncertainty and accordingly endows the model with both reliability and robustness for out-of-distribution samples. Extensive experimental results validate the effectiveness of the proposed model in accuracy, reliability and robustness.",マルチビュー分類（MVC）は通常、さまざまなビューからの情報を使用して分類の精度を向上させることに重点を置いており、通常、それらをダウンストリームタスクの統合された包括的な表現に統合します。ただし、予測が信頼できるかどうかを示す信頼性の高い不確実性の見積もりを提供するために、さまざまなサンプルのビューの品質を動的に評価することも重要です。この目的のために、信頼できるマルチビュー分類と呼ばれる新しいマルチビュー分類方法を提案します。これは、証拠レベルでさまざまなビューを動的に統合することにより、マルチビュー学習の新しいパラダイムを提供します。このアルゴリズムは、複数のビューを共同で利用して、各ビューからの証拠を統合することにより、分類の信頼性（テスト中の不確実性の推定）と堅牢性（トレーニング中の分布外の認識）の両方を促進します。これを実現するために、ディリクレ分布を使用してクラス確率の分布をモデル化し、さまざまなビューからの証拠でパラメーター化して、デンプスターシェーファー理論と統合します。統一された学習フレームワークは、正確な不確実性を誘発し、それに応じて、分布外のサンプルの信頼性と堅牢性の両方をモデルに与えます。広範な実験結果により、提案されたモデルの精度、信頼性、および堅牢性の有効性が検証されます。,6.33,
Improve Object Detection with Feature-based Knowledge Distillation: Towards Accurate and Efficient Detectors,"['Linfeng Zhang', 'Kaisheng Ma']",https://openreview.net/forum?id=uKhGRvM8QNH,"Knowledge distillation, in which a student model is trained to mimic a teacher model, has been proved as an effective technique for model compression and model accuracy boosting. However, most knowledge distillation methods, designed for image classification, have failed on more challenging tasks, such as object detection. In this paper, we suggest that the failure of knowledge distillation on object detection is mainly caused by two reasons: (1) the imbalance between pixels of foreground and background and (2) lack of distillation on the relation between different pixels. Observing the above reasons, we propose attention-guided distillation and non-local distillation to address the two problems, respectively.  Attention-guided distillation is proposed to find the crucial pixels of foreground objects with attention mechanism and then make the students take more effort to learn their features. Non-local distillation is proposed to enable students to learn not only the feature of an individual pixel but also the relation between different pixels captured by non-local modules. Experiments show that our methods achieve excellent AP improvements on both one-stage and two-stage, both anchor-based and anchor-free detectors. For example, Faster RCNN101 with our distillation achieves 43.9 AP on COCO2017, which is 4.1 higher than the baseline. Codes will be released on Github.",生徒のモデルが教師のモデルを模倣するようにトレーニングされる知識蒸留は、モデルの圧縮とモデルの精度を高めるための効果的な手法として証明されています。ただし、画像分類用に設計されたほとんどの知識蒸留法は、オブジェクト検出などのより困難なタスクで失敗しました。この論文では、物体検出における知識蒸留の失敗は、主に2つの理由によって引き起こされることを示唆します：（1）前景と背景のピクセル間の不均衡と（2）異なるピクセル間の関係に関する蒸留の欠如。上記の理由を考慮して、2つの問題にそれぞれ対処するために注意誘導蒸留と非局所蒸留を提案します。注意誘導蒸留は、注意メカニズムを備えた前景オブジェクトの重要なピクセルを見つけ、学生に彼らの特徴を学ぶためにより多くの努力をさせるために提案されています。非局所蒸留は、学生が個々のピクセルの特徴だけでなく、非局所モジュールによってキャプチャされた異なるピクセル間の関係も学習できるようにするために提案されています。実験は、私たちの方法が、アンカーベースの検出器とアンカーフリーの検出器の両方で、1段式と2段式の両方で優れたAPの改善を達成することを示しています。たとえば、蒸留を使用したより高速なRCNN101は、COCO2017で43.9 APを達成します。これは、ベースラインより4.1高い値です。コードはGithubでリリースされます。,6.33,
Boosting Certified Robustness of Deep Networks via a Compositional Architecture,"['Mark Niklas Mueller', 'Mislav Balunovic', 'Martin Vechev']",https://openreview.net/forum?id=USCNapootw,"A core challenge with existing certified defense mechanisms is that while they improve certified robustness, they also tend to drastically decrease natural accuracy, making it difficult to use these methods in practice. In this work, we propose a new architecture which addresses this challenge and enables one to boost the certified robustness of any state-of-the-art deep network, while controlling the overall accuracy loss, without requiring retraining. The key idea is to combine this model with a (smaller) certified network where at inference time, an adaptive selection mechanism decides on the network to process the input sample. The approach is compositional: one can combine any pair of state-of-the-art (e.g., EfficientNet or ResNet) and certified networks, without restriction. The resulting architecture enables much higher natural accuracy than previously possible with certified defenses alone, while substantially boosting the certified robustness of deep networks. We demonstrate the effectiveness of this adaptive approach on a variety of datasets and architectures.  For instance, on CIFAR-10 with an $\ell_\infty$ perturbation of 2/255, we are the first to obtain a high natural accuracy (90.1%) with non-trivial certified robustness (27.5%). Notably, prior state-of-the-art methods incur a substantial drop in accuracy for a similar certified robustness.",既存の認定された防御メカニズムの中心的な課題は、認定された堅牢性を向上させる一方で、自然の精度を大幅に低下させる傾向があり、これらの方法を実際に使用することを困難にすることです。この作業では、この課題に対処し、再トレーニングを必要とせずに全体的な精度の低下を制御しながら、最先端のディープネットワークの認定された堅牢性を高めることができる新しいアーキテクチャを提案します。重要なアイデアは、このモデルを（より小さな）認定ネットワークと組み合わせることです。推論時に、適応選択メカニズムが入力サンプルを処理するネットワークを決定します。このアプローチは構成的です。制限なしに、最先端のネットワーク（EfficientNetやResNetなど）と認定済みネットワークの任意のペアを組み合わせることができます。結果として得られるアーキテクチャは、認定された防御のみで以前に可能であったよりもはるかに高い自然精度を可能にすると同時に、ディープネットワークの認定された堅牢性を大幅に向上させます。さまざまなデータセットとアーキテクチャに対するこの適応アプローチの有効性を示します。たとえば、l（）摂動が2/255のCIFAR-10では、高い自然精度（90.1）を最初に取得しました。,6.33,
MIROSTAT: A NEURAL TEXT DECODING ALGORITHM THAT DIRECTLY CONTROLS PERPLEXITY,"['Sourya Basu', 'Govardana Sachitanandam Ramachandran', 'Nitish Shirish Keskar', 'Lav R. Varshney']",https://openreview.net/forum?id=W1G1JZEIy5_,"Neural text decoding algorithms strongly influence the quality of texts generated using language models, but popular algorithms like top-k, top-p (nucleus), and temperature-based sampling may yield texts that have objectionable repetition or incoherence. Although these methods generate high-quality text after ad hoc parameter tuning that depends on the language model and the length of generated text, not much is known about the control they provide over the statistics of the output. This is important, however, since recent reports show that humans prefer when perplexity is neither too much nor too little and since we experimentally show that cross-entropy (log of perplexity) has a near-linear relation with repetition. First, we provide a theoretical analysis of perplexity in top-k, top-p, and temperature sampling, under Zipfian statistics. Then, we use this analysis to design a feedback-based adaptive top-k text decoding algorithm called mirostat that generates text (of any length) with a predetermined target value of perplexity without any tuning. Experiments show that for low values of k and p, perplexity drops significantly with generated text length and leads to excessive repetitions (the boredom trap). Contrarily, for large values of k and p, perplexity increases with generated text length and leads to incoherence (confusion trap). Mirostat avoids both traps. Specifically, we show that setting target perplexity value beyond a threshold yields negligible sentence-level repetitions. Experiments with
human raters for fluency, coherence, and quality further verify our findings.",ニューラルテキストデコードアルゴリズムは、言語モデルを使用して生成されるテキストの品質に大きく影響しますが、top-k、top-p（核）、温度ベースのサンプリングなどの一般的なアルゴリズムでは、好ましくない繰り返しや一貫性のないテキストが生成される場合があります。これらのメソッドは、言語モデルと生成されたテキストの長さに依存するアドホックパラメーター調整後に高品質のテキストを生成しますが、出力の統計に対して提供する制御についてはあまり知られていません。ただし、最近の報告では、パープレキシティが多すぎず少なすぎない場合に人間が好むことが示され、クロスエントロピー（パープレキシティの対数）が繰り返しとほぼ線形の関係にあることが実験的に示されているため、これは重要です。まず、Zipfian統計の下で、top-k、top-p、および温度サンプリングのパープレキシティの理論的分析を提供します。次に、この分析を使用して、ミロスタットと呼ばれるフィードバックベースの適応型top-kテキストデコードアルゴリズムを設計します。このアルゴリズムは、調整なしで、事前に定義されたパープレキシティのターゲット値を持つテキスト（任意の長さ）を生成します。実験によると、kとpの値が低い場合、生成されたテキストの長さとともに複雑さが大幅に低下し、過度の繰り返しが発生します（退屈の罠）。逆に、kとpの値が大きい場合、生成されたテキストの長さとともに複雑さが増し、一貫性が失われます（混乱の罠）。ミロスタットは両方のトラップを回避します。具体的には、しきい値を超えてターゲットのパープレキシティ値を設定すると、文レベルの繰り返しが無視できることを示します。流暢さ、一貫性、品質についての人間の評価者による実験は、私たちの発見をさらに検証します。,6.33,
PDE-Driven Spatiotemporal Disentanglement,"['Jérémie Donà', 'Jean-Yves Franceschi', 'sylvain lamprier', 'patrick gallinari']",https://openreview.net/forum?id=vLaHRtHvfFp,"A recent line of work in the machine learning community addresses the problem of predicting high-dimensional spatiotemporal phenomena by leveraging specific tools from the differential equations theory. Following this direction, we propose in this article a novel and general paradigm for this task based on a resolution method for partial differential equations: the separation of variables. This inspiration allows us to introduce a dynamical interpretation of spatiotemporal disentanglement. It induces a principled model based on learning disentangled spatial and temporal representations of a phenomenon to accurately predict future observations. We experimentally demonstrate the performance and broad applicability of our method against prior state-of-the-art models on physical and synthetic video datasets.",機械学習コミュニティの最近の一連の作業は、微分方程式理論の特定のツールを活用することにより、高次元の時空間現象を予測する問題に取り組んでいます。この方向性に従って、この記事では、偏微分方程式の解決方法に基づくこのタスクの新しい一般的なパラダイム、つまり変数分離を提案します。このインスピレーションにより、時空間的解きほぐしの動的な解釈を導入することができます。それは、将来の観測を正確に予測するために、現象の解きほぐされた空間的および時間的表現の学習に基づく原理モデルを誘発します。物理的および合成ビデオデータセットの以前の最先端モデルに対する私たちの方法のパフォーマンスと幅広い適用性を実験的に示します。,6.33,https://d3i71xaburhd42.cloudfront.net/fef00d097117b48129f0925e9c0165496cc024b1/5-Figure1-1.png
Genetic Soft Updates for Policy Evolution in Deep Reinforcement Learning,"['Enrico Marchesini', 'Davide Corsi', 'Alessandro Farinelli']",https://openreview.net/forum?id=TGFO0DbD_pk,"The combination of Evolutionary Algorithms (EA) and Deep Reinforcement Learning (DRL) has been recently proposed to merge the benefits of both solutions. Existing mixed approaches, however, have been successfully applied only to actor-critic methods and present significant overhead. We address these issues by introducing a novel mixed framework that exploits a periodical genetic evaluation to soft update the weights of a DRL agent. The resulting approach is applicable with any DRL method and, in a worst-case scenario, it does not exhibit detrimental behaviours. Experiments in robotic applications and continuous control benchmarks demonstrate the versatility of our approach that significantly outperforms prior DRL, EA, and mixed approaches. Finally, we employ formal verification to confirm the policy improvement, mitigating the inefficient exploration and hyper-parameter sensitivity of DRL.",最近、進化的アルゴリズム（EA）と深層強化学習（DRL）の組み合わせが、両方のソリューションの利点を統合するために提案されました。ただし、既存の混合アプローチは、アクタークリティカルな方法にのみ正常に適用されており、かなりのオーバーヘッドがあります。定期的な遺伝的評価を利用してDRLエージェントの重みをソフト更新する新しい混合フレームワークを導入することにより、これらの問題に対処します。結果として得られるアプローチは、どのDRLメソッドにも適用可能であり、最悪のシナリオでは、有害な動作を示しません。ロボットアプリケーションと連続制御ベンチマークでの実験は、以前のDRL、EA、および混合アプローチを大幅に上回るアプローチの多様性を示しています。最後に、フォーマル検証を使用してポリシーの改善を確認し、DRLの非効率的な調査とハイパーパラメータの感度を軽減します。,6.33,
Understanding the effects of data parallelism and sparsity on neural network training,"['Namhoon Lee', 'Thalaiyasingam Ajanthan', 'Philip Torr', 'Martin Jaggi']",https://openreview.net/forum?id=rsogjAnYs4z,"We study two factors in neural network training: data parallelism and sparsity; here, data parallelism means processing training data in parallel using distributed systems (or equivalently increasing batch size), so that training can be accelerated; for sparsity, we refer to pruning parameters in a neural network model, so as to reduce computational and memory cost. Despite their promising benefits, however, understanding of their effects on neural network training remains elusive. In this work, we first measure these effects rigorously by conducting extensive experiments while tuning all metaparameters involved in the optimization. As a result, we find across various workloads of data set, network model, and optimization algorithm that there exists a general scaling trend between batch size and number of training steps to convergence for the effect of data parallelism, and further, difficulty of training under sparsity. Then, we develop a theoretical analysis based on the convergence properties of stochastic gradient methods and smoothness of the optimization landscape, which illustrates the observed phenomena precisely and generally, establishing a better account of the effects of data parallelism and sparsity on neural network training.",ニューラルネットワークトレーニングの2つの要素を研究します。データの並列性とスパース性です。ここで、データの並列処理とは、分散システムを使用してトレーニングデータを並列処理すること（または同等にバッチサイズを増やすこと）を意味します。スパース性については、計算コストとメモリコストを削減するために、ニューラルネットワークモデルのプルーニングパラメータを参照します。それらの有望な利点にもかかわらず、しかしながら、ニューラルネットワークトレーニングに対するそれらの効果の理解はとらえどころのないままです。この作業では、最初に、最適化に関係するすべてのメタパラメーターを調整しながら、広範な実験を行うことにより、これらの効果を厳密に測定します。その結果、データセット、ネットワークモデル、最適化アルゴリズムのさまざまなワークロードにわたって、データの並列処理の効果を収束するためのバッチサイズとトレーニングステップ数の間に一般的なスケーリング傾向が存在し、さらに、スパース性。次に、確率的勾配法の収束特性と最適化ランドスケープの滑らかさに基づいた理論的分析を開発します。これにより、観測された現象が正確かつ一般的に示され、ニューラルネットワークトレーニングに対するデータの並列性とスパース性の影響がより適切に説明されます。,6.33,
Wasserstein-2 Generative Networks,"['Alexander Korotin', 'Vage Egiazarian', 'Arip Asadulaev', 'Alexander Safin', 'Evgeny Burnaev']",https://openreview.net/forum?id=bEoxzW_EXsa,"We propose a novel end-to-end non-minimax algorithm for training optimal transport mappings for the quadratic cost (Wasserstein-2 distance). The algorithm uses input convex neural networks and a cycle-consistency regularization to approximate Wasserstein-2 distance. In contrast to popular entropic and quadratic regularizers, cycle-consistency does not introduce bias and scales well to high dimensions. From the theoretical side, we estimate the properties of the generative mapping fitted by our algorithm. From the practical side, we evaluate our algorithm on a wide range of tasks: image-to-image color transfer, latent space optimal transport, image-to-image style transfer, and domain adaptation.",二次コスト（Wasserstein-2距離）の最適な輸送マッピングをトレーニングするための新しいエンドツーエンドの非ミニマックスアルゴリズムを提案します。このアルゴリズムは、入力凸型ニューラルネットワークとサイクル整合性正則化を使用してWasserstein-2距離を近似します。一般的なエントロピーおよび2次レギュラライザーとは対照的に、サイクルの一貫性はバイアスを導入せず、高次元に適切にスケーリングします。理論的な側面から、アルゴリズムによって適合された生成マッピングのプロパティを推定します。実用的な側面から、画像から画像への色の転送、潜在空間の最適な転送、画像から画像へのスタイルの転送、ドメインの適応など、幅広いタスクでアルゴリズムを評価します。,6.33,https://d3i71xaburhd42.cloudfront.net/c7f8a4b90aaabe1033d66ef7cf4b386db4e11f0f/1-Figure1-1.png
Shapley Explanation Networks,"['Rui Wang', 'Xiaoqian Wang', 'David I. Inouye']",https://openreview.net/forum?id=vsU0efpivw,"Shapley values have become one of the most popular feature attribution explanation methods. However, most prior work has focused on post-hoc Shapley explanations, which can be computationally demanding (exponential time complexity) and preclude model regularization based on Shapley explanations during training. Thus, we propose to incorporate Shapley values themselves as latent representations in deep models---thereby making Shapley explanations first-class citizens in the modeling paradigm. This intrinsic explanation approach enables layer-wise explanations, explanation regularization of the model during training, and fast explanation computation at test time. We define the Shapley transform that transforms the input into a Shapley representation given a specific function. We operationalize the Shapley transform as a neural network module and construct both shallow and deep networks, called ShapNets, by composing Shapley modules. We prove that our Shallow ShapNets compute the exact Shapley values and our Deep ShapNets maintain the missingness and accuracy properties of Shapley values. We demonstrate on synthetic and real-world datasets that our ShapNets enable layer-wise Shapley explanations, novel Shapley regularizations during training, and fast computation while maintaining reasonable performance. Code is available at https://www.github.com/RuiWang1998/ShapleyExplanationNetworks.",シャープレイ値は、最も一般的な機能属性の説明方法の1つになっています。ただし、これまでのほとんどの作業は、計算量が多く（指数関数的な時間計算量）、トレーニング中のShapleyの説明に基づくモデルの正則化を妨げる可能性のある事後のShapleyの説明に焦点を当てていました。したがって、我々は、シャープレイ値自体を深いモデルの潜在的表現として組み込むことを提案し、それによって、モデリングパラダイムでシャープレイ説明を第一級市民にします。この本質的な説明アプローチにより、層ごとの説明、トレーニング中のモデルの説明の正則化、およびテスト時の高速な説明の計算が可能になります。特定の関数を指定して、入力をシャープレイ表現に変換するシャープレイ変換を定義します。 Shapley変換をニューラルネットワークモジュールとして運用し、Shapleyモジュールを構成することにより、ShapNetsと呼ばれる浅いネットワークと深いネットワークの両方を構築します。浅いShapNetが正確なShapley値を計算し、DeepShapNetがShapley値の欠落と精度のプロパティを維持していることを証明します。合成データセットと実世界のデータセットで、ShapNetがレイヤーごとのShapleyの説明、トレーニング中の新しいShapleyの正則化、および妥当なパフォーマンスを維持しながら高速な計算を可能にすることを示します。コードはhttps://www.github.com/RuiWang1998/ShapleyExplanationNetworksで入手できます。,6.33,
The Importance of Pessimism in Fixed-Dataset Policy Optimization,"['Jacob Buckman', 'Carles Gelada', 'Marc G Bellemare']",https://openreview.net/forum?id=E3Ys6a1NTGT,"We study worst-case guarantees on the expected return of fixed-dataset policy optimization algorithms. Our core contribution is a unified conceptual and mathematical framework for the study of algorithms in this regime. This analysis reveals that for naive approaches, the possibility of erroneous value overestimation leads to a difficult-to-satisfy requirement: in order to guarantee that we select a policy which is near-optimal, we may need the dataset to be informative of the value of every policy. To avoid this, algorithms can follow the pessimism principle, which states that we should choose the policy which acts optimally in the worst possible world. We show why pessimistic algorithms can achieve good performance even when the dataset is not informative of every policy, and derive families of algorithms which follow this principle. These theoretical findings are validated by experiments on a tabular gridworld, and deep learning experiments on four MinAtar environments.",固定データセットポリシー最適化アルゴリズムの期待収益に関する最悪の場合の保証を調査します。私たちの中心的な貢献は、この体制におけるアルゴリズムの研究のための統一された概念的および数学的フレームワークです。この分析により、ナイーブなアプローチの場合、誤った値の過大評価の可能性が要件を満たすのが困難になることが明らかになります。最適に近いポリシーを選択することを保証するために、データセットに値を通知する必要がある場合があります。すべてのポリシーの。これを回避するために、アルゴリズムは悲観論の原則に従うことができます。悲観論の原則では、最悪の世界で最適に機能するポリシーを選択する必要があります。データセットがすべてのポリシーについて情報を提供しているわけではない場合でも、悲観的なアルゴリズムが優れたパフォーマンスを達成できる理由を示し、この原則に従うアルゴリズムのファミリーを導き出します。これらの理論的発見は、表形式のグリッドワールドでの実験、および4つのMinAtar環境での深層学習実験によって検証されます。,6.33,https://d3i71xaburhd42.cloudfront.net/86fa0f350b0ede3a86e31aa2900af551531ee570/2-Figure1-1.png
Characterizing signal propagation to close the performance gap in unnormalized ResNets,"['Andrew Brock', 'Soham De', 'Samuel L Smith']",https://openreview.net/forum?id=IX3Nnir2omJ,"Batch Normalization is a key component in almost all state-of-the-art image classifiers, but it also introduces practical challenges: it breaks the independence between training examples within a batch, can incur compute and memory overhead, and often results in unexpected bugs. Building on recent theoretical analyses of deep ResNets at initialization, we propose a simple set of analysis tools to characterize signal propagation on the forward pass, and leverage these tools to design highly performant ResNets without activation normalization layers.  Crucial to our success is an adapted version of the recently proposed Weight Standardization.  Our analysis tools show how this technique preserves the signal in ReLU networks by ensuring that the per-channel activation means do not grow with depth. Across a range of FLOP budgets, our networks attain performance competitive with state-of-the-art EfficientNets on ImageNet.",バッチ正規化は、ほとんどすべての最先端の画像分類器の重要なコンポーネントですが、実用的な課題ももたらします。バッチ内のトレーニング例間の独立性が失われ、計算とメモリのオーバーヘッドが発生し、予期しないバグが発生することがよくあります。 。初期化時のディープResNetの最近の理論的分析に基づいて、フォワードパスでの信号伝搬を特徴付ける単純な分析ツールのセットを提案し、これらのツールを活用して、アクティブ化正規化レイヤーなしで高性能のResNetを設計します。私たちの成功にとって重要なのは、最近提案された重量標準化の適応バージョンです。私たちの分析ツールは、チャネルごとのアクティブ化手段が深さとともに成長しないようにすることで、この手法がReLUネットワークの信号をどのように保持するかを示しています。さまざまなFLOP予算全体で、当社のネットワークはImageNet上の最先端のEfficientNetと競争力のあるパフォーマンスを実現しています。,6.33,https://d3i71xaburhd42.cloudfront.net/feeae38fd404fdc17cad19d80461843059216fde/3-Figure1-1.png
Explainable Deep One-Class Classification,"['Philipp Liznerski', 'Lukas Ruff', 'Robert A. Vandermeulen', 'Billy Joe Franks', 'Marius Kloft', 'Klaus Robert Muller']",https://openreview.net/forum?id=A5VV3UyIQz,"Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.",異常検出のための深い1クラス分類バリアントは、名目上のサンプルを特徴空間に集中させて異常をマッピングするマッピングを学習します。この変換は非常に非線形であるため、解釈を見つけることは重要な課題となります。この論文では、説明可能な深い1クラス分類法である完全畳み込みデータ記述（FCDD）を提示します。ここで、マップされたサンプル自体も説明ヒートマップです。 FCDDは、競争力のある検出パフォーマンスを実現し、CIFAR-10およびImageNetを使用した一般的な異常検出ベンチマークに関する合理的な説明を提供します。グラウンドトゥルースアノマリーマップを提供する最近の製造データセットであるMVTec-ADで、FCDDは監視されていない設定で新しい最先端技術を設定します。私たちの方法では、トレーニング中にグラウンドトゥルース異常マップを組み込むことができ、これらのいくつか（5）を使用するだけでもパフォーマンスが大幅に向上します。最後に、FCDDの説明を使用して、画像透かしなどの偽の画像特徴に対する深い1クラス分類モデルの脆弱性を示します。,6.33,https://d3i71xaburhd42.cloudfront.net/16a67491ed4bdb6293d1c2be35b0e8bae962cdeb/2-Figure1-1.png
A Learning Theoretic Perspective on Local Explainability,"['Jeffrey Li', 'Vaishnavh Nagarajan', 'Gregory Plumb', 'Ameet Talwalkar']",https://openreview.net/forum?id=7aL-OtQrBWD,"In this paper, we explore connections between interpretable machine learning and learning theory through the lens of local approximation explanations. First, we tackle the traditional problem of performance generalization and bound the test-time accuracy of a model using a notion of how locally explainable it is. Second, we explore the novel problem of explanation generalization which is an important concern for a growing class of finite sample-based local approximation explanations. Finally, we validate our theoretical results empirically and show that they reflect what can be seen in practice. ",この論文では、局所近似説明のレンズを通して、解釈可能な機械学習と学習理論の関係を探ります。まず、パフォーマンスの一般化という従来の問題に取り組み、モデルがローカルで説明できるという概念を使用して、モデルのテスト時の精度を制限します。次に、説明の一般化の新しい問題を調査します。これは、有限サンプルベースの局所近似説明のクラスが増えているために重要な懸念事項です。最後に、理論的な結果を経験的に検証し、実際に見られるものを反映していることを示します。,6.33,
X2T: Training an X-to-Text Typing Interface with Online Learning from User Feedback,"['Jensen Gao', 'Siddharth Reddy', 'Glen Berseth', 'Anca Dragan', 'Sergey Levine']",https://openreview.net/forum?id=LiX3ECzDPHZ,"We aim to help users communicate their intent to machines using flexible, adaptive interfaces that translate arbitrary user input into desired actions. In this work, we focus on assistive typing applications in which a user cannot operate a keyboard, but can instead supply other inputs, such as webcam images that capture eye gaze. Standard methods train a model on a fixed dataset of user inputs, then deploy a static interface that does not learn from its mistakes; in part, because extracting an error signal from user behavior can be challenging. We investigate a simple idea that would enable such interfaces to improve over time, with minimal additional effort from the user: online learning from user feedback on the accuracy of the interface's actions. In the typing domain, we leverage backspaces as feedback that the interface did not perform the desired action. We propose an algorithm called x-to-text (X2T) that trains a predictive model of this feedback signal, and uses this model to fine-tune any existing, default interface for translating user input into actions that select words or characters. We evaluate X2T through a small-scale online user study with 12 participants who type sentences by gazing at their desired words, and a large-scale observational study on handwriting samples from 60 users. The results show that X2T learns to outperform a non-adaptive default interface, stimulates user co-adaptation to the interface, personalizes the interface to individual users, and can leverage offline data collected from the default interface to improve its initial performance and accelerate online learning.",私たちは、ユーザーが任意のユーザー入力を目的のアクションに変換する柔軟で適応性のあるインターフェイスを使用して、ユーザーがマシンに意図を伝えるのを支援することを目指しています。この作業では、ユーザーがキーボードを操作できず、代わりに視線をキャプチャするWebカメラ画像などの他の入力を提供できる補助タイピングアプリケーションに焦点を当てます。標準的な方法では、ユーザー入力の固定データセットでモデルをトレーニングしてから、その間違いから学習しない静的インターフェイスをデプロイします。一部には、ユーザーの行動からエラー信号を抽出するのは難しい場合があるためです。ユーザーからの追加の労力を最小限に抑えながら、このようなインターフェースを時間の経過とともに改善できるようにする簡単なアイデアを調査します。インターフェースアクションの精度に関するユーザーフィードバックからのオンライン学習です。タイピングドメインでは、インターフェイスが目的のアクションを実行しなかったというフィードバックとしてバックスペースを活用します。このフィードバック信号の予測モデルをトレーニングするx-to-text（X2T）と呼ばれるアルゴリズムを提案し、このモデルを使用して、ユーザー入力を単語または文字を選択するアクションに変換するための既存のデフォルトインターフェイスを微調整します。 X2Tは、12人の参加者が希望の単語を見つめて文章を入力する小規模なオンラインユーザー調査と、60人のユーザーからの手書きサンプルに関する大規模な観察調査を通じて評価されます。結果は、X2Tが非適応型のデフォルトのインターフェースよりも優れていることを学習し、ユーザーのインターフェースへの共適応を刺激し、インターフェースを個々のユーザーに合わせてパーソナライズし、デフォルトのインターフェースから収集されたオフラインデータを活用して、初期パフォーマンスを向上させ、オンライン学習を加速できることを示しています。 。,6.33,
Learning from Demonstration with Weakly Supervised Disentanglement,"['Yordan Hristov', 'Subramanian Ramamoorthy']",https://openreview.net/forum?id=Ldau9eHU-qO,"Robotic manipulation tasks, such as wiping with a soft sponge, require control from multiple rich sensory modalities. Human-robot interaction, aimed at teaching robots, is difficult in this setting as there is potential for mismatch between human and machine comprehension of the rich data streams. We treat the task of interpretable learning from demonstration as an optimisation problem over a probabilistic generative model. To account for the high-dimensionality of the data, a high-capacity neural network is chosen to represent the model. The latent variables in this model are explicitly aligned with high-level notions and concepts that are manifested in a set of demonstrations. We show that such alignment is best achieved through the use of labels from the end user, in an appropriately restricted vocabulary, in contrast to the conventional approach of the designer picking a prior over the latent variables. Our approach is evaluated in the context of a table-top robot manipulation task performed by a PR2 robot -- that of dabbing liquids with a sponge (forcefully pressing a sponge and moving it along a surface). The robot provides visual information, arm joint positions and arm joint efforts. We have made videos of the task and data available - see supplementary materials at: https://sites.google.com/view/weak-label-lfd.",柔らかいスポンジで拭くなどのロボット操作タスクには、複数の豊富な感覚モダリティからの制御が必要です。ロボットを教えることを目的とした人間とロボットの相互作用は、豊富なデータストリームの人間と機械の理解の間に不一致が生じる可能性があるため、この設定では困難です。デモンストレーションからの解釈可能な学習のタスクを、確率的生成モデルに対する最適化問題として扱います。データの高次元性を説明するために、モデルを表すために大容量のニューラルネットワークが選択されます。このモデルの潜在変数は、一連のデモンストレーションで明示されている高レベルの概念および概念と明示的に整合しています。このような配置は、潜在変数よりも優先順位を選択する設計者の従来のアプローチとは対照的に、適切に制限された語彙でエンドユーザーからのラベルを使用することによって最もよく達成されることを示します。私たちのアプローチは、PR2ロボットによって実行される卓上ロボット操作タスクのコンテキストで評価されます。これは、スポンジで液体を軽くたたく（スポンジを強く押して表面に沿って動かす）ものです。ロボットは、視覚情報、腕の関節の位置、腕の関節の動きを提供します。タスクとデータのビデオを利用できるようにしました。https：//sites.google.com/view/weak-label-lfdの補足資料を参照してください。,6.33,https://d3i71xaburhd42.cloudfront.net/b3322bb657d5750bfa1b16415d4e65c08f5524fb/2-Figure1-1.png
The Recurrent Neural Tangent Kernel,"['Sina Alemohammad', 'Zichao Wang', 'Randall Balestriero', 'Richard Baraniuk']",https://openreview.net/forum?id=3T9iFICe0Y9,"The study of deep neural networks (DNNs) in the infinite-width limit, via the so-called neural tangent kernel (NTK) approach, has provided new insights into the dynamics of learning, the capacity of generalization, and the impact of initialization. One key DNN architecture remains to be kernelized, namely, the recurrent neural network (RNN). In this paper we introduce and study the Recurrent Neural Tangent Kernel (RNTK), which provides new insights into the behavior of overparametrized RNNs, including how different time steps are weighted by the RNTK to form the output under different initialization parameters and nonlinearity choices, and how inputs of different lengths are treated. The ability to compare inputs of different length is a key property of the RNTK that should greatly benefit practitioners. We demonstrate via a synthetic and 53 real-world data experiments that the RNTK offers significant performance gains over other kernels, including standard NTKs, across a wide array of data sets. ",いわゆるニューラルタンジェントカーネル（NTK）アプローチを介した、無限幅の制限におけるディープニューラルネットワーク（DNN）の研究は、学習のダイナミクス、一般化の能力、および初期化の影響に関する新しい洞察を提供しました。 1つの重要なDNNアーキテクチャ、つまりリカレントニューラルネットワーク（RNN）はまだカーネル化されていません。このホワイトペーパーでは、リカレントニューラルタンジェントカーネル（RNTK）を紹介および調査します。これは、さまざまな初期化パラメーターと非線形性の選択の下で出力を形成するために、さまざまな時間ステップがRNTKによってどのように重み付けされるかなど、パラメーター化されたRNNの動作に関する新しい洞察を提供します。異なる長さの入力がどのように扱われるか。異なる長さの入力を比較する機能は、実践者に大きな利益をもたらすRNTKの重要な特性です。合成および53の実世界のデータ実験を通じて、RNTKが、さまざまなデータセットにわたって、標準のNTKを含む他のカーネルよりも大幅にパフォーマンスが向上することを示します。,6.33,https://d3i71xaburhd42.cloudfront.net/53416f6ee0d87be5a874bb520e262e711844cf47/3-Figure1-1.png
Simple Augmentation Goes a Long Way: ADRL for DNN Quantization,"['Lin Ning', 'Guoyang Chen', 'Weifeng Zhang', 'Xipeng Shen']",https://openreview.net/forum?id=Qr0aRliE_Hb,"Mixed precision quantization improves DNN performance by assigning different layers with different bit-width values. Searching for the optimal bit-width for each layer, however, remains a challenge. Deep Reinforcement Learning (DRL) shows some recent promise. It however suffers instability due to function approximation errors, causing large variances in the early training stages, slow convergence, and suboptimal policies in the mixed-precision quantization problem. This paper proposes augmented DRL (ADRL) as a way to alleviate these issues. This new strategy augments the neural networks in DRL with a complementary scheme to boost the performance of learning. The paper examines the effectiveness of ADRL both analytically and empirically, showing that it can produce more accurate quantized models than the state of the art DRL-based quantization while improving the learning speed by 4.5-64 times. ",混合精度の量子化は、異なるビット幅の値で異なるレイヤーを割り当てることにより、DNNのパフォーマンスを向上させます。ただし、各層に最適なビット幅を検索することは依然として課題です。深層強化学習（DRL）は、最近のいくつかの可能性を示しています。ただし、関数近似誤差のために不安定になり、トレーニングの初期段階で大きな分散が発生し、収束が遅くなり、混合精度の量子化問題でポリシーが最適化されなくなります。このホワイトペーパーでは、これらの問題を軽減する方法として、拡張DRL（ADRL）を提案します。この新しい戦略は、学習のパフォーマンスを向上させるための補完的なスキームでDRLのニューラルネットワークを強化します。このホワイトペーパーでは、ADRLの有効性を分析的および経験的に検証し、学習速度を4.5〜64倍向上させながら、最先端のDRLベースの量子化よりも正確な量子化モデルを生成できることを示しています。,6.33,
Projected Latent Markov Chain Monte Carlo: Conditional Sampling of Normalizing Flows,"['Chris Cannella', 'Mohammadreza Soltani', 'Vahid Tarokh']",https://openreview.net/forum?id=MBpHUFrcG2x,"We introduce Projected Latent Markov Chain Monte Carlo (PL-MCMC), a technique for sampling from the exact conditional distributions learned by normalizing flows. As a conditional sampling method, PL-MCMC enables Monte Carlo Expectation Maximization (MC-EM) training of normalizing flows from incomplete data. Through experimental tests applying normalizing flows to missing data tasks for a variety of data sets, we demonstrate the efficacy of PL-MCMC for conditional sampling from normalizing flows.",フローを正規化することによって学習された正確な条件付き分布からサンプリングする手法である、射影潜在マルコフ連鎖モンテカルロ（PL-MCMC）を紹介します。条件付きサンプリング方法として、PL-MCMCは、不完全なデータからのフローを正規化するモンテカルロ期待値最大化（MC-EM）トレーニングを可能にします。さまざまなデータセットの欠落データタスクに正規化フローを適用する実験テストを通じて、正規化フローからの条件付きサンプリングに対するPL-MCMCの有効性を示します。,6.33,
Generating Adversarial Computer Programs using Optimized Obfuscations,"['Shashank Srikant', 'Sijia Liu', 'Tamara Mitrovska', 'Shiyu Chang', 'Quanfu Fan', 'Gaoyuan Zhang', ""Una-May O'Reilly""]",https://openreview.net/forum?id=PH5PH9ZO_4,"Machine learning (ML) models that learn and predict properties of computer programs are increasingly being adopted and deployed. 
These models have demonstrated success in applications such as auto-completing code, summarizing large programs, and detecting bugs and malware in programs. 
In this work, we investigate principled ways to adversarially perturb a computer program to fool such learned models, and thus determine their adversarial robustness. We use program obfuscations, which have conventionally been used to avoid attempts at reverse engineering programs, as adversarial perturbations. These perturbations modify programs in ways that do not alter their functionality but can be crafted to deceive an ML model when making a decision. We provide a general formulation for an adversarial program that allows applying multiple obfuscation transformations to a program in any language. We develop first-order optimization algorithms to  efficiently determine two key aspects -- which parts of the program to transform, and what transformations to use. We show that it is important to optimize both these aspects to generate the best adversarially perturbed program. Due to the discrete nature of this problem, we also propose using randomized smoothing to improve the attack loss landscape to ease optimization. 
We evaluate our work on Python and Java programs on the problem of program summarization. 
We show that our best attack proposal achieves a $52\%$ improvement over a state-of-the-art attack generation approach for programs trained on a \textsc{seq2seq} model.
We further show that our formulation is better at training models that are robust to adversarial attacks.",コンピュータープログラムのプロパティを学習および予測する機械学習（ML）モデルは、ますます採用および展開されています。これらのモデルは、コードの自動補完、大規模なプログラムの要約、プログラム内のバグやマルウェアの検出などのアプリケーションで成功を収めています。この作業では、コンピュータプログラムを敵対的に混乱させて、そのような学習済みモデルをだますための原理的な方法を調査し、敵対的な堅牢性を判断します。敵対的な摂動として、リバースエンジニアリングプログラムの試みを回避するために従来使用されてきたプログラムの難読化を使用します。これらの摂動は、機能を変更しない方法でプログラムを変更しますが、決定を下すときにMLモデルを欺くように作成できます。複数の難読化変換を任意の言語のプログラムに適用できるようにする、敵対的なプログラムの一般的な定式化を提供します。プログラムのどの部分を変換するか、およびどの変換を使用するかという2つの重要な側面を効率的に決定するために、1次最適化アルゴリズムを開発します。敵対的に混乱した最良のプログラムを生成するには、これらの両方の側面を最適化することが重要であることを示します。この問題は離散的であるため、ランダム化された平滑化を使用して攻撃損失の状況を改善し、最適化を容易にすることも提案します。プログラムの要約の問題について、PythonおよびJavaプログラムでの作業を評価します。私たちの最良の攻撃提案は、SEQ2SEQモデルでトレーニングされたプログラムに対して、最先端の攻撃生成アプローチよりも52％向上することを示しています。さらに、敵対的攻撃に対してロバストなトレーニングモデルで私たちの定式化が優れていることを示します。,6.33,
Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks,"['Shikuang Deng', 'Shi Gu']",https://openreview.net/forum?id=FZ1oTwcXchK,"Spiking neural networks (SNNs) are biology-inspired artificial neural networks (ANNs) that comprise of spiking neurons to process asynchronous discrete signals. While more efficient in power consumption and inference speed on the neuromorphic hardware, SNNs are usually difficult to train directly from scratch with spikes due to the discreteness. As an alternative, many efforts have been devoted to converting conventional ANNs into SNNs by copying the weights from ANNs and adjusting the spiking threshold potential of neurons in SNNs. Researchers have designed new SNN architectures and conversion algorithms to diminish the conversion error. However, an effective conversion should address the difference between the SNN and ANN architectures with an efficient approximation on the loss function, which is missing in the field. In this work, we analyze the conversion error by recursive reduction to layer-wise summation and propose a novel strategic pipeline that transfers the weights to the target SNN by combining threshold balance and soft-reset mechanisms. This pipeline enables almost no accuracy loss between the converted SNNs and conventional ANNs with only $\sim1/10$ of the typical SNN simulation time. Our method is promising to get implanted onto embedded platforms with better support of SNNs with limited energy and memory.",スパイキングニューラルネットワーク（SNN）は、生物学に着想を得た人工ニューラルネットワーク（ANN）であり、非同期の離散信号を処理するためのスパイキングニューロンで構成されています。ニューロモーフィックハードウェアでの消費電力と推論速度はより効率的ですが、SNNは通常、離散性のためにスパイクを使用して最初から直接トレーニングすることは困難です。別の方法として、ANNから重みをコピーし、SNN内のニューロンのスパイクしきい値ポテンシャルを調整することにより、従来のANNをSNNに変換することに多くの努力が注がれています。研究者は、変換エラーを減らすために、新しいSNNアーキテクチャと変換アルゴリズムを設計しました。ただし、効果的な変換では、SNNアーキテクチャとANNアーキテクチャの違いに対処し、現場で欠落している損失関数を効率的に近似する必要があります。この作業では、レイヤーごとの合計への再帰的削減による変換エラーを分析し、しきい値バランスとソフトリセットメカニズムを組み合わせることによって重みをターゲットSNNに転送する新しい戦略的パイプラインを提案します。このパイプラインにより、変換されたSNNと従来のANNの間で、通常のSNNシミュレーション時間のわずか1/10で精度がほとんど失われません。私たちの方法は、限られたエネルギーとメモリでSNNをより適切にサポートする組み込みプラットフォームに移植されることを約束しています。,6.33,
Adversarially Guided Actor-Critic,"['Yannis Flet-Berliac', 'Johan Ferret', 'Olivier Pietquin', 'Philippe Preux', 'Matthieu Geist']",https://openreview.net/forum?id=_mQp5cr_iNy,"Despite definite success in deep reinforcement learning problems, actor-critic algorithms are still confronted with sample inefficiency in complex environments. These methods consider a policy (the actor) and a value (the critic) whose respective losses are obtained using different motivations and approaches. We introduce a third protagonist, the adversary. While this adversary mimics the actor by minimizing the KL-divergence between their respective action distributions, the actor maximizes the log-probability difference between its action and that of the adversary in combination with maximizing expected rewards. This novel objective stimulates the actor to follow strategies that could not have been correctly predicted from previous trajectories, making its behavior innovative in tasks where the reward is extremely rare. Our experimental analysis shows that the resulting Adversarially Guided Actor-Critic (AGAC) algorithm leads to more exhaustive exploration. Notably, AGAC outperforms current state-of-the-art methods on a set of various hard-exploration and procedurally-generated tasks.",深層強化学習の問題で確実に成功したにもかかわらず、アクタークリティカルなアルゴリズムは、複雑な環境でのサンプルの非効率性に依然として直面しています。これらの方法は、異なる動機とアプローチを使用してそれぞれの損失が得られるポリシー（アクター）と値（批評家）を考慮します。 3番目の主人公である敵を紹介します。この敵は、それぞれのアクション分布間のKL発散を最小化することによってアクターを模倣しますが、アクターは、期待される報酬を最大化することと組み合わせて、そのアクションと敵のアクションとの間の対数確率の差を最大化します。この新しい目的は、以前の軌道からは正しく予測できなかった戦略に従うように俳優を刺激し、報酬が非常にまれなタスクでその行動を革新的にします。私たちの実験的分析は、結果として得られるAdversarially Guided Actor-Critic（AGAC）アルゴリズムがより徹底的な調査につながることを示しています。特に、AGACは、さまざまなハード探索および手続き型生成タスクのセットで、現在の最先端の方法よりも優れています。,6.33,
Implicit Gradient Regularization,"['David Barrett', 'Benoit Dherin']",https://openreview.net/forum?id=3q5IqUrkcF,"Gradient descent can be surprisingly good at optimizing deep neural networks without overfitting and without explicit regularization. We find that the discrete steps of gradient descent implicitly regularize models by penalizing gradient descent trajectories that have large loss gradients. We call this Implicit Gradient Regularization (IGR) and we use backward error analysis to calculate the size of this regularization. We confirm empirically that implicit gradient regularization biases gradient descent toward flat minima, where test errors are small and solutions are robust to noisy parameter perturbations. Furthermore, we demonstrate that the implicit gradient regularization term can be used as an explicit regularizer, allowing us to control this gradient regularization directly. More broadly, our work indicates that backward error analysis is a useful theoretical approach to the perennial question of how learning rate, model size, and parameter regularization interact to determine the properties of overparameterized models optimized with gradient descent.",最急降下法は、過剰適合や明示的な正則化を行わずに、ディープニューラルネットワークを最適化するのに驚くほど優れています。勾配降下の離散ステップは、大きな損失勾配を持つ勾配降下軌道にペナルティを課すことにより、モデルを暗黙的に正則化することがわかります。これを陰的勾配正則化（IGR）と呼び、後方誤差分析を使用してこの正則化のサイズを計算します。暗黙の勾配正則化が勾配降下を平坦な最小値に偏らせることを経験的に確認します。この場合、テストエラーは小さく、解はノイズの多いパラメーターの摂動に対してロバストです。さらに、暗黙的な勾配正則化項を明示的な正則化として使用できることを示し、この勾配正則化を直接制御できるようにします。より広義には、後方誤差分析は、学習率、モデルサイズ、およびパラメーターの正則化が相互作用して、勾配降下法で最適化されたパラメーター過剰モデルのプロパティを決定するという長年の問題に対する有用な理論的アプローチであることを示しています。,6.33,https://d3i71xaburhd42.cloudfront.net/ac1a4df77afea1ac868eb32f9d970d58f64640a1/5-Figure1-1.png
Learning Neural Generative Dynamics for Molecular Conformation Generation,"['Minkai Xu', 'Shitong Luo', 'Yoshua Bengio', 'Jian Peng', 'Jian Tang']",https://openreview.net/forum?id=pAbm1qfheGk,"We study how to generate molecule conformations (\textit{i.e.}, 3D structures) from a molecular graph. Traditional methods, such as molecular dynamics, sample conformations via computationally expensive simulations. Recently, machine learning methods have shown great potential by training on a large collection of conformation data. Challenges arise from the limited model capacity for capturing complex distributions of conformations and the difficulty in modeling long-range dependencies between atoms. Inspired by the recent progress in deep generative models, in this paper, we propose a novel probabilistic framework to generate valid and diverse conformations given a molecular graph. We propose a method combining the advantages of both flow-based and energy-based models, enjoying: (1) a high model capacity to estimate the multimodal conformation distribution; (2) explicitly capturing the complex long-range dependencies between atoms in both hidden and observation space. Extensive experiments demonstrate the superior performance of the proposed method on several benchmarks, including conformation generation and distance modeling tasks, with a significant improvement over existing generative models for molecular conformation sampling.",分子グラフから分子コンフォメーション（3D構造）を生成する方法を研究します。分子動力学などの従来の方法では、計算コストの高いシミュレーションを介してコンフォメーションをサンプリングします。最近、機械学習手法は、コンフォメーションデータの大規模なコレクションをトレーニングすることで大きな可能性を示しています。立体配座の複雑な分布をキャプチャするための限られたモデル容量と、原子間の長距離依存性のモデル化の難しさから課題が生じます。深い生成モデルの最近の進歩に触発されて、この論文では、分子グラフが与えられた場合に有効で多様なコンフォメーションを生成するための新しい確率的フレームワークを提案します。フローベースモデルとエネルギーベースモデルの両方の利点を組み合わせて、次のことを楽しむ方法を提案します。（1）マルチモーダル配座分布を推定するための高いモデル容量。 （2）隠れ空間と観測空間の両方で原子間の複雑な長距離依存関係を明示的にキャプチャします。広範な実験により、コンフォメーション生成および距離モデリングタスクを含むいくつかのベンチマークで提案された方法の優れたパフォーマンスが実証され、分子コンフォメーションサンプリングの既存の生成モデルよりも大幅に改善されています。,6.33,
No MCMC for me: Amortized sampling for fast and stable training of energy-based models,"['Will Sussman Grathwohl', 'Jacob Jin Kelly', 'Milad Hashemi', 'Mohammad Norouzi', 'Kevin Swersky', 'David Duvenaud']",https://openreview.net/forum?id=ixpSxO9flk3,"Energy-Based Models (EBMs) present a flexible and appealing way to represent uncertainty. Despite recent advances, training EBMs on high-dimensional data remains a challenging problem as the state-of-the-art approaches are costly, unstable, and require considerable tuning and domain expertise to apply successfully. In this work, we present a simple method for training EBMs at scale which uses an entropy-regularized generator to amortize the MCMC sampling typically used in EBM training. We improve upon prior MCMC-based entropy regularization methods with a fast variational approximation. We demonstrate the effectiveness of our approach by using it to train tractable likelihood models. Next, we apply our estimator to the recently proposed Joint Energy Model (JEM), where we match the original performance with faster and stable training. This allows us to extend JEM models to semi-supervised classification on tabular data from a variety of continuous domains.",エネルギーベースモデル（EBM）は、不確実性を表すための柔軟で魅力的な方法を提供します。最近の進歩にもかかわらず、最先端のアプローチはコストがかかり、不安定であり、正常に適用するにはかなりの調整とドメインの専門知識が必要であるため、高次元データでEBMをトレーニングすることは依然として困難な問題です。この作業では、エントロピー正則化ジェネレーターを使用してEBMトレーニングで通常使用されるMCMCサンプリングを償却する、EBMを大規模にトレーニングするための簡単な方法を示します。高速変分近似を使用して、以前のMCMCベースのエントロピー正則化手法を改善します。扱いやすい尤度モデルをトレーニングするために使用することにより、アプローチの有効性を示します。次に、推定量を最近提案されたジョイントエネルギーモデル（JEM）に適用します。ここでは、元のパフォーマンスをより高速で安定したトレーニングと一致させます。これにより、JEMモデルを、さまざまな連続ドメインからの表形式データの半教師あり分類に拡張できます。,6.33,https://d3i71xaburhd42.cloudfront.net/af9f434a3cd6b232dd4ae32c39710fd86eb95931/2-Figure1-1.png
Multi-resolution modeling of a discrete stochastic process identifies causes of cancer,"['Adam Uri Yaari', 'Maxwell Sherman', 'Oliver Clarke Priebe', 'Po-Ru Loh', 'Boris Katz', 'Andrei Barbu', 'Bonnie Berger']",https://openreview.net/forum?id=KtH8W3S_RE,"Detection of cancer-causing mutations within the vast and mostly unexplored human genome is a major challenge. Doing so requires modeling the background mutation rate, a highly non-stationary stochastic process, across regions of interest varying in size from one to millions of positions. Here, we present the split-Poisson-Gamma (SPG) distribution, an extension of the classical Poisson-Gamma formulation, to model a discrete stochastic process at multiple resolutions. We demonstrate that the probability model has a closed-form posterior, enabling efficient and accurate linear-time prediction over any length scale after the parameters of the model have been inferred a single time. We apply our framework to model mutation rates in tumors and show that model parameters can be accurately inferred from high-dimensional epigenetic data using a convolutional neural network, Gaussian process, and maximum-likelihood estimation. Our method is both more accurate and more efficient than existing models over a large range of length scales. We demonstrate the usefulness of multi-resolution modeling by detecting genomic elements that drive tumor emergence and are of vastly differing sizes.",広大でほとんど未踏のヒトゲノム内の癌を引き起こす突然変異の検出は、主要な課題です。そのためには、1から数百万の位置までサイズが異なる関心領域全体で、非常に非定常的な確率過程であるバックグラウンド突然変異率をモデル化する必要があります。ここでは、複数の解像度で離散確率過程をモデル化するために、古典的なポアソン-ガンマ定式化の拡張である分割-ポアソン-ガンマ（SPG）分布を示します。確率モデルには閉形式の後方があり、モデルのパラメーターが1回推測された後、任意の長さスケールで効率的かつ正確な線形時間予測が可能になることを示します。フレームワークを腫瘍の突然変異率のモデル化に適用し、畳み込みニューラルネットワーク、ガウス過程、最尤推定を使用して、モデルパラメーターを高次元のエピジェネティックデータから正確に推測できることを示します。私たちの方法は、広範囲の長さスケールにわたって既存のモデルよりも正確で効率的です。腫瘍の出現を促進し、サイズが大きく異なるゲノム要素を検出することにより、多重解像度モデリングの有用性を示します。,6.33,
On Learning Universal Representations Across Languages,"['Xiangpeng Wei', 'Yue Hu', 'Rongxiang Weng', 'Luxi Xing', 'Heng Yu', 'Weihua Luo']",https://openreview.net/forum?id=Uu1Nw-eeTxJ,"Recent studies have demonstrated the overwhelming advantage of cross-lingual pre-trained models (PTMs), such as multilingual BERT and XLM, on cross-lingual NLP tasks. However, existing approaches essentially capture the co-occurrence among tokens through involving the masked language model (MLM) objective with token-level cross entropy. In this work, we extend these approaches to learn sentence-level representations, and show the effectiveness on cross-lingual understanding and generation. We propose Hierarchical Contrastive Learning (HiCTL) to (1) learn universal representations for parallel sentences distributed in one or multiple languages and (2) distinguish the semantically-related words from a shared cross-lingual vocabulary for each sentence. We conduct evaluations on two challenging cross-lingual tasks, XTREME and machine translation. Experimental results show that the HiCTL outperforms the state of the art XLM-R by an absolute gain of 1.3% accuracy on XTREME as well as achieves substantial improvements of +1.7~+3.6 BLEU on both the high-resource and low-resource English-X translation tasks over strong baselines.",最近の研究では、多言語BERTやXLMなどの多言語事前トレーニングモデル（PTM）が、言語間NLPタスクで圧倒的な利点を発揮することが示されています。ただし、既存のアプローチは基本的に、トークンレベルのクロスエントロピーでマスクされた言語モデル（MLM）の目的を含むことにより、トークン間の共起をキャプチャします。この作業では、これらのアプローチを拡張して文レベルの表現を学習し、言語間の理解と生成に対する有効性を示します。階層的対照学習（HiCTL）を提案して、（1）1つまたは複数の言語で分散された並列文の普遍的な表現を学習し、（2）意味的に関連する単語を各文の共有言語間語彙から区別します。 XTREMEと機械翻訳という2つの難しいクロスリンガルタスクの評価を行います。実験結果は、HiCTLが最先端のXLM-Rよりも絶対ゲイン1.3だけ優れていることを示しています。,6.33,https://d3i71xaburhd42.cloudfront.net/311909621177c397c6b7099beff32332124f7d46/3-Figure1-1.png
Multi-Class Uncertainty Calibration via Mutual Information Maximization-based Binning,"['Kanil Patel', 'William H. Beluch', 'Bin Yang', 'Michael Pfeiffer', 'Dan Zhang']",https://openreview.net/forum?id=AICNpd8ke-m,"Post-hoc multi-class calibration is a common approach for providing high-quality confidence estimates of deep neural network predictions. Recent work has shown that widely used scaling methods underestimate their calibration error, while alternative Histogram Binning (HB) methods often fail to preserve classification accuracy. When classes have small prior probabilities, HB also faces the issue of severe sample-inefficiency after the conversion into K one-vs-rest class-wise calibration problems. The goal of this paper is to resolve the identified issues of HB in order to provide calibrated confidence estimates using only a small holdout calibration dataset for bin optimization while preserving multi-class ranking accuracy. From an information-theoretic perspective, we derive the I-Max concept for binning, which maximizes the mutual information between labels and quantized logits. This concept mitigates potential loss in ranking performance due to lossy quantization, and by disentangling the optimization of bin edges and representatives allows simultaneous improvement of ranking and calibration performance. To improve the sample efficiency and estimates from a small calibration set, we propose a shared class-wise (sCW) calibration strategy, sharing one calibrator among similar classes (e.g., with similar class priors) so that the training sets of their class-wise calibration problems can be merged to train the single calibrator. The combination of sCW and I-Max binning outperforms the state of the art calibration methods on various evaluation metrics across different benchmark datasets and models, using a small calibration set (e.g., 1k samples for ImageNet).",事後マルチクラスキャリブレーションは、ディープニューラルネットワーク予測の高品質な信頼性推定を提供するための一般的なアプローチです。最近の研究では、広く使用されているスケーリング方法ではキャリブレーションエラーが過小評価されている一方で、代替のヒストグラムビニング（HB）方法では分類の精度を維持できないことがよくあります。クラスの事前確率が小さい場合、HBは、K個の1対残りのクラスごとのキャリブレーション問題に変換した後、深刻なサンプルの非効率性の問題にも直面します。このホワイトペーパーの目的は、HBの特定された問題を解決し、マルチクラスのランキング精度を維持しながら、ビンの最適化のために小さなホールドアウトキャリブレーションデータセットのみを使用してキャリブレーションされた信頼性推定を提供することです。情報理論の観点から、ラベルと量子化ロジット間の相互情報量を最大化するビニングのI-Maxコンセプトを導き出します。この概念は、不可逆量子化によるランキングパフォーマンスの潜在的な損失を軽減し、ビンエッジと代表の最適化を解くことにより、ランキングとキャリブレーションのパフォーマンスを同時に向上させることができます。小さなキャリブレーションセットからのサンプル効率と推定値を改善するために、共有クラスワイズ（sCW）キャリブレーション戦略を提案し、類似クラス間で1つのキャリブレーターを共有して（たとえば、類似クラスの事前確率を使用）、クラスワイズのトレーニングセットを作成します。キャリブレーションの問題をマージして、単一のキャリブレーターをトレーニングできます。 sCWとI-Maxのビニングの組み合わせは、小さなキャリブレーションセット（たとえば、ImageNetの1kサンプル）を使用して、さまざまなベンチマークデータセットおよびモデルにわたるさまざまな評価メトリックで最先端のキャリブレーション方法よりも優れています。,6.33,https://d3i71xaburhd42.cloudfront.net/0c926ad1764874e34584e06fa478a1c56cb627dc/2-Figure1-1.png
Improving relational regularized autoencoders with spherical sliced fused Gromov Wasserstein,"['Khai Nguyen', 'Son Nguyen', 'Nhat Ho', 'Tung Pham', 'Hung Bui']",https://openreview.net/forum?id=DiQD7FWL233,"Relational regularized autoencoder (RAE) is a framework to learn the distribution of data by minimizing a reconstruction loss together with a relational regularization on the prior of latent space. A recent attempt to reduce the inner discrepancy between the prior and aggregated posterior distributions is to incorporate sliced fused Gromov-Wasserstein (SFG) between these distributions. That approach has a weakness since it treats every slicing direction similarly, meanwhile several directions are not useful for the discriminative task. To improve the discrepancy and consequently the relational regularization, we propose a new relational discrepancy, named spherical sliced fused Gromov Wasserstein (SSFG), that can find an important area of projections characterized by a von Mises-Fisher distribution. Then, we introduce two variants of SSFG to improve its performance. The first variant, named mixture spherical sliced fused Gromov Wasserstein (MSSFG), replaces the vMF distribution by a mixture of von Mises-Fisher distributions to capture multiple important areas of directions that are far from each other. The second variant, named power spherical sliced fused Gromov Wasserstein (PSSFG), replaces the vMF distribution by a power spherical distribution to improve the sampling time of the vMF distribution in high dimension settings. We then apply the new discrepancies to the RAE framework to achieve its new variants. Finally, we conduct extensive experiments to show that the new autoencoders have favorable performance in learning latent manifold structure, image generation, and reconstruction.",リレーショナル正則化オートエンコーダー（RAE）は、潜在空間の事前確率でのリレーショナル正則化とともに再構成損失を最小化することにより、データの分布を学習するためのフレームワークです。前の分布と集約された事後分布の間の内部の不一致を減らす最近の試みは、これらの分布の間にスライスされた融合グロモフ-ワッサースタイン（SFG）を組み込むことです。このアプローチは、すべてのスライス方向を同様に扱うため、弱点がありますが、いくつかの方向は、識別タスクには役立ちません。不一致とその結果としての関係の正則化を改善するために、フォンミーゼス-フィッシャー分布によって特徴付けられる投影の重要な領域を見つけることができる、球形スライス融合グロモフワッサースタイン（SSFG）という名前の新しい関係の不一致を提案します。次に、パフォーマンスを向上させるためにSSFGの2つのバリアントを紹介します。混合球面スライス融合グロモフワッサースタイン（MSSFG）という名前の最初のバリアントは、vMF分布をフォンミーゼスフィッシャー分布の混合に置き換えて、互いに遠く離れた方向の複数の重要な領域をキャプチャします。パワー球面スライス融合グロモフワッサースタイン（PSSFG）という名前の2番目のバリアントは、vMF分布をパワー球面分布に置き換えて、高次元設定でのvMF分布のサンプリング時間を改善します。次に、新しい不一致をRAEフレームワークに適用して、新しいバリアントを実現します。最後に、広範な実験を行って、新しいオートエンコーダが潜在的な多様体構造、画像生成、および再構成の学習において好ましいパフォーマンスを発揮することを示します。,6.33,https://d3i71xaburhd42.cloudfront.net/129fed5e7c229b20efb9a0a07a4f7b403e147eb8/4-Figure1-1.png
Degree-Quant: Quantization-Aware Training for Graph Neural Networks,"['Shyam Anil Tailor', 'Javier Fernandez-Marques', 'Nicholas Donald Lane']",https://openreview.net/forum?id=NSBrFgJAHg,"Graph neural networks (GNNs) have demonstrated strong performance on a wide variety of tasks due to their ability to model non-uniform structured data. Despite their promise, there exists little research exploring methods to make them more efficient at inference time. In this work, we explore the viability of training quantized GNNs, enabling the usage of low precision integer arithmetic during inference. For GNNs seemingly unimportant choices in quantization implementation cause dramatic changes in performance. We identify the sources of error that uniquely arise when attempting to quantize GNNs, and propose an architecturally-agnostic and stable method, Degree-Quant, to improve performance over existing quantization-aware training baselines commonly used on other architectures, such as CNNs. We validate our method on six datasets and show, unlike previous quantization attempts, that models generalize to unseen graphs. Models trained with Degree-Quant for INT8 quantization perform as well as FP32 models in most cases; for INT4 models, we obtain up to 26% gains over the baselines. Our work enables up to 4.7x speedups on CPU when using INT8 arithmetic.",グラフニューラルネットワーク（GNN）は、不均一な構造化データをモデル化できるため、さまざまなタスクで強力なパフォーマンスを発揮します。それらの約束にもかかわらず、推論時にそれらをより効率的にする方法を探求する研究はほとんどありません。この作業では、量子化されたGNNのトレーニングの実行可能性を調査し、推論中に低精度の整数演算を使用できるようにします。 GNNの場合、量子化の実装で一見重要でないように見える選択は、パフォーマンスに劇的な変化を引き起こします。 GNNの量子化を試みるときに一意に発生するエラーの原因を特定し、アーキテクチャにとらわれない安定した方法であるDegree-Quantを提案して、CNNなどの他のアーキテクチャで一般的に使用される既存の量子化対応トレーニングベースラインよりもパフォーマンスを向上させます。 6つのデータセットでメソッドを検証し、以前の量子化の試みとは異なり、モデルが見えないグラフに一般化することを示します。 INT8量子化用にDegree-Quantでトレーニングされたモデルは、ほとんどの場合FP32モデルと同様に機能します。 INT4モデルの場合、最大26を取得します,6.33,https://d3i71xaburhd42.cloudfront.net/709610c36dd25c8546173558c7756846635c18bb/1-Figure1-1.png
PSTNet: Point Spatio-Temporal Convolution on Point Cloud Sequences,"['Hehe Fan', 'Xin Yu', 'Yuhang Ding', 'Yi Yang', 'Mohan Kankanhalli']",https://openreview.net/forum?id=O3bqkf_Puys,"Point cloud sequences are irregular and unordered in the spatial dimension while exhibiting regularities and order in the temporal dimension. Therefore, existing grid based convolutions for conventional video processing cannot be directly applied to spatio-temporal modeling of raw point cloud sequences. In this paper, we propose a point spatio-temporal (PST) convolution to achieve informative representations of point cloud sequences. The proposed PST convolution first disentangles space and time in point cloud sequences.  Then, a spatial convolution is employed to capture the local structure of points in the 3D space, and a temporal convolution is used to model the dynamics of the spatial regions along the time dimension.  Furthermore, we incorporate the proposed PST convolution into a deep network, namely PSTNet, to extract features of point cloud sequences in a hierarchical manner.  Extensive experiments on widely-used 3D action recognition and 4D semantic segmentation datasets demonstrate the effectiveness of PSTNet to model point cloud sequences.",点群シーケンスは、空間次元では不規則で順序付けられていませんが、時間次元では規則性と順序を示しています。したがって、従来のビデオ処理用の既存のグリッドベースの畳み込みを、生の点群シーケンスの時空間モデリングに直接適用することはできません。この論文では、点群シーケンスの有益な表現を実現するために、点時空間（PST）畳み込みを提案します。提案されたPST畳み込みは、最初に点群シーケンスの空間と時間を解きほぐします。次に、空間畳み込みを使用して3D空間内の点の局所構造をキャプチャし、時間畳み込みを使用して時間次元に沿った空間領域のダイナミクスをモデル化します。さらに、提案されたPST畳み込みをディープネットワーク、つまりPSTNetに組み込んで、点群シーケンスの特徴を階層的に抽出します。広く使用されている3Dアクション認識および4Dセマンティックセグメンテーションデータセットに関する広範な実験は、点群シーケンスをモデル化するためのPSTNetの有効性を示しています。,6.33,
Selectivity considered harmful: evaluating the causal impact of class selectivity in DNNs,"['Matthew L Leavitt', 'Ari S. Morcos']",https://openreview.net/forum?id=8nl0k08uMi,"The properties of individual neurons are often analyzed in order to understand the biological and artificial neural networks in which they're embedded. Class selectivity—typically defined as how different a neuron's responses are across different classes of stimuli or data samples—is commonly used for this purpose. However, it remains an open question whether it is necessary and/or sufficient for deep neural networks (DNNs) to learn class selectivity in individual units. We investigated the causal impact of class selectivity on network function by directly regularizing for or against class selectivity. Using this regularizer to reduce class selectivity across units in convolutional neural networks increased test accuracy by over 2% in ResNet18 and 1% in ResNet50 trained on Tiny ImageNet. For ResNet20 trained on CIFAR10 we could reduce class selectivity by a factor of 2.5 with no impact on test accuracy, and reduce it nearly to zero with only a small (~2%) drop in test accuracy. In contrast, regularizing to increase class selectivity significantly decreased test accuracy across all models and datasets. These results indicate that class selectivity in individual units is neither sufficient nor strictly necessary, and can even impair DNN performance. They also encourage caution when focusing on the properties of single units as representative of the mechanisms by which DNNs function.",個々のニューロンの特性は、それらが埋め込まれている生物学的および人工的なニューラルネットワークを理解するために分析されることがよくあります。クラス選択性は、通常、刺激またはデータサンプルの異なるクラス間でニューロンの応答がどのように異なるかとして定義され、この目的で一般的に使用されます。ただし、ディープニューラルネットワーク（DNN）が個々のユニットでクラスの選択性を学習する必要があるかどうか、および/または十分であるかどうかは未解決の問題です。クラス選択性を直接正則化することにより、ネットワーク機能に対するクラス選択性の因果的影響を調査しました。この正則化を使用して畳み込みニューラルネットワークのユニット間のクラス選択性を下げると、テストの精度が2以上向上しました。,6.33,https://d3i71xaburhd42.cloudfront.net/f60ce46af07db12e1540200ec0193ce1d8915d4e/4-Figure1-1.png
Conformation-Guided Molecular Representation with Hamiltonian Neural Networks,"['Ziyao Li', 'Shuwen Yang', 'Guojie Song', 'Lingsheng Cai']",https://openreview.net/forum?id=q-cnWaaoUTH,"Well-designed molecular representations (fingerprints) are vital to combine medical chemistry and deep learning. Whereas incorporating 3D geometry of molecules (i.e. conformations) in their representations seems beneficial, current 3D algorithms are still in infancy. In this paper, we propose a novel molecular representation algorithm which preserves 3D conformations of molecules with a Molecular Hamiltonian Network (HamNet). In HamNet, implicit positions and momentums of atoms in a molecule interact in the Hamiltonian Engine following the discretized Hamiltonian equations. These implicit coordinations are supervised with real conformations with translation- & rotation-invariant losses, and further used as inputs to the Fingerprint Generator, a message-passing neural network. Experiments show that the Hamiltonian Engine can well preserve molecular conformations, and that the fingerprints generated by HamNet achieve state-of-the-art performances on MoleculeNet, a standard molecular machine learning benchmark.",適切に設計された分子表現（指紋）は、医薬品化学と深層学習を組み合わせるために不可欠です。分子の3Dジオメトリ（つまりコンフォメーション）を表現に組み込むことは有益であるように思われますが、現在の3Dアルゴリズムはまだ初期段階にあります。この論文では、分子ハミルトニアンネットワーク（HamNet）を使用して分子の3Dコンフォメーションを保持する新しい分子表現アルゴリズムを提案します。 HamNetでは、分子内の原子の陰的な位置と運動量は、離散化されたハミルトニアン方程式に従ってハミルトニアンエンジンで相互作用します。これらの暗黙の調整は、平行移動および回転不変の損失を伴う実際のコンフォメーションで監視され、さらにメッセージパッシングニューラルネットワークである指紋ジェネレーターへの入力として使用されます。実験によると、ハミルトニアンエンジンは分子の立体配座を十分に保持でき、HamNetによって生成されたフィンガープリントは、標準的な分子機械学習ベンチマークであるMoleculeNetで最先端のパフォーマンスを実現します。,6.33,
WaNet - Imperceptible Warping-based Backdoor Attack,"['Tuan Anh Nguyen', 'Anh Tuan Tran']",https://openreview.net/forum?id=eEn8KTtJOx,"With the thriving of deep learning and the widespread practice of using pre-trained networks, backdoor attacks have become an increasing security threat drawing many research interests in recent years. A third-party model can be poisoned in training to work well in normal conditions but behave maliciously when a trigger pattern appears. However, the existing backdoor attacks are all built on noise perturbation triggers, making them noticeable to humans. In this paper, we instead propose using warping-based triggers. The proposed backdoor outperforms the previous methods in a human inspection test by a wide margin, proving its stealthiness. To make such models undetectable by machine defenders, we propose a novel training mode, called the ``noise mode. The trained networks successfully attack and bypass the state of the art defense methods on standard classification datasets, including MNIST, CIFAR-10, GTSRB, and CelebA. Behavior analyses show that our backdoors are transparent to network inspection, further proving this novel attack mechanism's efficiency.",ディープラーニングの繁栄と事前トレーニング済みネットワークの使用の普及により、バックドア攻撃はセキュリティの脅威になりつつあり、近年多くの研究関心を集めています。サードパーティモデルは、通常の状態で正常に機能するようにトレーニング中に中毒する可能性がありますが、トリガーパターンが表示されると悪意を持って動作します。ただし、既存のバックドア攻撃はすべてノイズ摂動トリガーに基づいて構築されているため、人間が目立つようになっています。この論文では、代わりにワーピングベースのトリガーを使用することを提案します。提案されたバックドアは、人間の検査テストで以前の方法を大幅に上回り、そのステルス性を証明しています。このようなモデルをマシンディフェンダーが検出できないようにするために、ノイズモードと呼ばれる新しいトレーニングモードを提案します。トレーニングを受けたネットワークは、MNIST、CIFAR-10、GTSRB、CelebAなどの標準的な分類データセットに対する最先端の防御方法を攻撃してバイパスします。動作分析は、バックドアがネットワーク検査に対して透過的であることを示しており、この新しい攻撃メカニズムの効率をさらに証明しています。,6.33,
Neural Network Extrapolations with G-invariances from a Single Environment,"['S Chandra Mouli', 'Bruno Ribeiro']",https://openreview.net/forum?id=7t1FcJUWhi3,"Despite —or maybe because of— their astonishing capacity to fit data, neural networks are believed to have difficulties extrapolating beyond training data distribution. This work shows that, for extrapolations based on finite transformation groups, a model’s inability to extrapolate is unrelated to its capacity. Rather, the shortcoming is inherited from a learning hypothesis: Examples not explicitly observed with infinitely many training examples have underspecified outcomes in the learner’s model. In order to endow neural networks with the ability to extrapolate over group transformations, we introduce a learning framework counterfactually-guided by the learning hypothesis that any group invariance to (known) transformation groups is mandatory even without evidence, unless the learner deems it inconsistent with the training data. Unlike existing invariance-driven methods for (counterfactual) extrapolations, this framework allows extrapolations from a single environment. Finally, we introduce sequence and image extrapolation tasks that validate our framework and showcase the shortcomings of traditional approaches.",データを適合させる驚くべき能力にもかかわらず、またはおそらくそのために、ニューラルネットワークはトレーニングデータ分布を超えて外挿するのが難しいと考えられています。この作業は、有限変換グループに基づく外挿の場合、外挿できないモデルはその容量とは無関係であることを示しています。むしろ、欠点は学習仮説から受け継がれています。無限に多くのトレーニング例で明示的に観察されていない例では、学習者モデルの結果が過小評価されています。ニューラルネットワークにグループ変換を推定する機能を与えるために、学習者が矛盾していると見なさない限り、（既知の）変換グループへのグループ不変性は必須であるという学習仮説に反事実的に導かれる学習フレームワークを導入しますトレーニングデータ。 （反事実的）外挿のための既存の不変性駆動型の方法とは異なり、このフレームワークは単一の環境からの外挿を可能にします。最後に、フレームワークを検証し、従来のアプローチの欠点を示すシーケンスおよび画像の外挿タスクを紹介します。,6.33,
Learning Reasoning Paths over Semantic Graphs for Video-grounded Dialogues,"['Hung Le', 'Nancy F. Chen', 'Steven Hoi']",https://openreview.net/forum?id=hPWj1qduVw8,"Compared to traditional visual question answering, video-grounded dialogues require additional reasoning over dialogue context to answer questions in a multi-turn setting. Previous approaches to video-grounded dialogues mostly use dialogue context as a simple text input without modelling the inherent information flows at the turn level. We propose to discover information flows among dialogue turns through a semantic graph constructed based on lexical components in each question and answer. We then introduce a new approach that learns to predict reasoning paths over this semantic graph. Our path prediction model predicts a path from the current turn through past dialogue turns that contain additional visual cues to answer the current question. Our reasoning model sequentially processes both visual and textual information through this reasoning path and the propagated features are used to generate the answer. Our experimental results demonstrate the effectiveness of our method and provide additional insights on how models use semantic dependencies in a dialogue context to retrieve visual cues.",従来の視覚的な質問応答と比較して、ビデオに基づいた対話では、マルチターン設定で質問に回答するために、対話コンテキストに関する追加の推論が必要です。ビデオベースのダイアログへの以前のアプローチは、ほとんどの場合、ターンレベルで固有の情報フローをモデル化せずに、ダイアログコンテキストを単純なテキスト入力として使用します。各質問と回答の語彙コンポーネントに基づいて構築されたセマンティックグラフを通じて、対話ターン間の情報フローを発見することを提案します。次に、このセマンティックグラフ上で推論パスを予測することを学習する新しいアプローチを紹介します。私たちのパス予測モデルは、現在のターンから、現在の質問に答えるための追加の視覚的な手がかりを含む過去のダイアログターンまでのパスを予測します。私たちの推論モデルは、この推論パスを介して視覚情報とテキスト情報の両方を順次処理し、伝播された機能を使用して回答を生成します。私たちの実験結果は、私たちの方法の有効性を示し、モデルが対話コンテキストでセマンティック依存関係を使用して視覚的な手がかりを取得する方法に関する追加の洞察を提供します。,6.33,
Direction Matters: On the Implicit Regularization Effect of Stochastic Gradient Descent with Moderate Learning Rate,"['Jingfeng Wu', 'Difan Zou', 'Vladimir Braverman', 'Quanquan Gu']",https://openreview.net/forum?id=3X64RLgzY6O,"Understanding the algorithmic regularization effect of stochastic gradient descent (SGD) is one of the key challenges in modern machine learning and deep learning theory. Most of the existing works, however, focus on very small or even infinitesimal learning rate regime, and fail to cover practical scenarios where the learning rate is moderate and annealing. In this paper, we make an initial attempt to characterize the particular regularization effect of SGD in the moderate learning rate regime by studying its behavior for optimizing an overparameterized linear regression problem. In this case, SGD and GD are known to converge to the unique minimum-norm solution; however, with the moderate and annealing learning rate, we show that they exhibit different directional bias: SGD converges along the large eigenvalue directions of the data matrix, while GD goes after the small eigenvalue directions. Furthermore, we show that such directional bias does matter when early stopping is adopted, where the SGD output is nearly optimal but the GD output is suboptimal. Finally, our theory explains several folk arts in practice used for SGD hyperparameter tuning, such as (1) linearly scaling the initial learning rate with batch size; and (2) overrunning SGD with high learning rate even when the loss stops decreasing.",確率的勾配降下法（SGD）のアルゴリズムの正則化効果を理解することは、現代の機械学習と深層学習理論における重要な課題の1つです。ただし、既存の作業のほとんどは、非常に小さい、またはごくわずかな学習率体制に焦点を合わせており、学習率が中程度でアニーリングしている実際のシナリオをカバーできていません。この論文では、パラメータが過剰な線形回帰問題を最適化するための動作を研究することにより、中程度の学習率レジームにおけるSGDの特定の正則化効果を特徴づける最初の試みを行います。この場合、SGDとGDは一意の最小ノルム解に収束することが知られています。ただし、中程度のアニーリング学習率では、それらが異なる方向バイアスを示すことを示します。SGDはデータ行列の大きな固有値方向に沿って収束し、GDは小さな固有値方向を追跡します。さらに、SGD出力はほぼ最適であるが、GD出力は最適ではない早期停止を採用する場合、このような方向バイアスが重要であることを示します。最後に、私たちの理論は、SGDハイパーパラメータ調整に実際に使用されるいくつかの民芸を説明しています。たとえば、（1）バッチサイズで初期学習率を線形にスケーリングします。 （2）損失が減少しなくなった場合でも、高い学習率でSGDをオーバーランします。,6.33,https://d3i71xaburhd42.cloudfront.net/89cd1a37012317393ad230ef3b93a286978649f0/2-Figure1-1.png
The Unreasonable Effectiveness of Patches in Deep Convolutional Kernels Methods,"['Louis THIRY', 'Michael Arbel', 'Eugene Belilovsky', 'Edouard Oyallon']",https://openreview.net/forum?id=aYuZO9DIdnn,"A recent line of work showed that  various forms of convolutional  kernel methods can be competitive with standard supervised deep convolutional networks on datasets like CIFAR-10, obtaining accuracies in the range of 87-90% while being more amenable to theoretical analysis. In this work, we highlight the importance of a data-dependent feature extraction step that is key to the obtain good performance in convolutional kernel methods. This step typically corresponds to a whitened dictionary of patches, and gives rise to a data-driven convolutional kernel methods.We extensively study its effect, demonstrating it is the key ingredient for high performance of these methods. Specifically, we show that one of the simplest instances of such kernel methods, based on a single layer of  image patches followed by a linear classifier is already obtaining classification accuracies on CIFAR-10 in the same range as previous more sophisticated convolutional kernel methods. We scale this method to the challenging ImageNet dataset, showing such a simple approach can exceed all existing non-learned representation methods. This is a new baseline for object recognition without representation learning methods, that  initiates the investigation of  convolutional kernel models  on ImageNet. We conduct experiments to analyze the dictionary that we used, our ablations showing they exhibit low-dimensional properties.",最近の一連の作業により、さまざまな形式の畳み込みカーネル法が、CIFAR-10などのデータセット上の標準の教師あり深い畳み込みネットワークと競合し、87〜90の範囲の精度が得られることが示されました。,6.25,
Model-Based Offline Planning,"['Arthur Argenson', 'Gabriel Dulac-Arnold']",https://openreview.net/forum?id=OMNB1G5xzd4,"Offline learning is a key part of making reinforcement learning (RL) useable in real systems. Offline RL looks at scenarios where there is data from a system's operation, but no direct access to the system when learning a policy. Recent work on training RL policies from offline data has shown results both with model-free policies learned directly from the data, or with planning on top of learnt models of the data. Model-free policies tend to be more performant, but are more opaque, harder to command externally, and less easy to integrate into larger systems. We propose an offline learner that generates a model that can be used to control the system directly through planning. This allows us to have easily controllable policies directly from data, without ever interacting with the system. We show the performance of our algorithm, Model-Based Offline Planning (MBOP) on a series of robotics-inspired tasks, and demonstrate its ability leverage planning to respect environmental constraints. We are able to find near-optimal polices for certain simulated systems from as little as 50 seconds of real-time system interaction, and create zero-shot goal-conditioned policies on a series of environments.",オフライン学習は、強化学習（RL）を実際のシステムで使用できるようにするための重要な部分です。オフラインRLは、システム操作からのデータはあるが、ポリシーを学習するときにシステムに直接アクセスできないシナリオを調べます。オフラインデータからRLポリシーをトレーニングする最近の作業では、データから直接学習したモデルフリーポリシー、または学習したデータモデルに基づいた計画の両方で結果が示されています。モデルフリーポリシーはパフォーマンスが向上する傾向がありますが、不透明性が高く、外部からのコマンドが難しく、大規模なシステムへの統合が容易ではありません。計画を通じて直接システムを制御するために使用できるモデルを生成するオフライン学習者を提案します。これにより、システムと対話することなく、データから直接簡単に制御できるポリシーを設定できます。ロボット工学に着想を得た一連のタスクでのアルゴリズムであるモデルベースオフライン計画（MBOP）のパフォーマンスを示し、環境の制約を尊重する計画を活用する能力を示します。わずか50秒のリアルタイムシステムインタラクションから、特定のシミュレートされたシステムにほぼ最適なポリシーを見つけ、一連の環境でゼロショットの目標条件付きポリシーを作成できます。,6.25,https://d3i71xaburhd42.cloudfront.net/3cb8e96faba73efa027fa858e2a78cd1fc3c6e4d/6-Figure1-1.png
Learning Better Structured Representations Using Low-rank Adaptive Label Smoothing,"['Asish Ghoshal', 'Xilun Chen', 'Sonal Gupta', 'Luke Zettlemoyer', 'Yashar Mehdad']",https://openreview.net/forum?id=5NsEIflpbSv,"Training with soft targets instead of hard targets has been shown to improve performance and calibration of deep neural networks. Label smoothing is popular way of computing soft targets, where one-hot encoding of a class is smoothed with a uniform distribution. Owing to its simplicity, it has found wide-spread use for training deep neural networks on a wide variety of tasks, ranging from image and text classification to machine translation and semantic parsing. Complementing recent empirical justification for label smoothing, we obtain PAC-Bayesian generalization bounds for label smoothing and show that the generalization error depends on choice of the noise (smoothing) distribution. Then we propose low-rank adaptive label smoothing (LORAS): a simple yet novel method for training with learned soft targets that generalizes label smoothing and adapts to the latent structure of the label space in structured prediction tasks. Specifically, we evaluate our method on task-oriented semantic parsing tasks and show that just by training with appropriately smoothed soft targets, one can improve the accuracy of models by as much as 2% and reduce calibration error by 55% as compared to vanilla label smoothing. Used in conjunction with pre-trained sequence-to-sequence models, our method achieves state of the art performance on three semantic parsing data sets. LORAS can be used with any model, improves performance and implicit model calibration without increasing the number of model parameters, and can be scaled to problems with large label spaces containing tens of thousands of labels.
",ハードターゲットの代わりにソフトターゲットを使用したトレーニングは、ディープニューラルネットワークのパフォーマンスとキャリブレーションを改善することが示されています。ラベルスムージングは​​、ソフトターゲットを計算する一般的な方法であり、クラスのワンホットエンコーディングが一様分布でスムージングされます。その単純さのおかげで、画像やテキストの分類から機械翻訳や意味解析に至るまで、さまざまなタスクでディープニューラルネットワークをトレーニングするために広く使用されています。ラベル平滑化の最近の経験的正当化を補完して、ラベル平滑化のPAC-Bayesian汎化限界を取得し、汎化誤差がノイズ（平滑化）分布の選択に依存することを示します。次に、低ランクの適応ラベル平滑化（LORAS）を提案します。これは、ラベル平滑化を一般化し、構造化予測タスクのラベル空間の潜在構造に適応する、学習したソフトターゲットを使用したトレーニングのシンプルで斬新な方法です。具体的には、タスク指向のセマンティック解析タスクでメソッドを評価し、適切に平滑化されたソフトターゲットを使用してトレーニングするだけで、モデルの精度を2倍も向上できることを示します。,6.25,
Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks,"['Alexander Levine', 'Soheil Feizi']",https://openreview.net/forum?id=YUGG2tFuPM,"Adversarial poisoning attacks distort training data in order to corrupt the test-time behavior of a classifier. A provable defense provides a certificate for each test sample, which is a lower bound on the magnitude of any adversarial distortion of the training set that can corrupt the test sample's classification.
We propose two novel provable defenses against poisoning attacks: (i) Deep Partition Aggregation (DPA), a certified defense against a general poisoning threat model, defined as the insertion or deletion of a bounded number of samples to the training set --- by implication, this threat model also includes arbitrary distortions to a bounded number of images and/or labels; and (ii) Semi-Supervised DPA (SS-DPA), a certified defense against label-flipping poisoning attacks. DPA is an ensemble method where base models are trained on partitions of the training set determined by a hash function. DPA is related to both subset aggregation, a well-studied ensemble method in classical machine learning, as well as to randomized smoothing, a popular provable defense against evasion (inference) attacks. Our defense against label-flipping poison attacks, SS-DPA, uses a semi-supervised learning algorithm as its base classifier model: each base classifier is trained using the entire unlabeled training set in addition to the labels for a partition. SS-DPA significantly outperforms the existing certified defense for label-flipping attacks (Rosenfeld et al., 2020) on both MNIST and CIFAR-10: provably tolerating, for at least half of test images, over 600 label flips (vs. < 200 label flips) on MNIST and over 300 label flips (vs. 175 label flips) on CIFAR-10. Against general poisoning attacks where no prior certified defenses exists, DPA can certify $\geq$ 50% of test images against over 500 poison image insertions on MNIST, and nine insertions on CIFAR-10. These results establish new state-of-the-art provable defenses against general and label-flipping poison attacks. ",敵対的な中毒攻撃は、分類器のテスト時の動作を破壊するためにトレーニングデータを歪めます。証明可能な防御は、各テストサンプルの証明書を提供します。これは、テストサンプルの分類を損なう可能性のあるトレーニングセットの敵対的な歪みの大きさの下限です。中毒攻撃に対する2つの新しい証明可能な防御を提案します。（i）一般的な中毒脅威モデルに対する認定された防御であるDeep Partition Aggregation（DPA）は、含意によって設定されたトレーニングへの限られた数のサンプルの挿入または削除として定義されます。脅威モデルには、限られた数の画像やラベルに対する任意の歪みも含まれます。 （ii）半教師ありDPA（SS-DPA）、ラベル反転中毒攻撃に対する認定された防御。 DPAは、ハッシュ関数によって決定されたトレーニングセットのパーティションでベースモデルがトレーニングされるアンサンブル手法です。 DPAは、古典的な機械学習でよく研究されているアンサンブル手法であるサブセット集約と、回避（推論）攻撃に対する一般的な証明可能な防御であるランダム化平滑化の両方に関連しています。ラベル反転毒攻撃に対する防御であるSS-DPAは、基本分類子モデルとして半教師あり学習アルゴリズムを使用します。各基本分類器は、パーティションのラベルに加えて、ラベルなしのトレーニングセット全体を使用してトレーニングされます。 SS-DPAは、MNISTとCIFAR-10の両方で、ラベル反転攻撃に対する既存の認定防御（Rosenfeld et al。、2020）を大幅に上回っています。テスト画像の少なくとも半分で、600を超えるラベル反転（vs. &lt;200）を確実に許容します。 MNISTではラベルフリップ）、CIFAR-10では300を超えるラベルフリップ（vs. 175ラベルフリップ）。事前に認定された防御が存在しない一般的な中毒攻撃に対して、DPAは50を認定できます,6.25,https://d3i71xaburhd42.cloudfront.net/abef3821cdab3819ce998f0abcbb10cc8acdc5c1/3-Figure1-1.png
HalentNet: Multimodal Trajectory Forecasting with Hallucinative Intents,"['Deyao Zhu', 'Mohamed Zahran', 'Li Erran Li', 'Mohamed Elhoseiny']",https://openreview.net/forum?id=9GBZBPn0Jx,"Motion forecasting is essential for making intelligent decisions in robotic navigation. As a result, the multi-agent behavioral prediction has become a core component of modern human-robot interaction applications such as autonomous driving. Due to various intentions and interactions among agents, agent trajectories can have multiple possible futures. Hence, the motion forecasting model's ability to cover possible modes becomes essential to enable accurate prediction. Towards this goal, we introduce HalentNet to better model the future motion distribution in addition to a traditional trajectory regression learning objective by incorporating generative augmentation losses. We model intents with unsupervised discrete random variables whose training is guided by a collaboration between two key signals: A discriminative loss that encourages intents' diversity and a hallucinative loss that explores intent transitions (i.e., mixed intents) and encourages their smoothness. This regulates the neural network behavior to be more accurately predictive on uncertain scenarios due to the active yet careful exploration of possible future agent behavior. Our model's learned representation leads to better and more semantically meaningful coverage of the trajectory distribution. Our experiments show that our method can improve over the state-of-the-art trajectory forecasting benchmarks, including vehicles and pedestrians, for about 20% on average FDE and 50% on road boundary violation rate when predicting 6 seconds future. We also conducted human experiments to show that our predicted trajectories received 39.6% more votes than the runner-up approach and 32.2% more votes than our variant without hallucinative mixed intent loss. The code will be released soon. ",ロボットナビゲーションでインテリジェントな意思決定を行うには、モーション予測が不可欠です。その結果、マルチエージェントの行動予測は、自動運転などの最新の人間とロボットの相互作用アプリケーションのコアコンポーネントになりました。エージェント間のさまざまな意図と相互作用により、エージェントの軌道には複数の可能性のある未来があります。したがって、可能なモードをカバーするモーション予測モデルの機能は、正確な予測を可能にするために不可欠になります。この目標に向けて、HalentNetを導入して、生成的増大損失を組み込むことにより、従来の軌道回帰学習目標に加えて、将来のモーション分布をより適切にモデル化します。教師なし離散確率変数を使用してインテントをモデル化します。そのトレーニングは、インテントの多様性を促進する識別的損失と、インテント遷移（つまり、混合インテント）を探索し、それらの滑らかさを促進する幻覚的損失の2つの主要な信号間のコラボレーションによって導かれます。これにより、ニューラルネットワークの動作が調整され、将来のエージェントの動作の可能性を積極的かつ注意深く調査するため、不確実なシナリオをより正確に予測できるようになります。私たちのモデル学習表現は、軌道分布のより良い、より意味的に意味のあるカバレッジにつながります。私たちの実験は、私たちの方法が、車両や歩行者を含む最先端の軌道予測ベンチマークを約20回上回っていることを示しています。,6.25,
Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds,"['Efthymios Tzinis', 'Scott Wisdom', 'Aren Jansen', 'Shawn Hershey', 'Tal Remez', 'Dan Ellis', 'John R. Hershey']",https://openreview.net/forum?id=MDsQkFP1Aw,"Recent progress in deep learning has enabled many advances in sound separation and visual scene understanding. However, extracting sound sources which are apparent in natural videos remains an open problem. In this work, we present AudioScope, a novel audio-visual sound separation framework that can be trained without supervision to isolate on-screen sound sources from real in-the-wild videos. Prior audio-visual separation work assumed artificial limitations on the domain of sound classes (e.g., to speech or music), constrained the number of sources, and required strong sound separation or visual segmentation labels. AudioScope overcomes these limitations, operating on an open domain of sounds, with variable numbers of sources, and without labels or prior visual segmentation.  The training procedure for AudioScope uses mixture invariant training (MixIT) to separate synthetic mixtures of mixtures (MoMs) into individual sources, where noisy labels for mixtures are provided by an unsupervised audio-visual coincidence model. Using the noisy labels, along with attention between video and audio features, AudioScope learns to identify audio-visual similarity and to suppress off-screen sounds. We demonstrate the effectiveness of our approach using a dataset of video clips extracted from open-domain YFCC100m video data. This dataset contains a wide diversity of sound classes recorded in unconstrained conditions, making the application of previous methods unsuitable. For evaluation and semi-supervised experiments, we collected human labels for presence of on-screen and off-screen sounds on a small subset of clips.",ディープラーニングの最近の進歩により、音の分離と視覚的なシーンの理解に多くの進歩がもたらされました。ただし、自然なビデオで明らかな音源を抽出することは、未解決の問題のままです。この作業では、AudioScopeを紹介します。これは、監視なしでトレーニングして、画面上の音源を実際の野生のビデオから分離できる、新しいオーディオビジュアルサウンド分離フレームワークです。以前の視聴覚分離作業は、音声クラスのドメイン（たとえば、音声または音楽）に対する人為的な制限を想定し、ソースの数を制限し、強力な音声分離または視覚セグメンテーションラベルを必要としました。 AudioScopeはこれらの制限を克服し、サウンドのオープンドメインで動作し、ソースの数は可変で、ラベルや事前の視覚的セグメンテーションはありません。 AudioScopeのトレーニング手順では、混合不変トレーニング（MixIT）を使用して、混合物の合成混合物（MoM）を個々のソースに分離します。混合物のノイズの多いラベルは、教師なし視聴覚一致モデルによって提供されます。 AudioScopeは、ノイズの多いラベルを使用し、ビデオ機能とオーディオ機能の間の注意を払って、オーディオビジュアルの類似性を識別し、画面外の音を抑制することを学習します。オープンドメインのYFCC100mビデオデータから抽出されたビデオクリップのデータセットを使用して、アプローチの有効性を示します。このデータセットには、制約のない条件で録音された多種多様なサウンドクラスが含まれているため、以前の方法の適用は不適切です。評価と半教師あり実験のために、クリップの小さなサブセットに画面上の音と画面外の音が存在するかどうかを示す人間のラベルを収集しました。,6.25,https://d3i71xaburhd42.cloudfront.net/8cc141d242387dc9b64124e97896097ddfd6bcf2/1-Figure1-1.png
Learning Hyperbolic Representations of Topological Features,"['Panagiotis Kyriakis', 'Iordanis Fostiropoulos', 'Paul Bogdan']",https://openreview.net/forum?id=yqPnIRhHtZv,"Learning task-specific representations of persistence diagrams is an important problem in topological data analysis and machine learning. However, current state of the art methods are restricted in terms of their expressivity as they are focused on Euclidean representations. Persistence diagrams often contain features of infinite persistence (i.e., essential features) and Euclidean spaces shrink their importance relative to non-essential features because they cannot assign infinite distance to finite points. To deal with this issue, we propose a method to learn representations of persistence diagrams on hyperbolic spaces, more specifically on the Poincare ball. By representing features of infinite persistence infinitesimally close to the boundary of the ball, their distance to non-essential features approaches infinity, thereby their relative importance is preserved. This is achieved without utilizing extremely high values for the learnable parameters, thus the representation can be fed into downstream optimization methods and trained efficiently in an end-to-end fashion. We present experimental results on graph and image classification tasks and show that the performance of our method is on par with or exceeds the performance of other state of the art methods.
",永続性図のタスク固有の表現を学習することは、トポロジーデータ分析と機械学習における重要な問題です。ただし、現在の最先端の方法は、ユークリッド表現に焦点を合わせているため、表現力の点で制限されています。永続性図には、無限の永続性の特徴（つまり、本質的な特徴）が含まれることが多く、ユークリッド空間は、有限の点に無限の距離を割り当てることができないため、本質的でない特徴に比べて重要性が低くなります。この問題に対処するために、双曲空間、より具体的にはポアンカレ球の持続性図の表現を学習する方法を提案します。ボールの境界に非常に近い無限の持続性の特徴を表すことにより、本質的でない特徴までの距離が無限に近づき、それによってそれらの相対的な重要性が維持されます。これは、学習可能なパラメーターに非常に高い値を使用せずに実現されるため、表現をダウンストリームの最適化手法にフィードし、エンドツーエンドで効率的にトレーニングできます。グラフと画像の分類タスクに関する実験結果を提示し、私たちの方法のパフォーマンスが他の最先端の方法のパフォーマンスと同等かそれを超えることを示します。,6.25,
Efficient Inference of Flexible Interaction in Spiking-neuron Networks,"['Feng Zhou', 'Yixuan Zhang', 'Jun Zhu']",https://openreview.net/forum?id=aGfU_xziEX8,"Hawkes process provides an effective statistical framework for analyzing the time-dependent interaction of neuronal spiking activities. Although utilized in many real applications, the classic Hawkes process is incapable of modelling inhibitory interactions among neurons. Instead, the nonlinear Hawkes process allows for a more flexible influence pattern with excitatory or inhibitory interactions. In this paper, three sets of auxiliary latent variables (Polya-Gamma variables, latent marked Poisson processes and sparsity variables) are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. As a result, an efficient expectation-maximization (EM) algorithm is derived to obtain the maximum a posteriori (MAP) estimate. We demonstrate the accuracy and efficiency performance of our algorithm on synthetic and real data. For real neural recordings, we show our algorithm can estimate the temporal dynamics of interaction and reveal the interpretable functional connectivity underlying neural spike trains. ",ホークスプロセスは、ニューロンのスパイキング活動の時間依存の相互作用を分析するための効果的な統計的フレームワークを提供します。多くの実際のアプリケーションで利用されていますが、古典的なホークスプロセスはニューロン間の抑制性相互作用をモデル化することができません。代わりに、非線形ホークスプロセスは、興奮性または抑制性相互作用を伴うより柔軟な影響パターンを可能にします。この論文では、3セットの補助潜在変数（ポリアガンマ変数、潜在マークポアソン過程、およびスパース変数）を拡張して、ガウス形式で関数接続の重みを作成します。これにより、分析の更新を伴う単純な反復アルゴリズムが可能になります。その結果、効率的な期待値最大化（EM）アルゴリズムが導出され、最大事後（MAP）推定値が取得されます。合成データと実際のデータに対するアルゴリズムの精度と効率のパフォーマンスを示します。実際の神経記録については、アルゴリズムが相互作用の時間的ダイナミクスを推定し、神経スパイク列の根底にある解釈可能な機能的接続性を明らかにできることを示しています。,6.25,
Ringing ReLUs: Harmonic Distortion Analysis of Nonlinear Feedforward Networks,"['Christian H.X. Ali Mehmeti-Göpel', 'David Hartmann', 'Michael Wand']",https://openreview.net/forum?id=TaYhv-q1Xit,"In this paper, we apply harmonic distortion analysis to understand the effect of nonlinearities in the spectral domain. Each nonlinear layer creates higher-frequency harmonics, which we call ""blueshift"", whose magnitude increases with network depth, thereby increasing the “roughness” of the output landscape. Unlike differential models (such as vanishing gradients, sharpness), this provides a more global view of how network architectures behave across larger areas of their parameter domain. For example, the model predicts that residual connections are able to counter the effect by dampening corresponding higher frequency modes. We empirically verify the connection between blueshift and architectural choices, and provide evidence for a connection with trainability.",この論文では、高調波歪み解析を適用して、スペクトル領域の非線形性の影響を理解します。各非線形層は、「ブルーシフト」と呼ばれる高周波高調波を生成します。この高調波の大きさは、ネットワークの深さとともに増加し、それによって出力ランドスケープの粗さが増加します。差分モデル（勾配消失、シャープネスなど）とは異なり、これにより、ネットワークアーキテクチャがパラメータドメインのより広い領域でどのように動作するかについて、よりグローバルなビューが提供されます。たとえば、モデルは、残りの接続が対応する高周波モードを減衰させることによって影響に対抗できることを予測します。ブルーシフトとアーキテクチャの選択の関係を経験的に検証し、トレーニング可能性との関係の証拠を提供します。,6.25,
Early Stopping in Deep Networks: Double Descent and How to Eliminate it,"['Reinhard Heckel', 'Fatih Furkan Yilmaz']",https://openreview.net/forum?id=tlV90jvZbw,"Over-parameterized models, such as large deep networks, often exhibit a double descent phenomenon, whereas a function of model size, error first decreases, increases, and decreases at last. This intriguing double descent behavior also occurs as a function of training epochs and has been conjectured to arise because training epochs control the model complexity. In this paper, we show that such epoch-wise double descent occurs for a different reason: It is caused by a superposition of two or more bias-variance tradeoffs that arise because different parts of the network are learned at different epochs, and mitigating this by proper scaling of stepsizes can significantly improve the early stopping performance. We show this analytically for i) linear regression, where differently scaled features give rise to a superposition of bias-variance tradeoffs, and for ii) a wide two-layer neural network, where the first and second layers govern bias-variance tradeoffs. Inspired by this theory, we study two standard convolutional networks empirically and show that eliminating epoch-wise double descent through adjusting stepsizes of different layers improves the early stopping performance.",大規模なディープネットワークなどのパラメーターが多すぎるモデルは、しばしば二重降下現象を示しますが、モデルサイズの関数では、エラーは最初に減少し、増加し、最後に減少します。この興味をそそる二重降下の振る舞いは、トレーニングエポックの関数としても発生し、トレーニングエポックがモデルの複雑さを制御するために発生すると推測されています。この論文では、そのようなエポックワイズの二重降下が異なる理由で発生することを示します。これは、ネットワークの異なる部分が異なるエポックで学習されるために発生する2つ以上のバイアス分散のトレードオフの重ね合わせによって引き起こされ、これを軽減します。ステップサイズを適切にスケーリングすることにより、早期停止のパフォーマンスを大幅に向上させることができます。これを、i）異なるスケーリングの特徴が偏りと分散のトレードオフの重ね合わせを引き起こす線形回帰、およびii）第1層と第2層が偏りと分散のトレードオフを支配する広い2層ニューラルネットワークについて分析的に示します。この理論に触発されて、2つの標準畳み込みネットワークを経験的に研究し、異なるレイヤーのステップサイズを調整することでエポックワイズの二重降下を排除すると、早期停止のパフォーマンスが向上することを示します。,6.25,https://d3i71xaburhd42.cloudfront.net/580ed7e52079880e6a3534632921c81cc83531a7/2-Figure1-1.png
Transient Non-stationarity and Generalisation in Deep Reinforcement Learning,"['Maximilian Igl', 'Gregory Farquhar', 'Jelena Luketina', 'Wendelin Boehmer', 'Shimon Whiteson']",https://openreview.net/forum?id=Qun8fv4qSby,"Non-stationarity can arise in Reinforcement Learning (RL) even in stationary environments. For example, most RL algorithms collect new data throughout training, using a non-stationary behaviour policy. Due to the transience of this non-stationarity, it is often not explicitly addressed in deep RL and a single neural network is continually updated. However, we find evidence that neural networks exhibit a memory effect, where these transient non-stationarities can permanently impact the latent representation and adversely affect generalisation performance. Consequently, to improve generalisation of deep RL agents, we propose Iterated Relearning (ITER). ITER augments standard RL training by repeated knowledge transfer of the current policy into a freshly initialised network, which thereby experiences less non-stationarity during training. Experimentally, we show that ITER improves performance on the challenging generalisation benchmarks ProcGen and Multiroom.",非定常性は、定常環境でも強化学習（RL）で発生する可能性があります。たとえば、ほとんどのRLアルゴリズムは、非定常動作ポリシーを使用して、トレーニング全体を通じて新しいデータを収集します。この非定常性の一時性のために、ディープRLで明示的に対処されないことが多く、単一のニューラルネットワークが継続的に更新されます。ただし、ニューラルネットワークがメモリ効果を示すという証拠が見つかりました。これらの一時的な非定常性は、潜在表現に永続的に影響を与え、一般化のパフォーマンスに悪影響を与える可能性があります。したがって、ディープRLエージェントの一般化を改善するために、反復再学習（ITER）を提案します。 ITERは、現在のポリシーを新たに初期化されたネットワークに繰り返し知識を伝達することにより、標準のRLトレーニングを強化します。これにより、トレーニング中の非定常性が少なくなります。実験的に、ITERが挑戦的な一般化ベンチマークであるProcGenとMultiroomのパフォーマンスを改善することを示します。,6.25,
Distance-Based Regularisation of Deep Networks for Fine-Tuning,"['Henry Gouk', 'Timothy Hospedales', 'massimiliano pontil']",https://openreview.net/forum?id=IFqrg1p5Bc,"We investigate approaches to regularisation during fine-tuning of deep neural networks. First we provide a neural network generalisation bound based on Rademacher complexity that uses the distance the weights have moved from their initial values. This bound has no direct dependence on the number of weights and compares favourably to other bounds when applied to convolutional networks. Our bound is highly relevant for fine-tuning, because providing a network with a good initialisation based on transfer learning means that learning can modify the weights less, and hence achieve tighter generalisation. Inspired by this, we develop a simple yet effective fine-tuning algorithm that constrains the hypothesis class to a small sphere centred on the initial pre-trained weights, thus obtaining provably better generalisation performance than conventional transfer learning. Empirical evaluation shows that our algorithm works well, corroborating our theoretical results. It outperforms both state of the art fine-tuning competitors, and penalty-based alternatives that we show do not directly constrain the radius of the search space.",ディープニューラルネットワークの微調整中の正則化へのアプローチを調査します。最初に、重みが初期値から移動した距離を使用する、ラデマッハー複雑度に基づくニューラルネットワークの一般化限界を提供します。この境界は重みの数に直接依存せず、畳み込みネットワークに適用すると他の境界と比べて遜色ありません。転移学習に基づく適切な初期化をネットワークに提供することは、学習が重みをあまり変更できないことを意味し、したがってより厳密な一般化を達成できるため、私たちの限界は微調整に非常に関連しています。これに触発されて、仮説クラスを初期の事前トレーニングされた重みを中心とする小さな球に制約する、シンプルで効果的な微調整アルゴリズムを開発します。これにより、従来の転移学習よりも確かに優れた一般化パフォーマンスが得られます。経験的評価は、私たちのアルゴリズムがうまく機能することを示しており、私たちの理論的結果を裏付けています。これは、最先端の微調整の競合他社よりも優れており、ペナルティベースの代替案が検索スペースの半径を直接制約しないことを示しています。,6.25,https://d3i71xaburhd42.cloudfront.net/54cde630354eb6e08dbc5e0ec3f0d2396776a870/8-Figure1-1.png
Learning and Evaluating Representations for Deep One-Class Classification,"['Kihyuk Sohn', 'Chun-Liang Li', 'Jinsung Yoon', 'Minho Jin', 'Tomas Pfister']",https://openreview.net/forum?id=HCSgyPUfeDj,"We present a two-stage framework for deep one-class classification. We first learn self-supervised representations from one-class data, and then build classifiers using generative or discriminative models on learned representations. In particular, we present a novel distribution-augmented contrastive learning method that extends training distributions via data augmentation to obstruct the uniformity of vanilla contrastive representations, yielding more suitable representations for one-class classification. Moreover, we argue that classifiers inspired by the statistical perspective in generative or discriminative models are more effective than existing approaches, such as an average of normality scores from a surrogate classifier. In experiments, we demonstrate state-of-the-art performance on visual domain one-class classification benchmarks. The framework does not only learn a better representation, but it also permits building one-class classifiers that are more faithful to the target task. Finally, we present visual explanations, confirming that the decision-making process of our deep one-class classifier is intuitive to humans.",深い1クラス分類のための2段階のフレームワークを提示します。最初に1クラスのデータから自己教師あり表現を学習し、次に学習した表現で生成モデルまたは識別モデルを使用して分類器を構築します。特に、バニラの対照表現の均一性を妨げるためにデータ拡張を介してトレーニング分布を拡張し、1クラス分類により適した表現を生成する新しい分布拡張対照学習法を提示します。さらに、生成モデルまたは識別モデルの統計的観点に触発された分類器は、代理分類器からの正規性スコアの平均など、既存のアプローチよりも効果的であると主張します。実験では、ビジュアルドメインの1クラス分類ベンチマークで最先端のパフォーマンスを示します。フレームワークは、より良い表現を学習するだけでなく、ターゲットタスクにより忠実な1クラスの分類器を構築することもできます。最後に、視覚的な説明を提示し、深きものども分類器の意思決定プロセスが人間にとって直感的であることを確認します。,6.25,https://d3i71xaburhd42.cloudfront.net/498e003901f8287e89e5064477cd22dd47e49d61/2-Figure1-1.png
DC3: A learning method for optimization with hard constraints,"['Priya L. Donti', 'David Rolnick', 'J Zico Kolter']",https://openreview.net/forum?id=V1ZHVxJ6dSS,"Large optimization problems with hard constraints arise in many settings, yet classical solvers are often prohibitively slow, motivating the use of deep networks as cheap ""approximate solvers."" Unfortunately, naive deep learning approaches typically cannot enforce the hard constraints of such problems, leading to infeasible solutions. In this work, we present Deep Constraint Completion and Correction (DC3), an algorithm to address this challenge. Specifically, this method enforces feasibility via a differentiable procedure, which implicitly completes partial solutions to satisfy equality constraints and unrolls gradient-based corrections to satisfy inequality constraints. We demonstrate the effectiveness of DC3 both in simple quadratic programming tasks and in the real-world setting of AC optimal power flow, where hard constraints encode the physics of the electrical grid. In both cases, DC3 substantially improves runtime over standard solvers, and achieves near-optimal objective values while preserving feasibility.",多くの設定でハード制約を伴う大規模な最適化問題が発生しますが、従来のソルバーは非常に遅いことが多く、安価な「近似ソルバー」としてディープネットワークを使用する動機になります。残念ながら、ナイーブな深層学習アプローチは通常、そのような問題の厳しい制約を強制することができず、実行不可能な解決策につながります。この作業では、この課題に対処するためのアルゴリズムであるDeep Constraint Completion and Correction（DC3）を紹介します。具体的には、このメソッドは、微分可能手順を介して実現可能性を強制します。これは、等式制約を満たすために部分解を暗黙的に完了し、不等式制約を満たすために勾配ベースの修正を展開します。単純な二次計画法タスクと、AC最適電力潮流の実際の設定の両方で、DC3の有効性を示します。ここでは、厳しい制約が電力網の物理をエンコードします。どちらの場合も、DC3は標準のソルバーよりも実行時間を大幅に改善し、実現可能性を維持しながらほぼ最適な目標値を達成します。,6.25,
MODALS: Modality-agnostic Automated Data Augmentation in the Latent Space,"['Tsz-Him Cheung', 'Dit-Yan Yeung']",https://openreview.net/forum?id=XjYgR6gbCEc,"Data augmentation is an efficient way to expand a training dataset by creating additional artificial data. While data augmentation is found to be effective in improving the generalization capability of models for various machine learning tasks, the underlying augmentation methods are usually manually designed and carefully evaluated for each data modality separately, like image processing functions for image data and word-replacing rules for text data. In this work, we propose an automated data augmentation approach called MODALS (Modality-agnostic Automated Data Augmentation in the Latent Space) to augment data for any modality in a generic way. MODALS exploits automated data augmentation to fine-tune four universal data transformation operations in the latent space to adapt the transform to data of different modalities. Through comprehensive experiments, we demonstrate the effectiveness of MODALS on multiple datasets for text, tabular, time-series and image modalities.",データ拡張は、追加の人工データを作成することにより、トレーニングデータセットを拡張する効率的な方法です。データ拡張は、さまざまな機械学習タスクのモデルの一般化機能を改善するのに効果的であることがわかっていますが、基礎となる拡張方法は通常、手動で設計され、画像データの画像処理機能や単語置換ルールなど、データモダリティごとに個別に慎重に評価されます。テキストデータ用。この作業では、MODALS（潜在空間におけるモダリティにとらわれない自動データ拡張）と呼ばれる自動データ拡張アプローチを提案し、一般的な方法で任意のモダリティのデータを拡張します。 MODALSは、自動化されたデータ拡張を利用して、潜在空間で4つのユニバーサルデータ変換操作を微調整し、変換をさまざまなモダリティのデータに適合させます。包括的な実験を通じて、テキスト、表形式、時系列、および画像モダリティの複数のデータセットに対するMODALSの有効性を示します。,6.25,
MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering,"['Tsung Wei Tsai', 'Chongxuan Li', 'Jun Zhu']",https://openreview.net/forum?id=gV3wdEOGy_V,"We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.",対照学習によって学習された識別表現と潜在混合モデルによってキャプチャされた意味構造を同時に活用する、統一された確率的クラスタリングフレームワークであるMixture of Contrastive Experts（MiCE）を紹介します。専門家の混合に動機付けられたMiCEは、ゲート機能を使用して、ラベルのないデータセットを潜在意味に従ってサブセットに分割し、複数の専門家が、対照的な学習方法で割り当てられたインスタンスの個別のサブセットを識別します。潜在変数によって引き起こされる自明でない推論と学習の問題を解決するために、MiCEの期待値最大化（EM）アルゴリズムのスケーラブルなバリアントをさらに開発します。経験的に、広く採用されている4つの自然画像データセットでMiCEのクラスタリングパフォーマンスを評価します。 MiCEは、以前のさまざまな方法よりも大幅に優れた結果と、強力な対照学習ベースラインを実現します。,6.25,
Efficient Empowerment Estimation for Unsupervised Stabilization,"['Ruihan Zhao', 'Kevin Lu', 'Pieter Abbeel', 'Stas Tiomkin']",https://openreview.net/forum?id=u2YNJPcQlwq,"Intrinsically motivated artificial agents learn advantageous behavior without externally-provided rewards. Previously, it was shown that maximizing mutual information between agent actuators and future states, known as the empowerment principle, enables unsupervised stabilization of dynamical systems at upright positions, which is a prototypical intrinsically motivated behavior for upright standing and walking. That follows from the coincidence between the objective of stabilization and the objective of empowerment. Unfortunately, sample-based estimation of this kind of mutual information is challenging. Recently, various variational lower bounds (VLBs) on empowerment have been proposed as solutions; however, they are often biased, have high sample complexity, and are unstable in training. In this work, we propose an alternative solution based on a trainable representation of a dynamical system as a Gaussian channel, which allows us to efficiently calculate an unbiased estimator of empowerment by convex optimization. We demonstrate our solution for sample-based unsupervised stabilization on different dynamical control systems and show the advantages of our method by comparing it to the existing VLB approaches. Specifically, we show that our method has a lower sample complexity, is more stable in training, possesses the essential properties of the empowerment function, and allows estimation of empowerment from images. Consequently, our method opens a path to wider and easier adoption of empowerment for many applications.",本質的に動機付けられた人工エージェントは、外部から提供される報酬なしで有利な行動を学びます。以前は、エンパワーメントの原理として知られる、エージェントアクチュエータと将来の状態の間の相互情報量を最大化することで、直立姿勢での動的システムの監視されていない安定化が可能になることが示されました。これは、直立および歩行の典型的な本質的な動機付けの動作です。それは、安定化の目的とエンパワーメントの目的の一致から生じます。残念ながら、この種の相互情報量のサンプルベースの推定は困難です。最近、エンパワーメントに関するさまざまな変分下限（VLB）が解決策として提案されています。ただし、それらはしばしば偏りがあり、サンプルの複雑さが高く、トレーニングが不安定です。この作業では、ガウスチャネルとしての動的システムのトレーニング可能な表現に基づく代替ソリューションを提案します。これにより、凸最適化によるエンパワーメントの不偏推定量を効率的に計算できます。さまざまな動的制御システムでのサンプルベースの教師なし安定化のソリューションを示し、既存のVLBアプローチと比較することでこの方法の利点を示します。具体的には、私たちの方法はサンプルの複雑さが低く、トレーニングでより安定しており、エンパワーメント関数の本質的な特性を備えており、画像からエンパワーメントを推定できることを示しています。その結果、私たちの方法は、多くのアプリケーションにエンパワーメントをより広く、より簡単に採用するための道を開きます。,6.25,
Accelerating Convergence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction,"['Wei Deng', 'Qi Feng', 'Georgios P. Karagiannis', 'Guang Lin', 'Faming Liang']",https://openreview.net/forum?id=iOnhIy-a-0n,"Replica exchange stochastic gradient Langevin dynamics (reSGLD) has shown promise in accelerating the convergence in non-convex learning; however, an excessively large correction for avoiding biases from noisy energy estimators has limited the potential of the acceleration. To address this issue, we study the variance reduction for noisy energy estimators, which promotes much more effective swaps. Theoretically, we provide a non-asymptotic analysis on the exponential convergence for the underlying continuous-time Markov jump process; moreover, we consider a generalized Girsanov theorem which includes the change of Poisson measure to overcome the crude discretization based on the Gr\""{o}wall's inequality and yields a much tighter error in the 2-Wasserstein ($\mathcal{W}_2$) distance. Numerically, we conduct extensive experiments and obtain state-of-the-art results in optimization and uncertainty estimates for synthetic experiments and image data.",レプリカ交換確率勾配ランジュバンダイナミクス（reSGLD）は、非凸学習の収束を加速する可能性を示しています。ただし、ノイズの多いエネルギー推定器からのバイアスを回避するための過度に大きな補正は、加速の可能性を制限しました。この問題に対処するために、ノイズの多いエネルギー推定量の分散減少を研究します。これにより、はるかに効果的なスワップが促進されます。理論的には、基礎となる連続時間マルコフジャンププロセスの指数収束に関する非漸近解析を提供します。さらに、グロウォールの不等式に基づく粗い離散化を克服するためのポアソン測度の変更を含む一般化されたギルサノフの定理を検討し、2ワッサーシュタイン（W2）距離ではるかに厳密な誤差を生成します。数値的には、広範な実験を実施し、合成実験と画像データの最適化と不確実性の推定において最先端の結果を取得しています。,6.25,https://d3i71xaburhd42.cloudfront.net/45d17f397fe04cc25aeeee5e0872bcbf85e9aedc/2-Figure1-1.png
ResNet After All: Neural ODEs and Their Numerical Solution,"['Katharina Ott', 'Prateek Katiyar', 'Philipp Hennig', 'Michael Tiemann']",https://openreview.net/forum?id=HxzSxSxLOJZ,"A key appeal of the recently proposed Neural Ordinary Differential Equation (ODE) framework is that it seems to provide a continuous-time extension of discrete residual neural networks. 
As we show herein, though, trained Neural ODE models actually depend on the specific numerical method used during training.
If the trained model is supposed to be a flow generated from an ODE, it should be possible to choose another numerical solver with equal or smaller numerical error without loss of performance.
We observe that if training relies on a solver with overly coarse discretization, then testing with another solver of equal or smaller numerical error results in a sharp drop in accuracy. 
In such cases, the combination of vector field and numerical method cannot be interpreted as a flow generated from an ODE, which arguably poses a fatal breakdown of the Neural ODE concept.
We observe, however, that there exists a critical step size beyond which the training yields a valid ODE vector field. 
We propose a method that monitors the behavior of the ODE solver during training to adapt its step size, aiming to ensure a valid ODE without unnecessarily increasing computational cost.
We verify this adaption algorithm on a common bench mark dataset as well as a synthetic dataset. 
",最近提案されたニューラル常微分方程式（ODE）フレームワークの主な魅力は、離散残余ニューラルネットワークの連続時間拡張を提供するように見えることです。ただし、ここで示すように、トレーニングされたニューラルODEモデルは、実際にはトレーニング中に使用された特定の数値手法に依存します。トレーニングされたモデルがODEから生成されたフローであると想定される場合、パフォーマンスを損なうことなく、同等以下の数値誤差を持つ別の数値ソルバーを選択できるはずです。トレーニングが過度に粗い離散化のソルバーに依存している場合、数値誤差が等しいかそれよりも小さい別のソルバーでテストすると、精度が大幅に低下することがわかります。このような場合、ベクトル場と数値解法の組み合わせは、ODEから生成されたフローとして解釈することはできません。これは、間違いなく、ニューラルODEの概念の致命的な崩壊を引き起こします。ただし、それを超えるとトレーニングによって有効なODEベクトル場が生成される重要なステップサイズが存在することがわかります。トレーニング中にODEソルバーの動作を監視してステップサイズを適応させる方法を提案し、計算コストを不必要に増加させることなく有効なODEを確保することを目指します。この適応アルゴリズムは、一般的なベンチマークデータセットと合成データセットで検証します。,6.25,
"Kanerva++: Extending the Kanerva Machine With Differentiable, Locally Block Allocated Latent Memory","['Jason Ramapuram', 'Yan Wu', 'Alexandros Kalousis']",https://openreview.net/forum?id=QoWatN-b8T,"Episodic and semantic memory are critical components of the human memory model. The theory of complementary learning system (McClelland et al., 1995) suggests that the compressed representation produced by a serial event (episodic memory) is later restructured to build a more generalized form of reusable knowledge (semantic memory). In this work, we develop a new principled Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. We take inspiration from traditional heap allocation and extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory. In contrast to the Kanerva Machine, we simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to disperse information within the memory. We demonstrate that this allocation scheme improves performance in conditional image generation, resulting in new state-of-the-art likelihood values on binarized MNIST (≤41.58 nats/image) , binarized Omniglot (≤66.24 nats/image), as well as presenting competitive performance on CIFAR10, DMLab Mazes, Celeb-A and ImageNet32×32.",エピソード記憶と意味記憶は、人間の記憶モデルの重要な要素です。補完的学習システムの理論（McClelland et al。、1995）は、シリアルイベント（エピソード記憶）によって生成された圧縮表現が後で再構築されて、より一般化された形式の再利用可能な知識（意味記憶）を構築することを示唆しています。この作業では、階層的潜在変数モデルを介してエピソード記憶と意味記憶の間のギャップを埋める新しい原理的なベイズ記憶割り当てスキームを開発します。従来のヒープ割り当てからインスピレーションを得て、ローカルで隣接するメモリのアイデアをKanerva Machineに拡張し、新しい差別化可能なブロック割り当ての潜在メモリを実現します。 Kanerva Machineとは対照的に、メモリ内に情報を分散するために読み取りキー分布の確率論に依存して、完全なフィードフォワード決定論的プロセスとして扱うことにより、メモリ書き込みのプロセスを簡素化します。この割り当てスキームにより、条件付き画像生成のパフォーマンスが向上し、2値化されたMNIST（41.58 nats / image）、2値化されたOmniglot（66.24 nats / image）で新しい最先端の尤度値が得られ、競争力のあるパフォーマンスが得られることを示します。 CIFAR10、DMLab Mazes、Celeb-A、ImageNet3232で。,6.25,
Robust and Generalizable Visual Representation Learning via Random Convolutions,"['Zhenlin Xu', 'Deyi Liu', 'Junlin Yang', 'Colin Raffel', 'Marc Niethammer']",https://openreview.net/forum?id=BVSM0x3EDK6,"While successful for various computer vision tasks, deep neural networks have shown to be vulnerable to texture style shifts and small perturbations to which humans are robust. In this work, we show that the robustness of neural networks can be greatly improved through the use of random convolutions as data augmentation. Random convolutions are approximately shape-preserving and may distort local textures. Intuitively, randomized convolutions create an infinite number of new domains with similar global shapes but random local texture. Therefore, we explore using outputs of multi-scale random convolutions as new images or mixing them with the original images during training. When applying a network trained with our approach to unseen domains, our method consistently improves the performance on domain generalization benchmarks and is scalable to ImageNet. In particular, in the challenging scenario of generalizing to the sketch domain in PACS and to ImageNet-Sketch, our method outperforms state-of-art methods by a large margin. More interestingly, our method can benefit downstream tasks by providing a more robust pretrained visual representation.",ディープニューラルネットワークは、さまざまなコンピュータービジョンのタスクで成功しますが、テクスチャスタイルの変化や人間が頑強な小さな摂動に対して脆弱であることが示されています。この作業では、データの拡張としてランダムな畳み込みを使用することで、ニューラルネットワークの堅牢性を大幅に向上できることを示します。ランダムな畳み込みはほぼ形状を保持し、ローカルテクスチャを歪める可能性があります。直感的に、ランダム化された畳み込みは、類似したグローバル形状であるがランダムなローカルテクスチャを持つ無数の新しいドメインを作成します。したがって、マルチスケールランダム畳み込みの出力を新しい画像として使用するか、トレーニング中に元の画像と混合することを検討します。見えないドメインへのアプローチでトレーニングされたネットワークを適用する場合、私たちの方法は、ドメイン一般化ベンチマークのパフォーマンスを一貫して改善し、ImageNetにスケーラブルです。特に、PACSのスケッチドメインとImageNet-Sketchに一般化するという難しいシナリオでは、私たちの方法は最先端の方法を大幅に上回っています。さらに興味深いことに、私たちの方法は、より堅牢な事前トレーニング済みの視覚的表現を提供することにより、ダウンストリームタスクに利益をもたらすことができます。,6.25,https://d3i71xaburhd42.cloudfront.net/b27ad18e20d27efe8a9fbc54b1c2dcef8b2da19f/2-Figure1-1.png
Towards Machine Ethics with Language Models,"['Dan Hendrycks', 'Collin Burns', 'Steven Basart', 'Andrew Critch', 'Jerry Li', 'Dawn Song', 'Jacob Steinhardt']",https://openreview.net/forum?id=dNy_RKzJacY,"We show how to assess a language model's knowledge of basic concepts of morality. We introduce the ETHICS dataset, a new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality. Models predict widespread moral judgments about diverse text scenarios. This requires connecting physical and social world knowledge to value judgements, a capability that may enable us to steer chatbot outputs or eventually regularize open-ended reinforcement learning agents. With the ETHICS dataset, we find that current language models have a promising but incomplete ability to predict basic human ethical judgements. Our work shows that progress can be made on machine ethics today, and it provides a steppingstone toward AI that is aligned with human values.",道徳の基本的な概念の言語モデルの知識を評価する方法を示します。正義、幸福、義務、美徳、常識的な道徳の概念にまたがる新しいベンチマークであるETHICSデータセットを紹介します。モデルは、多様なテキストシナリオに関する広範な道徳的判断を予測します。これには、物理​​的および社会的世界の知識を価値判断に結び付ける必要があります。これは、チャットボットの出力を操作したり、最終的にはオープンエンドの強化学習エージェントを正規化したりできる機能です。 ETHICSデータセットを使用すると、現在の言語モデルには、基本的な人間の倫理的判断を予測するための有望であるが不完全な能力があることがわかります。私たちの仕事は、今日の機械倫理が進歩する可能性があることを示しており、人間の価値観に沿ったAIへの足がかりを提供します。,6.25,
Variational State-Space Models for Localisation and Dense 3D Mapping in 6 DoF,"['Atanas Mirchev', 'Baris Kayalibay', 'Patrick van der Smagt', 'Justin Bayer']",https://openreview.net/forum?id=XAS3uKeFWj,"We solve the problem of 6-DoF localisation and 3D dense reconstruction in spatial environments as approximate Bayesian inference in a deep state-space model. Our approach leverages both learning and domain knowledge from multiple-view geometry and rigid-body dynamics. This results in an expressive predictive model of the world, often missing in current state-of-the-art visual SLAM solutions. The combination of variational inference, neural networks and a differentiable raycaster ensures that our model is amenable to end-to-end gradient-based optimisation. We evaluate our approach on realistic unmanned aerial vehicle flight data, nearing the performance of state-of-the-art visual-inertial odometry systems.
We demonstrate the applicability of the model to generative prediction and planning.
",深い状態空間モデルにおける近似ベイズ推定として、空間環境における6-DoFローカリゼーションと3D高密度再構成の問題を解決します。私たちのアプローチは、マルチビュージオメトリと剛体力学からの学習とドメイン知識の両方を活用します。これにより、世界の表現力豊かな予測モデルが生まれ、現在の最先端のビジュアルSLAMソリューションには見落とされがちです。変分推論、ニューラルネットワーク、および微分可能なレイキャスターの組み合わせにより、モデルがエンドツーエンドの勾配ベースの最適化に適していることが保証されます。最先端の視覚的慣性走行距離測定システムの性能に近づき、現実的な無人航空機の飛行データに対するアプローチを評価します。モデルの生成的予測と計画への適用可能性を示します。,6.25,https://d3i71xaburhd42.cloudfront.net/32d88170812ea8295536a4ecb1976b94ce5622ec/1-Figure1-1.png
Class Normalization for Zero-Shot Learning,"['Ivan Skorokhodov', 'Mohamed Elhoseiny']",https://openreview.net/forum?id=7pgFL2Dkyyy,"Normalization techniques have proved to be a crucial ingredient of successful training in a traditional supervised learning regime. However, in zero-shot learning (ZSL) world, these ideas have recieved only marginal attention. In this work, we study normalization in ZSL scenario from both theoretical and practical perspectives. First, we give a theoretical explanation to two popular tricks used in zero-shot learning: normalize+scale and attributes normalization and show that they help training by preserving variance during a forward pass. Next, we demonstrate that they are insufficient to normalize a deep ZSL model and propose class normalization: a normalization scheme, which alleviates this issue both provably and in practice. Third, we show that ZSL models typically have more irregular loss surface compared to traditional classifiers and that the proposed method partially remedies this problem. Then, we test our approach on 4 standard ZSL datasets and outperform sophisticated modern SotA with a simple MLP optimized without any bells and whistles and having ~50 times faster training speed. Finally, we generalize ZSL to a broader problem — continual ZSL, and introduce some principled metrics and rigorous baselines for this new setup. The code will be made available. ",正規化手法は、従来の教師あり学習体制でトレーニングを成功させるための重要な要素であることが証明されています。ただし、ゼロショット学習（ZSL）の世界では、これらのアイデアはごくわずかな注目しか受けていません。この作業では、理論的および実践的な観点から、ZSLシナリオでの正規化を研究します。最初に、ゼロショット学習で使用される2つの一般的なトリックである正規化+スケールと属性の正規化について理論的に説明し、フォワードパス中に分散を維持することでトレーニングに役立つことを示します。次に、ディープZSLモデルを正規化するには不十分であることを示し、クラスの正規化を提案します。正規化スキームは、この問題を証明可能かつ実際に軽減します。第三に、ZSLモデルは通常、従来の分類器と比較してより不規則な損失面を持ち、提案された方法がこの問題を部分的に改善することを示します。次に、4つの標準ZSLデータセットでアプローチをテストし、ベルやホイッスルなしで最適化され、トレーニング速度が50倍速いシンプルなMLPを使用して、洗練された最新のSotAを上回ります。最後に、ZSLをより広範な問題の継続的なZSLに一般化し、この新しいセットアップのいくつかの原則的なメトリックと厳密なベースラインを紹介します。コードが利用可能になります。,6.25,
Reducing the Computational Cost of Deep Generative Models with Binary Neural Networks,"['Thomas Bird', 'Friso Kingma', 'David Barber']",https://openreview.net/forum?id=sTeoJiB4uR,"Deep generative models provide a powerful set of tools to understand real-world data. But as these models improve, they increase in size and complexity, so their computational cost in memory and execution time grows. Using binary weights in neural networks is one method which has shown promise in reducing this cost. However, whether binary neural networks can be used in generative models is an open problem. In this work we show, for the first time, that we can successfully train generative models which utilize binary neural networks. This reduces the computational cost of the models massively. We develop a new class of binary weight normalization, and provide insights for architecture designs of these binarized generative models. We demonstrate that two state-of-the-art deep generative models, the ResNet VAE and Flow++ models, can be binarized effectively using these techniques. We train binary models that achieve loss values close to those of the regular models but are 90%-94% smaller in size, and also allow significant speed-ups in execution time.",深い生成モデルは、実世界のデータを理解するための強力なツールセットを提供します。ただし、これらのモデルが改善されると、サイズと複雑さが増すため、メモリと実行時間の計算コストが増大します。ニューラルネットワークでバイナリウェイトを使用することは、このコストを削減する上で有望であることが示されている1つの方法です。ただし、バイナリニューラルネットワークを生成モデルで使用できるかどうかは、未解決の問題です。この作業では、バイナリニューラルネットワークを利用する生成モデルを正常にトレーニングできることを初めて示します。これにより、モデルの計算コストが大幅に削減されます。新しいクラスのバイナリ重み正規化を開発し、これらのバイナリ化された生成モデルのアーキテクチャ設計に関する洞察を提供します。これらの手法を使用して、ResNetVAEモデルとFlow ++モデルの2つの最先端の深層生成モデルを効果的に2値化できることを示します。通常のモデルに近い損失値を達成するが90であるバイナリモデルをトレーニングします,6.25,
Adversarially-Trained Deep Nets Transfer Better,"['Francisco Utrera', 'Evan Kravitz', 'N. Benjamin Erichson', 'Rajiv Khanna', 'Michael W. Mahoney']",https://openreview.net/forum?id=ijJZbomCJIm,"Transfer learning has emerged as a powerful methodology for adapting pre-trained deep neural networks on image recognition tasks to new domains. This process consists of taking a neural network pre-trained on a large feature-rich source dataset, freezing the early layers that encode essential generic image properties, and then fine-tuning the last few layers in order to capture specific information related to the target situation. This approach is particularly useful when only limited or weakly labeled data are available for the new task. In this work, we demonstrate that adversarially-trained models transfer better than non-adversarially-trained models, especially if only limited data are available for the new domain task. Further, we observe that adversarial training biases the learnt representations to retaining shapes, as opposed to textures, which impacts the transferability of the source models. Finally, through the lens of influence functions, we discover that transferred adversarially-trained models contain more human-identifiable semantic information, which explains -- at least partly -- why adversarially-trained models transfer better.",転移学習は、画像認識タスクで事前にトレーニングされたディープニューラルネットワークを新しいドメインに適応させるための強力な方法論として登場しました。このプロセスは、大規模な機能豊富なソースデータセットで事前トレーニングされたニューラルネットワークを取得し、重要な一般的な画像プロパティをエンコードする初期レイヤーをフリーズし、ターゲットに関連する特定の情報をキャプチャするために最後の数レイヤーを微調整することで構成されます状況。このアプローチは、新しいタスクで使用できるデータが限られているか、ラベルが弱い場合に特に役立ちます。この作業では、特に新しいドメインタスクで利用できるデータが限られている場合に、敵対的に訓練されたモデルが非敵対的に訓練されたモデルよりも転送が優れていることを示します。さらに、敵対的なトレーニングは、ソースモデルの転送可能性に影響を与えるテクスチャではなく、学習した表現を保持する形状にバイアスすることを観察します。最後に、影響関数のレンズを通して、転送された敵対的に訓練されたモデルには、より多くの人間が識別可能なセマンティック情報が含まれていることを発見します。,6.25,
Using latent space regression to analyze and leverage compositionality in GANs,"['Lucy Chai', 'Jonas Wulff', 'Phillip Isola']",https://openreview.net/forum?id=sjuuTm4vj0,"In recent years, Generative Adversarial Networks have become ubiquitous in both research and public perception, but how GANs convert an unstructured latent code to coherent, high quality output is still an open question. In this work, we investigate regression into the latent space as a probe to understand the compositional properties of GANs. We find that combining the regressor and a pretrained generator provides a strong image prior, allowing us to create composite images from a collage of random image parts at inference time and leverage the generator to rectify the inconsistencies. To compare compositional properties across different generators, we measure the trade-offs between reconstruction of the unrealistic input and image quality of the regenerated samples. We find that the regression approach enables more localized editing of individual image parts compared to direct editing in the latent space, and we conduct experiments to quantify this independence effect. Our method is agnostic to how image parts are extracted, and does not require explicit labelled knowledge of concepts during training. Because this approach only uses a single feed-forward pass, it can operate in real-time and also perform a number of related applications, such as image inpainting or example-based image editing. We demonstrate its effectiveness on several GANs and datasets.",近年、Generative Adversarial Networksは、研究と一般の認識の両方でユビキタスになっていますが、GANが非構造化潜在コードを一貫性のある高品質の出力に変換する方法は未解決の問題です。この作業では、GANの構成特性を理解するためのプローブとして、潜在空間への回帰を調査します。リグレッサと事前トレーニング済みジェネレータを組み合わせると、事前に強力な画像が提供され、推論時にランダムな画像パーツのコラージュから合成画像を作成し、ジェネレータを利用して不整合を修正できることがわかります。異なるジェネレーター間で組成特性を比較するために、非現実的な入力の再構成と再生されたサンプルの画質との間のトレードオフを測定します。回帰アプローチでは、潜在空間での直接編集と比較して、個々の画像部分のより局所的な編集が可能であることがわかり、この独立効果を定量化するための実験を行います。私たちの方法は、画像部分がどのように抽出されるかにとらわれず、トレーニング中に概念の明示的なラベル付きの知識を必要としません。このアプローチは単一のフィードフォワードパスのみを使用するため、リアルタイムで動作し、画像の修復や例に基づく画像編集など、関連する多くのアプリケーションを実行することもできます。いくつかのGANとデータセットでその有効性を示します。,6.25,
Local Convergence Analysis of Gradient Descent Ascent with Finite Timescale Separation,"['Tanner Fiez', 'Lillian J Ratliff']",https://openreview.net/forum?id=AWOSz_mMAPx,"We study the role that a finite timescale separation parameter $\tau$ has on gradient descent-ascent in non-convex, non-concave zero-sum games where the learning rate of player 1 is denoted by $\gamma_1$ and the learning rate of player 2 is defined to be $\gamma_2=\tau\gamma_1$. We show there exists  a finite timescale separation parameter $\tau^{\ast}$ such that $x^{\ast}$ is a stable critical point of gradient descent-ascent for all $\tau \in (\tau^{\ast}, \infty)$ if and only if it is a strict local minmax equilibrium.  Moreover, we provide an explicit construction for computing $\tau^{\ast}$ along with corresponding convergence rates. The convergence results we present are complemented by a non-convergence result: given a critical point $x^{\ast}$ that is not a strict local minmax equilibrium, there exists a finite timescale separation $\tau_0$ such that $x^{\ast}$ is unstable for all $\tau\in (\tau_0, \infty)$. Finally, we extend the results to gradient penalty regularization methods for generative adversarial networks and empirically demonstrate on CIFAR-10 and CelebA the significant impact timescale separation has on training performance.",プレーヤー1の学習率が1で表され、プレーヤー2の学習率が次のように定義される非凸、非凹のゼロサムゲームで、有限のタイムスケール分離パラメーターが勾配降下-上昇に及ぼす役割を研究します。 2 =1。x^（*）がすべての（^（*）、）の勾配降下-上昇の安定した臨界点であるような有限のタイムスケール分離パラメーター^（*）が存在することを示します。厳密な局所最小最大平衡。さらに、対応する収束率とともに^（*）を計算するための明示的な構成を提供します。私たちが提示する収束結果は、非収束結果によって補完されます。厳密な局所ミニマックス平衡ではない臨界点x ^（*）が与えられると、x ^（*）がすべてに対して不安定になるような有限のタイムスケール分離0が存在します。 （0、）。最後に、結果を生成的敵対的ネットワークの勾配ペナルティ正則化手法に拡張し、CIFAR-10とCelebAで、タイムスケールの分離がトレーニングパフォーマンスに与える重要な影響を経験的に示します。,6.25,
Estimating informativeness of samples with Smooth Unique Information,"['Hrayr Harutyunyan', 'Alessandro Achille', 'Giovanni Paolini', 'Orchid Majumder', 'Avinash Ravichandran', 'Rahul Bhotika', 'Stefano Soatto']",https://openreview.net/forum?id=kEnBH98BGs5,"We define a notion of information that an individual sample provides to the training of a neural network, and we specialize it to measure both how much a sample informs the final weights and how much it informs the function computed by the weights. Though related, we show that these quantities have a  qualitatively different behavior. We give efficient approximations of these quantities using a linearized network and demonstrate empirically that the approximation is accurate for real-world architectures, such as pre-trained ResNets. We apply these measures to several problems, such as dataset summarization, analysis of under-sampled classes, comparison of informativeness of different data sources, and detection of adversarial and corrupted examples. Our work generalizes existing frameworks, but enjoys better computational properties for heavily over-parametrized models, which makes it possible to apply it to real-world networks.",個々のサンプルがニューラルネットワークのトレーニングに提供する情報の概念を定義し、サンプルが最終的な重みを通知する量と、重みによって計算された関数を通知する量の両方を測定するように特化します。関連していますが、これらの量は質的に異なる動作をすることを示しています。線形化されたネットワークを使用してこれらの量の効率的な近似を行い、事前にトレーニングされたResNetなどの実際のアーキテクチャで近似が正確であることを経験的に示します。これらの対策は、データセットの要約、サンプリング不足のクラスの分析、さまざまなデータソースの有益性の比較、敵対的で破損した例の検出など、いくつかの問題に適用されます。私たちの仕事は既存のフレームワークを一般化しますが、非常にパラメーター化されたモデルの計算特性が向上しているため、実際のネットワークに適用することができます。,6.25,https://d3i71xaburhd42.cloudfront.net/e557a52b1917c9efbd3a9c794faa80fc5f37d30c/7-Figure1-1.png
Adaptive Federated Optimization,"['Sashank J. Reddi', 'Zachary Charles', 'Manzil Zaheer', 'Zachary Garrett', 'Keith Rush', 'Jakub Konečný', 'Sanjiv Kumar', 'Hugh Brendan McMahan']",https://openreview.net/forum?id=LkFG3lB13U5,"Federated learning is a distributed machine learning paradigm in which a large number of clients coordinate with a central server to learn a model without sharing their own training data. Standard federated optimization methods such as Federated Averaging (FedAvg) are often difficult to tune and exhibit unfavorable convergence behavior. In non-federated settings, adaptive optimization methods have had notable success in combating such issues. In this work, we propose federated versions of adaptive optimizers, including Adagrad, Adam, and  Yogi, and analyze their convergence in the presence of heterogeneous data for general non-convex settings. Our results highlight the interplay between client heterogeneity and communication efficiency. We also perform extensive experiments on these methods and show that the use of adaptive optimizers can significantly improve the performance of federated learning.",統合学習は分散型機械学習パラダイムであり、多数のクライアントが中央サーバーと連携して、独自のトレーニングデータを共有せずにモデルを学習します。 Federated Averaging（FedAvg）などの標準的なフェデレーション最適化手法は、調整が難しく、好ましくない収束動作を示すことがよくあります。非連合環境では、適応最適化手法はそのような問題との闘いにおいて顕著な成功を収めてきました。この作業では、Adagrad、Adam、Yogiなどの適応オプティマイザーのフェデレーションバージョンを提案し、一般的な非凸設定の異種データの存在下での収束を分析します。私たちの結果は、クライアントの異質性と通信効率の間の相互作用を強調しています。また、これらの方法について広範な実験を行い、適応オプティマイザーを使用すると、連合学習のパフォーマンスを大幅に向上できることを示しています。,6.25,https://d3i71xaburhd42.cloudfront.net/9691d9bad193e9c371678d99c3fe5afe510dc845/10-Figure2-1.png
Personalized Federated Learning with First Order Model Optimization,"['Michael Zhang', 'Karan Sapra', 'Sanja Fidler', 'Serena Yeung', 'Jose M. Alvarez']",https://openreview.net/forum?id=ehJqJQk9cw,"While federated learning traditionally aims to train a single global model across decentralized local datasets, one model may not always be ideal for all participating clients. Here we propose an alternative, where each client only federates with other relevant clients to obtain a stronger model per client-specific objectives. To achieve this personalization, rather than computing a single model average with constant weights for the entire federation as in traditional FL, we efficiently calculate optimal weighted model combinations for each client, based on figuring out how much a client can benefit from another's model. We do not assume knowledge of any underlying data distributions or client similarities, and allow each client to optimize for arbitrary target distributions of interest, enabling greater flexibility for personalization. We evaluate and characterize our method on a variety of federated settings, datasets, and degrees of local data heterogeneity. Our method outperforms existing alternatives, while also enabling new features for personalized FL such as transfer outside of local data distributions.",連合学習は、従来、分散型ローカルデータセット全体で単一のグローバルモデルをトレーニングすることを目的としていますが、1つのモデルがすべての参加クライアントにとって常に理想的であるとは限りません。ここでは、各クライアントが他の関連するクライアントとのみ連携して、クライアント固有の目的ごとに強力なモデルを取得するという代替案を提案します。このパーソナライズを実現するために、従来のFLのようにフェデレーション全体で一定の重みを持つ単一のモデル平均を計算するのではなく、クライアントが別のモデルからどれだけの利益を得ることができるかを把握することに基づいて、各クライアントの最適な重み付きモデルの組み合わせを効率的に計算します。基礎となるデータ分布やクライアントの類似性に関する知識を前提とせず、各クライアントが関心のある任意のターゲット分布に合わせて最適化できるようにすることで、パーソナライズの柔軟性を高めます。さまざまなフェデレーション設定、データセット、およびローカルデータの不均一性の程度に基づいて、メソッドを評価および特性評価します。私たちの方法は、既存の代替手段よりも優れていると同時に、ローカルデータ配信の外部への転送など、パーソナライズされたFLの新機能を有効にします。,6.25,https://d3i71xaburhd42.cloudfront.net/30dba214afa23aa38340d9035ebfdbd77a135411/6-Figure1-1.png
Drop-Bottleneck: Learning Discrete Compressed Representation for Noise-Robust Exploration,"['Jaekyeom Kim', 'Minjung Kim', 'Dongyeon Woo', 'Gunhee Kim']",https://openreview.net/forum?id=1rxHOBjeDUW,"We propose a novel information bottleneck (IB) method named Drop-Bottleneck, which discretely drops input features that are irrelevant to the target variable. Drop-Bottleneck not only enjoys a simple and tractable compression objective but also additionally provides a deterministic compressed representation of the input variable, which is useful for inference tasks that require consistent representation. Moreover, it can perform feature selection considering each feature dimension's relevance to the target task, which is unattainable by most neural network-based IB methods. We propose an exploration method based on Drop-Bottleneck for reinforcement learning tasks. In a multitude of noisy and reward sparse maze navigation tasks in VizDoom (Kempka et al., 2016) and DMLab (Beattie et al., 2016), our exploration method achieves state-of-the-art performance. As a new IB framework, we demonstrate that Drop-Bottleneck outperforms Variational Information Bottleneck (VIB) (Alemi et al., 2017) in multiple aspects including adversarial robustness and dimensionality reduction.",Drop-Bottleneckという名前の新しい情報ボトルネック（IB）メソッドを提案します。これは、ターゲット変数に関係のない入力特徴を個別にドロップします。 Drop-Bottleneckは、シンプルで扱いやすい圧縮目標を享受するだけでなく、入力変数の決定論的な圧縮表現を提供します。これは、一貫した表現を必要とする推論タスクに役立ちます。さらに、ほとんどのニューラルネットワークベースのIB手法では達成できない、ターゲットタスクとの各特徴次元の関連性を考慮して特徴選択を実行できます。強化学習タスクのためのDrop-Bottleneckに基づく探索方法を提案します。 VizDoom（Kempka et al。、2016）およびDMLab（Beattie et al。、2016）の多数のノイズが多く、報酬がまばらな迷路ナビゲーションタスクで、私たちの探索方法は最先端のパフォーマンスを実現します。新しいIBフレームワークとして、敵対的な堅牢性や次元削減などの複数の側面で、Drop-BottleneckがVariational Information Bottleneck（VIB）（Alemi et al。、2017）よりも優れていることを示します。,6.25,
On the Curse of Memory in Recurrent Neural Networks: Approximation and Optimization Analysis,"['Zhong Li', 'Jiequn Han', 'Weinan E', 'Qianxiao Li']",https://openreview.net/forum?id=8Sqhl-nF50,"We study the approximation properties and optimization dynamics of recurrent neural networks (RNNs) when applied to learn input-output relationships in temporal data. We consider the simple but representative setting of using continuous-time linear RNNs to learn from data generated by linear relationships. Mathematically, the latter can be understood as a sequence of linear functionals.  We prove a universal approximation theorem of such linear functionals and characterize the approximation rate.  Moreover, we perform a fine-grained dynamical analysis of training linear RNNs by gradient methods.  A unifying theme uncovered is the non-trivial effect of memory, a notion that can be made precise in our framework, on both approximation and optimization: when there is long term memory in the target, it takes a large number of neurons to approximate it. Moreover, the training process will suffer from slow downs.  In particular, both of these effects become exponentially more pronounced with increasing memory - a phenomenon we call the “curse of memory”.  These analyses represent a basic step towards a concrete mathematical understanding of new phenomenons that may arise in learning temporal relationships using recurrent architectures.",時間データの入出力関係を学習するために適用された場合のリカレントニューラルネットワーク（RNN）の近似特性と最適化ダイナミクスを研究します。線形関係によって生成されたデータから学習するために、連続時間線形RNNを使用する単純ですが代表的な設定を検討します。数学的には、後者は線形汎関数のシーケンスとして理解できます。このような線形汎関数の普遍近似定理を証明し、近似率を特徴付けます。さらに、勾配法による線形RNNのトレーニングの詳細な動的分析を実行します。明らかになった統一テーマは、近似と最適化の両方で、フレームワークで正確にすることができる概念であるメモリの重要な効果です。ターゲットに長期記憶がある場合、それを近似するには多数のニューロンが必要です。 。さらに、トレーニングプロセスは遅くなります。特に、これらの効果は両方とも、記憶の増加とともに指数関数的に顕著になります。これは、記憶の呪いと呼ばれる現象です。これらの分析は、反復アーキテクチャを使用して時間的関係を学習する際に発生する可能性のある新しい現象の具体的な数学的理解に向けた基本的なステップを表しています。,6.25,https://d3i71xaburhd42.cloudfront.net/423b717951dbca0079b2f753e451d51fdd05cb20/14-Figure1-1.png
Improving Zero-Shot Voice Style Transfer via Disentangled Representation Learning,"['Siyang Yuan', 'Pengyu Cheng', 'Ruiyi Zhang', 'Weituo Hao', 'Zhe Gan', 'Lawrence Carin']",https://openreview.net/forum?id=TgSVWXw22FQ,"Voice style transfer, also called voice conversion, seeks to modify one speaker's voice to generate speech as if it came from another (target) speaker. Previous works have made progress on voice conversion with parallel training data and pre-known speakers. However, zero-shot voice style transfer, which learns from non-parallel data and generates voices for previously unseen speakers, remains a challenging problem. In this paper we propose a novel zero-shot voice transfer method via disentangled representation learning. The proposed method first encodes speaker-related style and voice content of each input voice into separate low-dimensional embedding spaces, and then transfers to a new voice by combining the source content embedding and target style embedding through a decoder. With information-theoretic guidance, the style and content embedding spaces are representative and (ideally) independent of each other. On real-world datasets, our method outperforms other baselines and obtains state-of-the-art results in terms of transfer accuracy and voice naturalness.",音声変換とも呼ばれる音声スタイル転送は、ある話者の声を変更して、別の（ターゲット）話者から来たかのように音声を生成しようとします。以前の作品は、並列トレーニングデータと既知の話者による音声変換で進歩を遂げました。ただし、非並列データから学習し、以前は見られなかった話者の音声を生成するゼロショット音声スタイル転送は、依然として困難な問題です。本論文では、解きほぐされた表現学習による新しいゼロショット音声転送法を提案した。提案手法は、まず各入力音声の話者関連のスタイルと音声コンテンツを別々の低次元埋め込み空間にエンコードし、次にデコーダを介してソースコンテンツの埋め込みとターゲットスタイルの埋め込みを組み合わせることによって新しい音声に転送します。情報理論のガイダンスにより、スタイルとコンテンツの埋め込みスペースは代表的であり、（理想的には）互いに独立しています。実際のデータセットでは、私たちの方法は他のベースラインを上回り、転送精度と音声の自然さの点で最先端の結果を取得します。,6.25,
Neural representation and generation for RNA secondary structures,"['Zichao Yan', 'William L. Hamilton', 'Mathieu Blanchette']",https://openreview.net/forum?id=snOgiCYZgJ7,"Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.",私たちの仕事は、細胞の活動や機能に影響を与える複雑な構造をとることができる遺伝子高分子の一種であるRNAの生成と標的設計に関係しています。大規模で複雑な生物学的構造の設計は、専用のグラフベースの深層生成モデリング技術に拍車をかけます。これは、計算による創薬の重要であるが過小評価されている側面を表しています。この作業では、さまざまなRNA構造モダリティの表現と生成の背後にある原理を調査し、意味のある潜在空間にこれらの分子構造とその配列を一緒に埋め込んで生成するための柔軟なフレームワークを提案します。 RNAの分子構造を深く理解している当社の最も洗練されたエンコードおよびデコード方法は、分子グラフとジャンクションツリー階層で動作し、RNA構造の規則性とフォールディングメカニズムに関する強力な誘導バイアスを統合して、高い構造妥当性、安定性、多様性を実現します。生成されたRNAの数が達成されます。また、タンパク質との相互作用に関してRNA分子埋め込みの潜在空間を適切に整理することを目指しており、ターゲットを絞った最適化を使用してこの潜在空間をナビゲートし、目的の新規RNA分子を検索します。,6.25,https://d3i71xaburhd42.cloudfront.net/2f2c563d3ebff5133a5fc67a0d3ef2462029e404/3-Figure1-1.png
"Learning ""What-if"" Explanations for Sequential Decision-Making","['Ioana Bica', 'Daniel Jarrett', 'Alihan Hüyük', 'Mihaela van der Schaar']",https://openreview.net/forum?id=h0de3QWtGG,"Building interpretable parameterizations of real-world decision-making on the basis of demonstrated behavior--i.e. trajectories of observations and actions made by an expert maximizing some unknown reward function--is essential for introspecting and auditing policies in different institutions. In this paper, we propose learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to ``""what if'' outcomes: Given the current history of observations, what would happen if we took a particular action? To learn these cost-benefit tradeoffs associated with the expert's actions, we integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior, and also satisfies the constraints of real-world decision-making---where active experimentation is often impossible (e.g. in healthcare). Additionally, by estimating the effects of different actions, counterfactuals readily tackle the off-policy nature of policy evaluation in the batch setting, and can naturally accommodate settings where the expert policies depend on histories of observations rather than just current states. Through illustrative experiments in both real and simulated medical environments, we highlight the effectiveness of our batch, counterfactual inverse reinforcement learning approach in recovering accurate and interpretable descriptions of behavior.",実証された行動に基づいて、現実世界の意思決定の解釈可能なパラメータ化を構築します。いくつかの未知の報酬機能を最大化する専門家によって行われた観察と行動の軌跡は、さまざまな機関の方針を内省し監査するために不可欠です。この論文では、「もしも結果：現在の観測の歴史を考えると、特定の行動をとったらどうなるだろうか？これらのコストを学ぶために-」に関する選好の観点から彼らの報酬関数をモデル化することによって専門家の決定の説明を学ぶことを提案する専門家の行動に関連する利益のトレードオフ、反事実的推論をバッチ逆強化学習に統合します。これは、報酬関数を定義し、専門家の行動を説明する原理的な方法を提供し、アクティブな実験がしばしば不可能である現実の意思決定の制約も満たします（さらに、さまざまなアクションの影響を推定することにより、カウンターファクトはバッチ設定でのポリシー評価のポリシー外の性質に容易に取り組み、専門家のポリシーが現在の状態だけでなく観察の履歴に依存する設定に自然に対応できます。 。実際の医療環境とシミュレートされた医療環境の両方での実例となる実験を通じてメントでは、行動の正確で解釈可能な記述を回復する際の、バッチの反事実的逆強化学習アプローチの有効性を強調します。,6.25,
Fair Mixup: Fairness via Interpolation,"['Ching-Yao Chuang', 'Youssef Mroueh']",https://openreview.net/forum?id=DNl5s5BXeBn,"Training classifiers under fairness constraints such as group fairness, regularizes the disparities of predictions between the groups. Nevertheless, even though the constraints are satisfied during training, they might not generalize at evaluation time. To improve the generalizability of fair classifiers, we propose fair mixup, a new data augmentation strategy for imposing the fairness constraint. In particular, we show that fairness can be achieved by regularizing the models on paths of interpolated samples  between the groups. We use mixup, a powerful data augmentation strategy  to generate these interpolates. We analyze fair mixup and empirically show that it ensures a better generalization for both accuracy and fairness measurement in tabular, vision, and language benchmarks.",グループの公平性などの公平性の制約の下で分類器をトレーニングすると、グループ間の予測の不一致が正規化されます。それでも、トレーニング中に制約が満たされていても、評価時に一般化されない場合があります。公平な分類器の一般化可能性を改善するために、公平性の制約を課すための新しいデータ拡張戦略である公平な混合を提案します。特に、グループ間の補間サンプルのパスでモデルを正則化することにより、公平性を実現できることを示します。これらの補間を生成するために、強力なデータ拡張戦略であるミックスアップを使用します。公正な取り違えを分析し、表、ビジョン、および言語のベンチマークでの精度と公平性の測定の両方について、より良い一般化を保証することを経験的に示しています。,6.25,
Better Fine-Tuning by Reducing Representational Collapse,"['Armen Aghajanyan', 'Akshat Shrivastava', 'Anchit Gupta', 'Naman Goyal', 'Luke Zettlemoyer', 'Sonal Gupta']",https://openreview.net/forum?id=OQ08SN70M1V,"Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.",広く採用されていますが、事前トレーニングされた言語モデルを微調整するための既存のアプローチは、ハイパーパラメータ設定全体で不安定であることが示され、信頼領域メソッドに関する最近の作業の動機となっています。この論文では、信頼領域理論に根ざした単純化された効率的な方法を提示します。これは、以前に使用された敵対的目的をパラメトリックノイズ（正規分布または一様分布からのサンプリング）に置き換え、パフォーマンスを損なうことなく、可能な場合は微調整中に表現の変更を阻止します。また、表象的崩壊を研究することにより、信頼領域法の使用をより一般的に動機付けるための新しい分析を紹介します。特定の最終タスク用に微調整されているため、事前にトレーニングされたモデルからの一般化可能な表現の劣化。広範な実験により、私たちの微調整方法は、さまざまな理解および生成タスク（DailyMail / CNN、Gigaword、Reddit TIFU、およびGLUEベンチマークを含む）で以前の信頼領域方法のパフォーマンスと同等またはそれを上回り、同時にはるかに高速であることが示されています。また、表現が崩壊する可能性が低いことも示しています。事前にトレーニングされたモデルは、微調整されるたびに、より一般化可能な表現を維持します。,6.25,https://d3i71xaburhd42.cloudfront.net/b88c11922cac84e5ea902f82d27ae21c3dda2e04/4-Figure1-1.png
Nonseparable Symplectic Neural Networks,"['Shiying Xiong', 'Yunjin Tong', 'Xingzhe He', 'Cheng Yang', 'Shuqi Yang', 'Bo Zhu']",https://openreview.net/forum?id=B5VvQrI49Pa,"Predicting the behaviors of Hamiltonian systems has been drawing increasing attention in scientific machine learning. However, the vast majority of the literature was focused on predicting separable Hamiltonian systems with their kinematic and potential energy terms being explicitly decoupled, while building data-driven paradigms to predict nonseparable Hamiltonian systems that are ubiquitous in fluid dynamics and quantum mechanics were rarely explored. The main computational challenge lies in the effective embedding of symplectic priors to describe the inherently coupled evolution of position and momentum, which typically exhibits intricate dynamics. To solve the problem, we propose a novel neural network architecture, Nonseparable Symplectic Neural Networks (NSSNNs), to uncover and embed the symplectic structure of a nonseparable Hamiltonian system from limited observation data. The enabling mechanics of our approach is an augmented symplectic time integrator to decouple the position and momentum energy terms and facilitate their evolution. We demonstrated the efficacy and versatility of our method by predicting a wide range of Hamiltonian systems, both separable and nonseparable, including chaotic vortical flows. We showed the unique computational merits of our approach to yield long-term, accurate, and robust predictions for large-scale Hamiltonian systems by rigorously enforcing symplectomorphism.",ハミルトン系の振る舞いを予測することは、科学的な機械学習においてますます注目を集めています。ただし、文献の大部分は、運動学的および位置エネルギー項が明示的に分離された分離可能なハミルトン系の予測に焦点を当てていましたが、流体力学や量子力学に遍在する分離不可能なハミルトン系を予測するデータ駆動型パラダイムの構築はめったに検討されていませんでした。主な計算上の課題は、位置と運動量の本質的に結合された進化を説明するためのシンプレクティックプライアの効果的な埋め込みにあります。これは通常、複雑なダイナミクスを示します。この問題を解決するために、限られた観測データから分離不可能なハミルトン系のシンプレクティック構造を明らかにして埋め込むために、新しいニューラルネットワークアーキテクチャである分離不可能なシンプレクティックニューラルネットワーク（NSSNN）を提案します。私たちのアプローチを可能にするメカニズムは、位置と運動量のエネルギー項を分離し、それらの進化を促進するための拡張シンプレクティック時間積分器です。カオス渦流を含む、分離可能と分離不可能の両方の広範囲のハミルトン系を予測することにより、私たちの方法の有効性と多様性を実証しました。シンプレクティック同形性を厳密に適用することにより、大規模ハミルトン系の長期的で正確かつロバストな予測を生成するアプローチの独自の計算上のメリットを示しました。,6.25,https://d3i71xaburhd42.cloudfront.net/10b41a4a58bba7542f1ce4563f7f8770058f3703/2-Figure1-1.png
Convex Regularization behind Neural Reconstruction,"['Arda Sahiner', 'Morteza Mardani', 'Batu Ozturkler', 'Mert Pilanci', 'John M. Pauly']",https://openreview.net/forum?id=VErQxgyrbfn,"Neural networks have shown tremendous potential for reconstructing high-resolution images in inverse problems. The non-convex and opaque nature of neural networks, however, hinders their utility in sensitive applications such as medical imaging. To cope with this challenge, this paper advocates a convex duality framework that makes a two-layer fully-convolutional ReLU denoising network amenable to convex optimization. The convex dual network not only offers the optimum training with convex solvers, but also facilitates interpreting training and prediction. In particular, it implies training neural networks with weight decay regularization induces path sparsity while the prediction is piecewise linear filtering. A range of experiments with MNIST and fastMRI datasets confirm the efficacy of the dual network optimization problem. ",ニューラルネットワークは、逆問題で高解像度画像を再構成するための途方もない可能性を示しています。ただし、ニューラルネットワークの非凸で不透明な性質は、医用画像などの高感度アプリケーションでの有用性を妨げます。この課題に対処するために、この論文では、2層の完全畳み込みReLUノイズ除去ネットワークを凸最適化に適したものにする凸双対フレームワークを提唱しています。凸型デュアルネットワークは、凸型ソルバーによる最適なトレーニングを提供するだけでなく、トレーニングと予測の解釈も容易にします。特に、予測が区分的線形フィルタリングであるのに対し、重み減衰正則化を使用してニューラルネットワークをトレーニングするとパスのスパース性が誘発されることを意味します。 MNISTおよびfastMRIデータセットを使用した一連の実験により、デュアルネットワーク最適化問題の有効性が確認されています。,6.25,https://d3i71xaburhd42.cloudfront.net/a0886a4e611b211c4baf7b2fa5971efcb505c9de/5-Figure1-1.png
Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration,"['Xavier Puig', 'Tianmin Shu', 'Shuang Li', 'Zilin Wang', 'Yuan-Hong Liao', 'Joshua B. Tenenbaum', 'Sanja Fidler', 'Antonio Torralba']",https://openreview.net/forum?id=w_7JMpGZRh0,"In this paper, we introduce Watch-And-Help (WAH), a challenge for testing social intelligence in agents. In WAH, an AI agent needs to help a human-like agent perform a complex household task efficiently. To succeed, the AI agent needs to i) understand the underlying goal of the task by watching a single demonstration of the human-like agent performing the same task (social perception), and ii) coordinate with the human-like agent to solve the task in an unseen environment as fast as possible (human-AI collaboration). For this challenge, we build VirtualHome-Social, a multi-agent household environment, and provide a benchmark including both planning and learning based baselines. We evaluate the performance of AI agents with the human-like agent as well as and with real humans using objective metrics and subjective user ratings. Experimental results demonstrate that our challenge and virtual environment enable a systematic evaluation on the important aspects of machine social intelligence at scale.",このホワイトペーパーでは、エージェントのソーシャルインテリジェンスをテストするための課題であるWatch-And-Help（WAH）を紹介します。 WAHでは、AIエージェントは、人間のようなエージェントが複雑な家事を効率的に実行できるようにする必要があります。成功するには、AIエージェントは、i）同じタスク（社会的知覚）を実行する人間のようなエージェントの単一のデモンストレーションを見て、タスクの根本的な目標を理解し、ii）人間のようなエージェントと調整して解決する必要があります。目に見えない環境でできるだけ早くタスクを実行します（人間とAIのコラボレーション）。この課題のために、マルチエージェントの家庭環境であるVirtualHome-Socialを構築し、計画と学習に基づくベースラインの両方を含むベンチマークを提供します。客観的な指標と主観的なユーザー評価を使用して、AIエージェントのパフォーマンスを、人間のようなエージェントと実際の人間で評価します。実験結果は、私たちの課題と仮想環境が、大規模な機械の社会的知能の重要な側面に関する体系的な評価を可能にすることを示しています。,6.25,https://d3i71xaburhd42.cloudfront.net/dd24143d9f9d6244bf4c7a6a1cd30ab9ae059096/2-Figure1-1.png
Teaching Temporal Logics to Neural Networks,"['Christopher Hahn', 'Frederik Schmitt', 'Jens U. Kreber', 'Markus Norman Rabe', 'Bernd Finkbeiner']",https://openreview.net/forum?id=dOcQK-f4byz,"We study two fundamental questions in neuro-symbolic computing: can deep learning tackle challenging problems in logics end-to-end, and can neural networks learn the semantics of logics. In this work we focus on linear-time temporal logic (LTL), as it is widely used in verification. We train a Transformer on the problem to directly predict a solution, i.e. a trace, to a given LTL formula. The training data is generated with classical solvers, which, however, only provide one of many possible solutions to each formula. We demonstrate that it is sufficient to train on those particular solutions to formulas, and that Transformers can predict solutions even to formulas from benchmarks from the literature on which the classical solver timed out. Transformers also generalize to the semantics of the logics: while they often deviate from the solutions found by the classical solvers, they still predict correct solutions to most formulas.",ニューロシンボリックコンピューティングの2つの基本的な質問を研究します。ディープラーニングはロジックの難しい問題にエンドツーエンドで取り組むことができ、ニューラルネットワークはロジックのセマンティクスを学習できます。この作業では、検証で広く使用されている線形時相論理（LTL）に焦点を当てます。問題についてTransformerをトレーニングして、特定のLTL式の解、つまりトレースを直接予測します。トレーニングデータは古典的なソルバーを使用して生成されますが、各式に対して可能な多くのソリューションの1つしか提供しません。数式の特定のソリューションをトレーニングするだけで十分であり、Transformersは、古典的なソルバーがタイムアウトした文献のベンチマークから数式のソリューションを予測できることを示しています。トランスフォーマーは、ロジックのセマンティクスにも一般化されます。従来のソルバーで見つかった解から逸脱することがよくありますが、それでもほとんどの式の正しい解を予測します。,6.25,
Latent Convergent Cross Mapping,"['Edward De Brouwer', 'Adam Arany', 'Jaak Simm', 'Yves Moreau']",https://openreview.net/forum?id=4TSiOTkKe5P,"Discovering causal structures of temporal processes is a major tool of scientific inquiry because it helps us better understand and explain the mechanisms driving a phenomenon of interest, thereby facilitating analysis, reasoning, and synthesis for such systems. 
However, accurately inferring causal structures within a phenomenon based on observational data only is still an open problem. Indeed, this type of data usually consists in short time series with missing or noisy values for which causal inference is increasingly difficult. In this work, we propose a method to uncover causal relations in chaotic dynamical systems from short, noisy and sporadic time series (that is, incomplete observations at infrequent and irregular intervals) where the classical convergent cross mapping (CCM) fails. Our method works by learning a Neural ODE latent process modeling the state-space dynamics of the time series and by checking the existence of a continuous map between the resulting processes. We provide theoretical analysis and show empirically that Latent-CCM can reliably uncover the true causal pattern, unlike traditional methods.",時間的プロセスの因果構造を発見することは、関心のある現象を推進するメカニズムをよりよく理解して説明するのに役立ち、それによってそのようなシステムの分析、推論、および統合を容易にするため、科学的調査の主要なツールです。しかし、観測データのみに基づいて現象内の因果構造を正確に推測することは、依然として未解決の問題です。実際、このタイプのデータは通常、因果関係の推測がますます困難になる、値が欠落しているかノイズが多い短い時系列で構成されています。この作業では、古典的な収束クロスマッピング（CCM）が失敗する、短く、ノイズが多く、散発的な時系列（つまり、まれで不規則な間隔での不完全な観測）からカオス力学系の因果関係を明らかにする方法を提案します。私たちの方法は、時系列の状態空間ダイナミクスをモデル化するニューラルODE潜在プロセスを学習し、結果のプロセス間の連続マップの存在をチェックすることによって機能します。理論的分析を提供し、Latent-CCMが従来の方法とは異なり、真の原因パターンを確実に明らかにできることを経験的に示します。,6.25,
Optimizing Memory Placement using Evolutionary Graph Reinforcement Learning,"['Shauharda Khadka', 'Estelle Aflalo', 'Mattias Mardar', 'Avrech Ben-David', 'Santiago Miret', 'Shie Mannor', 'Tamir Hazan', 'Hanlin Tang', 'Somdeb Majumdar']",https://openreview.net/forum?id=-6vS_4Kfz0,"For deep neural network accelerators, memory movement is both energetically expensive and can bound computation. Therefore, optimal mapping of tensors to memory hierarchies is critical to performance. The growing complexity of neural networks calls for automated memory mapping instead of manual heuristic approaches; yet the search space of neural network computational graphs have previously been prohibitively large. We introduce Evolutionary Graph Reinforcement Learning (EGRL), a method designed for large search spaces, that combines graph neural networks, reinforcement learning, and evolutionary search. A set of fast, stateless policies guide the evolutionary search to improve its sample-efficiency. We train and validate our approach directly on the Intel NNP-I chip for inference. EGRL outperforms policy-gradient, evolutionary search and dynamic programming baselines on BERT, ResNet-101 and ResNet-50. We additionally achieve 28-78% speed-up compared to the native NNP-I compiler on all three workloads.  ",ディープニューラルネットワークアクセラレータの場合、メモリの移動はエネルギー的に高価であり、計算を制限する可能性があります。したがって、テンソルのメモリ階層への最適なマッピングは、パフォーマンスにとって重要です。ニューラルネットワークの複雑さが増すにつれて、手動のヒューリスティックアプローチではなく自動メモリマッピングが必要になります。それでも、ニューラルネットワークの計算グラフの検索スペースは以前は法外に大きかった。グラフニューラルネットワーク、強化学習、進化的検索を組み合わせた、大規模な検索空間向けに設計された方法である進化的グラフ強化学習（EGRL）を紹介します。一連の高速でステートレスなポリシーは、サンプル効率を向上させるための進化的検索をガイドします。推論のために、IntelNNP-Iチップ上で直接アプローチをトレーニングおよび検証します。 EGRLは、BERT、ResNet-101、およびResNet-50で、ポリシー勾配の進化的検索および動的計画法のベースラインよりも優れています。さらに28-78を達成,6.25,
A PAC-Bayesian Approach to Generalization Bounds for Graph Neural Networks,"['Renjie Liao', 'Raquel Urtasun', 'Richard Zemel']",https://openreview.net/forum?id=TR-Nj6nFx42,"In this paper, we derived generalization bounds for two primary classes of graph neural networks (GNNs), namely graph convolutional networks (GCNs) and message passing GNNs, via a PAC-Bayesian approach. 
Specifically, our result  reveals that the maximum node degree and spectral norm of the weights govern the generalization bound.
Importantly, our bound is a natural generalization of the results developed in \cite{neyshabur2017pac} for fully-connected and convolutional neural networks.
For message passing GNNs, our PAC-Bayes bound improves over the 
Rademacher complexity based bound in \cite{garg2020generalization}, showing a tighter dependency on the maximum node degree and the maximum hidden dimension. 
The key ingredients of our proof is a perturbation analysis of GNNs and the generalization of PAC-Bayes analysis to non-homogeneous GNNs. 
We perform an empirical study on several real-world graph datasets and verify that our PAC-Bayes bound is tighter than others.",この論文では、PAC-ベイズアプローチを介して、グラフニューラルネットワーク（GNN）の2つの主要なクラス、つまりグラフ畳み込みネットワーク（GCN）とメッセージパッシングGNNの一般化限界を導き出しました。具体的には、我々の結果は、重みの最大ノード次数とスペクトルノルムが一般化限界を支配することを明らかにしています。重要なことに、私たちの限界は、完全に接続された畳み込みニューラルネットワークのために開発された結果の自然な一般化です。メッセージパッシングGNNの場合、PAC-Bayes境界は、ラデマッハー複雑度ベースの境界よりも改善されており、最大ノード次数と最大非表示次元への依存度が高くなっています。私たちの証明の重要な要素は、GNNの摂動解析と、PACベイズ解析の不均一なGNNへの一般化です。いくつかの実世界のグラフデータセットで実証的研究を実行し、PACベイズの境界が他のデータセットよりもタイトであることを確認します。,6.25,
Noise against noise: stochastic label noise helps combat inherent label noise,"['Pengfei Chen', 'Guangyong Chen', 'Junjie Ye', 'jingwei zhao', 'Pheng-Ann Heng']",https://openreview.net/forum?id=80FMcTSZ6J0,"The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect, previously studied in optimization by analyzing the dynamics of parameter updates. In this paper, we are interested in learning with noisy labels, where we have a collection of samples with potential mislabeling. We show that a previously rarely discussed SGD noise, induced by stochastic label noise (SLN), mitigates the effects of inherent label noise. In contrast, the common SGD noise directly applied to model parameters does not. We formalize the differences and connections of SGD noise variants, showing that SLN induces SGD noise dependent on the sharpness of output landscape and the confidence of output probability, which may help escape from sharp minima and prevent overconfidence. SLN not only improves generalization in its simplest form but also boosts popular robust training methods, including sample selection and label correction. Specifically, we present an enhanced algorithm by applying SLN to label correction. Our code is released.",確率的勾配降下法（SGD）のノイズは、パラメーター更新のダイナミクスを分析することによって最適化で以前に研究された、重要な暗黙の正則化効果を提供します。この論文では、ノイズの多いラベルを使用した学習に関心があります。ここでは、誤ったラベルが付けられている可能性のあるサンプルのコレクションがあります。確率的ラベルノイズ（SLN）によって誘発される、これまでめったに議論されなかったSGDノイズが、固有のラベルノイズの影響を軽減することを示します。対照的に、モデルパラメータに直接適用される一般的なSGDノイズはそうではありません。 SGDノイズバリアントの違いと接続を形式化し、SLNが出力ランドスケープのシャープネスと出力確率の信頼度に依存してSGDノイズを誘発することを示します。これは、シャープな最小値からの脱出と自信過剰の防止に役立つ可能性があります。 SLNは、最も単純な形式で一般化を改善するだけでなく、サンプルの選択やラベルの修正など、一般的な堅牢なトレーニング方法を強化します。具体的には、ラベル修正にSLNを適用することにより、強化されたアルゴリズムを提示します。コードがリリースされました。,6.25,
Taking Notes on the Fly Helps Language Pre-Training,"['Qiyu Wu', 'Chen Xing', 'Yatao Li', 'Guolin Ke', 'Di He', 'Tie-Yan Liu']",https://openreview.net/forum?id=lU5Rs_wCweN,"How to make unsupervised language pre-training more efficient and less resource-intensive is an important research direction in NLP. In this paper, we focus on improving the efficiency of language pre-training methods through providing better data utilization. It is well-known that in language data corpus, words follow a heavy-tail distribution. A large proportion of words appear only very few times and the embeddings of rare words are usually poorly optimized. We argue that such embeddings carry inadequate semantic signals, which could make the data utilization inefficient and slow down the pre-training of the entire model. To mitigate this problem, we propose Taking Notes on the Fly (TNF), which takes notes for rare words on the fly during pre-training to help the model understand them when they occur next time. Specifically, TNF maintains a note dictionary and saves a rare word's contextual information in it as notes when the rare word occurs in a sentence. When the same rare word occurs again during training, the note information saved beforehand can be employed to enhance the semantics of the current sentence. By doing so, TNF provides a better data utilization since cross-sentence information is employed to cover the inadequate semantics caused by rare words in the sentences. We implement TNF on both BERT and ELECTRA to check its efficiency and effectiveness.  Experimental results show that TNF's training time is 60% less than its backbone pre-training models when reaching the same performance.  When trained with same number of iterations, TNF outperforms its backbone methods on most of downstream tasks and the average GLUE score. Code is attached in the supplementary material.",教師なし言語の事前トレーニングをより効率的にし、リソースをあまり消費しないようにする方法は、NLPの重要な研究の方向性です。この論文では、より良いデータ利用を提供することにより、言語の事前トレーニング方法の効率を改善することに焦点を当てています。言語データコーパスでは、単語が裾の重い分布に従うことはよく知られています。単語の大部分はごくわずかしか出現せず、まれな単語の埋め込みは通常、最適化が不十分です。このような埋め込みは不適切なセマンティック信号を伝達するため、データの利用が非効率になり、モデル全体の事前トレーニングが遅くなる可能性があると主張します。この問題を軽減するために、事前トレーニング中にその場で珍しい単語をメモして、モデルが次に発生したときにそれらを理解できるようにする、Taking Notes on the Fly（TNF）を提案します。具体的には、TNFはノート辞書を維持し、レアワードが文に出現したときにレアワードのコンテキスト情報をノートとして保存します。トレーニング中に同じレアワードが再び発生した場合、事前に保存されたメモ情報を使用して、現在の文のセマンティクスを強化できます。そうすることで、文中のまれな単語によって引き起こされる不適切なセマンティクスをカバーするために文間情報が使用されるため、TNFはより良いデータ利用を提供します。 BERTとELECTRAの両方にTNFを実装して、その効率と有効性を確認します。実験結果は、TNFのトレーニング時間が60であることを示しています,6.25,
On the Impossibility of Global Convergence in Multi-Loss Optimization,['Alistair Letcher'],https://openreview.net/forum?id=NQbnPjPYaG6,"Under mild regularity conditions, gradient-based methods converge globally to a critical point in the single-loss setting. This is known to break down for vanilla gradient descent when moving to multi-loss optimization, but can we hope to build some algorithm with global guarantees? We negatively resolve this open problem by proving that desirable convergence properties cannot simultaneously hold for any algorithm. Our result has more to do with the existence of games with no satisfactory outcomes, than with algorithms per se. More explicitly we construct a two-player game with zero-sum interactions whose losses are both coercive and analytic, but whose only simultaneous critical point is a strict maximum. Any 'reasonable' algorithm, defined to avoid strict maxima, will therefore fail to converge. This is fundamentally different from single losses, where coercivity implies existence of a global minimum.  Moreover, we prove that a wide range of existing gradient-based methods almost surely have bounded but non-convergent iterates in a constructed zero-sum game for suitably small learning rates. It nonetheless remains an open question whether such behavior can arise in high-dimensional games of interest to ML practitioners, such as GANs or multi-agent RL.",穏やかな規則性の条件下では、勾配ベースの方法は、単一損失設定の臨界点にグローバルに収束します。これは、マルチロス最適化に移行するときにバニラ勾配降下法で崩壊することが知られていますが、グローバル保証付きのアルゴリズムを構築することを期待できますか？望ましい収束特性がどのアルゴリズムにも同時に当てはまらないことを証明することにより、この未解決の問題を否定的に解決します。私たちの結果は、アルゴリズム自体よりも、満足のいく結果が得られないゲームの存在と関係があります。より明確に言えば、損失が強制的かつ分析的であるが、同時の臨界点は厳密な最大値のみであるゼロサム相互作用を持つ2人用ゲームを構築します。したがって、厳密な最大値を回避するように定義された合理的なアルゴリズムは、収束に失敗します。これは、保磁力がグローバル最小値の存在を意味する単一損失とは根本的に異なります。さらに、広範囲の既存の勾配ベースの方法がほぼ確実に制限されているが、適切に小さい学習率のために構築されたゼロサムゲームで非収束反復することを証明します。それにもかかわらず、GANやマルチエージェントRLなどのML実践者が関心を持つ高次元のゲームでそのような動作が発生する可能性があるかどうかは未解決の問題です。,6.25,
Colorization Transformer,"['Manoj Kumar', 'Dirk Weissenborn', 'Nal Kalchbrenner']",https://openreview.net/forum?id=5NA1PinlGFu,"We present the Colorization Transformer, a novel approach for diverse high fidelity image colorization based on self-attention. Given a grayscale image, the colorization proceeds in three steps. We first use an autoregressive transformer to produce a low resolution coarse coloring of the grayscale image. Our architecture adopts conditional self-attention blocks to effectively capture grayscale input. Two subsequent fully parallel networks upsample the coarse colored low resolution image into a finely colored high resolution image. Sampling from the Colorization Transformer produces diverse colorings whose fidelity outperforms the previous state-of-the-art on colorising ImageNet based on FID results and based on a human evaluation in a Mechanical Turk test. Remarkably, in more than 60\% of cases human evaluators prefer the highest rated among three generated colorings over the ground truth.",自己注意に基づく多様で忠実度の高い画像の色付けのための新しいアプローチであるColorizationTransformerを紹介します。グレースケール画像が与えられると、カラー化は3つのステップで進行します。まず、自己回帰トランスフォーマーを使用して、グレースケール画像の低解像度の粗いカラーリングを生成します。私たちのアーキテクチャは、条件付き自己注意ブロックを採用して、グレースケール入力を効果的にキャプチャします。後続の2つの完全並列ネットワークは、粗い色の低解像度画像を細かい色の高解像度画像にアップサンプリングします。 Colorization Transformerからのサンプリングにより、さまざまなカラーリングが生成されます。その忠実度は、FIDの結果とMechanical Turkテストでの人間による評価に基づいて、ImageNetのカラーリングに関する以前の最先端技術を上回ります。驚くべきことに、60％以上の場合、人間の評価者は、グラウンドトゥルースよりも生成された3つの着色料の中で最も高い評価を好みます。,6.25,
On the Dynamics of Training Attention Models,"['Haoye Lu', 'Yongyi Mao', 'Amiya Nayak']",https://openreview.net/forum?id=1OCTOShAmqB,"The attention mechanism has been widely used in deep neural networks as a model component. By now, it has become a critical building block in many state-of-the-art natural language models. Despite its great success established empirically, the working mechanism of attention has not been investigated at a sufficient theoretical depth to date. In this paper, we set up a simple text classification task and study the dynamics of training a simple attention-based classification model using gradient descent. In this setting, we show that, for the discriminative words that the model should attend to, a persisting identity exists relating its embedding and the inner product of its key and the query. This allows us to prove that training must converge to attending to the discriminative words when the attention output is classified by a linear classifier. Experiments are performed, which validates our theoretical analysis and provides further insights.",注意メカニズムは、モデルコンポーネントとしてディープニューラルネットワークで広く使用されています。今では、それは多くの最先端の自然言語モデルの重要な構成要素になっています。経験的に確立されたその大きな成功にもかかわらず、注意の作用メカニズムは、今日まで十分な理論的深さで調査されていません。この論文では、単純なテキスト分類タスクを設定し、勾配降下法を使用して単純な注意ベースの分類モデルをトレーニングするダイナミクスを研究します。この設定では、モデルが注意を払う必要のある識別語について、その埋め込みと、そのキーとクエリの内積に関連する永続的なアイデンティティが存在することを示します。これにより、注意出力が線形分類器によって分類されるときに、トレーニングが識別語に注意を向けることに収束する必要があることを証明できます。実験が実行され、理論的な分析が検証され、さらなる洞察が得られます。,6.25,
Self-supervised Learning from a Multi-view Perspective,"['Yao-Hung Hubert Tsai', 'Yue Wu', 'Ruslan Salakhutdinov', 'Louis-Philippe Morency']",https://openreview.net/forum?id=-bdp_8Itjwp,"As a subset of unsupervised representation learning, self-supervised representation learning adopts self-defined signals as supervision and uses the learned representation for downstream tasks, such as object detection and image captioning. Many proposed approaches for self-supervised learning follow naturally a multi-view perspective, where the input (e.g., original images) and the self-supervised signals (e.g., augmented images) can be seen as two redundant views of the data. Building from this multi-view perspective, this paper provides an information-theoretical framework to better understand the properties that encourage successful self-supervised learning. Specifically, we demonstrate that self-supervised learned representations can extract task-relevant information and discard task-irrelevant information. Our theoretical framework paves the way to a larger space of self-supervised learning objective design. In particular, we propose a composite objective that bridges the gap between prior contrastive and predictive learning objectives, and introduce an additional objective term to discard task-irrelevant information. To verify our analysis, we conduct controlled experiments to evaluate the impact of the composite objectives. We also explore our framework's empirical generalization beyond the multi-view perspective, where the cross-view redundancy may not be clearly observed.",教師なし表現学習のサブセットとして、教師あり表現学習は、教師として自己定義信号を採用し、オブジェクト検出や画像キャプションなどのダウンストリームタスクに学習した表現を使用します。自己教師あり学習のために提案された多くのアプローチは、入力（たとえば、元の画像）と自己教師あり信号（たとえば、拡張画像）がデータの2つの冗長なビューとして表示される、マルチビューの視点に自然に従います。このマルチビューの観点から構築して、このペーパーは、成功した自己教師あり学習を促進する特性をよりよく理解するための情報理論的フレームワークを提供します。具体的には、自己教師あり学習表現がタスク関連情報を抽出し、タスク非関連情報を破棄できることを示します。私たちの理論的枠組みは、自己教師あり学習の目標設計のより広い空間への道を開きます。特に、以前の対照的な学習目標と予測学習目標の間のギャップを埋める複合目標を提案し、タスクに関係のない情報を破棄するための追加の目標用語を導入します。分析を検証するために、制御された実験を実施して、複合目的の影響を評価します。また、クロスビューの冗長性が明確に観察されない可能性があるマルチビューの観点を超えて、フレームワークの経験的な一般化についても検討します。,6.25,
Provable Rich Observation Reinforcement Learning with Combinatorial Latent States,"['Dipendra Misra', 'Qinghua Liu', 'Chi Jin', 'John Langford']",https://openreview.net/forum?id=hx1IXFHAw7R,"We propose a novel setting for reinforcement learning that combines two common real-world difficulties: presence of observations (such as camera images) and factored states (such as location of objects). In our setting, the agent receives observations generated stochastically from a ""latent"" factored state. These observations are ""rich enough"" to enable decoding of the latent state and remove partial observability concerns. Since the latent state is combinatorial, the size of state space is exponential in the number of latent factors. We create a learning algorithm FactoRL (Fact-o-Rel) for this setting,  which uses noise-contrastive learning to identify latent structures in emission processes and discover a factorized state space. We derive polynomial sample complexity guarantees for FactoRL which polynomially depend upon the number factors, and very weakly depend on the size of the observation space.  We also provide a guarantee of polynomial time complexity when given access to an efficient planning algorithm.",観測の存在（カメラ画像など）と因数分解された状態（オブジェクトの位置など）という2つの一般的な現実世界の困難を組み合わせた強化学習の新しい設定を提案します。私たちの設定では、エージェントは「潜在的な」因数分解された状態から確率的に生成された観測値を受け取ります。これらの観測は、潜在状態のデコードを可能にし、部分的な観測可能性の懸念を取り除くのに「十分に豊富」です。潜在状態は組み合わせであるため、状態空間のサイズは潜在因子の数で指数関数的です。この設定用の学習アルゴリズムFactoRL（Fact-o-Rel）を作成します。これは、ノイズ対照学習を使用して、放出プロセスの潜在構造を識別し、因数分解された状態空間を検出します。 FactoRLの多項式サンプルの複雑さの保証を導き出します。これは、多項式的に数の要因に依存し、観測空間のサイズに非常に弱く依存します。また、効率的な計画アルゴリズムへのアクセスが与えられた場合、多項式の時間計算量が保証されます。,6.25,
Influence Functions in Deep Learning Are Fragile,"['Samyadeep Basu', 'Phil Pope', 'Soheil Feizi']",https://openreview.net/forum?id=xHKVVHGDOEk,"Influence functions approximate the effect of training samples in test-time predictions and have a wide variety of applications in machine learning interpretability and uncertainty estimation. A commonly-used (first-order) influence function can be implemented efficiently as a post-hoc method requiring access only to the gradients and Hessian of the model. For linear models, influence functions are well-defined due to the convexity of the underlying loss function and are generally accurate even across difficult settings where model changes are fairly large such as estimating group influences. Influence functions, however, are not well-understood in the context of deep learning with non-convex loss functions.  In this paper, we provide a comprehensive and large-scale empirical study of successes and failures of influence functions in neural network models trained on datasets such as Iris, MNIST, CIFAR-10 and ImageNet. Through our extensive experiments, we show that the network architecture, its depth and width, as well as the extent of model parameterization and regularization techniques have strong effects in the accuracy of influence functions. In particular, we find that (i) influence estimates are fairly accurate for shallow networks, while for deeper networks the estimates are often erroneous; (ii) for certain network architectures and datasets, training with weight-decay regularization is important to get high-quality influence estimates; and (iii) the accuracy of influence estimates can vary significantly depending on the examined test points. These results suggest that in general influence functions in deep learning are fragile and call for developing improved influence estimation methods to mitigate these issues in non-convex setups.",影響関数は、テスト時間の予測におけるトレーニングサンプルの効果を近似し、機械学習の解釈可能性と不確実性の推定にさまざまな用途があります。一般的に使用される（1次）影響関数は、モデルの勾配とヘッセ行列へのアクセスのみを必要とする事後メソッドとして効率的に実装できます。線形モデルの場合、影響関数は基礎となる損失関数の凸性のために明確に定義されており、グループの影響の推定など、モデルの変更がかなり大きい難しい設定でも一般に正確です。ただし、影響関数は、非凸損失関数を使用した深層学習のコンテキストでは十分に理解されていません。このホワイトペーパーでは、Iris、MNIST、CIFAR-10、ImageNetなどのデータセットでトレーニングされたニューラルネットワークモデルにおける影響関数の成功と失敗に関する包括的で大規模な実証的研究を提供します。広範な実験を通じて、ネットワークアーキテクチャ、その深さと幅、およびモデルのパラメータ化と正則化の手法の範囲が、影響関数の精度に強い影響を与えることを示しています。特に、（i）影響の推定値は浅いネットワークではかなり正確ですが、深いネットワークでは推定値が誤っていることがよくあります。 （ii）特定のネットワークアーキテクチャとデータセットの場合、高品質の影響推定値を取得するには、重み減衰正則化を使用したトレーニングが重要です。 （iii）影響の推定の精度は、調査したテストポイントによって大幅に異なる可能性があります。これらの結果は、一般に深層学習の影響関数が脆弱であることを示唆しており、非凸セットアップでこれらの問題を軽減するための改善された影響推定方法の開発が必要です。,6.25,https://d3i71xaburhd42.cloudfront.net/8990131f470fd620a35831d8bd49e4b02bc4f4b3/4-Figure1-1.png
A Design Space Study for LISTA and Beyond,"['Tianjian Meng', 'Xiaohan Chen', 'Yifan Jiang', 'Zhangyang Wang']",https://openreview.net/forum?id=GMgHyUPrXa,"In recent years, great success has been witnessed in building problem-specific deep networks from unrolling iterative algorithms, for solving inverse problems and beyond. Unrolling is believed to incorporate the model-based prior with the learning capacity of deep learning. This paper revisits \textit{the role of unrolling as a design approach for deep networks}: to what extent its resulting special architecture is superior, and can we find better? Using LISTA for sparse recovery as a representative example, we conduct the first thorough \textit{design space study} for the unrolled models.  Among all possible variations, we focus on extensively varying the connectivity patterns and neuron types, leading to a gigantic design space arising from LISTA. To efficiently explore this space and identify top performers, we leverage the emerging tool of neural architecture search (NAS). We carefully examine the searched top architectures in a number of settings, and are able to discover networks that consistently better than LISTA. We further present more visualization and analysis to ``open the black box"", and find that the searched top architectures demonstrate highly consistent and potentially transferable patterns. We hope our study to spark more reflections and explorations on how to better mingle model-based optimization prior and data-driven learning.",近年、逆問題を解決するために、反復アルゴリズムを展開することから問題固有の深いネットワークを構築することに大きな成功が見られました。展開には、モデルベースの事前学習と深層学習の学習能力が組み込まれていると考えられています。このホワイトペーパーでは、ディープネットワークの設計アプローチとしての展開の役割を再検討します。結果として得られる特別なアーキテクチャはどの程度優れているのでしょうか。代表的な例としてスパースリカバリのLISTAを使用して、展開されたモデルの最初の徹底的な設計空間調査を実施します。考えられるすべてのバリエーションの中で、接続パターンとニューロンタイプを大幅に変化させることに焦点を当て、LISTAから生じる巨大なデザインスペースに導きます。この空間を効率的に探索し、トップパフォーマーを特定するために、ニューラルアーキテクチャ検索（NAS）の新しいツールを活用します。検索された上位のアーキテクチャをさまざまな設定で注意深く調べ、LISTAよりも一貫して優れているネットワークを見つけることができます。さらに、ブラックボックスを開くための視覚化と分析をさらに提示します」と検索した上位のアーキテクチャは、一貫性が高く、転送可能な可能性のあるパターンを示していることがわかりました。モデルベースの最適化を事前に、データ駆動型学習。,6.25,
Learning the Pareto Front with Hypernetworks,"['Aviv Navon', 'Aviv Shamsian', 'Gal Chechik', 'Ethan Fetaya']",https://openreview.net/forum?id=NjF772F4ZZR,"Multi-objective optimization (MOO) problems are prevalent in machine learning. These problems have a set of optimal solutions, called the Pareto front, where each point on the front represents a different trade-off between possibly conflicting objectives. Recent MOO methods can target a specific desired ray in loss space, however, most approaches still face two grave limitations: (i) A separate model has to be trained for each point on the front; and (ii) The exact trade-off must be known prior to the optimization process. Here, we tackle the problem of learning the entire Pareto front, with the capability of selecting a desired operating point on the front after training. We call this new setup Pareto-Front Learning (PFL).

We describe an approach to PFL implemented using HyperNetworks, which we term Pareto HyperNetworks (PHNs). PHN learns the entire Pareto front simultaneously using a single hypernetwork, which receives as input a desired preference vector and returns a Pareto-optimal model whose loss vector is in the desired ray. The unified model is runtime efficient compared to training multiple models, and generalizes to new operating points not used during training. We evaluate our method on a wide set of problems, from multi-task regression and classification to fairness. PHNs learns the entire Pareto front in roughly the same time as learning a single point on the front, and also reaches a better solution set. PFL opens the door to new applications where models are selected based on preferences that are only available at run time. ",多目的最適化（MOO）の問題は、機械学習でよく見られます。これらの問題には、パレートフロントと呼ばれる一連の最適なソリューションがあります。フロントの各ポイントは、競合する可能性のある目的間の異なるトレードオフを表します。最近のMOOメソッドは、損失空間内の特定の目的の光線をターゲットにすることができますが、ほとんどのアプローチは、依然として2つの重大な制限に直面しています。 （ii）最適化プロセスの前に、正確なトレードオフを知る必要があります。ここでは、トレーニング後にフロントで目的の動作点を選択する機能を使用して、パレートフロント全体を学習するという問題に取り組みます。この新しいセットアップをパレートフロントラーニング（PFL）と呼びます。パレートハイパーネットワーク（PHN）と呼ばれるハイパーネットワークを使用して実装されたPFLへのアプローチについて説明します。 PHNは、単一のハイパーネットワークを使用してパレートフロント全体を同時に学習します。このハイパーネットワークは、入力として目的の選好ベクトルを受け取り、損失ベクトルが目的の光線にあるパレート最適モデルを返します。統合モデルは、複数のモデルのトレーニングと比較して実行時に効率的であり、トレーニング中に使用されない新しい動作点に一般化されます。マルチタスク回帰や分類から公平性まで、幅広い問題についてメソッドを評価します。 PHNは、フロントの1つのポイントを学習するのとほぼ同時に、パレートフロント全体を学習し、より優れたソリューションセットに到達します。 PFLは、実行時にのみ使用可能な設定に基づいてモデルが選択される新しいアプリケーションへの扉を開きます。,6.25,https://d3i71xaburhd42.cloudfront.net/d96711ced185b92a011f3e51191497e8ae4b8559/2-Figure1-1.png
Deep Neural Network Fingerprinting by Conferrable Adversarial Examples,"['Nils Lukas', 'Yuxuan Zhang', 'Florian Kerschbaum']",https://openreview.net/forum?id=VqzVhqxkjH1,"In Machine Learning as a Service, a provider trains a deep neural network and gives many users access. The hosted (source) model is susceptible to model stealing attacks, where an adversary derives a surrogate model from API access to the source model. For post hoc detection of such attacks, the provider needs a robust method to determine whether a suspect model is a surrogate of their model. We propose a fingerprinting method for deep neural network classifiers that extracts a set of inputs from the source model so that only surrogates agree with the source model on the classification of such inputs. These inputs are a subclass of transferable adversarial examples which we call conferrable adversarial examples that exclusively transfer with a target label from a source model to its surrogates. We propose a new method to generate these conferrable adversarial examples. We present an extensive study on the irremovability of our fingerprint against fine-tuning, weight pruning, retraining, retraining with different architectures, three model extraction attacks from related work, transfer learning, adversarial training, and two new adaptive attacks. Our fingerprint is robust against distillation, related model extraction attacks, and even transfer learning when the attacker has no access to the model provider's dataset. Our fingerprint is the first method that reaches a ROC AUC of 1.0 in verifying surrogates, compared to a ROC AUC of 0.63 by previous fingerprints. ",サービスとしての機械学習では、プロバイダーがディープニューラルネットワークをトレーニングし、多くのユーザーにアクセスを提供します。ホストされた（ソース）モデルは、モデルを盗む攻撃の影響を受けやすく、攻撃者はソースモデルへのAPIアクセスから代理モデルを派生させます。このような攻撃を事後的に検出するために、プロバイダーは、疑わしいモデルがモデルの代理であるかどうかを判断するための堅牢な方法を必要としています。ソースモデルから入力のセットを抽出するディープニューラルネットワーク分類器のフィンガープリント法を提案します。これにより、サロゲートのみがそのような入力の分類に関してソースモデルと一致します。これらの入力は、ソースモデルからそのサロゲートにターゲットラベルを使用して排他的に転送する、転送可能な敵対的な例のサブクラスです。これらの説得力のある敵対的な例を生成するための新しい方法を提案します。微調整、重みの剪定、再トレーニング、さまざまなアーキテクチャでの再トレーニング、関連する作業からの3つのモデル抽出攻撃、転移学習、敵対的トレーニング、および2つの新しい適応攻撃に対する指紋の除去不能性に関する広範な研究を紹介します。私たちのフィンガープリントは、蒸留、関連するモデル抽出攻撃、さらには攻撃者がモデルプロバイダーのデータセットにアクセスできない場合の転送学習に対しても堅牢です。私たちのフィンガープリントは、以前のフィンガープリントによるROC AUC 0.63と比較して、サロゲートの検証でROCAUCが1.0に達する最初の方法です。,6.25,https://d3i71xaburhd42.cloudfront.net/3018f18219a8c4e8c5a9a08f1edc1f34bc6e56eb/1-Figure1-1.png
Bayesian Context Aggregation for Neural Processes,"['Michael Volpp', 'Fabian Flürenbrock', 'Lukas Grossberger', 'Christian Daniel', 'Gerhard Neumann']",https://openreview.net/forum?id=ufZN2-aehFa,"Formulating scalable probabilistic regression models with reliable uncertainty estimates has been a long-standing challenge in machine learning research. Recently, casting probabilistic regression as a multi-task learning problem in terms of conditional latent variable (CLV) models such as the Neural Process (NP) has shown promising results. In this paper, we focus on context aggregation, a central component of such architectures, which fuses information from multiple context data points. So far, this aggregation operation has been treated separately from the inference of a latent representation of the target function in CLV models. Our key contribution is to combine these steps into one holistic mechanism by phrasing context aggregation as a Bayesian inference problem. The resulting Bayesian Aggregation (BA) mechanism allows principled handling of task ambiguity, which is key for efficiently processing context information. We demonstrate on a range of challenging experiments, including dynamics modeling and image completion, that BA consistently improves upon the performance of traditional aggregation methods while remaining computationally efficient and fully compatible with existing NP-based models.",信頼できる不確実性の推定値を使用してスケーラブルな確率回帰モデルを定式化することは、機械学習の研究において長年の課題でした。最近、確率的回帰を、神経プロセス（NP）などの条件付き潜在変数（CLV）モデルの観点からマルチタスク学習問題としてキャストすることで、有望な結果が示されました。このホワイトペーパーでは、このようなアーキテクチャの中心的なコンポーネントであるコンテキスト集約に焦点を当てます。これは、複数のコンテキストデータポイントからの情報を融合します。これまでのところ、この集計操作は、CLVモデルのターゲット関数の潜在的な表現の推論とは別に扱われてきました。私たちの主な貢献は、コンテキスト集約をベイズ推定問題として表現することにより、これらのステップを1つの全体的なメカニズムに結合することです。結果として得られるベイジアンアグリゲーション（BA）メカニズムにより、タスクのあいまいさを原則的に処理できます。これは、コンテキスト情報を効率的に処理するための鍵です。 BAは、計算効率を維持し、既存のNPベースのモデルと完全に互換性を保ちながら、従来の集計方法のパフォーマンスを一貫して改善することを、ダイナミクスモデリングや画像完成などのさまざまな挑戦的な実験で示します。,6.25,
Adaptive Extra-Gradient Methods for Min-Max Optimization and Games,"['Kimon Antonakopoulos', 'Veronica Belmega', 'Panayotis Mertikopoulos']",https://openreview.net/forum?id=R0a0kFI3dJx,"We present a new family of min-max optimization algorithms that automatically exploit the geometry of the gradient data observed at earlier iterations to perform more informative extra-gradient steps in later ones. Thanks to this adaptation mechanism, the proposed method automatically detects whether the problem is smooth or not, without requiring any prior tuning by the optimizer. As a result, the algorithm simultaneously achieves order-optimal convergence rates, i.e., it converges to an $\varepsilon$-optimal solution within $\mathcal{O}(1/\varepsilon)$ iterations in smooth problems, and within $\mathcal{O}(1/\varepsilon^2)$ iterations in non-smooth ones. Importantly, these guarantees do not require any of the standard boundedness or Lipschitz continuity conditions that are typically assumed in the literature; in particular, they apply even to problems with singularities (such as resource allocation problems and the like). This adaptation is achieved through the use of a geometric apparatus based on Finsler metrics and a suitably chosen mirror-prox template that allows us to derive sharp convergence rates for the methods at hand.",以前の反復で観察された勾配データのジオメトリを自動的に活用して、後の反復でより有益な勾配外ステップを実行する、ミニマックス最適化アルゴリズムの新しいファミリを紹介します。この適応メカニズムのおかげで、提案された方法は、オプティマイザによる事前の調整を必要とせずに、問題がスムーズであるかどうかを自動的に検出します。その結果、アルゴリズムは同時に次数最適収束率を達成します。つまり、滑らかな問題ではO（1 /）反復内で、非滑らかな問題ではO（1/2）反復内で最適解に収束します。重要なことに、これらの保証は、文献で通常想定されている標準的な有界性またはリプシッツ連続性条件を必要としません。特に、特異点の問題（リソース割り当ての問題など）にも適用されます。この適応は、フィンスラー計量に基づく幾何学的装置と、手元の方法の鋭い収束率を導き出すことを可能にする適切に選択されたミラープロキシテンプレートを使用することによって達成されます。,6.25,https://d3i71xaburhd42.cloudfront.net/93d715bb46005880ebc9d32cb64344cf1697be07/7-Figure1-1.png
HyperDynamics: Generating Expert Dynamics Models by Observation,"['Zhou Xian', 'Shamit Lal', 'Hsiao-Yu Tung', 'Emmanouil Antonios Platanios', 'Katerina Fragkiadaki']",https://openreview.net/forum?id=pHXfe1cOmA,"We propose HyperDynamics, a framework that conditions on an agent’s interactions with the environment and optionally its visual observations, and generates the parameters of neural dynamics models based on inferred properties of the dynamical system. Physical and visual properties of the environment that are not part of the low-dimensional state yet affect its temporal dynamics are inferred from the interaction history and visual observations, and are implicitly captured in the generated parameters. We test HyperDynamics on a set of object pushing and locomotion tasks. It outperforms existing dynamics models in the literature that adapt to environment variations by learning dynamics over high dimensional visual observations, capturing the interactions of the agent in recurrent state representations, or using gradient-based meta-optimization. We also show our method matches the performance of an ensemble of separately trained experts, while also being able to generalize well to unseen environment variations at test time. We attribute its good performance to the multiplicative interactions between the inferred system properties—captured in the generated parameters—and the low-dimensional state representation of the dynamical system.",HyperDynamicsを提案します。これは、エージェントと環境との相互作用およびオプションでその視覚的観察を条件とし、動的システムの推定プロパティに基づいて神経ダイナミクスモデルのパラメーターを生成するフレームワークです。低次元状態の一部ではないが、その時間的ダイナミクスに影響を与える環境の物理的および視覚的特性は、相互作用の履歴と視覚的観察から推測され、生成されたパラメーターに暗黙的に取り込まれます。一連のオブジェクトプッシュおよび移動タスクでHyperDynamicsをテストします。これは、高次元の視覚的観察でダイナミクスを学習したり、反復状態表現でエージェントの相互作用をキャプチャしたり、勾配ベースのメタ最適化を使用したりすることで、環境の変化に適応する文献の既存のダイナミクスモデルよりも優れています。また、私たちの方法が、個別に訓練された専門家のアンサンブルのパフォーマンスと一致すると同時に、テスト時に目に見えない環境の変化にうまく一般化できることも示します。その優れたパフォーマンスは、生成されたパラメーターでキャプチャされた推定システムプロパティと動的システムの低次元状態表現との間の乗法的相互作用に起因します。,6.25,
Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech,"['Yoonhyung Lee', 'Joongbo Shin', 'Kyomin Jung']",https://openreview.net/forum?id=o3iritJHLfO,"Although early text-to-speech (TTS) models such as Tacotron 2 have succeeded in generating human-like speech, their autoregressive architectures have several limitations: (1) They require a lot of time to generate a mel-spectrogram consisting of hundreds of steps. (2) The autoregressive speech generation shows a lack of robustness due to its error propagation property. In this paper, we propose a novel non-autoregressive TTS model called BVAE-TTS, which eliminates the architectural limitations and generates a mel-spectrogram in parallel. BVAE-TTS adopts a bidirectional-inference variational autoencoder (BVAE) that learns hierarchical latent representations using both bottom-up and top-down paths to increase its expressiveness. To apply BVAE to TTS, we design our model to utilize text information via an attention mechanism. By using attention maps that BVAE-TTS generates, we train a duration predictor so that the model uses the predicted duration of each phoneme at inference. In experiments conducted on LJSpeech dataset, we show that our model generates a mel-spectrogram 27 times faster than Tacotron 2 with similar speech quality. Furthermore, our BVAE-TTS outperforms Glow-TTS, which is one of the state-of-the-art non-autoregressive TTS models, in terms of both speech quality and inference speed while having 58% fewer parameters.",Tacotron 2などの初期のテキスト読み上げ（TTS）モデルは人間のような音声を生成することに成功しましたが、それらの自己回帰アーキテクチャにはいくつかの制限があります。（1）数百からなるメルスペクトログラムを生成するには多くの時間が必要です。ステップ。 （2）自己回帰音声生成は、そのエラー伝播特性のためにロバスト性の欠如を示しています。この論文では、BVAE-TTSと呼ばれる新しい非自己回帰TTSモデルを提案します。これは、アーキテクチャの制限を排除し、並行してメルスペクトログラムを生成します。 BVAE-TTSは、双方向推論変分オートエンコーダー（BVAE）を採用しており、ボトムアップパスとトップダウンパスの両方を使用して階層的な潜在表現を学習し、表現力を高めます。 BVAEをTTSに適用するために、注意メカニズムを介してテキスト情報を利用するようにモデルを設計します。 BVAE-TTSが生成する注意マップを使用することにより、モデルが推論時に各音素の予測期間を使用するように、期間予測子をトレーニングします。 LJSpeechデータセットで実施された実験では、モデルが同様の音声品質でTacotron2より27倍高速にメルスペクトログラムを生成することを示しています。さらに、当社のBVAE-TTSは、音声品質と推論速度の両方の点で、最先端の非自己回帰TTSモデルの1つであるGlow-TTSよりも優れています。,6.25,
Generalized Multimodal ELBO,"['Thomas Marco Sutter', 'Imant Daunhawer', 'Julia E Vogt']",https://openreview.net/forum?id=5Y21V0RDBV,"Multiple data types naturally co-occur when describing real-world phenomena and learning from them is a long-standing goal in machine learning research. However, existing self-supervised generative models approximating an ELBO are not able to fulfill all desired requirements of multimodal models: their posterior approximation functions lead to a trade-off between the semantic coherence and the ability to learn the joint data distribution. We propose a new, generalized ELBO formulation for multimodal data that overcomes these limitations. The new objective encompasses two previous methods as special cases and combines their benefits without compromises. In extensive experiments, we demonstrate the advantage of the proposed method compared to state-of-the-art models in self-supervised, generative learning tasks.",実世界の現象を説明するときに複数のデータ型が自然に発生し、それらから学習することは、機械学習研究の長年の目標です。ただし、ELBOを近似する既存の自己教師あり生成モデルは、マルチモーダルモデルのすべての望ましい要件を満たすことができません。それらの事後近似関数は、セマンティックコヒーレンスと共同データ分布を学習する能力の間のトレードオフにつながります。これらの制限を克服するマルチモーダルデータ用の新しい一般化されたELBO定式化を提案します。新しい目的は、特別な場合として以前の2つの方法を包含し、妥協することなくそれらの利点を組み合わせます。大規模な実験では、自己管理型の生成的学習タスクにおける最先端のモデルと比較して、提案された方法の利点を示しています。,6.25,
Anytime Sampling for Autoregressive Models via Ordered Autoencoding,"['Yilun Xu', 'Yang Song', 'Sahaj Garg', 'Linyuan Gong', 'Rui Shu', 'Aditya Grover', 'Stefano Ermon']",https://openreview.net/forum?id=TSRTzJnuEBS,"Autoregressive models are widely used for tasks such as image and audio generation. The sampling process of these models, however, does not allow interruptions and cannot adapt to real-time computational resources. This challenge impedes the deployment of powerful autoregressive models, which involve a slow sampling process that is sequential in nature and typically scales linearly with respect to the data dimension.  To address this difficulty, we propose a new family of autoregressive models that enables anytime sampling. Inspired by Principal Component Analysis, we learn a structured representation space where dimensions are ordered based on their importance with respect to reconstruction. Using an autoregressive model in this latent space, we trade off sample quality for computational efficiency by truncating the generation process before decoding into the original data space. Experimentally, we demonstrate in several image and audio generation tasks that sample quality degrades gracefully as we reduce the computational budget for sampling. The approach suffers almost no loss in sample quality (measured by FID) using only 60\% to 80\% of all latent dimensions for image data.",自己回帰モデルは、画像や音声の生成などのタスクに広く使用されています。ただし、これらのモデルのサンプリングプロセスでは、中断が許可されず、リアルタイムの計算リソースに適応できません。この課題は、強力な自己回帰モデルの展開を妨げます。これには、本質的にシーケンシャルであり、通常はデータディメンションに対して線形にスケーリングする低速のサンプリングプロセスが含まれます。この困難に対処するために、いつでもサンプリングできる自己回帰モデルの新しいファミリを提案します。主成分分析に触発されて、再構成に関する重要性に基づいて次元が順序付けられる構造化された表現空間を学習します。この潜在空間で自己回帰モデルを使用して、元のデータ空間にデコードする前に生成プロセスを切り捨てることにより、サンプルの品質と計算効率をトレードオフします。実験的に、いくつかの画像および音声生成タスクで、サンプリングの計算バジェットを減らすと、サンプル品質が適切に低下することを示します。このアプローチでは、画像データのすべての潜在的な次元の60％から80％のみを使用して、サンプル品質（FIDで測定）がほとんど低下しません。,6.25,
BSQ: Exploring Bit-Level Sparsity for Mixed-Precision Neural Network Quantization,"['Huanrui Yang', 'Lin Duan', 'Yiran Chen', 'Hai Li']",https://openreview.net/forum?id=TiXl51SCNw8,"Mixed-precision quantization can potentially achieve the optimal tradeoff between performance and compression rate of deep neural networks, and thus, have been widely investigated. However, it lacks a systematic method to determine the exact quantization scheme. Previous methods either examine only a small manually-designed search space or utilize a cumbersome neural architecture search to explore the vast search space. These approaches cannot lead to an optimal quantization scheme efficiently. This work proposes bit-level sparsity quantization (BSQ) to tackle the mixed-precision quantization from a new angle of inducing bit-level sparsity. We consider each bit of quantized weights as an independent trainable variable and introduce a differentiable bit-sparsity regularizer. BSQ can induce all-zero bits across a group of weight elements and realize the dynamic precision reduction, leading to a mixed-precision quantization scheme of the original model. Our method enables the exploration of the full mixed-precision space with a single gradient-based optimization process, with only one hyperparameter to tradeoff the performance and compression. BSQ achieves both higher accuracy and higher bit reduction on various model architectures on the CIFAR-10 and ImageNet datasets comparing to previous methods.",混合精度の量子化は、ディープニューラルネットワークのパフォーマンスと圧縮率の間の最適なトレードオフを達成できる可能性があるため、広く研究されてきました。ただし、正確な量子化スキームを決定するための体系的な方法がありません。以前の方法では、手動で設計された小さな検索空間のみを調べるか、面倒なニューラルアーキテクチャ検索を利用して広大な検索空間を探索していました。これらのアプローチは、最適な量子化スキームを効率的に導くことはできません。この作業は、ビットレベルのスパース性を誘発する新しい角度から混合精度の量子化に取り組むためのビットレベルのスパース性量子化（BSQ）を提案します。量子化された重みの各ビットを独立したトレーニング可能な変数と見なし、微分可能なビットスパース正則化を導入します。 BSQは、重み要素のグループ全体ですべてゼロのビットを誘導し、動的な精度の低下を実現して、元のモデルの混合精度の量子化スキームを実現できます。私たちの方法は、パフォーマンスと圧縮をトレードオフするための1つのハイパーパラメータのみを使用して、単一の勾配ベースの最適化プロセスで完全な混合精度空間の探索を可能にします。 BSQは、以前の方法と比較して、CIFAR-10およびImageNetデータセットのさまざまなモデルアーキテクチャで、より高い精度とより高いビット削減の両方を実現します。,6.25,
AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on the Fly,"['Yuchen Jin', 'Tianyi Zhou', 'Liangyu Zhao', 'Yibo Zhu', 'Chuanxiong Guo', 'Marco Canini', 'Arvind Krishnamurthy']",https://openreview.net/forum?id=SlrqM9_lyju,"The learning rate (LR) schedule is one of the most important hyper-parameters needing careful tuning in training DNNs. However, it is also one of the least automated parts of machine learning systems and usually costs significant manual effort and computing. Though there are pre-defined LR schedules and optimizers with adaptive LR, they introduce new hyperparameters that need to be tuned separately for different tasks/datasets. In this paper, we consider the question: Can we automatically tune the LR over the course of training without human involvement? We propose an efficient method, AutoLRS, which automatically optimizes the LR for each training stage by modeling training dynamics. AutoLRS aims to find an LR that minimizes the validation loss, every $\tau$ steps. We formulate it as black-box optimization and solve it by Bayesian optimization (BO). However, collecting training instances for BO requires a system to evaluate each LR queried by BO's acquisition function for $\tau$ steps, which is prohibitively expensive in practice. Instead, we apply each candidate LR for only $\tau'\ll\tau$ steps and train an exponential model to predict the validation loss after $\tau$ steps. This mutual-training process between BO and the exponential model allows us to bound the number of training steps invested in the BO search. We demonstrate the advantages and the generality of AutoLRS through extensive experiments of training DNNs from diverse domains and using different optimizers. The LR schedules auto-generated by AutoLRS leads to a speedup of $1.22\times$, $1.43\times$, and $1.5\times$ when training ResNet-50, Transformer, and BERT, respectively, compared to the LR schedules in their original papers, and an average speedup of $1.31\times$ over state-of-the-art highly tuned LR schedules.",学習率（LR）スケジュールは、DNNのトレーニングで注意深い調整が必要な最も重要なハイパーパラメーターの1つです。ただし、これは機械学習システムの中で最も自動化されていない部分の1つでもあり、通常、手作業とコンピューティングに多大なコストがかかります。事前定義されたLRスケジュールとアダプティブLRを備えたオプティマイザーがありますが、それらは、異なるタスク/データセットに対して個別に調整する必要がある新しいハイパーパラメーターを導入します。このホワイトペーパーでは、次の質問について検討します。人間の関与なしに、トレーニングの過程でLRを自動的に調整できますか？トレーニングダイナミクスをモデル化することにより、各トレーニングステージのLRを自動的に最適化する効率的な方法AutoLRSを提案します。 AutoLRSは、すべてのステップで検証の損失を最小限に抑えるLRを見つけることを目的としています。それをブラックボックス最適化として定式化し、ベイズ最適化（BO）によって解決します。ただし、BOのトレーニングインスタンスを収集するには、BOの取得機能によってクエリされた各LRのステップを評価するシステムが必要であり、実際には非常にコストがかかります。代わりに、各候補LRをステップのみに適用し、指数モデルをトレーニングして、ステップ後の検証損失を予測します。 BOと指数モデル間のこの相互トレーニングプロセスにより、BO検索に投資されるトレーニングステップの数を制限できます。さまざまなドメインからDNNをトレーニングし、さまざまなオプティマイザーを使用する広範な実験を通じて、AutoLRSの利点と一般性を示します。 AutoLRSによって自動生成されたLRスケジュールは、ResNet-50、Transformer、およびBERTをトレーニングするときに、元の論文のLRスケジュールと比較して、それぞれ1.22、1.43、および1.5のスピードアップにつながり、州全体で平均1.31のスピードアップになります。 -最先端の高度に調整されたLRスケジュール。,6.25,
Prototypical Contrastive Learning of Unsupervised Representations,"['Junnan Li', 'Pan Zhou', 'Caiming Xiong', 'Steven Hoi']",https://openreview.net/forum?id=KmykpuSrjcq,"This paper presents Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that bridges contrastive learning with clustering. PCL not only learns low-level features for the task of instance discrimination, but more importantly, it implicitly encodes semantic structures of the data into the learned embedding space. Specifically, we introduce prototypes as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework. We iteratively perform E-step as finding the distribution of prototypes via clustering and M-step as optimizing the network via contrastive learning. We propose ProtoNCE loss, a generalized version of the InfoNCE loss for contrastive learning, which encourages representations to be closer to their assigned prototypes. PCL outperforms state-of-the-art instance-wise contrastive learning methods on multiple benchmarks with substantial improvement in low-resource transfer learning.",このホワイトペーパーでは、対照学習とクラスタリングの橋渡しをする教師なし表現学習手法であるプロトタイプ対照学習（PCL）について説明します。 PCLは、インスタンスの識別タスクの低レベルの機能を学習するだけでなく、さらに重要なことに、データのセマンティック構造を学習した埋め込みスペースに暗黙的にエンコードします。具体的には、潜在変数としてプロトタイプを導入し、期待値最大化フレームワークでネットワークパラメーターの最尤推定を見つけるのに役立てます。クラスタリングを介してプロトタイプの分布を見つけるためにE-stepを繰り返し実行し、対照学習を介してネットワークを最適化するためにM-stepを繰り返し実行します。対照学習のためのInfoNCE損失の一般化バージョンであるProtoNCE損失を提案します。これにより、表現を割り当てられたプロトタイプに近づけることができます。 PCLは、複数のベンチマークで最先端のインスタンスごとの対照学習方法を上回り、低リソース転送学習が大幅に改善されています。,6.25,https://d3i71xaburhd42.cloudfront.net/787c6ae0119620ba31def1a1d034c6f8ad5607db/2-Figure1-1.png
Contrastive Syn-to-Real Generalization,"['Wuyang Chen', 'Zhiding Yu', 'Shalini De Mello', 'Sifei Liu', 'Jose M. Alvarez', 'Zhangyang Wang', 'Anima Anandkumar']",https://openreview.net/forum?id=F8whUO8HNbP,"Training on synthetic data can be beneficial for label or data-scarce scenarios. However, synthetically trained models often suffer from poor generalization in real domains due to domain gaps. In this work, we make a key observation that the diversity of the learned feature embeddings plays an important role in the generalization performance. To this end, we propose contrastive synthetic-to-real generalization (CSG), a novel framework that leverage the pre-trained ImageNet knowledge to prevent overfitting to the synthetic domain, while promoting the diversity of feature embeddings as an inductive bias to improve generalization. In addition, we enhance the proposed CSG framework with attentional pooling (A-pool) to let the model focus on semantically important regions and further improve its generalization. We demonstrate the effectiveness of CSG on various synthetic training tasks, exhibiting state-of-the-art performance on zero-shot domain generalization.",合成データのトレーニングは、ラベルまたはデータが不足しているシナリオに役立ちます。ただし、合成的にトレーニングされたモデルは、ドメインのギャップが原因で、実際のドメインでの一般化が不十分になることがよくあります。この作業では、学習された特徴の埋め込みの多様性が一般化のパフォーマンスに重要な役割を果たすことを重要な観察します。この目的のために、対照的な合成から現実への一般化（CSG）を提案します。これは、事前にトレーニングされたImageNetの知識を活用して合成ドメインへの過剰適合を防ぎ、一般化を改善するための誘導バイアスとして機能の埋め込みの多様性を促進する新しいフレームワークです。 。さらに、提案されたCSGフレームワークを注意プーリング（Aプール）で拡張して、モデルが意味的に重要な領域に焦点を合わせ、その一般化をさらに改善できるようにします。さまざまな合成トレーニングタスクでのCSGの有効性を示し、ゼロショットドメインの一般化で最先端のパフォーマンスを示します。,6.25,
Scalable Transfer Learning with Expert Models,"['Joan Puigcerver', 'Carlos Riquelme Ruiz', 'Basil Mustafa', 'Cedric Renggli', 'André Susano Pinto', 'Sylvain Gelly', 'Daniel Keysers', 'Neil Houlsby']",https://openreview.net/forum?id=23ZjUGpjcc,"Transfer of pre-trained representations can improve sample efficiency and reduce computational requirements for new tasks. However, representations used for transfer are usually generic, and are not tailored to a particular distribution of downstream tasks. We explore the use of expert representations for transfer with a simple, yet effective, strategy. We train a diverse set of experts by exploiting existing label structures, and use cheap-to-compute performance proxies to select the relevant expert for each target task. This strategy scales the process of transferring to new tasks, since it does not revisit the pre-training data during transfer. Accordingly, it requires little extra compute per target task, and results in a speed-up of 2-3 orders of magnitude compared to competing approaches. Further, we provide an adapter-based architecture able to compress many experts into a single model. We evaluate our approach on two different data sources and demonstrate that it outperforms baselines on over 20 diverse vision tasks in both cases.",事前にトレーニングされた表現を転送すると、サンプルの効率が向上し、新しいタスクの計算要件が軽減されます。ただし、転送に使用される表現は通常一般的であり、ダウンストリームタスクの特定の分散に合わせて調整されていません。シンプルでありながら効果的な戦略を使用して、転送のための専門家の表現の使用を検討します。既存のラベル構造を活用して多様な専門家をトレーニングし、計算コストの低いパフォーマンスプロキシを使用して、各ターゲットタスクに関連する専門家を選択します。この戦略は、転送中に事前トレーニングデータに再度アクセスしないため、新しいタスクに転送するプロセスをスケーリングします。したがって、ターゲットタスクごとに追加の計算をほとんど必要とせず、競合するアプローチと比較して2〜3桁の速度向上をもたらします。さらに、多くの専門家を1つのモデルに圧縮できるアダプタベースのアーキテクチャを提供します。 2つの異なるデータソースでアプローチを評価し、どちらの場合も20を超える多様なビジョンタスクでベースラインを上回っていることを示しています。,6.25,https://d3i71xaburhd42.cloudfront.net/beffe798cff58416e06372904de204dcf9fb9157/2-Figure1-1.png
"SAFENet: A Secure, Accurate and Fast Neural Network Inference","['Qian Lou', 'Yilin Shen', 'Hongxia Jin', 'Lei Jiang']",https://openreview.net/forum?id=Cz3dbFm5u-,"The advances in neural networks have driven many companies to provide prediction services to users in a wide range of applications. However, current prediction systems raise privacy concerns regarding the user's private data. A cryptographic neural network inference service is an efficient way to allow two parties to execute neural network inference without revealing either party’s data or model. Nevertheless, existing cryptographic neural network inference services suffer from huge running latency; in particular, the latency of communication-expensive cryptographic activation function is 3 orders of magnitude higher than plaintext-domain activation function. And activations are the necessary components of the modern neural networks. Therefore, slow cryptographic activation has become the primary obstacle of efficient cryptographic inference. 

In this paper, we propose a new technique, called SAFENet, to enable a Secure, Accurate and Fast nEural Network inference service. To speedup secure inference and guarantee inference accuracy, SAFENet includes channel-wise activation approximation with multiple-degree options. This is implemented by keeping the most useful activation channels and replacing the remaining, less useful, channels with various-degree polynomials. SAFENet also supports mixed-precision activation approximation by automatically assigning different replacement ratios to various layer; further increasing the approximation ratio and reducing inference latency. Our experimental results show SAFENet obtains the state-of-the-art inference latency and performance, reducing latency by $38\% \sim 61\%$ or improving accuracy by $1.8\% \sim 4\%$ over prior techniques on various encrypted datasets.",ニューラルネットワークの進歩により、多くの企業が幅広いアプリケーションのユーザーに予測サービスを提供するようになりました。ただし、現在の予測システムでは、ユーザーの個人データに関するプライバシーの懸念が生じています。暗号化ニューラルネットワーク推論サービスは、当事者のデータやモデルを明らかにすることなく、2つの当事者がニューラルネットワーク推論を実行できるようにする効率的な方法です。それにもかかわらず、既存の暗号化ニューラルネットワーク推論サービスは、実行中の待ち時間が非常に長くなります。特に、通信コストの高い暗号化アクティベーション機能の遅延は、プレーンテキストドメインのアクティベーション機能よりも3桁高くなっています。そして、アクティベーションは現代のニューラルネットワークに必要なコンポーネントです。したがって、暗号のアクティブ化が遅いことが、効率的な暗号推論の主な障害となっています。この論文では、安全で正確かつ高速なニューラルネットワーク推論サービスを可能にするSAFENetと呼ばれる新しい手法を提案します。安全な推論を高速化し、推論の精度を保証するために、SAFENetには、複数度のオプションを備えたチャネルごとのアクティベーション近似が含まれています。これは、最も有用なアクティベーションチャネルを維持し、残りのあまり有用ではないチャネルをさまざまな次数の多項式に置き換えることによって実装されます。 SAFENetは、さまざまなレイヤーにさまざまな置換率を自動的に割り当てることにより、混合精度のアクティベーション近似もサポートします。近似比をさらに高め、推論の待ち時間を短縮します。私たちの実験結果は、SAFENetが最先端の推論レイテンシーとパフォーマンスを取得し、さまざまな暗号化データセットでの従来の手法よりもレイテンシーを38％61％削減するか、精度を1.8％4％向上させることを示しています。,6.25,
Integrating Categorical Semantics into Unsupervised Domain Translation,"['Samuel Lavoie-Marchildon', 'Faruk Ahmed', 'Aaron Courville']",https://openreview.net/forum?id=IMPA6MndSXU,"While unsupervised domain translation (UDT) has seen a lot of successes recently, we argue that allowing its translation to be mediated via categorical semantic features could enable wider applicability. In particular, we argue that categorical semantics are important when translating between domains with multiple object categories possessing distinctive styles, or even between domains that are simply too different but still share high-level semantics. We propose a method to learn, in an unsupervised manner, categorical semantic features (such as object labels) invariantly of the source and the target domains. We show that conditioning the style of a unsupervised domain translation methods on the learned categorical semantics leads to a considerably better high-level features preservation on tasks such as MNIST$\leftrightarrow$SVHN and to a more realistic stylization on Sketches$\to$Reals.",教師なしドメイン翻訳（UDT）は最近多くの成功を収めていますが、その翻訳をカテゴリセマンティック機能を介して仲介できるようにすることで、より広い適用性が可能になると主張します。特に、異なるスタイルを持つ複数のオブジェクトカテゴリを持つドメイン間、または単に異なるが高レベルのセマンティクスを共有しているドメイン間でさえ、カテゴリセマンティクスが重要であると主張します。教師なしの方法で、ソースドメインとターゲットドメインのカテゴリセマンティック機能（オブジェクトラベルなど）を不変に学習する方法を提案します。学習したカテゴリセマンティクスで教師なしドメイン変換メソッドのスタイルを調整すると、MNISTSVHNなどのタスクでの高レベルの特徴の保存が大幅に改善され、SketchesRealsでより現実的なスタイルが作成されることを示します。,6.25,https://d3i71xaburhd42.cloudfront.net/09b09a624cd126b78b3416c8839bc4e4325e1cfe/3-Figure1-1.png
AdaSpeech: Adaptive Text to Speech for Custom Voice,"['Mingjian Chen', 'Xu Tan', 'Bohan Li', 'Yanqing Liu', 'Tao Qin', 'sheng zhao', 'Tie-Yan Liu']",https://openreview.net/forum?id=Drynvt7gg4L,"Custom voice, a specific text to speech (TTS) service in commercial speech platforms, aims to adapt a source TTS model to synthesize personal voice for a target speaker using few speech from her/him. Custom voice presents two unique challenges for TTS adaptation: 1) to support diverse customers, the adaptation model needs to handle diverse acoustic conditions which could be very different from source speech data, and 2) to support a large number of customers, the adaptation parameters need to be small enough for each target speaker to reduce memory usage while maintaining high voice quality. In this work, we propose AdaSpeech, an adaptive TTS system for high-quality and efficient customization of new voices. We design several techniques in AdaSpeech to address the two challenges in custom voice: 1) To handle different acoustic conditions, we model the acoustic information in both utterance and phoneme level. Specifically, we use one acoustic encoder to extract an utterance-level vector and another one to extract a sequence of phoneme-level vectors from the target speech during pre-training and fine-tuning; in inference, we extract the utterance-level vector from a reference speech and use an acoustic predictor to predict the phoneme-level vectors. 2) To better trade off the adaptation parameters and voice quality, we introduce conditional layer normalization in the mel-spectrogram decoder of AdaSpeech, and fine-tune this part in addition to speaker embedding for adaptation. We pre-train the source TTS model on LibriTTS datasets and fine-tune it on VCTK and LJSpeech datasets (with different acoustic conditions from LibriTTS) with few adaptation data, e.g., 20 sentences, about 1 minute speech. Experiment results show that AdaSpeech achieves much better adaptation quality than baseline methods, with only about 5K specific parameters for each speaker, which demonstrates its effectiveness for custom voice. The audio samples are available at https://adaspeech.github.io/.",商用音声プラットフォームの特定の音声合成（TTS）サービスであるカスタム音声は、ソースTTSモデルを適応させて、ターゲットスピーカーからのわずかな音声を使用して個人の音声を合成することを目的としています。カスタム音声は、TTS適応に2つの固有の課題を提示します。1）多様な顧客をサポートするため、適応モデルは、ソース音声データとは大きく異なる可能性がある多様な音響条件を処理する必要があります。2）多数の顧客をサポートするために、適応パラメータ高い音声品質を維持しながらメモリ使用量を削減するには、各ターゲットスピーカーに対して十分に小さい必要があります。この作業では、新しい音声を高品質で効率的にカスタマイズするための適応型TTSシステムであるAdaSpeechを提案します。カスタム音声の2つの課題に対処するために、AdaSpeechでいくつかの手法を設計します。1）さまざまな音響条件を処理するために、発話レベルと音素レベルの両方で音響情報をモデル化します。具体的には、1つの音響エンコーダーを使用して発話レベルのベクトルを抽出し、別の1つを使用して、事前トレーニングおよび微調整中にターゲット音声から音素レベルのベクトルのシーケンスを抽出します。推論では、参照音声から発話レベルのベクトルを抽出し、音響予測子を使用して音素レベルのベクトルを予測します。 2）適応パラメータと音声品質をより適切にトレードオフするために、AdaSpeechのメルスペクトログラムデコーダに条件付きレイヤー正規化を導入し、適応のためのスピーカー埋め込みに加えて、この部分を微調整します。 LibriTTSデータセットでソースTTSモデルを事前トレーニングし、VCTKおよびLJSpeechデータセット（LibriTTSとは異なる音響条件）で微調整します。適応データはほとんどありません。たとえば、20文、約1分の音声です。実験結果は、AdaSpeechがベースライン方法よりもはるかに優れた適応品質を達成し、各スピーカーに約5Kの特定のパラメーターしかなく、カスタム音声に対するその有効性を示しています。オーディオサンプルはhttps://adaspeech.github.io/で入手できます。,6.25,
CoCon: A Self-Supervised Approach for Controlled Text Generation,"['Alvin Chan', 'Yew-Soon Ong', 'Bill Pung', 'Aston Zhang', 'Jie Fu']",https://openreview.net/forum?id=VD_ozqvBy4W,"Pretrained Transformer-based language models (LMs) display remarkable natural language generation capabilities. With their immense potential, controlling text generation of such LMs is getting attention. While there are studies that seek to control high-level attributes (such as sentiment and topic) of generated text, there is still a lack of more precise control over its content at the word- and phrase-level. Here, we propose Content-Conditioner (CoCon) to control an LM's output text with a content input, at a fine-grained level. In our self-supervised approach, the CoCon block learns to help the LM complete a partially-observed text sequence by conditioning with content inputs that are withheld from the LM. Through experiments, we show that CoCon can naturally incorporate target content into generated texts and control high-level text attributes in a zero-shot manner.",事前にトレーニングされたTransformerベースの言語モデル（LM）は、驚くべき自然言語生成機能を表示します。それらの計り知れない可能性により、そのようなLMのテキスト生成を制御することが注目されています。生成されたテキストの高レベルの属性（感情やトピックなど）を制御しようとする研究はありますが、単語レベルおよびフレーズレベルでそのコンテンツをより正確に制御することはまだできていません。ここでは、コンテンツ入力を使用してLMの出力テキストをきめ細かいレベルで制御するContent-Conditioner（CoCon）を提案します。私たちの自己監視アプローチでは、CoConブロックは、LMから差し控えられたコンテンツ入力で条件付けすることにより、LMが部分的に観察されたテキストシーケンスを完了するのを支援することを学習します。実験を通じて、CoConがターゲットコンテンツを生成されたテキストに自然に組み込み、ゼロショット方式で高レベルのテキスト属性を制御できることを示します。,6.25,https://d3i71xaburhd42.cloudfront.net/012c1b56e4157959c125368968142ea8bc892d0d/4-Figure1-1.png
Counterfactual Generative Networks,"['Axel Sauer', 'Andreas Geiger']",https://openreview.net/forum?id=BXewfAYMmJw,"Neural networks are prone to learning shortcuts -- they often model simple correlations, ignoring more complex ones that potentially generalize better. Prior works on image classification show that instead of learning a connection to object shape, deep classifiers tend to exploit spurious correlations with low-level texture or the background for solving the classification task. In this work, we take a step towards more robust and interpretable classifiers that explicitly expose the task's causal structure. Building on current advances in deep generative modeling, we propose to decompose the image generation process into independent causal mechanisms that we train without direct supervision. By exploiting appropriate inductive biases, these mechanisms disentangle object shape, object texture, and background; hence, they allow for generating counterfactual images. We demonstrate the ability of our model to generate such images on MNIST and ImageNet. Further, we show that the counterfactual images can improve out-of-distribution robustness with a marginal drop in performance on the original classification task, despite being synthetic. Lastly, our generative model can be trained efficiently on a single GPU, exploiting common pre-trained models as inductive biases.",ニューラルネットワークは、単純な相関関係をモデル化することが多いショートカットを学習する傾向があり、より一般化する可能性のあるより複雑なものを無視します。画像分類に関する以前の研究では、オブジェクトの形状との関係を学習する代わりに、深い分類器は、分類タスクを解決するために、低レベルのテクスチャまたは背景との疑似相関を利用する傾向があることが示されています。この作業では、タスクの因果構造を明示的に公開する、より堅牢で解釈可能な分類子に向けた一歩を踏み出します。深い生成モデリングの現在の進歩に基づいて、画像生成プロセスを、直接の監督なしにトレーニングする独立した因果メカニズムに分解することを提案します。これらのメカニズムは、適切な誘導バイアスを利用することにより、オブジェクトの形状、オブジェクトのテクスチャ、および背景を解きほぐします。したがって、それらは反事実的な画像を生成することを可能にします。 MNISTとImageNetでそのような画像を生成するモデルの能力を示します。さらに、反事実的画像は、合成であるにもかかわらず、元の分類タスクのパフォーマンスをわずかに低下させることで、分布外のロバスト性を向上させることができることを示します。最後に、生成モデルは単一のGPUで効率的にトレーニングでき、一般的な事前トレーニング済みモデルを誘導バイアスとして活用できます。,6.25,https://d3i71xaburhd42.cloudfront.net/011fbfe79c738b84c1bfcdabcd752977524b1363/2-Figure1-1.png
Stochastic Security: Adversarial Defense Using Long-Run Dynamics of Energy-Based Models,"['Mitch Hill', 'Jonathan Craig Mitchell', 'Song-Chun Zhu']",https://openreview.net/forum?id=gwFTuzxJW0,"The vulnerability of deep networks to adversarial attacks is a central problem for deep learning from the perspective of both cognition and security. The current most successful defense method is to train a classifier using adversarial images created during learning. Another defense approach involves transformation or purification of the original input to remove adversarial signals before the image is classified. We focus on defending naturally-trained classifiers using Markov Chain Monte Carlo (MCMC) sampling with an Energy-Based Model (EBM) for adversarial purification. In contrast to adversarial training, our approach is intended to secure highly vulnerable pre-existing classifiers. To our knowledge, no prior defense method is capable of securing naturally-trained classifiers, and our method is the first to validate a post-training defense approach that is distinct from current successful defenses which modify classifier training.

The memoryless behavior of long-run MCMC sampling will eventually remove adversarial signals, while metastable behavior preserves consistent appearance of MCMC samples after many steps to allow accurate long-run prediction. Balancing these factors can lead to effective purification and robust classification. We evaluate adversarial defense with an EBM using the strongest known attacks against purification. Our contributions are 1) an improved method for training EBM's with realistic long-run MCMC samples for effective purification, 2) an Expectation-Over-Transformation (EOT) defense that resolves ambiguities for evaluating stochastic defenses and from which the EOT attack naturally follows, and 3) state-of-the-art adversarial defense for naturally-trained classifiers and competitive defense compared to adversarial training on CIFAR-10, SVHN, and CIFAR-100.",敵対的攻撃に対するディープネットワークの脆弱性は、認知とセキュリティの両方の観点からディープラーニングの中心的な問題です。現在最も成功している防御方法は、学習中に作成された敵対的な画像を使用して分類器をトレーニングすることです。別の防御アプローチには、画像が分類される前に敵対的な信号を除去するための元の入力の変換または精製が含まれます。敵対的浄化のためのエネルギーベースモデル（EBM）によるマルコフ連鎖モンテカルロ（MCMC）サンプリングを使用して、自然に訓練された分類器を防御することに焦点を当てています。敵対的なトレーニングとは対照的に、私たちのアプローチは、非常に脆弱な既存の分類器を保護することを目的としています。私たちの知る限り、自然に訓練された分類器を確保できる事前の防御方法はありません。私たちの方法は、分類器の訓練を変更する現在の成功した防御とは異なる訓練後の防御アプローチを検証する最初の方法です。長期MCMCサンプリングのメモリレス動作は、最終的に敵対信号を除去しますが、準安定動作は、正確な長期予測を可能にするために、多くのステップの後、MCMCサンプルの一貫した外観を維持します。これらの要因のバランスをとることで、効果的な精製と堅牢な分類につながる可能性があります。浄化に対する最も強力な既知の攻撃を使用して、EBMによる敵対的防御を評価します。私たちの貢献は、1）効果的な精製のために現実的な長期MCMCサンプルを使用してEBMをトレーニングするための改善された方法、2）確率的防御を評価するための曖昧さを解決し、EOT攻撃が自然に続くExpectation-Over-Transformation（EOT）防御です。 3）CIFAR-10、SVHN、およびCIFAR-100での敵対的訓練と比較した、自然に訓練された分類器に対する最先端の敵対的防御および競争的防御。,6.25,https://d3i71xaburhd42.cloudfront.net/d966edcc545f2b6a8ee2403da237eafc2330e048/2-Figure1-1.png
Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics,"['Yanchao Sun', 'Da Huo', 'Furong Huang']",https://openreview.net/forum?id=9r30XCjf5Dt,"Poisoning attacks on Reinforcement Learning (RL) systems could take advantage of RL algorithm’s vulnerabilities and cause failure of the learning. However, prior works on poisoning RL usually either unrealistically assume the attacker knows the underlying Markov Decision Process (MDP), or directly apply the poisoning methods in supervised learning to RL. In this work, we build a generic poisoning framework for online RL via a comprehensive investigation of heterogeneous poisoning models in RL. Without any prior knowledge of the MDP, we propose a strategic poisoning algorithm called Vulnerability-Aware Adversarial Critic Poison (VA2C-P), which works for most policy-based deep RL agents, closing the gap that no poisoning method exists for policy-based RL agents. VA2C-P uses a novel metric, stability radius in RL, that measures the vulnerability of RL algorithms. Experiments on multiple deep RL agents and multiple environments show that our poisoning algorithm successfully prevents agents from learning a good policy or teaches the agents to converge to a target policy, with a limited attacking budget.",強化学習（RL）システムに対する中毒攻撃は、RLアルゴリズムの脆弱性を利用して、学習の失敗を引き起こす可能性があります。ただし、RLのポイズニングに関する以前の作業では、通常、攻撃者が基礎となるマルコフ決定過程（MDP）を知っていると非現実的に想定するか、教師あり学習でポイズニング手法をRLに直接適用します。この作業では、RLの異種中毒モデルの包括的な調査を通じて、オンラインRLの一般的な中毒フレームワークを構築します。 MDPの予備知識がなくても、脆弱性を意識した敵対的批評家毒（VA2C-P）と呼ばれる戦略的中毒アルゴリズムを提案します。これは、ほとんどのポリシーベースのディープRLエージェントで機能し、ポリシーベースのポイズニング方法が存在しないというギャップを埋めます。 RLエージェント。 VA2C-Pは、RLアルゴリズムの脆弱性を測定する、RLの安定半径という新しいメトリックを使用します。複数のディープRLエージェントと複数の環境での実験では、ポイズニングアルゴリズムにより、エージェントが適切なポリシーを学習できないようにするか、限られた攻撃予算でエージェントにターゲットポリシーに収束するように指示します。,6.25,https://d3i71xaburhd42.cloudfront.net/4d049e71c99bc804036192800348e9ca0de66f0e/3-Figure1-1.png
Cross-Attentional Audio-Visual Fusion for Weakly-Supervised Action Localization,"['Jun-Tae Lee', 'Mihir Jain', 'Hyoungwoo Park', 'Sungrack Yun']",https://openreview.net/forum?id=hWr3e3r-oH5,"Temporally localizing actions in videos is one of the key components for video understanding. Learning from weakly-labeled data is seen as a potential solution towards avoiding expensive frame-level annotations. Different from other works, which only depend on the visual-modality, we propose to learn richer audio-visual representations for weakly-supervised action localization. First, we propose a multi-stage cross-attention mechanism to collaboratively fuse audio and visual features, which preserves the intra-modal characteristics. Second, to model both foreground and background frames, we construct an open-max classifier, which treats the background class as an open-set. Third, for precise action localization, we design consistency losses to enforce temporal continuity for the action-class prediction, and also help with foreground-prediction reliability. Extensive experiments on two publicly available video-datasets (AVE and ActivityNet1.2) show that the proposed method effectively fuses audio and visual modalities, and achieves the state-of-the-art results for weakly-supervised action localization.",動画内のアクションを一時的にローカライズすることは、動画を理解するための重要な要素の1つです。弱くラベル付けされたデータから学習することは、高価なフレームレベルの注釈を回避するための潜在的な解決策と見なされています。視覚モダリティのみに依存する他の作品とは異なり、弱教師ありアクションローカリゼーションのためのより豊かな視聴覚表現を学習することを提案します。まず、モード内の特性を維持する、オーディオとビジュアルの機能を協調的に融合する多段階のクロスアテンションメカニズムを提案します。次に、前景フレームと背景フレームの両方をモデル化するために、背景クラスを開集合として扱うopen-max分類器を作成します。第3に、正確なアクションのローカリゼーションのために、一貫性の損失を設計して、アクションクラスの予測の時間的連続性を強制し、前景予測の信頼性も支援します。 2つの公開されているビデオデータセット（AVEとActivityNet1.2）での広範な実験は、提案された方法がオーディオとビジュアルのモダリティを効果的に融合し、弱く監視されたアクションのローカリゼーションのための最先端の結果を達成することを示しています。,6.25,
Differentiable Trust Region Layers for Deep Reinforcement Learning,"['Fabian Otto', 'Philipp Becker', 'Vien Anh Ngo', 'Hanna Carolin Maria Ziesche', 'Gerhard Neumann']",https://openreview.net/forum?id=qYZD-AO1Vn,"Trust region methods are a popular tool in reinforcement learning as they yield robust policy updates in continuous and discrete action spaces. However, enforcing such trust regions in deep reinforcement learning is difficult. Hence, many approaches, such as Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO), are based on approximations. Due to those approximations, they violate the constraints or fail to find the optimal solution within the trust region. Moreover, they are difficult to implement, lack sufficient exploration, and have been shown to depend on seemingly unrelated implementation choices. In this work, we propose differentiable neural network layers to enforce trust regions for deep Gaussian policies via closed-form projections.  Unlike existing methods, those layers formalize trust regions for each state individually and can complement existing reinforcement learning algorithms. We derive trust region projections based on the Kullback-Leibler divergence, the Wasserstein L2 distance, and the Frobenius norm for Gaussian distributions. We empirically demonstrate that those projection layers achieve similar or better results than existing methods while being almost agnostic to specific implementation choices.",信頼領域法は、連続的および離散的なアクションスペースで堅牢なポリシー更新を生成するため、強化学習で人気のあるツールです。ただし、このような信頼領域を深層強化学習に適用することは困難です。したがって、信頼領域ポリシー最適化（TRPO）や近接ポリシー最適化（PPO）などの多くのアプローチは、近似に基づいています。これらの近似により、制約に違反するか、信頼領域内で最適なソリューションを見つけることができません。さらに、それらは実装が難しく、十分な調査が不足しており、一見無関係な実装の選択に依存していることが示されています。この作業では、閉じた形式の投影を介して深いガウスポリシーの信頼領域を適用するための微分可能なニューラルネットワーク層を提案します。既存の方法とは異なり、これらのレイヤーは各状態の信頼領域を個別に形式化し、既存の強化学習アルゴリズムを補完できます。カルバック・ライブラー発散、ワッサースタインL2距離、およびガウス分布のフロベニウスノルムに基づいて信頼領域の予測を導き出します。これらのプロジェクションレイヤーは、特定の実装の選択にほとんど依存せずに、既存の方法と同等またはそれ以上の結果を達成することを経験的に示しています。,6.25,https://d3i71xaburhd42.cloudfront.net/0efa2efa49a1923954d69eaa9f898af22f63a983/6-Figure1-1.png
Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes' Rule,"['Shuhei Kurita', 'Kyunghyun Cho']",https://openreview.net/forum?id=45uOPa46Kh,"Vision-and-language navigation (VLN) is a task in which an agent is embodied in a realistic 3D environment and follows an instruction to reach the goal node. While most of the previous studies have built and investigated a discriminative approach, we notice that there are in fact two possible approaches to building such a VLN agent: discriminative and generative. In this paper, we design and investigate a generative language-grounded policy which uses a language model to compute the distribution over all possible instructions i.e. all possible sequences of vocabulary tokens given action and the transition history. In experiments, we show that the proposed generative approach outperforms the discriminative approach in the Room-2-Room (R2R) and Room-4-Room (R4R) datasets, especially in the unseen environments. We further show that the combination of the generative and discriminative policies achieves close to the state-of-the art results in the R2R dataset, demonstrating that the generative and discriminative policies capture the different aspects of VLN.",視覚と言語のナビゲーション（VLN）は、エージェントが現実的な3D環境で具体化され、指示に従ってゴールノードに到達するタスクです。これまでの研究のほとんどは識別的アプローチを構築および調査してきましたが、実際には、そのようなVLNエージェントを構築するための2つの可能なアプローチがあります。識別的アプローチと生成的アプローチです。この論文では、言語モデルを使用して、すべての可能な命令、つまりアクションと遷移履歴が与えられた語彙トークンのすべての可能なシーケンスにわたる分布を計算する生成言語ベースのポリシーを設計および調査します。実験では、提案された生成的アプローチが、特に見えない環境で、Room-2-Room（R2R）およびRoom-4-Room（R4R）データセットの識別的アプローチよりも優れていることを示します。さらに、生成ポリシーと識別ポリシーの組み合わせがR2Rデータセットの最先端の結果に近い結果を達成することを示し、生成ポリシーと識別ポリシーがVLNのさまざまな側面をキャプチャすることを示します。,6.25,https://d3i71xaburhd42.cloudfront.net/3435e193998ec4118f51bbb608a843b0e123661b/2-Figure1-1.png
Disambiguating Symbolic Expressions in Informal Documents,"['Dennis Müller', 'Cezary Kaliszyk']",https://openreview.net/forum?id=K5j7D81ABvt,"We propose the task of \emph{disambiguating} symbolic expressions in informal STEM documents in the form of \LaTeX files -- that is, determining their precise semantics and abstract syntax tree -- as a neural machine translation task. We discuss the distinct challenges involved and present a dataset with roughly 33,000 entries. We evaluated several baseline models on this dataset, which failed to yield even syntactically valid \LaTeX before overfitting. Consequently, we describe a methodology using a \emph{transformer} language model pre-trained on sources obtained from \url{arxiv.org}, which yields promising results despite the small size of the dataset. We evaluate our model using a plurality of dedicated techniques, taking syntax and semantics of symbolic expressions into account.","非公式のSTEMドキュメントのシンボリック式をLaTeXfilesの形式で明確にするタスク、つまり、ニューラル機械翻訳タスクとしての正確なセマンティクスと抽象構文ツリーを決定するタスクを提案します。関連する明確な課題について説明し、約33,000エントリのデータセットを提示します。このデータセットでいくつかのベースラインモデルを評価しましたが、過剰適合する前に構文的に有効なLaTeXを生成することさえできませんでした。したがって、arxiv.orgから取得したソースで事前トレーニングされたトランスフォーマー言語モデルを使用する方法論について説明します。これにより、データセットのサイズが小さいにもかかわらず、有望な結果が得られます。シンボリック式の構文とセマンティクスを考慮に入れて、複数の専用技術を使用してモデルを評価します。",6.25,https://d3i71xaburhd42.cloudfront.net/e7b959c2e2bc3e823ba9d51213f604530c242912/4-Figure1-1.png
GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy Images,"['Sungmin Cha', 'Taeeon Park', 'Byeongjoon Kim', 'Jongduk Baek', 'Taesup Moon']",https://openreview.net/forum?id=SHvF5xaueVn,"We tackle a challenging blind image denoising problem, in which only single distinct noisy images are available for training a denoiser, and no information about noise is known, except for it being zero-mean, additive, and independent of the clean image. In such a setting, which often occurs in practice, it is not possible to train a denoiser with the standard discriminative training or with the recently developed Noise2Noise (N2N) training; the former requires the underlying clean image for the given noisy image, and the latter requires two independently realized noisy image pair for a clean image. To that end, we propose GAN2GAN (Generated-Artificial-Noise to Generated-Artificial-Noise) method that first learns a generative model that can 1) simulate the noise in the given noisy images and 2) generate a rough, noisy estimates of the clean images, then 3) iteratively trains a denoiser with subsequently synthesized noisy image pairs (as in N2N), obtained from the generative model. In results, we show the denoiser trained with our GAN2GAN achieves an impressive denoising performance on both synthetic and real-world datasets for the blind denoising setting; it almost approaches the performance of the standard discriminatively-trained or N2N-trained models that have more information than ours, and it significantly outperforms the recent baseline for the same setting, \textit{e.g.}, Noise2Void, and a more conventional yet strong one, BM3D. ",ノイズ除去装置のトレーニングに使用できるノイズの多い画像は1つだけであり、平均がゼロで加算的でクリーンな画像から独立していることを除いて、ノイズに関する情報がわからないという、困難なブラインド画像のノイズ除去の問題に取り組みます。実際によく発生するこのような設定では、標準の識別トレーニングまたは最近開発されたNoise2Noise（N2N）トレーニングでデノイザーをトレーニングすることはできません。前者は、与えられたノイズの多い画像の基礎となるクリーンな画像を必要とし、後者は、クリーンな画像のために2つの独立して実現されたノイズの多い画像のペアを必要とします。そのために、GAN2GAN（Generated-Artificial-Noise to Generated-Artificial-Noise）メソッドを提案します。この方法では、1）与えられたノイズの多い画像のノイズをシミュレートし、2）大まかなノイズの多い推定値を生成できる生成モデルを最初に学習します。次に、3）生成モデルから取得した、ノイズの多い画像ペア（N2Nの場合のように）を後で合成して、ノイズ除去装置を繰り返しトレーニングします。結果として、GAN2GANでトレーニングされたノイズ除去装置が、ブラインドノイズ除去設定の合成データセットと実世界のデータセットの両方で印象的なノイズ除去パフォーマンスを達成することを示します。これは、私たちよりも多くの情報を持つ標準の識別トレーニングまたはN2Nトレーニングモデルのパフォーマンスにほぼ近づき、同じ設定（Noise2Voidなど）や、より従来型でありながら強力なBM3Dの最近のベースラインを大幅に上回っています。,6.25,https://d3i71xaburhd42.cloudfront.net/52f3ad1ad62bf95b9e7ff5bfc58fdd9e80b8e86f/4-Figure1-1.png
Revisiting Few-sample BERT Fine-tuning,"['Tianyi Zhang', 'Felix Wu', 'Arzoo Katiyar', 'Kilian Q Weinberger', 'Yoav Artzi']",https://openreview.net/forum?id=cO1IH43yUF,"This paper is a study of fine-tuning of BERT contextual representations, with focus on commonly observed instabilities in few-sample scenarios. We identify several factors that cause this instability: the common use of a non-standard optimization method with biased gradient estimation; the limited applicability of significant parts of the BERT network for down-stream tasks; and the prevalent practice of using a pre-determined, and small number of training iterations. We empirically test the impact of these factors, and identify alternative practices that resolve the commonly observed instability of the process. In light of these observations, we re-visit recently proposed methods to improve few-sample fine-tuning with BERT and re-evaluate their effectiveness. Generally, we observe the impact of these methods diminishes significantly with our modified process. ",このペーパーは、BERTコンテキスト表現の微調整の研究であり、いくつかのサンプルシナリオで一般的に観察される不安定性に焦点を当てています。この不安定性の原因となるいくつかの要因を特定します。バイアス勾配推定を使用した非標準の最適化手法の一般的な使用。ダウンストリームタスクに対するBERTネットワークの重要な部分の限定的な適用性。事前に決定された少数のトレーニング反復を使用する一般的な方法。これらの要因の影響を経験的にテストし、一般的に観察されるプロセスの不安定性を解決する代替手法を特定します。これらの観察に照らして、BERTを使用した少数サンプルの微調整を改善するために最近提案された方法を再検討し、それらの有効性を再評価します。一般に、これらのメソッドの影響は、変更されたプロセスによって大幅に減少することがわかります。,6.25,https://d3i71xaburhd42.cloudfront.net/e1b5740979f2e8549084f8b15fb035e494153556/4-Figure1-1.png
GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,"['Dmitry Lepikhin', 'HyoukJoong Lee', 'Yuanzhong Xu', 'Dehao Chen', 'Orhan Firat', 'Yanping Huang', 'Maxim Krikun', 'Noam Shazeer', 'Zhifeng Chen']",https://openreview.net/forum?id=qrwe7XHTmYb,"Neural network scaling has been critical for improving the model quality in many real-world machine learning applications with vast amounts of training data and compute. Although this trend of scaling is affirmed to be a sure-fire approach for better model quality, there are challenges on the path such as the computation cost,ease of programming, and efficient implementation on parallel devices.  In this paper we demonstrate conditional computation as a remedy to the above mentioned impediments, and demonstrate its efficacy and utility.  We make extensive use of GShard, a module composed of a set of lightweight annotation APIs and an extension to the XLA compiler to enable large scale models with up to trillions of parameters. GShard and conditional computation enable us to scale up multilingual neural machine translation Transformer model with Sparsely-Gated Mixture-of-Experts. We demonstrate that such a giant model with 600 billion parameters can efficiently be trained on 2048 TPU v3 cores in 4 days to achieve far superior quality for translation from 100 languages to English compared to the prior art.","ニューラルネットワークのスケーリングは、大量のトレーニングデータとコンピューティングを使用する多くの実際の機械学習アプリケーションでモデルの品質を向上させるために重要です。このスケーリングの傾向は、モデルの品質を向上させるための確実なアプローチであることが確認されていますが、計算コスト、プログラミングの容易さ、並列デバイスでの効率的な実装などの課題があります。この論文では、上記の障害に対する救済策として条件付き計算を示し、その有効性と有用性を示します。軽量のアノテーションAPIのセットとXLAコンパイラの拡張機能で構成されるモジュールであるGShardを多用して、最大数兆のパラメータを持つ大規模モデルを実現します。 GShardと条件付き計算により、多言語ニューラル機械翻訳TransformerモデルをSparsely-GatedMixture-of-Expertsでスケールアップできます。 6,000億個のパラメーターを持つこのような巨大なモデルを、2048 TPU v3コアで4日間で効率的にトレーニングして、従来技術と比較して100言語から英語への翻訳ではるかに優れた品質を実現できることを示します。",6.25,https://d3i71xaburhd42.cloudfront.net/1882f194cb43828852cc052887671e55a80f945a/2-Figure1-1.png
Effective and Efficient Vote Attack on Capsule Networks,"['Jindong Gu', 'Baoyuan Wu', 'Volker Tresp']",https://openreview.net/forum?id=33rtZ4Sjwjn,"Standard Convolutional Neural Networks (CNNs) can be easily fooled by images with small quasi-imperceptible artificial perturbations. As alternatives to CNNs, the recently proposed Capsule Networks (CapsNets) are shown to be more robust to white-box attack than CNNs under popular attack protocols. Besides, the class-conditional reconstruction part of CapsNets is also used to detect adversarial examples. In this work, we investigate the adversarial robustness of CapsNets, especially how the inner workings of CapsNets change when the output capsules are attacked. The first observation is that adversarial examples misled CapsNets by manipulating the votes from primary capsules. Another observation is the high computational cost, when we directly apply multi-step attack methods designed for CNNs to attack CapsNets, due to the computationally expensive routing mechanism. Motivated by these two observations, we propose a novel vote attack where we attack votes of CapsNets directly. Our vote attack is not only effective, but also efficient by circumventing the routing process. Furthermore, we integrate our vote attack into the detection-aware attack paradigm, which can successfully bypass the class-conditional reconstruction based detection method. Extensive experiments demonstrate the superior attack performance of our vote attack on CapsNets.",標準の畳み込みニューラルネットワーク（CNN）は、小さな準知覚不可能な人工摂動を伴う画像に簡単にだまされる可能性があります。 CNNの代替として、最近提案されたカプセルネットワーク（CapsNets）は、一般的な攻撃プロトコルの下でCNNよりもホワイトボックス攻撃に対してより堅牢であることが示されています。さらに、CapsNetsのクラス条件付き再構築部分は、敵対的な例を検出するためにも使用されます。この作業では、CapsNetの敵対的な堅牢性、特に出力カプセルが攻撃されたときにCapsNetの内部動作がどのように変化するかを調査します。最初の観察は、敵対的な例が一次カプセルからの投票を操作することによってCapsNetsを誤解させたことです。もう1つの観察結果は、計算コストが高いルーティングメカニズムのために、CNN用に設計されたマルチステップ攻撃方法を直接適用してCapsNetを攻撃する場合の計算コストが高いことです。これらの2つの観察に動機付けられて、CapsNetsの投票を直接攻撃する新しい投票攻撃を提案します。私たちの投票攻撃は効果的であるだけでなく、ルーティングプロセスを回避することによっても効率的です。さらに、投票攻撃を検出認識攻撃パラダイムに統合します。これにより、クラス条件付き再構築ベースの検出方法を正常にバイパスできます。広範な実験により、CapsNetsに対する投票攻撃の優れた攻撃パフォーマンスが実証されています。,6.25,
Multiscale Score Matching for Out-of-Distribution Detection,"['Ahsan Mahmood', 'Junier Oliva', 'Martin Andreas Styner']",https://openreview.net/forum?id=xoHdgbQJohv,"We present a new methodology for detecting out-of-distribution (OOD) images by utilizing norms of the score estimates at multiple noise scales. A score is defined to be the gradient of the log density with respect to the input data. Our methodology is completely unsupervised and follows a straight forward training scheme. First, we train a deep network to estimate scores for $L$ levels of noise. Once trained, we calculate the noisy score estimates for $N$ in-distribution samples and take the L2-norms across the input dimensions (resulting in an $N$x$L$ matrix). Then we train an auxiliary model (such as a Gaussian Mixture Model) to learn the in-distribution spatial regions in this $L$-dimensional space. This auxiliary model can now be used to identify points that reside outside the learned space. Despite its simplicity, our experiments show that this methodology significantly outperforms the state-of-the-art in detecting out-of-distribution images. For example, our method can effectively separate CIFAR-10 (inlier) and SVHN (OOD) images, a setting which has been previously shown to be difficult for deep likelihood models.",複数のノイズスケールでのスコア推定の基準を利用することにより、分布外（OOD）画像を検出するための新しい方法論を提示します。スコアは、入力データに対するログ密度の勾配として定義されます。私たちの方法論は完全に監視されておらず、簡単なトレーニングスキームに従います。まず、Lレベルのノイズのスコアを推定するために深いネットワークをトレーニングします。トレーニングが完了したら、N個の分布サンプルのノイズの多いスコア推定値を計算し、入力次元全体でL2ノルムを取得します（結果としてNxL行列になります）。次に、補助モデル（ガウス混合モデルなど）をトレーニングして、このL次元空間の分布内空間領域を学習します。この補助モデルを使用して、学習した空間の外側にあるポイントを特定できるようになりました。その単純さにもかかわらず、私たちの実験は、この方法論が、分布外の画像を検出する際に最先端技術を大幅に上回っていることを示しています。たとえば、私たちの方法では、CIFAR-10（インライア）画像とSVHN（OOD）画像を効果的に分離できます。これは、深い尤度モデルでは困難であることが以前に示された設定です。,6.25,https://d3i71xaburhd42.cloudfront.net/703ffd7ab0bdfcb091400ebb9c7b92446204831f/2-Figure1-1.png
Universal approximation power of deep residual neural networks via nonlinear control theory,"['Paulo Tabuada', 'Bahman Gharesifard']",https://openreview.net/forum?id=-IXhmY16R3M,"In this paper, we explain the universal approximation capabilities of deep residual neural networks through geometric nonlinear control. Inspired by recent work establishing links between residual networks and control systems, we provide a general sufficient condition for a residual network to have the power of universal approximation by asking the activation function, or one of its derivatives, to satisfy a quadratic differential equation. Many activation functions used in practice satisfy this assumption, exactly or approximately, and we show this property to be sufficient for an adequately deep neural network with $n+1$ neurons per
layer to approximate arbitrarily well, on a compact set and with respect to the supremum norm, any continuous function from $\mathbb{R}^n$ to $\mathbb{R}^n$. We further show this result to hold for very simple architectures for which the weights only need to assume two values. The first key technical contribution consists of relating the universal approximation problem to controllability of an ensemble of control systems corresponding to a residual network and to leverage classical Lie algebraic techniques to characterize controllability. The second technical contribution is to identify monotonicity as the bridge between controllability of finite ensembles and uniform approximability on compact sets.",この論文では、幾何学的非線形制御による深部残余ニューラルネットワークの普遍近似機能について説明します。残余ネットワークと制御システムの間のリンクを確立する最近の研究に触発されて、2次微分方程式を満たすように活性化関数またはその導関数の1つを求めることにより、残余ネットワークが普遍近似の力を持つための一般的な十分条件を提供します。実際に使用される多くの活性化関数は、この仮定を正確にまたはほぼ満たしており、コンパクトなセットで、上限に関して、層ごとにn +1個のニューロンを持つ十分に深いニューラルネットワークが任意に適切に近似するのに十分であることを示しています。ノルム、R ^（n）からR ^（n）までの任意の連続関数。さらに、この結果が、重みが2つの値を想定するだけでよい非常に単純なアーキテクチャにも当てはまることを示します。最初の重要な技術的貢献は、普遍近似問題を残余ネットワークに対応する制御システムのアンサンブルの制御可能性に関連付け、制御可能性を特徴付けるために古典的なリー代数手法を活用することで構成されます。 2番目の技術的貢献は、有限集合の制御可能性とコンパクトセットでの均一な近似性の間の橋渡しとして単調性を特定することです。,6.25,
Tradeoffs in Data Augmentation: An Empirical Study,"['Raphael Gontijo-Lopes', 'Sylvia Smullin', 'Ekin Dogus Cubuk', 'Ethan Dyer']",https://openreview.net/forum?id=ZcKPWuhG6wy,"Though data augmentation has become a standard component of deep neural network training, the underlying mechanism behind the effectiveness of these techniques remains poorly understood. In practice, augmentation policies are often chosen using heuristics of distribution shift or augmentation diversity. Inspired by these, we conduct an empirical study to quantify how data augmentation improves model generalization. We introduce two interpretable and easy-to-compute measures: Affinity and Diversity. We find that augmentation performance is predicted not by either of these alone but by jointly optimizing the two.",データの増強はディープニューラルネットワークトレーニングの標準コンポーネントになっていますが、これらの手法の有効性の背後にある根本的なメカニズムはよくわかっていません。実際には、拡張ポリシーは、多くの場合、分布シフトまたは拡張ダイバーシティのヒューリスティックを使用して選択されます。これらに触発されて、データ拡張がモデルの一般化をどのように改善するかを定量化するための実証研究を実施します。親和性と多様性という、解釈可能で計算しやすい2つの指標を紹介します。増強性能は、これらのいずれかだけではなく、2つを共同で最適化することによって予測されることがわかります。,6.25,
Learning a Latent Search Space for Routing Problems using Variational Autoencoders,"['André Hottung', 'Bhanu Bhandari', 'Kevin Tierney']",https://openreview.net/forum?id=90JprVrJBO,"Methods for automatically learning to solve routing problems are rapidly improving in performance. While most of these methods excel at generating solutions quickly, they are unable to effectively utilize longer run times because they lack a sophisticated search component. We present a learning-based optimization approach that allows a guided search in the distribution of high-quality solutions for a problem instance. More precisely, our method uses a conditional variational autoencoder that learns to map points in a continuous (latent) search space to high-quality, instance-specific routing problem solutions. The learned space can then be searched by any unconstrained continuous optimization method. We show that even using a standard differential evolution search strategy our approach is able to outperform existing purely machine learning based approaches. ",ルーティングの問題を解決するために自動的に学習する方法は、パフォーマンスが急速に向上しています。これらのメソッドのほとんどはソリューションの迅速な生成に優れていますが、高度な検索コンポーネントがないため、より長い実行時間を効果的に利用することはできません。問題インスタンスの高品質ソリューションの配布におけるガイド付き検索を可能にする学習ベースの最適化アプローチを提示します。より正確には、私たちの方法は、連続（潜在）検索空間内のポイントを高品質のインスタンス固有のルーティング問題ソリューションにマッピングすることを学習する条件付き変分オートエンコーダーを使用します。学習された空間は、制約のない連続最適化手法で検索できます。標準の差分進化検索戦略を使用しても、私たちのアプローチは既存の純粋な機械学習ベースのアプローチよりも優れていることを示しています。,6.25,
Multi-Level Local SGD: Distributed SGD for Heterogeneous Hierarchical Networks,"['Timothy Castiglia', 'Anirban Das', 'Stacy Patterson']",https://openreview.net/forum?id=C70cp4Cn32,"We propose Multi-Level Local SGD, a distributed stochastic gradient method for learning a smooth, non-convex objective in a multi-level communication network with heterogeneous workers. Our network model consists of a set of disjoint sub-networks, with a single hub and multiple workers; further, workers may have different operating rates. The hubs exchange information with one another via a connected, but not necessarily complete communication network. In our algorithm, sub-networks execute a distributed SGD algorithm, using a hub-and-spoke paradigm, and the hubs periodically average their models with neighboring hubs. We first provide a unified mathematical framework that describes the Multi-Level Local SGD algorithm. We then present a theoretical analysis of the algorithm; our analysis shows the dependence of the convergence error on the worker node heterogeneity, hub network topology, and the number of local, sub-network, and global iterations. We illustrate the effectiveness of our algorithm in a multi-level network with slow workers via simulation-based experiments.",マルチレベルローカルSGDを提案します。これは、異種ワーカーとのマルチレベル通信ネットワークで滑らかな非凸目的を学習するための分散確率的勾配法です。私たちのネットワークモデルは、単一のハブと複数のワーカーを備えた、互いに素なサブネットワークのセットで構成されています。さらに、労働者の稼働率は異なる場合があります。ハブは、接続されているが必ずしも完全な通信ネットワークを介して相互に情報を交換します。私たちのアルゴリズムでは、サブネットワークはハブアンドスポークパラダイムを使用して分散SGDアルゴリズムを実行し、ハブはモデルを隣接するハブと定期的に平均化します。まず、マルチレベルローカルSGDアルゴリズムを説明する統一された数学的フレームワークを提供します。次に、アルゴリズムの理論的分析を示します。私たちの分析は、収束エラーがワーカーノードの異質性、ハブネットワークトポロジ、およびローカル、サブネットワーク、およびグローバルの反復回数に依存していることを示しています。シミュレーションベースの実験を介して、遅いワーカーがいるマルチレベルネットワークでのアルゴリズムの有効性を示します。,6.25,
Modelling Hierarchical Structure between Dialogue Policy and Natural Language Generator with Option Framework for Task-oriented Dialogue System,"['Jianhong Wang', 'Yuan Zhang', 'Tae-Kyun Kim', 'Yunjie Gu']",https://openreview.net/forum?id=kLbhLJ8OT12,"Designing task-oriented dialogue systems is a challenging research topic, since it needs not only to generate utterances fulfilling user requests but also to guarantee the comprehensibility. Many previous works trained end-to-end (E2E) models with supervised learning (SL), however, the bias in annotated system utterances remains as a bottleneck. Reinforcement learning (RL) deals with the problem through using non-differentiable evaluation metrics (e.g., the success rate) as rewards. Nonetheless, existing works with RL showed that the comprehensibility of generated system utterances could be corrupted when improving the performance on fulfilling user requests. In our work, we (1) propose modelling the hierarchical structure between dialogue policy and natural language generator (NLG) with the option framework, called HDNO, where the latent dialogue act is applied to avoid designing specific dialogue act representations; (2) train HDNO via hierarchical reinforcement learning (HRL), as well as suggest the asynchronous updates between dialogue policy and NLG during training to theoretically guarantee their convergence to a local maximizer; and (3) propose using a discriminator modelled with language models as an additional reward to further improve the comprehensibility. We test HDNO on MultiWoz 2.0 and MultiWoz 2.1, the datasets on multi-domain dialogues, in comparison with word-level E2E model trained with RL, LaRL and HDSA, showing improvements on the performance evaluated by automatic evaluation metrics and human evaluation. Finally, we demonstrate the semantic meanings of latent dialogue acts to show the ability of explanation.",タスク指向の対話システムの設計は、ユーザーの要求を満たす発話を生成するだけでなく、理解しやすさを保証する必要があるため、挑戦的な研究トピックです。以前の多くの作品は、教師あり学習（SL）を使用してエンドツーエンド（E2E）モデルをトレーニングしましたが、注釈付きシステムの発話のバイアスはボトルネックのままです。強化学習（RL）は、差別化できない評価指標（成功率など）を報酬として使用することで問題に対処します。それにもかかわらず、RLを使用した既存の作業では、ユーザーの要求を満たすパフォーマンスを向上させると、生成されたシステム発話の理解度が損なわれる可能性があることが示されました。私たちの仕事では、（1）特定の対話行為表現の設計を回避するために潜在的な対話行為が適用されるHDNOと呼ばれるオプションフレームワークを使用して、対話ポリシーと自然言語ジェネレーター（NLG）の間の階層構造をモデル化することを提案します。 （2）階層的強化学習（HRL）を介してHDNOをトレーニングし、トレーニング中にダイアログポリシーとNLGの間の非同期更新を提案して、ローカルマキシマイザーへの収束を理論的に保証します。 （3）理解しやすさをさらに向上させるための追加の報酬として、言語モデルでモデル化された弁別子を使用することを提案します。マルチドメインダイアログのデータセットであるMultiWoz2.0およびMultiWoz2.1でHDNOをテストし、RL、LaRL、およびHDSAでトレーニングされた単語レベルのE2Eモデルと比較して、自動評価メトリックと人間による評価によって評価されたパフォーマンスの改善を示します。最後に、説明の能力を示すための潜在的な対話行為の意味的意味を示します。,6.25,https://d3i71xaburhd42.cloudfront.net/cf4ce485d4971b17c8733188da65065d153a68a5/4-Figure1-1.png
Learning perturbation sets for robust machine learning,"['Eric Wong', 'J Zico Kolter']",https://openreview.net/forum?id=MIDckA56aD,"Although much progress has been made towards robust deep learning, a significant gap in robustness remains between real-world perturbations and more narrowly defined sets typically studied in adversarial defenses. In this paper, we aim to bridge this gap by learning perturbation sets from data, in order to characterize real-world effects for robust training and evaluation. Specifically, we use a conditional generator that defines the perturbation set over a constrained region of the latent space. We formulate desirable properties that measure the quality of a learned perturbation set, and theoretically prove that a conditional variational autoencoder naturally satisfies these criteria. Using this framework, our approach can generate a variety of perturbations at different complexities and scales, ranging from baseline spatial transformations, through common image corruptions, to lighting variations. We measure the quality of our learned perturbation sets both quantitatively and qualitatively, finding that our models are capable of producing a diverse set of meaningful perturbations beyond the limited data seen during training. Finally, we leverage our learned perturbation sets to train models which are empirically and certifiably robust to adversarial image corruptions and adversarial lighting variations, while improving generalization on non-adversarial data. All code and configuration files for reproducing the experiments as well as pretrained model weights can be found in the supplementary material. ",堅牢な深層学習に向けて多くの進歩が見られましたが、現実世界の摂動と、敵対的な防御で通常研究されるより狭く定義されたセットとの間には、堅牢性に大きなギャップが残っています。このホワイトペーパーでは、データから摂動セットを学習することでこのギャップを埋め、堅牢なトレーニングと評価のために実際の効果を特徴付けることを目指しています。具体的には、潜在空間の制約された領域に設定された摂動を定義する条件付きジェネレーターを使用します。学習した摂動セットの品質を測定する望ましいプロパティを定式化し、条件付き変分オートエンコーダがこれらの基準を自然に満たすことを理論的に証明します。このフレームワークを使用して、私たちのアプローチは、ベースラインの空間変換から、一般的な画像の破損、照明の変化に至るまで、さまざまな複雑さとスケールでさまざまな摂動を生成できます。学習した摂動セットの品質を定量的および定性的に測定し、トレーニング中に見られる限られたデータを超えて、モデルが意味のある摂動の多様なセットを生成できることを発見しました。最後に、学習した摂動セットを活用して、敵対的な画像の破損や敵対的な照明の変動に対して経験的かつ確実に堅牢なモデルをトレーニングすると同時に、非敵対的なデータの一般化を改善します。実験を再現するためのすべてのコードと構成ファイル、および事前にトレーニングされたモデルの重みは、補足資料にあります。,6.25,https://d3i71xaburhd42.cloudfront.net/9b961159782b12b86e63acc76e2e0461a97a4f05/7-Figure1-1.png
DeLighT: Deep and Light-weight Transformer,"['Sachin Mehta', 'Marjan Ghazvininejad', 'Srinivasan Iyer', 'Luke Zettlemoyer', 'Hannaneh Hajishirzi']",https://openreview.net/forum?id=ujmgfuxSLrO,"We introduce a deep and light-weight transformer, DeLighT, that delivers similar or better performance than standard transformer-based models with significantly fewer parameters. DeLighT more efficiently allocates parameters both (1) within each Transformer block using the DeLighT transformation, a deep and light-weight transformation and (2) across blocks using block-wise scaling, that allows for shallower and narrower DeLighT blocks near the input and wider and deeper DeLighT blocks near the output. Overall, DeLighT networks are 2.5 to 4 times deeper than standard transformer models and yet have fewer parameters and operations. Experiments on benchmark machine translation and language modeling tasks show that DeLighT matches or improves the performance of baseline Transformers with 2 to 3 times fewer parameters on average. ",深くて軽量なトランスDeLighTを紹介します。これは、パラメーターが大幅に少ない標準のトランスベースモデルと同等またはそれ以上のパフォーマンスを提供します。 DeLighTは、（1）DeLighT変換を使用した各Transformerブロック内、深くて軽量な変換、および（2）ブロック単位のスケーリングを使用したブロック間で、パラメーターをより効率的に割り当てます。出力の近くのより深いDeLighTブロック。全体として、DeLighTネットワークは、標準のトランスモデルよりも2.5〜4倍深くなっていますが、パラメーターと操作は少なくなっています。ベンチマーク機械翻訳および言語モデリングタスクの実験では、DeLighTは、平均して2〜3倍少ないパラメーターで、ベースライントランスフォーマーのパフォーマンスと一致または改善することが示されています。,6.25,
CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning,"['Ossama Ahmed', 'Frederik Träuble', 'Anirudh Goyal', 'Alexander Neitz', 'Manuel Wuthrich', 'Yoshua Bengio', 'Bernhard Schölkopf', 'Stefan Bauer']",https://openreview.net/forum?id=SK7A5pdrgov,"Despite recent successes of reinforcement learning (RL), it remains a challenge for agents to transfer learned skills to related environments. To facilitate research addressing this, we propose CausalWorld, a benchmark for causal structure and transfer learning in a robotic manipulation environment. The environment is a simulation of an open-source robotic platform, hence offering the possibility of sim-to-real transfer.  Tasks consist of constructing 3D shapes from a given set of blocks - inspired by how children learn to build complex structures.  The key  strength of CausalWorld is that it provides a combinatorial family of such tasks with  common causal structure and underlying factors (including, e.g., robot and object masses, colors, sizes). The user (or the agent) may intervene on all causal variables, which allows for fine-grained control over how similar different  tasks (or task distributions) are. One can thus easily define training and evaluation distributions of a desired difficulty level, targeting a specific form of generalization (e.g., only changes in appearance or object mass).  Further, this common parametrization facilitates defining curricula by interpolating between an initial and a target task. While users may define their own task distributions, we present eight meaningful distributions as concrete benchmarks, ranging from simple to very challenging, all of which require long-horizon planning and precise low-level motor control at the same time. Finally, we provide baseline results for a subset of these tasks on distinct training curricula and corresponding evaluation protocols, verifying the feasibility of the tasks in this benchmark.",強化学習（RL）の最近の成功にもかかわらず、エージェントが学習したスキルを関連する環境に転送することは依然として課題です。これに対処する研究を容易にするために、我々は、ロボット操作環境における因果構造と転移学習のベンチマークであるCausalWorldを提案します。この環境は、オープンソースのロボットプラットフォームのシミュレーションであるため、simからrealへの転送の可能性を提供します。タスクは、特定のブロックのセットから3D形状を構築することで構成されます。これは、子供たちが複雑な構造を構築する方法を学ぶ方法に触発されたものです。 CausalWorldの主な強みは、そのようなタスクの組み合わせファミリーに、共通の因果構造と基礎となる要因（たとえば、ロボットとオブジェクトの質量、色、サイズなど）を提供することです。ユーザー（またはエージェント）は、すべての因果変数に介入できます。これにより、さまざまなタスク（またはタスク分布）がどの程度類似しているかをきめ細かく制御できます。したがって、特定の形式の一般化（たとえば、外観またはオブジェクトの質量の変化のみ）を対象として、目的の難易度のトレーニングおよび評価分布を簡単に定義できます。さらに、この一般的なパラメータ化により、初期タスクとターゲットタスクの間を補間することでカリキュラムの定義が容易になります。ユーザーは独自のタスク分布を定義できますが、具体的なベンチマークとして8つの意味のある分布を示します。これらは単純なものから非常に難しいものまであり、すべて同時に長期計画と正確な低レベルのモーター制御が必要です。最後に、個別のトレーニングカリキュラムと対応する評価プロトコルでこれらのタスクのサブセットのベースライン結果を提供し、このベンチマークでのタスクの実現可能性を検証します。,6.25,
Theoretical bounds on estimation error for meta-learning,"['James Lucas', 'Mengye Ren', 'Irene Raissa KAMENI KAMENI', 'Toniann Pitassi', 'Richard Zemel']",https://openreview.net/forum?id=SZ3wtsXfzQR,"Machine learning models have traditionally been developed under the assumption that the training and test distributions match exactly. However, recent success in few-shot learning and related problems are encouraging signs that these models can be adapted to more realistic settings where train and test distributions differ. Unfortunately, there is severely limited theoretical support for these algorithms and little is known about the difficulty of these problems. In this work, we provide novel information-theoretic lower-bounds on minimax rates of convergence for algorithms that are trained on data from multiple sources and tested on novel data. Our bounds depend intuitively on the information shared between sources of data, and characterize the difficulty of learning in this setting for arbitrary algorithms. We demonstrate these bounds on a hierarchical Bayesian model of meta-learning, computing both upper and lower bounds on parameter estimation via maximum-a-posteriori inference.",機械学習モデルは、従来、トレーニングとテストの分布が完全に一致することを前提として開発されてきました。ただし、数ショットの学習および関連する問題での最近の成功は、これらのモデルをトレーニングとテストの分布が異なるより現実的な設定に適合させることができるという有望な兆候です。残念ながら、これらのアルゴリズムの理論的サポートは厳しく制限されており、これらの問題の難しさについてはほとんど知られていません。この作業では、複数のソースからのデータでトレーニングされ、新しいデータでテストされたアルゴリズムの最小収束率に関する新しい情報理論的な下限を提供します。私たちの限界は、データのソース間で共有される情報に直感的に依存し、任意のアルゴリズムのこの設定での学習の難しさを特徴づけます。メタ学習の階層ベイズモデルでこれらの境界を示し、最大事後推論によるパラメーター推定の上限と下限の両方を計算します。,6.25,
AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition,"['Yue Meng', 'Rameswar Panda', 'Chung-Ching Lin', 'Prasanna Sattigeri', 'Leonid Karlinsky', 'Kate Saenko', 'Aude Oliva', 'Rogerio Feris']",https://openreview.net/forum?id=bM3L3I_853,"Temporal modelling is the key for efficient video action recognition. While understanding temporal information can improve recognition accuracy for dynamic actions, removing temporal redundancy and reusing past features can significantly save computation leading to efficient action recognition. In this paper, we introduce an adaptive temporal fusion network, called AdaFuse, that dynamically fuses channels from current and past feature maps for strong temporal modelling. Specifically, the necessary information from the historical convolution feature maps is fused with current pruned feature maps with the goal of improving both recognition accuracy and efficiency. In addition, we use a skipping operation to further reduce the computation cost of action recognition. Extensive experiments on SomethingV1\&V2, Jester and Mini-Kinetics show that our approach can achieve about 40\% computation savings with comparable accuracy to state-of-the-art methods.",時間モデリングは、効率的なビデオアクション認識の鍵です。時間情報を理解することで動的アクションの認識精度を向上させることができますが、時間的冗長性を取り除き、過去の機能を再利用することで計算を大幅に節約でき、効率的なアクション認識につながります。この論文では、AdaFuseと呼ばれる適応型時間融合ネットワークを紹介します。これは、強力な時間モデリングのために、現在および過去の特徴マップからチャネルを動的に融合します。具体的には、過去の畳み込み特徴マップからの必要な情報が、認識の精度と効率の両方を向上させることを目的として、現在の剪定された特徴マップと融合されます。さらに、スキップ操作を使用して、アクション認識の計算コストをさらに削減します。 SomethingV1＆V2、Jester、およびMini-Kineticsに関する広範な実験により、私たちのアプローチは、最先端の方法に匹敵する精度で約40％の計算の節約を達成できることが示されています。,6.25,
Monotonic Kronecker-Factored Lattice,"['William Taylor Bakst', 'Nobuyuki Morioka', 'Erez Louidor']",https://openreview.net/forum?id=0pxiMpCyBtr,"It is computationally challenging to learn flexible monotonic functions that guarantee model behavior and provide interpretability beyond a few input features, and in a time where minimizing resource use is increasingly important, we must be able to learn such models that are still efficient. In this paper we show how to effectively and efficiently learn such functions using Kronecker-Factored Lattice ($\mathrm{KFL}$), an efficient reparameterization of flexible monotonic lattice regression via Kronecker product. Both computational and storage costs scale linearly in the number of input features, which is a significant improvement over existing methods that grow exponentially. We also show that we can still properly enforce monotonicity and other shape constraints. The $\mathrm{KFL}$ function class consists of products of piecewise-linear functions, and the size of the function class can be further increased through ensembling. We prove that the function class of an ensemble of $M$ base $\mathrm{KFL}$ models strictly increases as $M$ increases up to a certain threshold. Beyond this threshold, every multilinear interpolated lattice function can be expressed. Our experimental results demonstrate that $\mathrm{KFL}$ trains faster with fewer parameters while still achieving accuracy and evaluation speeds comparable to or better than the baseline methods and preserving monotonicity guarantees on the learned model.",モデルの動作を保証し、いくつかの入力機能を超えて解釈可能性を提供する柔軟な単調関数を学習することは計算上困難であり、リソースの使用を最小限に抑えることがますます重要になっている時代に、依然として効率的なモデルを学習できなければなりません。この論文では、クロネッカー積を介した柔軟な単調格子回帰の効率的な再パラメーター化であるクロネッカー因数分解格子（KFL）を使用して、このような関数を効果的かつ効率的に学習する方法を示します。計算コストとストレージコストはどちらも、入力フィーチャの数に比例して増加します。これは、指数関数的に増加する既存の方法に比べて大幅に改善されています。また、単調性やその他の形状の制約を適切に適用できることも示しています。 KFL関数クラスは区分的線形関数の積で構成されており、関数クラスのサイズはアンサンブルによってさらに大きくすることができます。 Mが特定のしきい値まで増加すると、MベースKFLモデルのアンサンブルの関数クラスが厳密に増加することを証明します。このしきい値を超えると、すべての多重線形補間格子関数を表現できます。私たちの実験結果は、KFLがより少ないパラメーターでより速くトレーニングし、ベースライン方法と同等またはそれ以上の精度と評価速度を達成し、学習したモデルで単調性の保証を維持することを示しています。,6.25,
AdaGCN: Adaboosting Graph Convolutional Networks into Deep Models,"['Ke Sun', 'Zhouchen Lin', 'Zhanxing Zhu']",https://openreview.net/forum?id=QkRbdiiEjM,"The design of deep graph models still remains to be investigated and the crucial part is how to explore and exploit the knowledge from different hops of neighbors in an efficient way. In this paper, we propose a novel RNN-like deep graph neural network architecture by incorporating AdaBoost into the computation of network; and the proposed graph convolutional network called AdaGCN~(Adaboosting Graph Convolutional Network) has the ability to efficiently extract knowledge from high-order neighbors of current nodes and then integrates knowledge from different hops of neighbors into the network in an Adaboost way. Different from other graph neural networks that directly stack many graph convolution layers, AdaGCN shares the same base neural network architecture among all ``layers'' and is recursively optimized, which is similar to a RNN. Besides, We also theoretically established the connection between AdaGCN and existing graph convolutional methods, presenting the benefits of our proposal. Finally, extensive experiments demonstrate the consistent state-of-the-art prediction performance on graphs across different label rates and the computational advantage of our approach AdaGCN.",深いグラフモデルの設計はまだ調査されておらず、重要な部分は、効率的な方法で近隣のさまざまなホップからの知識を探索して活用する方法です。この論文では、ネットワークの計算にAdaBoostを組み込むことにより、新しいRNNのようなディープグラフニューラルネットワークアーキテクチャを提案します。また、提案されているAdaGCN（Adaboosting Graph Convolutional Network）と呼ばれるグラフ畳み込みネットワークには、現在のノードの高次の隣接ノードから知識を効率的に抽出し、隣接するさまざまなホップからの知識をAdaboost方式でネットワークに統合する機能があります。多くのグラフ畳み込み層を直接スタックする他のグラフニューラルネットワークとは異なり、AdaGCNはすべての層間で同じ基本ニューラルネットワークアーキテクチャを共有し、RNNと同様に再帰的に最適化されます。さらに、理論的にはAdaGCNと既存のグラフ畳み込み法との関係を確立し、提案の利点を示しました。最後に、広範な実験により、さまざまなラベルレートにわたるグラフでの一貫した最先端の予測パフォーマンスと、AdaGCNアプローチの計算上の利点が実証されています。,6.25,https://d3i71xaburhd42.cloudfront.net/6c6c265c6d1de08f03fed0da0604bef5307fbcec/3-Figure1-1.png
DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION,"['Pengcheng He', 'Xiaodong Liu', 'Jianfeng Gao', 'Weizhu Chen']",https://openreview.net/forum?id=XPZIaotutsD,"Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks. In this paper we propose a new model architecture \textbf{DeBERTa} (\textbf{D}ecoding-\textbf{e}nhanced \textbf{BERT} with disentangled \textbf{a}ttention) that improves the BERT and RoBERTa models using two novel techniques. The first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively, and the attention weights among words are computed using disentangled matrices on their contents and relative positions. Second, an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre-training. We show that these two techniques significantly improve the efficiency of model pre-training and performance of downstream tasks. Compared to RoBERTa-Large, a DeBERTa model  trained on half of the training data performs consistently better on a wide range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%), on SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%). The DeBERTa code and pre-trained models will be made publicly available. ",事前にトレーニングされた神経言語モデルの最近の進歩により、多くの自然言語処理（NLP）タスクのパフォーマンスが大幅に向上しました。この論文では、2つの新しい技術を使用してBERTモデルとRoBERTaモデルを改善する新しいモデルアーキテクチャDEBERTA（注意を解きほぐしたデコード強化BERT）を提案します。 1つ目は、解きほぐされた注意メカニズムです。各単語は、その内容と位置をそれぞれエンコードする2つのベクトルを使用して表され、単語間の注意の重みは、内容と相対位置の解きほぐされた行列を使用して計算されます。次に、強化されたマスクデコーダーを使用して、デコードレイヤーに絶対位置を組み込み、モデルの事前トレーニングでマスクされたトークンを予測します。これらの2つの手法により、モデルの事前トレーニングの効率とダウンストリームタスクのパフォーマンスが大幅に向上することを示します。 RoBERTa-Largeと比較して、トレーニングデータの半分でトレーニングされたDeBERTaモデルは、幅広いNLPタスクで一貫して優れたパフォーマンスを発揮し、MNLIを+0.9改善します。,6.25,https://d3i71xaburhd42.cloudfront.net/8193a34ae2929240fe9818d1906341e37633b227/7-Figure1-1.png
MARS: Markov Molecular Sampling for Multi-objective Drug Discovery,"['Yutong Xie', 'Chence Shi', 'Hao Zhou', 'Yuwei Yang', 'Weinan Zhang', 'Yong Yu', 'Lei Li']",https://openreview.net/forum?id=kHSu4ebxFXY,"Searching for novel molecules with desired chemical properties is crucial in drug discovery.  Existing work focuses on developing deep generative models to generate either sequences or chemical molecular graphs. However, it remains a great challenge to find novel and diverse compounds satisfying many properties. In this paper, we propose MARS, a method for multi-objective drug molecule discovery. MARS is based on the idea of generating the chemical candidates by iterative editing fragments of molecular graphs. To search for the best candidates, it employs an annealing scheme together with Markov chain Monte Carlo sampling (MCMC) on molecules. To further improve sample efficiency, MARS is equipped with a graph neural network (GNN) as the proposal for candidate edits on molecules, while the GNN is trained on-the-fly utilizing the sample paths in MCMC. Our experiments show that MARS achieves state-of-the-art performance in various multi-objective settings where molecular bio-activity, drug-likeness, and synthesizability are simultaneously considered.  In the most challenging setting where four objectives – bio-activities to two different targets, drug-likeness and synthesizability – are simultaneously  considered,  our  method  outperforms  the  state-of-the-art  significantly in a comprehensive evaluation.",創薬では、目的の化学的性質を持つ新規分子を探すことが重要です。既存の作業は、シーケンスまたは化学分子グラフのいずれかを生成するための深い生成モデルの開発に焦点を合わせています。しかし、多くの特性を満たす新規で多様な化合物を見つけることは依然として大きな課題です。本論文では、多目的薬物分子発見の手法であるMARSを提案する。 MARSは、分子グラフのフラグメントを繰り返し編集することによって化学候補を生成するというアイデアに基づいています。最適な候補を検索するために、分子のマルコフ連鎖モンテカルロサンプリング（MCMC）とともにアニーリングスキームを採用しています。サンプル効率をさらに向上させるために、MARSには分子の候補編集の提案としてグラフニューラルネットワーク（GNN）が装備されており、GNNはMCMCのサンプルパスを利用してオンザフライでトレーニングされます。私たちの実験は、MARSが、分子の生物活性、ドラッグライクネス、および合成可能性が同時に考慮されるさまざまな多目的設定で最先端のパフォーマンスを達成することを示しています。 2つの異なるターゲットに対する4つの目的の生物活性、ドラッグライクネスと合成可能性が同時に考慮される最も困難な設定では、私たちの方法は、包括的な評価において最先端技術を大幅に上回ります。,6.25,
SSD: A Unified Framework for Self-Supervised Outlier Detection,"['Vikash Sehwag', 'Mung Chiang', 'Prateek Mittal']",https://openreview.net/forum?id=v5gjXpmR8J,"We ask the following question: what training information is required to design an effective outlier / out-of-distribution (OOD) detector, i.e, detecting samples that lie far away from training distribution? Since unlabeled data is easily accessible for many applications, the most compelling approach is to develop detectors based on only unlabeled in-distribution data. However, we observe that existing detectors based on unlabeled data perform poorly, often equivalent to a random prediction. In contrast, existing state-of-the-art OOD detectors achieve impressive performance but require access to fine-grained data labels for supervised training. We propose SSD, an outlier detector based on only unlabeled training data. We use self-supervised representation learning followed by a Mahalanobis distance based detection in the feature space. We demonstrate that SSD outperforms existing detectors based on unlabeled data by a large margin. Additionally, SSD achieves performance on par, and sometimes even better, with supervised training based detectors.  Finally, we expand our detection framework with two key extensions. First, we formulate few-shot OOD detection, in which the detector has access to only one to five samples from the targeted OOD dataset. Second, we extend our framework to incorporate training data labels, if available. We find that our novel detection framework based on SSD displays enhanced performance with these extensions, and achieves state-of-the-art performance.",次の質問をします。効果的な外れ値/分布外（OOD）検出器を設計するために、つまりトレーニング分布から遠く離れたサンプルを検出するために必要なトレーニング情報は何ですか？ラベルのないデータは多くのアプリケーションで簡単にアクセスできるため、最も説得力のあるアプローチは、ラベルのない分布データのみに基づいて検出器を開発することです。ただし、ラベルのないデータに基づく既存の検出器のパフォーマンスは低く、ランダムな予測と同等であることがよくあります。対照的に、既存の最先端のOOD検出器は優れたパフォーマンスを実現しますが、教師ありトレーニングのためにきめ細かいデータラベルにアクセスする必要があります。ラベルのないトレーニングデータのみに基づく外れ値検出器であるSSDを提案します。自己教師あり表現学習と、それに続く特徴空間でのマハラノビス距離ベースの検出を使用します。 SSDは、ラベルのないデータに基づく既存の検出器よりも大幅に優れていることを示しています。さらに、SSDは、教師ありトレーニングベースの検出器を使用して、同等のパフォーマンスを実現し、場合によってはさらに優れたパフォーマンスを実現します。最後に、2つの主要な拡張機能を使用して検出フレームワークを拡張します。まず、数ショットのOOD検出を定式化します。この検出では、ターゲットのOODデータセットから1〜5個のサンプルにしかアクセスできません。次に、フレームワークを拡張して、可能な場合はトレーニングデータラベルを組み込みます。 SSDに基づく新しい検出フレームワークは、これらの拡張機能によってパフォーマンスが向上し、最先端のパフォーマンスを実現していることがわかりました。,6.25,
Understanding the failure modes of out-of-distribution generalization,"['Vaishnavh Nagarajan', 'Anders Andreassen', 'Behnam Neyshabur']",https://openreview.net/forum?id=fSTD6NFIW_b,"Empirical studies suggest that machine learning models often rely on features, such as the background, that may be spuriously correlated with the label only during training time, resulting in poor accuracy during test-time. In this work, we identify the fundamental factors that give rise to this behavior, by explaining why models fail this way even in easy-to-learn tasks where one would expect these models to succeed. In particular, through a theoretical study of gradient-descent-trained linear classifiers on some easy-to-learn tasks, we uncover two complementary failure modes. These modes arise from how spurious correlations induce two kinds of skews in the data: one geometric in nature and another, statistical. Finally, we construct natural modifications of image classification datasets to understand when these failure modes can arise in practice. We also design experiments to isolate the two failure modes when training modern neural networks on these datasets.",経験的研究によると、機械学習モデルは、背景などの特徴に依存していることが多く、トレーニング時間中にのみラベルと誤って相関している可能性があり、テスト時間中の精度が低くなります。この作業では、これらのモデルが成功すると予想される学習しやすいタスクでもモデルがこのように失敗する理由を説明することにより、この動作を引き起こす基本的な要因を特定します。特に、いくつかの習得しやすいタスクに関する勾配降下法でトレーニングされた線形分類器の理論的研究を通じて、2つの補完的な故障モードを明らかにします。これらのモードは、疑似相関がデータに2種類のスキューを引き起こす方法から生じます。1つは本質的に幾何学的で、もう1つは統計的です。最後に、画像分類データセットの自然な変更を構築して、これらの障害モードが実際にいつ発生するかを理解します。また、これらのデータセットで最新のニューラルネットワークをトレーニングするときに、2つの障害モードを分離する実験を設計します。,6.25,https://d3i71xaburhd42.cloudfront.net/1b4a54670bb4fe15bcb0d06de0391d5b6d10ace2/2-Figure1-1.png
Bag of Tricks for Adversarial Training,"['Tianyu Pang', 'Xiao Yang', 'Yinpeng Dong', 'Hang Su', 'Jun Zhu']",https://openreview.net/forum?id=Xb8xvrtB8Ce,"Adversarial training (AT) is one of the most effective strategies for promoting model robustness. However, recent benchmarks show that most of the proposed improvements on AT are less effective than simply early stopping the training procedure. This counter-intuitive fact motivates us to investigate the implementation details of tens of AT methods. Surprisingly, we find that the basic settings (e.g., weight decay, training schedule, etc.) used in these methods are highly inconsistent. In this work, we provide comprehensive evaluations on CIFAR-10, focusing on the effects of mostly overlooked training tricks and hyperparameters for adversarially trained models. Our empirical observations suggest that adversarial robustness is much more sensitive to some basic training settings than we thought. For example, a slightly different value of weight decay can reduce the model robust accuracy by more than $7\%$, which is probable to override the potential promotion induced by the proposed methods. We conclude a baseline training setting and re-implement previous defenses to achieve new state-of-the-art results. These facts also appeal to more concerns on the overlooked confounders when benchmarking defenses.",敵対的トレーニング（AT）は、モデルの堅牢性を促進するための最も効果的な戦略の1つです。ただし、最近のベンチマークでは、ATで提案されている改善のほとんどは、トレーニング手順を早期に停止するよりも効果が低いことが示されています。この直感に反する事実により、数十のATメソッドの実装の詳細を調査するようになりました。驚いたことに、これらの方法で使用される基本設定（たとえば、体重減少、トレーニングスケジュールなど）は非常に一貫性がないことがわかりました。この作業では、CIFAR-10の包括的な評価を提供し、敵対的にトレーニングされたモデルのほとんど見過ごされているトレーニングトリックとハイパーパラメータの影響に焦点を当てます。私たちの経験的観察は、敵対的な頑健性が私たちが思っていたよりもいくつかの基本的な訓練設定にはるかに敏感であることを示唆しています。たとえば、重み減衰の値がわずかに異なると、モデルのロバスト精度が7％以上低下する可能性があります。これは、提案された方法によって引き起こされる潜在的な促進を無効にする可能性があります。ベースライントレーニング設定を終了し、以前の防御を再実装して、新しい最先端の結果を達成します。これらの事実は、防御のベンチマークを行う際に見落とされている交絡因子に関するより多くの懸念にも訴えます。,6.25,https://d3i71xaburhd42.cloudfront.net/f1209119572225d3bf3ec0e4f277fa4fcd187b8c/5-Figure1-1.png
Network Pruning That Matters:  A Case Study on Retraining Variants,"['Duong Hoang Le', 'Binh-Son Hua']",https://openreview.net/forum?id=Cb54AMqHQFP,"Network pruning is an effective method to reduce the computational expense of over-parameterized neural networks for deployment on low-resource systems. Recent state-of-the-art techniques for retraining pruned networks such as weight rewinding and learning rate rewinding have been shown to outperform the traditional fine-tuning technique in recovering the lost accuracy (Renda et al., 2020), but so far it is unclear what accounts for such performance. In this work, we conduct extensive experiments to verify and analyze the uncanny effectiveness of learning rate rewinding. We find that the reason behind the success of learning rate rewinding is the usage of a large learning rate. Similar phenomenon can be observed in other learning rate schedules that involve large learning rates, e.g., the 1-cycle learning rate schedule (Smith et al., 2019). By leveraging the right learning rate schedule in retraining, we demonstrate a counter-intuitive phenomenon in that randomly pruned networks could even achieve better performance than methodically pruned networks (fine-tuned with the conventional approach). Our results emphasize the cruciality of the learning rate schedule in pruned network retraining - a detail often overlooked by practitioners during the implementation of network pruning. ",ネットワークプルーニングは、低リソースシステムに展開するためのパラメーターが多すぎるニューラルネットワークの計算コストを削減するための効果的な方法です。重みの巻き戻しや学習率の巻き戻しなど、剪定されたネットワークを再トレーニングするための最近の最先端技術は、失われた精度を回復する際に従来の微調整技術よりも優れていることが示されています（Renda et al。、2020）が、これまでのところ何がそのようなパフォーマンスを説明するのかは不明です。この作業では、学習率の巻き戻しの驚くべき効果を検証および分析するために、広範な実験を実施します。学習率の巻き戻しが成功した理由は、大きな学習率の使用にあることがわかりました。同様の現象は、大きな学習率を伴う他の学習率スケジュール、たとえば1サイクルの学習率スケジュールでも観察できます（Smith et al。、2019）。再トレーニングで適切な学習率スケジュールを活用することにより、ランダムにプルーニングされたネットワークが、系統的にプルーニングされたネットワークよりも優れたパフォーマンスを達成できるという直感に反する現象を示します（従来のアプローチで微調整）。私たちの結果は、剪定されたネットワークの再トレーニングにおける学習率スケジュールの重要性を強調しています。これは、ネットワークの剪定の実装中に実践者が見落としがちな詳細です。,6.25,
Generative Time-series Modeling with Fourier Flows,"['Ahmed Alaa', 'Alex James Chan', 'Mihaela van der Schaar']",https://openreview.net/forum?id=PpshD0AXfA,"Generating synthetic time-series data is crucial in various application domains, such as medical prognosis, wherein research is hamstrung by the lack of access to data due to concerns over privacy. Most of the recently proposed methods for generating synthetic time-series rely on implicit likelihood modeling using generative adversarial networks (GANs)—but such models can be difficult to train, and may jeopardize privacy by “memorizing” temporal patterns in training data. In this paper, we propose an explicit likelihood model based on a novel class of normalizing flows that view time-series data in the frequency-domain rather than the time-domain. The proposed flow, dubbed a Fourier flow, uses a discrete Fourier transform (DFT) to convert variable-length time-series with arbitrary sampling periods into fixed-length spectral representations, then applies a (data-dependent) spectral filter to the frequency-transformed time-series. We show that, by virtue of the DFT analytic properties, the Jacobian determinants and inverse mapping for the Fourier flow can be computed efficiently in linearithmic time, without imposing explicit structural constraints as in existing flows such as NICE (Dinh et al. (2014)), RealNVP (Dinh et al. (2016)) and GLOW (Kingma & Dhariwal (2018)). Experiments show that Fourier flows perform competitively compared to state-of-the-art baselines.",合成時系列データの生成は、医療予後などのさまざまなアプリケーションドメインで重要です。医療予後では、プライバシーへの懸念からデータへのアクセスが不足しているため、研究が妨げられています。合成時系列を生成するために最近提案された方法のほとんどは、生成的敵対的ネットワーク（GAN）を使用した暗黙の尤度モデリングに依存していますが、そのようなモデルはトレーニングが困難な場合があり、トレーニングデータの時間的パターンを記憶することによってプライバシーを危険にさらす可能性があります。この論文では、時系列データを時間領域ではなく周波数領域で表示する新しいクラスの正規化フローに基づく明示的な尤度モデルを提案します。提案されたフローは、フーリエフローと呼ばれ、離散フーリエ変換（DFT）を使用して、任意のサンプリング周期を持つ可変長時系列を固定長スペクトル表現に変換し、（データ依存の）スペクトルフィルターを周波数に適用します。変換された時系列。 DFT分析特性により、NICEなどの既存のフローのように明示的な構造制約を課すことなく、フーリエフローのヤコビ行列式と逆マッピングを線形時間で効率的に計算できることを示します（Dinh et al。（2014） ）、RealNVP（Dinh et al。（2016））およびGLOW（Kingma＆Dhariwal（2018））。実験は、フーリエフローが最先端のベースラインと比較して競争力があることを示しています。,6.25,
ANOCE: Analysis of Causal Effects with Multiple Mediators via Constrained Structural Learning,"['Hengrui Cai', 'Rui Song', 'Wenbin Lu']",https://openreview.net/forum?id=7I12hXRi8F,"In the era of causal revolution, identifying the causal effect of an exposure on the outcome of interest is an important problem in many areas, such as epidemics, medicine, genetics, and economics. Under a general causal graph, the exposure may have a direct effect on the outcome and also an indirect effect regulated by a set of mediators. An analysis of causal effects that interprets the causal mechanism contributed through mediators is hence challenging but on demand. To the best of our knowledge, there are no feasible algorithms that give an exact decomposition of the indirect effect on the level of individual mediators, due to common interaction among mediators in the complex graph. In this paper, we establish a new statistical framework to comprehensively characterize causal effects with multiple mediators, namely, ANalysis Of Causal Effects (ANOCE), with a newly introduced definition of the mediator effect, under the linear structure equation model. We further propose a constrained causal structure learning method by incorporating a novel identification constraint that specifies the temporal causal relationship of variables. The proposed algorithm is applied to investigate the causal effects of 2020 Hubei lockdowns on reducing the spread of the coronavirus in Chinese major cities out of Hubei. ",因果関係革命の時代において、関心のある結果に対する曝露の因果関係を特定することは、エピデミック、医学、遺伝学、経済学などの多くの分野で重要な問題です。一般的な因果関係のグラフでは、曝露は結果に直接的な影響を与える可能性があり、また一連のメディエーターによって規制される間接的な影響も与える可能性があります。したがって、メディエーターを介して提供される因果メカニズムを解釈する因果効果の分析は困難ですが、要求に応じて行われます。私たちの知る限り、複雑なグラフ内のメディエーター間の共通の相互作用のために、個々のメディエーターのレベルに対する間接的な影響を正確に分解する実行可能なアルゴリズムはありません。本論文では、線形構造方程式モデルの下で、新たに導入されたメディエーター効果の定義を用いて、複数のメディエーターによる因果効果を包括的に特徴づける新しい統計的枠組み、すなわち、因果効果の分析（ANOCE）を確立する。さらに、変数の時間的因果関係を指定する新しい識別制約を組み込むことにより、制約付き因果構造学習方法を提案します。提案されたアルゴリズムは、湖北省外の中国の主要都市におけるコロナウイルスの拡散を減らす上での2020年湖北省封鎖の因果関係を調査するために適用されます。,6.25,
Acting in Delayed Environments with Non-Stationary Markov Policies,"['Gal Dalal', 'Esther Derman', 'Shie Mannor']",https://openreview.net/forum?id=j1RMMKeP2gR,"The standard Markov Decision Process (MDP) formulation hinges on the assumption that an action is executed immediately after it was chosen. However, assuming it is often unrealistic and can lead to catastrophic failures in applications such as robotic manipulation, cloud computing, and finance. We introduce a framework for learning and planning in MDPs where the decision-maker commits actions that are executed with a delay of $m$ steps. The brute-force state augmentation baseline where the state is concatenated to the last $m$ committed actions suffers from an exponential complexity in $m$, as we show for policy iteration. We then prove that with execution delay, Markov policies in the original state-space are sufficient for attaining maximal reward, but need to be non-stationary. As for stationary Markov policies, we show they are sub-optimal in general. Consequently, we devise a non-stationary Q-learning style model-based algorithm that solves delayed execution tasks without resorting to state-augmentation. Experiments on tabular, physical, and Atari domains reveal that it converges quickly to high performance even for substantial delays, while standard approaches that either ignore the delay or rely on state-augmentation struggle or fail due to divergence. The code will be shared upon publication.",標準のマルコフ決定過程（MDP）の定式化は、アクションが選択された直後に実行されるという仮定に基づいています。ただし、それが非現実的であることが多く、ロボット操作、クラウドコンピューティング、財務などのアプリケーションで壊滅的な障害が発生する可能性があると想定します。意思決定者がmステップの遅延で実行されるアクションをコミットするMDPでの学習と計画のためのフレームワークを紹介します。ポリシーの反復で示すように、状態が最後のm個のコミットされたアクションに連結されるブルートフォース状態拡張ベースラインは、mの指数関数的な複雑さに悩まされます。次に、実行の遅延により、元の状態空間のマルコフポリシーが最大の報酬を達成するのに十分であるが、非定常である必要があることを証明します。定常マルコフ政策に関しては、一般的に最適ではないことを示しています。したがって、状態の拡張に頼ることなく、遅延実行タスクを解決する非定常Q学習スタイルのモデルベースのアルゴリズムを考案します。表形式、物理ドメイン、およびAtariドメインでの実験では、大幅な遅延があってもすぐに高性能に収束することが明らかになっていますが、遅延を無視するか、状態拡張の問題に依存するか、発散のために失敗する標準的なアプローチがあります。コードは公開時に共有されます。,6.25,
Unsupervised Meta-Learning through Latent-Space Interpolation in Generative Models,"['Siavash Khodadadeh', 'Sharare Zehtabian', 'Saeed Vahidian', 'Weijia Wang', 'Bill Lin', 'Ladislau Boloni']",https://openreview.net/forum?id=XOjv2HxIF6i,"Several recently proposed unsupervised meta-learning approaches rely on synthetic meta-tasks created using techniques such as random selection, clustering and/or augmentation. In this work, we describe a novel approach that generates meta-tasks using generative models. The proposed family of algorithms generate pairs of in-class and out-of-class samples from the latent space in a principled way, allowing us to create synthetic classes forming the training and validation data of a meta-task. We find that the proposed approach, LAtent Space Interpolation Unsupervised Meta-learning (LASIUM), outperforms or is competitive with current unsupervised learning baselines on few-shot classification tasks on the most widely used benchmark datasets. ",最近提案されたいくつかの教師なしメタ学習アプローチは、ランダム選択、クラスタリング、および/または拡張などの手法を使用して作成された合成メタタスクに依存しています。この作業では、生成モデルを使用してメタタスクを生成する新しいアプローチについて説明します。提案されたアルゴリズムファミリーは、原理的な方法で潜在空間からクラス内サンプルとクラス外サンプルのペアを生成し、メタタスクのトレーニングおよび検証データを形成する合成クラスを作成できるようにします。提案されたアプローチである潜在空間補間教師なしメタ学習（LASIUM）は、最も広く使用されているベンチマークデータセットの数ショット分類タスクで、現在の教師なし学習ベースラインよりも優れているか、競合していることがわかります。,6.25,https://d3i71xaburhd42.cloudfront.net/64bc52c8349cd62cc561f11c78cbb9b914064819/4-Figure1-1.png
Parameter Efficient Multimodal Transformers for Video Representation Learning,"['Sangho Lee', 'Youngjae Yu', 'Gunhee Kim', 'Thomas Breuel', 'Jan Kautz', 'Yale Song']",https://openreview.net/forum?id=6UdQLhqJyFD,"The recent success of Transformers in the language domain has motivated adapting it to a multimodal setting, where a new visual model is trained in tandem with an already pretrained language model. However, due to the excessive memory requirements from Transformers, existing work typically fixes the language model and train only the vision module, which limits its ability to learn cross-modal information in an end-to-end manner. In this work, we focus on reducing the parameters of multimodal Transformers in the context of audio-visual video representation learning. We alleviate the high memory requirement by sharing the weights of Transformers across layers and modalities; we decompose the Transformer into modality-specific and modality-shared parts so that the model learns the dynamics of each modality both individually and together, and propose a novel parameter sharing scheme based on low-rank approximation. We show that our approach reduces parameters up to 80%, allowing us to train our model end-to-end from scratch. We also propose a negative sampling approach based on an instance similarity measured on the CNN embedding space that our model learns with the Transformers. To demonstrate our approach, we pretrain our model on 30-second clips from Kinetics-700 and transfer it to audio-visual classification tasks. 
",言語ドメインでのトランスフォーマーの最近の成功は、新しいビジュアルモデルがすでに事前にトレーニングされた言語モデルと並行してトレーニングされるマルチモーダル設定にそれを適応させる動機を与えました。ただし、トランスフォーマーからの過剰なメモリ要件のため、既存の作業では通常、言語モデルが修正され、ビジョンモジュールのみがトレーニングされます。これにより、クロスモーダル情報をエンドツーエンドで学習する機能が制限されます。この作業では、オーディオビジュアルビデオ表現学習のコンテキストでマルチモーダルトランスフォーマーのパラメーターを減らすことに焦点を当てます。レイヤーやモダリティ間でトランスフォーマーの重みを共有することで、高いメモリ要件を緩和します。モデルが各モダリティのダイナミクスを個別におよび一緒に学習するように、Transformerをモダリティ固有の部分とモダリティ共有部分に分解し、低ランク近似に基づく新しいパラメーター共有スキームを提案します。私たちのアプローチがパラメータを最大80まで削減することを示します,6.25,https://d3i71xaburhd42.cloudfront.net/3655a6344ffb57838fd7f7acce651f36d3a9d526/2-Figure1-1.png
How Multipurpose Are Language Models?,"['Dan Hendrycks', 'Collin Burns', 'Steven Basart', 'Andy Zou', 'Mantas Mazeika', 'Dawn Song', 'Jacob Steinhardt']",https://openreview.net/forum?id=d7KBjmI3GmQ,"We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",テキストモデルのマルチタスク精度を測定するための新しいテストを提案します。このテストは、初等数学、米国の歴史、コンピューターサイエンス、法律などを含む57のタスクをカバーしています。このテストで高精度を達成するには、モデルは広範な世界知識と問題解決能力を備えている必要があります。最新のモデルはほぼランダムな確率の精度を持っていますが、非常に最大のGPT-3モデルは、ランダムな確率よりも平均してほぼ20パーセントポイント向上していることがわかります。ただし、57のタスクのすべてで、最高のモデルは、エキスパートレベルの精度に到達する前に、大幅な改善が必要です。モデルのパフォーマンスも偏っており、いつ間違っているのかわからないことがよくあります。さらに悪いことに、道徳や法などの社会的に重要な主題については、依然としてほぼランダムな精度を持っています。モデルの学術的および専門的な理解の幅と深さを包括的に評価することにより、私たちのテストを使用して、多くのタスクにわたるモデルを分析し、重要な欠点を特定できます。,6.25,
Beyond Categorical Label Representations for Image Classification,"['Boyuan Chen', 'Yu Li', 'Sunand Raghupathi', 'Hod Lipson']",https://openreview.net/forum?id=MyHwDabUHZm,"We find that the way we choose to represent data labels can have a profound effect on the quality of trained models. For example, training an image classifier to regress audio labels rather than traditional categorical probabilities produces a more reliable classification. This result is surprising, considering that audio labels are more complex than simpler numerical probabilities or text. We hypothesize that high dimensional, high entropy label representations are generally more useful because they provide a stronger error signal. We support this hypothesis with evidence from various label representations including constant matrices, spectrograms, shuffled spectrograms, Gaussian mixtures, and uniform random matrices of various dimensionalities. Our experiments reveal that high dimensional, high entropy labels achieve comparable accuracy to text (categorical) labels on standard image classification tasks, but features learned through our label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data. These results suggest that label representation may play a more important role than previously thought.",データラベルの表現方法を選択すると、トレーニング済みモデルの品質に大きな影響を与える可能性があることがわかりました。たとえば、従来のカテゴリ確率ではなく音声ラベルを回帰するように画像分類器をトレーニングすると、より信頼性の高い分類が生成されます。オーディオラベルが単純な数値確率やテキストよりも複雑であることを考えると、この結果は驚くべきものです。高次元、高エントロピーのラベル表現は、より強力なエラー信号を提供するため、一般的にはより有用であると仮定します。定数行列、スペクトログラム、シャッフルされたスペクトログラム、ガウス混合、さまざまな次元の均一なランダム行列など、さまざまなラベル表現からの証拠でこの仮説を支持します。私たちの実験では、高次元、高エントロピーのラベルが標準的な画像分類タスクのテキスト（カテゴリ）ラベルと同等の精度を達成することが明らかになりましたが、ラベル表現を通じて学習した機能は、さまざまな敵対攻撃の下でより堅牢で、限られた量のトレーニングデータでより優れた効果を示します。これらの結果は、ラベル表現が以前に考えられていたよりも重要な役割を果たす可能性があることを示唆しています。,6.25,
Fooling a Complete Neural Network Verifier,"['Dániel Zombori', 'Balázs Bánhelyi', 'Tibor Csendes', 'István Megyeri', 'Márk Jelasity']",https://openreview.net/forum?id=4IwieFS44l,"The efficient and accurate characterization of the robustness of neural networks to input perturbation is an important open problem. Many approaches exist including heuristic and exact (or complete) methods. Complete methods are expensive but their mathematical formulation guarantees that they provide exact robustness metrics. However, this guarantee is valid only if we assume that the verified network applies arbitrary-precision arithmetic and the verifier is reliable. In practice, however, both the networks and the verifiers apply limited-precision floating point arithmetic. In this paper, we show that numerical roundoff errors can be exploited to craft adversarial networks, in which the actual robustness and the robustness computed by a state-of-the-art complete verifier radically differ. We also show that such adversarial networks can be used to insert a backdoor into any network in such a way that the backdoor is completely missed by the verifier. The attack is easy to detect in its naive form but, as we show, the adversarial network can be transformed to make its detection less trivial. We offer a simple defense against our particular attack based on adding a very small perturbation to the network weights. However, our conjecture is that other numerical attacks are possible, and exact verification has to take into account all the details of the computation executed by the verified networks, which makes the problem significantly harder.
",入力摂動に対するニューラルネットワークのロバスト性の効率的かつ正確な特性評価は、重要な未解決の問題です。ヒューリスティックで正確な（または完全な）方法を含む多くのアプローチが存在します。完全な方法は費用がかかりますが、それらの数学的定式化により、正確な堅牢性メトリックが提供されることが保証されます。ただし、この保証は、検証されたネットワークが任意精度の演算を適用し、検証者が信頼できると想定した場合にのみ有効です。ただし、実際には、ネットワークとベリファイアの両方が、制限された精度の浮動小数点演算を適用します。この論文では、数値の丸め誤差を利用して敵対的ネットワークを作成できることを示します。このネットワークでは、実際の堅牢性と最先端の完全な検証者によって計算された堅牢性が根本的に異なります。また、このような敵対的ネットワークを使用して、検証者がバックドアを完全に見逃すような方法で、任意のネットワークにバックドアを挿入できることも示します。攻撃はナイーブな形で簡単に検出できますが、ここで示すように、敵対的ネットワークを変換して、検出を簡単にすることができます。ネットワークの重みに非常に小さな摂動を追加することに基づいて、特定の攻撃に対する単純な防御を提供します。しかし、私たちの推測では、他の数値攻撃が可能であり、正確な検証では、検証されたネットワークによって実行される計算のすべての詳細を考慮に入れる必要があるため、問題は非常に困難になります。,6.25,
On the role of planning in model-based deep reinforcement learning,"['Jessica B Hamrick', 'Abram L. Friesen', 'Feryal Behbahani', 'Arthur Guez', 'Fabio Viola', 'Sims Witherspoon', 'Thomas Anthony', 'Lars Holger Buesing', 'Petar Veličković', 'Theophane Weber']",https://openreview.net/forum?id=IrM64DGB21,"Model-based planning is often thought to be necessary for deep, careful reasoning and generalization in artificial agents. While recent successes of model-based reinforcement learning (MBRL) with deep function approximation have strengthened this hypothesis, the resulting diversity of model-based methods has also made it difficult to track which components drive success and why. In this paper, we seek to disentangle the contributions of recent methods by focusing on three questions: (1) How does planning benefit MBRL agents? (2) Within planning, what choices drive performance? (3) To what extent does planning improve generalization? To answer these questions, we study the performance of MuZero (Schrittwieser et al., 2019), a state-of-the-art MBRL algorithm with strong connections and overlapping components with many other MBRL algorithms. We perform a number of interventions and ablations of MuZero across a wide range of environments, including control tasks, Atari, and 9x9 Go. Our results suggest the following: (1) Planning is most useful in the learning process, both for policy updates and for providing a more useful data distribution. (2) Using shallow trees with simple Monte-Carlo rollouts is as performant as more complex methods, except in the most difficult reasoning tasks. (3) Planning alone is insufficient to drive strong generalization. These results indicate where and how to utilize planning in reinforcement learning settings, and highlight a number of open questions for future MBRL research.",モデルベースの計画は、人工エージェントの深く注意深い推論と一般化に必要であると考えられることがよくあります。深い関数近似を使用したモデルベースの強化学習（MBRL）の最近の成功により、この仮説が強化されましたが、結果として生じるモデルベースの方法の多様性により、どのコンポーネントが成功を促進するのか、そしてその理由を追跡することも困難になっています。このホワイトペーパーでは、次の3つの質問に焦点を当てて、最近の方法の貢献を解き明かそうとしています。（1）計画はMBRLエージェントにどのように役立つか。 （2）計画の中で、どのような選択がパフォーマンスを促進しますか？ （3）計画は一般化をどの程度改善しますか？これらの質問に答えるために、MuZero（Schrittwieser et al。、2019）のパフォーマンスを研究します。これは、強力な接続と他の多くのMBRLアルゴリズムとの重複コンポーネントを備えた最先端のMBRLアルゴリズムです。制御タスク、Atari、9x9 Goなど、さまざまな環境でMuZeroの多数の介入とアブレーションを実行します。私たちの結果は次のことを示唆しています。（1）計画は、ポリシーの更新と、より有用なデータ配布の提供の両方において、学習プロセスで最も役立ちます。 （2）単純なモンテカルロロールアウトで浅い木を使用することは、最も難しい推論タスクを除いて、より複雑な方法と同じくらいパフォーマンスが高いです。 （3）計画だけでは、強力な一般化を推進するには不十分です。これらの結果は、強化学習の設定で計画をどこでどのように利用するかを示し、将来のMBRL研究のための多くの未解決の質問を浮き彫りにします。,6.25,https://d3i71xaburhd42.cloudfront.net/bbf4992a5922c41d1a6c61c0fa62d0cd036b1499/2-Figure1-1.png
Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching,"['Jonas Geiping', 'Liam H Fowl', 'W. Ronny Huang', 'Wojciech Czaja', 'Gavin Taylor', 'Michael Moeller', 'Tom Goldstein']",https://openreview.net/forum?id=01olnfLIbD,"Data Poisoning attacks modify training data to maliciously control a model trained on such data. Previous poisoning attacks against deep neural networks have been limited in scope and success, working only in simplified settings or being prohibitively expensive for large datasets.
In this work, we focus on a particularly malicious poisoning attack that is both  ""from scratch"" and ""clean label"", meaning we analyze an attack that successfully works against new, randomly initialized models, and is nearly imperceptible to humans, all while perturbing only a small fraction of the training data. 
The central mechanism of this attack is matching the gradient direction of malicious examples. We analyze why this works, supplement with practical considerations. and show its threat to real-world practitioners, finding that it is the first poisoning method to cause targeted misclassification in modern deep networks trained from scratch on a full-sized, poisoned ImageNet dataset.
Finally we demonstrate the limitations of existing defensive strategies against such an attack, concluding that data poisoning is a credible threat, even for large-scale deep learning systems.",データポイズニング攻撃は、トレーニングデータを変更して、そのようなデータでトレーニングされたモデルを悪意を持って制御します。ディープニューラルネットワークに対する以前のポイズニング攻撃は、範囲と成功が制限されており、単純化された設定でのみ機能するか、大規模なデータセットでは法外な費用がかかります。この作業では、「ゼロから」と「クリーンなラベル」の両方である特に悪意のある中毒攻撃に焦点を当てます。つまり、ランダムに初期化された新しいモデルに対して正常に機能し、人間にはほとんど知覚できない攻撃を分析します。トレーニングデータのごく一部にすぎません。この攻撃の中心的なメカニズムは、悪意のある例の勾配方向を一致させることです。これが機能する理由を分析し、実際的な考慮事項を補足します。そして、実世界の開業医に脅威を示し、フルサイズのポイズニングされたImageNetデータセットでゼロからトレーニングされた最新のディープネットワークでターゲットを絞った誤分類を引き起こす最初のポイズニング方法であることを発見しました。最後に、このような攻撃に対する既存の防御戦略の限界を示し、大規模な深層学習システムであっても、データポイズニングは信頼できる脅威であると結論付けます。,6.25,https://d3i71xaburhd42.cloudfront.net/630c1be63b7b64d80b33f82c341e46b6ee2fef62/2-Figure1-1.png
Teaching with Commentaries,"['Aniruddh Raghu', 'Maithra Raghu', 'Simon Kornblith', 'David Duvenaud', 'Geoffrey Hinton']",https://openreview.net/forum?id=4RbdgBh9gE,"Effective training of deep neural networks can be challenging, and there remain many open questions on how to best learn these models. Recently developed methods to improve neural network training examine teaching: providing learned information during the training process to improve downstream model performance. In this paper, we take steps towards extending the scope of teaching. We propose a flexible teaching framework using commentaries,  meta-learned information helpful for training on a particular task or dataset. We present an efficient and scalable gradient-based method to learn commentaries, leveraging recent work on implicit differentiation. We explore diverse applications of commentaries, from learning weights for individual training examples, to parameterising label-dependent data augmentation policies, to representing attention masks that highlight salient image regions. In these settings, we find that commentaries can improve training speed and/or performance and also provide fundamental insights about the dataset and training process.",ディープニューラルネットワークの効果的なトレーニングは困難な場合があり、これらのモデルを最適に学習する方法については多くの未解決の質問が残っています。ニューラルネットワークトレーニングを改善するために最近開発された方法は、教育を検討します。トレーニングプロセス中に学習した情報を提供して、ダウンストリームモデルのパフォーマンスを改善します。この論文では、教育の範囲を拡大するための措置を講じます。解説、特定のタスクまたはデータセットのトレーニングに役立つメタ学習情報を使用した柔軟な教育フレームワークを提案します。暗黙の微分に関する最近の研究を活用して、解説を学習するための効率的でスケーラブルな勾配ベースの方法を提示します。個々のトレーニング例の重みの学習から、ラベルに依存するデータ拡張ポリシーのパラメーター化、顕著な画像領域を強調する注意マスクの表現まで、解説のさまざまなアプリケーションを調査します。これらの設定では、解説によってトレーニングの速度やパフォーマンスが向上し、データセットとトレーニングプロセスに関する基本的な洞察が得られることがわかりました。,6.25,https://d3i71xaburhd42.cloudfront.net/e8e1ee451a8d27677d1e7f693ef12b9a4c9a7ec9/4-Figure1-1.png
Neural Spatio-Temporal Point Processes,"['Ricky T. Q. Chen', 'Brandon Amos', 'Maximilian Nickel']",https://openreview.net/forum?id=XQQA6-So14,"We propose a new class of parameterizations for spatio-temporal point processes which leverage Neural ODEs as a computational method and enable flexible, high-fidelity models of discrete events that are localized in continuous time and space. Central to our approach is a combination of recurrent continuous-time neural networks with two novel neural architectures, i.e., Jump and Attentive Continuous-time Normalizing Flows. This approach allows us to learn complex distributions for both the spatial and temporal domain and to condition non-trivially on the observed event history. We validate our models on data sets from a wide variety of contexts such as seismology, epidemiology, urban mobility, and neuroscience.",計算方法としてニューラルODEを活用し、連続時間と空間にローカライズされた離散イベントの柔軟で忠実度の高いモデルを可能にする、時空間点過程の新しいクラスのパラメーター化を提案します。私たちのアプローチの中心は、反復連続時間ニューラルネットワークと2つの新しいニューラルアーキテクチャ、つまりジャンプと注意深い連続時間正規化フローの組み合わせです。このアプローチにより、空間ドメインと時間ドメインの両方の複雑な分布を学習し、観察されたイベント履歴を自明ではない条件で調整できます。地震学、疫学、都市移動、神経科学など、さまざまなコンテキストのデータセットでモデルを検証します。,6.25,https://d3i71xaburhd42.cloudfront.net/289322a72c5693f5942054019a8e90bd3adebd94/1-Figure1-1.png
IEPT: Instance-Level and Episode-Level Pretext Tasks for Few-Shot Learning,"['Manli Zhang', 'Jianhong Zhang', 'Zhiwu Lu', 'Tao Xiang', 'Mingyu Ding', 'Songfang Huang']",https://openreview.net/forum?id=xzqLpqRzxLq,"The need of collecting large quantities of labeled training data for each new task has limited the usefulness of deep neural networks. Given data from a set of source tasks, this limitation can be overcome using two transfer learning approaches: few-shot learning (FSL) and self-supervised learning (SSL). The former aims to learn `how to learn' by designing learning episodes using source tasks to simulate the challenge of solving the target new task with few labeled samples. In contrast, the latter exploits an annotation-free pretext task across all source tasks in order to learn generalizable feature representations. In this work, we propose a novel Instance-level and Episode-level Pretext Task (IEPT) framework that seamlessly integrates SSL into FSL. Specifically, given an FSL episode, we first apply geometric transformations to each instance to generate extended episodes. At the instance-level, transformation recognition is performed as per standard SSL. Importantly, at the episode-level, two SSL-FSL hybrid learning objectives are devised: (1) The consistency across the predictions of an FSL classifier from different extended episodes is maximized as an episode-level pretext task. (2) The features extracted from each instance across different episodes are integrated to construct a single FSL classifier for meta-learning. Extensive experiments show that our proposed model (i.e., FSL with IEPT) achieves the new state-of-the-art. ",新しいタスクごとにラベル付きのトレーニングデータを大量に収集する必要があるため、ディープニューラルネットワークの有用性が制限されています。一連のソースタスクからのデータが与えられた場合、この制限は、2つの転送学習アプローチ（少数ショット学習（FSL）と自己教師あり学習（SSL））を使用して克服できます。前者は、ソースタスクを使用して学習エピソードを設計し、いくつかのラベル付きサンプルを使用してターゲットの新しいタスクを解決するという課題をシミュレートすることにより、学習方法を学習することを目的としています。対照的に、後者は、一般化可能な特徴表現を学習するために、すべてのソースタスクにわたって注釈のない口実タスクを利用します。この作業では、SSLをFSLにシームレスに統合する新しいインスタンスレベルおよびエピソードレベルの口実タスク（IEPT）フレームワークを提案します。具体的には、FSLエピソードが与えられた場合、最初に各インスタンスに幾何学的変換を適用して、拡張エピソードを生成します。インスタンスレベルでは、変換認識は標準のSSLに従って実行されます。重要なのは、エピソードレベルで、2つのSSL-FSLハイブリッド学習目標が考案されていることです。（1）エピソードレベルの口実タスクとして、さまざまな拡張エピソードからのFSL分類子の予測全体の一貫性が最大化されます。 （2）異なるエピソードにわたって各インスタンスから抽出された特徴が統合され、メタ学習用の単一のFSL分類器が構築されます。広範な実験により、提案されたモデル（つまり、IEPTを使用したFSL）が新しい最先端を実現していることが示されています。,6.2,
Adaptive and Generative Zero-Shot Learning,"['Yu-Ying Chou', 'Hsuan-Tien Lin', 'Tyng-Luh Liu']",https://openreview.net/forum?id=ahAUv8TI2Mz,"We address the problem of generalized zero-shot learning (GZSL) where the task is to predict the class label of a target image whether its label belongs to the seen or unseen category. Similar to ZSL, the learning setting assumes that all class-level semantic features are given, while only the images of seen classes are available for training. By exploring the correlation between image features and the corresponding semantic features, the main idea of the proposed approach is to enrich the semantic-to-visual (S2V) embeddings via a seamless fusion of adaptive and generative learning. To this end, we extend the semantic features of each class by supplementing image-adaptive attention so that the learned S2V embedding can account for not only inter-class but also intra-class variations. In addition, to break the limit of training with images only from seen classes, we design a generative scheme to simultaneously generate virtual class labels and their visual features by sampling and interpolating over seen counterparts. In inference, a testing image will give rise to two different S2V embeddings, seen and virtual. The former is used to decide whether the underlying label is of the unseen category or otherwise a specific seen class; the latter is to predict an unseen class label. To demonstrate the effectiveness of our method, we report state-of-the-art results on four standard GZSL datasets, including an ablation study of the proposed modules. ",一般化されたゼロショット学習（GZSL）の問題に対処します。この問題では、ターゲット画像のラベルが表示されているカテゴリと表示されていないカテゴリのどちらに属しているかを予測します。 ZSLと同様に、学習設定では、すべてのクラスレベルのセマンティック機能が提供され、見られたクラスの画像のみがトレーニングに使用できることを前提としています。画像の特徴と対応するセマンティックの特徴との相関関係を調査することにより、提案されたアプローチの主なアイデアは、適応学習と生成学習のシームレスな融合を介してセマンティックからビジュアル（S2V）の埋め込みを強化することです。この目的のために、学習したS2V埋め込みがクラス間だけでなくクラス内の変動も考慮できるように、画像適応注意を補足することによって各クラスのセマンティック機能を拡張します。さらに、見たクラスからの画像のみを使用したトレーニングの制限を打破するために、見た対応物をサンプリングして補間することにより、仮想クラスラベルとその視覚的特徴を同時に生成する生成スキームを設計します。推論では、テスト画像は、表示と仮想の2つの異なるS2V埋め込みを生成します。前者は、基になるラベルが非表示カテゴリであるか、特定の表示クラスであるかを判断するために使用されます。後者は、見えないクラスラベルを予測することです。私たちの方法の有効性を実証するために、提案されたモジュールのアブレーション研究を含む、4つの標準GZSLデータセットに関する最先端の結果を報告します。,6.2,
Why resampling outperforms reweighting for correcting sampling bias with stochastic descents,"['Jing An', 'Lexing Ying', 'Yuhua Zhu']",https://openreview.net/forum?id=iQQK02mxVIT,"A data set sampled from a certain population is biased if the subgroups of the population are sampled at proportions that are significantly different from their underlying proportions. Training machine learning models on biased data sets requires correction techniques to compensate for the bias. We consider two commonly-used techniques, resampling and reweighting, that rebalance the proportions of the subgroups to maintain the desired objective function. Though statistically equivalent, it has been observed that resampling outperforms reweighting when combined with stochastic gradient algorithms. By analyzing illustrative examples, we explain the reason behind this phenomenon using tools from dynamical stability and stochastic asymptotics. We also present experiments from regression, classification, and off-policy prediction to demonstrate that this is a general phenomenon. We argue that it is imperative to consider the objective function design and the optimization algorithm together while addressing the sampling bias.
",特定の母集団からサンプリングされたデータセットは、母集団のサブグループが基礎となる比率とは大幅に異なる比率でサンプリングされた場合にバイアスがかかります。偏ったデータセットで機械学習モデルをトレーニングするには、偏りを補正するための修正手法が必要です。サブグループの比率を再調整して目的の目的関数を維持する、2つの一般的に使用される手法であるリサンプリングと再重み付けを検討します。統計的には同等ですが、確率的勾配アルゴリズムと組み合わせると、リサンプリングが再重み付けよりも優れていることが観察されています。実例を分析することにより、動的安定性と確率的漸近解析のツールを使用して、この現象の背後にある理由を説明します。また、これが一般的な現象であることを示すために、回帰、分類、およびポリシー外の予測からの実験を示します。サンプリングバイアスに対処する際には、目的関数の設計と最適化アルゴリズムを一緒に検討することが不可欠であると主張します。,6.2,
Evaluating the Disentanglement of Deep Generative Models through Manifold Topology,"['Sharon Zhou', 'Eric Zelikman', 'Fred Lu', 'Andrew Y. Ng', 'Gunnar E. Carlsson', 'Stefano Ermon']",https://openreview.net/forum?id=djwS0m4Ft_A,"Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.",解きほぐされた表現を学習することは、生成モデルの一般化、堅牢性、および解釈可能性を改善するための基本的なタスクと見なされます。ただし、解きほぐしの測定は困難で一貫性がなく、アドホックな外部モデルに依存したり、特定のデータセットに固有のものであることがよくあります。これに対処するために、学習された表現の条件付き部分多様体の位相的類似性を測定することにより、生成モデルのみを使用する解きほぐしを定量化する方法を提示します。このメソッドは、教師なしバリアントと教師なしバリアントの両方を示します。私たちの方法の有効性と適用性を説明するために、複数のデータセットにわたっていくつかの最先端のモデルを経験的に評価します。私たちの方法は、既存の方法と同様にモデルをランク付けしていることがわかります。コードはhttps://github.com/stanfordmlgroup/disentanglementで公開されています。,6.2,
SCoRe: Pre-Training for Context Representation in Conversational Semantic Parsing,"['Tao Yu', 'Rui Zhang', 'Alex Polozov', 'Christopher Meek', 'Ahmed Hassan Awadallah']",https://openreview.net/forum?id=oyZxhRI2RiE,"Conversational Semantic Parsing (CSP) is the task of converting a sequence of natural language queries to formal language (e.g., SQL, SPARQL) that can be executed against a structured ontology (e.g.  databases, knowledge bases).  To accomplish  this  task,  a  CSP  system  needs  to  model  the  relation  between  the unstructured language utterance and the structured ontology while representing the multi-turn dynamics of the dialog. Pre-trained language models (LMs) are the state-of-the-art for various natural language processing tasks. However, existing pre-trained LMs that use language modeling training objectives over free-form text have limited ability to represent natural language references to contextual structural data. In this work, we present SCORE, a new pre-training approach for CSP tasks designed to induce representations that capture the alignment between the dialogue flow and the structural context. We demonstrate the broad applicability of SCORE to CSP tasks by combining SCORE with strong base systems on four different tasks (SPARC, COSQL, MWOZ, and SQA). We show that SCORE can improve the performance over all these base systems by a significant margin and achieves state-of-the-art results on three of them. Our implementation and checkpoints of the model will be available at Anonymous URL.",会話型セマンティック解析（CSP）は、一連の自然言語クエリを、構造化されたオントロジー（データベース、知識ベースなど）に対して実行できる形式言語（SQL、SPARQLなど）に変換するタスクです。このタスクを実行するには、CSPシステムは、ダイアログのマルチターンダイナミクスを表現しながら、非構造化言語の発話と構造化オントロジーの間の関係をモデル化する必要があります。事前トレーニング済みの言語モデル（LM）は、さまざまな自然言語処理タスクの最先端技術です。ただし、自由形式のテキストに対して言語モデリングのトレーニング目標を使用する既存の事前トレーニング済みLMは、コンテキスト構造データへの自然言語参照を表す機能が制限されています。この作業では、対話フローと構造コンテキストの間の整合をキャプチャする表現を誘導するように設計されたCSPタスクの新しい事前トレーニングアプローチであるSCOREを紹介します。 SCOREを4つの異なるタスク（SPARC、COSQL、MWOZ、およびSQA）の強塩基システムと組み合わせることにより、SCOREのCSPタスクへの幅広い適用性を示します。 SCOREは、これらすべての基本システムのパフォーマンスを大幅に向上させ、そのうち3つで最先端の結果を達成できることを示しています。モデルの実装とチェックポイントは、匿名URLで入手できます。,6.2,
Universal Weakly Supervised Segmentation by Pixel-to-Segment Contrastive Learning,"['Tsung-Wei Ke', 'Jyh-Jing Hwang', 'Stella Yu']",https://openreview.net/forum?id=N33d7wjgzde,"Weakly supervised segmentation is challenging as sparsely labeled pixels do not provide sufficient supervision:  A semantic segment may contain multiple distinctive regions whereas adjacent segments may appear similar.  Common approaches use the few labeled pixels in all training images to train a segmentation model, and then propagate labels within each image based on visual or feature similarity.  Instead, we treat segmentation as a semi-supervised pixel-wise metric learning problem, where pixels in different segments are mapped to distinctive features.   Naturally, our unlabeled pixels participate not only in data-driven grouping within each image, but also in discriminative feature learning within and across images.  Our results on Pascal VOC and DensePose datasets demonstrate our substantial accuracy gain on various forms of weak supervision including image-level tags, bounding boxes, labeled points, and scribbles.",ラベルがまばらなピクセルでは十分な監視が提供されないため、弱く監視されたセグメンテーションは困難です。セマンティックセグメントには複数の特徴的な領域が含まれる場合がありますが、隣接するセグメントは類似しているように見えます。一般的なアプローチでは、すべてのトレーニング画像のいくつかのラベル付きピクセルを使用してセグメンテーションモデルをトレーニングし、視覚的または特徴的な類似性に基づいて各画像内でラベルを伝播します。代わりに、セグメンテーションを半教師ありピクセル単位のメトリック学習問題として扱います。この問題では、異なるセグメントのピクセルが特徴的な特徴にマッピングされます。当然、ラベルのないピクセルは、各画像内のデータ駆動型グループ化だけでなく、画像内および画像間の識別的特徴学習にも関与します。 Pascal VOCおよびDensePoseデータセットに関する結果は、画像レベルのタグ、境界ボックス、ラベル付きポイント、落書きなど、さまざまな形式の弱い監視で大幅な精度の向上を示しています。,6.2,
Auction Learning as a Two-Player Game,"['Jad Rahme', 'Samy Jelassi', 'S. Matthew Weinberg']",https://openreview.net/forum?id=YHdeAO61l6T,"Designing an incentive compatible auction that maximizes expected revenue is a central problem in Auction Design. While theoretical approaches to the problem have hit some limits, a recent research direction initiated by Duetting et al. (2019) consists in building neural network architectures to find optimal auctions.  We propose two conceptual deviations from their approach which result in enhanced performance. First, we use recent results in theoretical auction design to introduce a time-independent Lagrangian.  This not only circumvents the need for an expensive hyper-parameter search (as in prior work), but also provides a single metric to compare the performance of two auctions (absent from prior work). Second, the optimization procedure in previous work uses an inner maximization loop to compute optimal misreports. We amortize this process through the introduction of an additional neural network. We demonstrate the effectiveness of our approach by learning competitive or strictly improved auctions compared to prior work. Both results together further imply a novel formulation of Auction Design as a two-player game with stationary utility functions.",期待される収益を最大化するインセンティブ互換のオークションを設計することは、オークション設計の中心的な問題です。問題への理論的アプローチはいくつかの限界に達していますが、Duett etal。によって開始された最近の研究の方向性。 （2019）は、最適なオークションを見つけるためのニューラルネットワークアーキテクチャの構築で構成されています。パフォーマンスの向上につながる、アプローチからの2つの概念的な逸脱を提案します。まず、理論的なオークション設計の最近の結果を使用して、時間に依存しないラグランジアンを導入します。これにより、（前の作業のように）高価なハイパーパラメータ検索の必要性が回避されるだけでなく、2つのオークションのパフォーマンスを比較するための単一のメトリックが提供されます（前の作業にはありません）。次に、前の作業の最適化手順では、内部最大化ループを使用して最適な誤報を計算します。追加のニューラルネットワークを導入することで、このプロセスを償却します。以前の作業と比較して競争力のある、または厳密に改善されたオークションを学習することにより、アプローチの有効性を示します。両方の結果を合わせると、固定ユーティリティ機能を備えた2人用ゲームとしてのオークションデザインの新しい定式化がさらに示唆されます。,6.2,https://d3i71xaburhd42.cloudfront.net/1db7a459b6062beb3ce81b564e4df16935c717f2/10-Figure2-1.png
Faster Binary Embeddings for Preserving Euclidean Distances,"['Jinjie Zhang', 'Rayan Saab']",https://openreview.net/forum?id=YCXrx6rRCXO,"We propose a fast, distance-preserving, binary embedding algorithm to transform a high-dimensional dataset $\mathcal{T}\subseteq\mathbb{R}^n$ into binary sequences in the cube $\{\pm 1\}^m$. When $\mathcal{T}$ consists of well-spread (i.e., non-sparse) vectors, our embedding method applies a stable noise-shaping quantization scheme to $A x$ where $A\in\mathbb{R}^{m\times n}$ is a sparse Gaussian random matrix. This contrasts with most binary embedding methods, which usually use $x\mapsto \mathrm{sign}(Ax)$ for the embedding. Moreover, we show that Euclidean distances among the elements of $\mathcal{T}$ are approximated by the $\ell_1$ norm on the images of $\{\pm 1\}^m$ under a fast linear transformation. This again contrasts with standard methods, where the Hamming distance is used instead.  Our method is both fast and memory efficient, with time complexity  $O(m)$ and space complexity $O(m)$ on well-spread data. When the data is not well-spread, we show that the approach still works provided that data is transformed via a Walsh-Hadamard matrix, but now the cost is $O(n\log n)$ per data point.  Further, we prove that the method is accurate and its associated error is comparable to that of a continuous valued Johnson-Lindenstrauss embedding plus a quantization error that admits a polynomial decay as the embedding dimension $m$ increases.
	Thus the length of the binary codes required to achieve a desired accuracy is quite small, and we show it can even be compressed further without compromising the accuracy. To illustrate our results, we test the proposed method on natural images and show that it achieves strong performance.",高次元データセットTR ^（n）をキューブ{1} ^（m）内のバイナリシーケンスに変換するための、高速で距離を保存するバイナリ埋め込みアルゴリズムを提案します。 Tが十分に広がった（つまり、スパースでない）ベクトルで構成されている場合、埋め込み方法は、安定したノイズシェーピング量子化スキームをAxに適用します。ここで、AR ^（mn）はスパースガウスランダム行列です。これは、通常、埋め込みにx記号（Ax）を使用するほとんどのバイナリ埋め込み方法とは対照的です。さらに、Tの要素間のユークリッド距離は、高速線形変換の下で{1} ^（m）の画像のl1ノルムによって近似されることを示します。これも、代わりにハミング距離が使用される標準的な方法とは対照的です。私たちの方法は高速でメモリ効率が高く、十分に分散されたデータでは時間計算量O（m）と空間計算量O（m）があります。データが十分に普及していない場合でも、データがWalsh-Hadamard行列を介して変換されれば、このアプローチは機能することを示しますが、コストはデータポイントあたりO（nlog n）です。さらに、この方法が正確であり、それに関連する誤差が、連続値のジョンソン-リンデンシュトラウス埋め込みの誤差に加えて、埋め込み次元mが増加するにつれて多項式の減衰を認める量子化誤差に匹敵することを証明します。したがって、必要な精度を達成するために必要なバイナリコードの長さは非常に短く、精度を損なうことなくさらに圧縮できることを示しています。結果を説明するために、提案された方法を自然画像でテストし、それが強力なパフォーマンスを達成することを示します。,6.2,https://d3i71xaburhd42.cloudfront.net/36245cf9c6409eec0730c84bcc389ac1cb23971d/13-Figure1-1.png
Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation,"['Hao Li', 'Chenxin Tao', 'Xizhou Zhu', 'Xiaogang Wang', 'Gao Huang', 'Jifeng Dai']",https://openreview.net/forum?id=MJAqnaC2vO1,"Designing proper loss functions is essential in training deep networks. Especially in the field of semantic segmentation, various evaluation metrics have been proposed for diverse scenarios. Despite the success of the widely adopted cross-entropy loss and its variants, the mis-alignment between the loss functions and evaluation metrics degrades the network performance. Meanwhile, manually designing loss functions for each specific metric requires expertise and significant manpower. In this paper, we propose to automate the design of metric-specific loss functions by searching differentiable surrogate losses for each metric. We substitute the non-differentiable operations in the metrics with parameterized functions, and conduct parameter search to optimize the shape of loss surfaces. Two constraints are introduced to regularize the search space and make the search efficient. Extensive experiments on PASCAL VOC and Cityscapes demonstrate that the searched surrogate losses outperform the manually designed loss functions consistently. The searched losses can generalize well to other datasets and networks. Code shall be released.",適切な損失関数を設計することは、深いネットワークをトレーニングするために不可欠です。特にセマンティックセグメンテーションの分野では、さまざまなシナリオに対してさまざまな評価指標が提案されています。広く採用されているクロスエントロピー損失とその変形の成功にもかかわらず、損失関数と評価メトリックの間の不整合はネットワークパフォーマンスを低下させます。一方、特定のメトリックごとに損失関数を手動で設計するには、専門知識と多大な人的資源が必要です。この論文では、各メトリックの微分可能な代理損失を検索することにより、メトリック固有の損失関数の設計を自動化することを提案します。メトリック内の微分不可能な操作をパラメーター化された関数に置き換え、パラメーター検索を実行して損失面の形状を最適化します。検索スペースを正規化し、検索を効率化するために、2つの制約が導入されています。 PASCAL VOCとCityscapesに関する広範な実験は、検索された代理損失が手動で設計された損失関数を一貫して上回っていることを示しています。検索された損失は、他のデータセットやネットワークによく一般化できます。コードはリリースされます。,6.0,https://d3i71xaburhd42.cloudfront.net/98f2cb7e6baa140e1b5e72fd5af9357c678c176b/4-Figure1-1.png
Reset-Free Lifelong Learning with Skill-Space Planning,"['Kevin Lu', 'Aditya Grover', 'Pieter Abbeel', 'Igor Mordatch']",https://openreview.net/forum?id=HIGSa_3kOx3,"The objective of \textit{lifelong} reinforcement learning (RL) is to optimize agents which can continuously adapt and interact in changing environments. However, current RL approaches fail drastically when environments are non-stationary and interactions are non-episodic. We propose \textit{Lifelong Skill Planning} (LiSP), an algorithmic framework for lifelong RL based on planning in an abstract space of higher-order skills. We learn the skills in an unsupervised manner using intrinsic rewards and plan over the learned skills using a learned dynamics model. Moreover, our framework permits skill discovery even from offline data, thereby reducing the need for excessive real-world interactions. We demonstrate empirically that LiSP successfully enables long-horizon planning and learns agents that can avoid catastrophic failures even in challenging non-stationary and non-episodic environments derived from gridworld and MuJoCo benchmarks.",生涯強化学習（RL）の目的は、変化する環境に継続的に適応して相互作用できるエージェントを最適化することです。ただし、現在のRLアプローチは、環境が非定常であり、相互作用が非エピソード的である場合、大幅に失敗します。高次スキルの抽象的な空間での計画に基づく生涯RLのアルゴリズムフレームワークである生涯スキル計画（LiSP）を提案します。本質的な報酬を使用して教師なしでスキルを学習し、学習したダイナミクスモデルを使用して学習したスキルを計画します。さらに、私たちのフレームワークはオフラインデータからでもスキルの発見を可能にし、それによって過度の現実世界の相互作用の必要性を減らします。 LiSPが長期計画を成功裏に可能にし、gridworldおよびMuJoCoベンチマークから派生した非定常および非エピソード環境に挑戦する場合でも壊滅的な障害を回避できるエージェントを学習することを経験的に示します。,6.0,https://d3i71xaburhd42.cloudfront.net/876b4f27824b3d44c5fb04f5b539b911d7ac23fe/5-Figure2-1.png
FedBN: Federated Learning on Non-IID Features via Local Batch Normalization,"['Xiaoxiao Li', 'Meirui JIANG', 'Xiaofei Zhang', 'Michael Kamp', 'Qi Dou']",https://openreview.net/forum?id=6YEQUn0QICG,"The emerging paradigm of federated learning (FL) strives to enable collaborative training of deep models on the network edge without centrally aggregating raw data and hence improving data privacy. In most cases, the assumption of independent and identically distributed samples across local clients does not hold for federated learning setups. Under this setting, neural network training performance may vary significantly according to the data distribution and even hurt training convergence. 
Most of the previous work has focused on a difference in the distribution of labels. Unlike those settings, we address an important problem of FL, e.g., different scanner/sensors in medical imaging, different scenery distribution in autonomous driving (highway vs. city), where local clients may store examples with different marginal or conditional feature distributions compared to other nodes, which we denote as feature shift non-iid.  In this work, we propose an effective method that uses local batch normalization to alleviate the feature shift before averaging models. The resulting scheme, called FedBN, outperforms both classical FedAvg, as well as the state-of-the-art for non-iid data (FedProx) on our extensive experiments. These empirical results are supported by a convergence analysis that shows in a simplified setting that FedBN has a faster convergence rate in expectation than FedAvg.",フェデレーションラーニング（FL）の新しいパラダイムは、生データを一元的に集約することなく、ネットワークエッジでディープモデルの共同トレーニングを可能にし、データのプライバシーを向上させることを目指しています。ほとんどの場合、ローカルクライアント間で独立して同じように分散されたサンプルの仮定は、フェデレーション学習のセットアップには当てはまりません。この設定では、ニューラルネットワークのトレーニングパフォーマンスはデータの分布に応じて大幅に変化し、トレーニングの収束に悪影響を与える可能性があります。これまでの作業のほとんどは、ラベルの配布の違いに焦点を当てていました。これらの設定とは異なり、FLの重要な問題に対処します。たとえば、医用画像のスキャナー/センサーの違い、自動運転（高速道路と都市）の風景の分布の違いなど、ローカルクライアントは周辺または条件付きの特徴の分布が異なる例を保存できます。他のノード。これを機能シフト非iidと呼びます。この作業では、モデルを平均化する前に、ローカルバッチ正規化を使用して特徴シフトを軽減する効果的な方法を提案します。結果として得られるFedBNと呼ばれるスキームは、従来のFedAvgと、広範な実験での非iidデータの最先端（FedProx）の両方を上回ります。これらの経験的結果は、FedBNがFedAvgよりも期待値が速い収束率を持っていることを簡略化された設定で示す収束分析によってサポートされています。,6.0,
Planning from Pixels using Inverse Dynamics Models,"['Keiran Paster', 'Sheila A. McIlraith', 'Jimmy Ba']",https://openreview.net/forum?id=V6BjBgku7Ro,"Learning dynamics models in high-dimensional observation spaces can be challenging for model-based RL agents. We propose a novel way to learn models in a latent space by learning to predict sequences of future actions conditioned on task completion. These models track task-relevant environment dynamics over a distribution of tasks, while simultaneously serving as an effective heuristic for planning with sparse rewards. We evaluate our method on challenging visual goal completion tasks and show a substantial increase in performance compared to prior model-free approaches.",高次元の観測空間でダイナミクスモデルを学習することは、モデルベースのRLエージェントにとって困難な場合があります。タスクの完了を条件とする将来のアクションのシーケンスを予測することを学習することにより、潜在空間でモデルを学習する新しい方法を提案します。これらのモデルは、タスクの分散全体でタスク関連の環境ダイナミクスを追跡すると同時に、報酬が少ない計画の効果的なヒューリスティックとして機能します。挑戦的な視覚的目標完了タスクで私たちの方法を評価し、以前のモデルフリーアプローチと比較してパフォーマンスの大幅な向上を示しています。,6.0,https://d3i71xaburhd42.cloudfront.net/0bf1a78aeefa158a80b23fd5b57a5586a32eb7c1/2-Figure1-1.png
Self-Supervised Learning of Compressed Video Representations,"['Youngjae Yu', 'Sangho Lee', 'Gunhee Kim', 'Yale Song']",https://openreview.net/forum?id=jMPcEkJpdD,"Self-supervised learning of video representations has received great attention. Existing methods typically require frames to be decoded before being processed, which increases compute and storage requirements and ultimately hinders large-scale training. In this work, we propose an efficient self-supervised approach to learn video representations by eliminating the expensive decoding step. We use a three-stream video architecture that encodes I-frames and P-frames of a compressed video. Unlike existing approaches that encode I-frames and P-frames individually, we propose to jointly encode them by establishing bidirectional dynamic connections across streams. To enable self-supervised learning, we propose two pretext tasks that leverage the multimodal nature (RGB, motion vector, residuals) and the internal GOP structure of compressed videos. The first task asks our network to predict zeroth-order motion statistics in a spatio-temporal pyramid; the second task asks correspondence types between I-frames and P-frames after applying temporal transformations. We show that our approach achieves competitive performance on compressed video recognition both in supervised and self-supervised regimes. 
",ビデオ表現の自己教師あり学習は大きな注目を集めています。既存の方法では通常、処理する前にフレームをデコードする必要があります。これにより、計算とストレージの要件が増加し、最終的に大規模なトレーニングが妨げられます。この作業では、高価なデコード手順を排除することにより、ビデオ表現を学習するための効率的な自己教師ありアプローチを提案します。圧縮ビデオのIフレームとPフレームをエンコードする3ストリームビデオアーキテクチャを使用します。 IフレームとPフレームを個別にエンコードする既存のアプローチとは異なり、ストリーム間で双方向の動的接続を確立することにより、それらを共同でエンコードすることを提案します。自己教師あり学習を可能にするために、マルチモーダルな性質（RGB、動きベクトル、残差）と圧縮ビデオの内部GOP構造を活用する2つの口実タスクを提案します。最初のタスクは、時空間ピラミッドの0次モーション統計を予測するようにネットワークに要求します。 2番目のタスクは、時間変換を適用した後、IフレームとPフレームの間の対応タイプを尋ねます。私たちのアプローチは、監視ありと自己監視の両方の体制で圧縮ビデオ認識で競争力のあるパフォーマンスを達成することを示しています。,6.0,
Learning Accurate Entropy Model with Global Reference for Image Compression,"['Yichen Qian', 'Zhiyu Tan', 'Xiuyu Sun', 'Ming Lin', 'Dongyang Li', 'Zhenhong Sun', 'Li Hao', 'Rong Jin']",https://openreview.net/forum?id=cTbIjyrUVwJ,"In recent deep image compression neural networks, the entropy model plays a critical role in estimating the prior distribution of deep image encodings. Existing methods combine hyperprior with local context in the entropy estimation function. This greatly limits their performance due to the absence of a global vision. In this work, we propose a novel Global Reference Model for image compression to effectively leverage both the local and the global context information, leading to an enhanced compression rate. The proposed method scans decoded latents and then finds the most relevant latent to assist the distribution estimating of the current latent. A by-product of this work is the innovation of a mean-shifting GDN module that further improves the performance. Experimental results demonstrate that the proposed model outperforms the rate-distortion performance of most of the state-of-the-art methods in the industry.",最近の深部画像圧縮ニューラルネットワークでは、エントロピーモデルが深部画像エンコーディングの事前分布を推定する上で重要な役割を果たしています。既存の方法は、エントロピー推定関数でハイパープライアとローカルコンテキストを組み合わせます。これは、グローバルなビジョンがないため、パフォーマンスを大幅に制限します。この作業では、ローカルとグローバルの両方のコンテキスト情報を効果的に活用して圧縮率を向上させる、画像圧縮の新しいグローバル参照モデルを提案します。提案された方法は、デコードされた潜在性をスキャンし、次に、現在の潜在性の分布推定を支援するために最も関連性のある潜在性を見つける。この作業の副産物は、パフォーマンスをさらに向上させる平均シフトGDNモジュールの革新です。実験結果は、提案されたモデルが、業界のほとんどの最先端の方法のレート歪み性能を上回っていることを示しています。,6.0,https://d3i71xaburhd42.cloudfront.net/0a5bb24c97f1abe927f318535442801e0afaa1e8/1-Figure1-1.png
FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning,"['Hong-You Chen', 'Wei-Lun Chao']",https://openreview.net/forum?id=dgtpE6gKjHn,"Federated learning aims to collaboratively train a strong global model by accessing users' locally trained models but not their own data. A crucial step is therefore to aggregate local models into a global model, which has been shown challenging when users have non-i.i.d. data. In this paper, we propose a novel aggregation algorithm named FedBE, which takes a Bayesian inference perspective by sampling higher-quality global models and combining them via Bayesian model Ensemble, leading to much robust aggregation. We show that an effective model distribution can be constructed by simply fitting a Gaussian or Dirichlet distribution to the local models. Our empirical studies validate FedBE's superior performance, especially when users' data are not i.i.d. and when the neural networks go deeper. Moreover, FedBE is compatible with recent efforts in regularizing users' model training, making it an easily applicable module: you only need to replace the aggregation method but leave other parts of your federated learning algorithm intact.",連合学習は、ローカルでトレーニングされたモデルにアクセスするが、自分のデータにはアクセスしないことにより、強力なグローバルモデルを共同でトレーニングすることを目的としています。したがって、重要なステップは、ローカルモデルをグローバルモデルに集約することです。これは、ユーザーが非iidデータを持っている場合に困難であることが示されています。この論文では、FedBEという名前の新しい集約アルゴリズムを提案します。これは、高品質のグローバルモデルをサンプリングし、ベイジアンモデルEnsembleを介してそれらを組み合わせることにより、ベイズ推定の観点を取り、非常に堅牢な集約を実現します。ガウス分布またはディリクレ分布をローカルモデルに適合させるだけで、効果的なモデル分布を構築できることを示します。私たちの実証研究は、特にユーザーデータがiidでない場合、およびニューラルネットワークがより深くなる場合に、FedBEの優れたパフォーマンスを検証します。さらに、FedBEは、ユーザーモデルトレーニングを正規化する最近の取り組みと互換性があるため、簡単に適用できるモジュールになります。集計方法を置き換えるだけで、フェデレーション学習アルゴリズムの他の部分はそのままにします。,6.0,
Diverse Video Generation using a Gaussian Process Trigger,"['Gaurav Shrivastava', 'Abhinav Shrivastava']",https://openreview.net/forum?id=Qm7R_SdqTpT,"Generating future frames given a few context (or past) frames is a challenging task. It requires modeling the temporal coherence of videos as well as multi-modality in terms of diversity in the potential future states. Current variational approaches for video generation tend to marginalize over multi-modal future outcomes. Instead, we propose to explicitly model the multi-modality in the future outcomes and leverage it to sample diverse futures. Our approach, Diverse Video Generator, uses a GP to learn priors on future states given the past and maintains a probability distribution over possible futures given a particular sample. We leverage the changes in this distribution over time to control the sampling of diverse future states by estimating the end of on-going sequences. In particular, we use the variance of GP over the output function space to trigger a change in the action sequence. We achieve state-of-the-art results on diverse future frame generation in terms of reconstruction quality and diversity of the generated sequences.",いくつかのコンテキスト（または過去）フレームを指定して将来のフレームを生成することは、困難な作業です。それには、ビデオの時間的一貫性と、潜在的な将来の状態における多様性の観点からのマルチモダリティをモデル化する必要があります。ビデオ生成のための現在の変分アプローチは、マルチモーダルの将来の結果を無視する傾向があります。代わりに、将来の結果におけるマルチモダリティを明示的にモデル化し、それを活用して多様な未来をサンプリングすることを提案します。私たちのアプローチであるDiverseVideo Generatorは、GPを使用して、過去が与えられた場合の将来の状態の事前確率を学習し、特定のサンプルが与えられた場合の可能な将来の確率分布を維持します。この分布の経時変化を利用して、進行中のシーケンスの終了を推定することにより、さまざまな将来の状態のサンプリングを制御します。特に、出力関数空間でのGPの分散を使用して、アクションシーケンスの変更をトリガーします。再構成の品質と生成されたシーケンスの多様性の観点から、多様な将来のフレーム生成に関する最先端の結果を実現します。,6.0,
Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies,"['Paul Pu Liang', 'Manzil Zaheer', 'Yuan Wang', 'Amr Ahmed']",https://openreview.net/forum?id=Vd7lCMvtLqg,"Learning continuous representations of discrete objects such as text, users, movies, and URLs lies at the heart of many applications including language and user modeling. When using discrete objects as input to neural networks, we often ignore the underlying structures (e.g. natural groupings and similarities) and embed the objects independently into individual vectors. As a result, existing methods do not scale to large vocabulary sizes. In this paper, we design a simple and efficient embedding algorithm that learns a small set of anchor embeddings and a sparse transformation matrix. We call our method Anchor & Transform (ANT) as the embeddings of discrete objects are a sparse linear combination of the anchors, weighted according to the transformation matrix. ANT is scalable, flexible, and end-to-end trainable. We further provide a statistical interpretation of our algorithm as a Bayesian nonparametric prior for embeddings that encourages sparsity and leverages natural groupings among objects. By deriving an approximate inference algorithm based on Small Variance Asymptotics, we obtain a natural extension that automatically learns the optimal number of anchors instead of having to tune it as a hyperparameter. On text classification, language modeling, and movie recommendation benchmarks, we show that ANT is particularly suitable for large vocabulary sizes and demonstrates stronger performance with fewer parameters (up to 40x compression) as compared to existing compression baselines.",テキスト、ユーザー、映画、URLなどの個別のオブジェクトの連続表現を学習することは、言語やユーザーモデリングを含む多くのアプリケーションの中心にあります。ニューラルネットワークへの入力として個別のオブジェクトを使用する場合、基礎となる構造（自然なグループ化や類似性など）を無視し、オブジェクトを個別のベクトルに個別に埋め込むことがよくあります。その結果、既存の方法は大きな語彙サイズに拡張できません。この論文では、アンカー埋め込みの小さなセットとスパース変換行列を学習する、シンプルで効率的な埋め込みアルゴリズムを設計します。離散オブジェクトの埋め込みは、変換行列に従って重み付けされたアンカーの疎な線形結合であるため、メソッドをアンカー＆変換（ANT）と呼びます。 ANTはスケーラブルで柔軟性があり、エンドツーエンドでトレーニング可能です。さらに、スパース性を促進し、オブジェクト間の自然なグループ化を活用する埋め込みのベイズノンパラメトリック事前確率として、アルゴリズムの統計的解釈を提供します。 Small Variance Asymptoticsに基づいて近似推論アルゴリズムを導出することにより、ハイパーパラメータとして調整する代わりに、アンカーの最適な数を自動的に学習する自然な拡張を取得します。テキスト分類、言語モデリング、および映画の推奨ベンチマークについて、ANTは大きな語彙サイズに特に適しており、既存の圧縮ベースラインと比較して、より少ないパラメーター（最大40倍の圧縮）でより強力なパフォーマンスを示すことを示します。,6.0,
Neural Learning of One-of-Many Solutions for Combinatorial Problems in Structured Output Spaces,"['Yatin Nandwani', 'Deepanshu Jindal', 'Mausam .', 'Parag Singla']",https://openreview.net/forum?id=ATp1nW2FuZL,"Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any ""one"" of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two-fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks,  demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.
",最近の研究では、構造化された出力空間の組み合わせ問題を解決するためのニューラルアーキテクチャが提案されています。このような問題の多くでは、特定の入力に対して複数の解決策が存在する可能性があります。たとえば、部分的に満たされた数独パズルには、すべての制約を満たす多くの完了がある場合があります。さらに、私たちはしばしば、それらの間の好みなしに、可能な解決策の「1つ」を見つけることに興味を持っています。既存のアプローチは、このソリューションの多様性を完全に無視しています。このホワイトペーパーでは、複数のソリューションの存在に気付かないと、トレーニング能力が大幅に低下する可能性があると主張します。私たちの貢献は2つあります。まず、構造化された出力空間での組み合わせ問題の多対1の解を学習するタスクを正式に定義します。これは、N-Queensや数独などの関心のあるいくつかの問題の解決に適用できます。次に、ソリューションの多様性を処理するために、組み合わせ問題に対して既存の予測ネットワークを適応させる一般的な学習フレームワークを提示します。私たちのフレームワークは、選択モジュールを使用します。その目標は、すべての入力について、任意の学習反復でネットワークパラメーターをトレーニングするのに最も効果的なソリューションを動的に決定することです。選択モジュールを予測ネットワークと共同でトレーニングするためのRLベースのアプローチを提案します。 3つの異なるドメインでの実験と、2つの異なる予測ネットワークの使用により、フレームワークが設定の精度を大幅に向上させ、ベースラインを最大21ポイント上回っていることを示しています。,6.0,https://d3i71xaburhd42.cloudfront.net/51c62d63c6204deecb24a1d3f9ea8e0a42d23817/6-Figure1-1.png
Optimism in Reinforcement Learning with Generalized Linear Function Approximation,"['Yining Wang', 'Ruosong Wang', 'Simon Shaolei Du', 'Akshay Krishnamurthy']",https://openreview.net/forum?id=CBmJwzneppz,"We design a new provably efficient algorithm for episodic reinforcement learning with generalized linear function approximation. We analyze the algorithm under a new expressivity assumption that we call ""optimistic closure,"" which is strictly weaker than assumptions from prior analyses for the linear setting. With optimistic closure, we prove that our algorithm enjoys a regret bound of $\tilde{O}(\sqrt{d^3T})$ where d is the dimensionality of the state-action features and T is the number of episodes. This is the first statistically and computationally efficient algorithm for reinforcement learning with generalized linear functions.",一般化線形関数近似を使用して、エピソード強化学習のための新しい証明可能な効率的なアルゴリズムを設計します。 「楽観的クロージャ」と呼ばれる新しい表現力の仮定の下でアルゴリズムを分析します。これは、線形設定の以前の分析からの仮定よりも厳密に弱いものです。楽観的なクロージャを使用して、アルゴリズムが$ \ tilde {O}（\ sqrt {d ^ 3T}）$の後悔の限界を享受していることを証明します。ここで、dは状態アクション特徴の次元であり、Tはエピソードの数です。これは、一般化線形関数を使用した強化学習のための最初の統計的および計算的に効率的なアルゴリズムです。,6.0,
CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding,"['Yanru Qu', 'Dinghan Shen', 'Yelong Shen', 'Sandra Sajeev', 'Weizhu Chen', 'Jiawei Han']",https://openreview.net/forum?id=Ozk9MrX1hvA,"Data augmentation has been demonstrated as an effective strategy for improving model generalization and data efficiency.  However, due to the discrete nature of natural language, designing label-preserving transformations for text data tends to be more challenging. In this paper, we propose a novel data augmentation frame-work dubbed CoDA, which synthesizes diverse and informative augmented examples by integrating multiple transformations organically.  Moreover, a contrastive regularization is introduced to capture the global relationship among all the data samples.  A momentum encoder along with a memory bank is further leveraged to better estimate the contrastive loss. To verify the effectiveness of the proposed framework, we apply CoDA to Transformer-based models on a wide range of natural language understanding tasks. On the GLUE benchmark, CoDA gives rise to an average improvement of 2.2%while applied to the Roberta-large model. More importantly, it consistently exhibits stronger results relative to several competitive data augmentation and adversarial training baselines (including the low-resource settings). Extensive experiments show that the proposed contrastive objective can be flexibly combined with various data augmentation approaches to further boost their performance, highlighting the wide applicability of the CoDA framework.",データの拡張は、モデルの一般化とデータ効率を改善するための効果的な戦略として実証されています。ただし、自然言語は離散的であるため、テキストデータのラベル保存変換の設計はより困難になる傾向があります。この論文では、CoDAと呼ばれる新しいデータ拡張フレームワークを提案します。これは、複数の変換を有機的に統合することにより、多様で有益な拡張例を合成します。さらに、対照的な正則化が導入され、すべてのデータサンプル間のグローバルな関係がキャプチャされます。運動量エンコーダとメモリバンクをさらに活用して、対照的な損失をより正確に推定します。提案されたフレームワークの有効性を検証するために、CoDAをさまざまな自然言語理解タスクのTransformerベースのモデルに適用します。 GLUEベンチマークでは、CoDAにより平均2.2の改善が見られます。,6.0,https://d3i71xaburhd42.cloudfront.net/77f08ec1fc1a26d5e2c493be06a305d1480ad1c0/3-Figure1-1.png
Accurate Learning of Graph Representations with Graph Multiset Pooling,"['Jinheon Baek', 'Minki Kang', 'Sung Ju Hwang']",https://openreview.net/forum?id=JHcqXGaqiGn,"Message-passing graph neural networks have been widely used on modeling graph data, achieving impressive results on a number of graph classification and link prediction tasks. Yet, obtaining an accurate representation for a graph further requires a well-defined pooling function that maps the set of node representations into a compact form, without information loss of the individual node features and the global graph structure. A simple sum or average over all node representations considers all node features equally without consideration of their task relevance, and any structural dependencies among them. Recently proposed hierarchical graph pooling methods, on the other hand, may yield the same representation for two different graphs that are distinguished by the Weisfeiler-Lehman test, as they suboptimally preserve information from the node features. To tackle these limitations of existing graph pooling methods, we first formulate the graph pooling problem as a multiset encoding problem with auxiliary information about the graph structure, and propose a Graph Multiset Transformer (GMT) which is a multi-head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. We show that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods can be easily extended to the previous node clustering approaches for hierarchical graph pooling. Our experimental results show that GMT significantly outperforms state-of-the-art graph pooling methods on graph classification benchmarks with high memory efficiency, and obtains even larger performance gain on graph reconstruction and generation tasks, which more directly measure the expressiveness of graph pooling methods.",メッセージパッシンググラフニューラルネットワークは、グラフデータのモデリングに広く使用されており、多くのグラフ分類およびリンク予測タスクで印象的な結果を達成しています。ただし、グラフの正確な表現を取得するには、個々のノード機能とグローバルグラフ構造の情報を失うことなく、ノード表現のセットをコンパクトな形式にマッピングする明確に定義されたプーリング関数がさらに必要です。すべてのノード表現の単純な合計または平均は、タスクの関連性やそれらの間の構造的な依存関係を考慮せずに、すべてのノード機能を等しく考慮します。一方、最近提案された階層グラフプーリング方法は、ノードの特徴からの情報を最適に保持しないため、Weisfeiler-Lehmanテストによって区別される2つの異なるグラフに対して同じ表現を生成する可能性があります。既存のグラフプーリング方法のこれらの制限に取り組むために、まずグラフプーリング問題をグラフ構造に関する補助情報を含むマルチセットエンコーディング問題として定式化し、マルチヘッドアテンションベースのグローバルプーリングレイヤーであるグラフマルチセットトランスフォーマー（GMT）を提案します。構造的な依存関係に従ってノード間の相互作用をキャプチャします。 GMTは、注入性と順列不変性の両方を満たし、Weisfeiler-Lehmanグラフ同型検定と同じくらい強力であることを示します。さらに、私たちの方法は、階層グラフプーリングのための以前のノードクラスタリングアプローチに簡単に拡張できます。私たちの実験結果は、GMTが、高いメモリ効率を備えたグラフ分類ベンチマークで最先端のグラフプーリング手法を大幅に上回り、グラフの再構築および生成タスクでさらに大きなパフォーマンスの向上を実現し、グラフプーリング手法の表現力をより直接的に測定することを示しています。 。,6.0,
Combining Physics and Machine Learning for Network Flow Estimation,"['Arlei Lopes da Silva', 'Furkan Kocayusufoglu', 'Saber Jafarpour', 'Francesco Bullo', 'Ananthram Swami', 'Ambuj Singh']",https://openreview.net/forum?id=l0V53bErniB,"The flow estimation problem consists of predicting missing edge flows in a network (e.g., traffic, power and water) based on partial observations. These missing flows depend both on the underlying physics (edge features and a flow conservation law) as well as the observed edge flows. This paper introduces an optimization framework for computing missing flows and solves the problem using bilevel optimization and deep learning. Empirical results show that the method accurately predicts missing flows, outperforming the best baseline by up to 20%, and is able to capture relevant physical properties in traffic and power networks.",フロー推定の問題は、部分的な観測に基づいて、ネットワーク内の欠落しているエッジフロー（トラフィック、電力、水など）を予測することで構成されます。これらの欠落したフローは、基礎となる物理学（エッジの特徴とフロー保存則）と、観測されたエッジフローの両方に依存します。このホワイトペーパーでは、欠落しているフローを計算するための最適化フレームワークを紹介し、バイレベル最適化とディープラーニングを使用して問題を解決します。経験的結果は、この方法が欠落しているフローを正確に予測し、最良のベースラインを最大20回上回っていることを示しています。,6.0,
VA-RED$^2$: Video Adaptive Redundancy Reduction,"['Bowen Pan', 'Rameswar Panda', 'Camilo Luciano Fosco', 'Chung-Ching Lin', 'Alex J Andonian', 'Yue Meng', 'Kate Saenko', 'Aude Oliva', 'Rogerio Feris']",https://openreview.net/forum?id=g21u6nlbPzn,"Performing inference on deep learning models for videos remains a challenge due to the large amount of computational resources required to achieve robust recognition. An inherent property of real-world videos is the high correlation of information across frames which can translate into redundancy in either temporal or spatial feature maps of the models, or both. The type of redundant features depends on the dynamics and type of events in the video: static videos have more temporal redundancy while videos focusing on objects tend to have more channel redundancy. Here we present a redundancy reduction framework, termed VA-RED$^2$, which is {\em input-dependent}. Specifically, our VA-RED$^2$ framework uses an input-dependent policy to decide how many features need to be computed for temporal and channel dimensions. To keep the capacity of the original model, after fully computing the necessary features, we reconstruct the remaining redundant features from those using cheap operations. We learn the adaptive policy jointly with the network weights in a differentiable way with a shared-weight mechanism, making it highly efficient. Extensive experiments on multiple video datasets and different visual tasks show that our framework achieves $20\% - 40\%$ reduction in computation (FLOPs) when compared to state-of-the-art methods without any performance loss.",ビデオの深層学習モデルで推論を実行することは、堅牢な認識を実現するために大量の計算リソースが必要になるため、依然として課題です。実世界のビデオに固有の特性は、フレーム間の情報の高い相関関係であり、モデルの時間的または空間的特徴マップ、あるいはその両方の冗長性に変換できます。冗長機能のタイプは、ビデオのダイナミクスとイベントのタイプによって異なります。静的ビデオは時間的冗長性が高く、オブジェクトに焦点を当てたビデオはチャネル冗長性が高い傾向があります。ここでは、入力に依存するVA-RED2と呼ばれる冗長性削減フレームワークを紹介します。具体的には、VA-RED2フレームワークは、入力に依存するポリシーを使用して、時間次元とチャネル次元に対して計算する必要のある特徴の数を決定します。元のモデルの容量を維持するために、必要な機能を完全に計算した後、安価な操作を使用する機能から残りの冗長な機能を再構築します。共有ウェイトメカニズムを使用して差別化可能な方法でネットワークウェイトと共同で適応ポリシーを学習し、非常に効率的にします。複数のビデオデータセットとさまざまな視覚的タスクに関する広範な実験により、パフォーマンスを低下させることなく、最先端の方法と比較した場合、フレームワークが計算（FLOP）を20％40％削減できることが示されています。,6.0,
"On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines","['Marius Mosbach', 'Maksym Andriushchenko', 'Dietrich Klakow']",https://openreview.net/forum?id=nzpLWnVAyah,"Fine-tuning pre-trained transformer-based language models such as BERT has become a common practice dominating leaderboards across various NLP benchmarks. Despite the strong empirical performance of fine-tuned models, fine-tuning is an unstable process: training the same model with multiple random seeds can result in a large variance of the task performance. Previous literature (Devlin et al., 2019; Lee et al., 2020; Dodge et al., 2020) identified two potential reasons for the observed instability: catastrophic forgetting and small size of the fine-tuning datasets. In this paper, we show that both hypotheses fail to explain the fine-tuning instability. We analyze BERT, RoBERTa, and ALBERT, fine-tuned on commonly used datasets from the GLUE benchmark, and show that the observed instability is caused by optimization difficulties that lead to vanishing gradients. Additionally, we show that the remaining variance of the downstream task performance can be attributed to differences in generalization where fine-tuned models with the same training loss exhibit noticeably different test performance. Based on our analysis, we present a simple but strong baseline that makes fine-tuning BERT-based models significantly more stable than the previously proposed approaches.",BERTなどの事前トレーニング済みのトランスベースの言語モデルを微調整することは、さまざまなNLPベンチマーク全体でリーダーボードを支配する一般的な方法になっています。微調整されたモデルの強力な経験的パフォーマンスにもかかわらず、微調整は不安定なプロセスです。複数のランダムシードを使用して同じモデルをトレーニングすると、タスクのパフォーマンスに大きなばらつきが生じる可能性があります。以前の文献（Devlin et al。、2019; Lee et al。、2020; Dodge et al。、2020）は、観察された不安定性の2つの潜在的な理由を特定しました：壊滅的な忘却と微調整データセットの小さいサイズ。この論文では、両方の仮説が微調整の不安定性を説明できないことを示しています。 GLUEベンチマークから一般的に使用されるデータセットで微調整されたBERT、RoBERTa、およびALBERTを分析し、観測された不安定性が勾配消失につながる最適化の問題によって引き起こされることを示します。さらに、ダウンストリームタスクのパフォーマンスの残りの分散は、同じトレーニング損失を持つ微調整されたモデルが著しく異なるテストパフォーマンスを示す一般化の違いに起因する可能性があることを示します。私たちの分析に基づいて、BERTベースのモデルを以前に提案されたアプローチよりも大幅に安定させるシンプルで強力なベースラインを提示します。,6.0,https://d3i71xaburhd42.cloudfront.net/8b9d77d5e52a70af37451d3db3d32781b83ea054/2-Figure1-1.png
Remembering for the Right Reasons: Explanations Reduce Catastrophic Forgetting,"['Sayna Ebrahimi', 'Suzanne Petryk', 'Akash Gokul', 'William Gan', 'Joseph E. Gonzalez', 'Marcus Rohrbach', 'trevor darrell']",https://openreview.net/forum?id=tHgJoMfy6nI,"The goal of continual learning (CL) is to learn a sequence of tasks without suffering from the phenomenon of catastrophic forgetting. Previous work has shown that leveraging memory in the form of a replay buffer can reduce performance degradation on prior tasks. We hypothesize that forgetting can be further reduced when the model is encouraged to remember the evidence for previously made decisions. As a first step towards exploring this hypothesis, we propose a simple novel training paradigm, called Remembering for the Right Reasons (RRR), that additionally stores visual model explanations for each example in the buffer and ensures the model has ``the right reasons'' for its predictions by encouraging its explanations to remain consistent with those used to make decisions at training time. Without this constraint, there is a drift in explanations and increase in forgetting as conventional continual learning algorithms learn new tasks. We demonstrate how RRR can be easily added to any memory or regularization-based approach and results in reduced forgetting, and more importantly, improved model explanations. We have evaluated our approach in the standard and few-shot settings and observed a consistent improvement across various CL approaches using different architectures and techniques to generate model explanations and demonstrated our approach showing a promising connection between explainability and continual learning. Our code is attached in the supplementary materials.",継続学習（CL）の目標は、壊滅的な忘却の現象に悩まされることなく、一連のタスクを学習することです。以前の作業では、再生バッファーの形でメモリを活用することで、以前のタスクのパフォーマンスの低下を減らすことができることが示されています。モデルが以前に行われた決定の証拠を記憶するように促されると、忘却をさらに減らすことができると仮定します。この仮説を探求するための最初のステップとして、Remembering for the Right Reasons（RRR）と呼ばれる単純な新しいトレーニングパラダイムを提案します。これは、各例の視覚的なモデルの説明をバッファーに追加で保存し、モデルに予測の正しい理由があることを確認します。トレーニング時に決定を下すために使用される説明と一貫性を保つように説明を奨励することによって。この制約がないと、従来の継続学習アルゴリズムが新しいタスクを学習するため、説明にドリフトが生じ、忘却が増加します。 RRRをメモリまたは正則化ベースのアプローチに簡単に追加して、忘却を減らし、さらに重要なことに、モデルの説明を改善する方法を示します。標準設定と数ショット設定でアプローチを評価し、さまざまなアーキテクチャと手法を使用してモデルの説明を生成するさまざまなCLアプローチ全体で一貫した改善を観察し、説明可能性と継続的な学習の間の有望な関係を示すアプローチを示しました。私たちのコードは補足資料に添付されています。,6.0,https://d3i71xaburhd42.cloudfront.net/c31d46f13cc9e5212e1cffd6e2fbc17fdf5d5ba9/2-Figure1-1.png
Greedy-GQ with Variance Reduction: Finite-time Analysis and Improved Complexity,"['Shaocong Ma', 'Ziyi Chen', 'Yi Zhou', 'Shaofeng Zou']",https://openreview.net/forum?id=6t_dLShIUyZ,"Greedy-GQ is a value-based reinforcement learning (RL) algorithm for optimal control. Recently, the finite-time analysis of Greedy-GQ has been developed under linear function approximation and Markovian sampling, and the algorithm is shown to achieve an $\epsilon$-stationary point with a sample complexity in the order of $\mathcal{O}(\epsilon^{-3})$. Such a high sample complexity is due to the large variance induced by the Markovian samples. In this paper, we propose a variance-reduced Greedy-GQ (VR-Greedy-GQ) algorithm for off-policy optimal control. In particular, the algorithm applies the SVRG-based variance reduction scheme to reduce the stochastic variance of the two time-scale updates. We study the finite-time convergence of VR-Greedy-GQ under linear function approximation and Markovian sampling and show that the algorithm achieves a much smaller bias and variance error than the original Greedy-GQ. In particular, we prove that VR-Greedy-GQ achieves an improved sample complexity that is in the order of $\mathcal{O}(\epsilon^{-2})$. We further compare the performance of VR-Greedy-GQ with that of Greedy-GQ in various RL experiments to corroborate our theoretical findings.",Greedy-GQは、最適制御のための値ベースの強化学習（RL）アルゴリズムです。最近、Greedy-GQの有限時間解析が線形関数近似とマルコフサンプリングの下で​​開発され、アルゴリズムはO（^（3））のオーダーのサンプル複雑さで停留点を達成することが示されています。このような高いサンプルの複雑さは、マルコフサンプルによって引き起こされる大きな分散によるものです。この論文では、ポリシー外の最適制御のための分散減少Greedy-GQ（VR-Greedy-GQ）アルゴリズムを提案します。特に、アルゴリズムはSVRGベースの分散削減スキームを適用して、2つのタイムスケール更新の確率的分散を削減します。線形関数近似とマルコフサンプリングの下で​​VR-Greedy-GQの有限時間収束を研究し、アルゴリズムが元のGreedy-GQよりもはるかに小さい偏りと分散誤差を達成することを示します。特に、VR-Greedy-GQがO（^（2））のオーダーのサンプルの複雑さを改善することを証明します。さらに、VR-Greedy-GQのパフォーマンスをさまざまなRL実験でGreedy-GQのパフォーマンスと比較して、理論的な発見を裏付けています。,6.0,
Loss Function Discovery for Object Detection via Convergence-Simulation Driven Search,"['Peidong Liu', 'Gengwei Zhang', 'Bochao Wang', 'Hang Xu', 'Xiaodan Liang', 'Yong Jiang', 'Zhenguo Li']",https://openreview.net/forum?id=5jzlpHvvRk,"Designing proper loss functions for vision tasks has been a long-standing research direction to advance the capability of existing models. For object detection, the well-established classification and regression loss functions have been carefully designed by considering diverse learning challenges (e.g. class imbalance, hard negative samples, and scale variances). Inspired by the recent progress in network architecture search, it is interesting to explore the possibility of discovering new loss function formulations via directly searching the primitive operation combinations. So that the learned losses not only fit for diverse object detection challenges to alleviate huge human efforts, but also have better alignment with evaluation metric and good mathematical convergence property. Beyond the previous auto-loss works on face recognition and image classification, our work makes the first attempt to discover new loss functions for the challenging object detection from primitive operation levels and finds the searched losses are insightful. We propose an effective convergence-simulation driven evolutionary search algorithm, called CSE-Autoloss, for speeding up the search progress by regularizing the mathematical rationality of loss candidates via two progressive convergence simulation modules: convergence property verification and model optimization simulation. CSE-Autoloss involves the search space (i.e. 20 mathematical operators, 3 constant-type inputs, and 3 variable-type inputs) that cover a wide range of the possible variants of existing losses and discovers best-searched loss function combination within a short time (around 1.5 wall-clock days with 20x speedup in comparison to the vanilla evolutionary algorithm). We conduct extensive evaluations of loss function search on popular detectors and validate the good generalization capability of searched losses across diverse architectures and various datasets. Our experiments show that the best-discovered loss function combinations outperform default combinations (Cross-entropy/Focal loss for classification and L1 loss for regression) by 1.1% and 0.8% in terms of mAP for two-stage and one-stage detectors on COCO respectively.",視覚タスクの適切な損失関数を設計することは、既存のモデルの機能を向上させるための長年の研究の方向性です。オブジェクト検出では、確立された分類関数と回帰損失関数が、さまざまな学習課題（クラスの不均衡、ハードネガティブサンプル、スケールの分散など）を考慮して慎重に設計されています。ネットワークアーキテクチャ検索の最近の進歩に触発されて、プリミティブ操作の組み合わせを直接検索することにより、新しい損失関数の定式化を発見する可能性を探求することは興味深いことです。そのため、学習した損失は、人間の多大な労力を軽減するためのさまざまなオブジェクト検出の課題に適合するだけでなく、評価メトリックおよび優れた数学的収束特性との整合性も向上します。顔認識と画像分類に関する以前の自動損失作業に加えて、私たちの作業は、原始的な操作レベルからの挑戦的なオブジェクト検出のための新しい損失関数を発見する最初の試みを行い、検索された損失が洞察に満ちていることを発見します。収束特性検証とモデル最適化シミュレーションの2つのプログレッシブ収束シミュレーションモジュールを介して損失候補の数学的合理性を正規化することにより、検索の進行を高速化するための、CSE-Autolossと呼ばれる効果的な収束シミュレーション駆動型進化的検索アルゴリズムを提案します。 CSE-Autolossは、既存の損失の可能なバリアントの広い範囲をカバーし、短時間で最もよく検索された損失関数の組み合わせを発見する検索スペース（つまり、20の数学演算子、3つの定数型入力、および3つの可変型入力）を含みます。 （バニラ進化的アルゴリズムと比較して20倍のスピードアップで約1.5壁時計日）。人気のある検出器で損失関数検索の広範な評価を実施し、さまざまなアーキテクチャとさまざまなデータセットにわたって検索された損失の優れた一般化機能を検証します。私たちの実験では、最もよく発見された損失関数の組み合わせが、デフォルトの組み合わせ（分類のクロスエントロピー/焦点損失および回帰のL1損失）よりも1.1優れていることが示されています。,6.0,
CO2: Consistent Contrast for Unsupervised Visual Representation Learning,"['Chen Wei', 'Huiyu Wang', 'Wei Shen', 'Alan Yuille']",https://openreview.net/forum?id=U4XLJhqwNF1,"Contrastive learning has been adopted as a core method for unsupervised visual representation learning. Without human annotation, the common practice is to perform an instance discrimination task: Given a query image crop, this task labels crops from the same image as positives, and crops from other randomly sampled images as negatives. An important limitation of this label assignment strategy is that it can not reflect the heterogeneous similarity between the query crop and each crop from other images, taking them as equally negative, while some of them may even belong to the same semantic class of the query. To address this issue, inspired by consistency regularization in semi-supervised learning on unlabeled data, we propose Consistent Contrast (CO2), which introduces a consistency regularization term into the current contrastive learning framework. Regarding the similarity of the query crop to each crop from other images as ``unlabeled'', the consistency term takes the corresponding similarity of a positive crop as a pseudo label and encourages consistency between these two similarities. Empirically, CO2 improves Momentum Contrast (MoCo) by 2.9% top-1 accuracy on ImageNet linear protocol, 3.8% and 1.1% top-5 accuracy on 1% and 10% labeled semi-supervised settings. It also transfers to image classification, object detection, and semantic segmentation on PASCAL VOC. This shows that CO2 learns better visual representations for these downstream tasks.",対照学習は、教師なし視覚表現学習のコアメソッドとして採用されています。人間による注釈がない場合、一般的な方法はインスタンス識別タスクを実行することです。クエリ画像のトリミングが与えられると、このタスクは同じ画像からのトリミングをポジティブとしてラベル付けし、他のランダムにサンプリングされた画像からのトリミングをネガティブとしてラベル付けします。このラベル割り当て戦略の重要な制限は、クエリクロップと他の画像の各クロップとの間の不均一な類似性を反映できず、それらを等しくネガティブと見なし、クエリの同じセマンティッククラスに属するものもあることです。この問題に対処するために、ラベルなしデータの半教師あり学習における一貫性の正則化に触発されて、現在の対照的な学習フレームワークに一貫性の正則化項を導入する一貫性のあるコントラスト（CO2）を提案します。クエリクロップと他の画像の各クロップとの類似性をラベルなしとして、一貫性の用語は、ポジティブクロップの対応する類似性を疑似ラベルとして取り、これら2つの類似性間の一貫性を促進します。経験的に、CO2は運動量コントラスト（MoCo）を2.9改善します,6.0,https://d3i71xaburhd42.cloudfront.net/b6f54f6d3a0cb9d3f1244c63773c40b0f5a1e224/3-Figure1-1.png
CT-Net: Channel Tensorization Network for Video Classification,"['Kunchang Li', 'Xianhang Li', 'Yali Wang', 'Jun Wang', 'Yu Qiao']",https://openreview.net/forum?id=UoaQUQREMOs,"3D convolution is powerful for video classification but often computationally expensive, recent studies mainly focus on decomposing it on spatial-temporal and/or channel dimensions.  Unfortunately,  most approaches fail to achieve a preferable balance between convolutional efficiency and feature-interaction sufficiency.  For this reason,  we propose a concise and novel Channel Tensorization Network (CT-Net),  by treating the channel dimension of input feature as a multiplication of K sub-dimensions. On one hand,  it naturally factorizes convolution in a multiple dimension way,  leading to a light computation burden.  On the other hand, it can effectively enhance feature interaction from different channels,  and progressively enlarge the 3D receptive field of such interaction to boost classification accuracy.  Furthermore, we equip our CT-Module with a Tensor Excitation (TE) mechanism. It can learn to exploit spatial, temporal and channel attention in a high-dimensional manner, to improve the cooperative power of all the feature dimensions in our CT-Module. Finally, we flexibly adapt ResNet as our CT-Net. Extensive experiments are conducted on several challenging video benchmarks, e.g., Kinetics-400, Something-Something V1 and V2. Our CT-Net outperforms a number of recent SOTA approaches, in terms of accuracy and/or efficiency.",3D畳み込みはビデオ分類には強力ですが、多くの場合計算コストが高く、最近の研究では主に時空間および/またはチャネル次元での分解に焦点が当てられています。残念ながら、ほとんどのアプローチでは、畳み込み効率と機能の相互作用の十分性の間で好ましいバランスをとることができません。このため、入力特徴のチャネル次元をK個のサブ次元の乗算として扱うことにより、簡潔で新しいチャネルテンソリゼーションネットワーク（CT-Net）を提案します。一方では、畳み込みを多次元の方法で自然に因数分解し、計算の負担を軽くします。一方、異なるチャネルからの特徴の相互作用を効果的に強化し、そのような相互作用の3D受容野を徐々に拡大して、分類の精度を高めることができます。さらに、CTモジュールにテンソル励起（TE）メカニズムを装備しています。 CTモジュールのすべての特徴次元の協調力を向上させるために、空間的、時間的、およびチャネルの注意を高次元的に活用することを学ぶことができます。最後に、ResNetをCT-Netとして柔軟に適応させます。 Kinetics-400、Something-Something V1、V2など、いくつかの挑戦的なビデオベンチマークで広範な実験が行われます。当社のCT-Netは、精度や効率の点で、最近の多くのSOTAアプローチよりも優れています。,6.0,
MixKD: Towards Efficient Distillation of Large-scale Language Models,"['Kevin J Liang', 'Weituo Hao', 'Dinghan Shen', 'Yufan Zhou', 'Weizhu Chen', 'Changyou Chen', 'Lawrence Carin']",https://openreview.net/forum?id=UFGEelJkLu5,"Large-scale language models have demonstrated impressive empirical performance in recent years. Nevertheless, the improved results are attained at the price of bigger size, more power consumption, and slower inference, which hinder their applicability to low-resource (memory and computation) platforms. Knowledge distillation (KD) has been demonstrated as an effective framework for compressing such big models. However, large-scale neural network systems are prone to memorizing training instances, and thus tend to make inconsistent predictions when the data distribution is slightly altered. Moreover, the student model has few opportunities to request useful information from teacher model when there is limited task-specific data available. To address these issues, we propose MixKD, a data-agnostic distillation framework that leverages Mixup, a simple yet efficient data augmentation approach, to endow the resulting model with stronger generalization ability. Concretely, in addition to the original training examples, the student model is encouraged to mimic teacher's behaviour on the linear interpolations of example pairs as well. We prove, from a theoretical perspective, that MixKD gives rise to a smaller gap between the generalization error and the empirical error. To verify its effectiveness, we conduct extensive experiments on the GLUE benchmark, where MixKD consistently leads to significant gains over the standard KD training, and outperforms several competitive baselines. Experiments under a limited-data setting and ablation studies further demonstrate the advantages of the proposed approach.",大規模な言語モデルは、近年、印象的な経験的パフォーマンスを示しています。それにもかかわらず、改善された結果は、より大きなサイズ、より多くの電力消費、およびより遅い推論の代償で達成され、それは低リソース（メモリおよび計算）プラットフォームへのそれらの適用を妨げる。知識蒸留（KD）は、このような大きなモデルを圧縮するための効果的なフレームワークとして実証されています。ただし、大規模なニューラルネットワークシステムはトレーニングインスタンスを記憶する傾向があるため、データ分布がわずかに変更されると、一貫性のない予測を行う傾向があります。さらに、利用可能なタスク固有のデータが限られている場合、学生モデルには教師モデルに有用な情報を要求する機会がほとんどありません。これらの問題に対処するために、MixKDを提案します。これは、シンプルでありながら効率的なデータ拡張アプローチであるMixupを活用して、結果のモデルに強力な一般化機能を与える、データに依存しない蒸留フレームワークです。具体的には、元のトレーニング例に加えて、学生モデルは、例のペアの線形補間でも教師の行動を模倣することが推奨されます。理論的な観点から、MixKDが汎化誤差と経験的誤差の間に小さなギャップを生じさせることを証明します。その有効性を検証するために、GLUEベンチマークで広範な実験を実施します。ここで、MixKDは、標準のKDトレーニングよりも一貫して大幅な向上をもたらし、いくつかの競合ベースラインを上回っています。限られたデータ設定とアブレーション研究の下での実験は、提案されたアプローチの利点をさらに示しています。,6.0,https://d3i71xaburhd42.cloudfront.net/e8f6eb89897c5880a99748f23c3d3763346eea45/7-Figure1-1.png
Learning Subgoal Representations with Slow Dynamics,"['Siyuan Li', 'Lulu Zheng', 'Jianhao Wang', 'Chongjie Zhang']",https://openreview.net/forum?id=wxRwhSdORKG,"In goal-conditioned Hierarchical Reinforcement Learning (HRL), a high-level policy periodically sets subgoals for a low-level policy, and the low-level policy is trained to reach those subgoals. A proper subgoal representation function, which abstracts a state space to a latent subgoal space, is crucial for effective goal-conditioned HRL, since different low-level behaviors are induced by reaching subgoals in the compressed representation space. Observing that the high-level agent operates at an abstract temporal scale, we propose a slowness objective to effectively learn the subgoal representation (i.e., the high-level action space). We provide a theoretical grounding for the slowness objective. That is, selecting slow features as the subgoal space can achieve efficient hierarchical exploration. As a result of better exploration ability, our approach significantly outperforms state-of-the-art HRL and exploration methods on a number of benchmark continuous-control tasks. Thanks to the generality of the proposed subgoal representation learning method, empirical results also demonstrate that the learned representation and corresponding low-level policies can be transferred between distinct tasks.",目標条件付き階層強化学習（HRL）では、高レベルのポリシーが定期的に低レベルのポリシーのサブゴールを設定し、低レベルのポリシーがそれらのサブゴールに到達するようにトレーニングされます。状態空間を潜在的なサブゴール空間に抽象化する適切なサブゴール表現関数は、圧縮された表現空間のサブゴールに到達することによってさまざまな低レベルの動作が誘発されるため、効果的なゴール条件付きHRLにとって重要です。高レベルのエージェントが抽象的な時間スケールで動作することを観察して、サブゴール表現（つまり、高レベルのアクション空間）を効果的に学習するためのスローネス目標を提案します。スローネス目標の理論的根拠を提供します。つまり、サブゴールスペースとして低速のフィーチャを選択すると、効率的な階層探索を実現できます。より優れた探査能力の結果として、私たちのアプローチは、多くのベンチマーク連続制御タスクにおいて、最先端のHRLおよび探査方法を大幅に上回っています。提案されたサブゴール表現学習方法の一般性のおかげで、経験的結果は、学習された表現と対応する低レベルのポリシーが異なるタスク間で転送できることも示しています。,6.0,
Exploring the Uncertainty Properties of Neural NetworksвЂ™ Implicit Priors in the Infinite-Width Limit,"['Ben Adlam', 'Jaehoon Lee', 'Lechao Xiao', 'Jeffrey Pennington', 'Jasper Snoek']",https://openreview.net/forum?id=MjvduJCsE4,"Modern deep learning models have achieved great success in predictive accuracy for many data modalities. However, their application to many real-world tasks is restricted by poor uncertainty estimates, such as overconfidence on out-of-distribution (OOD) data and ungraceful failing under distributional shift. Previous benchmarks have found that ensembles of neural networks (NNs) are typically the best calibrated models on OOD data. Inspired by this, we leverage recent theoretical advances that characterize the function-space prior of an infinitely-wide NN as a Gaussian process, termed the neural network Gaussian process (NNGP). We use the NNGP with a softmax link function to build a probabilistic model for multi-class classification and marginalize over the latent Gaussian outputs to sample from the posterior. This gives us a better understanding of the implicit prior NNs place on function space and allows a direct comparison of the calibration of the NNGP and its finite-width analogue. We also examine the calibration of previous approaches to classification with the NNGP, which treat classification problems as regression to the one-hot labels. In this case the Bayesian posterior is exact, and we compare several heuristics to generate a categorical distribution over classes. We find these methods are well calibrated under distributional shift. Finally, we consider an infinite-width final layer in conjunction with a pre-trained embedding. This replicates the important practical use case of transfer learning and allows scaling to significantly larger datasets. As well as achieving competitive predictive accuracy, this approach is better calibrated than its finite width analogue.",最新の深層学習モデルは、多くのデータモダリティの予測精度で大きな成功を収めています。ただし、多くの実際のタスクへの適用は、不確実性の見積もりが不十分であるために制限されています。たとえば、配布外（OOD）データに対する信頼の過大さや、配布シフトの下での不当な失敗などです。以前のベンチマークでは、ニューラルネットワーク（NN）のアンサンブルは、通常、OODデータで最適に調整されたモデルであることがわかっています。これに触発されて、ニューラルネットワークガウス過程（NNGP）と呼ばれるガウス過程として無限幅のNNの前の関数空間を特徴付ける最近の理論的進歩を活用します。ソフトマックスリンク関数を備えたNNGPを使用して、マルチクラス分類の確率モデルを構築し、潜在ガウス出力を周辺化して、後方からサンプリングします。これにより、関数空間に配置された暗黙の以前のNNをよりよく理解でき、NNGPとその有限幅のアナログのキャリブレーションを直接比較できます。また、分類の問題をワンホットラベルへの回帰として扱うNNGPを使用した分類への以前のアプローチのキャリブレーションについても検討します。この場合、ベイズ事後確率は正確であり、いくつかのヒューリスティックを比較して、クラス全体のカテゴリ分布を生成します。これらのメソッドは、分布シフトの下で適切に調整されていることがわかります。最後に、事前にトレーニングされた埋め込みと組み合わせて、無限幅の最終レイヤーを検討します。これは、転移学習の重要な実用的なユースケースを複製し、非常に大きなデータセットへのスケーリングを可能にします。このアプローチは、競争力のある予測精度を達成するだけでなく、有限幅のアナログよりも適切に調整されています。,6.0,
Usable Information and Evolution of Optimal Representations During Training,"['Michael Kleinman', 'Alessandro Achille', 'Daksh Idnani', 'Jonathan Kao']",https://openreview.net/forum?id=p8agn6bmTbr,"We introduce a notion of usable information contained in the representation learned by a deep network, and use it to study how optimal representations for the task emerge during training, and how they adapt to different tasks. We use this to characterize the transient dynamics of deep neural networks on perceptual decision-making tasks inspired by neuroscience literature, as well as on standard image classification tasks. We show that both the random initialization and the implicit regularization from Stochastic Gradient Descent play an important role in learning minimal sufficient representations for the task. In addition, we evaluate how perturbing the initial part of training impacts the learning dynamics and resulting representations.",深いネットワークによって学習された表現に含まれる使用可能な情報の概念を紹介し、それを使用して、トレーニング中にタスクに最適な表現がどのように現れるか、およびそれらがさまざまなタスクにどのように適応するかを研究します。これを使用して、神経科学の文献に触発された知覚的意思決定タスク、および標準的な画像分類タスクで、ディープニューラルネットワークの一時的なダイナミクスを特徴付けます。確率的勾配降下法からのランダムな初期化と暗黙の正則化の両方が、タスクの最小限の十分な表現を学習する上で重要な役割を果たすことを示します。さらに、トレーニングの最初の部分の摂動が学習ダイナミクスと結果の表現にどのように影響するかを評価します。,6.0,https://d3i71xaburhd42.cloudfront.net/a4d9cd56e50c62d1cd00422eb6ad1fb85ad7a0a1/3-Figure1-1.png
Simple Spectral Graph Convolution,"['Hao Zhu', 'Piotr Koniusz']",https://openreview.net/forum?id=CYO5T-YjWZV,"Graph Convolutional Networks (GCNs) have drawn significant attention and become leading methods for learning graph representations. The most GCNs  suffer the performance loss when the depth of the model increases. Similarly to CNNs, without specially designed architectures, the performance of a network degrades quickly with increased depth. Some researchers argue  that  the required neighbourhood size and neural network depth are two completely orthogonal aspects of graph representation. Thus, several methods extend the neighbourhood by aggregating $k$-hop neighbourhoods of nodes while using shallow neural networks. However, these methods still encounter oversmoothing, high computation and storage costs. In this paper, we use a modified Markov Diffusion Kernel to derive a variant of GCN called Simple Spectral Graph Convolution (S2GC). Our spectral analysis shows that our simple spectral graph convolution used in S2GC is a trade-off of low-pass and high-pass filter which captures the global and local contexts of each node. We provide two theoretical claims which demonstrate that we can aggregate over a sequence of increasingly larger neighborhoods compared to competitors while limiting severe oversmoothing.

Our experimental evaluation demonstrates that S2GC with a linear learner is competitive in text, node and graph classification tasks. Moreover, S2GC is comparable to other state-of-the-art methods for node clustering and community prediction tasks. ",グラフ畳み込みネットワーク（GCN）は大きな注目を集めており、グラフ表現を学習するための主要な方法になっています。ほとんどのGCNは、モデルの深さが増すとパフォーマンスが低下します。 CNNと同様に、特別に設計されたアーキテクチャがないと、ネットワークのパフォーマンスは深度が増すにつれて急速に低下します。一部の研究者は、必要な近傍サイズとニューラルネットワークの深さはグラフ表現の2つの完全に直交する側面であると主張しています。したがって、いくつかの方法は、浅いニューラルネットワークを使用しながらノードのkホップ近傍を集約することによって近傍を拡張します。ただし、これらの方法では、依然として過度の平滑化、高い計算およびストレージコストが発生します。このホワイトペーパーでは、修正されたMarkov Diffusion Kernelを使用して、Simple Spectral Graph Convolution（S2GC）と呼ばれるGCNのバリアントを導出します。スペクトル分析は、S2GCで使用される単純なスペクトルグラフ畳み込みが、各ノードのグローバルコンテキストとローカルコンテキストをキャプチャするローパスフィルターとハイパスフィルターのトレードオフであることを示しています。深刻な過度の平滑化を制限しながら、競合他社と比較してますます大きくなる近隣のシーケンスにわたって集約できることを示す2つの理論的主張を提供します。私たちの実験的評価は、線形学習器を備えたS2GCが、テキスト、ノード、およびグラフの分類タスクで競争力があることを示しています。さらに、S2GCは、ノードクラスタリングおよびコミュニティ予測タスクのための他の最先端の方法に匹敵します。,6.0,
Learning to interpret trajectories,"['Alexander Neitz', 'Giambattista Parascandolo', 'Bernhard Schölkopf']",https://openreview.net/forum?id=ECuvULjFQia,"By learning to predict trajectories of dynamical systems, model-based methods can make extensive use of all observations from past experience. However, due to partial observability, stochasticity, compounding errors, and irrelevant dynamics, training to predict observations explicitly often results in poor models. Model-free techniques try to side-step the problem by learning to predict values directly. While breaking the explicit dependency on future observations can result in strong performance, this usually comes at the cost of low sample efficiency, as the abundant information about the dynamics contained in future observations goes unused. Here we take a step back from both approaches: Instead of hand-designing how trajectories should be incorporated, a teacher network learns to interpret the trajectories and to provide target activations which guide a student model that can only observe the present. The teacher is trained with meta-gradients to maximize the student's performance on a validation set. We show that our approach performs well on tasks that are difficult for model-free and model-based methods, and we study the role of every component through ablation studies.",動的システムの軌道を予測することを学ぶことにより、モデルベースの方法は、過去の経験からのすべての観察を広範囲に利用することができます。ただし、部分的な可観測性、確率論、複合エラー、および無関係なダイナミクスのために、観測を明示的に予測するためのトレーニングは、多くの場合、不十分なモデルになります。モデルフリーの手法は、値を直接予測することを学習することにより、問題を回避しようとします。将来の観測への明示的な依存を解消すると、パフォーマンスが向上する可能性がありますが、将来の観測に含まれるダイナミクスに関する豊富な情報が使用されないため、通常、サンプル効率が低くなります。ここでは、両方のアプローチから一歩後退します。軌道を組み込む方法を手作業で設計する代わりに、教師ネットワークは軌道を解釈し、現在のみを観察できる学生モデルを導くターゲットアクティベーションを提供することを学習します。教師は、検証セットで生徒のパフォーマンスを最大化するためにメタグラデーションでトレーニングされています。私たちのアプローチは、モデルフリーおよびモデルベースの方法では困難なタスクでうまく機能することを示し、アブレーション研究を通じてすべてのコンポーネントの役割を研究します。,6.0,
Learning Manifold Patch-Based Representations of Man-Made Shapes,"['Dmitriy Smirnov', 'Mikhail Bessmeltsev', 'Justin Solomon']",https://openreview.net/forum?id=Gu5WqN9J3Fn,"Choosing the right representation for geometry is crucial for making 3D models compatible with existing applications. Focusing on piecewise-smooth man-made shapes, we propose a new representation that is usable in conventional CAD modeling pipelines and can also be learned by deep neural networks. We demonstrate its benefits by applying it to the task of sketch-based modeling. Given a raster image, our system infers a set of parametric surfaces that realize the input in 3D. To capture piecewise smooth geometry, we learn a special shape representation: a deformable parametric template composed of Coons patches. Naively training such a system, however, is hampered by non-manifold artifacts in the parametric shapes and by a lack of data. To address this, we introduce loss functions that bias the network to output non-self-intersecting shapes and implement them as part of a fully self-supervised system, automatically generating both shape templates and synthetic training data. We develop a testbed for sketch-based modeling, demonstrate shape interpolation, and provide comparison to related work.",3Dモデルを既存のアプリケーションと互換性を持たせるには、ジオメトリの適切な表現を選択することが重要です。区分的に滑らかな人工形状に焦点を当て、従来のCADモデリングパイプラインで使用でき、ディープニューラルネットワークでも学習できる新しい表現を提案します。スケッチベースのモデリングのタスクに適用することで、その利点を示します。ラスター画像が与えられると、私たちのシステムは、3Dでの入力を実現する一連のパラメトリック曲面を推測します。区分的に滑らかなジオメトリをキャプチャするために、特別な形状表現を学習します。これは、Coonsパッチで構成される変形可能なパラメトリックテンプレートです。ただし、このようなシステムを単純にトレーニングすることは、パラメトリック形状の非多様体アーティファクトとデータの不足によって妨げられます。これに対処するために、ネットワークにバイアスをかけて非自己交差形状を出力し、完全に自己監視されたシステムの一部として実装し、形状テンプレートと合成トレーニングデータの両方を自動的に生成する損失関数を導入します。スケッチベースのモデリング用のテストベッドを開発し、形状の補間を示し、関連する作業との比較を提供します。,6.0,
Shape-Texture Debiased Neural Network Training,"['Yingwei Li', 'Qihang Yu', 'Mingxing Tan', 'Jieru Mei', 'Peng Tang', 'Wei Shen', 'Alan Yuille', 'cihang xie']",https://openreview.net/forum?id=Db4yerZTYkz,"Shape  and  texture  are  two  prominent  and complementary  cues  for  recognizing objects.  Nonetheless, Convolutional Neural Networks (CNNs) are often biased towards either texture or shape, depending on the training dataset.  Our ablation shows that such bias degenerates model performance. Motivated by this observation, we develop a simple algorithm for shape-texture debiased learning.  To pre-vent models from exclusively attending on a single cue in representation learning, we augment training data with images with conflicting shape and texture information (e.g.,  an image of chimpanzee shape but with lemon texture) and, most importantly, provide the corresponding supervisions from shape and texture simultaneously.

Experiments show that our method successfully improves model performance on several image recognition benchmarks and adversarial robustness.  For example, by training on ImageNet, it helps ResNet-152 achieve substantial improvements on ImageNet (+1.2%), ImageNet-A (+5.2%), ImageNet-C (+8.3%) and Stylized-ImageNet (+11.1%), and on defending against FGSM adversarial attacker on Ima-geNet (+14.4%). Our method also claims to be compatible to other advanced data augmentation strategies, e.g., Mixup and CutMix.",形状とテクスチャは、オブジェクトを認識するための2つの顕著な補完的な手がかりです。それにもかかわらず、畳み込みニューラルネットワーク（CNN）は、トレーニングデータセットに応じて、テクスチャまたは形状のいずれかに偏っていることがよくあります。私たちのアブレーションは、そのようなバイアスがモデルのパフォーマンスを低下させることを示しています。この観察に動機付けられて、我々は形状テクスチャ偏りのない学習のための単純なアルゴリズムを開発します。モデルが表現学習の単一のキューに排他的に参加するのを防ぐために、形状とテクスチャの情報が競合する画像（たとえば、チンパンジーの形状であるがレモンのテクスチャを持つ画像）でトレーニングデータを補強し、最も重要なことに、対応する監視を提供します形と質感から同時に。実験は、私たちの方法がいくつかの画像認識ベンチマークと敵対的なロバスト性でモデルのパフォーマンスをうまく改善することを示しています。たとえば、ImageNetでトレーニングすることにより、ResNet-152がImageNetで大幅な改善（+1.2）を達成するのに役立ちます。,6.0,https://d3i71xaburhd42.cloudfront.net/b7826eb413218602e152e9affc96e14833bbb360/2-Figure1-1.png
AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights,"['Byeongho Heo', 'Sanghyuk Chun', 'Seong Joon Oh', 'Dongyoon Han', 'Sangdoo Yun', 'Gyuwan Kim', 'Youngjung Uh', 'Jung-Woo Ha']",https://openreview.net/forum?id=Iz3zU3M316D,"Normalization techniques, such as batch normalization (BN), are a boon for modern deep learning. They let weights converge more quickly with often better generalization performances. It has been argued that the normalization-induced scale invariance among the weights provides an advantageous ground for gradient descent (GD) optimizers: the effective step sizes are automatically reduced over time, stabilizing the overall training procedure. It is often overlooked, however, that the additional introduction of momentum in GD optimizers results in a far more rapid reduction in effective step sizes for scale-invariant weights, a phenomenon that has not yet been studied and may have caused unwanted side effects in the current practice. This is a crucial issue because arguably the vast majority of modern deep neural networks consist of (1) momentum-based GD (e.g. SGD or Adam) and (2) scale-invariant parameters (e.g. more than 90% of the weights in ResNet are scale-invariant due to BN). In this paper, we verify that the widely-adopted combination of the two ingredients lead to the premature decay of effective step sizes and sub-optimal model performances. We propose a simple and effective remedy, SGDP and AdamP: get rid of the radial component, or the norm-increasing direction, at each optimizer step. Because of the scale invariance, this modification only alters the effective step sizes without changing the effective update directions, thus enjoying the original convergence properties of GD optimizers. Given the ubiquity of momentum GD and scale invariance in machine learning, we have evaluated our methods against the baselines on 13 benchmarks. They range from vision tasks like classification (e.g. ImageNet), retrieval (e.g. CUB and SOP), and detection (e.g. COCO) to language modelling (e.g. WikiText) and audio classification (e.g. DCASE) tasks. We verify that our solution brings about uniform gains in performances in those benchmarks. Source code is available at https://github.com/clovaai/adamp",バッチ正規化（BN）などの正規化手法は、現代の深層学習に恩恵をもたらします。これらにより、重みがより迅速に収束し、一般化のパフォーマンスが向上することがよくあります。重み間の正規化によって引き起こされるスケール不変性は、勾配降下（GD）オプティマイザーに有利な根拠を提供すると主張されています。有効なステップサイズは時間の経過とともに自動的に減少し、トレーニング手順全体が安定します。ただし、GDオプティマイザに運動量を追加すると、スケール不変の重みの有効なステップサイズがはるかに急速に減少することは見過ごされがちです。この現象はまだ研究されておらず、望ましくない副作用を引き起こしている可能性があります。現在の習慣。現代のディープニューラルネットワークの大部分は、（1）運動量ベースのGD（SGDやAdamなど）と（2）スケール不変パラメーター（90以上など）で構成されているため、これは重大な問題です。,6.0,https://d3i71xaburhd42.cloudfront.net/1c96b2ce697a03777a7185d5f08d21bcb9a97cbd/2-Figure1-1.png
Skill Transfer via Partially Amortized Hierarchical Planning,"['Kevin Xie', 'Homanga Bharadhwaj', 'Danijar Hafner', 'Animesh Garg', 'Florian Shkurti']",https://openreview.net/forum?id=jXe91kq3jAq,"To quickly solve new tasks in complex environments, intelligent agents need to build up reusable knowledge. For example, a learned world model captures knowledge about the environment that applies to new tasks. Similarly, skills capture general behaviors that can apply to new tasks. In this paper, we investigate how these two approaches can be integrated into a single reinforcement learning agent. Specifically, we leverage the idea of partial amortization for fast adaptation at test time. For this, actions are produced by a policy that is learned over time while the skills it conditions on are chosen using online planning. We demonstrate the benefits of our design decisions across a suite of challenging locomotion tasks and demonstrate improved sample efficiency in single tasks as well as in transfer from one task to another, as compared to competitive baselines. Videos are available at: https://sites.google.com/view/partial-amortization/home",複雑な環境で新しいタスクをすばやく解決するには、インテリジェントエージェントは再利用可能な知識を構築する必要があります。たとえば、学習した世界モデルは、新しいタスクに適用される環境に関する知識をキャプチャします。同様に、スキルは、新しいタスクに適用できる一般的な動作をキャプチャします。この論文では、これら2つのアプローチを単一の強化学習エージェントに統合する方法を調査します。具体的には、部分償却のアイデアを活用して、テスト時の迅速な適応を実現します。このため、アクションは、時間の経過とともに学習されるポリシーによって生成され、その条件となるスキルはオンライン計画を使用して選択されます。競合するベースラインと比較して、一連の困難な移動タスク全体での設計上の決定の利点を示し、単一のタスクおよびあるタスクから別のタスクへの転送におけるサンプル効率の向上を示します。ビデオはhttps://sites.google.com/view/partial-amortization/homeで入手できます。,6.0,https://d3i71xaburhd42.cloudfront.net/4d1537347d8f5c463188166ae96c3c0d7a3260fa/1-Figure1-1.png
Uncertainty-aware Active Learning for Optimal Bayesian Classifier,"['Guang Zhao', 'Edward Dougherty', 'Byung-Jun Yoon', 'Francis Alexander', 'Xiaoning Qian']",https://openreview.net/forum?id=Mu2ZxFctAI,"For pool-based active learning, in each iteration a candidate training sample is chosen for labeling by optimizing an acquisition function. In Bayesian classification, expected Loss Reduction~(ELR) methods maximize the expected reduction in the classification error given a new labeled candidate based on a one-step-look-ahead strategy. ELR is the optimal strategy with a single query; however, since such myopic strategies cannot identify the long-term effect of a query on the classification error, ELR may get stuck before reaching the optimal classifier.  In this paper, inspired by the mean objective cost of uncertainty (MOCU), a metric quantifying the uncertainty directly affecting the classification error, we propose an acquisition function based on a weighted form of MOCU. Similar to ELR, the proposed method focuses on the reduction of the uncertainty that pertains to the classification error. But unlike any other existing scheme, it provides the critical advantage that the resulting Bayesian active learning algorithm guarantees convergence to the optimal classifier of the true model. We demonstrate its performance with both synthetic and real-world datasets.",プールベースの能動学習の場合、各反復で、取得関数を最適化することにより、ラベル付けのために候補トレーニングサンプルが選択されます。ベイズ分類では、期待損失削減（ELR）メソッドは、ワンステップ先読み戦略に基づいて新しいラベル付き候補が与えられた場合に、分類エラーの期待削減を最大化します。 ELRは、単一のクエリによる最適な戦略です。ただし、このような近視眼的な戦略では、分類エラーに対するクエリの長​​期的な影響を特定できないため、ELRは最適な分類子に到達する前にスタックする可能性があります。この論文では、分類誤差に直接影響する不確実性を定量化するメトリックである不確実性の平均客観的コスト（MOCU）に触発されて、MOCUの加重形式に基づく取得関数を提案します。 ELRと同様に、提案された方法は、分類エラーに関連する不確実性の低減に焦点を合わせています。しかし、他の既存のスキームとは異なり、結果として得られるベイズ能動学習アルゴリズムが真のモデルの最適な分類器への収束を保証するという決定的な利点を提供します。合成データセットと実世界のデータセットの両方でそのパフォーマンスを示します。,6.0,
"Self-supervised Adversarial Robustness for the Low-label, High-data Regime","['Sven Gowal', 'Po-Sen Huang', 'Aaron van den Oord', 'Timothy Mann', 'Pushmeet Kohli']",https://openreview.net/forum?id=bgQek2O63w,"Recent work discovered that training models to be invariant to adversarial perturbations requires substantially larger datasets than those required for standard classification. Perhaps more surprisingly, these larger datasets can be ""mostly"" unlabeled. Pseudo-labeling, a technique simultaneously pioneered by four separate and simultaneous works in 2019, has been proposed as a competitive alternative to labeled data for training adversarially robust models. However, when the amount of labeled data decreases, the performance of pseudo-labeling catastrophically drops, thus questioning the theoretical insights put forward by Uesato et al. (2019), which suggest that the sample complexity for learning an adversarially robust model from unlabeled data should match the fully supervised case. We introduce Bootstrap Your Own Robust Latents (BYORL), a self-supervised learning technique based on BYOL for training adversarially robust models. Our method enables us to train robust representations without any labels (reconciling practice with theory). This robust representation can be leveraged by a linear classifier to train adversarially robust models. We evaluate BYORL and pseudo-labeling on CIFAR-10 and demonstrate that BYORL achieves significantly higher robustness (i.e., models resulting from BYORL are up to two times more accurate). Experiments on CIFAR-10 against $\ell_2$ and $\ell_\infty$ norm-bounded perturbations demonstrate that BYORL achieves near state-of-the-art robustness with as little as 500 labeled examples. We also note that against $\ell_2$ norm-bounded perturbations of size $\epsilon = 128/255$, BYORL surpasses the known state-of-the-art with an accuracy under attack of 77.61% (against 72.91% for the prior art).",最近の研究では、敵対的な摂動に対して不変であるトレーニングモデルには、標準的な分類に必要なデータセットよりも大幅に大きなデータセットが必要であることがわかりました。おそらくもっと驚くべきことに、これらのより大きなデータセットは「ほとんど」ラベルが付けられていない可能性があります。 2019年に4つの別々の同時作業によって同時に開拓された手法である疑似ラベリングは、敵対的に堅牢なモデルをトレーニングするためのラベル付きデータの競争力のある代替手段として提案されています。ただし、ラベル付けされたデータの量が減少すると、疑似ラベル付けのパフォーマンスが壊滅的に低下するため、上里らが提唱した理論的洞察に疑問が生じます。 （2019）、これは、ラベルのないデータから敵対的にロバストなモデルを学習するためのサンプルの複雑さが、完全に教師ありの場合と一致する必要があることを示唆しています。敵対的にロバストなモデルをトレーニングするためのBYOLに基づく自己教師あり学習手法であるBootstrapYour Own Robust Latents（BYORL）を紹介します。私たちの方法では、ラベルなしで堅牢な表現をトレーニングできます（実践と理論の調整）。このロバストな表現は、線形分類器で活用して、敵対的にロバストなモデルをトレーニングできます。 BYORLとCIFAR-10の疑似ラベリングを評価し、BYORLが大幅に高いロバスト性を実現することを示します（つまり、BYORLから得られるモデルは最大2倍正確です）。 l2およびl（）ノルム境界摂動に対するCIFAR-10の実験は、BYORLがわずか500のラベル付きの例でほぼ最先端の堅牢性を達成することを示しています。また、サイズ= 128/255のl2ノルム制限摂動に対して、BYORLは77.61の攻撃下での精度で既知の最先端技術を上回っていることにも注意してください。,6.0,
Single-Photon Image Classification,"['Thomas Fischbacher', 'Luciano Sbaiz']",https://openreview.net/forum?id=CHLhSw9pSw8,"Quantum Computing based Machine Learning mainly focuses on quantum computing hardware that is experimentally challenging to realize due to requiring quantum gates that operate at very low temperature. We demonstrate the existence of a ""quantum computing toy model"" that illustrates key aspects of quantum information processing while being experimentally accessible with room temperature optics. Pondering the question of the theoretical classification accuracy performance limit for MNIST (respectively ""Fashion-MNIST"") classifiers, subject to the constraint that a decision has to be made after detection of the very first photon that passed through an image-filter, we show that a machine learning system that is permitted to use quantum interference on the photon's state can substantially outperform any machine learning system that can not.  Specifically, we prove that a ""classical"" MNIST (respectively ""Fashion-MNIST"") classifier cannot achieve an accuracy of better than $21.28\%$ (respectively $18.28\%$ for ""Fashion-MNIST"") if it must make a decision after seeing a single photon falling on one of the $28\times 28$ image pixels of a detector array.  We further demonstrate that a classifier that is permitted to employ quantum interference by optically transforming the photon state prior to detection can achieve a classification accuracy of at least $41.27\%$ for MNIST (respectively $36.14\%$ for ""Fashion-MNIST""). We show in detail how to train the corresponding quantum state transformation with TensorFlow and also explain how this example can serve as a teaching tool for the measurement process in quantum mechanics.
",量子コンピューティングベースの機械学習は、主に、非常に低い温度で動作する量子ゲートを必要とするため、実験的に実現が困難な量子コンピューティングハードウェアに焦点を当てています。室温光学で実験的にアクセス可能でありながら、量子情報処理の重要な側面を説明する「量子コンピューティングトイモデル」の存在を示します。 MNIST（それぞれ「Fashion-MNIST」）分類器の理論的な分類精度のパフォーマンス制限の問題を熟考し、画像フィルターを通過した最初の光子の検出後に決定を下す必要があるという制約を条件として、次のことを示します。光子状態で量子干渉を使用することが許可されている機械学習システムは、使用できない機械学習システムよりも大幅に優れている可能性があります。具体的には、「クラシック」MNIST（それぞれ「Fashion-MNIST」）分類器は、単一の光子を見た後に決定を下さなければならない場合、21.28％（「Fashion-MNIST」ではそれぞれ18.28％）を超える精度を達成できないことを証明します。検出器アレイの2828個の画像ピクセルの1つに該当します。さらに、検出前に光子状態を光学的に変換することによって量子干渉を使用できる分類器が、MNISTで少なくとも41.27％（「Fashion-MNIST」でそれぞれ36.14％）の分類精度を達成できることを示します。 TensorFlowを使用して対応する量子状態変換をトレーニングする方法を詳細に示し、この例が量子力学の測定プロセスの教育ツールとしてどのように役立つかについても説明します。,6.0,https://d3i71xaburhd42.cloudfront.net/e86099c24d7825fa36a484981eff11474debe3b3/5-Figure1-1.png
CcGAN: Continuous Conditional Generative Adversarial Networks for Image Generation,"['Xin Ding', 'Yongwei Wang', 'Zuheng Xu', 'William J Welch', 'Z. Jane Wang']",https://openreview.net/forum?id=PrzjugOsDeE,"This work proposes the continuous conditional generative adversarial network (CcGAN), the first generative model for image generation conditional on continuous, scalar conditions (termed regression labels). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (e.g., class labels); conditioning on a continuous label is mathematically distinct and raises two fundamental problems: (P1) Since there may be very few (even zero) real images for some regression labels, minimizing existing empirical versions of cGAN losses (a.k.a. empirical cGAN losses) often fails in practice; (P2) Since regression labels are scalar and infinitely many, conventional label input methods (e.g., combining a hidden map of the generator/discriminator with a one-hot encoded label) are not applicable. The proposed CcGAN solves the above problems, respectively, by (S1) reformulating existing empirical cGAN losses to be appropriate for the continuous scenario; and (S2) proposing a novel method to incorporate regression labels into the generator and the discriminator. The reformulation in (S1) leads to two novel empirical discriminator losses, termed the hard vicinal discriminator loss (HVDL) and the soft vicinal discriminator loss (SVDL) respectively, and a novel empirical generator loss. The error bounds of a discriminator trained with HVDL and SVDL are derived under mild assumptions in this work. A new benchmark dataset, RC-49, is also proposed for generative image modeling conditional on regression labels. Our experiments on the Circular 2-D Gaussians, RC-49, and UTKFace datasets show that CcGAN is able to generate diverse, high-quality samples from the image distribution conditional on a given regression label. Moreover, in these experiments, CcGAN substantially outperforms cGAN both visually and quantitatively.",この作業は、連続スカラー条件（回帰ラベルと呼ばれる）を条件とする画像生成の最初の生成モデルである、連続条件付き生成敵対的ネットワーク（CcGAN）を提案します。既存の条件付きGAN（cGAN）は、主にカテゴリ条件（クラスラベルなど）用に設計されています。連続ラベルの条件付けは数学的に異なり、2つの基本的な問題が発生します。（P1）一部の回帰ラベルの実像は非常に少ない（ゼロでさえある）ため、既存の経験的バージョンのcGAN損失（別名経験的cGAN損失）を最小化すると失敗することがよくあります。練習; （P2）回帰ラベルはスカラーであり、無限に多いため、従来のラベル入力方法（たとえば、ジェネレーター/ディスクリミネーターの非表示マップをワンホットエンコードラベルと組み合わせる）は適用できません。提案されたCcGANは、（S1）既存の経験的cGAN損失を継続的なシナリオに適切になるように再定式化することにより、上記の問題をそれぞれ解決します。 （S2）回帰ラベルをジェネレーターとディスクリミネーターに組み込むための新しい方法を提案する。 （S1）の再定式化は、それぞれハードビシナルディスクリミネーター損失（HVDL）およびソフトビシナルディスクリミネーター損失（SVDL）と呼ばれる2つの新しい経験的ディスクリミネーター損失、および新しい経験的ジェネレーター損失につながります。 HVDLとSVDLでトレーニングされた弁別器の誤差範囲は、この作業では穏やかな仮定の下で導き出されます。新しいベンチマークデータセットであるRC-49も、回帰ラベルを条件とする生成画像モデリング用に提案されています。 Circular 2-D Gaussians、RC-49、およびUTKFaceデータセットに関する実験では、CcGANが、特定の回帰ラベルを条件として、画像分布から多様で高品質のサンプルを生成できることが示されています。さらに、これらの実験では、CcGANは視覚的にも定量的にもcGANを大幅に上回っています。,6.0,https://d3i71xaburhd42.cloudfront.net/f70a9bcd4cc1dffdcb2611441db2a70047a750b1/4-Figure1-1.png
Representation Learning via Invariant Causal Mechanisms,"['Jovana Mitrovic', 'Brian McWilliams', 'Jacob C Walker', 'Lars Holger Buesing', 'Charles Blundell']",https://openreview.net/forum?id=9p2ekP904Rs,"Self-supervised learning has emerged as a strategy to reduce the reliance on costly supervised signal by pretraining representations only using unlabeled data. These methods combine heuristic proxy classification tasks with data augmentations and have achieved significant success, but our theoretical understanding of this success remains limited. In this paper we analyze self-supervised representation learning using a causal framework.  We show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. Based on this, we propose a novel self-supervised objective, Representation Learning via Invariant Causal Mechanisms (ReLIC), that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. Further, using causality we generalize contrastive learning, a particular kind of self-supervised method,  and provide an alternative theoretical explanation for the  success  of  these  methods. Empirically, ReLIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet, while also significantly outperforming these methods on Atari achieving above human-level performance on 51 out of 57 games.",自己教師あり学習は、ラベルのないデータのみを使用して表現を事前トレーニングすることにより、コストのかかる教師あり信号への依存を減らす戦略として登場しました。これらの方法は、ヒューリスティックプロキシ分類タスクとデータ拡張を組み合わせて大きな成功を収めていますが、この成功についての理論的な理解は限られています。この論文では、因果的フレームワークを使用して、自己教師あり表現学習を分析します。事前トレーニング中に使用されるプロキシ分類器の明示的な不変性制約を通じて、データ拡張をより効果的に利用する方法を示します。これに基づいて、新しい自己教師あり目的である不変因果メカニズムによる表現学習（ReLIC）を提案します。これは、不変正則化によって拡張全体のプロキシターゲットの不変予測を強制し、一般化の保証を向上させます。さらに、因果関係を使用して、特定の種類の自己教師あり方法である対照学習を一般化し、これらの方法の成功についての代替の理論的説明を提供します。経験的に、ReLICは、ImageNetでの堅牢性と配布外の一般化の点で競合するメソッドを大幅に上回っていますが、57ゲーム中51ゲームで人間レベルを超えるパフォーマンスを達成するAtariでこれらのメソッドを大幅に上回っています。,6.0,https://d3i71xaburhd42.cloudfront.net/57835c5ad5424f94ee75901c3113730f3900e656/3-Figure1-1.png
IOT: Instance-wise Layer Reordering for Transformer Structures,"['Jinhua Zhu', 'Lijun Wu', 'Yingce Xia', 'Shufang Xie', 'Tao Qin', 'Wengang Zhou', 'Houqiang Li', 'Tie-Yan Liu']",https://openreview.net/forum?id=ipUPfYxWZvM,"With sequentially stacked self-attention, (optional) encoder-decoder attention, and feed-forward layers, Transformer achieves big success in natural language processing (NLP), and many variants have been proposed. Currently, almost all these models assume that the \emph{layer order} is fixed and kept the same across data samples. We observe that different data samples actually favor different orders of the layers. Based on this observation, in this work, we break the assumption of the fixed layer order in Transformer and introduce instance-wise layer reordering into model structure. Our Instance-wise Ordered Transformer (IOT) can model variant functions by reordered layers, which enables each sample to select the better one to improve the model performance under the constraint of almost same number of parameters. To achieve this, we introduce a light predictor with negligible parameter and inference cost to decide the most capable and favorable layer order for any input sequence. Experiments on $3$ tasks (neural machine translation, abstractive summarization, and code generation) and $9$ datasets demonstrate consistent improvements of our method. We further show that our method can also be applied to other architectures beyond Transformer. Our code is released at Github\footnote{\url{https://github.com/instance-wise-ordered-transformer/IOT}}.",順次積み重ねられた自己注意、（オプションの）エンコーダー-デコーダー注意、およびフィードフォワード層により、Transformerは自然言語処理（NLP）で大きな成功を収め、多くのバリエーションが提案されています。現在、これらのモデルのほとんどすべては、レイヤーの順序が固定されており、データサンプル全体で同じに保たれていることを前提としています。異なるデータサンプルが実際には異なる次数のレイヤーを優先することがわかります。この観察に基づいて、この作業では、Transformerでの固定レイヤー順序の仮定を破り、モデル構造にインスタンスごとのレイヤー並べ替えを導入します。インスタンスごとの順序付きトランスフォーマー（IOT）は、再順序付けされたレイヤーによってバリアント関数をモデル化できます。これにより、各サンプルがより適切なものを選択して、ほぼ同じ数のパラメーターの制約の下でモデルのパフォーマンスを向上させることができます。これを実現するために、パラメーターと推論コストが無視できる軽い予測子を導入して、任意の入力シーケンスに対して最も有能で好ましいレイヤー順序を決定します。 3つのタスク（ニューラル機械翻訳、抽象的要約、コード生成）と9つのデータセットでの実験は、私たちの方法の一貫した改善を示しています。さらに、この方法がTransformer以外の他のアーキテクチャにも適用できることを示します。私たちのコードはGithub [1]でリリースされています。 [1] https://github.com/instance-wise-ordered-transformer/IOT,6.0,
Blending MPC & Value Function Approximation for Efficient Reinforcement Learning,"['Mohak Bhardwaj', 'Sanjiban Choudhury', 'Byron Boots']",https://openreview.net/forum?id=RqCC_00Bg7V,"Model-Predictive Control (MPC) is a powerful tool for controlling complex, real-world systems that uses a model to make predictions about future behavior. For each state encountered, MPC solves an online optimization problem to choose a control action that will minimize future cost. This is a surprisingly effective strategy, but real-time performance requirements warrant the use of simple models. If the model is not sufficiently accurate, then the resulting controller can be biased, limiting performance. We present a framework for improving on MPC with model-free reinforcement learning (RL). The key insight is to view MPC as constructing a series of local Q-function approximations. We show that by using a parameter $\lambda$, similar to the trace decay parameter in TD($\lambda$), we can systematically trade-off learned value estimates against the local Q-function approximations. We present a theoretical analysis that shows how error from inaccurate models in MPC and value function estimation in RL can be balanced. We further propose an algorithm that changes $\lambda$ over time to reduce the dependence on MPC as our estimates of the value function improve, and test the efficacy our approach on challenging high-dimensional manipulation tasks with biased models in simulation. We demonstrate that our approach can obtain performance comparable with MPC with access to true dynamics even under severe model bias and is more sample efficient as compared to model-free RL.",Model-Predictive Control（MPC）は、モデルを使用して将来の動作に関する予測を行う、複雑な実世界のシステムを制御するための強力なツールです。 MPCは、発生した状態ごとに、オンライン最適化問題を解決して、将来のコストを最小限に抑える制御アクションを選択します。これは驚くほど効果的な戦略ですが、リアルタイムのパフォーマンス要件は単純なモデルの使用を保証します。モデルが十分に正確でない場合、結果のコントローラーにバイアスがかかり、パフォーマンスが制限される可能性があります。モデルフリー強化学習（RL）を使用してMPCを改善するためのフレームワークを提示します。重要な洞察は、MPCを一連のローカルQ関数近似を構築するものと見なすことです。 TD（）のトレース減衰パラメーターと同様のパラメーターを使用することにより、学習した値の推定値をローカルのQ関数近似と体系的にトレードオフできることを示します。 MPCの不正確なモデルからのエラーとRLの値関数推定のバランスをとることができる方法を示す理論的分析を提示します。さらに、値関数の推定値が向上するにつれてMPCへの依存を減らすために時間とともに変化するアルゴリズムを提案し、シミュレーションでバイアスモデルを使用して高次元操作タスクに挑戦するアプローチの有効性をテストします。私たちのアプローチは、厳しいモデルバイアスの下でも真のダイナミクスにアクセスできるMPCに匹敵するパフォーマンスを得ることができ、モデルフリーRLと比較してサンプル効率が高いことを示しています。,6.0,
Initialization and Regularization of Factorized Neural Layers,"['Mikhail Khodak', 'Neil A. Tenenholtz', 'Lester Mackey', 'Nicolo Fusi']",https://openreview.net/forum?id=KTlJT1nof6d,"Factorized layers---operations parameterized by products of two or more matrices---occur in a variety of deep learning contexts, including compressed model training, certain types of knowledge distillation, and multi-head self-attention architectures. We study how to initialize and regularize deep nets containing such layers, examining two simple, understudied schemes, spectral initialization and Frobenius decay, for improving their performance. The guiding insight is to design optimization routines for these networks that are as close as possible to that of their well-tuned, non-decomposed counterparts; we back this intuition with an analysis of how the initialization and regularization schemes impact training with gradient descent, drawing on modern attempts to understand the interplay of weight-decay and batch-normalization. Empirically, we highlight the benefits of spectral initialization and Frobenius across a variety of settings. In model compression, we show that they enable low-rank methods to significantly outperform both unstructured sparsity and tensor methods on the task of training low-memory residual networks; analogs of the schemes also improve the performance of tensor decomposition techniques. For knowledge distillation, Frobenius decay enables a simple, self-taught baseline that yields a compact model from over-parameterized training without requiring retraining with or pruning a teacher network. Finally, we show how both schemes applied to multi-head attention lead to improved performance on both translation and unsupervised pre-training.",2つ以上のマトリックスの積によってパラメーター化された因数分解されたレイヤー操作は、圧縮モデルトレーニング、特定のタイプの知識蒸留、マルチヘッド自己注意アーキテクチャなど、さまざまな深層学習コンテキストで発生します。そのような層を含む深いネットを初期化および正規化する方法を研究し、2つの単純で十分に研究されていないスキーム、スペクトル初期化とフロベニウス崩壊を調べて、それらの性能を改善します。指針となる洞察は、これらのネットワークの最適化ルーチンを、適切に調整され、分解されていない対応するものに可能な限り近いものとして設計することです。初期化と正則化のスキームが勾配降下法によるトレーニングにどのように影響するかを分析し、重みの減衰とバッチ正規化の相互作用を理解するための最新の試みを利用して、この直感を裏付けます。経験的に、さまざまな設定でのスペクトル初期化とフロベニウスの利点を強調します。モデル圧縮では、低ランクの方法が、低メモリの残余ネットワークをトレーニングするタスクで、非構造化スパース法とテンソル法の両方を大幅に上回ることができることを示します。スキームの類似物は、テンソル分解手法のパフォーマンスも向上させます。知識の蒸留の場合、フロベニウス崩壊は、教師ネットワークによる再トレーニングや剪定を必要とせずに、パラメーター化されたトレーニングからコンパクトなモデルを生成する、単純な独学のベースラインを可能にします。最後に、マルチヘッドアテンションに適用された両方のスキームが、翻訳と教師なし事前トレーニングの両方でパフォーマンスの向上にどのようにつながるかを示します。,6.0,
On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning,"['Ren Wang', 'Kaidi Xu', 'Sijia Liu', 'Pin-Yu Chen', 'Tsui-Wei Weng', 'Chuang Gan', 'Meng Wang']",https://openreview.net/forum?id=o81ZyBCojoA,"Model-agnostic meta-learning (MAML) has emerged as one of the most successful meta-learning techniques in few-shot learning. It enables us to learn a $\textit{meta-initialization}$ of model parameters (that we call $\textit{meta-model}$) to rapidly adapt to new tasks using a small amount of labeled training data. Despite the generalization power of the meta-model, it remains elusive that how $\textit{adversarial robustness}$ can be maintained by MAML in few-shot learning. In addition to generalization, robustness is also desired for a meta-model to defend adversarial examples (attacks). Toward promoting adversarial robustness in MAML, we first study $\textit{when}$ a robustness-promoting regularization should be incorporated, given the fact that MAML adopts a bi-level (fine-tuning vs. meta-update) learning procedure. We show that robustifying the meta-update stage is sufficient to make robustness adapted to the task-specific fine-tuning stage even if the latter uses a standard training protocol. We also make additional justification on the acquired robustness adaptation by peering into the interpretability of neurons' activation maps. Furthermore, we investigate $\textit{how}$ robust regularization can $\textit{efficiently}$ be designed in MAML. We propose a general but easily-optimized robustness-regularized meta-learning framework, which allows the use of unlabeled data augmentation, fast adversarial attack generation, and computationally-light fine-tuning. In particular, we for the first time show that the auxiliary contrastive learning task can enhance the adversarial robustness of MAML. Finally, extensive experiments are conducted to demonstrate the effectiveness of our proposed methods in robust few-shot learning.",モデルにとらわれないメタ学習（MAML）は、数回の学習で最も成功したメタ学習手法の1つとして浮上しています。これにより、モデルパラメータのメタ初期化（メタモデルと呼びます）を学習して、少量のラベル付きトレーニングデータを使用して新しいタスクに迅速に適応できます。メタモデルの一般化力にもかかわらず、数ショットの学習でMAMLによって敵対的なロバスト性をどのように維持できるかはわかりにくいままです。一般化に加えて、敵対的な例（攻撃）を防御するためのメタモデルにも堅牢性が求められます。 MAMLで敵対的なロバスト性を促進するために、MAMLが2レベル（微調整とメタ更新）の学習手順を採用しているという事実を踏まえて、ロバスト性を促進する正則化を組み込む必要がある場合を最初に調査します。メタ更新ステージをロバスト化することで、タスク固有の微調整ステージが標準のトレーニングプロトコルを使用している場合でも、ロバスト性をタスク固有の微調整ステージに適合させるのに十分であることを示します。また、ニューロンの活性化マップの解釈可能性を覗き込むことにより、獲得したロバストネス適応について追加の正当化を行います。さらに、堅牢な正則化をMAMLで効率的に設計する方法を調査します。ラベルなしのデータ拡張、高速な敵対的攻撃の生成、および計算量の少ない微調整の使用を可能にする、一般的であるが容易に最適化されるロバスト性正則化メタ学習フレームワークを提案します。特に、補助的な対照学習タスクがMAMLの敵対的ロバスト性を強化できることを初めて示しました。最後に、堅牢な数ショット学習における提案された方法の有効性を実証するために、広範な実験が実施されます。,6.0,
Learning What To Do by Simulating the Past,"['David Lindner', 'Rohin Shah', 'Pieter Abbeel', 'Anca Dragan']",https://openreview.net/forum?id=kBVJ2NtiY-,"Since reward functions are hard to specify, recent work has focused on learning policies from human feedback. However, such approaches are impeded by the expense of acquiring such feedback. Recent work proposed that agents have access to a source of information that is effectively free: in any environment that humans have acted in, the state will already be optimized for human preferences, and thus an agent can extract information about what humans want from the state. Such learning is possible in principle, but requires simulating all possible past trajectories that could have led to the observed state. This is feasible in grid worlds, but how do we scale it to complex tasks? In this work, we show that by combining a learned feature encoder with learned inverse models, we can enable agents to simulate human actions backwards in time to infer what they must have done. The resulting algorithm is able to reproduce a specific skill in MuJoCo environments given a single state sampled from the optimal policy for that skill.",報酬関数を指定するのは難しいため、最近の作業では、人間のフィードバックからポリシーを学習することに重点が置かれています。しかし、そのようなアプローチは、そのようなフィードバックを取得する費用によって妨げられます。最近の研究では、エージェントは事実上無料の情報源にアクセスできることが提案されています。人間が行動した環境では、状態はすでに人間の好みに合わせて最適化されているため、エージェントは状態から人間が望むものに関する情報を抽出できます。 。このような学習は原則として可能ですが、観測された状態につながる可能性のあるすべての可能な過去の軌跡をシミュレートする必要があります。これはグリッドの世界では実現可能ですが、複雑なタスクにどのようにスケーリングするのでしょうか。この作業では、学習された特徴エンコーダーを学習された逆モデルと組み合わせることにより、エージェントが人間の行動を時間的に逆方向にシミュレートして、何をしなければならないかを推測できることを示します。結果として得られるアルゴリズムは、そのスキルの最適なポリシーからサンプリングされた単一の状態が与えられた場合に、MuJoCo環境で特定のスキルを再現することができます。,6.0,
i-Mix: A Strategy for Regularizing Contrastive Representation Learning,"['Kibok Lee', 'Yian Zhu', 'Kihyuk Sohn', 'Chun-Liang Li', 'Jinwoo Shin', 'Honglak Lee']",https://openreview.net/forum?id=T6AxtOaWydQ,"Contrastive representation learning has shown to be an effective way of learning representations from unlabeled data. However, much progress has been made in vision domains relying on data augmentations carefully designed using domain knowledge. In this work, we propose i-Mix, a simple yet effective regularization strategy for improving contrastive representation learning in both vision and non-vision domains. We cast contrastive learning as training a non-parametric classifier by assigning a unique virtual class to each data in a batch. Then, data instances are mixed in both the input and virtual label spaces, providing more augmented data during training. In experiments, we demonstrate that i-Mix consistently improves the quality of self-supervised representations across domains, resulting in significant performance gains on downstream tasks. Furthermore, we confirm its regularization effect via extensive ablation studies across model and dataset sizes. The code will be released.",対照的な表現学習は、ラベルのないデータから表現を学習する効果的な方法であることが示されています。ただし、ドメイン知識を使用して慎重に設計されたデータ拡張に依存するビジョンドメインでは、多くの進歩が見られました。この作業では、ビジョンと非ビジョンの両方のドメインで対照的な表現学習を改善するためのシンプルで効果的な正則化戦略であるi-Mixを提案します。バッチ内の各データに一意の仮想クラスを割り当てることにより、ノンパラメトリック分類器のトレーニングとして対照学習をキャストします。次に、データインスタンスが入力スペースと仮想ラベルスペースの両方で混合され、トレーニング中にさらに拡張されたデータが提供されます。実験では、i-Mixがドメイン全体で自己監視表現の品質を一貫して改善し、ダウンストリームタスクのパフォーマンスが大幅に向上することを示しています。さらに、モデルとデータセットのサイズ全体にわたる広範なアブレーション研究を通じて、その正則化効果を確認します。コードがリリースされます。,6.0,
How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision,"['Dongkwan Kim', 'Alice Oh']",https://openreview.net/forum?id=Wi5KUNlqWty,"Attention mechanism in graph neural networks is designed to assign larger weights to important neighbor nodes for better representation. However, what graph attention learns is not understood well, particularly when graphs are noisy. In this paper, we propose a self-supervised graph attention network (SuperGAT), an improved graph attention model for noisy graphs. Specifically, we exploit two attention forms compatible with a self-supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. By encoding edges, SuperGAT learns more expressive attention in distinguishing mislinked neighbors. We find two graph characteristics influence the effectiveness of attention forms and self-supervision: homophily and average degree. Thus, our recipe provides guidance on which attention design to use when those two graph characteristics are known. Our experiment on 17 real-world datasets demonstrates that our recipe generalizes across 15 datasets of them, and our models designed by recipe show improved performance over baselines.",グラフニューラルネットワークの注意メカニズムは、より適切な表現のために重要な隣接ノードにより大きな重みを割り当てるように設計されています。ただし、特にグラフにノイズが多い場合、グラフの注意が学習する内容はよく理解されていません。本論文では、ノイズの多いグラフのための改良されたグラフ注意モデルである自己監視グラフ注意ネットワーク（SuperGAT）を提案する。具体的には、自己監視タスクと互換性のある2つの注意フォームを利用してエッジを予測します。エッジの有無には、ノード間の関係の重要性に関する固有の情報が含まれています。エッジをエンコードすることにより、SuperGATは、誤ってリンクされたネイバーを区別する際に、より表現力豊かな注意を学習します。 2つのグラフ特性が注意フォームと自己監視の有効性に影響を与えることがわかります：同質性と平均次数。したがって、私たちのレシピは、これら2つのグラフ特性がわかっている場合に使用する注意設計に関するガイダンスを提供します。 17の実世界のデータセットでの実験は、レシピがそれらの15のデータセットにわたって一般化され、レシピによって設計されたモデルがベースラインよりもパフォーマンスが向上していることを示しています。,6.0,
Neural Rankers are hitherto Outperformed by Gradient Boosted Decision Trees,"['Zhen Qin', 'Le Yan', 'Honglei Zhuang', 'Yi Tay', 'Rama Kumar Pasumarthi', 'Xuanhui Wang', 'Michael Bendersky', 'Marc Najork']",https://openreview.net/forum?id=Ut1vF_q_vC,"Despite the success of neural models on many major machine learning problems, their effectiveness on traditional Learning-to-Rank (LTR) problems is still not widely acknowledged. We first validate this concern by showing that most recent neural LTR models are, by a large margin, inferior to the best publicly available Gradient Boosted Decision Trees (GBDT) in terms of their reported ranking accuracy on benchmark datasets. This unfortunately was somehow overlooked in recent neural LTR papers. We then investigate why existing neural LTR models under-perform and identify several of their weaknesses. Furthermore, we propose a unified framework comprising of counter strategies to ameliorate the existing weaknesses of neural models. Our models are the first to be able to perform equally well, comparing with the best tree-based baseline, while outperforming recently published neural LTR models by a large margin. Our results can also serve as a benchmark to facilitate future improvement of neural LTR models.",多くの主要な機械学習問題でのニューラルモデルの成功にもかかわらず、従来のLearning-to-Rank（LTR）問題でのそれらの有効性はまだ広く認識されていません。最初に、最新のニューラルLTRモデルが、ベンチマークデータセットで報告されたランキング精度の点で、公開されている最良の勾配ブースト決定木（GBDT）よりも大幅に劣っていることを示すことにより、この懸念を検証します。残念ながら、これは最近のニューラルLTRの論文では見過ごされていました。次に、既存のニューラルLTRモデルのパフォーマンスが低下する理由を調査し、それらの弱点のいくつかを特定します。さらに、神経モデルの既存の弱点を改善するためのカウンター戦略で構成される統一されたフレームワークを提案します。私たちのモデルは、ツリーベースの最高のベースラインと比較して、最近公開されたニューラルLTRモデルを大幅に上回っており、同等のパフォーマンスを発揮できる最初のモデルです。私たちの結果は、神経LTRモデルの将来の改善を促進するためのベンチマークとしても役立ちます。,6.0,
Interpretable Models for Granger Causality Using Self-explaining Neural Networks,"['Ričards Marcinkevičs', 'Julia E Vogt']",https://openreview.net/forum?id=DEa4JdMWRHp,"Exploratory analysis of time series data can yield a better understanding of complex dynamical systems. Granger causality is a practical framework for analysing interactions in sequential data, applied in a wide range of domains. In this paper, we propose a novel framework for inferring multivariate Granger causality under nonlinear dynamics based on an extension of self-explaining neural networks. This framework is more interpretable than other neural-network-based techniques for inferring Granger causality, since in addition to relational inference, it also allows detecting signs of Granger-causal effects and inspecting their variability over time. In comprehensive experiments on simulated data, we show that our framework performs on par with several powerful baseline methods at inferring Granger causality and that it achieves better performance at inferring interaction signs. The results suggest that our framework is a viable and more interpretable alternative to sparse-input neural networks for inferring Granger causality.",時系列データの探索的分析により、複雑な動的システムをよりよく理解できます。グレンジャー因果性は、シーケンシャルデータの相互作用を分析するための実用的なフレームワークであり、幅広いドメインに適用されます。この論文では、自己説明型ニューラルネットワークの拡張に基づいて、非線形ダイナミクスの下で多変量グレンジャー因果性を推測するための新しいフレームワークを提案します。このフレームワークは、関係推論に加えて、グレンジャー因果効果の兆候を検出し、時間の経過に伴う変動を検査できるため、グレンジャー因果性を推論するための他のニューラルネットワークベースの手法よりも解釈しやすくなっています。シミュレートされたデータの包括的な実験では、フレームワークがグレンジャー因果性を推測する際にいくつかの強力なベースライン方法と同等に機能し、相互作用の兆候を推測する際により良いパフォーマンスを達成することを示します。結果は、私たちのフレームワークが、グレンジャー因果性を推測するためのスパース入力ニューラルネットワークの実行可能でより解釈可能な代替手段であることを示唆しています。,6.0,
Probing BERT in Hyperbolic Spaces,"['Boli Chen', 'Yao Fu', 'Guangwei Xu', 'Pengjun Xie', 'Chuanqi Tan', 'Mosha Chen', 'Liping Jing']",https://openreview.net/forum?id=17VnwXYZyhH,"Recently, a variety of probing tasks are proposed to discover linguistic properties learned in contextualized word embeddings. Many of these works implicitly assume these embeddings lay in certain metric spaces, typically the Euclidean space. This work posits a family of geometrically special spaces, the hyperbolic spaces, that exhibit better inductive biases for hierarchical structures and may better reveal linguistic hierarchies encoded in contextualized representations. We introduce a $\textit{Poincaré probe}$, a structural probe projecting these embeddings into a Poincaré subspace with explicitly defined hierarchies. We focus on two probing objectives: (a) dependency trees where the hierarchy is defined as head-dependent structures; (b) lexical sentiments where the hierarchy is defined as the polarity of words (positivity and negativity). We apply our probes on BERT, a typical contextualized embedding model. In the syntactic subspace, our probe better recovers tree structures than Euclidean probes, revealing the possibility that the geometry of BERT syntax may not necessarily be Euclidean. In the sentiment subspace, we reveal two possible meta-embeddings for positive and negative sentiments and show how lexically-controlled contextualization would change the geometric localization of embeddings. We demonstrate the findings with our Poincaré probe via extensive experiments and visualization. ",最近、文脈化された単語の埋め込みで学習された言語特性を発見するために、さまざまなプロービングタスクが提案されています。これらの作品の多くは、これらの埋め込みが特定の距離空間、通常はユークリッド空間にあることを暗黙的に想定しています。この作品は、階層構造に対してより良い誘導バイアスを示し、文脈化された表現でエンコードされた言語階層をよりよく明らかにする可能性のある、幾何学的に特別な空間のファミリーである双曲空間を想定しています。明示的に定義された階層を持つポアンカレ部分空間にこれらの埋め込みを投影する構造プローブであるポアンカレプローブを紹介します。 2つの調査目的に焦点を当てます。（a）階層がヘッド依存構造として定義されている依存ツリー。 （b）階層が単語の極性（ポジティブとネガティブ）として定義されている語彙感情。典型的なコンテキスト化された埋め込みモデルであるBERTにプローブを適用します。構文部分空間では、プローブはユークリッドプローブよりもツリー構造をより適切に回復し、BERT構文のジオメトリが必ずしもユークリッドであるとは限らない可能性を明らかにします。感情部分空間では、ポジティブ感情とネガティブ感情の2つの可能なメタ埋め込みを明らかにし、字句的に制御されたコンテキスト化が埋め込みの幾何学的ローカリゼーションをどのように変更するかを示します。広範な実験と視覚化を通じて、ポアンカレプローブを使用して調査結果を示します。,6.0,
Taming GANs with Lookahead-Minmax,"['Tatjana Chavdarova', 'Matteo Pagliardini', 'Sebastian U Stich', 'François Fleuret', 'Martin Jaggi']",https://openreview.net/forum?id=ZW0yXJyNmoG,"Generative Adversarial Networks are notoriously challenging to train. The underlying minmax optimization is highly susceptible to the variance of the stochastic gradient and the rotational component of the associated game vector field. To tackle these challenges, we propose the Lookahead algorithm for minmax optimization, originally developed for single objective minimization only. The backtracking step of our Lookahead–minmax naturally handles the rotational game dynamics, a property which was identified to be key for enabling gradient ascent descent methods to converge on challenging examples often analyzed in the literature. Moreover, it implicitly handles high variance without using large mini-batches, known to be essential for reaching state of the art performance. Experimental results on MNIST, SVHN, CIFAR-10, and ImageNet demonstrate a clear advantage of combining Lookahead–minmax with Adam or extragradient, in terms of performance and improved stability, for negligible memory and computational cost. Using 30-fold fewer parameters and 16-fold smaller minibatches we outperform the reported performance of the class-dependent BigGAN on CIFAR-10 by obtaining FID of 12.19 without using the class labels, bringing state-of-the-art GAN training within reach of common computational resources.",生成的敵対的ネットワークは、訓練が難しいことで有名です。基礎となるミニマックス最適化は、確率的勾配の分散と関連するゲームベクトル場の回転成分の影響を非常に受けやすくなっています。これらの課題に取り組むために、元々は単一目的の最小化のみを目的として開発された、ミニマックス最適化のための先読みアルゴリズムを提案します。 Lookaheadminmaxのバックトラックステップは、回転ゲームのダイナミクスを自然に処理します。これは、勾配上昇降下法を、文献でよく分析される困難な例に収束させるための鍵であると特定されたプロパティです。さらに、最先端のパフォーマンスに到達するために不可欠であることが知られている大きなミニバッチを使用せずに、暗黙的に高い変動を処理します。 MNIST、SVHN、CIFAR-10、およびImageNetでの実験結果は、パフォーマンスと安定性の向上の観点から、メモリと計算コストを無視できるという点で、LookaheadminmaxをAdamまたはエクストラグラディエントと組み合わせるという明らかな利点を示しています。 30分の1のパラメーターと16分の1の小さなミニバッチを使用して、クラスラベルを使用せずに12.19のFIDを取得し、最先端のGANトレーニングを利用できるようにすることで、CIFAR-10で報告されたクラス依存BigGANのパフォーマンスを上回ります。一般的な計算リソースの。,6.0,
Zero-Cost Proxies for Lightweight NAS,"['Mohamed S Abdelfattah', 'Abhinav Mehrotra', 'Łukasz Dudziak', 'Nicholas Donald Lane']",https://openreview.net/forum?id=0cmMMy8J5q,"Neural Architecture Search (NAS) is quickly becoming the standard methodology to design neural network models. However, NAS is typically compute-intensive because multiple models need to be evaluated before choosing the best one. To reduce the computational power and time needed, a proxy task is often used for evaluating each model instead of full training. In this paper, we evaluate conventional reduced-training proxies and quantify how well they preserve ranking between multiple models during search when compared with the rankings produced by final trained accuracy. We propose a series of zero-cost proxies, based on recent pruning literature, that use just a single minibatch of training data to compute a model's score. Our zero-cost proxies use 3 orders of magnitude less computation but can match and even outperform conventional proxies. For example, Spearman's rank correlation coefficient between final validation accuracy and our best zero-cost proxy on NAS-Bench-201 is 0.82, compared to 0.61 for EcoNAS (a recently proposed reduced-training proxy). Finally, we use these zero-cost proxies to enhance existing NAS search algorithms such as random search, reinforcement learning, evolutionary search and predictor-based search. For all search methodologies and across three different NAS datasets, we are able to significantly improve sample efficiency, and thereby decrease computation, by using our zero-cost proxies. For example on NAS-Bench-101, we achieved the same accuracy 4$\times$ quicker than the best previous result.
",ニューラルアーキテクチャ検索（NAS）は、ニューラルネットワークモデルを設計するための標準的な方法論に急速になりつつあります。ただし、最適なモデルを選択する前に複数のモデルを評価する必要があるため、NASは通常、計算量が多くなります。必要な計算能力と時間を削減するために、完全なトレーニングではなく、プロキシタスクを使用して各モデルを評価することがよくあります。この論文では、従来の削減されたトレーニングプロキシを評価し、最終的なトレーニングされた精度によって生成されたランキングと比較した場合に、検索中に複数のモデル間のランキングをどの程度維持するかを定量化します。最近の剪定に関する文献に基づいて、トレーニングデータの単一のミニバッチを使用してモデルスコアを計算する一連のゼロコストプロキシを提案します。当社のゼロコストプロキシは、3桁少ない計算を使用しますが、従来のプロキシに匹敵し、さらにはそれを上回ることができます。たとえば、スピアマンの順位相関係数は、最終的な検証精度とNAS-Bench-201での最高のゼロコストプロキシとの間で0.82ですが、EcoNAS（最近提案されたトレーニング削減プロキシ）では0.61です。最後に、これらのゼロコストプロキシを使用して、ランダム検索、強化学習、進化的検索、予測子ベースの検索など、既存のNAS検索アルゴリズムを強化します。すべての検索方法と3つの異なるNASデータセットで、ゼロコストのプロキシを使用することで、サンプルの効率を大幅に向上させ、計算を減らすことができます。たとえば、NAS-Bench-101では、以前の最良の結果よりも4速く同じ精度を達成しました。,6.0,
Control-Aware Representations for Model-based Reinforcement Learning,"['Brandon Cui', 'Yinlam Chow', 'Mohammad Ghavamzadeh']",https://openreview.net/forum?id=dgd4EJqsbW5,"A major challenge in modern reinforcement learning (RL) is efficient control of dynamical systems from high-dimensional sensory observations. Learning controllable embedding (LCE) is a promising approach that addresses this challenge by embedding the observations into a lower-dimensional latent space, estimating the latent dynamics, and utilizing it to perform control in the latent space. Two important questions in this area are how to learn a representation that is amenable to the control problem at hand, and how to achieve an end-to-end framework for representation learning and control. In this paper, we take a few steps towards addressing these questions. We first formulate a LCE model to learn representations that are suitable to be used by a policy iteration style algorithm in the latent space. We call this model control-aware representation learning (CARL). We derive a loss function and three implementations for CARL. In the offline implementation, we replace the locally-linear control algorithm (e.g., iLQR) used by the existing LCE methods with a RL algorithm, namely model-based soft actor-critic, and show that it results in significant improvement. In online CARL, we interleave representation learning and control, and demonstrate further gain in performance. Finally, we propose value-guided CARL, a variation in which we optimize a weighted version of the CARL loss function, where the weights depend on the TD-error of the current policy. We evaluate the proposed algorithms by extensive experiments on benchmark tasks and compare them with several LCE baselines.",現代の強化学習（RL）の主な課題は、高次元の感覚観察から動的システムを効率的に制御することです。制御可能な埋め込み（LCE）の学習は、観測値を低次元の潜在空間に埋め込み、潜在ダイナミクスを推定し、それを利用して潜在空間で制御を実行することにより、この課題に対処する有望なアプローチです。この分野での2つの重要な質問は、目前の制御問題に適した表現を学習する方法と、表現の学習と制御のためのエンドツーエンドのフレームワークを実現する方法です。このホワイトペーパーでは、これらの質問に対処するためにいくつかの手順を実行します。最初にLCEモデルを定式化して、潜在空間でポリシー反復スタイルのアルゴリズムで使用するのに適した表現を学習します。このモデルを制御認識表現学習（CARL）と呼びます。損失関数とCARLの3つの実装を導出します。オフラインの実装では、既存のLCEメソッドで使用されているローカル線形制御アルゴリズム（iLQRなど）をRLアルゴリズム、つまりモデルベースのソフトアクタークリティカルに置き換え、大幅な改善が見られることを示しています。オンラインCARLでは、表現の学習と制御をインターリーブし、パフォーマンスのさらなる向上を示します。最後に、価値に基づくCARLを提案します。これは、CARL損失関数の加重バージョンを最適化するバリエーションであり、加重は現在のポリシーのTDエラーに依存します。ベンチマークタスクに関する広範な実験によって提案されたアルゴリズムを評価し、それらをいくつかのLCEベースラインと比較します。,6.0,https://d3i71xaburhd42.cloudfront.net/b50da2e0bf200bb481725d92e5e3c80f8273dacc/4-Figure1-1.png
Scaling Symbolic Methods using Gradients for Neural Model Explanation,"['Subham Sekhar Sahoo', 'Subhashini Venugopalan', 'Li Li', 'Rishabh Singh', 'Patrick Riley']",https://openreview.net/forum?id=V5j-jdoDDP,"Symbolic techniques based on Satisfiability Modulo Theory (SMT) solvers have been proposed for analyzing and verifying neural network properties, but their usage has been fairly limited owing to their poor scalability with larger networks. In this work, we propose a technique for combining gradient-based methods with symbolic techniques to scale such analyses and demonstrate its application for model explanation. In particular, we apply this technique to identify minimal regions in an input that are most relevant for a neural network's prediction. Our approach uses gradient information (based on Integrated Gradients) to focus on a subset of neurons in the first layer, which allows our technique to scale to large networks. The corresponding SMT constraints encode the minimal input mask discovery problem such that after masking the input, the activations of the selected neurons are still above a threshold. After solving for the minimal masks, our approach scores the mask regions to generate a relative ordering of the features within the mask. This produces a saliency map which explains"" where a model is looking"" when making a prediction. We evaluate our technique on three datasets-MNIST, ImageNet, and Beer Reviews, and demonstrate both quantitatively and qualitatively that the regions generated by our approach are sparser and achieve higher saliency scores compared to the gradient-based methods alone.",ニューラルネットワークのプロパティを分析および検証するために、Satisfiability Modulo Theory（SMT）ソルバーに基づくシンボリック手法が提案されていますが、大規模なネットワークではスケーラビリティが低いため、その使用はかなり制限されています。この作業では、勾配ベースの方法をシンボリック手法と組み合わせて、そのような分析をスケーリングし、モデルの説明への応用を示す手法を提案します。特に、この手法を適用して、ニューラルネットワークの予測に最も関連する入力内の最小領域を特定します。私たちのアプローチでは、勾配情報（統合勾配に基づく）を使用して、第1層のニューロンのサブセットに焦点を合わせます。これにより、この手法を大規模なネットワークに拡張できます。対応するSMT制約は、入力をマスクした後でも、選択されたニューロンのアクティブ化がまだしきい値を超えているように、最小の入力マスク検出問題をエンコードします。最小マスクを解いた後、私たちのアプローチはマスク領域をスコアリングして、マスク内の特徴の相対的な順序を生成します。これにより、予測を行うときに「モデルがどこを見ているか」を説明する顕著性マップが作成されます。 MNIST、ImageNet、Beer Reviewsの3つのデータセットで手法を評価し、勾配ベースの方法のみと比較して、アプローチによって生成された領域がまばらで、高い顕著性スコアを達成していることを定量的および定性的に示します。,6.0,https://d3i71xaburhd42.cloudfront.net/d26dff2f8637e42340baf76b183489c4745341eb/7-Figure2-1.png
Seq2Tens: An Efficient Representation of Sequences by Low-Rank Tensor Projections,"['Csaba Toth', 'Patric Bonnier', 'Harald Oberhauser']",https://openreview.net/forum?id=dx4b7lm8jMM,"Sequential data such as time series, video, or text can be challenging to analyse as the ordered structure gives rise to complex dependencies. At the heart of this is non-commutativity, in the sense that reordering the elements of a sequence can completely change its meaning. We use a classical mathematical object -- the tensor algebra -- to capture such dependencies. To address the innate computational complexity of high degree tensors, we use compositions of low-rank tensor projections. This yields modular and scalable building blocks for neural networks that give state-of-the-art performance on standard benchmarks such as multivariate time series classification and generative models for video.",時系列、ビデオ、テキストなどのシーケンシャルデータは、順序付けられた構造によって複雑な依存関係が生じるため、分析が難しい場合があります。この中心にあるのは、シーケンスの要素を並べ替えるとその意味が完全に変わる可能性があるという意味で、非可換性です。このような依存関係をキャプチャするために、古典的な数学的オブジェクトであるテンソル代数を使用します。高次テンソルの固有の計算の複雑さに対処するために、低ランクのテンソル射影の合成を使用します。これにより、多変量時系列分類やビデオの生成モデルなどの標準ベンチマークで最先端のパフォーマンスを提供する、ニューラルネットワーク用のモジュール式でスケーラブルなビルディングブロックが得られます。,6.0,https://d3i71xaburhd42.cloudfront.net/75f6f8bf4f821d2aeee2d7d139014457aa2e9512/6-Figure1-1.png
What they do when in doubt: a study of inductive biases in seq2seq learners,"['Eugene Kharitonov', 'Rahma Chaabouni']",https://openreview.net/forum?id=YmA86Zo-P_t,"Sequence-to-sequence (seq2seq) learners are widely used, but we still have only limited knowledge about what inductive biases shape the way they generalize. We address that by investigating how popular seq2seq learners generalize in tasks that have high ambiguity in the training data. We use four new tasks  to study learners' preferences for memorization, arithmetic, hierarchical, and compositional reasoning. Further, we connect to Solomonoff's theory of induction and propose to use description length as a principled and sensitive measure of inductive biases. In our experimental study, we find that LSTM-based learners can learn to perform counting, addition, and multiplication by a constant from a single training example. Furthermore, Transformer and LSTM-based learners show a bias toward the hierarchical induction over the linear one, while CNN-based learners prefer the opposite. The latter also show a bias toward a compositional generalization over memorization. Finally, across all our experiments, description length proved to be a sensitive measure of inductive biases.",シーケンス間（seq2seq）学習者は広く使用されていますが、一般化する方法を形成する誘導バイアスについての知識はまだ限られています。人気のあるseq2seq学習者が、トレーニングデータのあいまいさの高いタスクでどのように一般化するかを調査することでこれに対処します。 4つの新しいタスクを使用して、暗記、算術、階層、および構成的推論に対する学習者の好みを研究します。さらに、帰納法のソロモノフ理論に接続し、帰納法のバイアスの原理的で敏感な尺度として記述長を使用することを提案します。私たちの実験的研究では、LSTMベースの学習者は、単一のトレーニング例から、定数によるカウント、加算、および乗算の実行を学習できることがわかりました。さらに、TransformerおよびLSTMベースの学習者は、線形誘導よりも階層的誘導に偏っていますが、CNNベースの学習者はその逆を好みます。後者はまた、暗記よりも構成の一般化へのバイアスを示しています。最後に、すべての実験で、記述の長さは誘導バイアスの敏感な尺度であることが証明されました。,6.0,https://d3i71xaburhd42.cloudfront.net/3c7e2e2a533374da617ffa2799f51eb5dfd1723c/4-Figure1-1.png
Property Controllable Variational Autoencoder via Invertible Mutual Dependence,"['Xiaojie Guo', 'Yuanqi Du', 'Liang Zhao']",https://openreview.net/forum?id=tYxG_OMs9WE,"Deep generative models have made important progress towards modeling complex, high dimensional data via learning latent representations. Their usefulness is nevertheless often limited by a lack of control over the generative process or a poor understanding of the latent representation. To overcome these issues, attention is now focused on discovering latent variables correlated to the data properties and ways to manipulate these properties. This paper presents the new Property controllable VAE (PCVAE), where a new Bayesian model is proposed to inductively bias the latent representation using explicit data properties via novel group-wise and property-wise disentanglement. Each data property corresponds seamlessly to a latent variable, by innovatively enforcing invertible mutual dependence between them. This allows us to move along the learned latent dimensions to control specific properties of the generated data with great precision. Quantitative and qualitative evaluations confirm that the PCVAE outperforms the existing models by up to 28% in capturing and 65% in manipulating the desired properties.",深い生成モデルは、潜在表現の学習を通じて複雑な高次元データのモデリングに向けて重要な進歩を遂げました。それにもかかわらず、それらの有用性は、生成プロセスに対する制御の欠如または潜在的表現の不十分な理解によってしばしば制限されます。これらの問題を克服するために、現在、データプロパティに相関する潜在変数の発見とこれらのプロパティを操作する方法に注目が集まっています。この論文では、新しいプロパティ制御可能VAE（PCVAE）を紹介します。ここでは、新しいベイズモデルを提案して、新しいグループごとおよびプロパティごとの解きほぐしを介して、明示的なデータプロパティを使用して潜在表現に帰納的にバイアスをかけます。各データプロパティは、それらの間の可逆的な相互依存を革新的に実施することにより、潜在変数にシームレスに対応します。これにより、学習した潜在的な次元に沿って移動し、生成されたデータの特定のプロパティを非常に正確に制御できます。定量的および定性的評価により、PCVAEが既存のモデルを最大28まで上回っていることを確認します,6.0,
Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network,"['James Diffenderfer', 'Bhavya Kailkhura']",https://openreview.net/forum?id=U_mat0b9iv,"Recently, \cite{frankle2018lottery} demonstrated that randomly-initialized dense networks contain subnetworks that once found can be trained to reach test accuracy comparable to the trained dense network. However, finding these high performing trainable subnetworks is expensive, requiring iterative process of training and pruning weights. 
In this paper, we propose (and prove) a stronger \emph{Multi-Prize Lottery Ticket Hypothesis}:

\emph{A sufficiently over-parameterized neural network with random weights contains several subnetworks (winning tickets) that (a) have comparable accuracy to a dense target network with learned weights (prize 1), (b) do not require any further training to achieve prize 1 (prize 2), and (c) is robust to extreme forms of quantization (i.e., binary weights and/or activation) (prize 3).}

\noindent This provides a new paradigm for learning compact yet highly accurate binary neural networks by pruning and quantizing randomly weighted full precision neural networks.
These multi-prize tickets enjoy a number of desirable properties including drastically reduced memory size, faster test-time inference, and lower power consumption compared to their dense and full-precision counterparts. Furthermore, we propose an algorithm for finding multi-prize tickets and test it by performing a series of experiments on CIFAR-10 and ImageNet datasets. Empirical results indicate that as models grow deeper and wider, untrained multi-prize tickets start to reach similar (and sometimes even higher) test accuracy compared to their significantly larger and full-precision counterparts that have been weight-trained.
With minimal hyperparameter tuning, our binary weight multi-prize tickets outperform current state-of-the-art in binary neural networks.",最近、ランダムに初期化された高密度ネットワークにサブネットワークが含まれていることが実証されました。サブネットワークは、一度検出されると、トレーニング済みの高密度ネットワークに匹敵するテスト精度に到達するようにトレーニングできます。ただし、これらの高性能のトレーニング可能なサブネットワークを見つけるにはコストがかかり、ウェイトのトレーニングとプルーニングの反復プロセスが必要になります。この論文では、より強力なマルチ賞宝くじチケット仮説を提案（および証明）します。ランダムな重みを持つ十分にパラメーター化されたニューラルネットワークには、（a）学習した高密度ターゲットネットワークと同等の精度を持ついくつかのサブネットワーク（当選チケット）が含まれます重み（賞1）、（b）は、賞1（賞2）を達成するために追加のトレーニングを必要とせず、（c）極端な形式の量子化（つまり、バイナリの重みおよび/またはアクティブ化）（賞3）に対して堅牢です。これは、ランダムに重み付けされた全精度ニューラルネットワークを剪定および量子化することにより、コンパクトでありながら高精度のバイナリニューラルネットワークを学習するための新しいパラダイムを提供します。これらのマルチプライズチケットは、メモリサイズの大幅な削減、テスト時間の推測の高速化、高密度で高精度のチケットと比較して消費電力の削減など、多くの望ましい特性を備えています。さらに、マルチプライズチケットを見つけるためのアルゴリズムを提案し、CIFAR-10およびImageNetデータセットで一連の実験を実行してテストします。経験的結果は、モデルがより深く、より広くなるにつれて、トレーニングされていないマルチプライズチケットは、ウェイトトレーニングされたかなり大きくて完全な精度のチケットと比較して、同様の（場合によってはさらに高い）テスト精度に到達し始めることを示しています。最小限のハイパーパラメータ調整により、バイナリウェイトマルチプライズチケットは、バイナリニューラルネットワークの現在の最先端技術を上回ります。,6.0,
Enforcing robust control guarantees within neural network policies,"['Priya L. Donti', 'Melrose Roderick', 'Mahyar Fazlyab', 'J Zico Kolter']",https://openreview.net/forum?id=5lhWG3Hj2By,"When designing controllers for safety-critical systems, practitioners often face a challenging tradeoff between robustness and performance. While robust control methods provide rigorous guarantees on system stability under certain worst-case disturbances, they often yield simple controllers that perform poorly in the average (non-worst) case. In contrast, nonlinear control methods trained using deep learning have achieved state-of-the-art performance on many control tasks, but often lack robustness guarantees. In this paper, we propose a technique that combines the strengths of these two approaches: constructing a generic nonlinear control policy class, parameterized by neural networks, that nonetheless enforces the same provable robustness criteria as robust control. Specifically, our approach entails integrating custom convex-optimization-based projection layers into a neural network-based policy. We demonstrate the power of this approach on several domains, improving in average-case performance over existing robust control methods and in worst-case stability over (non-robust) deep RL methods.",セーフティクリティカルシステム用のコントローラーを設計する場合、実務家は堅牢性とパフォーマンスの間で困難なトレードオフに直面することがよくあります。ロバスト制御方法は、特定の最悪の場合の外乱下でのシステムの安定性を厳密に保証しますが、平均的な（最悪でない）場合にはパフォーマンスが低下する単純なコントローラーを生成することがよくあります。対照的に、深層学習を使用してトレーニングされた非線形制御方法は、多くの制御タスクで最先端のパフォーマンスを達成しましたが、多くの場合、堅牢性の保証がありません。この論文では、これら2つのアプローチの長所を組み合わせた手法を提案します。ニューラルネットワークによってパラメータ化された一般的な非線形制御ポリシークラスを構築しますが、ロバスト制御と同じ証明可能なロバスト性基準を適用します。具体的には、私たちのアプローチでは、カスタムの凸最適化ベースの投影レイヤーをニューラルネットワークベースのポリシーに統合する必要があります。いくつかのドメインでこのアプローチの力を示し、既存のロバスト制御方法よりも平均的な場合のパフォーマンスを改善し、（非ロバスト）ディープRL方法よりも最悪の場合の安定性を向上させます。,6.0,https://d3i71xaburhd42.cloudfront.net/a524ac97582356d814b59102ab8559fdf7f44c0d/23-FigureI-1.png
Neural Jump Ordinary Differential Equations,"['Calypso Herrera', 'Florian Krach', 'Josef Teichmann']",https://openreview.net/forum?id=JFKR3WqwyXR,"Combinations of neural ODEs with recurrent neural networks (RNN), like GRU-ODE-Bayes or ODE-RNN are well suited to model irregularly observed time series. While those models outperform existing discrete-time approaches, no theoretical guarantees for their predictive capabilities are available. Assuming that the irregularly-sampled time series data originates from a continuous stochastic process, the $L^2$-optimal online prediction is the conditional expectation given the currently available information. We introduce the neural jump ODE (NJ-ODE) that provides a data-driven approach to learn, continuously in time, the conditional expectation of a stochastic process. Our approach models the conditional expectation between two observations with a neural ODE and jumps whenever a new observation is made. We define a novel training framework, which allows us to prove theoretical guarantees for the first time. In particular, we show that the output of our model converges to the $L^2$-optimal prediction. We provide experiments showing that the theoretical results also hold empirically. Moreover, we experimentally show that our model outperforms the baselines in more complex learning tasks and give comparisons on real-world datasets.",GRU-ODE-BayesやODE-RNNなどのニューラルODEとリカレントニューラルネットワーク（RNN）の組み合わせは、不規則に観測された時系列をモデル化するのに適しています。これらのモデルは既存の離散時間アプローチよりも優れていますが、予測機能の理論的保証はありません。不規則にサンプリングされた時系列データが連続確率過程に由来すると仮定すると、L2最適オンライン予測は、現在利用可能な情報を前提とした条件付き期待値です。確率過程の条件付き期待値を時間内に継続的に学習するためのデータ駆動型アプローチを提供するニューラルジャンプODE（NJ-ODE）を紹介します。私たちのアプローチは、ニューラルODEを使用して2つの観測間の条件付き期待値をモデル化し、新しい観測が行われるたびにジャンプします。新しいトレーニングフレームワークを定義します。これにより、理論上の保証を初めて証明できます。特に、モデルの出力がL2最適予測に収束することを示します。理論的結果も経験的に成り立つことを示す実験を提供します。さらに、モデルがより複雑な学習タスクのベースラインを上回っていることを実験的に示し、実際のデータセットで比較します。,6.0,
Bowtie Networks: Generative Modeling for Joint Few-Shot Recognition and Novel-View Synthesis,"['Zhipeng Bao', 'Yu-Xiong Wang', 'Martial Hebert']",https://openreview.net/forum?id=ESG-DMKQKsD,"In this paper, we propose a novel dual-task of joint few-shot recognition and novel-view synthesis: given only one or few images of a novel object from arbitrary views with only category annotation, we aim to simultaneously learn an object classifier and generate images of that type of object from new viewpoints. While there has been increasing interest in simultaneously addressing two or more tasks, existing work mainly focuses on multi-task learning of shareable feature representations. Here, we take a different perspective --- learning a shared generative model across the dual-task. To this end, we propose bowtie networks that jointly learn 3D geometric and semantic representations with a feedback loop. Experimental evaluation on challenging fine-grained recognition datasets demonstrates that our synthesized images are realistic from multiple viewpoints and significantly improve recognition performance as ways of data augmentation, especially in the low-data regime.",この論文では、共同数ショット認識と小説ビュー合成の新しいデュアルタスクを提案します。カテゴリ注釈のみの任意のビューからの小説オブジェクトの1つまたは少数の画像のみを与えられ、オブジェクト分類器とそのタイプのオブジェクトの画像を新しい視点から生成します。 2つ以上のタスクに同時に対処することへの関心が高まっている一方で、既存の作業は主に共有可能な特徴表現のマルチタスク学習に焦点を合わせています。ここでは、デュアルタスク全体で共有生成モデルを学習する別の視点を取ります。この目的のために、フィードバックループを使用して3Dの幾何学的表現と意味表現を共同で学習するボウタイネットワークを提案します。挑戦的なきめの細かい認識データセットの実験的評価は、私たちの合成画像が複数の視点から現実的であり、特に低データ体制において、データ増強の方法として認識性能を大幅に改善することを示しています。,6.0,https://d3i71xaburhd42.cloudfront.net/b28ae48d917a5aa7a766ca1659d7deb37799bc5c/2-Figure1-1.png
Statistical inference for individual fairness,"['Subha Maity', 'Songkai Xue', 'Mikhail Yurochkin', 'Yuekai Sun']",https://openreview.net/forum?id=z9k8BWL-_2u,"As we rely on machine learning (ML) models to make more consequential decisions, the issue of ML models perpetuating unwanted social biases has come to the fore of the public's and the research community's attention. In this paper, we focus on the problem of detecting violations of individual fairness in ML models. We formalize the problem as measuring the susceptibility of ML models against a form of adversarial attack and develop a suite of inference tools for the adversarial loss. The tools allow practitioners to assess the individual fairness of ML models in a statistically-principled way: form confidence intervals for the adversarial loss and test hypotheses of model fairness with (asymptotic) non-coverage/Type I error rate control. We demonstrate the utility of our tools in a real-world case study.",より重要な意思決定を行うために機械学習（ML）モデルに依存しているため、望ましくない社会的バイアスを永続させるMLモデルの問題が、一般の人々や研究コミュニティの注目を集めています。この論文では、MLモデルにおける個人の公平性の違反を検出する問題に焦点を当てます。敵対的攻撃の形式に対するMLモデルの感受性を測定することとして問題を形式化し、敵対的損失のための一連の推論ツールを開発します。これらのツールを使用すると、実践者は統計的に原理的な方法でMLモデルの個々の公平性を評価できます。敵対的損失の信頼区間を形成し、（漸近的な）非カバレッジ/タイプIのエラー率制御を使用してモデルの公平性の仮説をテストします。実際のケーススタディで、ツールの有用性を示します。,6.0,
Predicting Classification Accuracy when Adding New Unobserved Classes,"['Yuli Slavutsky', 'Yuval Benjamini']",https://openreview.net/forum?id=Y9McSeEaqUh,"Multiclass classifiers are often designed and evaluated only on a sample from the classes on which they will eventually be applied. Hence, their final accuracy remains unknown. In this work we study how a classifier’s performance over the initial class sample can be used to extrapolate its expected accuracy on a larger, unobserved set of classes. For this, we define a measure of separation between correct and incorrect classes that is independent of the number of classes: the ""reversed ROC"" (rROC), which is obtained by replacing the roles of classes and data-points in the common ROC. We show that the classification accuracy is a function of the rROC in multiclass classifiers, for which the learned representation of data from the initial class sample remains unchanged when new classes are added. Using these results we formulate a robust neural-network-based algorithm, ""CleaneX"", which learns to estimate the accuracy of such classifiers on arbitrarily large sets of classes. Unlike previous methods, our method uses both the observed accuracies of the classifier and densities of classification scores, and therefore achieves remarkably better predictions than current state-of-the-art methods on both simulations and real datasets of object detection, face recognition, and brain decoding.",マルチクラス分類器は、多くの場合、最終的に適用されるクラスのサンプルに対してのみ設計および評価されます。したがって、それらの最終的な精度は不明のままです。この作業では、最初のクラスサンプルに対する分類器のパフォーマンスを使用して、より大きな、観測されていないクラスのセットで期待される精度を推定する方法を研究します。このために、クラスの数に依存しない正しいクラスと正しくないクラスの分離の尺度を定義します。これは、共通のROCでクラスとデータポイントの役割を置き換えることによって取得される「逆ROC」（rROC）です。分類精度は、マルチクラス分類器のrROCの関数であり、新しいクラスが追加されても、初期クラスサンプルから学習されたデータの表現は変更されないことを示します。これらの結果を使用して、堅牢なニューラルネットワークベースのアルゴリズム「CleaneX」を作成します。このアルゴリズムは、任意の大きなクラスのセットでこのような分類器の精度を推定することを学習します。以前の方法とは異なり、私たちの方法は、分類器の観測された精度と分類スコアの密度の両方を使用するため、シミュレーションとオブジェクト検出、顔認識、および脳の解読。,6.0,https://d3i71xaburhd42.cloudfront.net/33391f5117b1e93548b0f297de1e36ee4a61157a/4-Figure1-1.png
Targeted Attack against Deep Neural Networks via Flipping Limited Weight Bits,"['Jiawang Bai', 'Baoyuan Wu', 'Yong Zhang', 'Yiming Li', 'Zhifeng Li', 'Shu-Tao Xia']",https://openreview.net/forum?id=iKQAk8a2kM0,"To explore the vulnerability of deep neural networks (DNNs), many attack paradigms have been well studied, such as the poisoning-based backdoor attack in the training stage and the adversarial attack in the inference stage. In this paper, we study a novel attack paradigm, which modifies model parameters in the deployment stage for malicious purposes. Specifically, our goal is to misclassify a specific sample into a target class without any sample modification, while not significantly reduce the prediction accuracy of other samples to ensure the stealthiness. To this end, we formulate this problem as a binary integer programming (BIP), since the parameters are stored as binary bits ($i.e.$, 0 and 1) in the memory. By utilizing the latest technique in integer programming, we equivalently reformulate this BIP problem as a continuous optimization problem, which can be effectively and efficiently solved using the alternating direction method of multipliers (ADMM) method. Consequently, the flipped critical bits can be easily determined through optimization, rather than using a heuristic strategy. Extensive experiments demonstrate the superiority of our method in attacking DNNs.",ディープニューラルネットワーク（DNN）の脆弱性を調査するために、トレーニング段階でのポイズニングベースのバックドア攻撃や推論段階での敵対的攻撃など、多くの攻撃パラダイムが十分に研究されてきました。このホワイトペーパーでは、悪意のある目的で展開段階でモデルパラメータを変更する新しい攻撃パラダイムを研究します。具体的には、ステルス性を確保するために他のサンプルの予測精度を大幅に低下させずに、サンプルを変更せずに特定のサンプルをターゲットクラスに誤って分類することを目標としています。この目的のために、パラメータが2進ビット（つまり、0と1）としてメモリに格納されるため、この問題を2進整数計画法（BIP）として定式化します。整数計画法の最新技術を利用することにより、このBIP問題を連続最適化問題として同等に再定式化します。これは乗数の交互方向法（ADMM）法を使用して効果的かつ効率的に解決できます。その結果、反転したクリティカルビットは、ヒューリスティック戦略を使用するのではなく、最適化によって簡単に決定できます。広範な実験は、DNNの攻撃における私たちの方法の優位性を示しています。,6.0,
Relating by Contrasting: A Data-efficient Framework for Multimodal Generative Models,"['Yuge Shi', 'Brooks Paige', 'Philip Torr', 'Siddharth N']",https://openreview.net/forum?id=vhKe9UFbrJo,"Multimodal learning for generative models often refers to the learning of abstract concepts from the commonality of information in multiple modalities, such as vision and language. While it has proven effective for learning generalisable representations, the training of such models often requires a large amount of related multimodal data that shares commonality, which can be expensive to come by. To mitigate this, we develop a novel contrastive framework for generative model learning, allowing us to train the model not just by the commonality between modalities, but by the distinction between ""related"" and ""unrelated"" multimodal data. We show in experiments that our method enables data-efficient multimodal learning on challenging datasets for various multimodal VAE models. We also show that under our proposed framework, the generative model can accurately identify related samples from unrelated ones, making it possible to make use of the plentiful unlabeled, unpaired multimodal data.",生成モデルのマルチモーダル学習は、多くの場合、視覚や言語などの複数のモダリティにおける情報の共通性から抽象的な概念を学習することを指します。一般化可能な表現の学習に効果的であることが証明されていますが、そのようなモデルのトレーニングには、共通性を共有する大量の関連するマルチモーダルデータが必要になることが多く、手に入れるのに費用がかかる可能性があります。これを軽減するために、生成モデル学習のための新しい対照的なフレームワークを開発し、モダリティ間の共通性だけでなく、「関連する」マルチモーダルデータと「関連しない」マルチモーダルデータの区別によってモデルをトレーニングできるようにします。実験では、私たちの方法がさまざまなマルチモーダルVAEモデルの挑戦的なデータセットでデータ効率の高いマルチモーダル学習を可能にすることを示しています。また、提案されたフレームワークの下で、生成モデルが関連のないサンプルから関連のあるサンプルを正確に識別できることを示します。これにより、ラベルのない、ペアになっていない豊富なマルチモーダルデータを利用できるようになります。,6.0,https://d3i71xaburhd42.cloudfront.net/f2f3c91fad164c8919699159e8eab511f03d0fe2/5-Figure5-1.png
Sharper Generalization Bounds for Learning with Gradient-dominated Objective Functions,"['Yunwen Lei', 'Yiming Ying']",https://openreview.net/forum?id=r28GdiQF7vM,"Stochastic optimization has become the workhorse behind many successful machine learning applications, which motivates a lot of theoretical analysis to understand its empirical behavior. As a comparison, there is far less work to study the generalization behavior especially in a non-convex learning setting. In this paper, we study the generalization behavior of stochastic optimization by leveraging the algorithmic stability for learning with $\beta$-gradient-dominated objective functions. We develop generalization bounds of the order $O(1/(n\beta))$ plus the convergence rate of the optimization algorithm, where $n$ is the sample size. Our stability analysis significantly improves the existing non-convex analysis by removing the bounded gradient assumption and implying better generalization bounds. We achieve this improvement by exploiting the smoothness of loss functions instead of the Lipschitz condition in Charles & Papailiopoulos (2018). We apply our general results to various stochastic optimization algorithms, which show clearly how the variance-reduction techniques improve not only training but also generalization. Furthermore, our discussion explains how interpolation helps generalization for highly expressive models.",確率的最適化は、多くの成功した機械学習アプリケーションの背後にある主力製品になりました。これは、その経験的動作を理解するために多くの理論的分析を動機付けます。比較として、特に非凸学習環境での一般化動作を研究する作業ははるかに少なくなります。この論文では、勾配が支配的な目的関数で学習するためのアルゴリズムの安定性を活用することにより、確率的最適化の一般化動作を研究します。次数O（1 /（n））と最適化アルゴリズムの収束率の一般化範囲を作成します。ここで、nはサンプルサイズです。私たちの安定性分析は、有界勾配の仮定を削除し、より良い一般化限界を暗示することにより、既存の非凸分析を大幅に改善します。 Charles＆Papailiopoulos（2018）のリプシッツ条件の代わりに、損失関数の滑らかさを利用することで、この改善を実現します。一般的な結果をさまざまな確率的最適化アルゴリズムに適用します。これは、分散減少法がトレーニングだけでなく一般化もどのように改善するかを明確に示しています。さらに、私たちの議論は、補間が表現力の高いモデルの一般化にどのように役立つかを説明しています。,6.0,
Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning,"['Beliz Gunel', 'Jingfei Du', 'Alexis Conneau', 'Veselin Stoyanov']",https://openreview.net/forum?id=cu7IUiOhujH,"State-of-the-art natural language understanding classification models follow two-stages: pre-training a large language model on an auxiliary task, and then fine-tuning the model on a task-specific labeled dataset using cross-entropy loss. Cross-entropy loss has several shortcomings that can lead to sub-optimal generalization and instability. Driven by the intuition that good generalization requires capturing the similarity between examples in one class and contrasting them with examples in other classes, we propose a supervised contrastive learning (SCL) objective for the fine-tuning stage. Combined with cross-entropy, the SCL loss we propose obtains significant improvements over a strong RoBERTa-Large baseline on multiple datasets of the GLUE benchmark in the few-shot learning settings, and it does not require any specialized architecture, data augmentation of any kind, memory banks, or additional unsupervised data. The new objective leads to models that are more robust to different levels of noise in the training data, and can generalize better to related tasks with limited labeled data.",最先端の自然言語理解分類モデルは、2つの段階に従います。補助タスクで大規模な言語モデルを事前トレーニングし、クロスエントロピー損失を使用してタスク固有のラベル付きデータセットでモデルを微調整します。クロスエントロピー損失には、次善の一般化と不安定性につながる可能性のあるいくつかの欠点があります。優れた一般化には、あるクラスの例間の類似性をキャプチャし、それらを他のクラスの例と対比する必要があるという直感に基づいて、微調整段階の教師あり対照学習（SCL）の目的を提案します。クロスエントロピーと組み合わせることで、私たちが提案するSCL損失は、数ショットの学習設定でGLUEベンチマークの複数のデータセットの強力なRoBERTa-Largeベースラインを大幅に改善し、特別なアーキテクチャやあらゆる種類のデータ拡張を必要としません。 、メモリバンク、または追加の教師なしデータ。新しい目的は、トレーニングデータのさまざまなレベルのノイズに対してより堅牢なモデルにつながり、ラベル付けされたデータが限られている関連タスクによりよく一般化できます。,6.0,https://d3i71xaburhd42.cloudfront.net/96c22a88ec3b9d3799daa41098555ab665c24ea8/3-Figure1-1.png
Understanding and Improving Encoder Layer Fusion in Sequence-to-Sequence Learning,"['Xuebo Liu', 'Longyue Wang', 'Derek F. Wong', 'Liang Ding', 'Lidia S. Chao', 'Zhaopeng Tu']",https://openreview.net/forum?id=n1HD8M6WGn,"Encoder layer fusion (EncoderFusion) is a technique to fuse all the encoder layers (instead of the uppermost layer) for sequence-to-sequence (Seq2Seq) models, which has proven effective on various NLP tasks. However, it is still not entirely clear why and when EncoderFusion should work. In this paper, our main contribution is to take a step further in understanding EncoderFusion. Many of previous studies believe that the success of EncoderFusion comes from exploiting surface and syntactic information embedded in lower encoder layers. Unlike them, we find that the encoder embedding layer is more important than other intermediate encoder layers. In addition, the uppermost decoder layer consistently pays more attention to the encoder embedding layer across NLP tasks. Based on this observation, we propose a simple fusion method, SurfaceFusion, by fusing only the encoder embedding layer for the softmax layer. Experimental results show that SurfaceFusion outperforms EncoderFusion on several NLP benchmarks, including machine translation, text summarization, and grammatical error correction. It obtains the state-of-the-art performance on WMT16 Romanian-English and WMT14 English-French translation tasks. Extensive analyses reveal that SurfaceFusion learns more expressive bilingual word embeddings by building a closer relationship between relevant source and target embeddings. The source code will be released.",エンコーダーレイヤーフュージョン（EncoderFusion）は、シーケンス間（Seq2Seq）モデルのすべてのエンコーダーレイヤー（最上層ではなく）をフュージョンする手法であり、さまざまなNLPタスクで効果的であることが証明されています。ただし、EncoderFusionが機能する理由と時期はまだ完全には明らかではありません。このホワイトペーパーでは、EncoderFusionをさらに理解するための一歩を踏み出すことが主な貢献です。以前の研究の多くは、EncoderFusionの成功は、下位のエンコーダー層に埋め込まれた表面情報と構文情報を活用することから来ると信じています。それらとは異なり、エンコーダ埋め込み層は他の中間エンコーダ層よりも重要であることがわかります。さらに、最上位のデコーダーレイヤーは、NLPタスク全体でエンコーダー埋め込みレイヤーに一貫して注意を払います。この観察に基づいて、ソフトマックス層のエンコーダ埋め込み層のみを融合することにより、単純な融合方法であるSurfaceFusionを提案します。実験結果は、SurfaceFusionが、機械翻訳、テキスト要約、文法エラー訂正など、いくつかのNLPベンチマークでEncoderFusionよりも優れていることを示しています。 WMT16ルーマニア語-英語およびWMT14英語-フランス語翻訳タスクで最先端のパフォーマンスを取得します。広範な分析により、SurfaceFusionは、関連するソースとターゲットの埋め込みの間のより緊密な関係を構築することにより、より表現力豊かなバイリンガルの単語埋め込みを学習することが明らかになりました。ソースコードが公開されます。,6.0,https://d3i71xaburhd42.cloudfront.net/9ee27d4df0a0e7032c520cb5f26567fb06769ad1/4-Figure1-1.png
Isometric Propagation Network for Generalized Zero-shot Learning,"['Lu Liu', 'Tianyi Zhou', 'Guodong Long', 'Jing Jiang', 'Xuanyi Dong', 'Chengqi Zhang']",https://openreview.net/forum?id=-mWcQVLPSPy,"Zero-shot learning (ZSL) aims to classify images of an unseen class only based on a few attributes describing that class but no access to any training sample. A popular strategy is to learn a mapping between the semantic space of class attributes and the visual space of images based on the seen classes and their data. Thus, an unseen class image can be ideally mapped to its corresponding class attributes. The key challenge is how to align the representations in the two spaces. For most ZSL settings, the attributes for each seen/unseen class are only represented by a vector while the seen-class data provide much more information. Thus, the imbalanced supervision from the semantic and the visual space can make the learned mapping easily overfitting to the seen classes. To resolve this problem, we propose Isometric Propagation Network (IPN), which learns to strengthen the relation between classes within each space and align the class dependency in the two spaces. Specifically, IPN learns to propagate the class representations on an auto-generated graph within each space. In contrast to only aligning the resulted static representation, we regularize the two dynamic propagation procedures to be isometric in terms of the two graphs' edge weights per step by minimizing a consistency loss between them. IPN achieves state-of-the-art performance on three popular ZSL benchmarks. To evaluate the generalization capability of IPN, we further build two larger benchmarks with more diverse unseen classes and demonstrate the advantages of IPN on them.",ゼロショット学習（ZSL）は、見えないクラスの画像を、そのクラスを説明するいくつかの属性のみに基づいて分類することを目的としていますが、トレーニングサンプルにはアクセスできません。一般的な戦略は、見られたクラスとそのデータに基づいて、クラス属性の意味空間と画像の視覚空間の間のマッピングを学習することです。したがって、見えないクラス画像は、対応するクラス属性に理想的にマッピングできます。重要な課題は、2つのスペースで表現をどのように整列させるかです。ほとんどのZSL設定では、各表示/非表示クラスの属性はベクトルでのみ表されますが、表示クラスデータははるかに多くの情報を提供します。したがって、セマンティック空間と視覚空間からの不均衡な監視により、学習したマッピングが見たクラスに簡単に過剰適合する可能性があります。この問題を解決するために、各空間内のクラス間の関係を強化し、2つの空間内のクラス依存関係を調整することを学習するアイソメトリック伝搬ネットワーク（IPN）を提案します。具体的には、IPNは、各空間内で自動生成されたグラフ上のクラス表現を伝播することを学習します。結果の静的表現のみを整列させるのとは対照的に、2つの動的伝播手順を、それらの間の一貫性の損失を最小限に抑えることにより、ステップごとの2つのグラフのエッジの重みに関して等長になるように正規化します。 IPNは、3つの人気のあるZSLベンチマークで最先端のパフォーマンスを実現します。 IPNの一般化機能を評価するために、さらに多様な目に見えないクラスを使用して2つの大きなベンチマークを構築し、それらに対するIPNの利点を示します。,6.0,https://d3i71xaburhd42.cloudfront.net/26147e2b3f82417b56f61ee01b02979396b7e1b7/2-Figure1-1.png
On Data-Augmentation and Consistency-Based Semi-Supervised Learning,"['Atin Ghosh', 'Alexandre H. Thiery']",https://openreview.net/forum?id=7FNqrcPtieT,"Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.",Piモデル、時間的アンサンブル、平均教師、仮想敵対的トレーニングなど、最近提案された一貫性ベースの半教師あり学習（SSL）手法は、いくつかのSSLタスクで最先端の結果を達成します。これらの方法は通常、ラベル付けされた例のごく一部を使用しながら、完全に監視された対応する方法に匹敵するパフォーマンスに到達できます。これらの方法論の進歩にもかかわらず、これらの方法の理解はまだ比較的限られています。進歩を遂げるために、分析的に扱いやすい結果が得られる設定でPiモデル（のバリエーション）を分析します。多様体接線分類器とのリンクを確立し、摂動の品質が妥当なSSLパフォーマンスを取得するための鍵であることを示します。さらに、データ拡張スキームを自然に組み込み、SSLメソッドを理解するための扱いやすいフレームワークを提供するHidden ManifoldModelの単純な拡張を提案します。,6.0,https://d3i71xaburhd42.cloudfront.net/b4cc976bd6fd45aa8ad91859a962d4b90ba580c3/5-Figure1-1.png
Monte-Carlo Planning and Learning with Language Action Value Estimates,"['Youngsoo Jang', 'Seokin Seo', 'Jongmin Lee', 'Kee-Eung Kim']",https://openreview.net/forum?id=7_G8JySGecm,"Interactive Fiction (IF) games provide a useful testbed for language-based reinforcement learning agents, posing significant challenges of natural language understanding, commonsense reasoning, and non-myopic planning in the combinatorial search space. Agents based on standard planning algorithms struggle to play IF games due to the massive search space of language actions. Thus, language-grounded planning is a key ability of such agents, since inferring the consequence of language action based on semantic understanding can drastically improve search. In this paper, we introduce Monte-Carlo planning with Language Action Value Estimates (MC-LAVE) that combines a Monte-Carlo tree search with language-driven exploration. MC-LAVE invests more search effort into semantically promising language actions using locally optimistic language value estimates, yielding a significant reduction in the effective search space of language actions. We then present a reinforcement learning approach via MC-LAVE, which alternates between MC-LAVE planning and supervised learning of the self-generated language actions. In the experiments, we demonstrate that our method achieves new high scores in various IF games.",インタラクティブフィクション（IF）ゲームは、言語ベースの強化学習エージェントに役立つテストベッドを提供し、自然言語理解、常識的推論、および組み合わせ検索スペースでの非ミオピック計画の重大な課題を提起します。標準の計画アルゴリズムに基づくエージェントは、言語アクションの膨大な検索スペースのためにIFゲームをプレイするのに苦労しています。したがって、意味理解に基づいて言語アクションの結果を推測することで検索を大幅に改善できるため、言語に基づいた計画はそのようなエージェントの重要な能力です。このホワイトペーパーでは、モンテカルロツリー検索と言語駆動型探索を組み合わせた言語アクション値推定（MC-LAVE）を使用したモンテカルロ計画を紹介します。 MC-LAVEは、ローカルで楽観的な言語値の推定値を使用して、意味的に有望な言語アクションにより多くの検索作業を投資し、言語アクションの有効な検索スペースを大幅に削減します。次に、MC-LAVEを介した強化学習アプローチを紹介します。これは、MC-LAVE計画と、自己生成言語アクションの教師あり学習を交互に行います。実験では、私たちの方法がさまざまなIFゲームで新しいハイスコアを達成することを示しています。,6.0,
Generating Furry Cars: Disentangling Object Shape and Appearance across Multiple Domains,"['Utkarsh Ojha', 'Krishna Kumar Singh', 'Yong Jae Lee']",https://openreview.net/forum?id=M88oFvqp_9,"We consider the novel task of learning disentangled representations of object shape and appearance across multiple domains (e.g., dogs and cars).  The goal is to learn a generative model that learns an intermediate distribution, which borrows a subset of properties from each domain, enabling the generation of images that did not exist in any domain exclusively.  This challenging problem requires an accurate disentanglement of object shape, appearance, and background from each domain, so that the appearance and shape factors from the two domains can be interchanged. We augment an existing approach that can disentangle factors within a single domain but struggles to do so across domains.  Our key technical contribution is to represent object appearance with a differentiable histogram of visual features, and to optimize the generator so that two images with the same latent appearance factor but different latent shape factors produce similar histograms. On multiple multi-domain datasets, we demonstrate our method leads to accurate and consistent appearance and shape transfer across domains.",複数のドメイン（犬や車など）でオブジェクトの形状と外観の解きほぐされた表現を学習するという新しいタスクを検討します。目標は、各ドメインからプロパティのサブセットを借用し、どのドメインにも排他的に存在しなかった画像の生成を可能にする中間分布を学習する生成モデルを学習することです。この困難な問題では、2つのドメインの外観と形状の要素を交換できるように、各ドメインのオブジェクトの形状、外観、背景を正確に解きほぐす必要があります。単一のドメイン内の要因を解きほぐすことができるが、ドメイン間でそうするのに苦労する既存のアプローチを強化します。私たちの重要な技術的貢献は、視覚的特徴の微分可能なヒストグラムでオブジェクトの外観を表現し、ジェネレータを最適化して、潜在的な外観係数が同じで潜在的な形状係数が異なる2つの画像が同様のヒストグラムを生成するようにすることです。複数のマルチドメインデータセットで、私たちの方法がドメイン間で正確で一貫した外観と形状の転送につながることを示します。,6.0,
Large-width functional asymptotics for deep Gaussian neural networks,"['Daniele Bracale', 'Stefano Favaro', 'Sandra Fortini', 'Stefano Peluchetti']",https://openreview.net/forum?id=0aW6lYOYB7d,"In this paper, we consider fully connected feed-forward deep neural networks where weights and biases are independent and identically distributed according to Gaussian distributions. Extending previous results (Matthews et al., 2018a;b;Yang, 2019)  we adopt a function-space perspective, i.e. we look at neural networks as infinite-dimensional random elements on the input space $\mathbb{R}^I$. Under suitable assumptions on the activation function we show that: i) a network defines a continuous Gaussian process on the input space $\mathbb{R}^I$; ii) a network with re-scaled weights converges weakly to a continuous Gaussian process in the large-width limit; iii) the limiting Gaussian process has almost surely locally $\gamma$-Hölder continuous paths, for $0 < \gamma <1$. Our results contribute to recent theoretical studies on the interplay between infinitely wide deep neural networks and Gaussian processes by establishing weak convergence in function-space with respect to a stronger metric.",この論文では、重みとバイアスが独立しており、ガウス分布に従って同一に分布している、完全に接続されたフィードフォワードディープニューラルネットワークについて検討します。以前の結果（Matthews et al。、2018a; b; Yang、2019）を拡張して、関数空間の視点を採用します。つまり、ニューラルネットワークを入力空間R ^（I）上の無限次元のランダム要素と見なします。活性化関数に関する適切な仮定の下で、次のことを示します。i）ネットワークが入力空間R ^（I）で連続ガウス過程を定義する。 ii）重みが再スケーリングされたネットワークは、広い幅の制限内で連続ガウス過程に弱く収束します。 iii）制限ガウス過程はほぼ確実に局所的に-0 &lt;&lt; 1の場合、連続パスを保持します。私たちの結果は、関数空間で弱い収束を確立することにより、無限に広い深層ニューラルネットワークとガウス過程の間の相互作用に関する最近の理論的研究に貢献します。より強力なメトリックに。,6.0,
"A Panda? No, It's a Sloth: Slowdown Attacks on Adaptive Multi-Exit Neural Network Inference","['Sanghyun Hong', 'Yigitcan Kaya', 'Ionuț-Vlad Modoranu', 'Tudor Dumitras']",https://openreview.net/forum?id=9xC2tWEwBD,"Recent increases in the computational demands of deep neural networks (DNNs), combined with the observation that most input samples require only simple models, have sparked interest in input-adaptive multi-exit architectures, such as MSDNets or Shallow Deep Networks. These architectures enable faster inferences and could bring DNNs to low-power devices, e.g. in the Internet of Things (IoT). However, it is unknown if the computational savings provided by this approach are robust against adversarial pressure. In particular, an adversary may aim to slow down adaptive DNNs by increasing their average inference time—a threat analogous to the denial-of-service attacks from the Internet. In this paper, we conduct a systematic evaluation of this threat by experimenting with three generic multi-exit DNNs (based on VGG16, MobileNet, and ResNet56) and a custom multi-exit architecture, on two popular image classification benchmarks (CIFAR-10 and Tiny ImageNet). To this end, we show that adversarial sample-crafting techniques can be modified to cause slowdown, and we propose a metric for comparing their impact on different architectures. We show that a slowdown attack reduces the efficacy of multi-exit DNNs by 90%–100%, and it amplifies the latency by 1.5–5× in a typical IoT deployment. We also show that it is possible to craft universal, reusable perturbations and that the attack can be effective in realistic black-box scenarios, where the attacker has limited knowledge about the victim. Finally, we show that adversarial training provides limited protection against slowdowns. These results suggest that further research is needed for defending multi-exit architectures against this emerging threat.",ディープニューラルネットワーク（DNN）の計算要求の最近の増加は、ほとんどの入力サンプルが単純なモデルのみを必要とするという観察と相まって、MSDNetsやShallow DeepNetworksなどの入力適応型マルチ出口アーキテクチャへの関心を呼び起こしました。これらのアーキテクチャは、より高速な推論を可能にし、モノのインターネット（IoT）などの低電力デバイスにDNNをもたらす可能性があります。ただし、このアプローチによって提供される計算上の節約が敵対的な圧力に対して堅牢であるかどうかは不明です。特に、攻撃者は、インターネットからのサービス拒否攻撃に類似した脅威の平均推論時間を増やすことによって、適応型DNNの速度を低下させることを目的とする場合があります。このホワイトペーパーでは、2つの一般的な画像分類ベンチマーク（CIFAR-10とResNet56）で、3つの汎用マルチ出口DNN（VGG16、MobileNet、およびResNet56に基づく）とカスタムマルチ出口アーキテクチャを実験することにより、この脅威の体系的な評価を行います。 Tiny ImageNet）。この目的のために、敵対的なサンプル作成手法を変更して速度を低下させることができることを示し、さまざまなアーキテクチャへの影響を比較するためのメトリックを提案します。スローダウン攻撃により、複数出口DNNの有効性が90低下することを示します,6.0,https://d3i71xaburhd42.cloudfront.net/14392f4d79d97a53670f9755eef7b275fc8224c0/2-Figure1-1.png
Overparameterisation and worst-case generalisation: friend or foe?,"['Aditya Krishna Menon', 'Ankit Singh Rawat', 'Sanjiv Kumar']",https://openreview.net/forum?id=jphnJNOwe36,"Overparameterised neural networks have demonstrated the remarkable ability to perfectly fit training samples, while still generalising to unseen test samples. However, several recent works have revealed that such models' good average performance does not always translate to good worst-case performance: in particular, they may perform poorly on subgroups that are under-represented in the training set. In this paper, we show that in certain settings, overparameterised models' performance on under-represented subgroups may be improved via post-hoc processing. Specifically, such models' bias can be restricted to their classification layers, and manifest as structured prediction shifts for rare subgroups. We detail two post-hoc correction techniques to mitigate this bias, which operate purely on the outputs of standard model training. We empirically verify that with such post-hoc correction, overparameterisation can improve average and worst-case performance.",過剰にパラメータ化されたニューラルネットワークは、目に見えないテストサンプルに一般化しながら、トレーニングサンプルに完全に適合する驚くべき能力を示しています。ただし、最近のいくつかの研究では、このようなモデルの平均パフォーマンスが良好であると、最悪の場合のパフォーマンスが良好であるとは限らないことが明らかになっています。特に、トレーニングセットで過小評価されているサブグループではパフォーマンスが低下する可能性があります。このホワイトペーパーでは、特定の設定で、過小評価されたサブグループでのパラメーター化されたモデルのパフォーマンスが事後処理によって改善される可能性があることを示します。具体的には、このようなモデルのバイアスは分類レイヤーに限定でき、まれなサブグループの構造化された予測シフトとして現れます。このバイアスを軽減するための2つの事後補正手法について詳しく説明します。これらは、標準モデルトレーニングの出力のみに基づいて動作します。このような事後修正により、パラメーター化が平均的および最悪の場合のパフォーマンスを改善できることを経験的に検証します。,6.0,
Learning advanced mathematical computations from examples,"['Francois Charton', 'Amaury Hayat', 'Guillaume Lample']",https://openreview.net/forum?id=-gfhS00XfKj,"Using transformers over large generated datasets, we train models to learn mathematical properties of differential systems, such as local stability, behavior at infinity and controllability. We achieve near perfect prediction of qualitative characteristics, and good approximations of numerical features of the system. This demonstrates that neural networks can learn to perform complex computations, grounded in advanced theory, from examples, without built-in mathematical knowledge.",生成された大規模なデータセットに対してトランスフォーマーを使用して、モデルをトレーニングし、局所的な安定性、無限大での動作、制御可能性など、微分システムの数学的特性を学習します。定性的特性のほぼ完全な予測と、システムの数値的特徴の適切な近似を実現します。これは、ニューラルネットワークが、組み込みの数学的知識がなくても、例から高度な理論に基づいた複雑な計算を実行することを学習できることを示しています。,6.0,
SOLAR: Sparse Orthogonal Learned and Random Embeddings,"['Tharun Medini', 'Beidi Chen', 'Anshumali Shrivastava']",https://openreview.net/forum?id=fw-BHZ1KjxJ,"Dense embedding models are commonly deployed in commercial search engines, wherein all the document vectors are pre-computed, and near-neighbor search (NNS) is performed with the query vector to find relevant documents. However, the bottleneck of indexing a large number of dense vectors and performing an NNS hurts the query time and accuracy of these models. In this paper, we argue that high-dimensional and ultra-sparse embedding is a significantly superior alternative to dense low-dimensional embedding for both query efficiency and accuracy. Extreme sparsity eliminates the need for NNS by replacing them with simple lookups, while its high dimensionality ensures that the embeddings are informative even when sparse. However, learning extremely high dimensional embeddings leads to blow up in the model size. To make the training feasible, we propose a partitioning algorithm that learns such high dimensional embeddings across multiple GPUs without any communication. This is facilitated by our novel asymmetric mixture of Sparse, Orthogonal, Learned and Random (SOLAR) Embeddings. The label vectors are random, sparse, and near-orthogonal by design, while the query vectors are learned and sparse. We theoretically prove that our way of one-sided learning is equivalent to learning both query and label embeddings. With these unique properties, we can successfully train 500K dimensional SOLAR embeddings for the tasks of searching through 1.6M books and multi-label classification on the three largest public datasets. We achieve superior precision and recall compared to the respective state-of-the-art baselines for each task with up to 10 times faster speed.",高密度埋め込みモデルは、一般に商用検索エンジンに導入されており、すべてのドキュメントベクトルが事前に計算され、クエリベクトルを使用してニアネイバー検索（NNS）が実行され、関連するドキュメントが検索されます。ただし、多数の密なベクトルにインデックスを付けてNNSを実行することのボトルネックは、これらのモデルのクエリ時間と精度を損ないます。この論文では、高次元で超疎な埋め込みが、クエリの効率と精度の両方において、高密度の低次元埋め込みよりもはるかに優れた代替手段であると主張します。極端なスパース性は、単純なルックアップに置き換えることでNNSの必要性を排除し、その高次元性により、スパースの場合でも埋め込みが有益であることを保証します。ただし、非常に高次元の埋め込みを学習すると、モデルサイズが大きくなります。トレーニングを実行可能にするために、通信なしで複数のGPUにまたがるこのような高次元の埋め込みを学習するパーティショニングアルゴリズムを提案します。これは、スパース、直交、学習、およびランダム（SOLAR）埋め込みの新しい非対称混合によって促進されます。ラベルベクトルは設計上ランダムでスパースでほぼ直交していますが、クエリベクトルは学習されてスパースです。理論的には、一方的な学習方法がクエリとラベルの埋め込みの両方を学習することと同等であることを証明します。これらの独自のプロパティを使用して、360万冊の書籍を検索し、3つの最大の公開データセットでマルチラベル分類を行うタスクのために、500K次元のSOLAR埋め込みを正常にトレーニングできます。各タスクのそれぞれの最先端のベースラインと比較して、最大10倍の速度で、優れた適合率と再現率を実現します。,6.0,https://d3i71xaburhd42.cloudfront.net/b2881852a6b072c731c0a54001d2908b488cd86e/3-Figure1-1.png
Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks,"['Yanbang Wang', 'Yen-Yu Chang', 'Yunyu Liu', 'Jure Leskovec', 'Pan Li']",https://openreview.net/forum?id=KYPz4YsCPj,"Temporal networks serve as abstractions of many real-world dynamic systems. These networks typically evolve according to certain laws, such as the law of triadic closure, which is universal in social networks. Inductive representation learning of temporal networks should be able to capture such laws and further be applied to systems that follow the same laws but have not been unseen during the training stage. Previous works in this area depend on either network node identities or rich edge attributes and typically fail to extract these laws. Here, we propose {\em Causal Anonymous Walks (CAWs)} to inductively represent a temporal network. CAWs are extracted by temporal random walks and work as automatic retrieval of temporal network motifs to represent network dynamics while avoiding the time-consuming selection and counting of those motifs. CAWs adopt a novel anonymization strategy that replaces node identities with the hitting counts of the nodes based on a set of sampled walks to keep the method inductive, and simultaneously establish the correlation between motifs. We further propose a neural-network model CAW-N to encode CAWs, and pair it with a CAW sampling strategy with constant memory and time cost to support online training and inference. CAW-N is evaluated to predict links over 6 real temporal networks and uniformly outperforms previous SOTA methods by averaged 15\% AUC gain in the inductive setting. CAW-N also outperforms previous methods in 5 out of the 6 networks in the transductive setting.",時間的ネットワークは、多くの実世界の動的システムの抽象化として機能します。これらのネットワークは通常、ソーシャルネットワークで普遍的なトライアドクロージャの法則などの特定の法則に従って進化します。時間的ネットワークの帰納的表現学習は、そのような法則を捉え、さらに同じ法則に従うがトレーニング段階では見られなかったシステムに適用できる必要があります。この分野でのこれまでの作業は、ネットワークノードIDまたはリッチエッジ属性のいずれかに依存しており、通常、これらの法則を抽出できません。ここでは、時間的ネットワークを帰納的に表すために、因果的匿名ウォーク（CAW）を提案します。 CAWは、時間的ランダムウォークによって抽出され、時間的ネットワークモチーフの自動検索として機能して、時間のかかるモチーフの選択とカウントを回避しながら、ネットワークダイナミクスを表します。 CAWは、ノードIDを、サンプリングされたウォークのセットに基づくノードのヒットカウントに置き換える新しい匿名化戦略を採用して、メソッドを帰納的に保ち、同時にモチーフ間の相関関係を確立します。さらに、CAWをエンコードするニューラルネットワークモデルCAW-Nを提案し、それを一定のメモリと時間コストでCAWサンプリング戦略と組み合わせて、オンライントレーニングと推論をサポートします。 CAW-Nは、6つの実際の時間ネットワーク上のリンクを予測するために評価され、誘導設定で平均15％のAUCゲインによって、以前のSOTAメソッドを均一に上回ります。 CAW-Nは、トランスダクティブ設定の6つのネットワークのうち5つで、以前の方法よりも優れています。,6.0,https://d3i71xaburhd42.cloudfront.net/f4304e275e79d2b74d87ddcc8c884972b2eda70d/2-Figure1-1.png
Revisiting Hierarchical Approach for Persistent Long-Term Video Prediction,"['Wonkwang Lee', 'Whie Jung', 'Han Zhang', 'Ting Chen', 'Jing Yu Koh', 'Thomas Huang', 'Hyungsuk Yoon', 'Honglak Lee', 'Seunghoon Hong']",https://openreview.net/forum?id=3RLN4EPMdYd,"Learning to predict the long-term future of video frames is notoriously challenging due to the inherent ambiguities in a distant future and dramatic amplification of prediction error over time. Despite the recent advances in the literature, existing approaches are limited to moderately short-term prediction (less than a few seconds), while extrapolating it to a longer future quickly leads to destruction in structure and content. In this work, we revisit the hierarchical models in video prediction. Our method generates future frames by first estimating a sequence of dense semantic structures and subsequently translating the estimated structures to pixels by video-to-video translation model. Despite the simplicity, we show that modeling structures and their dynamics in categorical structure space with stochastic sequential estimator leads to surprisingly successful long-term prediction. We evaluate our method on two challenging video prediction scenarios, \emph{car driving} and \emph{human dancing}, and demonstrate that it can generate complicated scene structures and motions over a very long time horizon (\ie~thousands frames), setting a new standard of video prediction with orders of magnitude longer prediction time than existing approaches. Video results are available at https://bit.ly/2EyDSem.",ビデオフレームの長期的な将来を予測することを学ぶことは、遠い将来に内在する曖昧さと時間の経過に伴う予測誤差の劇的な増幅のために、悪名高い挑戦です。文献の最近の進歩にもかかわらず、既存のアプローチは適度に短期的な予測（数秒未満）に制限されており、それをより長い未来に外挿すると、構造と内容がすぐに破壊されます。この作業では、ビデオ予測の階層モデルを再検討します。私たちの方法は、最初に密な意味構造のシーケンスを推定し、続いてビデオからビデオへの変換モデルによって推定された構造をピクセルに変換することによって、将来のフレームを生成します。単純さにもかかわらず、確率的逐次推定量を使用したカテゴリ構造空間での構造とそのダイナミクスのモデリングが、驚くほど成功した長期予測につながることを示します。車の運転と人間のダンスという2つの挑戦的なビデオ予測シナリオでこの方法を評価し、非常に長い期間（数千フレーム）にわたって複雑なシーン構造とモーションを生成できることを実証し、桁違いのビデオ予測の新しい基準を設定します既存のアプローチよりも長い予測時間。ビデオの結果はhttps://bit.ly/2EyDSemで入手できます。,6.0,
Discovering Diverse Multi-Agent Strategic Behavior via Reward Randomization,"['Zhenggang Tang', 'Chao Yu', 'Boyuan Chen', 'Huazhe Xu', 'Xiaolong Wang', 'Fei Fang', 'Simon Shaolei Du', 'Yu Wang', 'Yi Wu']",https://openreview.net/forum?id=lvRTC669EY_,"We propose a simple, general and effective technique, Reward Randomization for discovering diverse strategic policies in complex multi-agent games. Combining reward randomization and policy gradient, we derive a new algorithm, Reward-Randomized Policy Gradient (RPG). RPG is able to discover a set of multiple distinctive human-interpretable strategies in challenging temporal trust dilemmas, including grid-world games and a real-world game Agar.io, where multiple equilibria exist but standard multi-agent policy gradient algorithms always converge to a fixed one with a sub-optimal payoff for every player even using state-of-the-art exploration techniques. Furthermore, with the set of diverse strategies from RPG, we can (1) achieve higher payoffs by fine-tuning the best policy from the set; and (2) obtain an adaptive agent by using this set of strategies as its training opponents. ",複雑なマルチエージェントゲームで多様な戦略的ポリシーを発見するための、シンプルで一般的かつ効果的な手法である報酬のランダム化を提案します。報酬のランダム化とポリシーの勾配を組み合わせて、新しいアルゴリズムである報酬のランダム化されたポリシーの勾配（RPG）を導き出します。 RPGは、グリッドワールドゲームや現実世界のゲームAgar.ioなど、時間的信頼のジレンマに挑戦する際に、人間が解釈できる複数の特徴的な戦略のセットを発見できます。この場合、複数の平衡が存在しますが、標準のマルチエージェントポリシー勾配アルゴリズムは常に最先端の探索技術を使用していても、すべてのプレイヤーにとって最適ではないペイオフを伴う固定のもの。さらに、RPGのさまざまな戦略のセットを使用すると、（1）セットから最適なポリシーを微調整することで、より高いペイオフを達成できます。 （2）この一連の戦略をトレーニング相手として使用することにより、適応エージェントを取得します。,6.0,
DrNAS: Dirichlet Neural Architecture Search,"['Xiangning Chen', 'Ruochen Wang', 'Minhao Cheng', 'Xiaocheng Tang', 'Cho-Jui Hsieh']",https://openreview.net/forum?id=9FWas6YbmB3,"This paper proposes a novel differentiable architecture search method by formulating it into a distribution learning problem. We treat the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution. With recently developed pathwise derivatives, the Dirichlet parameters can be easily optimized with gradient-based optimizer in an end-to-end manner. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. Furthermore, to alleviate the large memory consumption of differentiable NAS, we propose a simple yet effective progressive learning scheme that enables searching directly on large-scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of our method. Specifically, we obtain a test error of 2.46% for CIFAR-10, 23.7% for ImageNet under the mobile setting. On NAS-Bench-201, we also achieve state-of-the-art results on all three datasets and provide insights for the effective design of neural architecture search algorithms.",本論文はそれを分布学習問題に定式化することにより新しい微分可能なアーキテクチャ探索法を提案した。継続的に緩和されたアーキテクチャの混合重みを、ディリクレ分布によってモデル化された確率変数として扱います。最近開発されたパスワイズ導関数を使用すると、ディリクレパラメーターを勾配ベースのオプティマイザーでエンドツーエンドで簡単に最適化できます。この定式化により、一般化能力が向上し、確率論が誘発され、探索空間での探索が自然に促進されます。さらに、微分可能なNASの大量のメモリ消費を軽減するために、大規模なタスクを直接検索できるシンプルで効果的なプログレッシブ学習スキームを提案し、検索フェーズと評価フェーズの間のギャップを排除します。広範な実験は、私たちの方法の有効性を示しています。具体的には、2.46のテストエラーが得られます。,6.0,https://d3i71xaburhd42.cloudfront.net/11b430ae91c5b7a3e51f86235818f74fd8b449ef/13-Figure1-1.png
VTNet: Visual Transformer Network for Object Goal Navigation,"['Heming Du', 'Xin Yu', 'Liang Zheng']",https://openreview.net/forum?id=DILxQP08O3B,"Object goal navigation aims to steer an agent towards a target object based on observations of the agent. It is of pivotal importance to design effective visual representations of the observed scene in determining navigation actions.  In this paper, we introduce a Visual Transformer Network (VTNet) for learning informative visual representation in navigation.  VTNet is a highly effective structure that embodies two key properties for visual representations: First, the relationships among all the object instances in a scene are exploited; Second, the spatial locations of objects and image regions are emphasized so that directional navigation signals can be learned. Furthermore, we also develop a pre-training scheme to associate the visual representations with navigation signals, and thus facilitate navigation policy learning. In a nutshell, VTNet embeds object and region features with their location cues as spatial-aware descriptors and then incorporates all the encoded descriptors through attention operations to achieve informative representation for navigation. Given such visual representations, agents are able to explore the correlations between visual observations and navigation actions. For example, an agent would prioritize ``turning right'' over ``turning left'' when the visual representation emphasizes on the right side of activation map. Experiments in the artificial environment AI2-Thor demonstrate that VTNet significantly outperforms state-of-the-art methods in unseen testing environments.",オブジェクトゴールナビゲーションは、エージェントの観察に基づいて、エージェントをターゲットオブジェクトに向けて誘導することを目的としています。ナビゲーションアクションを決定する際には、観察されたシーンの効果的な視覚的表現を設計することが極めて重要です。この論文では、ナビゲーションにおける有益な視覚的表現を学習するためのVisual Transformer Network（VTNet）を紹介します。 VTNetは、視覚的表現の2つの主要なプロパティを具体化する非常に効果的な構造です。まず、シーン内のすべてのオブジェクトインスタンス間の関係が活用されます。第二に、方向性ナビゲーション信号を学習できるように、オブジェクトと画像領域の空間的位置が強調されます。さらに、視覚的表現をナビゲーション信号に関連付けるための事前トレーニングスキームも開発し、ナビゲーションポリシーの学習を容易にします。簡単に言うと、VTNetは、オブジェクトと領域の特徴を、空間認識記述子としての位置キューとともに埋め込み、注意操作を通じてすべてのエンコードされた記述子を組み込んで、ナビゲーションの有益な表現を実現します。そのような視覚的表現が与えられると、エージェントは視覚的観察とナビゲーションアクションの間の相関関係を調査することができます。たとえば、エージェントは、アクティベーションマップの右側で視覚的表現が強調されている場合、左折よりも右折を優先します。人工環境AI2-Thorでの実験は、VTNetが目に見えないテスト環境で最先端の方法を大幅に上回っていることを示しています。,6.0,
Rethinking Embedding Coupling in Pre-trained Language Models,"['Hyung Won Chung', 'Thibault Fevry', 'Henry Tsai', 'Melvin Johnson', 'Sebastian Ruder']",https://openreview.net/forum?id=xpFFI_NtgpW,"We re-evaluate the standard practice of sharing weights between input and output embeddings in state-of-the-art pre-trained language models. We show that decoupled embeddings provide increased modeling flexibility, allowing us to significantly improve the efficiency of parameter allocation in the input embedding of multilingual models. By reallocating the input embedding parameters in the Transformer layers, we achieve dramatically better performance on standard natural language understanding tasks with the same number of parameters during fine-tuning. We also show that allocating additional capacity to the output embedding provides benefits to the model that persist through the fine-tuning stage even though the output embedding is discarded after pre-training. Our analysis shows that larger output embeddings prevent the model's last layers from overspecializing to the pre-training task and encourage Transformer representations to be more general and more transferable to other tasks and languages. Harnessing these findings, we are able to train models that achieve strong performance on the XTREME benchmark without increasing the number of parameters at the fine-tuning stage. ",最先端の事前トレーニング済み言語モデルで、入力埋め込みと出力埋め込みの間で重みを共有する標準的な方法を再評価します。分離された埋め込みによってモデリングの柔軟性が向上し、多言語モデルの入力埋め込みにおけるパラメーター割り当ての効率が大幅に向上することを示します。 Transformerレイヤーで入力埋め込みパラメーターを再割り当てすることにより、微調整中に同じ数のパラメーターを使用して、標準の自然言語理解タスクで劇的に優れたパフォーマンスを実現します。また、出力埋め込みに追加の容量を割り当てると、事前トレーニング後に出力埋め込みが破棄された場合でも、微調整段階を通じて持続するモデルに利点があることも示しています。私たちの分析によると、出力の埋め込みが大きいほど、モデルの最後のレイヤーが事前トレーニングタスクに過度に特化するのを防ぎ、Transformer表現がより一般的で他のタスクや言語に転送しやすくなることがわかります。これらの調査結果を利用して、微調整段階でパラメーターの数を増やすことなく、XTREMEベンチマークで強力なパフォーマンスを実現するモデルをトレーニングできます。,6.0,https://d3i71xaburhd42.cloudfront.net/bc87279d4b32a425377ff18ab63f7ecf95ff228c/8-Figure1-1.png
Practical Massively Parallel Monte-Carlo Tree Search Applied to Molecular Design,"['Xiufeng Yang', 'Tanuj Aasawat', 'Kazuki Yoshizoe']",https://openreview.net/forum?id=6k7VdojAIK,"It is common practice to use large computational resources to train neural networks, as is known from many examples, such as reinforcement learning applications.  However, while massively parallel computing is often used for training models, it is rarely used for searching solutions for combinatorial optimization problems. In this paper, we propose a novel massively parallel Monte-Carlo Tree Search (MP-MCTS) algorithm that works efficiently for 1,000 worker scale, and apply it to molecular design. This is the first work that applies distributed MCTS to a real-world and non-game problem. Existing work on large-scale parallel MCTS show efficient scalability in terms of the number of rollouts up to 100 workers, but suffer from the degradation in the quality of the solutions. MP-MCTS maintains the search quality at larger scale, and by running MP-MCTS on 256 CPU cores for only 10 minutes, we obtained candidate molecules having similar score to non-parallel MCTS running for 42 hours. Moreover, our results based on parallel MCTS (combined with a simple RNN model) significantly outperforms existing state-of-the-art work. Our method is generic and is expected to speed up other applications of MCTS.","強化学習アプリケーションなどの多くの例から知られているように、ニューラルネットワークをトレーニングするために大規模な計算リソースを使用することは一般的な方法です。ただし、モデルのトレーニングには超並列コンピューティングがよく使用されますが、組み合わせ最適化問題のソリューションの検索にはほとんど使用されません。本論文では、1,000人の労働者規模で効率的に機能する新しい超並列モンテカルロ木探索（MP-MCTS）アルゴリズムを提案し、それを分子設計に適用します。これは、分散MCTSを実際のゲーム以外の問題に適用する最初の作業です。大規模な並列MCTSに関する既存の作業では、最大100人のワーカーのロールアウト数に関して効率的なスケーラビリティが示されていますが、ソリューションの品質が低下します。 MP-MCTSは大規模な検索品質を維持し、256個のCPUコアでMP-MCTSをわずか10分間実行することで、42時間実行する非並列MCTSと同様のスコアを持つ候補分子を取得しました。さらに、並列MCTS（単純なRNNモデルと組み合わせたもの）に基づく結果は、既存の最先端の作業を大幅に上回っています。私たちの方法は一般的であり、MCTSの他のアプリケーションを高速化することが期待されています。",6.0,
Capturing Label Characteristics in VAEs,"['Tom Joy', 'Sebastian Schmon', 'Philip Torr', 'Siddharth N', 'Tom Rainforth']",https://openreview.net/forum?id=wQRlSUZ5V7B,"We present a principled approach to incorporating labels in variational autoencoders (VAEs) that captures the rich characteristic information associated with those labels. While prior work has typically conflated these by learning latent variables that directly correspond to label values, we argue this is contrary to the intended effect of supervision in VAEs—capturing rich label characteristics with the latents. For example, we may want to capture the characteristics of a face that make it look young, rather than just the age of the person. To this end, we develop a novel VAE model, the characteristic capturing VAE (CCVAE), which “reparameterizes” supervision through auxiliary variables and a concomitant variational objective. Through judicious structuring of mappings between latent and auxiliary variables, we show that the CCVAE can effectively learn meaningful representations of the characteristics of interest across a variety of supervision schemes. In particular, we show that the CCVAE allows for more effective and more general interventions to be performed, such as smooth traversals within the characteristics for a given label, diverse conditional generation, and transferring characteristics across datapoints.",これらのラベルに関連付けられている豊富な特性情報をキャプチャする変分オートエンコーダ（VAE）にラベルを組み込むための原理的なアプローチを提示します。以前の研究では通常、ラベル値に直接対応する潜在変数を学習することでこれらを混同していましたが、これは、潜在変数を使用して豊富なラベル特性をキャプチャするVAEでの監視の意図された効果に反すると主張します。たとえば、人物の年齢だけでなく、若く見える顔の特徴をキャプチャしたい場合があります。この目的のために、新しいVAEモデルである特性キャプチャVAE（CCVAE）を開発します。これは、補助変数と付随する変分目的によって監視を再パラメータ化します。潜在変数と補助変数の間のマッピングの賢明な構造化を通じて、CCVAEがさまざまな監督スキーム全体で関心のある特性の意味のある表現を効果的に学習できることを示します。特に、CCVAEを使用すると、特定のラベルの特性内でのスムーズな走査、多様な条件付き生成、データポイント間での特性の転送など、より効果的で一般的な介入を実行できることを示します。,6.0,
Trajectory Prediction using Equivariant Continuous Convolution,"['Robin Walters', 'Jinxi Li', 'Rose Yu']",https://openreview.net/forum?id=J8_GttYLFgr,"Trajectory prediction is a critical part of many AI applications, for example, the safe operation of autonomous vehicles. However, current methods are prone to making inconsistent and physically unrealistic predictions. We leverage insights from fluid dynamics to overcome this limitation by considering internal symmetry in trajectories. We propose a novel model, Equivariant Continous COnvolution (ECCO) for improved trajectory prediction. ECCO uses rotationally-equivariant continuous convolutions to embed the symmetries of the system. On two real-world vehicle and pedestrian trajectory datasets, ECCO attains competitive accuracy with significantly fewer parameters. It is also more sample efficient, generalizing automatically from few data points in any orientation. Lastly, ECCO improves generalization with equivariance, resulting in more physically consistent predictions. Our method provides a fresh perspective towards increasing trust and transparency in deep learning models.",軌道予測は、自動運転車の安全な操作など、多くのAIアプリケーションの重要な部分です。ただし、現在の方法では、一貫性がなく、物理的に非現実的な予測を行う傾向があります。流体力学からの洞察を活用して、軌道の内部対称性を考慮することにより、この制限を克服します。軌道予測を改善するために、新しいモデルであるEquivariant Continous COnvolution（ECCO）を提案します。 ECCOは、回転的に等変の連続畳み込みを使用して、システムの対称性を埋め込みます。 2つの実世界の車両と歩行者の軌道データセットで、ECCOは大幅に少ないパラメータで競争力のある精度を達成します。また、サンプル効率が高く、任意の方向のいくつかのデータポイントから自動的に一般化されます。最後に、ECCOは同変による一般化を改善し、より物理的に一貫した予測をもたらします。私たちの方法は、深層学習モデルの信頼と透明性を高めるための新鮮な視点を提供します。,6.0,https://d3i71xaburhd42.cloudfront.net/38e52bbcfb67029822c4284e53d15225b478b90f/1-Figure1-1.png
Isometric Transformation Invariant and Equivariant Graph Convolutional Networks,"['Masanobu Horie', 'Naoki Morita', 'Toshiaki Hishinuma', 'Yu Ihara', 'Naoto Mitsume']",https://openreview.net/forum?id=FX0vR39SJ5q,"Graphs are one of the most important data structures for representing pairwise relations between objects. Specifically, a graph embedded in a Euclidean space is essential to solving real problems, such as physical simulations. A crucial requirement for applying graphs in Euclidean spaces to physical simulations is learning and inferring the isometric transformation invariant and equivariant features in a computationally efficient manner. In this paper, we propose a set of transformation invariant and equivariant models based on graph convolutional networks, called IsoGCNs. We demonstrate that the proposed model has a competitive performance compared to state-of-the-art methods on tasks related to geometrical and physical simulation data. Moreover, the proposed model can scale up to graphs with 1M vertices and conduct an inference faster than a conventional finite element analysis, which the existing equivariant models cannot achieve.",グラフは、オブジェクト間のペアワイズ関係を表すための最も重要なデータ構造の1つです。具体的には、ユークリッド空間に埋め込まれたグラフは、物理シミュレーションなどの実際の問題を解決するために不可欠です。ユークリッド空間のグラフを物理シミュレーションに適用するための重要な要件は、計算効率の高い方法で等長変換の不変および同変の特徴を学習および推測することです。この論文では、IsoGCNと呼ばれるグラフ畳み込みネットワークに基づく変換不変および同変モデルのセットを提案します。提案されたモデルは、幾何学的および物理的シミュレーションデータに関連するタスクで最先端の方法と比較して競争力のあるパフォーマンスを持っていることを示しています。さらに、提案されたモデルは、1Mの頂点を持つグラフにスケールアップし、既存の同変モデルでは達成できない従来の有限要素解析よりも高速に推論を実行できます。,6.0,https://d3i71xaburhd42.cloudfront.net/49c0ebbd20630a5811513217f9be1d210c742ae8/7-Figure1-1.png
Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective,"['Wuyang Chen', 'Xinyu Gong', 'Zhangyang Wang']",https://openreview.net/forum?id=Cnon5ezMHtu,"Neural Architecture Search (NAS) has been explosively studied to automate the discovery of top-performer neural networks. Current works require heavy training of supernet or intensive architecture evaluations, thus suffering from heavy resource consumption and often incurring search bias due to truncated training or approximations. Can we select the best neural architectures without involving any training and eliminate a drastic portion of the search cost? 

We provide an affirmative answer, by proposing a novel framework called \textit{training-free neural architecture search} ($\textbf{TE-NAS}$). TE-NAS ranks architectures by analyzing the spectrum of the neural tangent kernel (NTK), and the number of linear regions in the input space. Both are motivated by recent theory advances in deep networks, and can be computed without any training. We show that: (1) these two measurements imply the $\textit{trainability}$ and $\textit{expressivity}$ of a neural network; and (2) they strongly correlate with the network's actual test accuracy. Further on, we design a pruning-based NAS mechanism to achieve a more flexible and superior trade-off between the trainability and expressivity during the search. In NAS-Bench-201 and DARTS search spaces, TE-NAS completes high-quality search but only costs $\textbf{0.5}$ and $\textbf{4}$ GPU hours with one 1080Ti on CIFAR-10 and ImageNet, respectively. We hope our work to inspire more attempts in bridging between the theoretic findings of deep networks and practical impacts in real NAS applications.",ニューラルアーキテクチャ検索（NAS）は、最高のパフォーマンスを発揮するニューラルネットワークの発見を自動化するために爆発的に研究されてきました。現在の作業では、スーパーネットの大量のトレーニングまたは集中的なアーキテクチャ評価が必要であるため、リソースの消費量が多く、トレーニングや近似が切り捨てられるために検索バイアスが発生することがよくあります。トレーニングを必要とせずに最適なニューラルアーキテクチャを選択し、検索コストの大幅な部分を排除できますか？トレーニングフリーのニューラルアーキテクチャ検索（TE-NAS）と呼ばれる新しいフレームワークを提案することにより、肯定的な答えを提供します。 TE-NASは、ニューラルタンジェントカーネル（NTK）のスペクトル、および入力空間の線形領域の数を分析することにより、アーキテクチャをランク付けします。どちらも、ディープネットワークにおける最近の理論の進歩に動機付けられており、トレーニングなしで計算できます。 （1）これら2つの測定値は、ニューラルネットワークのトレーニング可能性と表現力を意味します。 （2）ネットワークの実際のテスト精度と強く相関します。さらに、プルーニングベースのNASメカニズムを設計して、検索中のトレーニング可能性と表現力の間のより柔軟で優れたトレードオフを実現します。 NAS-Bench-201およびDARTS検索スペースでは、TE-NASは高品質の検索を完了しますが、CIFAR-10およびImageNetの1つの1080Tiでそれぞれ0.5および4GPU時間しかかかりません。私たちの仕事が、ディープネットワークの理論的発見と実際のNASアプリケーションにおける実際の影響との間を橋渡しする試みをさらに刺激することを願っています。,6.0,
Semi-supervised Keypoint Localization,"['Olga Moskvyak', 'Frederic Maire', 'Feras Dayoub', 'Mahsa Baktashmotlagh']",https://openreview.net/forum?id=yFJ67zTeI2,"Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.",画像内のオブジェクトのキーポイントの位置に関する知識は、特に野生動物など、視覚的外観に大きな影響を与えるポーズの大きな変動を示すオブジェクトの場合に、きめ細かい分類および識別タスクに役立ちます。ただし、キーポイント検出ネットワークの教師ありトレーニングでは、動物種ごとに大きな画像データセットに注釈を付ける必要があり、これは労働集約的な作業です。ラベル付きデータの必要性を減らすために、キーポイントヒートマップを同時に学習し、ラベル付き画像の小さなセットとラベルなし画像の大きなセットを使用して、半教師ありの方法で不変のキーポイント表現を提示することを提案します。キーポイント表現は、キーポイント検出ネットワークにデータセット全体の同じキーポイントの同様の機能を学習させるセマンティックキーポイント整合性制約を使用して学習されます。ポーズの不変性は、画像とその拡張コピーのキーポイント表現を特徴空間で互いに近づけることによって実現されます。私たちの半教師ありアプローチは、人体および動物の体のランドマークの位置特定に関するいくつかのベンチマークで、以前の方法を大幅に上回っています。,6.0,https://d3i71xaburhd42.cloudfront.net/ed8a5583f874c19fed7759ee51675e41c53e7438/2-Figure1-1.png
Neural Delay Differential Equations,"['Qunxi Zhu', 'Yao Guo', 'Wei Lin']",https://openreview.net/forum?id=Q1jmmQz72M2,"    Neural Ordinary Differential Equations (NODEs), a framework of continuous-depth neural networks, have been widely applied, showing exceptional efficacy in coping with some representative datasets.  Recently, an augmented framework has been successfully developed for conquering some limitations emergent in application of the original framework.  Here we propose a new class of continuous-depth neural networks with delay, named as Neural Delay Differential Equations (NDDEs),  and, for computing the corresponding gradients, we use the adjoint sensitivity method to obtain the delayed dynamics of the adjoint. Since the differential equations with delays are usually seen as dynamical systems of infinite dimension possessing more fruitful dynamics, the NDDEs, compared to the NODEs, own a stronger capacity of nonlinear representations.  Indeed, we analytically validate that the NDDEs are of universal approximators, and further articulate an extension of the NDDEs, where the initial function of the NDDEs is supposed to satisfy ODEs.   More importantly, we use several illustrative examples to demonstrate the outstanding capacities of the NDDEs and the NDDEs with ODEs' initial value.  More precisely, (1) we successfully model the delayed dynamics where the trajectories in the lower-dimensional phase space could be mutually intersected, while the traditional NODEs without any argumentation are not directly applicable for such modeling, and (2) we achieve lower loss and higher accuracy not only for the  data produced synthetically by complex models but also for the real-world image datasets, i.e., CIFAR10, MNIST and SVHN.   Our results on the NDDEs reveal that appropriately articulating the elements of dynamical systems into the network design is truly beneficial to promoting the network performance.",連続深度ニューラルネットワークのフレームワークであるニューラル常微分方程式（NODE）は広く適用されており、いくつかの代表的なデータセットに対処する上で並外れた効果を示しています。最近、元のフレームワークの適用で発生したいくつかの制限を克服するために、拡張フレームワークの開発に成功しました。ここでは、ニューラル遅延微分方程式（NDDE）と呼ばれる、遅延のある新しいクラスの連続深度ニューラルネットワークを提案し、対応する勾配を計算するために、随伴感度法を使用して随伴の遅延ダイナミクスを取得します。遅延のある微分方程式は通常、より実り多いダイナミクスを持つ無限次元の動的システムと見なされるため、NDDEは、NODEと比較して、より強力な非線形表現の能力を備えています。実際、NDDEが普遍近似器であることを分析的に検証し、NDDEの初期関数がODEを満たすと想定されるNDDEの拡張をさらに明確にします。さらに重要なことに、いくつかの実例を使用して、NDDEおよびODEの初期値を持つNDDEの優れた容量を示します。より正確には、（1）低次元の位相空間の軌道が相互に交差する可能性がある遅延ダイナミクスのモデリングに成功しましたが、議論のない従来のNODEはそのようなモデリングに直接適用できず、（2）より低い損失を達成しました複雑なモデルによって合成的に生成されたデータだけでなく、実際の画像データセット、つまりCIFAR10、MNIST、SVHNに対してもより高い精度が得られます。 NDDEに関する私たちの結果は、動的システムの要素をネットワーク設計に適切に表現することが、ネットワークパフォーマンスを促進するために本当に有益であることを明らかにしています。,6.0,
Disentangling 3D Prototypical Networks for Few-Shot Concept Learning,"['Mihir Prabhudesai', 'Shamit Lal', 'Darshan Patil', 'Hsiao-Yu Tung', 'Adam W Harley', 'Katerina Fragkiadaki']",https://openreview.net/forum?id=-Lr-u0b42he,"We present neural architectures that disentangle RGB-D images into objects’ shapes and styles and a map of the background scene, and explore their applications for few-shot 3D object detection and few-shot concept classification. Our networks incorporate architectural biases that reflect the image formation process, 3D  geometry of the world scene, and shape-style interplay. They are trained end-to-end self-supervised by predicting views in static scenes, alongside a small number of 3D object boxes. Objects and scenes are represented in terms of 3D feature grids in the bottleneck of the network. We show the proposed 3D neural representations are compositional: they can generate novel 3D scene feature maps by mixing object shapes and styles, resizing and adding the resulting object 3D feature maps over background scene feature maps. We show object detectors trained on hallucinated 3D neural scenes generalize better to novel environments. We show classifiers for object categories, color, materials, and spatial relationships trained over the  disentangled 3D feature sub-spaces generalize better with dramatically fewer exemplars over the current state-of-the-art, and enable a visual question answering system that uses them as its modules to generalize one-shot to novel objects in the scene.",RGB-D画像をオブジェクトの形状とスタイル、および背景シーンのマップに解きほぐすニューラルアーキテクチャを紹介し、数ショットの3Dオブジェクト検出と数ショットの概念分類への応用を探ります。私たちのネットワークには、画像形成プロセス、世界のシーンの3Dジオメトリ、および形状スタイルの相互作用を反映するアーキテクチャのバイアスが組み込まれています。それらは、少数の3Dオブジェクトボックスとともに、静的シーンのビューを予測することにより、エンドツーエンドの自己監視でトレーニングされます。オブジェクトとシーンは、ネットワークのボトルネックにある3Dフィーチャグリッドの観点から表されます。提案された3Dニューラル表現が構成的であることを示します。オブジェクトの形状とスタイルを混合し、結果のオブジェクトの3D特徴マップを背景シーンの特徴マップの上にサイズ変更して追加することにより、新しい3Dシーンの特徴マップを生成できます。幻覚の3D神経シーンで訓練されたオブジェクト検出器が新しい環境によりよく一般化することを示します。解きほぐされた3Dフィーチャサブスペースでトレーニングされたオブジェクトカテゴリ、色、マテリアル、および空間関係の分類子を示し、現在の最先端技術よりも劇的に少ないエグザンプラでより一般化し、それらを使用する視覚的な質問応答システムを有効にします。シーン内の新しいオブジェクトにワンショットを一般化するためのモジュールとして。,6.0,https://d3i71xaburhd42.cloudfront.net/9f24889a752ae72c5a4dcd5cdb2576b591f012cf/2-Figure1-1.png
On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections,"['Peizhao Li', 'Yifei Wang', 'Han Zhao', 'Pengyu Hong', 'Hongfu Liu']",https://openreview.net/forum?id=xgGS6PmzNq6,"Disparate impact has raised serious concerns in machine learning applications and its societal impacts. In response to the need of mitigating discrimination, fairness has been regarded as a crucial property in algorithmic design. In this work, we study the problem of disparate impact on graph-structured data. Specifically, we focus on dyadic fairness, which articulates a fairness concept that a predictive relationship between two instances should be independent of the sensitive attributes. Based on this, we theoretically relate the graph connections to dyadic fairness on link predictive scores in learning graph neural networks, and reveal that regulating weights on existing edges in a graph contributes to dyadic fairness conditionally. Subsequently, we propose our algorithm, \textbf{FairAdj}, to empirically learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. Empirical validation demonstrates that our method delivers effective dyadic fairness in terms of various statistics, and at the same time enjoys a favorable fairness-utility tradeoff.",さまざまな影響により、機械学習アプリケーションとその社会的影響に深刻な懸念が生じています。差別を緩和する必要性に応えて、公平性はアルゴリズム設計の重要な特性と見なされてきました。この作業では、グラフ構造化データへの異なる影響の問題を研究します。具体的には、2つのインスタンス間の予測関係は機密属性から独立している必要があるという公平性の概念を明確にする、二項公平性に焦点を当てます。これに基づいて、グラフ接続を学習グラフニューラルネットワークのリンク予測スコアの二項公平性に理論的に関連付け、グラフ内の既存のエッジの重みを調整することが条件付きで二項公平性に寄与することを明らかにします。続いて、フェアリンク予測のための適切なグラフ構造制約を使用してフェア隣接行列を経験的に学習し、その間に予測精度を可能な限り維持するためのアルゴリズムFAIRADJを提案します。経験的検証は、私たちの方法がさまざまな統計の観点から効果的な二項公平性を提供し、同時に有利な公平性とユーティリティのトレードオフを享受していることを示しています。,6.0,
Rethinking Soft Labels for Knowledge Distillation: A BiasвЂ“Variance Tradeoff Perspective,"['Helong Zhou', 'Liangchen Song', 'Jiajie Chen', 'Ye Zhou', 'Guoli Wang', 'Junsong Yuan', 'Qian Zhang']",https://openreview.net/forum?id=gIHd-5X324,"Knowledge distillation is an effective approach to leverage a well-trained network or an ensemble of them, named as the teacher, to guide the training of a student network.  The outputs from the teacher network are used as soft labels for supervising the training of a new network.  Recent studies (M ̈uller et al., 2019; Yuan et al., 2020) revealed an intriguing property of the soft labels that making labels soft serves as a good regularization to the student network.   From the perspective of statistical learning,  regularization aims to reduce the variance,  however how bias and variance change is not clear for training with soft labels.   In this paper, we investigate the bias-variance tradeoff brought by distillation with soft labels.   Specifically,  we observe that during training the bias-variance tradeoff varies sample-wisely. Further, under the same distillation temperature setting, we observe that the distillation performance is negatively associated with the number of some specific samples, which are named as regularization samples since these samples lead to bias increasing and variance decreasing.  Nevertheless, we empirically find that completely filtering out regularization samples also deteriorates distillation performance.  Our discoveries inspired us to propose the novel weighted soft labels to help the network adaptively handle the sample-wise bias-variance tradeoff.  Experiments on standard evaluation benchmarks validate the effectiveness of our method. Our code is available in the supplementary.",知識の蒸留は、十分に訓練されたネットワークまたは教師と呼ばれるそれらのアンサンブルを活用して、学生ネットワークの訓練を導くための効果的なアプローチです。教師ネットワークからの出力は、新しいネットワークのトレーニングを監督するためのソフトラベルとして使用されます。最近の研究（M uller et al。、2019; Yuan et al。、2020）は、ラベルをソフトにすることが学生ネットワークの優れた正則化として機能するというソフトラベルの興味深い特性を明らかにしました。統計的学習の観点から、正則化は分散を減らすことを目的としていますが、ソフトラベルを使用したトレーニングではバイアスと分散の変化がどのように変化するかは明確ではありません。この論文では、ソフトラベルを使用した蒸留によってもたらされるバイアスと分散のトレードオフを調査します。具体的には、トレーニング中に偏りと分散のトレードオフがサンプルごとに変化することを確認します。さらに、同じ蒸留温度設定の下で、蒸留性能がいくつかの特定のサンプルの数と負の関係にあることを観察します。これらのサンプルはバイアスの増加と分散の減少につながるため、正則化サンプルと呼ばれます。それにもかかわらず、正則化サンプルを完全に除外すると、蒸留性能も低下することが経験的にわかっています。私たちの発見は、ネットワークがサンプルごとの偏りと分散のトレードオフを適応的に処理するのに役立つ、新しい加重ソフトラベルを提案するように促しました。標準的な評価ベンチマークでの実験は、私たちの方法の有効性を検証します。私たちのコードは補足で利用可能です。,6.0,https://d3i71xaburhd42.cloudfront.net/be51e9141ae2af4daf3a1ba745ad3ff66a5990f3/5-Figure2-1.png
Evaluation of Similarity-based Explanations,"['Kazuaki Hanawa', 'Sho Yokoi', 'Satoshi Hara', 'Kentaro Inui']",https://openreview.net/forum?id=9uvhpyQwzM_,"Explaining predictions made by complex machine learning models helps users understand and accept the predicted outputs with confidence. One way to achieve this goal is to use similarity-based explanation that provides similar instances as evidence to support a model's prediction. Several \emph{relevance metrics} are used for this purpose. In this study, we investigate which relevance metric can provide a reasonable explanation to users. Specifically, we adopted three tests to evaluate whether the relevance metrics satisfy the minimal requirements for similarity-based explanation. Our experiments reveal that the cosine similarity of the gradients of the loss performs best, which would be a recommended choice in practice. In addition, we show that some metrics performs poorly in our tests, and analyze the reasons of their failure. We expect our insights to help practitioners to select appropriate relevance metrics, and also to help further researches for designing better relevance metrics for explanations.",複雑な機械学習モデルによって行われた予測を説明することで、ユーザーは予測された出力を自信を持って理解し、受け入れることができます。この目標を達成する1つの方法は、モデルの予測をサポートする証拠として類似のインスタンスを提供する類似性ベースの説明を使用することです。この目的のために、いくつかの関連性メトリックが使用されます。この調査では、どの関連性メトリックがユーザーに合理的な説明を提供できるかを調査します。具体的には、関連性メトリックが類似性ベースの説明の最小要件を満たしているかどうかを評価するために、3つのテストを採用しました。私たちの実験では、損失の勾配のコサイン類似性が最もよく機能することが明らかになりました。これは、実際に推奨される選択です。さらに、一部のメトリックがテストで不十分に機能することを示し、それらの失敗の理由を分析します。私たちの洞察は、実践者が適切な関連性指標を選択するのに役立つだけでなく、説明のためのより良い関連性指標を設計するためのさらなる研究にも役立つことを期待しています。,6.0,
Concept Learners for Few-Shot Learning,"['Kaidi Cao', 'Maria Brbic', 'Jure Leskovec']",https://openreview.net/forum?id=eJIJF3-LoZO,"Developing algorithms that are able to generalize to a novel task given only a few labeled examples represents a fundamental challenge in closing the gap between machine- and human-level performance. The core of human cognition lies in the structured, reusable concepts that help us to rapidly adapt to new tasks and provide reasoning behind our decisions. However, existing meta-learning methods learn complex representations across prior labeled tasks without imposing any structure on the learned representations. Here we propose COMET, a meta-learning method that improves generalization ability by learning to learn along human-interpretable concept dimensions. Instead of learning a joint unstructured metric space, COMET learns mappings of high-level concepts into semi-structured metric spaces, and effectively combines the outputs of independent concept learners. We evaluate our model on few-shot tasks from diverse domains, including fine-grained image classification, document categorization  and cell type annotation on a novel dataset from a biological domain developed in our work. COMET significantly outperforms strong meta-learning baselines, achieving 6-15% relative improvement on the most challenging 1-shot learning tasks, while unlike existing methods providing interpretations behind the model's predictions.",いくつかのラベル付きの例だけを与えられた新しいタスクに一般化できるアルゴリズムを開発することは、機械レベルと人間レベルのパフォーマンスの間のギャップを埋める上での根本的な課題を表しています。人間の認知の中核は、構造化された再利用可能な概念にあり、新しいタスクに迅速に適応し、意思決定の背後にある推論を提供するのに役立ちます。ただし、既存のメタ学習方法は、学習した表現に構造を課すことなく、以前にラベル付けされたタスク全体で複雑な表現を学習します。ここでは、人間が解釈できる概念の次元に沿って学習することを学習することにより、一般化能力を向上させるメタ学習方法であるCOMETを提案します。 COMETは、共同の非構造化距離空間を学習する代わりに、高レベルの概念の半構造化距離空間へのマッピングを学習し、独立した概念学習者の出力を効果的に組み合わせます。私たちは、細粒度の画像分類、ドキュメントの分類、および私たちの研究で開発された生物学的ドメインからの新しいデータセットの細胞型注釈を含む、多様なドメインからの数ショットのタスクでモデルを評価します。 COMETは、強力なメタ学習ベースラインを大幅に上回り、6〜15を達成しています,6.0,
InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective,"['Boxin Wang', 'Shuohang Wang', 'Yu Cheng', 'Zhe Gan', 'Ruoxi Jia', 'Bo Li', 'Jingjing Liu']",https://openreview.net/forum?id=hpH98mK5Puk,"Large-scale language models such as BERT have achieved state-of-the-art performance across a wide range of NLP tasks. Recent studies, however, show that such BERT-based models are vulnerable facing the threats of textual adversarial attacks. We aim to address this problem from an information-theoretic perspective, and propose InfoBERT, a novel learning framework for robust ﬁne-tuning of pre-trained language models. InfoBERT contains two mutual-information-based regularizers for model training: (i) an Information Bottleneck regularizer, which suppresses noisy mutual information between the input and the feature representation; and (ii) a Robust Feature regularizer, which increases the mutual information between local robust features and global features. We provide a principled way to theoretically analyze and improve the robustness of representation learning for language models in both standard and adversarial training. Extensive experiments demonstrate that InfoBERT achieves state-of-the-art robust accuracy over several adversarial datasets on Natural Language Inference (NLI) and Question Answering (QA) tasks.
Our code is available at https://github.com/AI-secure/InfoBERT.",BERTなどの大規模な言語モデルは、幅広いNLPタスクにわたって最先端のパフォーマンスを実現しています。ただし、最近の調査によると、このようなBERTベースのモデルは、テキストによる敵対的攻撃の脅威に直面して脆弱であることが示されています。情報理論の観点からこの問題に対処することを目指し、事前にトレーニングされた言語モデルの堅牢な微調整のための新しい学習フレームワークであるInfoBERTを提案します。 InfoBERTには、モデルトレーニング用の2つの相互情報量ベースの正則化が含まれています。（i）入力と特徴表現の間のノイズの多い相互情報量を抑制する情​​報ボトルネック正則化。 （ii）ロバスト機能正則化。ローカルのロバスト機能とグローバル機能の間の相互情報量を増やします。標準トレーニングと敵対トレーニングの両方で、言語モデルの表現学習の堅牢性を理論的に分析および改善するための原則的な方法を提供します。広範な実験により、InfoBERTは、自然言語推論（NLI）および質問応答（QA）タスクに関するいくつかの敵対的なデータセットに対して最先端の堅牢な精度を達成することが実証されています。私たちのコードはhttps://github.com/AI-secure/InfoBERTで入手できます。,6.0,
Mixed-Features Vectors and Subspace Splitting,"['Alejandro Pimentel-Alarcón', 'Daniel L. Pimentel-Alarcón']",https://openreview.net/forum?id=l-LGlk4Yl6G,"Motivated by metagenomics, recommender systems, dictionary learning, and related problems, this paper introduces subspace splitting(SS): the task of clustering the entries of what we call amixed-features vector, that is, a vector whose subsets of coordinates agree with a collection of subspaces. We derive precise identifiability conditions under which SS is well-posed, thus providing the first fundamental theory for this problem. We also propose the first three practical SS algorithms, each with advantages and disadvantages: a random sampling method , a projection-based greedy heuristic , and an alternating Lloyd-type algorithm ; all allow noise, outliers, and missing data. Our extensive experiments outline the performance of our algorithms, and in lack of other SS algorithms, for reference we compare against methods for tightly related problems, like robust matched subspace detection and maximum feasible subsystem, which are special simpler cases of SS.",メタゲノミクス、レコメンダーシステム、辞書学習、および関連する問題に動機付けられて、このペーパーでは、部分空間分割（SS）を紹介します。これは、混合特徴ベクトルと呼ばれるもののエントリをクラスタリングするタスクです。つまり、座標のサブセットが部分空間のコレクション。 SSが適切に設定されている正確な識別可能性条件を導き出し、この問題の最初の基本理論を提供します。また、最初の3つの実用的なSSアルゴリズムを提案します。それぞれに長所と短所があります。ランダムサンプリング法、射影ベースの欲張りヒューリスティック、および交互ロイドタイプアルゴリズムです。すべて、ノイズ、外れ値、および欠測データを許可します。私たちの広範な実験では、アルゴリズムのパフォーマンスの概要を説明し、他のSSアルゴリズムがないため、SSの特別な単純なケースである、ロバストな一致部分空間検出や最大実行可能サブシステムなど、密接に関連する問題の方法と比較します。,6.0,
Entropic gradient descent algorithms and wide flat minima,"['Fabrizio Pittorino', 'Carlo Lucibello', 'Christoph Feinauer', 'Gabriele Perugini', 'Carlo Baldassi', 'Elizaveta Demyanenko', 'Riccardo Zecchina']",https://openreview.net/forum?id=xjXg0bnoDmS,"The properties of flat minima in the empirical risk landscape of neural networks have been debated for some time. Increasing evidence suggests they possess better generalization capabilities with respect to sharp ones. In this work we first discuss the relationship between alternative measures of flatness: The local entropy, which is useful for analysis and algorithm development, and the local energy, which is easier to compute and was shown empirically in extensive tests on state-of-the-art networks to be the best predictor of generalization capabilities. We show semi-analytically in simple controlled scenarios that these two measures correlate strongly with each other and with generalization. Then, we extend the analysis to the deep learning scenario by extensive numerical validations. We study two algorithms, Entropy-SGD and Replicated-SGD, that explicitly include the local entropy in the optimization objective. We devise a training schedule by which we consistently find flatter minima (using both flatness measures), and improve the generalization error for common architectures (e.g. ResNet, EfficientNet).",ニューラルネットワークの経験的リスクランドスケープにおけるフラットミニマムの特性は、しばらくの間議論されてきました。証拠の増加は、鋭いものよりも優れた一般化機能を持っていることを示唆しています。この作業では、最初に、平坦性の代替測定値の関係について説明します。分析とアルゴリズム開発に役立つローカルエントロピーと、計算が容易で、最先端の広範なテストで経験的に示されたローカルエネルギーです。 -一般化機能の最良の予測因子となるアートネットワーク。単純な制御されたシナリオで半分析的に、これら2つの測定値が互いに強く相関していることと一般化と相関していることを示します。次に、広範な数値検証により、分析を深層学習シナリオに拡張します。最適化の目的にローカルエントロピーを明示的に含める2つのアルゴリズム、Entropy-SGDとReplicate-SGDを研究します。一貫してより平坦な最小値を見つけ（両方の平坦度測定を使用）、一般的なアーキテクチャ（ResNet、EfficientNetなど）の汎化誤差を改善するトレーニングスケジュールを考案します。,6.0,https://d3i71xaburhd42.cloudfront.net/7547e0b912b0a484e656d75f7cbd8623af147f38/4-Figure1-1.png
Protecting DNNs from Theft using an Ensemble of Diverse Models,"['Sanjay Kariyappa', 'Atul Prakash', 'Moinuddin K Qureshi']",https://openreview.net/forum?id=LucJxySuJcE,"Several recent works have demonstrated highly effective model stealing (MS) attacks on Deep Neural Networks (DNNs) in black-box settings, even when the training data is unavailable. These attacks typically use some form of Out of Distribution (OOD) data to query the target model and use the predictions obtained to train a clone model. Such a clone model learns to approximate the decision boundary of the target model, achieving high accuracy on in-distribution examples. We propose Ensemble of Diverse Models (EDM) to defend against such MS attacks. EDM is made up of models that are trained to produce dissimilar predictions for OOD inputs. By using a different member of the ensemble to service different queries, our defense produces predictions that are highly discontinuous in the input space for the adversary's OOD queries. Such discontinuities cause the clone model trained on these predictions to have poor generalization on in-distribution examples. Our evaluations on several image classification tasks demonstrate that EDM defense can severely degrade the accuracy of clone models (up to $39.7\%$). Our defense has minimal impact on the target accuracy, negligible computational costs during inference, and is compatible with existing defenses for MS attacks.",最近のいくつかの研究では、トレーニングデータが利用できない場合でも、ブラックボックス設定でディープニューラルネットワーク（DNN）に対する非常に効果的なモデル盗用（MS）攻撃が実証されています。これらの攻撃は通常、何らかの形式のOut of Distribution（OOD）データを使用してターゲットモデルにクエリを実行し、取得した予測を使用してクローンモデルをトレーニングします。このようなクローンモデルは、ターゲットモデルの決定境界を近似することを学習し、配布中の例で高精度を実現します。このようなMS攻撃から防御するために、Ensemble of Diverse Models（EDM）を提案します。 EDMは、OOD入力の異なる予測を生成するようにトレーニングされたモデルで構成されています。アンサンブルの異なるメンバーを使用して異なるクエリを処理することにより、防御は、敵のOODクエリの入力スペースで非常に不連続な予測を生成します。このような不連続性により、これらの予測でトレーニングされたクローンモデルは、配布内の例での一般化が不十分になります。いくつかの画像分類タスクに関する私たちの評価は、EDM防御がクローンモデルの精度を大幅に低下させる可能性があることを示しています（最大39.7％）。私たちの防御は、ターゲットの精度への影響を最小限に抑え、推論中の計算コストを無視でき、MS攻撃に対する既存の防御と互換性があります。,6.0,
Large Batch Simulation for Deep Reinforcement Learning,"['Brennan Shacklett', 'Erik Wijmans', 'Aleksei Petrenko', 'Manolis Savva', 'Dhruv Batra', 'Vladlen Koltun', 'Kayvon Fatahalian']",https://openreview.net/forum?id=cP5IcoAkfKa,"We accelerate deep reinforcement learning based training in visually complex 3D environments by two orders of magnitude over prior work, realizing end-to-end training speeds of over 19,000 frames of experience per second on a single GPU (and up to 72,000 frames per second on a single eight-GPU machine). The key idea of our approach is to design a 3D renderer and environment simulator around the principle of “batch simulation”:  accepting and executing large batches of requests simultaneously.  Beyond exposing large amounts of work at once,  batch simulation allows simulator implementations to amortize in-memory storage of scene assets, rendering work, data loading, and synchronization costs across many simulation requests, dramatically improving the number of simulated agents per GPU and overall simulation throughput.  To balance DNN inference and training costs with faster simulation, we also build a computationally efficient policy DNN that maintains high task performance, and modify training algorithms to maintain sample efficiency when training with large mini-batches. By combining batch simulation and DNN performance optimizations, we demonstrate that PointGoal navigation agents can be trained in complex 3D environments on a single GPU in 1.5 days to 97% of the accuracy of agents trained on a prior state-of-the-art system using a 64-GPU cluster over three days.  We provide open-source reference implementations of our batch 3D renderer and simulator to facilitate incorporation of these ideas into current and future RL systems.","視覚的に複雑な3D環境での深層強化学習ベースのトレーニングを以前の作業よりも2桁高速化し、単一のGPUで毎秒19,000フレームを超えるエンドツーエンドのトレーニング速度を実現します（最大72,000フレーム/秒）単一の8GPUマシン）。私たちのアプローチの重要なアイデアは、バッチシミュレーションの原則に基づいて3Dレンダラーと環境シミュレーターを設計することです。つまり、大量のリクエストを同時に受け入れて実行します。バッチシミュレーションでは、一度に大量の作業を公開するだけでなく、シミュレーターの実装により、シーンアセットのメモリ内ストレージ、レンダリング作業、データの読み込み、および多くのシミュレーションリクエストにわたる同期コストを償却し、GPUあたりのシミュレートされたエージェントの数とシミュレーション全体を劇的に改善できます。スループット。 DNNの推論とトレーニングのコストとより高速なシミュレーションのバランスをとるために、高いタスクパフォ​​ーマンスを維持する計算効率の高いポリシーDNNを構築し、トレーニングアルゴリズムを変更して、大きなミニバッチでトレーニングするときのサンプル効率を維持します。バッチシミュレーションとDNNパフォーマンスの最適化を組み合わせることにより、PointGoalナビゲーションエージェントを単一のGPU上の複雑な3D環境で1。5日から97日でトレーニングできることを示します。",5.8,
Estimating Lipschitz constants of monotone deep equilibrium models,"['Chirag Pabbaraju', 'Ezra Winston', 'J Zico Kolter']",https://openreview.net/forum?id=VcB4QkSfyO,"Several methods have been proposed in recent years to provide bounds on the Lipschitz constants of deep networks, which can be used to provide robustness guarantees, generalization bounds, and characterize the smoothness of decision boundaries. However, existing bounds get substantially weaker with increasing depth of the network, which makes it unclear how to apply such bounds to recently proposed models such as the deep equilibrium (DEQ) model, which can be viewed as representing an infinitely-deep network. In this paper, we show that monotone DEQs, a recently-proposed subclass of DEQs, have Lipschitz constants that can be bounded as a simple function of the strong monotonicity parameter of the network. We derive simple-yet-tight bounds on both the input-output mapping and the weight-output mapping defined by these networks, and demonstrate that they are small relative to those for comparable standard DNNs. We show that one can use these bounds to design monotone DEQ models, even with e.g. multi-scale convolutional structure, that still have constraints on the Lipschitz constant. We also highlight how to use these bounds to develop PAC-Bayes generalization bounds that do not depend on any depth of the network, and which avoid the exponential depth-dependence of comparable DNN bounds.",近年、深いネットワークのリプシッツ定数に限界を与えるためにいくつかの方法が提案されており、これを使用して、ロバスト性の保証、一般化の限界を提供し、決定境界の滑らかさを特徴付けることができます。ただし、既存の境界はネットワークの深さが増すにつれて大幅に弱くなるため、無限に深いネットワークを表すと見なすことができる深平衡（DEQ）モデルなどの最近提案されたモデルにそのような境界を適用する方法が不明確になります。この論文では、最近提案されたDEQのサブクラスである単調DEQが、ネットワークの強い単調性パラメーターの単純な関数として制限できるリプシッツ定数を持っていることを示します。これらのネットワークによって定義された入出力マッピングと重み-出力マッピングの両方について、単純でありながら厳密な境界を導き出し、同等の標準DNNの境界に比べて小さいことを示します。これらの境界を使用して、たとえばマルチスケール畳み込み構造であっても、リプシッツ定数に制約がある単調DEQモデルを設計できることを示します。また、これらの境界を使用して、ネットワークの深さに依存せず、同等のDNN境界の指数関数的な深さ依存性を回避するPACベイズ一般化境界を開発する方法についても説明します。,5.8,
SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization,"['A F M Shahab Uddin', 'Mst. Sirazam Monira', 'Wheemyung Shin', 'TaeChoong Chung', 'Sung-Ho Bae']",https://openreview.net/forum?id=-M0QkvBGTTq,"Advanced data augmentation strategies have widely been studied to improve the generalization ability of deep learning models. Regional dropout is one of the popular solutions that guides the model to focus on less discriminative parts by randomly removing image regions, resulting in improved regularization. However, such information removal is undesirable. On the other hand, recent strategies suggest to randomly cut and mix patches and their labels among training images, to enjoy the advantages of regional dropout without having any pointless pixel in the augmented images. We argue that the random selection of the patch may not necessarily represent any information about the corresponding object and thereby mixing the labels according to that uninformative patch enables the model to learn unexpected feature representation. Therefore, we propose SaliencyMix that carefully selects a representative image patch with the help of a saliency map and mixes this indicative patch with the target image that leads the model to learn more appropriate feature representation. SaliencyMix achieves the best known top-1 error of $21.26\%$ and $20.09\%$ for ResNet-50 and ResNet-101 architectures on ImageNet classification, respectively and also improves the model robustness against adversarial perturbations. Furthermore, SaliencyMix trained model helps to improve the object detection performance.",ディープラーニングモデルの一般化能力を向上させるために、高度なデータ拡張戦略が広く研究されてきました。リージョナルドロップアウトは、画像領域をランダムに削除することで識別性の低い部分に焦点を合わせるようにモデルをガイドする一般的なソリューションの1つであり、正則化が向上します。ただし、このような情報の削除は望ましくありません。一方、最近の戦略では、トレーニング画像間でパッチとそのラベルをランダムにカットして混合し、拡張画像に無意味なピクセルを持たずに地域ドロップアウトの利点を享受することを提案しています。パッチのランダムな選択は、必ずしも対応するオブジェクトに関する情報を表すとは限らないため、その情報の少ないパッチに従ってラベルを混合すると、モデルが予期しない特徴表現を学習できるようになると主張します。したがって、顕著性マップを使用して代表的な画像パッチを慎重に選択し、この指標パッチをターゲット画像と混合してモデルがより適切な特徴表現を学習するようにするSaliencyMixを提案します。 SaliencyMixは、ImageNet分類のResNet-50およびResNet-101アーキテクチャでそれぞれ21.26％および20.09％の最もよく知られているトップ1エラーを達成し、敵対的な摂動に対するモデルの堅牢性も向上させます。さらに、SaliencyMixでトレーニングされたモデルは、オブジェクト検出のパフォーマンスを向上させるのに役立ちます。,5.8,
Training with Quantization Noise for Extreme Model Compression,"['Angela Fan', 'Pierre Stock', 'Benjamin Graham', 'Edouard Grave', 'Rémi Gribonval', 'Herve Jegou', 'Armand Joulin']",https://openreview.net/forum?id=dV19Yyi1fS3,"We tackle the problem of producing compact models, maximizing their accuracy for a given model size. A standard solution is to train networks with Quantization Aware Training, where the weights are quantized during training and the gradients approximated with the Straight-Through Estimator. In this paper, we extend this approach to work with extreme compression methods where the approximations introduced by STE are severe. Our proposal is to only quantize a different random subset of weights during each forward, allowing for unbiased gradients to flow through the other weights. Controlling the amount of noise and its form allows for extreme compression rates while maintaining the performance of the original model. As a result we establish new state-of-the-art compromises between accuracy and model size both in natural language processing and image classification. For example, applying our method to state-of-the-art Transformer and ConvNet architectures, we can achieve 82.5% accuracy on MNLI by compressing RoBERTa to 14 MB and 80.0% top-1 accuracy on ImageNet by compressing an EfficientNet-B3 to 3.3 MB.",コンパクトなモデルを作成するという問題に取り組み、特定のモデルサイズで精度を最大化します。標準的な解決策は、Quantization Aware Trainingを使用してネットワークをトレーニングすることです。このトレーニングでは、トレーニング中に重みが量子化され、勾配がStraight-ThroughEstimatorで近似されます。このホワイトペーパーでは、このアプローチを拡張して、STEによって導入された近似が厳しい極端な圧縮方法を使用できるようにします。私たちの提案は、各フォワード中に重みの異なるランダムサブセットのみを量子化し、バイアスのない勾配が他の重みを流れることを可能にすることです。ノイズの量とその形状を制御することで、元のモデルのパフォーマンスを維持しながら、極端な圧縮率を実現できます。その結果、自然言語処理と画像分類の両方で、精度とモデルサイズの間に新しい最先端の妥協点を確立します。たとえば、この方法を最先端のTransformerおよびConvNetアーキテクチャに適用すると、82.5を達成できます。,5.8,https://d3i71xaburhd42.cloudfront.net/0171ad4cc87cc7db25b4ec3169e293eed9a13b39/2-Figure1-1.png
C-Learning: Horizon-Aware Cumulative Accessibility Estimation,"['Panteha Naderian', 'Gabriel Loaiza-Ganem', 'Harry J. Braviner', 'Anthony L. Caterini', 'Jesse C. Cresswell', 'Tong Li', 'Animesh Garg']",https://openreview.net/forum?id=W3Wf_wKmqm9,"Multi-goal reaching is an important problem in reinforcement learning needed to achieve algorithmic generalization. Despite recent advances in this field, current algorithms suffer from three major challenges: high sample complexity, learning only a single way of reaching the goals,  and difficulties in solving complex motion planning tasks. In order to address these limitations, we introduce the concept of cumulative accessibility functions, which measure the reachability of a goal from a given state within a specified horizon. We show that these functions obey a recurrence relation, which enables learning from offline interactions. We also prove that optimal cumulative accessibility functions are monotonic in the planning horizon. Additionally, our method can trade off speed and reliability in goal-reaching by suggesting multiple paths to a single goal depending on the provided horizon. We evaluate our approach on a set of multi-goal discrete and continuous control tasks. We show that our method outperforms state-of-the-art goal-reaching algorithms in success rate, sample complexity, and path optimality. Our code is available at https://github.com/layer6ai-labs/CAE, and additional visualizations can be found at https://sites.google.com/view/learning-cae/.",マルチゴールリーチは、アルゴリズムの一般化を達成するために必要な強化学習における重要な問題です。この分野での最近の進歩にもかかわらず、現在のアルゴリズムには3つの大きな課題があります。サンプルの複雑さが高いこと、目標を達成するための単一の方法しか学習できないこと、複雑な動作計画タスクを解決することが難しいことです。これらの制限に対処するために、累積アクセシビリティ関数の概念を導入します。これは、指定された範囲内の特定の状態からのゴールの到達可能性を測定します。これらの関数が、オフラインの相互作用からの学習を可能にする漸化式に従うことを示します。また、最適な累積アクセシビリティ関数が計画期間において単調であることも証明します。さらに、私たちの方法は、提供された期間に応じて単一の目標への複数のパスを提案することにより、目標達成の速度と信頼性をトレードオフすることができます。一連のマルチゴール離散および連続制御タスクでアプローチを評価します。私たちの方法は、成功率、サンプルの複雑さ、およびパスの最適性において、最先端の目標達成アルゴリズムよりも優れていることを示しています。私たちのコードはhttps://github.com/layer6ai-labs/CAEで入手でき、追加の視覚化はhttps://sites.google.com/view/learning-cae/で見つけることができます。,5.75,https://d3i71xaburhd42.cloudfront.net/d6a02799e3b71f137b15ffb0a460cc7b3080ec56/2-Figure1-1.png
"AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL","['Lucio M. Dery', 'Yann Dauphin', 'David Grangier']",https://openreview.net/forum?id=1GTma8HwlYp,"While deep learning has been very beneficial in data-rich settings, tasks with smaller training set
often resort to pre-training or multitask learning to leverage data from other tasks. In this case,
careful consideration is needed to select tasks and model parameterizations such that updates from
the auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions 
differently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that
purpose and show its advantage in practice. Our method leverages efficient automatic differentiation 
procedures and randomized singular value decomposition for scalability. We show that our framework is 
generic and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.",ディープラーニングはデータが豊富な設定で非常に有益ですが、トレーニングセットが小さいタスクは、他のタスクからのデータを活用するために、事前トレーニングまたはマルチタスク学習に頼ることがよくあります。この場合、補助タスクからの更新が実際にプライマリタスクに役立つように、タスクを選択してパラメータ化をモデル化するために慎重に検討する必要があります。補助タスクの勾配をきめ細かく操作するモデルにとらわれないフレームワークを策定することで、この負担を軽減しようとしています。補助的な更新を、主要なタスクの損失を支援、損傷、または変更しないままにする方向に分解することを提案します。これにより、対象の問題への影響に応じて、更新方向に異なる重みを付けることができます。その目的のための斬新で効率的なアルゴリズムを提示し、実際にその利点を示します。私たちの方法は、効率的な自動微分手順とランダム化された特異値分解を活用してスケーラビリティを実現します。私たちのフレームワークは一般的であり、特定のケースとしていくつかの以前の作業を包含していることを示します。私たちのアプローチは、テキストと画像の分類タスクに配布外のデータを活用する場合、強力で広く使用されているベースラインを常に上回っています。,5.75,
Provably robust classification of adversarial examples with detection,"['Fatemeh Sheikholeslami', 'Ali Lotfi', 'J Zico Kolter']",https://openreview.net/forum?id=sRA5rLNpmQc,"Adversarial attacks against deep networks can be defended against either by building robust classifiers or, by creating classifiers that can \emph{detect} the presence of adversarial perturbations.  Although it may intuitively seem easier to simply detect attacks rather than build a robust classifier, this has not bourne out in practice even empirically, as most detection methods have subsequently been broken by adaptive attacks, thus necessitating \emph{verifiable} performance for detection mechanisms.  In this paper, we propose a new method for jointly training a provably robust classifier and detector.  Specifically, we show that by introducing an additional ""abstain/detection"" into a classifier, we can modify existing certified defense mechanisms to allow the classifier to either robustly classify \emph{or} detect adversarial attacks.  We extend the common interval bound propagation (IBP) method for certified robustness under $\ell_\infty$ perturbations to account for our new robust objective, and show that the method outperforms traditional IBP used in isolation, especially for large perturbation sizes.  Specifically, tests on MNIST and CIFAR-10 datasets exhibit promising results, for example with provable robust error less than $63.63\%$ and $67.92\%$, for $55.6\%$ and $66.37\%$ natural error, for $\epsilon=8/255$ and $16/255$ on the CIFAR-10 dataset, respectively.
",ディープネットワークに対する敵対的攻撃は、堅牢な分類器を構築するか、敵対的摂動の存在を検出できる分類器を作成することによって防御できます。堅牢な分類器を構築するよりも、攻撃を単純に検出する方が直感的に簡単に思えるかもしれませんが、ほとんどの検出方法はその後適応的攻撃によって破られ、検出メカニズムの検証可能なパフォーマンスが必要になるため、これは実際には経験的にも発生していません。本論文では、証明可能なロバストな分類器と検出器を共同で訓練するための新しい方法を提案する。具体的には、分類器に追加の「棄権/検出」を導入することにより、既存の認定された防御メカニズムを変更して、分類器が敵対的攻撃を確実に分類または検出できるようにすることができることを示します。 l（）摂動下での認定されたロバスト性のための共通間隔境界伝搬（IBP）法を拡張して、新しいロバスト目的を説明し、特に大きな摂動サイズに対して、この方法が単独で使用される従来のIBPよりも優れていることを示します。具体的には、MNISTおよびCIFAR-10データセットでのテストは、有望な結果を示します。たとえば、CIFAR-で= 8/255および16/255の場合、55.6％および66.37％の自然誤差で63.63％および67.92％未満の証明可能なロバストエラーがあります。それぞれ10個のデータセット。,5.75,
Understanding Over-parameterization in Generative Adversarial Networks,"['Yogesh Balaji', 'Mohammadmahdi Sajedi', 'Neha Mukund Kalibhat', 'Mucong Ding', 'Dominik Stöger', 'Mahdi Soltanolkotabi', 'Soheil Feizi']",https://openreview.net/forum?id=C3qvk5IQIJY,"A broad class of {\it unsupervised} deep learning methods such as Generative Adversarial Networks (GANs) involve training of overparameterized models where the number of parameters of the model exceeds a certain threshold. Indeed, most successful GANs used in practice are trained using overparameterized generator and discriminator networks, both in terms of depth and width. A large body of work in {\it supervised} learning have shown the importance of model overparameterization in the convergence of the gradient descent (GD) to globally optimal solutions. In contrast, the unsupervised setting and GANs in particular involve non-convex concave mini-max optimization problems that are often trained using Gradient Descent/Ascent (GDA). The role and benefits of model overparameterization in the convergence of GDA to a global saddle point in non-convex concave problems is far less understood. In this work, we present a comprehensive analysis of the importance of model overparameterization in GANs both theoretically and empirically. We theoretically show that in an overparameterized GAN model with a $1$-layer neural network generator and a linear discriminator, GDA converges to a global saddle point of the underlying non-convex concave min-max problem. To the best of our knowledge, this is the first result for global convergence of GDA in such settings. Our theory is based on a more general result that holds for a broader class of nonlinear generators and discriminators that obey certain assumptions (including deeper generators and random feature discriminators). Our theory utilizes and builds upon a novel connection with the convergence analysis of linear time-varying dynamical systems which may have broader implications for understanding the convergence behavior of GDA for non-convex concave problems involving overparameterized models. We also empirically study the role of model overparameterization in GANs using several large-scale experiments on CIFAR-10 and Celeb-A datasets. Our experiments show that overparameterization improves the quality of generated samples across various model architectures and datasets. Remarkably, we observe that overparameterization leads to faster and more stable convergence behavior of GDA across the board.",Generative Adversarial Networks（GAN）などの教師なし深層学習手法の幅広いクラスには、モデルのパラメーターの数が特定のしきい値を超える、パラメーター化されたモデルのトレーニングが含まれます。実際、実際に使用されている最も成功しているGANは、深さと幅の両方の観点から、パラメーター化されたジェネレーターとディスクリミネーターのネットワークを使用してトレーニングされています。教師あり学習の多くの作業により、最急降下法（GD）のグローバルに最適なソリューションへの収束におけるモデルの過剰パラメーター化の重要性が示されています。対照的に、教師なし設定とGANには、特に、勾配降下/上昇（GDA）を使用してトレーニングされることが多い非凸凹ミニマックス最適化問題が含まれます。非凸凹問題のグローバル鞍点へのGDAの収束におけるモデルの過剰パラメーター化の役割と利点は、あまり理解されていません。この作業では、理論的および経験的の両方で、GANにおけるモデルの過剰パラメータ化の重要性の包括的な分析を提示します。理論的には、1層ニューラルネットワークジェネレーターと線形判別分析を使用したパラメーター化されたGANモデルで、GDAが基礎となる非凸凹ミニマックス問題のグローバル鞍点に収束することを示します。私たちの知る限り、これはそのような設定でのGDAのグローバルな収束の最初の結果です。私たちの理論は、特定の仮定に従う、より広いクラスの非線形ジェネレーターとディスクリミネーター（より深いジェネレーターとランダムな特徴のディスクリミネーターを含む）に当てはまる、より一般的な結果に基づいています。私たちの理論は、線形時変動的システムの収束解析との新しい接続を利用して構築します。これは、パラメーター化されたモデルが関与する非凸凹問題に対するGDAの収束動作を理解するための幅広い意味を持つ可能性があります。また、CIFAR-10およびCeleb-Aデータセットでのいくつかの大規模な実験を使用して、GANにおけるモデルの過剰パラメーター化の役割を経験的に研究します。私たちの実験は、過剰パラメータ化により、さまざまなモデルアーキテクチャとデータセットにわたって生成されたサンプルの品質が向上することを示しています。注目すべきことに、パラメーター化が過剰になると、GDAの収束動作が全面的に高速で安定することがわかります。,5.75,
Emergent Road Rules In Multi-Agent Driving Environments,"['Avik Pal', 'Jonah Philion', 'Yuan-Hong Liao', 'Sanja Fidler']",https://openreview.net/forum?id=d8Q1mt2Ghw,"For autonomous vehicles to safely share the road with human drivers, autonomous vehicles must abide by specific ""road rules"" that human drivers have agreed to follow. ""Road rules"" include rules that drivers are required to follow by law – such as the requirement that vehicles stop at red lights – as well as more subtle social rules – such as the implicit designation of fast lanes on the highway. In this paper, we provide empirical evidence that suggests that – instead of hard-coding road rules into self-driving algorithms – a scalable alternative may be to design multi-agent environments in which road rules emerge as optimal solutions to the problem of maximizing traffic flow.  We analyze what ingredients in driving environments cause the emergence of these road rules and find that two crucial factors are noisy perception and agents’ spatial density.  We provide qualitative and quantitative evidence of the emergence of seven social driving behaviors, ranging from obeying traffic signals to following lanes, all of which emerge from training agents to drive quickly to destinations without colliding. Our results add empirical support for the social road rules that countries worldwide have agreed on for safe, efficient driving.",自動運転車が安全に道路を人間のドライバーと共有するためには、自動運転車は人間のドライバーが従うことに同意した特定の「道路規則」を遵守する必要があります。 「交通ルール」には、車両が赤信号で停止するという要件などの法律によってドライバーが従う必要のあるルールや、高速道路の高速車線の暗黙的な指定などのより微妙な社会的ルールが含まれます。この論文では、自動運転アルゴリズムに道路規則をハードコーディングする代わりに、交通流を最大化する問題の最適な解決策として道路規則が出現するマルチエージェント環境を設計することがスケーラブルな代替手段である可能性があることを示唆する経験的証拠を提供します。運転環境のどの成分がこれらの道路規則の出現を引き起こすかを分析し、2つの重要な要因がノイズの多い知覚とエージェントの空間密度であることを発見しました。信号に従うことから車線をたどることまで、7つの社会的運転行動の出現の定性的および定量的証拠を提供します。これらはすべて、衝突することなく目的地まで迅速に運転するためのトレーニングエージェントから出現します。私たちの結果は、安全で効率的な運転のために世界中の国々が合意した社会的道路規則に対する経験的サポートを追加します。,5.75,https://d3i71xaburhd42.cloudfront.net/8b28d8cc9ada77bba7505b594c1f8a845ad7725c/1-Figure1-1.png
Group Equivariant Generative Adversarial Networks,"['Neel Dey', 'Antong Chen', 'Soheil Ghafurian']",https://openreview.net/forum?id=rgFNuJHHXv,"Recent improvements in generative adversarial visual synthesis incorporate real and fake image transformation in a self-supervised setting, leading to increased stability and perceptual fidelity. However, these approaches typically involve image augmentations via additional regularizers in the GAN objective and thus spend valuable network capacity towards approximating transformation equivariance instead of their desired task. In this work, we explicitly incorporate inductive symmetry priors into the network architectures via group-equivariant convolutional networks. Group-convolutions have higher expressive power with fewer samples and lead to better gradient feedback between generator and discriminator. Further, group-representations are especially relevant for modalities such as medical imaging, where image labels are typically invariant under rotation/reflection. We show that group-equivariance integrates seamlessly with recent techniques for GAN training across regularizers, architectures, and loss functions. We demonstrate the utility of our methods for conditional synthesis by improving generation in the limited data regime across globally-symmetric imaging datasets and even finding benefits for natural images with preferred orientation.",生成的敵対的視覚合成の最近の改善により、自己監視設定で実際の画像変換と偽の画像変換が組み込まれ、安定性と知覚の忠実度が向上します。ただし、これらのアプローチは通常、GAN目標の追加のレギュラライザーによる画像の拡張を伴うため、目的のタスクではなく、変換の同変を近似するために貴重なネットワーク容量を費やします。この作業では、グループ同変畳み込みネットワークを介して、帰納的対称事前分布をネットワークアーキテクチャに明示的に組み込みます。グループ畳み込みは、より少ないサンプルでより高い表現力を持ち、ジェネレーターとディスクリミネーター間のより良い勾配フィードバックにつながります。さらに、群の表現は、画像ラベルが回転/反射の下で通常不変である医用画像などのモダリティに特に関連しています。グループの同変性が、レギュラライザー、アーキテクチャー、および損失関数にわたるGANトレーニングの最近の手法とシームレスに統合されることを示します。グローバルに対称なイメージングデータセット全体の限られたデータレジームでの生成を改善し、優先方向の自然画像の利点を見つけることによって、条件付き合成の方法の有用性を示します。,5.75,https://d3i71xaburhd42.cloudfront.net/d2c565d0bbebe6fd050bfcde630446fa3c608f4e/2-Figure1-1.png
Grounding Language to Autonomously-Acquired Skills via Goal Generation,"['Ahmed Akakzia', 'Cédric Colas', 'Pierre-Yves Oudeyer', 'Mohamed CHETOUANI', 'Olivier Sigaud']",https://openreview.net/forum?id=chPj_I5KMHG,"We are interested in the autonomous acquisition of repertoires of skills. Language-conditioned reinforcement learning (LC-RL) approaches are great tools in this quest, as they allow to express abstract goals as sets of constraints on the states. However, most LC-RL agents are not autonomous and cannot learn without external instructions and feedback. Besides, their direct language condition cannot account for the goal-directed behavior of pre-verbal infants and strongly limits the expression of behavioral diversity for a given language input. To resolve these issues, we propose a new conceptual approach to language-conditioned RL: the Language-Goal-Behavior architecture (LGB). LGB decouples skill learning and language grounding via an intermediate semantic representation of the world. To showcase the properties of LGB, we present a specific implementation called DECSTR. DECSTR is an intrinsically motivated learning agent endowed with an innate semantic representation describing spatial relations between physical objects. In a first stage G -> B, it freely explores its environment and targets self-generated semantic configurations. In a second stage (L -> G), it trains a language-conditioned  goal generator to generate semantic goals that match the constraints expressed in language-based inputs. We showcase the additional properties of LGB w.r.t. both an end-to-end LC-RL approach and a similar approach leveraging non-semantic, continuous intermediate representations. Intermediate semantic representations help satisfy language commands in a diversity of ways, enable strategy switching after a failure and facilitate language grounding.",スキルのレパートリーを自律的に習得することに関心があります。言語条件付き強化学習（LC-RL）アプローチは、州に対する一連の制約として抽象的な目標を表現できるため、この探求における優れたツールです。ただし、ほとんどのLC-RLエージェントは自律的ではなく、外部からの指示とフィードバックなしでは学習できません。その上、彼らの直接的な言語状態は、言語前の乳児の目標指向の行動を説明することができず、与えられた言語入力に対する行動の多様性の表現を強く制限します。これらの問題を解決するために、言語条件付きRLへの新しい概念的アプローチであるLanguage-Goal-Behaviorアーキテクチャ（LGB）を提案します。 LGBは、世界の中間的な意味表現を介して、スキル学習と言語の基礎を切り離します。 LGBのプロパティを紹介するために、DECSTRと呼ばれる特定の実装を紹介します。 DECSTRは、物理オブジェクト間の空間的関係を記述する固有のセマンティック表現を備えた、本質的に動機付けられた学習エージェントです。最初の段階G-&gt; Bでは、環境を自由に探索し、自己生成されたセマンティック構成を対象とします。第2段階（L-&gt; G）では、言語ベースの入力で表現された制約に一致するセマンティックゴールを生成するように、言語条件付きゴールジェネレーターをトレーニングします。エンドツーエンドのLC-RLアプローチと、非セマンティックで連続的な中間表現を活用する同様のアプローチの両方で、LGBの追加のプロパティを紹介します。中間のセマンティック表現は、さまざまな方法で言語コマンドを満たし、障害後の戦略の切り替えを可能にし、言語の基盤を容易にするのに役立ちます。,5.75,https://d3i71xaburhd42.cloudfront.net/0b22f92be890b720eaa97fa75a49560f11ff2ab2/2-Figure1-1.png
Transformer protein language models are unsupervised structure learners,"['Roshan Rao', 'Joshua Meier', 'Tom Sercu', 'Sergey Ovchinnikov', 'Alexander Rives']",https://openreview.net/forum?id=fylclEqgvgd,"Unsupervised contact prediction is central to uncovering physical, structural, and functional constraints for protein structure determination and design. For decades, the predominant approach has been to infer evolutionary constraints from a set of related sequences. In the past year, protein language models have emerged as a potential alternative, but performance has fallen short of state-of-the-art approaches in bioinformatics. In this paper we demonstrate that Transformer attention maps learn contacts from the unsupervised language modeling objective. We find the highest capacity models that have been trained to date already outperform a state-of-the-art unsupervised contact prediction pipeline, suggesting these pipelines can be replaced with a single forward pass of an end-to-end model.",教師なし接触予測は、タンパク質構造の決定と設計のための物理的、構造的、および機能的な制約を明らかにするための中心です。何十年もの間、主なアプローチは、関連するシーケンスのセットから進化の制約を推測することでした。昨年、タンパク質言語モデルが潜在的な代替手段として浮上しましたが、パフォーマンスはバイオインフォマティクスの最先端のアプローチには達していません。このホワイトペーパーでは、Transformerアテンションマップが教師なし言語モデリングの目的から連絡先を学習することを示します。これまでにトレーニングされた最大容量のモデルは、最先端の監視されていない接触予測パイプラインをすでに上回っています。これは、これらのパイプラインをエンドツーエンドモデルの単一のフォワードパスに置き換えることができることを示唆しています。,5.75,
Contemplating Real-World Object Classification,['ali borji'],https://openreview.net/forum?id=Q4EUywJIkqr,"Deep object recognition models have been very successful over benchmark
datasets such as ImageNet. How accurate and robust are they to distribution
shifts arising from natural and synthetic variations in datasets? Prior research on
this problem has primarily focused on ImageNet variations (e.g., ImageNetV2,
ImageNet-A). To avoid potential inherited biases in these studies, we take a
different approach. Specifically, we reanalyze the ObjectNet dataset recently
proposed by Barbu et al. containing objects in daily life situations. They showed
a dramatic performance drop of the state of the art object recognition models on
this dataset. Due to the importance and implications of their results regarding
the generalization ability of deep models, we take a second look at their analysis.
We find that applying deep models to the isolated objects, rather than the entire
scene as is done in the original paper, results in around 20-30% performance
improvement. Relative to the numbers reported in Barbu et al., around 10-15%
of the performance loss is recovered, without any test time data augmentation.
Despite this gain, however, we conclude that deep models still suffer drastically
on the ObjectNet dataset. We also investigate the robustness of models against
synthetic image perturbations such as geometric transformations (e.g., scale,
rotation, translation), natural image distortions (e.g., impulse noise, blur) as well
as adversarial attacks (e.g., FGSM and PGD-5). Our results indicate that limiting
the object area as much as possible (i.e., from the entire image to the bounding
box to the segmentation mask) leads to consistent improvement in accuracy and
robustness. Finally, through a qualitative analysis of ObjectNet data, we find that
i) a large number of images in this dataset are hard to recognize even for humans,
and ii) easy (hard) samples for models match with easy (hard) samples for humans.
Overall, our analysis shows that ObjecNet is still a challenging test platform that
can be used to measure the generalization ability of models. The code and data
are available in [masked due to blind review].",深いオブジェクト認識モデルは、ImageNetなどのベンチマークデータセットに対して非常に成功しています。データセットの自然および合成の変動から生じる分布の変化に対して、それらはどの程度正確で堅牢ですか？この問題に関するこれまでの研究は、主にImageNetのバリエーション（ImageNetV2、ImageNet-Aなど）に焦点を当てていました。これらの研究における潜在的な遺伝的バイアスを回避するために、私たちは異なるアプローチを取ります。具体的には、Barbuらによって最近提案されたObjectNetデータセットを再分析します。日常生活の中でオブジェクトを含みます。彼らは、このデータセットの最先端のオブジェクト認識モデルの劇的なパフォーマンスの低下を示しました。ディープモデルの一般化能力に関する結果の重要性と影響のために、それらの分析を再検討します。元の論文のようにシーン全体ではなく、孤立したオブジェクトに深いモデルを適用すると、約20〜30の改善が見られます。 Barbu et al。で報告された数値と比較して、テスト時間のデータを増やすことなく、パフォーマンスの低下の約10〜15が回復しています。ただし、この利益にもかかわらず、ObjectNetデータセットではディープモデルが依然として大幅に苦しんでいると結論付けています。また、幾何学的変換（スケール、回転、平行移動など）、自然な画像の歪み（インパルスノイズ、ブラーなど）、敵対的な攻撃（FGSMやPGD-5など）などの合成画像の摂動に対するモデルの堅牢性についても調査します。 。私たちの結果は、オブジェクト領域を可能な限り制限すること（つまり、画像全体からバウンディングボックス、セグメンテーションマスクまで）が、精度と堅牢性の一貫した改善につながることを示しています。最後に、ObjectNetデータの定性分析により、i）このデータセット内の多数の画像は人間でも認識が困難であり、ii）モデルの簡単な（ハード）サンプルは人間の簡単な（ハード）サンプルと一致することがわかりました。 。全体として、私たちの分析は、ObjecNetがモデルの一般化能力を測定するために使用できる挑戦的なテストプラットフォームであることを示しています。コードとデータは[ブラインドレビューのためにマスクされています]で入手できます。,5.75,
FairBatch: Batch Selection for Model Fairness,"['Yuji Roh', 'Kangwook Lee', 'Steven Euijong Whang', 'Changho Suh']",https://openreview.net/forum?id=YNnpaAKeCfx,"Training a fair machine learning model is essential to prevent demographic disparity. Existing techniques for improving model fairness require broad changes in either data preprocessing or model training, rendering themselves difficult-to-adopt for potentially already complex machine learning systems. We address this problem via the lens of bilevel optimization. While keeping the standard training algorithm as an inner optimizer, we incorporate an outer optimizer so as to equip the inner problem with an additional functionality: Adaptively selecting minibatch sizes for the purpose of improving model fairness. Our batch selection algorithm, which we call FairBatch, implements this optimization and supports prominent fairness measures: equal opportunity, equalized odds, and demographic parity. FairBatch comes with a significant implementation benefit -- it does not require any modification to data preprocessing or model training. For instance, a single-line change of PyTorch code for replacing batch selection part of model training suffices to employ FairBatch. Our experiments conducted both on synthetic and benchmark real data demonstrate that FairBatch can provide such functionalities while achieving comparable (or even greater) performances against the state of the arts.  Furthermore, FairBatch can readily improve fairness of any pre-trained model simply via fine-tuning. It is also compatible with existing batch selection techniques intended for different purposes, such as faster convergence, thus gracefully achieving multiple purposes.",人口動態の格差を防ぐには、公正な機械学習モデルのトレーニングが不可欠です。モデルの公平性を向上させるための既存の手法では、データの前処理またはモデルトレーニングのいずれかを大幅に変更する必要があり、すでに複雑な可能性のある機械学習システムに採用するのが困難になっています。この問題は、バイレベル最適化のレンズを介して対処します。標準のトレーニングアルゴリズムを内部オプティマイザーとして維持しながら、内部問題に追加機能を装備するために外部オプティマイザーを組み込みます。モデルの公平性を向上させる目的でミニバッチサイズを適応的に選択します。 FairBatchと呼ばれるバッチ選択アルゴリズムは、この最適化を実装し、機会均等、オッズの均等化、人口統計学的パリティなどの卓越した公平性の尺度をサポートします。 FairBatchには、データの前処理やモデルのトレーニングを変更する必要がないという、実装上の大きなメリットがあります。たとえば、FairBatchを使用するには、モデルトレーニングのバッチ選択部分を置き換えるためのPyTorchコードの1行の変更で十分です。合成データとベンチマーク実データの両方で実施さ​​れた実験は、FairBatchがそのような機能を提供しながら、最先端のパフォーマンスと同等（またはそれ以上）のパフォーマンスを達成できることを示しています。さらに、FairBatchは、微調整するだけで、事前にトレーニングされたモデルの公平性を容易に向上させることができます。また、収束の高速化など、さまざまな目的を目的とした既存のバッチ選択手法とも互換性があるため、複数の目的を適切に実現できます。,5.75,https://d3i71xaburhd42.cloudfront.net/ea1d92032fc33028dd1cb2d1cc96b89cb0d96d27/2-Figure1-1.png
CPR: Classifier-Projection Regularization for Continual Learning,"['Sungmin Cha', 'Hsiang Hsu', 'Taebaek Hwang', 'Flavio Calmon', 'Taesup Moon']",https://openreview.net/forum?id=F2v4aqEL6ze,"We propose a general, yet simple patch that can be applied to existing regularization-based continual learning methods called classifier-projection regularization (CPR). Inspired by both recent results on neural networks with wide local minima and information theory, CPR adds an additional regularization term that maximizes the entropy of a classifier's output probability. We demonstrate that this additional term can be interpreted as a projection of the conditional probability given by a classifier's output to the uniform distribution. By applying the Pythagorean theorem for KL divergence, we then prove that this projection may (in theory) improve the performance of continual learning methods. In our extensive experimental results, we apply CPR to several state-of-the-art regularization-based continual learning methods and benchmark performance on popular image recognition datasets. Our results demonstrate that CPR indeed promotes a wide local minima and significantly improves both accuracy and plasticity while simultaneously mitigating the catastrophic forgetting of baseline continual learning methods.  ",分類器-射影正則化（CPR）と呼ばれる、既存の正則化ベースの継続的な学習方法に適用できる、一般的でありながら単純なパッチを提案します。広い極小値を持つニューラルネットワークに関する最近の結果と情報理論の両方に触発されて、CPRは、分類器の出力確率のエントロピーを最大化する追加の正則化項を追加します。この追加の項は、一様分布に出力される分類器によって与えられる条件付き確率の予測として解釈できることを示します。 KL発散にピタゴラス定理を適用することにより、この予測が（理論的には）継続的な学習方法のパフォーマンスを改善する可能性があることを証明します。広範な実験結果では、CPRをいくつかの最先端の正則化ベースの継続的な学習方法に適用し、人気のある画像認識データセットのパフォーマンスをベンチマークします。私たちの結果は、CPRが実際に広い極小値を促進し、精度と可塑性の両方を大幅に改善すると同時に、ベースラインの継続的な学習方法の壊滅的な忘却を軽減することを示しています。,5.75,https://d3i71xaburhd42.cloudfront.net/b1b7d597a9b6032a0e2013d5a75cb101b7d6e39c/2-Figure1-1.png
Shape or Texture: Understanding Discriminative Features in CNNs,"['Md Amirul Islam', 'Matthew Kowal', 'Patrick Esser', 'Sen Jia', 'Björn Ommer', 'Konstantinos G. Derpanis', 'Neil Bruce']",https://openreview.net/forum?id=NcFEZOi-rLa,"Contrasting the previous evidence that neurons in the later layers of a Convolutional Neural Network (CNN) respond to complex object shapes, recent studies have shown that CNNs actually exhibit a 'texture bias': given an image with both texture and shape cues (e.g., a stylized image), a CNN is biased towards predicting the category corresponding to the texture. However, these previous studies conduct experiments on the final classification output of the network, and fail to robustly evaluate the bias contained (i) in the latent representations, and (ii) on a per-pixel level. In this paper, we design a series of experiments that overcome these issues. We do this with the goal of better understanding what type of shape information contained in the network is discriminative, where shape information is encoded, as well as when the network learns about object shape during training. We show that a network learns the majority of overall shape information at the first few epochs of training and that this information is largely encoded in the last few layers of a CNN. Finally, we show that the encoding of shape does not imply the encoding of localized per-pixel semantic information. The experimental results and findings provide a more accurate understanding of the behaviour of current CNNs, thus helping to inform future design choices.",畳み込みニューラルネットワーク（CNN）の後の層のニューロンが複雑なオブジェクトの形状に応答するという以前の証拠とは対照的に、最近の研究では、CNNが実際にテクスチャの偏りを示すことが示されています。画像）、CNNは、テクスチャに対応するカテゴリの予測に偏っています。ただし、これらの以前の研究は、ネットワークの最終的な分類出力で実験を行っており、（i）潜在的な表現、および（ii）ピクセルごとのレベルに含まれるバイアスを確実に評価できません。この論文では、これらの問題を克服する一連の実験を設計します。これは、ネットワークに含まれるどのタイプの形状情報が識別可能であるか、形状情報がエンコードされる場所、およびネットワークがトレーニング中にオブジェクトの形状について学習するタイミングをよりよく理解することを目的としています。ネットワークがトレーニングの最初の数エポックで全体的な形状情報の大部分を学習し、この情報がCNNの最後の数層で大部分がエンコードされていることを示します。最後に、形状のエンコードは、ローカライズされたピクセルごとのセマンティック情報のエンコードを意味しないことを示します。実験結果と調査結果は、現在のCNNの動作をより正確に理解するのに役立ち、将来の設計の選択に情報を提供するのに役立ちます。,5.75,https://d3i71xaburhd42.cloudfront.net/fa3d0599f8a082add349b5b09a208136489dae34/2-Figure1-1.png
Extracting Strong Policies for Robotics Tasks from zero-order trajectory optimizers,"['Cristina Pinneri', 'Shambhuraj Sawant', 'Sebastian Blaes', 'Georg Martius']",https://openreview.net/forum?id=Nc3TJqbcl3,"Solving high-dimensional, continuous robotic tasks is a challenging optimization problem. Model-based methods that rely on zero-order optimizers like the cross-entropy method (CEM) have so far shown strong performance and are considered state-of-the-art in the model-based reinforcement learning community. However, this success comes at the cost of high computational complexity, being therefore not suitable for real-time control. In this paper, we propose a technique to jointly optimize the trajectory and distill a policy, which is essential for fast execution in real robotic systems. Our method builds upon standard approaches, like guidance cost and dataset aggregation, and introduces a novel adaptive factor which prevents the optimizer from collapsing to the learner's behavior at the beginning of the training. The extracted policies reach unprecedented performance on challenging tasks as making a humanoid stand up and opening a door without reward shaping",高次元の連続的なロボットタスクを解決することは、困難な最適化問題です。クロスエントロピー法（CEM）のようなゼロ次オプティマイザーに依存するモデルベースの方法は、これまでのところ強力なパフォーマンスを示しており、モデルベースの強化学習コミュニティでは最先端と見なされています。ただし、この成功は計算の複雑さを犠牲にしてもたらされるため、リアルタイム制御には適していません。本論文では、軌道を共同で最適化し、実際のロボットシステムでの高速実行に不可欠なポリシーを抽出する手法を提案します。私たちの方法は、ガイダンスコストやデータセットの集計などの標準的なアプローチに基づいて構築されており、トレーニングの開始時にオプティマイザが学習者の行動に崩壊するのを防ぐ新しい適応要素を導入しています。抽出されたポリシーは、ヒューマノイドを立ち上げ、報酬を形成せずにドアを開けるなど、困難なタスクで前例のないパフォーマンスを達成します,5.75,
Learning explanations that are hard to vary,"['Giambattista Parascandolo', 'Alexander Neitz', 'ANTONIO ORVIETO', 'Luigi Gresele', 'Bernhard Schölkopf']",https://openreview.net/forum?id=hb1sDDSLbV,"In this paper, we investigate the principle that good explanations are hard to vary in the context of deep learning.
We show that averaging gradients across examples -- akin to a logical OR of patterns -- can favor memorization and `patchwork' solutions that sew together different strategies, instead of identifying invariances.
To inspect this, we first formalize a notion of consistency for minima of the loss surface, which measures to what extent a minimum appears only when examples are pooled.
We then propose and experimentally validate a simple alternative algorithm based on a logical AND, that focuses on invariances and prevents memorization in a set of real-world tasks. 
Finally, using a synthetic dataset with a clear distinction between invariant and spurious mechanisms, we dissect learning signals and compare this approach to well-established regularizers.",この論文では、ディープラーニングのコンテキストで適切な説明を変更するのは難しいという原則を調査します。パターンの論理ORに類似した例全体の勾配を平均化すると、不変性を特定するのではなく、異なる戦略を組み合わせた暗記およびパッチワークソリューションに有利に働く可能性があることを示します。これを調べるために、まず、損失面の最小値の一貫性の概念を形式化します。これは、例がプールされた場合にのみ最小値がどの程度現れるかを測定します。次に、論理積に基づく単純な代替アルゴリズムを提案し、実験的に検証します。これは、不変性に焦点を当て、一連の実世界のタスクでの記憶を防ぎます。最後に、不変メカニズムとスプリアスメカニズムを明確に区別する合成データセットを使用して、学習信号を分析し、このアプローチを確立されたレギュラライザーと比較します。,5.75,
Unsupervised Discovery of 3D Physical Objects,"['Yilun Du', 'Kevin A. Smith', 'Tomer Ullman', 'Joshua B. Tenenbaum', 'Jiajun Wu']",https://openreview.net/forum?id=lf7st0bJIA5,"We study the problem of unsupervised physical object discovery. Unlike existing frameworks that aim to learn to decompose scenes into 2D segments purely based on each object's appearance, we explore how physics, especially object interactions, facilitates learning to disentangle and segment instances from raw videos, and to infer the 3D geometry and position of each object, all without supervision. Drawing inspiration from developmental psychology, our Physical Object Discovery Network (POD-Net) uses both multi-scale pixel cues and physical motion cues to accurately segment observable and partially occluded objects of varying sizes, and infer properties of those objects. Our model reliably segments objects on both synthetic and real scenes. The discovered object properties can also be used to reason about physical events.",教師なし物体発見の問題を研究します。純粋に各オブジェクトの外観に基づいてシーンを2Dセグメントに分解することを目的とする既存のフレームワークとは異なり、物理学、特にオブジェクトの相互作用が、生のビデオからインスタンスを解きほぐしてセグメント化し、それぞれの3Dジオメトリと位置を推測する方法を学習します。オブジェクト、すべて監督なし。発達心理学からインスピレーションを得て、私たちの物理オブジェクト発見ネットワーク（POD-Net）は、マルチスケールピクセルキューと物理モーションキューの両方を使用して、さまざまなサイズの観察可能で部分的に遮蔽されたオブジェクトを正確にセグメント化し、それらのオブジェクトのプロパティを推測します。私たちのモデルは、合成シーンと実際のシーンの両方でオブジェクトを確実にセグメント化します。検出されたオブジェクトのプロパティは、物理的なイベントについて推論するためにも使用できます。,5.75,
Learning N:M  Fine-grained Structured Sparse Neural Networks From Scratch,"['Aojun Zhou', 'Yukun Ma', 'Junnan Zhu', 'Jianbo Liu', 'Zhijie Zhang', 'Kun Yuan', 'Wenxiu Sun', 'Hongsheng Li']",https://openreview.net/forum?id=K9bw7vqp_s,"Sparsity in Deep Neural Networks (DNNs) has been widely studied to compress and accelerate the models on resource-constrained environments. It can be generally categorized into unstructured fine-grained sparsity that zeroes out multiple individual weights distributed across the neural network, and structured coarse-grained sparsity which prunes blocks of sub-networks of a neural network. Fine-grained sparsity can achieve a high compression ratio but is not hardware friendly and hence receives limited speed gains. On the other hand, coarse-grained sparsity cannot simultaneously achieve both apparent acceleration on modern GPUs and
decent performance. In this paper, we are the first to study training from scratch an N:M fine-grained structured sparse network, which can maintain the advantages of both unstructured fine-grained sparsity and structured coarse-grained sparsity simultaneously on specifically designed GPUs. Specifically, a 2 : 4 sparse network could achieve 2× speed-up without performance drop on Nvidia A100 GPUs. Furthermore, we propose a novel and effective ingredient, sparse-refined straight-through estimator (SR-STE), to alleviate the negative influence of the approximated gradients computed by vanilla STE during optimization. We also define a metric, Sparse Architecture Divergence (SAD), to measure the sparse network’s topology change during the training process. Finally, We justify SR-STE’s advantages with SAD and demonstrate the effectiveness of SR-STE by performing
comprehensive experiments on various tasks. Anonymous code and model will be at available at https://github.com/anonymous-NM-sparsity/NM-sparsity.",ディープニューラルネットワーク（DNN）のスパース性は、リソースに制約のある環境でモデルを圧縮および高速化するために広く研究されてきました。これは一般に、ニューラルネットワーク全体に分散された複数の個別の重みをゼロにする非構造化細粒度スパース性と、ニューラルネットワークのサブネットワークのブロックを削除する構造化粗粒度スパース性に分類できます。きめの細かいスパース性は高い圧縮率を実現できますが、ハードウェアに対応していないため、速度の向上は制限されます。一方、粗粒度のスパース性は、最新のGPUでの見かけの加速と適切なパフォーマンスの両方を同時に達成することはできません。このホワイトペーパーでは、特別に設計されたGPUで、非構造化細粒度スパース性と構造化粗視化スパース性の両方の利点を同時に維持できるN：M細粒度構造化スパースネットワークのトレーニングを最初から研究しました。具体的には、2：4のスパースネットワークは、Nvidia A100GPUのパフォーマンスを低下させることなく2つのスピードアップを実現できます。さらに、最適化中にバニラSTEによって計算された近似勾配の悪影響を軽減するために、新規で効果的な成分であるスパース洗練されたストレートスルー推定器（SR-STE）を提案します。また、トレーニングプロセス中のスパースネットワークトポロジの変化を測定するためのメトリック、スパースアーキテクチャダイバージェンス（SAD）を定義します。最後に、SADでSR-STEの利点を正当化し、さまざまなタスクで包括的な実験を実行することにより、SR-STEの有効性を示します。匿名のコードとモデルは、https：//github.com/anonymous-NM-sparsity/NM-sparsityで入手できます。,5.75,
Sample-Efficient Automated Deep Reinforcement Learning,"['Jörg K.H. Franke', 'Gregor Koehler', 'André Biedenkapp', 'Frank Hutter']",https://openreview.net/forum?id=hSjxQ3B7GWq,"Despite significant progress in challenging problems across various domains, applying state-of-the-art deep reinforcement learning (RL) algorithms remains challenging due to their sensitivity to the choice of hyperparameters. This sensitivity can partly be attributed to the non-stationarity of the RL problem, potentially requiring different hyperparameter settings at various stages of the learning process. Additionally, in the RL setting, hyperparameter optimization (HPO) requires a large number of environment interactions, hindering the transfer of the successes in RL to real-world applications. In this work, we tackle the issues of sample-efficient and dynamic HPO in RL. We propose a population-based automated RL (AutoRL) framework to meta-optimize arbitrary off-policy RL algorithms. In this framework, we optimize the hyperparameters and also the neural architecture while simultaneously training the agent. By sharing the collected experience across the population, we substantially increase the sample efficiency of the meta-optimization. We demonstrate the capabilities of our sample-efficient AutoRL approach in a case study with the popular TD3 algorithm in the MuJoCo benchmark suite, where we reduce the number of environment interactions needed for meta-optimization by up to an order of magnitude compared to population-based training.",さまざまなドメインにわたる問題への挑戦が大幅に進歩したにもかかわらず、ハイパーパラメータの選択に敏感であるため、最先端の深層強化学習（RL）アルゴリズムの適用は依然として挑戦的です。この感度は、RL問題の非定常性に部分的に起因する可能性があり、学習プロセスのさまざまな段階で異なるハイパーパラメータ設定が必要になる可能性があります。さらに、RL設定では、ハイパーパラメータ最適化（HPO）は多数の環境の相互作用を必要とし、RLでの成功を実際のアプリケーションに転送することを妨げます。この作業では、RLでのサンプル効率の高い動的HPOの問題に取り組みます。任意のオフポリシーRLアルゴリズムをメタ最適化するために、母集団ベースの自動RL（AutoRL）フレームワークを提案します。このフレームワークでは、エージェントを同時にトレーニングしながら、ハイパーパラメータとニューラルアーキテクチャを最適化します。収集した経験を母集団全体で共有することにより、メタ最適化のサンプル効率を大幅に向上させます。 MuJoCoベンチマークスイートで人気のあるTD3アルゴリズムを使用したケーススタディで、サンプル効率の高いAutoRLアプローチの機能を示します。ここでは、メタ最適化に必要な環境の相互作用の数を、人口と比較して最大1桁削減します。ベースのトレーニング。,5.75,
On the Transfer of Disentangled Representations in Realistic Settings,"['Andrea Dittadi', 'Frederik Träuble', 'Francesco Locatello', 'Manuel Wuthrich', 'Vaibhav Agrawal', 'Ole Winther', 'Stefan Bauer', 'Bernhard Schölkopf']",https://openreview.net/forum?id=8VXvj1QNRl1,"Learning meaningful representations that disentangle the underlying structure of the data generating process is considered to be of key importance in machine learning. While disentangled representations were found to be useful for diverse tasks such as abstract reasoning and fair classification, their scalability and real-world impact remain questionable.
We introduce a new high-resolution dataset with over 1M simulated images and 1k annotated real-world images of the same setup. In contrast to previous work, this new dataset exhibits correlations, a complex underlying structure, and allows to evaluate transfer to unseen simulated and real-world settings where the encoder i) remains in distribution or ii) is out of distribution. 
We propose new architectures in order to scale disentangled representation learning to realistic high-resolution settings and conduct a large-scale empirical study of disentangled representations on this dataset. We observe that disentanglement is a good predictor for out-of-distribution (OOD) task performance.",データ生成プロセスの基礎となる構造を解きほぐす意味のある表現を学習することは、機械学習において非常に重要であると考えられています。解きほぐされた表現は、抽象的な推論や公正な分類などのさまざまなタスクに役立つことがわかっていますが、そのスケーラビリティと実際の影響には疑問が残ります。同じセットアップの100万を超えるシミュレーション画像と1kの注釈付き実世界画像を含む新しい高解像度データセットを紹介します。以前の作業とは対照的に、この新しいデータセットは、相関関係、複雑な基礎構造を示し、エンコーダーがi）分布したままであるか、ii）分布していない、目に見えないシミュレーションおよび実世界の設定への転送を評価できます。解きほぐされた表現学習を現実的な高解像度設定にスケーリングし、このデータセットで解きほぐされた表現の大規模な実証的研究を実施するために、新しいアーキテクチャを提案します。解きほぐしは、アウトオブディストリビューション（OOD）タスクのパフォーマンスの優れた予測因子であることがわかります。,5.75,https://d3i71xaburhd42.cloudfront.net/f6bc1287138834e13fb587650df2605ae0e9c708/2-Figure1-1.png
Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks,"['Ingmar Schubert', 'Ozgur S Oguz', 'Marc Toussaint']",https://openreview.net/forum?id=w2Z2OwVNeK,"In high-dimensional state spaces, the usefulness of Reinforcement Learning (RL) is limited by the problem of exploration. This issue has been addressed using potential-based reward shaping (PB-RS) previously. In the present work, we introduce Final-Volume-Preserving Reward Shaping (FV-RS). FV-RS relaxes the strict optimality guarantees of PB-RS to a guarantee of preserved long-term behavior. Being less restrictive, FV-RS allows for reward shaping functions that are even better suited for improving the sample efficiency of RL algorithms. In particular, we consider settings in which the agent has access to an approximate plan. Here, we use examples of simulated robotic manipulation tasks to demonstrate that plan-based FV-RS can indeed significantly improve the sample efficiency of RL over plan-based PB-RS.",高次元の状態空間では、強化学習（RL）の有用性は探索の問題によって制限されます。この問題は、以前はポテンシャルベースの報酬シェーピング（PB-RS）を使用して対処されていました。本研究では、最終ボリューム保存報酬整形（FV-RS）を紹介します。 FV-RSは、PB-RSの厳密な最適性の保証を緩和して、長期的な動作の維持を保証します。 FV-RSは制限が少ないため、RLアルゴリズムのサンプル効率を改善するのにさらに適した報酬整形関数を使用できます。特に、エージェントがおおよそのプランにアクセスできる設定を検討します。ここでは、シミュレートされたロボット操作タスクの例を使用して、計画ベースのFV-RSが計画ベースのPB-RSよりもRLのサンプル効率を実際に大幅に改善できることを示します。,5.75,
Learning to Deceive Knowledge Graph Augmented Models via Targeted Perturbation,"['Mrigank Raman', 'Hansen Wang', 'PeiFeng Wang', 'Siddhant Agarwal', 'Sungchul Kim', 'Ryan Rossi', 'Handong Zhao', 'Nedim Lipka', 'Xiang Ren']",https://openreview.net/forum?id=b7g3_ZMHnT0,"Knowledge graphs (KGs) have helped neural-symbolic models improve performance on various knowledge-intensive tasks, like question answering and item recommendation. By using attention over the KG, such models can also ""explain"" which KG information was most relevant for making a given prediction. In this paper, we question whether these models are really behaving as we expect. We demonstrate that, through a reinforcement learning policy (or even simple heuristics), one can produce deceptively perturbed KGs which maintain the downstream performance of the original KG while significantly deviating from the original semantics and structure. Our findings raise doubts about KG-augmented models' ability to leverage KG information and provide plausible explanations.",ナレッジグラフ（KG）は、ニューラルシンボリックモデルが、質問応答やアイテムの推奨など、知識を大量に消費するさまざまなタスクのパフォーマンスを向上させるのに役立ちました。 KGに注意を払うことにより、そのようなモデルは、どのKG情報が特定の予測を行うのに最も関連していたかを「説明」することもできます。このホワイトペーパーでは、これらのモデルが実際に期待どおりに動作しているかどうかを確認します。強化学習ポリシー（または単純なヒューリスティック）を通じて、元のセマンティクスと構造から大幅に逸脱しながら、元のKGのダウンストリームパフォーマンスを維持する一見摂動されたKGを生成できることを示します。私たちの調査結果は、KG情報を活用し、もっともらしい説明を提供するKG拡張モデルの能力について疑問を投げかけています。,5.75,https://d3i71xaburhd42.cloudfront.net/a5654d5244b908a08936fcb7c13c03124dd5648e/3-Figure1-1.png
Graph Edit Networks,"['Benjamin Paassen', 'Daniele Grattarola', 'Daniele Zambon', 'Cesare Alippi', 'Barbara Eva Hammer']",https://openreview.net/forum?id=dlEJsyHGeaL,"While graph neural networks have made impressive progress in classification and regression on graphs, few approaches to date perform time series prediction on graphs and those that do are mostly limited to edge changes. We suggest that graph edits are a more natural interface for graph-to-graph learning. In particular,  graph edits are general enough to describe any graph-to-graph change, not only edge changes, they are sparse, making them easier to understand for humans and more efficient computationally, and they are local, avoiding the need for pooling layers in graph neural networks. In this paper, we propose a simple linear layer - the graph edit network - which takes node embeddings as input and generates a sequence of graph edits that transform the input graph to the output graph. Theoretically, we show that a mapping between the node sets of two graphs is sufficient to construct training data for a graph edit network and that an optimal mapping yields edit scripts that are almost as short as the graph edit distance between the graphs. We further provide a proof-of-concept empirical evaluation on several graph dynamical systems, which are difficult to learn for baselines from the literature.",グラフニューラルネットワークはグラフの分類と回帰において目覚ましい進歩を遂げましたが、これまでのところ、グラフの時系列予測を実行するアプローチはほとんどなく、ほとんどの場合、エッジの変更に限定されています。グラフの編集は、グラフ間の学習のためのより自然なインターフェースであることをお勧めします。特に、グラフの編集は、エッジの変更だけでなく、グラフ間の変更を記述するのに十分一般的であり、それらはまばらであり、人間にとって理解しやすく、計算効率が高く、ローカルであるため、レイヤーをプールする必要がありません。グラフニューラルネットワークで。この論文では、ノードの埋め込みを入力として受け取り、入力グラフを出力グラフに変換する一連のグラフ編集を生成する単純な線形レイヤー（グラフ編集ネットワーク）を提案します。理論的には、2つのグラフのノードセット間のマッピングは、グラフ編集ネットワークのトレーニングデータを構築するのに十分であり、最適なマッピングにより、グラフ間のグラフ編集距離とほぼ同じくらい短い編集スクリプトが生成されることを示します。さらに、文献からベースラインを学習するのが難しいいくつかのグラフ動的システムに関する概念実証の経験的評価を提供します。,5.75,
Conditional Negative Sampling for Contrastive Learning of Visual Representations,"['Mike Wu', 'Milan Mosse', 'Chengxu Zhuang', 'Daniel Yamins', 'Noah Goodman']",https://openreview.net/forum?id=v8b3e5jN66j,"Recent methods for learning unsupervised visual representations, dubbed contrastive learning, optimize the noise-contrastive estimation (NCE) bound on mutual information between two transformations of an image. NCE typically uses randomly sampled negative examples to normalize the objective, but this may often include many uninformative examples either because they are too easy or too hard to discriminate. Taking inspiration from  metric learning, we show that choosing semi-hard negatives can yield stronger contrastive representations. To do this, we introduce a family of mutual information estimators that sample negatives conditionally -- in a ""ring""around each positive. We prove that these estimators remain lower-bounds of mutual information, with higher bias but lower variance than NCE. Experimentally, we find our approach, applied on top of existing models (IR, CMC, and MoCo) improves accuracy by 2-5% absolute points in each case, measured by linear evaluation on four standard image benchmarks. Moreover, we find continued benefits when transferring features to a variety of new image distributions from the Meta-Dataset collection and to a variety of downstream tasks such as object detection, instance segmentation, and key-point detection.",教師なし視覚表現を学習するための最近の方法である、吹き替え対照学習は、画像の2つの変換間の相互情報量にバインドされたノイズ対照推定（NCE）を最適化します。 NCEは通常、ランダムにサンプリングされたネガティブな例を使用して目的を正規化しますが、簡単すぎるか、区別するのが難しいため、多くの有益でない例が含まれる場合があります。メトリック学習からインスピレーションを得て、セミハードネガを選択すると、より強力な対照表現が得られることを示します。これを行うために、各ポジティブの周りの「リング」でネガを条件付きでサンプリングする相互情報量推定量のファミリーを紹介します。これらの推定量は、NCEよりもバイアスは高いが分散は低い、相互情報量の下限のままであることを証明します。実験的に、既存のモデル（IR、CMC、およびMoCo）に適用されたアプローチにより、精度が2〜5向上することがわかりました。,5.75,https://d3i71xaburhd42.cloudfront.net/3a1dea12746651884fa1c4349aa71327d789ae6b/4-Figure1-1.png
Constellation Nets for Few-Shot Learning,"['Weijian Xu', 'yifan xu', 'Huaijin Wang', 'Zhuowen Tu']",https://openreview.net/forum?id=vujTf_I8Kmc,"The success of deep convolutional neural networks builds on top of the learning of effective convolution operations, capturing a hierarchy of structured features via filtering, activation, and pooling. However, the explicit structured features, e.g. object parts, are not expressive in the existing CNN frameworks. In this paper, we tackle the few-shot learning problem and make an effort to enhance structured features by expanding CNNs with a constellation model, which performs cell feature clustering and encoding with a dense part representation; the relationships among the cell features are further modeled by an attention mechanism. With the additional constellation branch to increase the awareness of object parts, our method is able to attain the advantages of the CNNs while making the overall internal representations more robust in the few-shot learning setting. Our approach attains a significant improvement over the existing methods in few-shot learning on the CIFAR-FS, FC100, and mini-ImageNet benchmarks.",深い畳み込みニューラルネットワークの成功は、効果的な畳み込み演算の学習に基づいて構築され、フィルタリング、アクティブ化、およびプーリングを介して構造化された機能の階層をキャプチャします。ただし、オブジェクトパーツなどの明示的な構造化機能は、既存のCNNフレームワークでは表現力がありません。この論文では、数ショットの学習問題に取り組み、CNNをコンステレーションモデルで拡張することにより、構造化された特徴を強化するよう努めます。コンステレーションモデルは、密な部分表現でセル特徴のクラスタリングとエンコードを実行します。セルの特徴間の関係は、注意メカニズムによってさらにモデル化されます。オブジェクトパーツの認識を高めるための追加のコンステレーションブランチを使用すると、この方法では、数ショットの学習設定で全体的な内部表現をより堅牢にしながら、CNNの利点を実現できます。私たちのアプローチは、CIFAR-FS、FC100、およびmini-ImageNetベンチマークでの数ショット学習において、既存の方法を大幅に改善します。,5.75,
Reinforcement Learning with Random Delays,"['Yann Bouteiller', 'Simon Ramstedt', 'Giovanni Beltrame', 'Christopher Pal', 'Jonathan Binas']",https://openreview.net/forum?id=QFYnKlBJYR,"Action and observation delays commonly occur in many Reinforcement Learning applications, such as remote control scenarios. We study the anatomy of randomly delayed environments, and show that partially resampling trajectory fragments in hindsight allows for off-policy multi-step value estimation. We apply this principle to derive Delay-Correcting Actor-Critic (DCAC), an algorithm based on Soft Actor-Critic with significantly better performance in environments with delays. This is shown theoretically and also demonstrated practically on a delay-augmented version of the MuJoCo continuous control benchmark.",アクションと観察の遅延は、リモートコントロールシナリオなどの多くの強化学習アプリケーションで一般的に発生します。ランダムに遅延した環境の構造を研究し、後知恵で軌道フラグメントを部分的にリサンプリングすることで、ポリシー外のマルチステップ値の推定が可能になることを示します。この原則を適用して、遅延修正アクタークリティカル（DCAC）を導出します。これは、遅延のある環境でパフォーマンスが大幅に向上するソフトアクタークリティカルに基づくアルゴリズムです。これは理論的に示され、MuJoCo連続制御ベンチマークの遅延拡張バージョンでも実際に示されています。,5.75,
Individually Fair Rankings,"['Amanda Bower', 'Hamid Eftekhari', 'Mikhail Yurochkin', 'Yuekai Sun']",https://openreview.net/forum?id=71zCSP_HuBN,We develop an algorithm to train individually fair learning-to-rank (LTR) models. The proposed approach ensures items from minority groups appear alongside similar items from majority groups. This notion of fair ranking is based on the definition of individual fairness from supervised learning and is more nuanced than prior fair LTR approaches that simply ensure the ranking model provides underrepresented items with a basic level of exposure. The crux of our method is an optimal transport-based regularizer that enforces individual fairness and an efficient algorithm for optimizing the regularizer. We show that our approach leads to certifiably individually fair LTR models and demonstrate the efficacy of our method on ranking tasks subject to demographic biases.,個別に公正なランク学習（LTR）モデルをトレーニングするアルゴリズムを開発します。提案されたアプローチにより、マイノリティグループのアイテムがマジョリティグループの同様のアイテムと一緒に表示されるようになります。この公正なランク付けの概念は、教師あり学習による個々の公平性の定義に基づいており、ランク付けモデルが過小評価されたアイテムに基本的なレベルの露出を提供することを保証する以前の公正なLTRアプローチよりも微妙な違いがあります。私たちの方法の核心は、個々の公平性を強制する最適なトランスポートベースの正則化と、正則化を最適化するための効率的なアルゴリズムです。私たちのアプローチが確実に個別に公正なLTRモデルにつながることを示し、人口統計学的バイアスの影響を受けるタスクのランク付けに対する私たちの方法の有効性を示します。,5.75,
Repurposing Pretrained Models for Robust Out-of-domain Few-Shot Learning,"['Namyeong Kwon', 'Hwidong Na', 'Gabriel Huang', 'Simon Lacoste-Julien']",https://openreview.net/forum?id=qkLMTphG5-h,"Model-agnostic meta-learning (MAML) is a popular method for few-shot learning but assumes that we have access to the meta-training set. In practice, training on the meta-training set may not always be an option due to data privacy concerns, intellectual property issues, or merely lack of computing resources. In this paper, we consider the novel problem of repurposing pretrained MAML checkpoints to solve new few-shot classification tasks. Because of the potential distribution mismatch, the original MAML steps may no longer be optimal. Therefore we propose an alternative meta-testing procedure and combine MAML gradient steps with adversarial training and uncertainty-based stepsize adaptation. Our method outperforms ""vanilla"" MAML on same-domain and cross-domains benchmarks using both SGD and Adam optimizers and shows improved robustness to the choice of base stepsize.",モデルにとらわれないメタ学習（MAML）は、数ショット学習の一般的な方法ですが、メタトレーニングセットにアクセスできることを前提としています。実際には、データプライバシーの懸念、知的財産の問題、または単にコンピューティングリソースの不足のために、メタトレーニングセットでのトレーニングが常にオプションであるとは限りません。この論文では、新しい数ショットの分類タスクを解決するために、事前にトレーニングされたMAMLチェックポイントを転用するという新しい問題について考察します。分布の不一致が発生する可能性があるため、元のMAMLステップが最適でなくなる可能性があります。したがって、代替のメタテスト手順を提案し、MAML勾配ステップを敵対的トレーニングおよび不確実性ベースのステップサイズ適応と組み合わせます。私たちの方法は、SGDオプティマイザーとAdamオプティマイザーの両方を使用して、同じドメインおよびクロスドメインのベンチマークで「バニラ」MAMLを上回り、基本ステップサイズの選択に対する堅牢性が向上していることを示しています。,5.75,
PolarNet: Learning to Optimize Polar Keypoints for Keypoint Based Object Detection,"['Wu Xiongwei', 'Steven HOI', 'Doyen Sahoo']",https://openreview.net/forum?id=TYXs_y84xRj,"A variety of anchor-free object detectors have been actively proposed as possible alternatives to the mainstream anchor-based detectors that often rely on complicated design of anchor boxes. Despite achieving promising performance at par with anchor-based detectors, the existing anchor-free detectors such as FCOS or CenterNet predict objects based on standard Cartesian coordinates, which often yield poor quality keypoints. Further, the bounding box regression is also scale-sensitive. In this paper, we propose a new anchor-free keypoint based detector ``""PolarNet"", where keypoints are represented as a set of Polar coordinates instead of Cartesian coordinates. The ``PolarNet detector learns offsets pointing to the corners of objects in order to learn high quality keypoints. Additionally, PolarNet uses corner points to localize objects, making the localization scale-insensitive. Finally in our experiments, we show that PolarNet, an anchor-free detector, outperforms the existing anchor-free detectors, and is able to achieve highly competitive result on COCO test-dev benchmark ($48.0\%$ AP under the single-model single-scale testing) which is at par with the state-of-the-art two-stage anchor-based object detectors. ",アンカーボックスの複雑な設計に依存することが多い主流のアンカーベースの検出器の可能な代替手段として、さまざまなアンカーフリーオブジェクト検出器が積極的に提案されています。アンカーベースの検出器と同等の有望なパフォーマンスを達成しているにもかかわらず、FCOSやCenterNetなどの既存のアンカーフリー検出器は、標準のデカルト座標に基づいてオブジェクトを予測します。さらに、バウンディングボックス回帰もスケールに敏感です。この論文では、新しいアンカーフリーのキーポイントベースの検出器「PolarNet」を提案します。この検出器では、キーポイントがデカルト座標ではなく極座標のセットとして表されます。 PolarNet検出器は、高品質のキーポイントを学習するために、オブジェクトのコーナーを指すオフセットを学習します。さらに、PolarNetはコーナーポイントを使用してオブジェクトをローカライズするため、ローカリゼーションはスケールに依存しません。最後に、私たちの実験では、アンカーフリー検出器であるPolarNetが既存のアンカーフリー検出器よりも優れており、COCO test-devベンチマークで非常に競争力のある結果を達成できることを示しています（単一モデルの単一スケールで48.0％AP）テスト）これは、最先端の2ステージアンカーベースのオブジェクト検出器と同等です。,5.75,
Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear Time,"['Yu Cheng', 'Honghao Lin']",https://openreview.net/forum?id=euDnVs0Ynts,"We study the problem of learning Bayesian networks where an $\epsilon$-fraction of the samples are adversarially corrupted.  We focus on the fully-observable case where the underlying graph structure is known.  In this work, we present the first nearly-linear time algorithm for this problem with a dimension-independent error guarantee.  Previous robust algorithms with comparable error guarantees are slower by at least a factor of $(d/\epsilon)$, where $d$ is the number of variables in the Bayesian network and $\epsilon$ is the fraction of corrupted samples.

Our work establishes a direct connection between robust learning of Bayesian networks and robust mean estimation.
By exploiting this connection, our algorithm and analysis are considerably simpler than those in previous work.  As a subroutine in our algorithm, we develop a robust mean estimation algorithm whose runtime is nearly-linear in the number of nonzeros in the input, which may be of independent interest.",サンプルの一部が敵対的に破損しているベイジアンネットワークの学習の問題を研究します。基礎となるグラフ構造がわかっている、完全に観察可能なケースに焦点を当てます。この作業では、次元に依存しないエラー保証を備えた、この問題の最初のほぼ線形の時間アルゴリズムを示します。同等のエラー保証を備えた以前の堅牢なアルゴリズムは、少なくとも（d /）の係数で遅くなります。ここで、dはベイジアンネットワーク内の変数の数であり、破損したサンプルの割合です。私たちの仕事は、ベイジアンネットワークのロバストな学習とロバストな平均推定の間の直接的な関係を確立します。この接続を利用することにより、アルゴリズムと分析は以前の作業よりもかなり簡単になります。アルゴリズムのサブルーチンとして、入力内の非ゼロの数がほぼ線形であるロバストな平均推定アルゴリズムを開発します。これは、独立した関心事である可能性があります。,5.75,
MetaNorm: Learning to Normalize Few-Shot Batches Across Domains,"['Yingjun Du', 'Xiantong Zhen', 'Ling Shao', 'Cees G. M. Snoek']",https://openreview.net/forum?id=9z_dNsC4B5t,"Batch normalization plays a crucial role when training deep neural networks. However, batch statistics become unstable with small batch sizes and are unreliable in the presence of distribution shifts. We propose MetaNorm, a simple yet effective meta-learning normalization. It tackles the aforementioned issues in a unified way by leveraging the meta-learning setting and learns to infer adaptive statistics for batch normalization. MetaNorm is generic, flexible and model-agnostic, making it a simple plug-and-play module that is seamlessly embedded into existing meta-learning approaches. It can be efficiently implemented by lightweight hypernetworks with low computational cost. We verify its effectiveness by extensive evaluation on representative tasks suffering from the small batch and domain shift problems: few-shot learning and domain generalization. We further introduce an even more challenging setting: few-shot domain generalization. Results demonstrate that MetaNorm consistently achieves better, or at least competitive, accuracy compared to existing batch normalization methods.  ",バッチ正規化は、ディープニューラルネットワークをトレーニングするときに重要な役割を果たします。ただし、バッチ統計はバッチサイズが小さいと不安定になり、分布の変化があると信頼性が低くなります。シンプルでありながら効果的なメタ学習の正規化であるMetaNormを提案します。メタ学習設定を活用することにより、前述の問題に統一された方法で取り組み、バッチ正規化のための適応統計を推測することを学習します。 MetaNormは汎用的で柔軟性があり、モデルに依存しないため、既存のメタ学習アプローチにシームレスに組み込まれたシンプルなプラグアンドプレイモジュールになっています。計算コストの低い軽量ハイパーネットワークで効率的に実装できます。小さなバッチとドメインシフトの問題に悩まされている代表的なタスク（数ショットの学習とドメインの一般化）を広範囲に評価することで、その有効性を検証します。さらに、さらに難しい設定である、数ショットのドメインの一般化を紹介します。結果は、MetaNormが既存のバッチ正規化方法と比較して、一貫してより優れた、または少なくとも競争力のある精度を達成していることを示しています。,5.75,
QPLEX: Duplex Dueling Multi-Agent Q-Learning,"['Jianhao Wang', 'Zhizhou Ren', 'Terry Liu', 'Yang Yu', 'Chongjie Zhang']",https://openreview.net/forum?id=Rcmk0xxIQV,"We explore value-based multi-agent reinforcement learning (MARL) in the popular paradigm of centralized training with decentralized execution (CTDE). CTDE has an important concept, Individual-Global-Max (IGM) principle, which requires the consistency between joint and local action selections to support efficient local decision-making. However, in order to achieve scalability, existing MARL methods either limit representation expressiveness of their value function classes or relax the IGM consistency, which may suffer from instability risk or lead to poor performance. This paper presents a novel MARL approach, called duPLEX dueling multi-agent Q-learning (QPLEX), which takes a duplex dueling network architecture to factorize the joint value function. This duplex dueling structure encodes the IGM principle into the neural network architecture and thus enables efficient value function learning. Theoretical analysis shows that QPLEX achieves a complete IGM function class. Empirical experiments on StarCraft II micromanagement tasks demonstrate that QPLEX significantly outperforms state-of-the-art baselines in both online and offline data collection settings, and also reveal that QPLEX achieves high sample efficiency and can benefit from offline datasets without additional online exploration.",分散実行（CTDE）を使用した集中トレーニングの一般的なパラダイムで、価値ベースのマルチエージェント強化学習（MARL）を調査します。 CTDEには重要な概念であるIndividual-Global-Max（IGM）の原則があり、効率的なローカルの意思決定をサポートするために、共同アクションとローカルアクションの選択の一貫性が必要です。ただし、スケーラビリティを実現するために、既存のMARLメソッドは、値関数クラスの表現表現力を制限するか、IGMの一貫性を緩和します。これにより、不安定性のリスクが発生したり、パフォーマンスが低下したりする可能性があります。このホワイトペーパーでは、duPLEXデュエルマルチエージェントQラーニング（QPLEX）と呼ばれる新しいMARLアプローチを紹介します。これは、デュプレックスデュエルネットワークアーキテクチャを使用して、ジョイントバリュー関数を因数分解します。この二重決闘構造は、IGMの原理をニューラルネットワークアーキテクチャにエンコードするため、効率的な価値関数の学習が可能になります。理論的分析は、QPLEXが完全なIGM関数クラスを達成することを示しています。 StarCraft IIマイクロ管理タスクの経験的実験は、QPLEXがオンラインとオフラインの両方のデータ収集設定で最先端のベースラインを大幅に上回っていることを示しています。また、QPLEXが高いサンプル効率を達成し、追加のオンライン探索なしでオフラインデータセットから利益を得ることができることも明らかにしています。,5.75,https://d3i71xaburhd42.cloudfront.net/00b6b26f0b3593911fed8ec015e8f1ba518fea29/4-Figure1-1.png
Representation Learning for Sequence Data with Deep Autoencoding Predictive Components,"['Junwen Bai', 'Weiran Wang', 'Yingbo Zhou', 'Caiming Xiong']",https://openreview.net/forum?id=Naqw7EHIfrv,"We propose Deep Autoencoding Predictive Components (DAPC) --  a self-supervised representation learning method for sequence data, based on the intuition that useful representations of sequence data should exhibit a simple structure in the latent space. We encourage this latent structure by maximizing an estimate of \emph{predictive information} of latent feature sequences, which is the mutual information between past and future windows at each time step. In contrast to the mutual information lower bound commonly used by contrastive learning, the estimate of predictive information we adopt is exact under a Gaussian assumption. Additionally, it can be computed without negative sampling. To reduce the degeneracy of the latent space extracted by powerful encoders and keep useful information from the inputs, we regularize predictive information learning with a challenging masked reconstruction loss. We demonstrate that our method recovers the latent space of noisy dynamical systems, extracts predictive features for forecasting tasks, and improves automatic speech recognition when used to pretrain the encoder on large amounts of unlabeled data.",シーケンスデータの有用な表現は潜在空間で単純な構造を示すべきであるという直感に基づいて、シーケンスデータの自己教師あり表現学習方法であるDeep Autoencoding Predictive Components（DAPC）を提案します。各タイムステップでの過去と未来のウィンドウ間の相互情報量である潜在的特徴シーケンスの予測情報の推定を最大化することにより、この潜在的構造を奨励します。対照学習で一般的に使用される相互情報量の下限とは対照的に、私たちが採用する予測情報の推定は、ガウスの仮定の下で正確です。さらに、負のサンプリングなしで計算できます。強力なエンコーダーによって抽出された潜在空間の縮退を減らし、入力からの有用な情報を保持するために、困難なマスクされた再構成損失を使用して予測情報学習を正規化します。私たちの方法は、ノイズの多い動的システムの潜在空間を回復し、予測タスクの予測機能を抽出し、ラベルのない大量のデータでエンコーダーを事前トレーニングするために使用すると、自動音声認識を改善することを示します。,5.75,https://d3i71xaburhd42.cloudfront.net/eab66826ca3e58b19289844be7a3ccb6c978192d/2-Figure1-1.png
DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues,"['Rishabh Joshi', 'Vidhisha Balachandran', 'Shikhar Vashishth', 'Alan Black', 'Yulia Tsvetkov']",https://openreview.net/forum?id=kDnal_bbb-E,"To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DialoGraph, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DialoGraph explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context. Our graph-based method outperforms prior state-of-the-art negotiation models both in the accuracy of strategy/dialogue act prediction and in the quality of downstream dialogue response generation. We qualitatively show further benefits of learned strategy-graphs in providing explicit associations between effective negotiation strategies over the course of the dialogue, leading to interpretable and strategic dialogues.",取引の交渉を成功させるには、流暢にコミュニケーションをとるだけでは不十分です。説得力のある交渉戦略の実用的な計画が不可欠です。現代の対話エージェントは流暢な文章の生成に優れていますが、それでも実用的な根拠がなく、戦略的に推論することはできません。グラフニューラルネットワークを使用した交渉対話に語用論的戦略を組み込んだ交渉システムであるDialoGraphを紹介します。 DialoGraphは、戦略のシーケンス間の依存関係を明示的に組み込んで、対話のコンテキストが与えられた場合に、次の最適な戦略の改善された解釈可能な予測を可能にします。私たちのグラフベースの方法は、戦略/対話行為の予測の精度と下流の対話応答生成の品質の両方で、以前の最先端の交渉モデルよりも優れています。私たちは、対話の過程で効果的な交渉戦略間の明確な関連性を提供し、解釈可能で戦略的な対話につながるという点で、学習した戦略グラフのさらなる利点を定性的に示します。,5.75,
Adaptive Procedural Task Generation for Hard-Exploration Problems,"['Kuan Fang', 'Yuke Zhu', 'Silvio Savarese', 'Fei-Fei Li']",https://openreview.net/forum?id=8xLkv08d70T,"We introduce Adaptive Procedural Task Generation (APT-Gen), an approach to progressively generate a sequence of tasks as curricula to facilitate reinforcement learning in hard-exploration problems. At the heart of our approach, a task generator learns to create tasks from a parameterized task space via a black-box procedural generation module. To enable curriculum learning in the absence of a direct indicator of learning progress, we propose to train the task generator by balancing the agent's performance in the generated tasks and the similarity to the target tasks. Through adversarial training, the task similarity is adaptively estimated by a task discriminator defined on the agent's experiences, allowing the generated tasks to approximate target tasks of unknown parameterization or outside of the predefined task space. Our experiments on grid world and robotic manipulation task domains show that APT-Gen achieves substantially better performance than various existing baselines by generating suitable tasks of rich variations.",適応型手続き型タスク生成（APT-Gen）を紹介します。これは、一連のタスクをカリキュラムとして段階的に生成し、困難な探索の問題における強化学習を促進するアプローチです。私たちのアプローチの中心にあるタスクジェネレーターは、ブラックボックスの手続き型生成モジュールを介して、パラメーター化されたタスクスペースからタスクを作成することを学習します。学習の進捗状況を直接示す指標がない場合にカリキュラム学習を可能にするために、生成されたタスクのエージェントのパフォーマンスとターゲットタスクとの類似性のバランスをとることにより、タスクジェネレーターをトレーニングすることを提案します。敵対的トレーニングを通じて、タスクの類似性は、エージェントの経験に基づいて定義されたタスク弁別子によって適応的に推定され、生成されたタスクが未知のパラメーター化のターゲットタスクまたは事前定義されたタスクスペースの外側に近似できるようにします。グリッドワールドとロボット操作タスクドメインに関する私たちの実験は、APT-Genが豊富なバリエーションの適切なタスクを生成することにより、さまざまな既存のベースラインよりも大幅に優れたパフォーマンスを達成することを示しています。,5.75,https://d3i71xaburhd42.cloudfront.net/e423c07b36936ddce137bce009b318f2c2741be5/3-Figure1-1.png
Variational Information Bottleneck for Effective Low-Resource Fine-Tuning,"['Rabeeh Karimi mahabadi', 'Yonatan Belinkov', 'James Henderson']",https://openreview.net/forum?id=kvhzKz-_DMF,"While large-scale pretrained language models have obtained impressive results when fine-tuned on a wide variety of tasks, they still often suffer from overfitting in low-resource scenarios. Since such models are general-purpose feature extractors, many of these features are inevitably irrelevant for a given target task.  We propose to use Variational Information Bottleneck (VIB) to suppress irrelevant features when fine-tuning on low-resource target tasks, and show that our method successfully reduces overfitting.  Moreover, we show that our VIB model finds sentence representations that are more robust to biases in natural language inference datasets, and thereby obtains better generalization to out-of-domain datasets. Evaluation on seven low-resource datasets in different tasks shows that our method significantly improves transfer learning in low-resource scenarios, surpassing prior work. Moreover, it improves generalization on 13 out of 15 out-of-domain natural language inference benchmarks.",大規模な事前トレーニング済み言語モデルは、さまざまなタスクで微調整すると印象的な結果が得られますが、それでもリソースが少ないシナリオでは過剰適合に悩まされることがよくあります。このようなモデルは汎用の機能抽出機能であるため、これらの機能の多くは、特定のターゲットタスクには必然的に無関係です。変動情報ボトルネック（VIB）を使用して、リソースの少ないターゲットタスクを微調整するときに無関係な機能を抑制することを提案し、この方法が過剰適合をうまく削減することを示します。さらに、VIBモデルが、自然言語推論データセットのバイアスに対してより堅牢な文表現を見つけ、それによってドメイン外データセットへのより良い一般化を取得することを示します。異なるタスクでの7つの低リソースデータセットの評価は、私たちの方法が以前の作業を超えて、低リソースシナリオでの転移学習を大幅に改善することを示しています。さらに、15のドメイン外自然言語推論ベンチマークのうち13の一般化を改善します。,5.75,
Hierarchical Reinforcement Learning by Discovering Intrinsic Options,"['Jesse Zhang', 'Haonan Yu', 'Wei Xu']",https://openreview.net/forum?id=r-gPPHEjpmw,"We propose a hierarchical reinforcement learning method, HIDIO, that can learn task-agnostic options in a self-supervised manner while jointly learning to utilize them to solve sparse-reward tasks. Unlike current hierarchical RL approaches that tend to formulate goal-reaching low-level tasks or pre-define ad hoc lower-level policies, HIDIO encourages lower-level option learning that is independent of the task at hand, requiring few assumptions or little knowledge about the task structure. These options are learned through an intrinsic entropy minimization objective conditioned on the option sub-trajectories. The learned options are diverse and task-agnostic. In experiments on sparse-reward robotic manipulation and navigation tasks, HIDIO achieves higher success rates with greater sample efficiency than regular RL baselines and two state-of-the-art hierarchical RL methods. Code at: https://github.com/jesbu1/hidio.",階層型強化学習法HIDIOを提案します。これは、タスクにとらわれないオプションを自己監視方式で学習しながら、それらを利用してまばらな報酬タスクを解決することを共同で学習できます。目標を達成する低レベルのタスクを策定したり、アドホックな低レベルのポリシーを事前に定義したりする傾向がある現在の階層型RLアプローチとは異なり、HIDIOは、目前のタスクから独立した低レベルのオプション学習を推奨します。タスク構造。これらのオプションは、オプションのサブ軌道を条件とする固有のエントロピー最小化目標を通じて学習されます。学習したオプションは多様で、タスクに依存しません。スパースリワードのロボット操作およびナビゲーションタスクの実験では、HIDIOは、通常のRLベースラインおよび2つの最先端の階層型RLメソッドよりも高いサンプル効率で高い成功率を達成します。コード：https：//github.com/jesbu1/hidio。,5.75,https://d3i71xaburhd42.cloudfront.net/dc92538d2806cb3575655577ee1302737047fda2/2-Figure1-1.png
Variational Intrinsic Control Revisited,['Taehwan Kwon'],https://openreview.net/forum?id=P0p33rgyoE,"In this paper, we revisit variational intrinsic control (VIC), an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. In the original work by Gregor et al. (2016), two VIC algorithms were proposed: one that represents the options explicitly, and the other that does it implicitly. We show that the intrinsic reward used in the latter is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To correct this behavior, we propose two methods respectively based on the transitional probability model and Gaussian Mixture Model. We substantiate our claims through rigorous mathematical derivations and experimental analyses. ",この論文では、エージェントが利用できる内在的オプションの最大のセットを見つけるための教師なし強化学習法である変分内在的制御（VIC）を再検討します。グレゴールらによるオリジナルの作品では。 （2016）、2つのVICアルゴリズムが提案されました。1つはオプションを明示的に表し、もう1つは暗黙的にそれを行います。後者で使用される固有の報酬は、確率的環境ではバイアスの影響を受けやすく、次善のソリューションへの収束を引き起こすことを示します。この動作を修正するために、遷移確率モデルとガウス混合モデルに基づいて、それぞれ2つの方法を提案します。私たちは、厳密な数学的導出と実験的分析を通じて、私たちの主張を実証します。,5.75,https://d3i71xaburhd42.cloudfront.net/d817f45273f24fd9b866a8ac8b845292ac2c5a64/8-Figure1-1.png
The Role of Momentum Parameters in the Optimal Convergence of Adaptive Polyak's Heavy-ball Methods,"['Wei Tao', 'Sheng Long', 'Gaowei Wu', 'Qing Tao']",https://openreview.net/forum?id=L7WD8ZdscQ5,"The adaptive stochastic gradient descent (SGD) with momentum has been widely adopted in deep learning as well as convex optimization. In practice, the last iterate is commonly used as the final solution to make decisions. However, the available regret analysis and the setting of constant momentum parameters only guarantee the optimal convergence of the averaged solution. In this paper, we fill this theory-practice gap by investigating the convergence of the last iterate (referred to as {\it individual convergence}), which is a more difficult task than convergence analysis of the averaged solution. Specifically, in the constrained convex cases, we prove that the adaptive Polyak's Heavy-ball (HB) method, in which only the step size is updated using the exponential moving average strategy, attains an optimal individual convergence rate of $O(\frac{1}{\sqrt{t}})$, as opposed to the optimality of $O(\frac{\log t}{\sqrt {t}})$ of SGD, where $t$ is the number of iteration. Our new analysis not only shows how the HB momentum and its time-varying weight help us to achieve the acceleration in convex optimization but also gives valuable hints how the momentum parameters should be scheduled in deep learning. Empirical results on optimizing convex functions and training deep networks validate the correctness of our convergence analysis and demonstrate the improved performance of the adaptive HB methods.",運動量を伴う適応確率的勾配降下法（SGD）は、凸最適化だけでなく深層学習でも広く採用されています。実際には、最後の反復は、決定を下すための最終的な解決策として一般的に使用されます。ただし、利用可能な後悔分析と一定の運動量パラメーターの設定は、平均化された解の最適な収束を保証するだけです。この論文では、平均化された解の収束分析よりも難しいタスクである最後の反復の収束（個別収束と呼ばれる）を調査することによって、この理論と実践のギャップを埋めます。具体的には、制約付き凸型の場合、指数移動平均戦略を使用してステップサイズのみを更新する適応型Polyaksヘビーボール（HB）法が、最適な個別収束率$ O（\ frac {を達成することを証明します。 SGDの$ O（\ frac {\ log t} {\ sqrt {t}}）$の最適性とは対照的に、1} {\ sqrt {t}}）$。ここで、tは反復回数です。私たちの新しい分析は、HB運動量とその時変重みが凸最適化の加速を達成するのにどのように役立つかを示すだけでなく、深層学習で運動量パラメーターをどのようにスケジュールするかについての貴重なヒントも提供します。凸関数の最適化とディープネットワークのトレーニングに関する経験的結果は、収束分析の正確さを検証し、適応型HBメソッドのパフォーマンスの向上を示しています。,5.75,
SkipW: Resource adaptable RNN with strict upper computational limit,"['Tsiry Mayet', 'Anne Lambert', 'Pascal Leguyadec', 'Francoise Le Bolzer', 'François Schnitzler']",https://openreview.net/forum?id=2CjEVW-RGOJ,"We introduce Skip-Window, a method to allow recurrent neural networks (RNNs) to trade off accuracy for computational cost during the analysis of a sequence. Similarly to existing approaches, Skip-Window extends existing RNN cells by adding a mechanism to encourage the model to process fewer inputs. Unlike existing approaches, Skip-Window is able to respect a strict computational budget, making this model more suitable for limited hardware. We evaluate this approach on two datasets: a human activity recognition task and adding task. Our results show that Skip-Window is able to exceed the accuracy of existing approaches for a lower computational cost while strictly limiting said cost.",シーケンスの分析中にリカレントニューラルネットワーク（RNN）が精度と計算コストをトレードオフできるようにする方法であるSkip-Windowを紹介します。既存のアプローチと同様に、Skip-Windowは、モデルがより少ない入力を処理するように促すメカニズムを追加することにより、既存のRNNセルを拡張します。既存のアプローチとは異なり、Skip-Windowは厳密な計算バジェットを尊重できるため、このモデルは限られたハードウェアにより適しています。このアプローチを、人間の行動認識タスクと追加タスクの2つのデータセットで評価します。私たちの結果は、Skip-Windowが既存のアプローチの精度を超えて、計算コストを低く抑えながら、コストを厳密に制限できることを示しています。,5.75,
Clairvoyance: A Pipeline Toolkit for Medical Time Series,"['Daniel Jarrett', 'Jinsung Yoon', 'Ioana Bica', 'Zhaozhi Qian', 'Ari Ercole', 'Mihaela van der Schaar']",https://openreview.net/forum?id=xnC8YwKUE3k,"Time-series learning is the bread and butter of data-driven *clinical decision support*, and the recent explosion in ML research has demonstrated great potential in various healthcare settings. At the same time, medical time-series problems in the wild are challenging due to their highly *composite* nature: They entail design choices and interactions among components that preprocess data, impute missing values, select features, issue predictions, estimate uncertainty, and interpret models. Despite exponential growth in electronic patient data, there is a remarkable gap between the potential and realized utilization of ML for clinical research and decision support. In particular, orchestrating a real-world project lifecycle poses challenges in engineering (i.e. hard to build), evaluation (i.e. hard to assess), and efficiency (i.e. hard to optimize). Designed to address these issues simultaneously, Clairvoyance proposes a unified, end-to-end, autoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical standard, and (iii) interface for optimization. Our ultimate goal lies in facilitating transparent and reproducible experimentation with complex inference workflows, providing integrated pathways for (1) personalized prediction, (2) treatment-effect estimation, and (3) information acquisition. Through illustrative examples on real-world data in outpatient, general wards, and intensive-care settings, we illustrate the applicability of the pipeline paradigm on core tasks in the healthcare journey. To the best of our knowledge, Clairvoyance is the first to demonstrate viability of a comprehensive and automatable pipeline for clinical time-series ML.",時系列学習は、データ駆動型の*臨床意思決定支援*の基本であり、最近のML研究の急増は、さまざまな医療環境で大きな可能性を示しています。同時に、野生の医療時系列問題は、その高度に*複合*な性質のために困難です。データを前処理し、欠落値を代入し、機能を選択し、予測を発行し、不確実性を推定し、モデルを解釈します。電子患者データの指数関数的成長にもかかわらず、臨床研究と意思決定支援のためのMLの潜在的な利用と実現された利用の間には顕著なギャップがあります。特に、実際のプロジェクトライフサイクルを調整することは、エンジニアリング（つまり、構築が難しい）、評価（つまり、評価が難しい）、および効率（つまり、最適化が難しい）において課題をもたらします。これらの問題に同時に対処するように設計されたClairvoyanceは、（i）ソフトウェアツールキット、（ii）経験的標準、および（iii）最適化のためのインターフェイスとして機能する統合されたエンドツーエンドのautoML対応パイプラインを提案します。私たちの究極の目標は、複雑な推論ワークフローを使用して透過的で再現性のある実験を促進し、（1）パーソナライズされた予測、（2）治療効果の推定、および（3）情報取得のための統合された経路を提供することです。外来患者、一般病棟、および集中治療室での実際のデータに関する実例を通じて、ヘルスケアの旅のコアタスクに対するパイプラインパラダイムの適用可能性を示します。私たちの知る限り、Clairvoyanceは、臨床時系列MLの包括的で自動化可能なパイプラインの実行可能性を初めて実証しました。,5.75,https://d3i71xaburhd42.cloudfront.net/b628204e8718c49b26f7d3bb58692595c378aa31/2-Figure1-1.png
Dataset Meta-Learning from Kernel-Ridge Regression,"['Timothy Nguyen', 'Zhourong Chen', 'Jaehoon Lee']",https://openreview.net/forum?id=l-PrrQrK0QR,"One of the most fundamental aspects of any machine learning algorithm is the training data used by the algorithm. 
We introduce the novel concept of $\epsilon$-approximation of datasets, obtaining datasets which are much smaller than or are significant corruptions of the original training data while maintaining similar performance. We introduce a meta-learning algorithm Kernel Inducing Points (KIP) for obtaining such remarkable datasets, drawing inspiration from recent developments in the correspondence between infinitely-wide neural networks and kernel ridge-regression (KRR). For KRR tasks, we demonstrate that KIP can compress datasets by one or two orders of magnitude, significantly improving previous dataset distillation and subset selection methods while obtaining state of the art results for MNIST and CIFAR10 classification. Furthermore, our KIP-learned datasets are transferable to the training of finite-width neural networks even beyond the lazy-training regime. Consequently, we obtain state of the art results for neural network dataset distillation with potential applications to privacy-preservation.",機械学習アルゴリズムの最も基本的な側面の1つは、アルゴリズムで使用されるトレーニングデータです。データセットの近似という新しい概念を紹介し、同様のパフォーマンスを維持しながら、元のトレーニングデータよりもはるかに小さいか、重大な破損であるデータセットを取得します。このような注目に値するデータセットを取得するためのメタ学習アルゴリズムKernelInducing Points（KIP）を紹介し、無限幅のニューラルネットワークとカーネルリッジ回帰（KRR）の対応における最近の開発からインスピレーションを得ています。 KRRタスクの場合、KIPがデータセットを1桁または2桁圧縮できることを示し、MNISTおよびCIFAR10分類の最先端の結果を取得しながら、以前のデータセットの蒸留およびサブセット選択方法を大幅に改善します。さらに、KIPで学習したデータセットは、レイジートレーニング体制を超えても有限幅ニューラルネットワークのトレーニングに転送できます。その結果、プライバシー保護への潜在的なアプリケーションを備えたニューラルネットワークデータセット蒸留の最先端の結果が得られます。,5.75,https://d3i71xaburhd42.cloudfront.net/8212605d274d5e68bcedf990728f4f5c26f88168/2-Figure1-1.png
not-MIWAE: Deep Generative Modelling with Missing not at Random Data,"['Niels Bruun Ipsen', 'Pierre-Alexandre Mattei', 'Jes Frellsen']",https://openreview.net/forum?id=tu29GQT0JFy,"When a missing process depends on the missing values themselves, it needs to be explicitly modelled and taken into account while doing likelihood-based inference. We present an approach for building and fitting deep latent variable models (DLVMs) in cases where the missing process is dependent on the missing data. Specifically, a deep neural network enables us to flexibly model the conditional distribution of the missingness pattern given the data. This allows for incorporating prior information about the type of missingness (e.g.~self-censoring) into the model. Our inference technique, based on importance-weighted variational inference, involves maximising a lower bound of the joint likelihood. Stochastic gradients of the bound are obtained by using the reparameterisation trick both in latent space and data space. We show on various kinds of data sets and missingness patterns that explicitly modelling the missing process can be invaluable.",欠落しているプロセスが欠落している値自体に依存している場合、尤度ベースの推論を行う際に、明示的にモデル化して考慮する必要があります。欠落しているプロセスが欠落しているデータに依存している場合に、深い潜在変数モデル（DLVM）を構築および適合させるためのアプローチを提示します。具体的には、ディープニューラルネットワークにより、データが与えられた場合の欠落パターンの条件付き分布を柔軟にモデル化できます。これにより、欠落のタイプに関する事前情報（自己検閲など）をモデルに組み込むことができます。重要度加重変分推論に基づく私たちの推論手法には、結合尤度の下限を最大化することが含まれます。境界の確率的勾配は、潜在空間とデータ空間の両方で再パラメーター化トリックを使用して取得されます。さまざまな種類のデータセットと欠落パターンについて、欠落しているプロセスを明示的にモデル化することが非常に重要である可能性があることを示します。,5.75,
Coping with Label Shift via Distributionally Robust Optimisation,"['Jingzhao Zhang', 'Aditya Krishna Menon', 'Andreas Veit', 'Srinadh Bhojanapalli', 'Sanjiv Kumar', 'Suvrit Sra']",https://openreview.net/forum?id=BtZhsSGNRNi,"The label shift problem refers to the supervised learning setting where the train and test label distributions do not match. Existing work addressing label shift usually assumes access to an unlabelled test sample. This sample may be used to estimate the test label distribution, and to then train a suitably re-weighted classifier. While approaches using this idea have proven effective, their scope is limited as it is not always feasible to access the target domain; further, they require repeated retraining if the model is to be deployed in multiple test environments. Can one instead learn a single classifier that is robust to arbitrary label shifts from a broad family? In this paper, we answer this question by proposing a model that minimises an objective based on distributionally robust optimisation (DRO). We then design and analyse a gradient descent-proximal mirror ascent algorithm tailored for large-scale problems to optimise the proposed objective.  Finally, through experiments on CIFAR-100 and ImageNet, we show that our technique can significantly improve performance over a number of baselines in settings where label shift is present.",ラベルシフトの問題は、トレインとテストのラベル分布が一致しない教師あり学習設定を指します。ラベルシフトに対処する既存の作業は、通常、ラベルのないテストサンプルへのアクセスを前提としています。このサンプルは、テストラベルの分布を推定し、適切に再重み付けされた分類器をトレーニングするために使用できます。このアイデアを使用したアプローチは効果的であることが証明されていますが、ターゲットドメインにアクセスすることが常に実行可能であるとは限らないため、その範囲は限られています。さらに、モデルを複数のテスト環境に展開する場合は、再トレーニングを繰り返す必要があります。代わりに、幅広いファミリーからの任意のラベルシフトに対してロバストな単一の分類器を学習できますか？この論文では、分布ロバスト最適化（DRO）に基づいて目的を最小化するモデルを提案することにより、この質問に答えます。次に、提案された目的を最適化するために、大規模な問題に合わせて調整された勾配降下近位ミラー上昇アルゴリズムを設計および分析します。最後に、CIFAR-100とImageNetでの実験を通じて、ラベルシフトが存在する設定で、私たちの手法が多くのベースラインにわたってパフォーマンスを大幅に改善できることを示します。,5.67,
Lossless Compression of Structured Convolutional Models via Lifting,"['Gustav Sourek', 'Filip Zelezny', 'Ondrej Kuzelka']",https://openreview.net/forum?id=oxnp2q-PGL4,"Lifting is an efficient technique to scale up graphical models generalized to relational domains by exploiting the underlying symmetries. Concurrently, neural models are continuously expanding from grid-like tensor data into structured representations, such as various attributed graphs and relational databases. To address the irregular structure of the data, the models typically extrapolate on the idea of convolution, effectively introducing parameter sharing in their, dynamically unfolded, computation graphs. The computation graphs themselves then reflect the symmetries of the underlying data, similarly to the lifted graphical models. Inspired by lifting, we introduce a simple and efficient technique to detect the symmetries and compress the neural models without loss of any information. We demonstrate through experiments that such compression can lead to significant speedups of structured convolutional models, such as various Graph Neural Networks, across various tasks, such as molecule classification and knowledge-base completion.",リフティングは、基礎となる対称性を利用して、リレーショナルドメインに一般化されたグラフィカルモデルをスケールアップするための効率的な手法です。同時に、ニューラルモデルは、グリッドのようなテンソルデータから、さまざまな属性付きグラフやリレーショナルデータベースなどの構造化された表現に継続的に拡張されています。データの不規則な構造に対処するために、モデルは通常、畳み込みの概念を外挿し、動的に展開された計算グラフにパラメーター共有を効果的に導入します。計算グラフ自体は、持ち上げられたグラフィカルモデルと同様に、基になるデータの対称性を反映します。リフティングに触発されて、対称性を検出し、情報を失うことなく神経モデルを圧縮するためのシンプルで効率的な手法を紹介します。このような圧縮は、分子分類や知識ベースの完成などのさまざまなタスクにわたって、さまざまなグラフニューラルネットワークなどの構造化畳み込みモデルの大幅な高速化につながる可能性があることを実験を通じて示しています。,5.67,https://d3i71xaburhd42.cloudfront.net/6cec566c0ebd4f155e297eb311e5c62c192f4e23/3-Figure1-1.png
Generalized Energy Based Models,"['Michael Arbel', 'Liang Zhou', 'Arthur Gretton']",https://openreview.net/forum?id=0PtUPB9z6qK,"We introduce the Generalized Energy Based Model (GEBM) for generative modelling. These models combine two  trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. 
Both the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the ""generator"").  
GEBMs are trained by alternating between learning the energy and the base. 
We show that both training stages are well-defined: the energy is learned by maximising a generalized likelihood, and the resulting energy-based loss provides informative gradients for learning the base.
Samples from the posterior on the latent space of the trained model can be obtained via MCMC, thus finding regions in this space that produce better quality samples.
Empirically, the GEBM samples on image-generation tasks are of much better quality than those from the learned generator alone, indicating that all else being equal, the GEBM will outperform a GAN of the same complexity. When using normalizing flows as base measures, GEBMs succeed on density modelling tasks returning comparable performance to direct maximum likelihood of the same networks.",生成モデリングのための一般化エネルギーベースモデル（GEBM）を紹介します。これらのモデルは、2つのトレーニング済みコンポーネントを組み合わせたものです。基本分布（通常は陰的モデル）。高次元空間で内在次元が低いデータのサポートを学習できます。学習したサポートの確率質量を洗練するためのエネルギー関数。ベース分布のみを保持するGAN（「ジェネレータ」）とは異なり、エネルギー関数とベースの両方が共同で最終モデルを構成します。 GEBMは、エネルギーとベースの学習を交互に行うことでトレーニングされます。両方のトレーニング段階が明確に定義されていることを示します。エネルギーは一般化された尤度を最大化することによって学習され、結果として生じるエネルギーベースの損失はベースを学習するための有益な勾配を提供します。訓練されたモデルの潜在空間の後方からのサンプルは、MCMCを介して取得できるため、この空間でより高品質のサンプルを生成する領域を見つけることができます。経験的に、画像生成タスクのGEBMサンプルは、学習したジェネレーターのみのサンプルよりもはるかに高品質であり、他のすべてが等しい場合、GEBMは同じ複雑さのGANよりもパフォーマンスが優れていることを示しています。正規化フローを基本メジャーとして使用する場合、GEBMは密度モデリングタスクに成功し、同じネットワークの最尤法に匹敵するパフォーマンスを返します。,5.67,
CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers,"['SHIYANG LI', 'Semih Yavuz', 'Kazuma Hashimoto', 'Jia Li', 'Tong Niu', 'Nazneen Rajani', 'Xifeng Yan', 'Yingbo Zhou', 'Caiming Xiong']",https://openreview.net/forum?id=eom0IUrF__F,"Dialogue state trackers (DST) have made significant progress on benchmark datasets but their generalization capability to novel and realistic scenarios beyond the held-out conversations is less understood. We propose controllable counterfactuals (CoCo) to bridge this gap and evaluate DST models on novel scenarios, i.e., would the system successfully tackle the request if the user responded differently but still consistent with the dialogue flow? CoCo leverages turn-level belief states as counterfactual conditionals to produce novel conversation scenarios in two steps: (i) counterfactual goal generation at turn-level by dropping and adding slots followed by replacing slot values, conditioned on which (ii) counterfactual conversation generation that is consistent with the dialogue flow. Evaluating state-of-the-art DST models on MultiWOZ dataset with CoCo-generated counterfactuals results in a significant performance drop of up to 30.8% (from 49.4% to 18.6%) in absolute joint goal accuracy while widely used techniques like paraphrasing only affect the accuracy by at most 2%.  The human evaluation shows that CoCo-generated conversations perfectly reflect the underlying user goal with more than 95% accuracy and are as human-like as the original conversations, which further strengthens its reliability and potential to be adopted as part of the robustness evaluation of DST models.",ダイアログ状態トラッカー（DST）は、ベンチマークデータセットで大きな進歩を遂げましたが、保留された会話を超えた斬新で現実的なシナリオへの一般化機能はあまり理解されていません。このギャップを埋め、新しいシナリオでDSTモデルを評価するために、制御可能な反事実（CoCo）を提案します。つまり、ユーザーが異なる応答をしたが、ダイアログフローと一貫性がある場合、システムは要求に正常に対処できますか？ CoCoは、ターンレベルの信念状態を反事実条件節として活用して、2つのステップで新しい会話シナリオを生成します。（i）スロットを削除および追加した後、スロット値を置き換えることによるターンレベルでの反事実的目標の生成。（ii）反事実的会話の生成対話の流れと一致しています。 CoCoで生成された反事実条件を使用してMultiWOZデータセットで最先端のDSTモデルを評価すると、最大30.8の大幅なパフォーマンス低下が発生します。,5.67,https://d3i71xaburhd42.cloudfront.net/16e4a6b20f1d8bff37fcfd5671e21a13b41d242f/3-Figure1-1.png
ALFWorld: Aligning Text and Embodied Environments for Interactive Learning,"['Mohit Shridhar', 'Xingdi Yuan', 'Marc-Alexandre Cote', 'Yonatan Bisk', 'Adam Trischler', 'Matthew Hausknecht']",https://openreview.net/forum?id=0IOX0YcCdTn,"Given a simple request like Put a washed apple in the kitchen fridge, humans can reason in purely abstract terms by imagining action sequences and scoring their likelihood of success, prototypicality, and efficiency, all without moving a muscle. Once we see the kitchen in question, we can update our abstract plans to fit the scene. Embodied agents require the same abilities, but existing work does not yet provide the infrastructure necessary for both reasoning abstractly and executing concretely. We address this limitation by introducing ALFWorld, a simulator that enables agents to learn abstract, text-based policies in TextWorld (Côté et al., 2018) and then execute goals from the ALFRED benchmark (Shridhar et al., 2020) in a rich visual environment. ALFWorld enables the creation of a new BUTLER agent whose abstract knowledge, learned in TextWorld, corresponds directly to concrete, visually grounded actions. In turn, as we demonstrate empirically, this fosters better agent generalization than training only in the visually grounded environment. BUTLER’s simple, modular design factors the problem to allow researchers to focus on models for improving every piece of the pipeline (language understanding, planning, navigation, and visual scene understanding).",洗ったリンゴをキッチンの冷蔵庫に入れるなどの簡単なリクエストがあれば、人間は、筋肉を動かすことなく、アクションシーケンスを想像し、成功の可能性、プロトタイプ性、効率性をスコアリングすることで、純粋に抽象的な言葉で推論できます。問題のキッチンを見つけたら、シーンに合わせて抽象的な計画を更新できます。具現化されたエージェントは同じ能力を必要としますが、既存の作業は、抽象的に推論し、具体的に実行するために必要なインフラストラクチャをまだ提供していません。エージェントがTextWorldで抽象的なテキストベースのポリシーを学習し（Cote et al。、2018）、ALFREDベンチマーク（Shridhar et al。、2020）から目標を実行できるようにするシミュレーターであるALFWorldを導入することで、この制限に対処します。視覚環境。 ALFWorldを使用すると、TextWorldで学習した抽象的な知識が、具体的で視覚的に根拠のあるアクションに直接対応する新しいBUTLERエージェントを作成できます。次に、経験的に示すように、これは視覚的に接地された環境でのみトレーニングするよりも優れたエージェントの一般化を促進します。バトラーのシンプルなモジュラー設計は、研究者がパイプラインのすべての部分（言語理解、計画、ナビゲーション、視覚シーンの理解）を改善するためのモデルに集中できるように問題を考慮に入れています。,5.67,https://d3i71xaburhd42.cloudfront.net/398a0625e8707a0b41ac58eaec51e8feb87dd7cb/1-Figure1-1.png
Deconstructing the Regularization of BatchNorm,"['Yann Dauphin', 'Ekin Dogus Cubuk']",https://openreview.net/forum?id=d-XzF81Wg1,"Batch normalization (BatchNorm) has become a standard technique in deep learning. Its popularity is in no small part due to its often positive effect on generalization. Despite this success, the regularization effect of the technique is still poorly understood. This study aims to decompose BatchNorm into separate mechanisms that are much simpler. We identify three effects of BatchNorm and assess their impact directly with ablations and interventions. We find that preventing explosive growth at the final layer at initialization and during training explains most of BatchNorm's generalization boost. This regularization mechanism can lift accuracy by $2.9\%$ for Resnet-50 on Imagenet without BatchNorm. We show it is linked to other methods like Dropout and recent initializations like Fixup. Surprisingly, this simple mechanism matches the improvement of $0.8\%$ of the more complex Dropout regularization for the state-of-the-art Efficientnet-B8 model on Imagenet. This demonstrates the underrated effectiveness of simple regularizations and sheds light on directions to further improve generalization for deep nets.",バッチ正規化（BatchNorm）は、深層学習の標準的な手法になりました。その人気は、一般化にプラスの効果をもたらすことが多いため、少なからずあります。この成功にもかかわらず、この手法の正則化効果はまだよくわかっていません。この調査は、BatchNormをはるかに単純な個別のメカニズムに分解することを目的としています。 BatchNormの3つの効果を特定し、アブレーションと介入によってそれらの影響を直接評価します。初期化時およびトレーニング中の最終層での爆発的な成長の防止が、BatchNormsの一般化の促進のほとんどを説明していることがわかりました。この正則化メカニズムにより、BatchNormを使用しないImagenet上のResnet-50の精度が2.9％向上します。 Dropoutのような他のメソッドやFixupのような最近の初期化にリンクされていることを示します。驚いたことに、この単純なメカニズムは、Imagenetの最先端のEfficientnet-B8モデルのより複雑なドロップアウト正則化の0.8％の改善と一致します。これは、単純な正則化の過小評価された有効性を示し、ディープネットの一般化をさらに改善するための方向性に光を当てます。,5.67,
Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization,"['Lanqing Li', 'Rui Yang', 'Dijun Luo']",https://openreview.net/forum?id=8cpHIfgY4Dj,"We study the offline meta-reinforcement learning (OMRL) problem, a paradigm which enables reinforcement learning (RL) algorithms to quickly adapt to unseen tasks without any interactions with the environments, making RL truly practical in many real-world applications. This problem is still not fully understood, for which two major challenges need to be addressed. First, offline RL usually suffers from bootstrapping errors of out-of-distribution state-actions which leads to divergence of value functions. Second, meta-RL requires efficient and robust task inference learned jointly with control policy. In this work, we enforce behavior regularization on learned policy as a general approach to offline RL, combined with a deterministic context encoder for efficient task inference. We propose a novel negative-power distance metric on bounded context embedding space, whose gradients propagation is detached from the Bellman backup. We provide analysis and insight showing that some simple design choices can yield substantial improvements over recent approaches involving meta-RL and distance metric learning. To the best of our knowledge, our method is the first model-free and end-to-end OMRL algorithm, which is computationally efficient and demonstrated to outperform prior algorithms on several meta-RL benchmarks.
",オフラインメタ強化学習（OMRL）問題を研究します。これは、強化学習（RL）アルゴリズムが環境との相互作用なしに目に見えないタスクにすばやく適応できるようにするパラダイムであり、RLを多くの実際のアプリケーションで真に実用的にします。この問題はまだ完全には理解されておらず、2つの主要な課題に対処する必要があります。まず、オフラインRLは通常、分布外の状態アクションのブートストラップエラーに悩まされ、値関数の発散につながります。次に、メタRLには、制御ポリシーと共同で学習した効率的で堅牢なタス​​ク推論が必要です。この作業では、効率的なタスク推論のための決定性文脈エンコーダーと組み合わせて、オフラインRLへの一般的なアプローチとして学習したポリシーに動作の正則化を適用します。勾配伝搬がベルマンバックアップから切り離されている、有界コンテキスト埋め込み空間での新しい負のパワー距離メトリックを提案します。いくつかの単純な設計の選択により、メタRLおよび距離計量学習を含む最近のアプローチよりも大幅に改善できることを示す分析と洞察を提供します。私たちの知る限り、私たちの方法は、最初のモデルフリーでエンドツーエンドのOMRLアルゴリズムであり、計算効率が高く、いくつかのメタRLベンチマークで以前のアルゴリズムよりも優れていることが実証されています。,5.67,https://d3i71xaburhd42.cloudfront.net/3c24383faf09cd3b0d6f07fd94c4122e32d9b52e/5-Figure1-1.png
Discrete Graph Structure Learning for Forecasting Multiple Time Series,"['Chao Shang', 'Jie Chen', 'Jinbo Bi']",https://openreview.net/forum?id=WEHSlH5mOk,"Time series forecasting is an extensively studied subject in statistics, economics, and computer science. Exploration of the correlation and causation among the variables in a multivariate time series shows promise in enhancing the performance of a time series model. When using deep neural networks as forecasting models, we hypothesize that exploiting the pairwise information among multiple (multivariate) time series also improves their forecast. If an explicit graph structure is known, graph neural networks (GNNs) have been demonstrated as powerful tools to exploit the structure. In this work, we propose learning the structure simultaneously with the GNN if the graph is unknown. We cast the problem as learning a probabilistic graph model through optimizing the mean performance over the graph distribution. The distribution is parameterized by a neural network so that discrete graphs can be sampled differentiably through reparameterization. Empirical evaluations show that our method is simpler, more efficient, and better performing than a recently proposed bilevel learning approach for graph structure learning, as well as a broad array of forecasting models, either deep or non-deep learning based, and graph or non-graph based.",時系列予測は、統計学、経済学、およびコンピューターサイエンスで広く研究されている主題です。多変量時系列の変数間の相関と因果関係の調査は、時系列モデルのパフォーマンスを向上させる上で有望であることを示しています。ディープニューラルネットワークを予測モデルとして使用する場合、複数の（多変量）時系列間でペアワイズ情報を活用すると、予測も改善されると仮定します。明示的なグラフ構造がわかっている場合、グラフニューラルネットワーク（GNN）は、構造を活用するための強力なツールとして実証されています。この作業では、グラフが不明な場合、GNNと同時に構造を学習することを提案します。グラフ分布全体の平均パフォーマンスを最適化することにより、確率的グラフモデルを学習することとして問題を投げかけます。分布はニューラルネットワークによってパラメーター化されるため、再パラメーター化によって離散グラフを差別的にサンプリングできます。経験的評価によると、私たちの方法は、グラフ構造学習のために最近提案された2レベル学習アプローチ、および深層学習または非深層学習ベース、グラフまたは非の幅広い予測モデルよりも単純で、効率的で、パフォーマンスが優れています。 -グラフベース。,5.67,
End-to-End Egospheric Spatial Memory,"['Daniel James Lenton', 'Stephen James', 'Ronald Clark', 'Andrew Davison']",https://openreview.net/forum?id=rRFIni1CYmy,"Spatial memory, or the ability to remember and recall specific locations and objects, is central to autonomous agents' ability to carry out tasks in real environments. However, most existing artificial memory modules have difficulty recalling information over long time periods and are not very adept at storing spatial information. We propose a parameter-free module, Egospheric Spatial Memory (ESM), which encodes the memory in an ego-sphere around the agent, enabling expressive 3D representations. ESM can be trained end-to-end via either imitation or reinforcement learning, and improves both training efficiency and final performance against other memory baselines on both drone and manipulator visuomotor control tasks. The explicit egocentric geometry also enables us to seamlessly combine the learned controller with other non-learned modalities, such as local obstacle avoidance. We further show applications to semantic segmentation on the ScanNet dataset, where ESM naturally combines image-level and map-level inference modalities. Through our broad set of experiments, we show that ESM provides a general computation graph for embodied spatial reasoning, and the module forms a bridge between real-time mapping systems and differentiable memory architectures.",空間メモリ、つまり特定の場所やオブジェクトを記憶して呼び出す機能は、実際の環境でタスクを実行する自律エージェント機能の中心です。ただし、ほとんどの既存の人工メモリモジュールは、長期間にわたって情報を呼び出すことが困難であり、空間情報の保存にあまり熟練していません。パラメータのないモジュールであるEgosphericSpatial Memory（ESM）を提案します。これは、エージェントの周囲の自我球にメモリをエンコードし、表現力豊かな3D表現を可能にします。 ESMは、模倣学習または強化学習のいずれかを介してエンドツーエンドでトレーニングでき、ドローンとマニピュレーターの両方の視覚運動制御タスクで、トレーニング効率と他のメモリベースラインに対する最終パフォーマンスの両方を向上させます。明示的な自己中心的なジオメトリにより、学習したコントローラーを、局所的な障害物の回避など、学習していない他のモダリティとシームレスに組み合わせることができます。さらに、ESMが画像レベルとマップレベルの推論モダリティを自然に組み合わせるScanNetデータセットでのセマンティックセグメンテーションへのアプリケーションを示します。幅広い一連の実験を通じて、ESMが具体化された空間推論の一般的な計算グラフを提供し、モジュールがリアルタイムマッピングシステムと微分可能なメモリアーキテクチャ間のブリッジを形成することを示します。,5.67,
DECENTRALIZED ATTRIBUTION OF GENERATIVE MODELS,"['Changhoon Kim', 'Yi Ren', 'Yezhou Yang']",https://openreview.net/forum?id=_kxlwvhOodK,"Growing applications of generative models have led to new threats such as malicious personation and digital copyright infringement. 
One solution to these threats is model attribution, i.e., the identification of user-end models where the contents under question are generated.
Existing studies showed empirical feasibility of attribution through a centralized classifier trained on all existing user-end models. 
However, this approach is not scalable in a reality where the number of models ever grows. Neither does it provide an attributability guarantee.
To this end, this paper studies decentralized attribution, which relies on binary classifiers associated with each user-end model. 
Each binary classifier is parameterized by a user-specific key and distinguishes its associated model distribution from the authentic data distribution. 
We develop sufficient conditions of the keys that guarantee an attributability lower bound.
Our method is validated on MNIST, CelebA, and FFHQ datasets. We also examine the trade-off between generation quality and robustness of attribution against adversarial post-processes.",生成モデルのアプリケーションの増加は、悪意のあるなりすましやデジタル著作権侵害などの新たな脅威につながっています。これらの脅威に対する1つの解決策は、モデルの帰属、つまり、問題のコンテンツが生成されるユーザーエンドモデルの識別です。既存の研究は、既存のすべてのユーザーエンドモデルでトレーニングされた一元化された分類子を介した帰属の経験的実現可能性を示しました。ただし、このアプローチは、モデルの数が増え続ける現実ではスケーラブルではありません。また、帰属性の保証も提供しません。この目的のために、このペーパーでは、各ユーザーエンドモデルに関連付けられたバイナリ分類子に依存する分散型アトリビューションについて説明します。各バイナリ分類子は、ユーザー固有のキーによってパラメーター化され、関連するモデル分布を本物のデータ分布と区別します。アトリビューションの下限を保証するキーの十分条件を開発します。私たちの方法は、MNIST、CelebA、およびFFHQデータセットで検証されています。また、生成の品質と、敵対的な後処理に対する帰属の堅牢性との間のトレードオフについても検討します。,5.67,
On the Bottleneck of Graph Neural Networks and its Practical Implications,"['Uri Alon', 'Eran Yahav']",https://openreview.net/forum?id=i80OPhOCVH2,"Since the proposal of the graph neural network (GNN) by Gori et al. (2005) and Scarselli et al. (2008), one of the major problems in training GNNs was their struggle to propagate information between distant nodes in the graph.
We propose a new explanation for this problem: GNNs are susceptible to a bottleneck when aggregating messages across a long path. This bottleneck causes the over-squashing of exponentially growing information into fixed-size vectors.
As a result, GNNs fail to propagate messages originating from distant nodes and perform poorly when the prediction task depends on long-range interaction.
In this paper, we highlight the inherent problem of over-squashing in GNNs.
We demonstrate that the bottleneck hinders popular GNNs from fitting long-range signals in the training data. 
We further show that GNNs that absorb incoming edges equally, such as GCN and GIN, are more susceptible to over-squashing than GAT and GGNN.
Finally, we show that prior work, which extensively tuned GNN models of long-range problems, suffer from over-squashing, and that breaking the bottleneck improves their state-of-the-art results without any tuning or additional weights.
Our code is available at https://github.com/tech-srl/bottleneck/ .",ゴリらによるグラフニューラルネットワーク（GNN）の提案以来。 （2005）およびScarselli etal。 （2008）、GNNのトレーニングにおける主要な問題の1つは、グラフ内の離れたノード間で情報を伝播するのに苦労したことでした。この問題の新しい説明を提案します。GNNは、長いパスでメッセージを集約するときにボトルネックの影響を受けやすくなります。このボトルネックにより、指数関数的に増大する情報が固定サイズのベクトルに押しつぶされすぎます。その結果、予測タスクが長距離の相互作用に依存している場合、GNNは離れたノードから発信されたメッセージの伝播に失敗し、パフォーマンスが低下します。このホワイトペーパーでは、GNNの過剰押しつぶしに固有の問題に焦点を当てます。ボトルネックが、人気のあるGNNがトレーニングデータに長距離信号を適合させるのを妨げていることを示します。さらに、GCNやGINなど、入力エッジを均等に吸収するGNNは、GATやGGNNよりも過剰に押しつぶされやすいことを示します。最後に、長距離問題のGNNモデルを広範囲に調整した以前の作業は、過度の押しつぶしに悩まされており、ボトルネックを解消すると、調整や追加の重みなしで最先端の結果が向上することを示します。私たちのコードはhttps://github.com/tech-srl/bottleneck/で入手できます。,5.6,https://d3i71xaburhd42.cloudfront.net/50efe5504d2786921bfd557e58e7d8b7afb7d6e1/2-Figure1-1.png
Prediction and generalisation over directed actions by grid cells,"['Changmin Yu', 'Timothy Behrens', 'Neil Burgess']",https://openreview.net/forum?id=Ptaz_zIFbX,"Knowing how the effects of directed actions generalise to new situations (e.g. moving North, South, East and West, or turning left, right, etc.) is key to rapid generalisation of action to new situations. Markovian tasks can be characterised by a state space and a transition matrix and recent work has proposed that neural grid codes provide an efficient representation of the state space, as eigenvectors of a transition matrix reflecting diffusion across states, that allows efficient prediction of future state distributions. Here we address the ability to predict the effects of directed actions across new tasks, irrespective of differences in local transition structure, to allow fast generalisation and form a ""sense of direction"". We extend the eigenbasis prediction model, utilising tools from Fourier analysis, to prediction over arbitrary translation-invariant directed transition structures (i.e. displacement and diffusion), showing that a single set of eigenvectors can support predictions over arbitrary directed actions via action-specific eigenvalues. We show the equivalence between the generalised prediction framework and traditional models of grid cells firing driven by self-motion to perform path integration using oscillatory interference models (via Fourier components as velocity-controlled oscillators) or continuous attractor networks (via analysis of the update dynamics). We thus provide a unifying framework for the role of the grid system in predictive planning, sense of direction and path integration. The resulting model allows a single grid-like representation to support efficient prediction over directed transitions in spatial and non-spatial tasks, supporting generalisable inference over directed actions across different tasks.",指示されたアクションの効果が新しい状況にどのように一般化するかを知ること（たとえば、北、南、東、西に移動する、または左、右に曲がるなど）は、新しい状況にアクションを迅速に一般化するための鍵です。マルコフタスクは、状態空間と遷移行列によって特徴付けることができ、最近の研究では、神経グリッドコードが、状態間の拡散を反映する遷移行列の固有ベクトルとして、状態空間の効率的な表現を提供し、将来の状態分布の効率的な予測を可能にすることが提案されています。 。ここでは、ローカル遷移構造の違いに関係なく、新しいタスク全体で指示されたアクションの効果を予測して、迅速な一般化を可能にし、「方向感覚」を形成する機能について説明します。フーリエ解析のツールを利用して固有基底予測モデルを拡張し、任意の並進不変の有向遷移構造（つまり、変位と拡散）の予測に拡張します。これは、単一の固有ベクトルのセットが、アクション固有の固有値を介して任意の有向アクションの予測をサポートできることを示しています。一般化された予測フレームワークと、振動干渉モデル（速度制御発振器としてのフーリエ成分を介して）または連続アトラクタネットワーク（更新ダイナミクスの分析を介して）を使用してパス統合を実行するための自己運動によって駆動されるグリッドセル発火の従来のモデルとの同等性を示します）。したがって、予測計画、方向感覚、およびパス統合におけるグリッドシステムの役割の統合フレームワークを提供します。結果として得られるモデルにより、単一のグリッドのような表現により、空間タスクと非空間タスクの有向遷移に対する効率的な予測がサポートされ、さまざまなタスクにわたる有向アクションに対する一般化可能な推論がサポートされます。,5.6,
NAS-Bench-ASR: Reproducible Neural Architecture Search for Speech Recognition,"['Abhinav Mehrotra', 'Alberto Gil C. P. Ramos', 'Sourav Bhattacharya', 'Łukasz Dudziak', 'Ravichander Vipperla', 'Thomas Chau', 'Mohamed S Abdelfattah', 'Samin Ishtiaq', 'Nicholas Donald Lane']",https://openreview.net/forum?id=CU0APx9LMaL,"Powered by innovations in novel architecture design, noise tolerance techniques and increasing model capacity, Automatic Speech Recognition (ASR) made giant strides in improving prediction accuracies over the past decade. ASR models are often trained with tens of thousand hours of high quality speech data to produce the state-of-the-art results. Industry-scale ASR model-training thus remains as a computationally heavy and time-consuming procedure, and consequently attracted little attention thus far in adopting automatic techniques in exploring neural architecture variations. Neural Architecture Search (NAS), on the other hand, gained a lot of interest in the past few years for its ability in discovering state-of-the-art architectures mainly in computer vision tasks. However, NAS approaches also suffer from the requirement of a large-scale computing infrastructure to support training of a massive number of neural networks and are often difficult to reproduce. Lately, a number of attempts have been made to ameliorate the computational problem and improve the search turnaround time of NAS algorithms by introducing benchmark datasets like NAS-Bench-101, NAS-Bench-201, and NAS-NLP. These datasets, however, focus predominantly on computer vision and NLP tasks and thus suffer from the problem of limited coverage of application domains. In this work we apply NAS for finding cell architecture for ASR models and release a comprehensive NAS-Bench dataset for reproducible NAS research. The dataset consists of 8,242 unique ASR models trained on the TIMIT audio dataset, each starting from 3 seed initializations. Novelty of our dataset includes consideration for on-device deployability and inclusion of runtime measures of all the models on diverse hardware platforms and settings. We further evaluate performances of a number of NAS algorithms on our dataset. Finally, we show that cells in our search space for TIMIT transfer well to a much larger LibriSpeech dataset. ","自動音声認識（ASR）は、新しいアーキテクチャ設計、ノイズ耐性技術、およびモデル容量の増加における革新によって強化され、過去10年間で予測精度の向上に大きな進歩を遂げました。 ASRモデルは、最先端の結果を生成するために、多くの場合、数万時間の高品質の音声データでトレーニングされます。したがって、業界規模のASRモデルトレーニングは、計算量が多く時間のかかる手順のままであり、その結果、ニューラルアーキテクチャのバリエーションを探索する際に自動技術を採用することでこれまでほとんど注目されていませんでした。一方、ニューラルアーキテクチャ検索（NAS）は、主にコンピュータビジョンタスクで最先端のアーキテクチャを発見する能力で、過去数年間に大きな関心を集めました。ただし、NASアプローチは、膨大な数のニューラルネットワークのトレーニングをサポートするための大規模なコンピューティングインフラストラクチャの要件にも悩まされており、再現が難しいことがよくあります。最近、NAS-Bench-101、NAS-Bench-201、NAS-NLPなどのベンチマークデータセットを導入することにより、計算上の問題を改善し、NASアルゴリズムの検索ターンアラウンドタイムを改善するための多くの試みが行われています。ただし、これらのデータセットは主にコンピュータービジョンとNLPタスクに焦点を合わせているため、アプリケーションドメインのカバレッジが制限されるという問題があります。この作業では、ASRモデルのセルアーキテクチャを見つけるためにNASを適用し、再現性のあるNAS研究のための包括的なNAS-Benchデータセットをリリースします。データセットは、TIMITオーディオデータセットでトレーニングされた8,242の一意のASRモデルで構成され、それぞれが3つのシード初期化から始まります。データセットの目新しさには、デバイス上での展開可能性の考慮と、さまざまなハードウェアプラットフォームおよび設定でのすべてのモデルの実行時測定値の組み込みが含まれます。さらに、データセットに対するいくつかのNASアルゴリズムのパフォーマンスを評価します。最後に、TIMITの検索スペース内のセルが、はるかに大きなLibriSpeechデータセットに適切に転送されることを示します。",5.6,
"Cut out the annotator, keep the cutout: better segmentation with weak supervision","['Sarah Hooper', 'Michael Wornow', 'Ying Hang Seah', 'Peter Kellman', 'Hui Xue', 'Frederic Sala', 'Curtis Langlotz', 'Christopher Re']",https://openreview.net/forum?id=bjkX6Kzb5H,"Constructing large, labeled training datasets for segmentation models is an expensive and labor-intensive process. This is a common challenge in machine learning, addressed by methods that require few or no labeled data points such as few-shot learning (FSL) and weakly-supervised learning (WS). Such techniques, however, have limitations when applied to image segmentation---FSL methods often produce noisy results and are strongly dependent on which few datapoints are labeled, while WS models struggle to fully exploit rich image information. We propose a framework that fuses FSL and WS for segmentation tasks, enabling users to train high-performing segmentation networks with very few hand-labeled training points. We use FSL models as weak sources in a WS framework, requiring a very small set of reference labeled images, and introduce a new WS model that focuses on key areas---areas with contention among noisy labels---of the image to fuse these weak sources. Empirically, we evaluate our proposed approach over seven well-motivated segmentation tasks. We show that our methods can achieve within 1.4 Dice points compared to fully supervised networks while only requiring five hand-labeled training points. Compared to existing FSL methods, our approach improves performance by a mean 3.6 Dice points over the next-best method. ",セグメンテーションモデル用のラベル付きの大規模なトレーニングデータセットを構築することは、費用と労力を要するプロセスです。これは機械学習の一般的な課題であり、少数ショット学習（FSL）や弱教師あり学習（WS）など、ラベル付けされたデータポイントをほとんどまたはまったく必要としない方法で対処されます。ただし、このような手法を画像セグメンテーションに適用すると制限があります。FSLメソッドはノイズの多い結果を生成することが多く、ラベル付けされるデータポイントの数に強く依存しますが、WSモデルは豊富な画像情報を十分に活用するのに苦労します。セグメンテーションタスクのためにFSLとWSを融合するフレームワークを提案します。これにより、ユーザーは、手作業でラベル付けされたトレーニングポイントをほとんど使用せずに、高性能のセグメンテーションネットワークをトレーニングできます。 WSフレームワークの弱いソースとしてFSLモデルを使用し、参照ラベル付き画像の非常に小さなセットを必要とし、これらの弱いソースを融合するために、画像のノイズの多いラベル間で競合する主要な領域に焦点を当てた新しいWSモデルを導入します。経験的に、7つの意欲的なセグメンテーションタスクにわたって提案されたアプローチを評価します。私たちの方法は、完全に監視されたネットワークと比較して1.4ダイスポイント以内で達成できることを示していますが、必要なのは5つの手書きのトレーニングポイントだけです。既存のFSLメソッドと比較して、私たちのアプローチは、次善のメソッドよりも平均3.6ダイスポイントパフォーマンスを向上させます。,5.6,
Learning Energy-Based Generative Models via Coarse-to-Fine Expanding and Sampling,"['Yang Zhao', 'Jianwen Xie', 'Ping Li']",https://openreview.net/forum?id=aD1_5zowqV,"Energy-based models (EBMs) for generative modeling parametrize a single net and can be directly trained by maximum likelihood estimation. Despite the simplicity and tractability, current approaches are either unstable to learn or difficult to synthesize diverse and high-fidelity images. We propose to train EBM via a multistage coarse-to-fine expanding and sampling strategy, namely CF-EBM. To improve the learning procedure, we propose an effective net architecture and advocate applying smooth activations.
The resulting approach is computationally efficient and achieves the best performance on image generation amongst EBMs and the spectral normalization GAN. Furthermore, we provide a recipe for being the first successful EBM to synthesize $512\times512$-pixel images and also improve out-of-distribution detection.
In the end, we effortlessly generalize CF-EBM to the one-sided unsupervised image-to-image translation and beat baseline methods with the model size reduced by $1000\times$ and the training budget by $9\times$. In parallel, we present a gradient-based discriminative saliency method to interpret the translation dynamics which align with human behavior explicitly.  ",生成モデリングのエネルギーベースモデル（EBM）は、単一のネットをパラメーター化し、最尤推定によって直接トレーニングできます。単純さと扱いやすさにもかかわらず、現在のアプローチは学習が不安定であるか、多様で忠実度の高い画像を合成するのが困難です。多段階の粗いものから細かいものへの拡張およびサンプリング戦略、すなわちCF-EBMを介してEBMをトレーニングすることを提案します。学習手順を改善するために、効果的なネットアーキテクチャを提案し、スムーズなアクティベーションを適用することを提唱します。結果として得られるアプローチは計算効率が高く、EBMとスペクトル正規化GANの中で画像生成で最高のパフォーマンスを実現します。さらに、512個の512ピクセル画像を合成し、分布外検出を改善する最初の成功したEBMになるためのレシピを提供します。最後に、CF-EBMを片側の教師なし画像間変換に簡単に一般化し、モデルサイズを1000削減し、トレーニング予算を9削減して、ベースライン手法を打ち負かします。並行して、勾配ベースの識別法を提示します。人間の行動に明示的に一致する翻訳ダイナミクスを解釈するための顕著性メソッド。,5.5,
The Bootstrap Framework: Generalization Through the Lens of Online Optimization,"['Preetum Nakkiran', 'Behnam Neyshabur', 'Hanie Sedghi']",https://openreview.net/forum?id=guetrIHLFGI,"We propose a new framework for reasoning about generalization in deep learning. 
The core idea is to couple the Real World, where optimizers take stochastic gradient steps on the empirical loss, to an Ideal World, where optimizers take steps on the population loss. This leads to an alternate decomposition of test error into: (1) the Ideal World test error plus (2) the gap between the two worlds. If the gap (2) is universally small, this reduces the problem of generalization in offline learning to the problem of optimization in online learning.
We then give empirical evidence that this gap between worlds can be small in realistic deep learning settings, in particular supervised image classification. For example, CNNs generalize better than MLPs on image distributions in the Real World, but this is ""because"" they optimize faster on the population loss in the Ideal World. This suggests our framework is a useful tool for understanding generalization in deep learning, and lays the foundation for future research in this direction. ",深層学習における一般化について推論するための新しいフレームワークを提案します。中心的なアイデアは、オプティマイザーが経験的損失に対して確率的勾配ステップを実行する実世界と、オプティマイザーが人口減少に対してステップを実行する理想世界を結合することです。これにより、テストエラーが次のように交互に分解されます。（1）理想的な世界のテストエラーと（2）2つの世界の間のギャップ。ギャップ（2）が普遍的に小さい場合、これはオフライン学習の一般化の問題をオンライン学習の最適化の問題に減らします。次に、現実的な深層学習の設定、特に教師あり画像の分類では、この世界間のギャップが小さい可能性があるという経験的証拠を示します。たとえば、CNNは、実世界での画像分布に関してMLPよりも一般化が優れていますが、これは、理想世界での人口減少をより迅速に最適化するためです。これは、私たちのフレームワークが深層学習の一般化を理解するための有用なツールであることを示唆しており、この方向での将来の研究の基礎を築きます。,5.5,
Debiasing Concept Bottleneck Models with a Technique from Instrumental Variables,"['Mohammad Taha Bahadori', 'David Heckerman']",https://openreview.net/forum?id=6puUoArESGp,"Studying the concept-based explanation techniques, we provided evidences for potential existence of spurious association between the features and concepts due to  unobserved latent variables or noise. We proposed a new causal prior graph that models the impact of the noise and latent confounding fron the estimated concepts. We showed that using the labels as instruments, we can remove the impact of the context from the explanations. Our experiments showed that our debiasing technique not only improves the quality of the explanations, but also improve the accuracy of predicting labels through the concepts. As future work, we will investigate other two-stage-regression techniques to
find the most accurate debiasing method.",概念ベースの説明手法を研究し、観測されていない潜在変数またはノイズに起因する機能と概念の間に疑似相関が存在する可能性があるという証拠を提供しました。推定された概念からノイズと潜在的な交絡の影響をモデル化する新しい因果的事前グラフを提案しました。ラベルを道具として使用することで、説明から文脈の影響を取り除くことができることを示しました。私たちの実験は、私たちのバイアス除去技術が説明の質を向上させるだけでなく、概念を通してラベルを予測する精度も向上させることを示しました。今後の作業として、他の2段階回帰手法を調査し、最も正確なバイアス除去方法を見つけます。,5.5,
Federated Semi-Supervised Learning with Inter-Client Consistency & Disjoint Learning,"['Wonyong Jeong', 'Jaehong Yoon', 'Eunho Yang', 'Sung Ju Hwang']",https://openreview.net/forum?id=ce6CFXBh30h,"While existing federated learning approaches mostly require that clients have fully-labeled data to train on, in realistic settings, data obtained at the client-side often comes without any accompanying labels. Such deficiency of labels may result from either high labeling cost, or difficulty of annotation due to the requirement of expert knowledge. Thus the private data at each client may be either partly labeled, or completely unlabeled with labeled data being available only at the server, which leads us to a new practical federated learning problem, namely Federated Semi-Supervised Learning (FSSL). In this work, we study two essential scenarios of FSSL based on the location of the labeled data. The first scenario considers a conventional case where clients have both labeled and unlabeled data (labels-at-client), and the second scenario considers a more challenging case, where the labeled data is only available at the server (labels-at-server). We then propose a novel method to tackle the problems, which we refer to as Federated Matching (FedMatch). FedMatch improves upon naive combinations of federated learning and semi-supervised learning approaches with a new inter-client consistency loss and decomposition of the parameters for disjoint learning on labeled and unlabeled data. Through extensive experimental validation of our method in the two different scenarios, we show that our method outperforms both local semi-supervised learning and baselines which naively combine federated learning with semi-supervised learning.",既存のフェデレーション学習アプローチでは、ほとんどの場合、クライアントがトレーニングするために完全にラベル付けされたデータを持っている必要がありますが、現実的な設定では、クライアント側で取得されたデータにはラベルが付いていないことがよくあります。このようなラベルの欠陥は、高いラベル付けコスト、または専門知識の必要性による注釈の難しさに起因する可能性があります。したがって、各クライアントのプライベートデータは、部分的にラベル付けされるか、サーバーでのみ使用可能なラベル付きデータで完全にラベル付けされない可能性があります。これにより、新しい実用的なフェデレーション学習の問題、つまりフェデレーション半教師あり学習（FSSL）が発生します。この作業では、ラベル付けされたデータの場所に基づいて、FSSLの2つの重要なシナリオを調査します。最初のシナリオでは、クライアントにラベル付きデータとラベルなしデータの両方がある従来のケース（labels-at-client）を検討し、2番目のシナリオでは、ラベル付きデータがサーバーでのみ利用可能である（labels-at-server）より困難なケースを検討します。 。次に、問題に取り組むための新しい方法を提案します。これをFederated Matching（FedMatch）と呼びます。 FedMatchは、フェデレーション学習と半教師あり学習アプローチの素朴な組み合わせを改善し、新しいクライアント間の一貫性の喪失と、ラベル付きデータとラベルなしデータの非結合学習のパラメーターの分解を行います。 2つの異なるシナリオでの方法の広範な実験的検証を通じて、私たちの方法が、ローカルの半教師あり学習と、連合学習と半教師あり学習を素朴に組み合わせるベースラインの両方よりも優れていることを示します。,5.5,
A Geometric Analysis of Deep Generative Image Models and Its Applications,"['Binxu Wang', 'Carlos R Ponce']",https://openreview.net/forum?id=GH7QRzUDdXG,"Generative adversarial networks (GANs) have emerged as a powerful unsupervised method to model the statistical patterns of real-world data sets, such as natural images. These networks are trained to map random inputs in their latent space to new samples representative of the learned data. However, the structure of the latent space is hard to intuit due to its high dimensionality and the non-linearity of the generator, which limits the usefulness of the models. Understanding the latent space requires a way to identify input codes for existing real-world images (inversion), and a way to identify directions with known image transformations (interpretability). Here, we use a geometric framework to address both issues simultaneously. We develop an architecture-agnostic method to compute the Riemannian metric of the image manifold created by GANs. The eigen-decomposition of the metric isolates axes that account for different levels of image variability. An empirical analysis of several pretrained GANs shows that image variation around each position is concentrated along surprisingly few major axes (the space is highly anisotropic) and the directions that create this large variation are similar at different positions in the space (the space is homogeneous). We show that many of the top eigenvectors correspond to interpretable transforms in the image space, with a substantial part of eigenspace corresponding to minor transforms which could be compressed out. This geometric understanding unifies key previous results related to GAN interpretability. We show that the use of this metric allows for more efficient optimization in the latent space (e.g. GAN inversion) and facilitates unsupervised discovery of interpretable axes. Our results illustrate that defining the geometry of the GAN image manifold can serve as a general framework for understanding GANs. ",生成的敵対的ネットワーク（GAN）は、自然画像などの実世界のデータセットの統計パターンをモデル化するための強力な教師なし手法として登場しました。これらのネットワークは、潜在空間のランダムな入力を、学習したデータを表す新しいサンプルにマッピングするようにトレーニングされています。ただし、潜在空間の構造は、その高次元性とジェネレーターの非線形性のために直感的に理解するのが難しく、モデルの有用性が制限されます。潜在空間を理解するには、既存の実世界の画像の入力コードを特定する方法（反転）と、既知の画像変換を使用して方向を特定する方法（解釈可能性）が必要です。ここでは、幾何学的フレームワークを使用して、両方の問題に同時に対処します。 GANによって作成された画像多様体のリーマン計量を計算するためのアーキテクチャにとらわれない方法を開発します。メトリックの固有分解により、さまざまなレベルの画像変動を説明する軸が分離されます。いくつかの事前トレーニングされたGANの経験的分析は、各位置の周りの画像の変化が驚くほど少数の主軸に沿って集中し（空間は非常に異方性である）、この大きな変化を生み出す方向は空間の異なる位置で類似していることを示しています（空間は均一です） 。上位の固有ベクトルの多くが画像空間の解釈可能な変換に対応し、固有空間のかなりの部分が圧縮される可能性のあるマイナーな変換に対応することを示します。この幾何学的な理解は、GANの解釈可能性に関連する重要な以前の結果を統合します。このメトリックを使用すると、潜在空間でのより効率的な最適化（GAN反転など）が可能になり、解釈可能な軸の教師なし発見が容易になることを示します。私たちの結果は、GAN画像多様体の形状を定義することがGANを理解するための一般的なフレームワークとして役立つことを示しています。,5.5,
Nearest Neighbor Machine Translation,"['Urvashi Khandelwal', 'Angela Fan', 'Dan Jurafsky', 'Luke Zettlemoyer', 'Mike Lewis']",https://openreview.net/forum?id=7wCBOfJ8hJM,"We introduce $k$-nearest-neighbor machine translation ($k$NN-MT), which predicts tokens with a nearest-neighbor classifier over a large datastore of cached examples, using representations from a neural translation model for similarity search. This approach requires no additional training and scales to give the decoder direct access to billions of examples at test time, resulting in a highly expressive model that consistently improves performance across many settings. Simply adding nearest-neighbor search improves a state-of-the-art German-English translation model by 1.5 BLEU. $k$NN-MT allows a single model to be adapted to diverse domains by using a domain-specific datastore, improving results by an average of 9.2 BLEU over zero-shot transfer, and achieving new state-of-the-art results---without training on these domains. A massively multilingual model can also be specialized for particular language pairs, with improvements of 3 BLEU for translating from English into German and Chinese. Qualitatively, $k$NN-MT is easily interpretable; it combines source and target context to retrieve highly relevant examples.",類似性検索のニューラル翻訳モデルからの表現を使用して、キャッシュされた例の大規模なデータストア上で最近傍分類器を使用してトークンを予測するk最近傍機械翻訳（kNN-MT）を紹介します。このアプローチでは、追加のトレーニングやスケールを必要とせず、デコーダーがテスト時に数十億の例に直接アクセスできるため、多くの設定で一貫してパフォーマンスが向上する表現力豊かなモデルが得られます。最近傍検索を追加するだけで、最先端のドイツ語-英語翻訳モデルが1.5BLEU向上します。 kNN-MTを使用すると、ドメイン固有のデータストアを使用して単一のモデルを多様なドメインに適合させ、ゼロショット転送で平均9.2 BLEUの結果を改善し、これらのドメインのトレーニングなしで新しい最先端の結果を達成できます。 。大規模な多言語モデルは、英語からドイツ語と中国語に翻訳するための3 BLEUの改善により、特定の言語ペアに特化することもできます。定性的には、kNN-MTは簡単に解釈できます。ソースコンテキストとターゲットコンテキストを組み合わせて、関連性の高い例を取得します。,5.5,
Robust Curriculum Learning: from clean label detection to noisy label self-correction,"['Tianyi Zhou', 'Shengjie Wang', 'Jeff Bilmes']",https://openreview.net/forum?id=lmTWnm3coJJ,"Neural network training can easily overfit noisy labels resulting in poor generalization performance. Existing methods address this problem by (1) filtering out the noisy data and only using the clean data for training or (2) relabeling the noisy data by the model during training or by another model trained only on a clean dataset. However, the former does not leverage the features' information of wrongly-labeled data, while the latter may produce wrong pseudo-labels for some data and introduce extra noises. In this paper, we propose a smooth transition and interplay between these two strategies as a curriculum that selects training samples dynamically. In particular, we start with learning from clean data and then gradually move to learn noisy-labeled data with pseudo labels produced by a time-ensemble of the model and data augmentations. Instead of using the instantaneous loss computed at the current step, our data selection is based on the dynamics of both the loss and output consistency for each sample across historical steps and different data augmentations, resulting in more precise detection of both clean labels and correct pseudo labels. On multiple benchmarks of noisy labels, we show that our curriculum learning strategy can significantly improve the test accuracy without any auxiliary model or extra clean data.",ニューラルネットワークトレーニングは、ノイズの多いラベルを簡単にオーバーフィットし、一般化のパフォーマンスを低下させる可能性があります。既存の方法は、（1）ノイズの多いデータを除外し、トレーニングにクリーンなデータのみを使用するか、（2）トレーニング中のモデル、またはクリーンなデータセットのみでトレーニングされた別のモデルによってノイズの多いデータにラベルを付け直すことで、この問題に対処します。ただし、前者は誤ってラベル付けされたデータの機能情報を活用しませんが、後者は一部のデータに対して誤った疑似ラベルを生成し、余分なノイズを導入する可能性があります。本稿では、トレーニングサンプルを動的に選択するカリキュラムとして、これら2つの戦略間のスムーズな移行と相互作用を提案します。特に、クリーンなデータから学習することから始めて、モデルの時間アンサンブルとデータ拡張によって生成された疑似ラベルを使用して、ノイズの多いラベル付きデータを学習するように徐々に移行します。現在のステップで計算された瞬間的な損失を使用する代わりに、データの選択は、履歴ステップとさまざまなデータ拡張にわたる各サンプルの損失と出力の一貫性の両方のダイナミクスに基づいており、クリーンなラベルと正しい疑似の両方をより正確に検出します。ラベル。ノイズの多いラベルの複数のベンチマークで、カリキュラム学習戦略により、補助モデルや余分なクリーンデータがなくてもテストの精度が大幅に向上することを示しています。,5.5,
Fast and Complete: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers,"['Kaidi Xu', 'Huan Zhang', 'Shiqi Wang', 'Yihan Wang', 'Suman Jana', 'Xue Lin', 'Cho-Jui Hsieh']",https://openreview.net/forum?id=nVZtXBI6LNn,"Formal verification of neural networks (NNs) is a challenging and important problem. Existing efficient complete solvers typically require the branch-and-bound (BaB) process, which splits the problem domain into sub-domains and solves each sub-domain using faster but weaker incomplete verifiers, such as Linear Programming (LP) on linearly relaxed sub-domains.  In this paper, we propose to use the backward mode linear relaxation based perturbation analysis (LiRPA) to replace LP during the BaB process, which can be efficiently implemented on the typical machine learning accelerators such as GPUs and TPUs.  However, unlike LP, LiRPA when applied naively can produce much weaker bounds and even cannot check certain conflicts of sub-domains during splitting, making the entire procedure incomplete after BaB. To address these challenges, we apply a fast gradient based bound tightening procedure combined with batch splits and the design of minimal usage of LP bound procedure, enabling us to effectively use LiRPA on the accelerator hardware for the challenging complete NN verification problem and significantly outperform LP-based approaches. On a single GPU, we demonstrate an order of magnitude speedup compared to existing LP-based approaches.",ニューラルネットワーク（NN）のフォーマル検証は、困難で重要な問題です。既存の効率的な完全ソルバーは通常、分枝限定（BaB）プロセスを必要とします。このプロセスは、問題のドメインをサブドメインに分割し、線形緩和されたサブの線形計画法（LP）など、より高速で弱い不完全な検証子を使用して各サブドメインを解決します。 -ドメイン。この論文では、後方モード線形緩和ベースの摂動解析（LiRPA）を使用して、BaBプロセス中にLPを置き換えることを提案します。これは、GPUやTPUなどの一般的な機械学習アクセラレーターに効率的に実装できます。ただし、LPとは異なり、LiRPAを単純に適用すると、境界がはるかに弱くなり、分割中にサブドメインの特定の競合をチェックすることさえできず、BaB後に手順全体が不完全になります。これらの課題に対処するために、バッチ分割と組み合わせた高速勾配ベースのバウンド引き締め手順とLPバウンド手順の最小限の使用の設計を適用し、困難な完全なNN検証問題に対してアクセラレータハードウェアでLiRPAを効果的に使用し、LPを大幅に上回ります。ベースのアプローチ。単一のGPUで、既存のLPベースのアプローチと比較して桁違いのスピードアップを示します。,5.5,
Group Equivariant Conditional Neural Processes,"['Makoto Kawano', 'Wataru Kumagai', 'Akiyoshi Sannai', 'Yusuke Iwasawa', 'Yutaka Matsuo']",https://openreview.net/forum?id=e8W-hsu_q5,"We present the group equivariant conditional neural process (EquivCNP), a meta-learning method with permutation invariance in a data set as in conventional conditional neural processes (CNPs), and it also has transformation equivariance in data space. Incorporating group equivariance, such as rotation and scaling equivariance, provides a way to consider the symmetry of real-world data. We give a decomposition theorem for permutation-invariant and group-equivariant maps, which leads us to construct EquivCNPs with an infinite-dimensional latent space to handle group symmetries. In this paper, we build architecture using Lie group convolutional layers for practical implementation. We show that EquivCNP with translation equivariance achieves comparable performance to conventional CNPs in a 1D regression task. Moreover, we demonstrate that incorporating an appropriate Lie group equivariance, EquivCNP is capable of zero-shot generalization for an image-completion task by selecting an appropriate Lie group equivariance.",グループ同変条件付き神経プロセス（EquivCNP）を提示します。これは、従来の条件付き神経プロセス（CNP）と同様に、データセットに順列不変性を伴うメタ学習法であり、データ空間にも変換同変があります。回転やスケーリングの同変などのグループ同変を組み込むと、実世界のデータの対称性を考慮する方法が提供されます。順列不変および群同変写像の分解定理を与えます。これにより、群の対称性を処理するための無限次元の潜在空間を持つEquivCNPを構築できます。この論文では、実用的な実装のためにリー群畳み込み層を使用してアーキテクチャを構築します。翻訳同変のEquivCNPが、1D回帰タスクで従来のCNPと同等のパフォーマンスを達成することを示します。さらに、適切なリー群同変を組み込むことで、EquivCNPは、適切なリー群同変を選択することにより、画像補完タスクのゼロショット一般化が可能であることを示します。,5.5,
Learning from others' mistakes: Avoiding dataset biases without modeling them,"['Victor Sanh', 'Thomas Wolf', 'Yonatan Belinkov', 'Alexander M Rush']",https://openreview.net/forum?id=Hf3qXoiNkR,"State-of-the-art natural language processing (NLP) models often learn to model dataset biases and surface form correlations instead of features that target the intended underlying task. Previous work has demonstrated effective methods to circumvent these issues when knowledge of the bias is available. We consider cases where the bias issues may not be explicitly identified, and show a method for training models that learn to ignore these problematic correlations. Our approach relies on the observation that models with limited capacity primarily learn to exploit biases in the dataset. We can leverage the errors of such limited capacity models to train a more robust model in a product of experts, thus bypassing the need to hand-craft a biased model. We show the effectiveness of this method to retain improvements in out-of-distribution settings even if no particular bias is targeted by the biased model.",最先端の自然言語処理（NLP）モデルは、意図された基礎となるタスクを対象とする機能ではなく、データセットのバイアスと表面形状の相関関係をモデル化することを学ぶことがよくあります。以前の研究は、バイアスの知識が利用可能であるときにこれらの問題を回避するための効果的な方法を示しました。バイアスの問題が明示的に識別されない可能性がある場合を検討し、これらの問題のある相関を無視することを学習するモデルをトレーニングする方法を示します。私たちのアプローチは、容量が限られているモデルが主にデータセットのバイアスを利用することを学習するという観察に依存しています。このような限られた容量のモデルのエラーを活用して、専門家の製品でより堅牢なモデルをトレーニングできるため、偏ったモデルを手作りする必要がなくなります。バイアスモデルの対象となる特定のバイアスがない場合でも、配布外の設定の改善を維持するためのこの方法の有効性を示します。,5.5,https://d3i71xaburhd42.cloudfront.net/734f85727161f27bc7b295f0140a905363202d3f/4-Figure1-1.png
CompOFA вЂ“ Compound Once-For-All Networks for Faster Multi-Platform Deployment,"['Manas Sahni', 'Shreya Varshini', 'Alind Khare', 'Alexey Tumanov']",https://openreview.net/forum?id=IgIk8RRT-Z,"The emergence of CNNs in mainstream deployment has necessitated methods to design and train efficient architectures tailored to maximize the accuracy under diverse hardware & latency constraints. To scale these resource-intensive tasks with an increasing number of deployment targets, Once-For-All (OFA) proposed an approach to jointly train several models at once with a constant training cost. However, this cost remains as high as 40-50 GPU days and also suffers from a combinatorial explosion of potentially sub-optimal model configurations. We find that the cost of this one-shot training is dependent on the size of the model design space, and hence seek to speed up the training by constraining the design space to configurations with better accuracy-latency trade-offs. We incorporate the insights of compound relationships between model dimensions to build CompOFA, a design space smaller by several orders of magnitude. Through experiments on ImageNet, we demonstrate that even with simple heuristics we can achieve a 2x reduction in training time and 216x speedup in model search/extraction time compared to the state of the art, without loss of Pareto optimality! We also show that this smaller design space is dense enough to support equally accurate models for similar diversity of hardware and latency targets, while also reducing the complexity of the training and subsequent extraction algorithms. Source code is at https//github.com/compofa-blind-review/compofa-iclr21",主流の展開におけるCNNの出現により、さまざまなハードウェアと遅延の制約の下で精度を最大化するように調整された効率的なアーキテクチャを設計およびトレーニングする方法が必要になりました。展開ターゲットの数が増えるにつれてこれらのリソースを大量に消費するタスクを拡張するために、Once-For-All（OFA）は、一定のトレーニングコストで複数のモデルを同時にトレーニングするアプローチを提案しました。ただし、このコストは40〜50 GPU日と高いままであり、最適ではない可能性のあるモデル構成の組み合わせ爆発にも悩まされています。このワンショットトレーニングのコストはモデルの設計スペースのサイズに依存することがわかりました。したがって、精度と遅延のトレードオフが優れた構成に設計スペースを制約することで、トレーニングを高速化しようとしています。モデルの次元間の複合関係の洞察を取り入れて、CompOFAを構築します。これは、数桁小さい設計空間です。 ImageNetでの実験を通じて、単純なヒューリスティックを使用しても、パレート最適性を失うことなく、最先端のモデル検索/抽出時間と比較して、トレーニング時間の2分の1の短縮とモデル検索/抽出時間の216倍の高速化を達成できることを示します。また、この小さな設計スペースは、トレーニングとその後の抽出アルゴリズムの複雑さを軽減しながら、ハードウェアとレイテンシーのターゲットの同様の多様性に対して同等に正確なモデルをサポートするのに十分な密度であることも示しています。ソースコードはhttps // github.com / compofa-blind-review / compofa-iclr21にあります,5.5,
Prototypical Representation Learning for Relation Extraction,"['Ning Ding', 'Xiaobin Wang', 'Yao Fu', 'Guangwei Xu', 'Rui Wang', 'Pengjun Xie', 'Ying Shen', 'Fei Huang', 'Hai-Tao Zheng', 'Rui Zhang']",https://openreview.net/forum?id=aCgLmfhIy_f,"Recognizing relations between entities is a pivotal task of relational learning.  Previously, the learning of relation representations from unstructured entity-linked corpora is less studied because of the rich, complicated expressions of relations in human language.  This paper aims to learn predictive, interpretable, and robust relation representations from textual data that are effective in different settings, including supervised, distantly supervised, and few-shot learning.  Instead of solely relying on the supervision from labels (which could be noisy), we propose to infer a latent prototype for each relation from contextual information to best explore the intrinsic semantics of relations.  Prototypes are representations in a latent space abstracting canonical relevance between entities in the textual data. We learn the prototypes with a collaborative metric learning approach that uses hybrid metric functions to measure prototype-statement and statement-statement similarities. With the collaborative strategy, this approach not only helps us to train effective encoders but also outputs meaningful, interpretable latent prototypes for the final classification. Experimental results on several relation learning tasks show that our model significantly outperforms the previous state-of-the-art models. ",エンティティ間の関係を認識することは、関係学習の極めて重要なタスクです。以前は、非構造化エンティティにリンクされたコーパスからの関係表現の学習は、人間の言語での関係の豊かで複雑な表現のためにあまり研究されていませんでした。このペーパーは、教師あり学習、遠隔教師あり学習、数ショット学習など、さまざまな設定で効果的なテキストデータから、予測的で解釈可能で堅牢な関係表現を学習することを目的としています。ラベルからの監視（ノイズが多い可能性があります）だけに依存するのではなく、コンテキスト情報から各関係の潜在的なプロトタイプを推測して、関係の固有のセマンティクスを最もよく調査することを提案します。プロトタイプは、テキストデータ内のエンティティ間の標準的な関連性を抽象化する潜在空間での表現です。ハイブリッドメトリック関数を使用してプロトタイプステートメントとステートメントステートメントの類似性を測定する協調メトリック学習アプローチを使用して、プロトタイプを学習します。協調戦略により、このアプローチは、効果的なエンコーダーをトレーニングするのに役立つだけでなく、最終的な分類のために意味のある、解釈可能な潜在的なプロトタイプを出力します。いくつかの関係学習タスクの実験結果は、私たちのモデルが以前の最先端のモデルを大幅に上回っていることを示しています。,5.5,
NOVAS: Non-convex Optimization via Adaptive Stochastic Search for End-to-end Learning and Control,"['Ioannis Exarchos', 'Marcus Aloysius Pereira', 'Ziyi Wang', 'Evangelos Theodorou']",https://openreview.net/forum?id=Iw4ZGwenbXf,"In this work we propose the use of adaptive stochastic search as a building block for general, non-convex optimization operations within deep neural network architectures. Specifically, for an objective function located at some layer in the network and parameterized by some network parameters, we employ adaptive stochastic search to perform optimization over its output. This operation is differentiable and does not obstruct the passing of gradients during backpropagation, thus enabling us to incorporate it as a component in end-to-end learning. We study the proposed optimization module's properties and benchmark it against two existing alternatives on a synthetic energy-based structured prediction task, and further showcase its use in stochastic optimal control applications.",この作業では、ディープニューラルネットワークアーキテクチャ内の一般的な非凸最適化操作の構成要素として、適応確率検索の使用を提案します。具体的には、ネットワーク内のあるレイヤーに配置され、いくつかのネットワークパラメーターによってパラメーター化された目的関数の場合、適応確率検索を使用して、その出力に対して最適化を実行します。この操作は微分可能であり、バックプロパゲーション中の勾配の通過を妨げないため、エンドツーエンドの学習のコンポーネントとして組み込むことができます。提案された最適化モジュールのプロパティを研究し、合成エネルギーベースの構造化予測タスクで2つの既存の代替案に対してベンチマークし、確率的最適制御アプリケーションでの使用をさらに示します。,5.5,https://d3i71xaburhd42.cloudfront.net/cbeeaedf86db42d23ac0701fac273ebc51ac4f4a/6-Figure1-1.png
Mapping the Timescale Organization of Neural Language Models,"['Hsiang-Yun Sherry Chien', 'Jinhan Zhang', 'Christopher Honey']",https://openreview.net/forum?id=J3OUycKwz-,"In the human brain, sequences of language input are processed within a distributed and hierarchical architecture, in which higher stages of processing encode contextual information over longer timescales. In contrast, in recurrent neural networks which perform natural language processing, we know little about how the multiple timescales of contextual information are functionally organized. Therefore, we applied tools developed in neuroscience to map the ""processing timescales"" of individual units within a word-level LSTM language model. This timescale-mapping method assigned long timescales to units previously found to track long-range syntactic dependencies, and revealed a new cluster of previously unreported long-timescale units. Next, we explored the functional role of units by examining the relationship between their processing timescales and network connectivity. We identified two classes of long-timescale units: ""Controller"" units composed a densely interconnected subnetwork and strongly projected to the forget and input gates of the rest of the network, while ""integrator"" units showed the longest timescales in the network, and expressed projection profiles closer to the mean projection profile. Ablating integrator and controller units affected model performance at different position of a sentence, suggesting distinctive functions of these two sets of long-timescale units. Finally, we tested the generalization of these results to a character-level LSTM model. In summary, we demonstrated a model-free technique for mapping the timescale organization in neural network models, and we applied this method to reveal the timescale and functional organization of LSTM language models.",人間の脳では、言語入力のシーケンスは、分散された階層アーキテクチャ内で処理されます。このアーキテクチャでは、処理のより高い段階で、より長いタイムスケールでコンテキスト情報がエンコードされます。対照的に、自然言語処理を実行するリカレントニューラルネットワークでは、コンテキスト情報の複数のタイムスケールがどのように機能的に編成されているかについてはほとんどわかっていません。したがって、神経科学で開発されたツールを適用して、単語レベルのLSTM言語モデル内の個々のユニットの「処理タイムスケール」をマッピングしました。このタイムスケールマッピング方法は、長距離の構文依存関係を追跡することが以前に見つかったユニットに長いタイムスケールを割り当て、以前に報告されていない長いタイムスケールユニットの新しいクラスターを明らかにしました。次に、ユニットの処理タイムスケールとネットワーク接続の関係を調べることにより、ユニットの機能的役割を調査しました。ロングタイムスケールユニットの2つのクラスを特定しました。「コントローラー」ユニットは密に相互接続されたサブネットワークを構成し、ネットワークの他の部分の忘却ゲートと入力ゲートに強く投影されました。一方、「インテグレーター」ユニットはネットワークで最も長いタイムスケールを示し、表現されました。平均投影プロファイルに近い投影プロファイル。積分器とコントローラーのユニットを切除すると、文のさまざまな位置でモデルのパフォーマンスに影響が出て、これら2セットのロングタイムスケールユニットの特徴的な機能が示唆されました。最後に、これらの結果の文字レベルのLSTMモデルへの一般化をテストしました。要約すると、ニューラルネットワークモデルのタイムスケール構成をマッピングするためのモデルフリー手法を示し、この方法を適用して、LSTM言語モデルのタイムスケールと機能構成を明らかにしました。,5.5,
Learning Task Decomposition with Order-Memory Policy Network,"['Yuchen Lu', 'Yikang Shen', 'Siyuan Zhou', 'Aaron Courville', 'Joshua B. Tenenbaum', 'Chuang Gan']",https://openreview.net/forum?id=vcopnwZ7bC,"Many complex real-world tasks are composed of several levels of sub-tasks. Humans leverage these hierarchical structures to accelerate the learning process and achieve better generalization. To simulate this process, we introduce Ordered Memory Policy Network (OMPN) to discover task decomposition by imitation learning from demonstration. OMPN has an explicit inductive bias to model a hierarchy of sub-tasks. Experiments on Craft world and Dial demonstrate that our model can more accurately recover the task boundaries with behavior cloning under both unsupervised and weakly supervised setting than previous methods. OMPN can also be directly applied to partially observable environments and still achieve high performance. Our visualization further confirms the intuition that OMPN can learn to expand the memory at higher levels when one subtask is close to completion.",多くの複雑な実世界のタスクは、いくつかのレベルのサブタスクで構成されています。人間はこれらの階層構造を活用して、学習プロセスを加速し、より良い一般化を実現します。このプロセスをシミュレートするために、順序付きメモリポリシーネットワーク（OMPN）を導入して、デモンストレーションからの模倣学習によるタスク分解を発見します。 OMPNには、サブタスクの階層をモデル化するための明示的な誘導バイアスがあります。 Craft worldとDialでの実験は、私たちのモデルが、以前の方法よりも、教師なし設定と弱教師あり設定の両方での動作の複製により、タスクの境界をより正確に回復できることを示しています。 OMPNは、部分的に観察可能な環境に直接適用することもでき、それでも高いパフォーマンスを実現します。私たちの視覚化は、1つのサブタスクが完了に近づいたときに、OMPNがより高いレベルでメモリを拡張することを学習できるという直感をさらに確認します。,5.5,
High-Capacity Expert Binary Networks,"['Adrian Bulat', 'Brais Martinez', 'Georgios Tzimiropoulos']",https://openreview.net/forum?id=MxaY4FzOTa,"Network binarization is a promising hardware-aware direction for creating efficient deep models. Despite its memory and computational advantages, reducing the accuracy gap between such models and their real-valued counterparts remains an unsolved challenging research problem. To this end, we make the following 3 contributions: (a) To increase model capacity, we propose Expert Binary Convolution, which, for the first time, tailors conditional computing to binary networks by learning to select one data-specific expert binary filter at a time conditioned on input features. (b) To increase representation capacity, we propose to address the inherent information bottleneck in binary networks by introducing an efficient width expansion mechanism which keeps the binary operations within the same budget. (c) To improve network design, we propose a principled binary network search mechanism that unveils a set of network topologies of favorable properties. Overall, our method improves upon prior work, with no increase in computational cost by $\sim6 \%$, reaching a groundbreaking $\sim 71\%$ on ImageNet classification.",ネットワークの2値化は、効率的なディープモデルを作成するための有望なハードウェア対応の方向性です。そのメモリと計算上の利点にもかかわらず、そのようなモデルとそれらの実数値の対応物との間の精度のギャップを減らすことは、未解決の挑戦的な研究問題のままです。この目的のために、次の3つの貢献を行います。（a）モデルの容量を増やすために、Expert Binary Convolutionを提案します。これは、データ固有のエキスパートバイナリフィルターを1つ選択することを学習することにより、条件付きコンピューティングをバイナリネットワークに初めて調整します。入力機能を条件とする時間。 （b）表現能力を高めるために、二項演算を同じ予算内に保つ効率的な幅拡張メカニズムを導入することにより、二項ネットワークに固有の情報ボトルネックに対処することを提案します。 （c）ネットワーク設計を改善するために、好ましい特性のネットワークトポロジのセットを明らかにする原理的なバイナリネットワーク検索メカニズムを提案します。全体として、私たちの方法は、計算コストを6％増加させることなく、以前の作業を改善し、ImageNet分類で画期的な71％に達しました。,5.5,https://d3i71xaburhd42.cloudfront.net/14971262963bdb5897b74aebd4018fd55a6becdf/3-Figure1-1.png
Generative Scene Graph Networks,"['Fei Deng', 'Zhuo Zhi', 'Donghun Lee', 'Sungjin Ahn']",https://openreview.net/forum?id=RmcPm9m3tnk,"Human perception excels at building compositional hierarchies of parts and objects from unlabeled scenes that help systematic generalization. Yet most work on generative scene modeling either ignores the part-whole relationship or assumes access to predefined parts labels. In this paper, we propose Generative Scene Graph Networks (GSGNs), the first deep generative model that learns to discover the primitive parts and infer the part-whole relationship jointly from multi-object scenes without supervision and in an end-to-end trainable way. We formulate GSGN as a variational autoencoder in which the latent representation is a tree-structured probabilistic scene graph. The leaf nodes in the latent tree correspond to primitive parts, and the edges represent the symbolic pose variables required for recursively composing the parts into whole objects and then the full scene. This allows novel objects and scenes to be generated both by sampling from the prior and by manual configuration of the pose variables, as we do with graphics engines. We evaluate GSGN on datasets of scenes containing multiple compositional objects, including a challenging compositional CLEVR dataset that we have developed. We show that GSGN is able to infer the latent scene graph, generalize out of the training regime, and improve data efficiency in downstream tasks.",人間の知覚は、体系的な一般化に役立つラベルのないシーンからパーツやオブジェクトの構成階層を構築するのに優れています。しかし、生成シーンモデリングに関するほとんどの作業は、パーツ全体の関係を無視するか、事前定義されたパーツラベルへのアクセスを想定しています。この論文では、生成シーングラフネットワーク（GSGN）を提案します。これは、原始的な部分を発見し、監視なしでエンドツーエンドのトレーニング可能なマルチオブジェクトシーンから部分全体の関係を共同で推測することを学習する最初の深い生成モデルです。仕方。 GSGNは、潜在表現がツリー構造の確率的シーングラフである変分オートエンコーダーとして定式化されます。潜在ツリーのリーフノードはプリミティブパーツに対応し、エッジは、パーツをオブジェクト全体に、次にシーン全体に再帰的に構成するために必要なシンボリックポーズ変数を表します。これにより、グラフィックエンジンの場合と同様に、以前のサンプリングとポーズ変数の手動構成の両方によって、新しいオブジェクトとシーンを生成できます。私たちは、開発した挑戦的な構図CLEVRデータセットを含む、複数の構図オブジェクトを含むシーンのデータセットでGSGNを評価します。 GSGNが潜在的なシーングラフを推測し、トレーニング体制から一般化し、ダウンストリームタスクのデータ効率を向上させることができることを示します。,5.5,
Incremental few-shot learning via vector quantization in deep embedded space,"['Kuilin Chen', 'Chi-Guhn Lee']",https://openreview.net/forum?id=3SV-ZePhnZM,"The capability of incrementally learning new tasks without forgetting old ones is a challenging problem due to catastrophic forgetting. This challenge becomes greater when novel tasks contain very few labelled training samples. Currently, most methods are dedicated to class-incremental learning and rely on sufficient training data to learn additional weights for newly added classes. Those methods cannot be easily extended to incremental regression tasks and could suffer from severe overfitting when learning few-shot novel tasks. In this study, we propose a nonparametric method in deep embedded space to tackle incremental few-shot learning problems. The knowledge about the learned tasks are compressed into a small number of quantized reference vectors. The proposed method learns new tasks sequentially by adding more reference vectors to the model using few-shot samples in each novel task. For classification problems, we employ the nearest neighbor scheme to make classification on sparsely available data and incorporate intra-class variation, less forgetting regularization and calibration of reference vectors to mitigate catastrophic forgetting. In addition, the proposed learning vector quantization (LVQ) in deep embedded space can be customized as a kernel smoother to handle incremental few-shot regression tasks. Experimental results demonstrate that the proposed method outperforms other state-of-the-art methods in incremental learning.",古いタスクを忘れることなく新しいタスクを段階的に学習する機能は、壊滅的な忘却のために困難な問題です。この課題は、新しいタスクにラベル付きのトレーニングサンプルがほとんど含まれていない場合に大きくなります。現在、ほとんどのメソッドはクラス増分学習専用であり、新しく追加されたクラスの追加の重みを学習するために十分なトレーニングデータに依存しています。これらの方法は、増分回帰タスクに簡単に拡張することはできず、数ショットの新しいタスクを学習するときに深刻な過剰適合に悩まされる可能性があります。この研究では、増分数ショット学習問題に取り組むために、深い埋め込み空間でのノンパラメトリック手法を提案します。学習したタスクに関する知識は、少数の量子化された参照ベクトルに圧縮されます。提案された方法は、各新規タスクで数ショットのサンプルを使用してモデルに参照ベクトルを追加することにより、新しいタスクを順次学習します。分類問題については、最近傍スキームを使用して、まばらに利用可能なデータで分類を行い、クラス内変動を組み込み、壊滅的な忘却を軽減するための参照ベクトルの正則化とキャリブレーションを忘れにくくします。さらに、深い埋め込み空間で提案されている学習ベクトル量子化（LVQ）は、増分数ショット回帰タスクを処理するためのカーネルスムーザーとしてカスタマイズできます。実験結果は、提案された方法がインクリメンタル学習において他の最先端の方法よりも優れていることを示しています。,5.5,
Deep Learning meets Projective Clustering,"['Alaa Maalouf', 'Harry Lang', 'Daniela Rus', 'Dan Feldman']",https://openreview.net/forum?id=EQfpYwF3-b,"A common approach for compressing Natural Language Processing (NLP) networks is to encode the embedding layer as a matrix $A\in\mathbb{R}^{n\times d}$, compute its rank-$j$ approximation $A_j$ via SVD (Singular Value Decomposition), and then factor $A_j$ into a pair of matrices that correspond to smaller fully-connected layers to replace the original embedding layer. Geometrically, the rows of $A$ represent points in $\mathbb{R}^d$, and the rows of $A_j$ represent their projections onto the $j$-dimensional subspace that minimizes the sum of squared distances (``errors'') to the points. 
In practice, these rows of $A$ may be spread around $k>1$ subspaces, so factoring $A$ based on a single subspace may lead to large errors that turn into large drops in accuracy.

Inspired by \emph{projective clustering} from computational geometry,  we suggest replacing this subspace by a set of $k$ subspaces, each of dimension $j$, that minimizes the sum of squared distances over every point (row in $A$) to its \emph{closest} subspace. Based on this approach, we provide a novel architecture that replaces the original embedding layer by a set of $k$ small layers that operate in parallel and are then recombined with a single fully-connected layer. 

Extensive experimental results on the GLUE benchmark yield networks that are both more accurate and smaller compared to the standard matrix factorization (SVD). For example, we further compress DistilBERT by reducing the size of the embedding layer by $40\%$ while incurring only a $0.5\%$ average drop in accuracy over all nine GLUE tasks, compared to a $2.8\%$ drop using the existing SVD approach.
On RoBERTa we achieve $43\%$ compression of the embedding layer with less than a $0.8\%$ average drop in accuracy as compared to a $3\%$ drop previously.",自然言語処理（NLP）ネットワークを圧縮するための一般的なアプローチは、埋め込み層を行列AR ^（nd）としてエンコードし、SVD（特異値分解）を介してそのランクj近似A（j）を計算し、次に因子A（ j）元の埋め込み層を置き換えるために、より小さな完全に接続された層に対応するマトリックスのペアに。幾何学的には、Aの行はR ^（d）の点を表し、A（j）の行は、点までの距離の2乗（エラー）の合計を最小化するj次元部分空間への射影を表します。実際には、これらのAの行はk&gt; 1の部分空間の周りに広がる可能性があるため、単一の部分空間に基づいてAを因数分解すると、大きなエラーが発生し、精度が大幅に低下する可能性があります。計算幾何学からの射影クラスタリングに触発されて、この部分空間を、各点（Aの行）から最も近い部分空間までの距離の2乗の合計を最小化するk個の部分空間のセット（それぞれ次元j）で置き換えることをお勧めします。このアプローチに基づいて、元の埋め込みレイヤーを、並列に動作し、完全に接続された単一のレイヤーと再結合されるk個の小さなレイヤーのセットに置き換える新しいアーキテクチャを提供します。 GLUEベンチマークに関する広範な実験結果により、標準の行列因数分解（SVD）と比較して、より正確で小さいネットワークが得られます。たとえば、埋め込みレイヤーのサイズを40％削減することで、DistilBERTをさらに圧縮しますが、既存のSVDアプローチを使用した場合の2.8％の低下と比較して、9つのGLUEタスクすべてで平均精度の低下はわずか0.5％です。 RoBERTaでは、以前の3％の低下と比較して、0.8％未満の平均精度低下で埋め込み層の43％の圧縮を達成しています。,5.33,https://d3i71xaburhd42.cloudfront.net/a80029ac0fd89bd0296d3d1f440ad8247f027b72/2-Figure1-1.png
Exploring Balanced Feature Spaces for Representation Learning,"['Bingyi Kang', 'Yu Li', 'Sa Xie', 'Zehuan Yuan', 'Jiashi Feng']",https://openreview.net/forum?id=OqtLIabPTit,"Existing self-supervised learning (SSL) methods are mostly applied for training representation models from artificially balanced datasets (e.g., ImageNet). It is unclear how well they will perform in the practical scenarios where datasets are often imbalanced w.r.t. the classes. Motivated by this question, we conduct a series of studies on the performance of self-supervised contrastive learning and supervised learning methods over multiple datasets where training instance distributions vary from a balanced one to a long-tailed one. Our findings are quite intriguing. Different from supervised methods with large performance drop, the self-supervised contrastive learning methods perform stably well even when the datasets are heavily imbalanced. This motivates us to explore the balanced feature spaces learned by contrastive learning, where the feature representations present similar linear separability w.r.t. all the classes. Our further experiments reveal that a representation model generating a balanced feature space can generalize better than that yielding an imbalanced one across multiple settings. Inspired by these insights, we develop a novel representation learning method, called $k$-positive contrastive learning. It effectively combines strengths of the supervised method and the contrastive learning method to learn representations that are both discriminative and balanced. Extensive experiments demonstrate its superiority on multiple recognition tasks. Remarkably, it achieves new state-of-the-art on challenging long-tailed recognition benchmarks. Code and models will be released.",既存の自己教師あり学習（SSL）メソッドは、主に、人工的にバランスの取れたデータセット（ImageNetなど）から表現モデルをトレーニングするために適用されます。データセットがクラスに対して不均衡であることが多い実際のシナリオで、それらがどの程度うまく機能するかは不明です。この質問に動機付けられて、トレーニングインスタンスの分布がバランスの取れたものからロングテールのものまで変化する複数のデータセットに対して、教師あり対照学習と教師あり学習方法のパフォーマンスに関する一連の研究を実施します。私たちの調査結果は非常に興味深いものです。パフォーマンスの低下が大きい教師あり手法とは異なり、自己教師あり対照学習手法は、データセットのバランスが大きくない場合でも安定して良好に機能します。これにより、対照学習によって学習されたバランスの取れた特徴空間を探索するようになります。特徴表現は、すべてのクラスで同様の線形分離可能性を示します。私たちのさらなる実験は、バランスの取れた特徴空間を生成する表現モデルが、複数の設定にわたって不均衡なものを生成する表現モデルよりも一般化できることを明らかにしています。これらの洞察に触発されて、k-ポジティブ対照学習と呼ばれる新しい表現学習法を開発します。教師あり法と対照学習法の長所を効果的に組み合わせて、識別的でバランスの取れた表現を学習します。広範な実験は、複数の認識タスクにおけるその優位性を示しています。驚くべきことに、それは挑戦的なロングテール認識ベンチマークで新しい最先端を達成します。コードとモデルがリリースされます。,5.33,
Towards Impartial Multi-task Learning,"['Liyang Liu', 'Yi Li', 'Zhanghui Kuang', 'Jing-Hao Xue', 'Yimin Chen', 'Wenming Yang', 'Qingmin Liao', 'Wayne Zhang']",https://openreview.net/forum?id=IMPnRXEWpvr,"Abstract Multi-task learning (MTL) has been widely used in representation learning. However, naively training all tasks simultaneously may lead to the partial training issue, where specific tasks are trained more adequately than others. In this paper, we propose to learn multiple tasks impartially. Specifically, for the task-shared parameters, we optimize the scaling factors via a closed-form solution, such that the aggregated gradient (sum of raw gradients weighted by the scaling factors) has equal projections onto individual tasks. For the task-specific parameters, we dynamically weigh the task losses so that all of them are kept at a comparable scale. Further, we find the above gradient balance and loss balance are complementary and thus propose a hybrid balance method to further improve the performance. Our impartial multi-task learning (IMTL) can be end-to-end trained without any heuristic hyper-parameter tuning, and is general to be applied on all kinds of losses without any distribution assumption. Moreover, our IMTL can converge to similar results even when the task losses are designed to have different scales, and thus it is scale-invariant. We extensively evaluate our IMTL on the standard MTL benchmarks including Cityscapes, NYUv2 and CelebA. It achieves the new state-of-the-art among loss weighting methods under the same experimental settings.",抽象マルチタスク学習（MTL）は、表現学習で広く使用されています。ただし、すべてのタスクを同時に単純にトレーニングすると、特定のタスクが他のタスクよりも適切にトレーニングされる部分的なトレーニングの問題が発生する可能性があります。この論文では、複数のタスクを公平に学習することを提案します。具体的には、タスク共有パラメーターの場合、閉じた形式のソリューションを介してスケーリングファクターを最適化し、集約された勾配（スケーリングファクターによって重み付けされた生の勾配の合計）が個々のタスクに等しく投影されるようにします。タスク固有のパラメーターについては、タスクの損失を動的に重み付けして、すべてが同等のスケールに保たれるようにします。さらに、上記の勾配バランスと損失バランスは補完的であることがわかり、パフォーマンスをさらに向上させるためのハイブリッドバランス法を提案します。私たちの公平なマルチタスク学習（IMTL）は、ヒューリスティックなハイパーパラメーター調整なしでエンドツーエンドでトレーニングでき、一般に、分布を仮定せずにあらゆる種類の損失に適用されます。さらに、タスク損失が異なるスケールを持つように設計されている場合でも、IMTLは同様の結果に収束する可能性があるため、スケール不変です。私たちは、Cityscapes、NYUv2、CelebAなどの標準MTLベンチマークでIMTLを広範囲に評価します。これは、同じ実験設定の下で損失加重方法の中で新しい最先端を実現します。,5.33,
Effective Distributed Learning with Random Features: Improved Bounds and Algorithms,"['Yong Liu', 'Jiankun Liu', 'Shuqiang Wang']",https://openreview.net/forum?id=jxdXSW9Doc,"In this paper, we study the statistical properties of distributed kernel ridge regression together with random features (DKRR-RF), and obtain optimal generalization bounds under the basic setting, which can substantially relax the restriction on the number of local machines in the existing state-of-art bounds. Specifically, we first show that the simple combination of divide-and-conquer technique and random features can achieve the same statistical accuracy as the exact KRR in expectation requiring only $\mathcal{O}(|\mathcal{D}|)$ memory and $\mathcal{O}(|\mathcal{D}|^{1.5})$ time. Then, beyond the generalization bounds in expectation that demonstrate the average information for multiple trails, we derive generalization bounds in probability to capture the learning performance for a single trail. Finally, we propose an effective communication strategy to further improve the performance of DKRR-RF, and validate the theoretical bounds via numerical experiments.",本論文では、ランダム特徴（DKRR-RF）とともに分散カーネルリッジ回帰の統計的性質を研究し、既存の状態のローカルマシンの数の制限を大幅に緩和できる基本設定の下で最適な一般化限界を取得します。 -最先端の境界。具体的には、分割統治法とランダム機能の単純な組み合わせが、O（| D |）メモリとO（| D | ^（1.5）のみを必要とすることを期待して、正確なKRRと同じ統計精度を達成できることを最初に示します。 ）時間。次に、複数のトレイルの平均情報を示す期待値の一般化範囲を超えて、単一のトレイルの学習パフォーマンスをキャプチャする確率の一般化範囲を導出します。最後に、DKRR-RFのパフォーマンスをさらに向上させるための効果的な通信戦略を提案し、数値実験によって理論上の限界を検証します。,5.33,
One Network Fits All? Modular versus Monolithic Task Formulations in Neural Networks,"['Atish Agarwala', 'Abhimanyu Das', 'Brendan Juba', 'Rina Panigrahy', 'Vatsal Sharan', 'Xin Wang', 'Qiuyi Zhang']",https://openreview.net/forum?id=uz5uw6gM0m,"Can deep learning solve multiple, very different tasks simultaneously? We investigate how the representations of the underlying tasks affect the ability of a single neural network to learn them jointly. We present theoretical and empirical findings that a single neural network is capable of simultaneously learning multiple tasks from a combined data set, for a variety of methods for representing tasks---for example, when the distinct tasks are encoded by well-separated clusters or decision trees over some task-code attributes. Indeed, more strongly, we present a novel analysis that shows that families of simple programming-like constructs for the codes encoding the tasks are learnable by two-layer neural networks with standard training. We study more generally how the complexity of learning such combined tasks grows with the complexity of the task codes; we find that learning many tasks can be provably hard, even though the individual tasks are easy to learn. We provide empirical support for the usefulness of the learning bounds by training networks on clusters, decision trees, and SQL-style aggregation.",ディープラーニングは、複数の非常に異なるタスクを同時に解決できますか？基礎となるタスクの表現が、単一のニューラルネットワークがそれらを共同で学習する能力にどのように影響するかを調査します。単一のニューラルネットワークが、結合されたデータセットから複数のタスクを同時に学習できるという理論的および経験的発見を提示します。たとえば、個別のタスクが十分に分離されたクラスターまたはいくつかの決定木によってエンコードされている場合、タスクを表すためのさまざまな方法があります。タスクコード属性。実際、より強力に、タスクをエンコードするコードの単純なプログラミングのような構造のファミリーが、標準的なトレーニングを備えた2層ニューラルネットワークによって学習可能であることを示す新しい分析を提示します。このような組み合わせタスクの学習の複雑さがタスクコードの複雑さとともにどのように増大するかを、より一般的に研究します。個々のタスクは簡単に習得できますが、多くのタスクを習得するのは確かに難しいことがわかります。クラスター、決定木、およびSQLスタイルの集計でネットワークをトレーニングすることにより、学習範囲の有用性を実証的にサポートします。,5.25,
Contrastive  Learning  with Adversarial Perturbations for Conditional Text Generation,"['Seanie Lee', 'Dong Bok Lee', 'Sung Ju Hwang']",https://openreview.net/forum?id=Wga_hrCa3P3,"Recently, sequence-to-sequence (seq2seq) models with the Transformer architecture have achieved remarkable performance on various conditional text generation tasks, such as machine translation. However, most of them are trained with teacher forcing with the ground truth label given at each time step, without being exposed to incorrectly generated tokens during training, which hurts its generalization to unseen inputs, that is known as the ""exposure bias"" problem. In this work, we propose to solve the conditional text generation problem by contrasting positive pairs with negative pairs, such that the model is exposed to various valid or incorrect perturbations of the inputs, for improved generalization. However, training the model with naïve contrastive learning framework using random non-target sequences as negative examples is suboptimal, since they are easily distinguishable from the correct output, especially so with models pretrained with large text corpora. Also, generating positive examples requires domain-specific augmentation heuristics which may not generalize over diverse domains. To tackle this problem, we propose a principled method to generate positive and negative samples for contrastive learning of seq2seq models. Specifically, we generate negative examples by adding small perturbations to the input sequence to minimize its conditional likelihood, and positive examples by adding  large perturbations while enforcing it to have a high conditional likelihood. Such `""hard'' positive and negative pairs generated using our method guides the model to better distinguish correct outputs from incorrect ones. We empirically show that our proposed method significantly improves the generalization of the seq2seq on three text generation tasks --- machine translation, text summarization, and question generation.",最近、Transformerアーキテクチャを使用したシーケンス間（seq2seq）モデルは、機械翻訳などのさまざまな条件付きテキスト生成タスクで優れたパフォーマンスを実現しました。ただし、それらのほとんどは、トレーニング中に誤って生成されたトークンにさらされることなく、各タイムステップで与えられたグラウンドトゥルースラベルを使用して教師に強制的にトレーニングされます。これは、「露出バイアス」問題として知られる、目に見えない入力への一般化を損ないます。この作業では、一般化を改善するために、モデルが入力のさまざまな有効または不正確な摂動にさらされるように、正のペアと負のペアを対比することによって、条件付きテキスト生成の問題を解決することを提案します。ただし、ランダムな非ターゲットシーケンスを否定的な例として使用して、素朴な対照学習フレームワークでモデルをトレーニングすることは、正しい出力と簡単に区別できるため、特に大きなテキストコーパスで事前トレーニングされたモデルでは最適ではありません。また、肯定的な例を生成するには、ドメイン固有の拡張ヒューリスティックが必要ですが、これは多様なドメインに一般化されていない可能性があります。この問題に取り組むために、seq2seqモデルの対照学習のために正と負のサンプルを生成する原理的な方法を提案します。具体的には、条件付き尤度を最小化するために入力シーケンスに小さな摂動を追加することによって負の例を生成し、高い条件付き尤度を持つように強制しながら大きな摂動を追加することによって正の例を生成します。このような「私たちの方法を使用して生成されたハードポジティブとネガティブのペアは、モデルが正しい出力と誤った出力をよりよく区別するように導きます。提案された方法が、機械翻訳、テキスト要約、質問の3つのテキスト生成タスクでseq2seqの一般化を大幅に改善することを経験的に示します世代。,5.25,https://d3i71xaburhd42.cloudfront.net/0e6756742dc2e0bac124801b5c65964abf652cf3/2-Figure1-1.png
Few-Shot Bayesian Optimization with Deep Kernel Surrogates,"['Martin Wistuba', 'Josif Grabocka']",https://openreview.net/forum?id=bJxgv5C3sYc,"Hyperparameter optimization (HPO) is a central pillar in the automation of machine learning solutions and is mainly performed via Bayesian optimization, where a parametric surrogate is learned to approximate the black box response function (e.g. validation error). Unfortunately, evaluating the response function is computationally intensive. As a remedy, earlier work emphasizes the need for transfer learning surrogates which learn to optimize hyperparameters for an algorithm from other tasks. In contrast to previous work, we propose to rethink HPO as a few-shot learning problem in which we train a shared deep surrogate model to quickly adapt (with few response evaluations) to the response function of a new task. We propose the use of a deep kernel network for a Gaussian process surrogate that is meta-learned in an end-to-end fashion in order to jointly approximate the response functions of a collection of training data sets. As a result, the novel few-shot optimization of our deep kernel surrogate leads to new state-of-the-art results at HPO compared to several recent methods on diverse metadata sets.",ハイパーパラメータ最適化（HPO）は、機械学習ソリューションの自動化の中心的な柱であり、主にベイズ最適化を介して実行されます。ベイズ最適化では、パラメトリックサロゲートが学習されてブラックボックス応答関数（検証エラーなど）が近似されます。残念ながら、応答関数の評価は計算量が多くなります。救済策として、以前の研究では、他のタスクからアルゴリズムのハイパーパラメータを最適化することを学習する転移学習サロゲートの必要性が強調されています。以前の作業とは対照的に、HPOを数ショットの学習問題として再考することを提案します。この問題では、共有の深い代理モデルをトレーニングして、新しいタスクの応答関数にすばやく適応します（応答評価はほとんどありません）。トレーニングデータセットのコレクションの応答関数を共同で近似するために、エンドツーエンドの方法でメタ学習されるガウス過程サロゲートにディープカーネルネットワークを使用することを提案します。その結果、ディープカーネルサロゲートの斬新な数ショットの最適化により、さまざまなメタデータセットに対する最近のいくつかの方法と比較して、HPOで新しい最先端の結果が得られます。,5.25,https://d3i71xaburhd42.cloudfront.net/aea3f03299ff0cfea9b394f5559aa1c173f9876f/5-Figure1-1.png
Incorporating Symmetry into Deep Dynamics Models for Improved Generalization,"['Rui Wang', 'Robin Walters', 'Rose Yu']",https://openreview.net/forum?id=wta_8Hx2KD,"Recent work has shown deep learning can accelerate the prediction of physical dynamics relative to numerical solvers. However, limited physical accuracy and an inability to generalize under distributional shift limit its applicability to the real world. We propose to improve accuracy and generalization by incorporating symmetries into convolutional neural networks. Specifically, we employ a variety of methods each tailored to enforce a different symmetry. Our models are both theoretically and experimentally robust to distributional shift by symmetry group transformations and enjoy favorable sample complexity. We demonstrate the advantage of our approach on a variety of physical dynamics including Rayleigh–Bénard convection and real-world ocean currents and temperatures. Compare with image or text applications, our work is a significant step towards applying equivariant neural networks to high-dimensional systems with complex dynamics.",最近の研究では、深層学習が数値ソルバーと比較して物理ダイナミクスの予測を加速できることが示されています。ただし、物理的な精度が制限され、分布シフトの下で一般化できないため、実世界への適用が制限されます。畳み込みニューラルネットワークに対称性を組み込むことにより、精度と一般化を改善することを提案します。具体的には、それぞれが異なる対称性を強制するように調整されたさまざまな方法を採用しています。私たちのモデルは、対称群変換による分布シフトに対して理論的および実験的に堅牢であり、サンプルの複雑さが良好です。 RayleighBenard対流や実際の海流と温度など、さまざまな物理ダイナミクスに対するアプローチの利点を示します。画像やテキストのアプリケーションと比較して、私たちの仕事は、複雑なダイナミクスを持つ高次元システムに同変ニューラルネットワークを適用するための重要なステップです。,5.25,https://d3i71xaburhd42.cloudfront.net/412d0b5aa97e0713259d203e76f8a57b0357e0c9/1-Figure1-1.png
Distributed Momentum for Byzantine-resilient Stochastic Gradient Descent,"['El Mahdi El Mhamdi', 'Rachid Guerraoui', 'Sébastien Rouault']",https://openreview.net/forum?id=H8UHdhWG6A3,"Byzantine-resilient Stochastic Gradient Descent (SGD) aims at shielding model training from Byzantine faults, be they ill-labeled training datapoints, software/hardware bugs, or malicious worker nodes in a distributed setting.
Two recent attacks have been challenging state-of-the-art defenses though, often successfully precluding the model from even fitting the training set.
The main identified weakness of current defenses is their requirement of a sufficiently low variance-norm ratio for the stochastic gradients.
We propose a practical method which, despite increasing the variance, reduces the variance-norm ratio, mitigating the identified weakness.
We assess the effectiveness of our method over 736 different training configurations, comprising the 2 state-of-the-art attacks and 6 defenses.
For confidence and reproducibility purposes, each configuration is run 5 times, with specified seeds (1 to 5), totalling 3680 runs.
In our experiments, when the attack is effective enough to decrease the highest observed top-1 cross-accuracy by at least 20% compared to the unattacked run, our technique systematically increases back the highest observed accuracy, and is able to recover at least 20% in more than 60% of the cases.",ビザンチン耐性確率的勾配降下法（SGD）は、ビザンチン障害からモデルトレーニングを保護することを目的としています。これらの障害は、ラベルの付いていないトレーニングデータポイント、ソフトウェア/ハードウェアのバグ、分散設定の悪意のあるワーカーノードなどです。最近の2つの攻撃は、最先端の防御に挑戦してきましたが、多くの場合、モデルがトレーニングセットに適合しないようにすることに成功しています。現在の防御の主な特定された弱点は、確率的勾配に対して十分に低い分散ノルム比の要件です。分散を増加させても、分散ノルム比を減少させ、特定された弱点を軽減する実用的な方法を提案します。 2つの最先端の攻撃と6つの防御を含む、736の異なるトレーニング構成での方法の有効性を評価します。信頼性と再現性の目的で、各構成は指定されたシード（1〜5）で5回実行され、合計3680回実行されます。私たちの実験では、攻撃が十分に効果的で、観測された最高のトップ1の交差精度を少なくとも20減少させる場合,5.25,
Communication in Multi-Agent Reinforcement Learning: Intention Sharing,"['Woojun Kim', 'Jongeui Park', 'Youngchul Sung']",https://openreview.net/forum?id=qpsl2dR9twy,"Communication is one of the core components for learning coordinated behavior in multi-agent systems.
In this paper, we propose a new communication scheme named  Intention Sharing (IS) for multi-agent reinforcement learning in order to enhance the coordination among agents. In the proposed IS scheme, each agent generates an imagined trajectory by modeling the environment dynamics and other agents' actions. The imagined trajectory is the simulated future trajectory of each agent based on the learned model of the environment dynamics and other agents and represents each agent's future action plan. Each agent compresses this imagined trajectory capturing its future action plan to generate its intention message for communication by applying an attention mechanism to learn the relative importance of the components in the imagined trajectory based on the received message from other agents. Numeral results show that the proposed IS scheme outperforms other communication schemes in multi-agent reinforcement learning.",コミュニケーションは、マルチエージェントシステムで協調行動を学習するためのコアコンポーネントの1つです。本論文では、エージェント間の調整を強化するために、マルチエージェント強化学習のための意図共有（IS）と呼ばれる新しいコミュニケーションスキームを提案する。提案されたISスキームでは、各エージェントは、環境のダイナミクスや他のエージェントのアクションをモデル化することにより、想像上の軌道を生成します。想像される軌道は、環境ダイナミクスおよび他のエージェントの学習モデルに基づいてシミュレートされた各エージェントの将来の軌道であり、各エージェントの将来の行動計画を表します。各エージェントは、他のエージェントから受信したメッセージに基づいて想像上の軌道内のコンポーネントの相対的な重要性を学習する注意メカニズムを適用することにより、コミュニケーションのための意図メッセージを生成するために、将来のアクションプランをキャプチャするこの想像上の軌道を圧縮します。数値結果は、提案されたISスキームが、マルチエージェント強化学習において他の通信スキームよりも優れていることを示しています。,5.25,
Solving Compositional Reinforcement Learning Problems via Task Reduction,"['Yunfei Li', 'Huazhe Xu', 'Yilin Wu', 'Xiaolong Wang', 'Yi Wu']",https://openreview.net/forum?id=9SS69KwomAM,"We propose a novel learning paradigm, Self-Imitation via Reduction (SIR), for solving compositional reinforcement learning problems. SIR is based on two core ideas: task reduction and self-imitation. Task reduction tackles a hard-to-solve task by actively reducing it to an easier task whose solution is known by the RL agent. Once the original hard task is successfully solved by task reduction, the agent naturally obtains a self-generated solution trajectory to imitate. By continuously collecting and imitating such demonstrations, the agent is able to progressively expand the solved subspace in the entire task space. Experiment results show that SIR can significantly accelerate and improve learning on a variety of challenging sparse-reward continuous-control problems with compositional structures.",構成強化学習問題を解決するための新しい学習パラダイム、還元による自己模倣（SIR）を提案します。 SIRは、タスクの削減と自己模倣という2つのコアアイデアに基づいています。タスク削減は、RLエージェントが解決策を知っているより簡単なタスクに積極的に削減することで、解決が難しいタスクに取り組みます。元のハードタスクがタスク削減によって正常に解決されると、エージェントは自然に自己生成されたソリューションの軌跡を取得して模倣します。このようなデモンストレーションを継続的に収集して模倣することにより、エージェントは、タスク空間全体で解決された部分空間を段階的に拡張できます。実験結果は、SIRが、構成構造に関するさまざまな困難なスパース報酬連続制御問題の学習を大幅に加速および改善できることを示しています。,5.25,
"For self-supervised learning, Rationality implies generalization, provably","['Yamini Bansal', 'Gal Kaplun', 'Boaz Barak']",https://openreview.net/forum?id=Srmggo3b3X6,"We prove a new upper bound on the generalization gap of classifiers that are obtained by first using self-supervision to learn a representation $r$ of the training~data, then fitting a simple (e.g., linear) classifier $g$ to the labels. Specifically, we show that (under the assumptions described below) the generalization gap of such classifiers tends to zero if $\mathsf{C}(g) \ll n$, where $\mathsf{C}(g)$ is an appropriately-defined measure of the complexity of the simple classifier $g$, and $n$ is the number of training samples. We stress that our bound is independent of the complexity of the representation $r$. 
We do not make any structural or conditional-independence  assumptions on the representation-learning task, which can use the same training dataset that is later used for classification. Rather, we assume that the training procedure satisfies certain natural noise-robustness (adding small amount of label noise causes small degradation in performance) and  rationality  (getting the wrong label is not better than getting no label at all) conditions that widely (and sometimes provably) hold across many standard architectures. We show that our bound is non-vacuous for many popular representation-learning based classifiers on CIFAR-10 and ImageNet, including SimCLR, AMDIM and BigBiGAN.",最初に自己監視を使用してトレーニングデータの表現rを学習し、次に単純な（たとえば線形）分類器gをラベルに適合させることによって得られる分類器の一般化ギャップの新しい上限を証明します。具体的には、（以下で説明する仮定の下で）C（g）nの場合、そのような分類器の一般化ギャップはゼロになる傾向があることを示します。ここで、C（g）は、単純な分類器gの複雑さの適切に定義された尺度です。トレーニングサンプルの数です。私たちの限界は表現rの複雑さに依存しないことを強調します。後で分類に使用されるのと同じトレーニングデータセットを使用できる表現学習タスクについて、構造的または条件付き独立性の仮定を行いません。むしろ、トレーニング手順は、特定の自然ノイズロバスト性（少量のラベルノイズを追加するとパフォーマンスがわずかに低下する）と合理性（ラベルをまったく取得しないよりも良い方法ではない）の条件を広く（場合によっては）満たすと想定していますおそらく）多くの標準アーキテクチャにまたがって保持します。 SimCLR、AMDIM、BigBiGANなど、CIFAR-10およびImageNet上の多くの一般的な表現学習ベースの分類器の境界が空虚でないことを示します。,5.25,https://d3i71xaburhd42.cloudfront.net/e2c80fd059ba9986da37e498330979dc5976beb7/2-Figure1-1.png
Explainable Subgraph Reasoning for Forecasting on Temporal Knowledge Graphs,"['Zhen Han', 'Peng Chen', 'Yunpu Ma', 'Volker Tresp']",https://openreview.net/forum?id=pGIHq1m7PU,"Interest has been rising lately towards modeling time-evolving knowledge graphs (KGs). Recently, graph representation learning approaches have become the dominant paradigm for link prediction on temporal KGs. However, the embedding-based approaches largely operate in a black-box fashion, lacking the ability to judge the results' reliability. This paper provides a future link forecasting framework that reasons over query-relevant subgraphs of temporal KGs and jointly models the graph structures and the temporal context information. Especially, we propose a temporal relational attention mechanism and a novel reverse representation update scheme to guide the extraction of an enclosing subgraph around the query. The subgraph is expanded by an iterative sampling of temporal neighbors and attention propagation. As a result, our approach provides human-understandable arguments for the prediction. We evaluate our model on four benchmark temporal knowledge graphs for the link forecasting task. While being more explainable, our model also obtains a relative improvement of up to 17.7 $\%$ on MRR compared to the previous best KG forecasting methods. We also conduct a survey with 53 respondents, and the results show that the reasoning arguments extracted by the model for knowledge forecasting are aligned with human understanding. ",最近、時間進化する知識グラフ（KG）のモデリングに対する関心が高まっています。最近、グラフ表現学習アプローチは、時間的KGのリンク予測の主要なパラダイムになっています。ただし、埋め込みベースのアプローチは主にブラックボックス方式で動作し、結果の信頼性を判断する機能がありません。このペーパーは、時間的KGのクエリ関連サブグラフを推論し、グラフ構造と時間的コンテキスト情報を共同でモデル化する将来のリンク予測フレームワークを提供します。特に、クエリの周囲のサブグラフの抽出をガイドするために、時間的関係注意メカニズムと新しい逆表現更新スキームを提案します。サブグラフは、時間的近傍の反復サンプリングと注意の伝播によって拡張されます。結果として、私たちのアプローチは、予測のための人間が理解できる議論を提供します。リンク予測タスクの4つのベンチマーク時間知識グラフでモデルを評価します。より説明しやすい一方で、私たちのモデルは、以前の最良のKG予測方法と比較して、MRRで最大17.7％の相対的な改善も得ています。また、53名の回答者を対象に調査を実施した結果、知識予測モデルによって抽出された推論の議論は、人間の理解と一致していることが示されました。,5.2,
Are wider nets better given the same number of parameters?,"['Anna Golubeva', 'Guy Gur-Ari', 'Behnam Neyshabur']",https://openreview.net/forum?id=_zx8Oka09eF,"Empirical studies demonstrate that the performance of neural networks improves with increasing number of parameters. In most of these studies, the number of parameters is increased by increasing the network width. This begs the question: Is the observed improvement due to the larger number of parameters, or is it due to the larger width itself? We compare different ways of increasing model width while keeping the number of parameters constant. We show that for models initialized with a random, static sparsity pattern in the weight tensors, network width is the determining factor for good performance, while the number of weights is secondary, as long as the model achieves high training accuarcy. As a step towards understanding this effect, we analyze these models in the framework of Gaussian Process kernels. We find that the distance between the sparse finite-width model kernel and the infinite-width kernel at initialization is indicative of model performance.",経験的研究は、ニューラルネットワークのパフォーマンスがパラメータの数の増加とともに向上することを示しています。これらの研究のほとんどでは、ネットワーク幅を増やすことによってパラメータの数が増えます。これは疑問を投げかけます：パラメータの数が多いために観察された改善ですか、それとも幅自体が大きいためですか？パラメータの数を一定に保ちながら、モデルの幅を増やすさまざまな方法を比較します。重みテンソルのランダムで静的なスパースパターンで初期化されたモデルの場合、モデルが高いトレーニング精度を達成する限り、ネットワーク幅が良好なパフォーマンスの決定要因であり、重みの数は二次的であることを示します。この効果を理解するためのステップとして、ガウス過程カーネルのフレームワークでこれらのモデルを分析します。初期化時のスパース有限幅モデルカーネルと無限幅カーネルの間の距離は、モデルのパフォーマンスを示していることがわかります。,5.0,
Fantastic Four: Differentiable and Efficient Bounds on Singular Values of Convolution Layers,"['Sahil Singla', 'Soheil Feizi']",https://openreview.net/forum?id=JCRblSgs34Z,"In deep neural networks, the spectral norm of the Jacobian of a layer bounds the factor by which the norm of a signal changes during forward/backward propagation. Spectral norm regularizations have been shown to improve generalization, robustness and optimization of deep learning methods. Existing methods to compute the spectral norm of convolution layers either rely on heuristics that are efficient in computation but lack guarantees or are theoretically-sound but computationally expensive. In this work, we obtain the best of both worlds by deriving {\it four} provable upper bounds on the spectral norm of a standard 2D multi-channel convolution layer. These bounds are differentiable and can be computed efficiently during training with negligible overhead. One of these bounds is in fact the popular heuristic method of Miyato et al. (multiplied by a constant factor depending on filter sizes). Each of these four bounds can achieve the tightest gap depending on convolution filters. Thus, we propose to use the minimum of these four bounds as a tight, differentiable and efficient upper bound on the spectral norm of convolution layers. Moreover, our spectral bound is an effective regularizer and can be used to bound either the lipschitz constant or curvature values (eigenvalues of the Hessian) of neural networks. Through experiments on MNIST and CIFAR-10, we demonstrate the effectiveness of our spectral bound in improving generalization and robustness of deep networks.",ディープニューラルネットワークでは、層のヤコビアンのスペクトルノルムが、順方向/逆方向の伝搬中に信号のノルムが変化する係数を制限します。スペクトルノルムの正則化は、深層学習手法の一般化、堅牢性、および最適化を改善することが示されています。畳み込み層のスペクトルノルムを計算する既存の方法は、計算は効率的であるが保証がないヒューリスティックに依存しているか、理論的には健全であるが計算コストが高くなります。この作業では、標準の2Dマルチチャネル畳み込み層のスペクトルノルムで4つの証明可能な上限を導出することにより、両方の長所を取得します。これらの境界は微分可能であり、トレーニング中に無視できるオーバーヘッドで効率的に計算できます。これらの境界の1つは、実際、Miyato etal。の一般的なヒューリスティック手法です。 （フィルターサイズに応じて一定の係数を掛けます）。これらの4つの境界のそれぞれは、畳み込みフィルターに応じて最も狭いギャップを達成できます。したがって、これらの4つの境界の最小値を、畳み込み層のスペクトルノルムの厳密で微分可能かつ効率的な上限として使用することを提案します。さらに、スペクトル境界は効果的な正則化であり、ニューラルネットワークのリプシッツ定数または曲率値（ヘッセ行列の固有値）のいずれかを制限するために使用できます。 MNISTとCIFAR-10での実験を通じて、ディープネットワークの一般化と堅牢性の向上におけるスペクトル境界の有効性を示します。,5.0,
Graph Information Bottleneck for Subgraph Recognition,"['Junchi Yu', 'Tingyang Xu', 'Yu Rong', 'Yatao Bian', 'Junzhou Huang', 'Ran He']",https://openreview.net/forum?id=bM4Iqfg8M2k,"Given the input graph and its label/property, several key problems  of graph learning, such as finding interpretable subgraphs, graph denoising and graph compression,  can be  attributed to the fundamental problem of recognizing a subgraph of the original one.  This subgraph shall be as informative as possible, yet contains less redundant and noisy structure. This problem setting is closely related to the well-known information bottleneck (IB) principle, which, however, has less been studied for the irregular graph data and graph neural networks (GNNs). In this paper, we propose a framework of Graph Information Bottleneck (GIB) for the subgraph recognition problem in deep graph learning. Under this framework, one can recognize the maximally informative yet compressive subgraph, named IB-subgraph.  However, the GIB objective is notoriously hard to optimize, mostly due to the intractability of the mutual information of irregular graph data and the unstable optimization process. In order to tackle these challenges, we propose:  i) a GIB objective based-on a mutual information estimator for the irregular graph data; ii) a bi-level optimization scheme to maximize the GIB objective; iii) a connectivity loss to stabilize the optimization process. We evaluate the properties of the IB-subgraph in three application scenarios: improvement of graph classification, graph interpretation and graph denoising. Extensive experiments demonstrate that the information-theoretic  IB-subgraph  enjoys superior graph properties. ",入力グラフとそのラベル/プロパティを考えると、解釈可能なサブグラフの検索、グラフのノイズ除去、グラフの圧縮など、グラフ学習のいくつかの重要な問題は、元のサブグラフを認識するという根本的な問題に起因する可能性があります。このサブグラフは、可能な限り有益でありながら、冗長性が低く、ノイズの多い構造を含んでいる必要があります。この問題の設定は、よく知られている情報ボトルネック（IB）の原則と密接に関連していますが、不規則なグラフデータとグラフニューラルネットワーク（GNN）についてはあまり研究されていません。本論文では、深層グラフ学習における部分グラフ認識問題のためのグラフ情報ボトルネック（GIB）のフレームワークを提案する。このフレームワークの下で、IB-subgraphという名前の最大限に有益でありながら圧縮性のサブグラフを認識することができます。ただし、GIBの目的は、主に不規則なグラフデータの相互情報量の難しさと不安定な最適化プロセスのために、最適化が難しいことで有名です。これらの課題に取り組むために、私たちは以下を提案します。i）不規則なグラフデータの相互情報量推定量に基づくGIBの目的。 ii）GIBの目的を最大化するための2レベルの最適化スキーム。 iii）最適化プロセスを安定させるための接続損失。グラフ分類の改善、グラフ解釈、グラフノイズ除去の3つのアプリケーションシナリオでIBサブグラフのプロパティを評価します。広範な実験は、情報理論的なIBサブグラフが優れたグラフ特性を享受していることを示しています。,5.0,https://d3i71xaburhd42.cloudfront.net/1a901533b09269bafa1222ad5f2f5eb0279915ac/3-Figure1-1.png
Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets,"['Hayeon Lee', 'Eunyoung Hyung', 'Sung Ju Hwang']",https://openreview.net/forum?id=rkQuFUmUOg3,"Despite the success of recent Neural Architecture Search (NAS) methods on various tasks which have shown to output networks that largely outperform human-designed networks, conventional NAS methods have mostly tackled the optimization of searching for the network architecture for a single task (dataset), which does not generalize well across multiple tasks (datasets). Moreover, since such task-specific methods search for a neural architecture from scratch for every given task, they incur a large computational cost, which is problematic when the time and monetary budget are limited. In this paper, we propose an efficient NAS framework that is trained once on a database consisting of datasets and pretrained networks and can rapidly search a neural architecture for a novel dataset. The proposed MetaD2A (Meta Dataset-to-Architecture) model can stochastically generate graphs (architectures) from a given set (dataset) via a cross-modal latent space learned with amortized meta-learning. Moreover, we also propose a meta-performance predictor to estimate and select the best architecture from those sampled from MetaD2A. The experimental results demonstrate that our model meta-learned on subsets of ImageNet-1K and architectures from NAS-Bench 201 search space successfully generalizes to multiple benchmark datasets including CIFAR-10 and CIFAR-100, with the search time of less than 30 GPU seconds on CIFAR-10. We believe that the MetaD2A proposes a new research direction for rapid NAS as well as ways to utilize the knowledge from rich databases of datasets and architectures accumulated over the past years.",人間が設計したネットワークを大幅に上回るネットワークを出力することが示されているさまざまなタスクでの最近のニューラルアーキテクチャ検索（NAS）メソッドの成功にもかかわらず、従来のNASメソッドは主に単一タスク（データセット）のネットワークアーキテクチャの検索の最適化に取り組んできました。 、これは複数のタスク（データセット）間でうまく一般化されません。さらに、このようなタスク固有の方法は、特定のタスクごとにニューラルアーキテクチャを最初から検索するため、計算コストが高くなり、時間と予算が限られている場合に問題が発生します。この論文では、データセットと事前にトレーニングされたネットワークで構成されるデータベースで一度トレーニングされ、新しいデータセットのニューラルアーキテクチャを迅速に検索できる効率的なNASフレームワークを提案します。提案されたMetaD2A（Meta Dataset-to-Architecture）モデルは、償却されたメタ学習で学習されたクロスモーダル潜在空間を介して、特定のセット（データセット）からグラフ（アーキテクチャ）を確率的に生成できます。さらに、MetaD2Aからサンプリングされたアーキテクチャから最適なアーキテクチャを推定して選択するために、メタパフォーマンス予測子も提案します。実験結果は、ImageNet-1KのサブセットとNAS-Bench 201検索スペースのアーキテクチャでメタ学習されたモデルが、30GPU秒未満の検索時間でCIFAR-10とCIFAR-100を含む複数のベンチマークデータセットに正常に一般化されることを示しています。 CIFAR-10で。 MetaD2Aは、高速NASの新しい研究の方向性と、過去数年間に蓄積されたデータセットとアーキテクチャの豊富なデータベースからの知識を活用する方法を提案すると考えています。,5.0,
EEC: Learning to Encode and Regenerate Images for Continual Learning,"['Ali Ayub', 'Alan Wagner']",https://openreview.net/forum?id=lWaz5a9lcFU,"The two main impediments to continual learning are catastrophic forgetting and memory limitations on the storage of data. To cope with these challenges, we propose a novel, cognitively-inspired approach which trains autoencoders with Neural Style Transfer to encode and store images. Reconstructed images from encoded episodes are replayed when training the classifier model on a new task to avoid catastrophic forgetting. The loss function for the reconstructed images is weighted to reduce its effect during classifier training to cope with image degradation. When the system runs out of memory the encoded episodes are converted into centroids and covariance matrices, which are used to generate pseudo-images during classifier training, keeping classifier performance stable with less memory. Our approach increases classification accuracy by 13-17% over state-of-the-art methods on benchmark datasets, while requiring 78% less storage space.",継続的な学習に対する2つの主な障害は、壊滅的な忘却とデータの保存に関するメモリの制限です。これらの課題に対処するために、画像をエンコードして保存するためにニューラルスタイル転送を使用してオートエンコーダーをトレーニングする、新しい認知に触発されたアプローチを提案します。エンコードされたエピソードから再構成された画像は、壊滅的な忘却を回避するために、新しいタスクで分類器モデルをトレーニングするときに再生されます。再構成された画像の損失関数は、画像の劣化に対処するための分類器トレーニング中の影響を減らすために重み付けされます。システムのメモリが不足すると、エンコードされたエピソードは重心と共分散行列に変換されます。これらは、分類器のトレーニング中に疑似画像を生成するために使用され、より少ないメモリで分類器のパフォーマンスを安定させます。私たちのアプローチは、分類の精度を13〜17向上させます,4.67,https://d3i71xaburhd42.cloudfront.net/61d9f8e25d496b5f631279f823fa9af056d540a5/4-Figure1-1.png
