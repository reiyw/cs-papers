title,authors,arxiv_url,abstract,abstract_ja,figure1_or_table1
Multi-Domain Multi-Task Rehearsal for Lifelong Learning,"['Fan Lyu', 'Shuai Wang', 'Wei Feng', 'Zihan Ye', 'Fuyuan Hu', 'Song Wang']",https://arxiv.org/abs/2012.07236,"Rehearsal, seeking to remind the model by storing old knowledge in lifelong learning, is one of the most effective ways to mitigate catastrophic forgetting, i.e., biased forgetting of previous knowledge when moving to new tasks. However, the old tasks of the most previous rehearsal-based methods suffer from the unpredictable domain shift when training the new task. This is because these methods always ignore two significant factors. First, the Data Imbalance between the new task and old tasks that makes the domain of old tasks prone to shift. Second, the Task Isolation among all tasks will make the domain shift toward unpredictable directions; To address the unpredictable domain shift, in this paper, we propose Multi-Domain Multi-Task (MDMT) rehearsal to train the old tasks and new task parallelly and equally to break the isolation among tasks. Specifically, a two-level angular margin loss is proposed to encourage the intra-class/task compactness and inter-class/task discrepancy, which keeps the model from domain chaos. In addition, to further address domain shift of the old tasks, we propose an optional episodic distillation loss on the memory to anchor the knowledge for each old task. Experiments on benchmark datasets validate the proposed approach can effectively mitigate the unpredictable domain shift.",リハーサルは、生涯学習に古い知識を保存することでモデルを思い出させることを目的としており、壊滅的な忘却、つまり、新しいタスクに移動するときに以前の知識を偏って忘れることを軽減する最も効果的な方法の1つです。ただし、以前のリハーサルベースの方法の古いタスクは、新しいタスクをトレーニングするときに予測できないドメインシフトに悩まされます。これは、これらのメソッドが常に2つの重要な要素を無視するためです。まず、新しいタスクと古いタスクの間のデータの不均衡により、古いタスクのドメインがシフトしやすくなります。次に、すべてのタスク間でタスクを分離すると、ドメインが予測できない方向にシフトします。予測できないドメインシフトに対処するために、このホワイトペーパーでは、マルチドメインマルチタスク（MDMT）リハーサルを提案して、古いタスクと新しいタスクを並行して均等にトレーニングし、タスク間の分離を解消します。具体的には、クラス内/タスクのコンパクト性とクラス間/タスクの不一致を促進するために、2レベルの角度マージン損失が提案されます。これにより、モデルがドメインの混乱から保護されます。さらに、古いタスクのドメインシフトにさらに対処するために、各古いタスクの知識を固定するために、メモリ上のオプションの一時的な蒸留損失を提案します。ベンチマークデータセットでの実験は、提案されたアプローチが予測不可能なドメインシフトを効果的に軽減できることを検証します。,https://d3i71xaburhd42.cloudfront.net/22e06fa904f2022b63954a08543df4a2da63059e/1-Figure1-1.png
EfficientDeRain: Learning Pixel-Wise Dilation Filtering for High-Efficiency Single-Image Deraining,"['Qing Guo', 'Jingyang Sun', 'Felix Juefei-Xu', 'Lei Ma', 'Xiaofei Xie', 'Wei Feng', 'Yang Liu', 'Jianjun Zhao']",https://arxiv.org/abs/2009.09238,"Single-image deraining is rather challenging due to the unknown rain model. Existing methods often make specific assumptions of the rain model, which can hardly cover many diverse circumstances in the real world, making them have to employ complex optimization or progressive refinement. This, however, significantly affects these methods' efficiency and effectiveness for many efficiency-critical applications. To fill this gap, in this paper, we regard the single-image deraining as a general image-enhancing problem and originally propose a model-free deraining method, i.e., EfficientDeRain, which is able to process a rainy image within 10~ms (i.e., around 6~ms on average), over 80 times faster than the state-of-the-art method (i.e., RCDNet), while achieving similar de-rain effects. We first propose the novel pixel-wise dilation filtering. In particular, a rainy image is filtered with the pixel-wise kernels estimated from a kernel prediction network, by which suitable multi-scale kernels for each pixel can be efficiently predicted. Then, to eliminate the gap between synthetic and real data, we further propose an effective data augmentation method (i.e., RainMix) that helps to train network for real rainy image handling.We perform comprehensive evaluation on both synthetic and real-world rainy datasets to demonstrate the effectiveness and efficiency of our method. We release the model and code in this https URL.",雨のモデルが不明なため、単一画像の排水はかなり困難です。既存の方法は、雨モデルの特定の仮定を行うことが多く、現実世界の多くの多様な状況をカバーすることはほとんど不可能であるため、複雑な最適化または漸進的な改良を採用する必要があります。ただし、これは、多くの効率が重要なアプリケーションのこれらのメソッドの効率と有効性に大きく影響します。このギャップを埋めるために、この論文では、単一画像のドレインを一般的な画像強調問題と見なし、最初にモデルフリーのドレイン方法、つまり10ミリ秒以内に雨の画像を処理できるEfficientDeRainを提案します（つまり、 、平均で約6ミリ秒）、最先端の方法（つまり、RCDNet）よりも80倍以上高速でありながら、同様の雨水除去効果を実現します。最初に、新しいピクセル単位の膨張フィルタリングを提案します。特に、雨の画像は、カーネル予測ネットワークから推定されたピクセル単位のカーネルでフィルタリングされます。これにより、各ピクセルに適したマルチスケールカーネルを効率的に予測できます。次に、合成データと実際のデータのギャップをなくすために、実際の雨画像処理のためのネットワークのトレーニングに役立つ効果的なデータ拡張方法（RainMix）をさらに提案します。合成データセットと実際の雨データセットの両方について包括的な評価を実行します。私たちの方法の有効性と効率を示します。このhttpsURLでモデルとコードをリリースします。,https://d3i71xaburhd42.cloudfront.net/2fe2871e3e21a7ea79a2efa19d9b596749a8c0c5/1-Figure1-1.png
Understanding Deformable Alignment in Video Super-Resolution,"['Kelvin C.K. Chan', 'Xintao Wang', 'Ke Yu', 'Chao Dong', 'Chen Change Loy']",,,,
A SAT-Based Resolution of Lam's Problem,"['Curtis Bright', 'Kevin Cheung', 'Brett Stevens', 'Ilias Kotsireas', 'Vijay Ganesh']",https://arxiv.org/abs/2012.04715,"In 1989, computer searches by Lam, Thiel, and Swiercz experimentally resolved Lam's problem from projective geometry$\unicode{x2014}$the long-standing problem of determining if a projective plane of order ten exists. Both the original search and an independent verification in 2011 discovered no such projective plane. However, these searches were each performed using highly specialized custom-written code and did not produce nonexistence certificates. In this paper, we resolve Lam's problem by translating the problem into Boolean logic and use satisfiability (SAT) solvers to produce nonexistence certificates that can be verified by a third party. Our work uncovered consistency issues in both previous searches$\unicode{x2014}$highlighting the difficulty of relying on special-purpose search code for nonexistence results.",1989年、Lam、Thiel、およびSwierczによるコンピューター検索により、射影幾何学からLams問題が実験的に解決されました$ \ unicode {x2014} $ 10次の射影平面が存在するかどうかを判断するという長年の問題。 2011年の最初の検索と独立した検証の両方で、そのような射影平面は発見されませんでした。ただし、これらの検索はそれぞれ、高度に専門化されたカスタム作成コードを使用して実行され、存在しない証明書は生成されませんでした。このホワイトペーパーでは、問題をブール論理に変換することでLams問題を解決し、充足可能性（SAT）ソルバーを使用して、サードパーティが検証できる存在しない証明書を生成します。私たちの仕事は、以前の両方の検索で一貫性の問題を明らかにしました$ \ unicode {x2014} $存在しない結果について、特別な目的の検索コードに依存することの難しさを強調しています。,https://d3i71xaburhd42.cloudfront.net/90f75f22bf9788b2d00e528c9942e6e06ff818aa/3-Figure1-1.png
Nearest Neighbor Classifier Embedded Network for Active Learning,"['Fang Wan', 'Tianning Yuan', 'Mengying Fu', 'Xiangyang Ji', 'Qingming Huang', 'Qixiang Ye']",,,,
Shape-Pose Ambiguity in Learning 3D Reconstruction from Images,"['Yunjie Wu', 'Zhengxing Sun', 'Youcheng Song', 'Yunhan Sun', 'YiJie Zhong', 'Jinlong Shi']",,,,
Why Adversarial Interaction Creates Non-Homogeneous Patterns: A Pseudo-Reaction-Diffusion Model for Turing Instability,['Litu Rout'],https://arxiv.org/abs/2010.00521,"Long after Turing's seminal Reaction-Diffusion (RD) model, the elegance of his fundamental equations alleviated much of the skepticism surrounding pattern formation. Though Turing model is a simplification and an idealization, it is one of the best-known theoretical models to explain patterns as a reminiscent of those observed in nature. Over the years, concerted efforts have been made to align theoretical models to explain patterns in real systems. The apparent difficulty in identifying the specific dynamics of the RD system makes the problem particularly challenging. Interestingly, we observe Turing-like patterns in a system of neurons with adversarial interaction. In this study, we establish the involvement of Turing instability to create such patterns. By theoretical and empirical studies, we present a pseudo-reaction-diffusion model to explain the mechanism that may underlie these phenomena. While supervised learning attains homogeneous equilibrium, this paper suggests that the introduction of an adversary helps break this homogeneity to create non-homogeneous patterns at equilibrium. Further, we prove that randomly initialized gradient descent with over-parameterization can converge exponentially fast to an $\epsilon$-stationary point even under adversarial interaction. In addition, different from sole supervision, we show that the solutions obtained under adversarial interaction are not limited to a tiny subspace around initialization.",Turingsの独創的な反応拡散（RD）モデルのずっと後、彼の基本的な方程式の優雅さは、パターン形成を取り巻く懐疑論の多くを軽減しました。チューリングモデルは単純化と理想化ですが、自然界で観察されたパターンを彷彿とさせるパターンを説明するための最もよく知られた理論モデルの1つです。何年にもわたって、実際のシステムのパターンを説明するために理論モデルを調整するための協調的な努力がなされてきました。 RDシステムの特定のダイナミクスを特定することの明らかな難しさは、問題を特に困難にします。興味深いことに、敵対的な相互作用を持つニューロンのシステムでチューリングのようなパターンを観察します。この研究では、そのようなパターンを作成するためのチューリング不安定性の関与を確立します。理論的および経験的研究により、これらの現象の根底にあるメカニズムを説明するための疑似反応拡散モデルを提示します。教師あり学習は均一な平衡を達成しますが、この論文は、敵対者の導入がこの均一性を破り、平衡状態で不均一なパターンを作成するのに役立つことを示唆しています。さらに、過剰パラメータ化を使用してランダムに初期化された勾配降下法は、敵対的な相互作用の下でも、指数関数的に高速に停留点に収束できることを証明します。さらに、単独の監督とは異なり、敵対的な相互作用の下で得られたソリューションは、初期化の周りの小さな部分空間に限定されないことを示します。,https://d3i71xaburhd42.cloudfront.net/6c1f436852cfa88dec9b620125647bb7014ac2a7/12-Figure1-1.png
Building Interpretable Interaction Trees for Deep NLP Models,"['Die Zhang', 'HuiLin Zhou', 'Xiaoyi Bao', 'Da Huo', 'Ruizhao Chen', 'Hao Zhang', 'Xu Cheng', 'Mengyue Wu', 'Quanshi Zhang']",https://arxiv.org/abs/2007.04298,"This paper proposes a method to disentangle and quantify interactions among words that are encoded inside a DNN for natural language processing. We construct a tree to encode salient interactions extracted by the DNN. Six metrics are proposed to analyze properties of interactions between constituents in a sentence. The interaction is defined based on Shapley values of words, which are considered as an unbiased estimation of word contributions to the network prediction. Our method is used to quantify word interactions encoded inside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental results have provided a new perspective to understand these DNNs, and have demonstrated the effectiveness of our method.",この論文は、自然言語処理のためにDNN内でエンコードされた単語間の相互作用を解きほぐして定量化する方法を提案します。 DNNによって抽出された顕著な相互作用をエンコードするツリーを構築します。文中の構成要素間の相互作用の特性を分析するために、6つのメトリックが提案されています。相互作用は、単語のシャープレイ値に基づいて定義されます。これは、ネットワーク予測への単語の寄与の不偏推定と見なされます。私たちの方法は、BERT、ELMo、LSTM、CNN、およびTransformerネットワーク内でエンコードされた単語の相互作用を定量化するために使用されます。実験結果は、これらのDNNを理解するための新しい視点を提供し、私たちの方法の有効性を示しています。,
Revisiting Dominance Pruning in Decoupled Search,['Daniel Gnad'],,"In classical planning as heuristic search, duplicate state pruning is a standard method to avoid unnecessarily handling the same state multiple times. In decoupled search, similar to symbolic search approaches, search nodes, called decoupled states, do not correspond to individual states, but to entire sets of states. As a result, duplicate state pruning cannot be applied in a straightforward manner. Instead, dominance pruning is employed, taking into account the state sets. We observe that the time required for dominance checking dominates the overall runtime, and propose two ways of tackling this issue. Our main contribution (1) is a stronger variant of dominance checking for optimal planning, where efficiency and pruning power are most crucial. The new variant greatly improves the latter, without incurring a computational overhead. Furthermore, (2) we develop and implement three methods that make the dominance check more efficient: exact duplicate checking, which, albeit resulting in weaker pruning, can pay off due to the use of hashing; avoiding the dominance check when leaf state spaces are invertible; and exploiting the transitivity of the dominance relation to only check against the relevant subset of visited decoupled states. We show empirically that all our improvements are indeed beneficial across many standard benchmark domains.",ヒューリスティック検索としての古典的な計画では、重複状態のプルーニングは、同じ状態を不必要に複数回処理することを回避するための標準的な方法です。分離検索では、シンボリック検索アプローチと同様に、分離状態と呼ばれる検索ノードは、個々の状態ではなく、状態のセット全体に対応します。その結果、重複状態のプルーニングを簡単な方法で適用することはできません。代わりに、状態セットを考慮して、優勢剪定が採用されます。優位性チェックに必要な時間がランタイム全体を支配していることを確認し、この問題に取り組む2つの方法を提案します。私たちの主な貢献（1）は、効率と剪定力が最も重要である最適な計画のための優勢チェックのより強力な変形です。新しいバリアントは、計算のオーバーヘッドを発生させることなく、後者を大幅に改善します。さらに、（2）ドミナンスチェックをより効率的にする3つの方法を開発および実装します。正確な重複チェック。プルーニングは弱くなりますが、ハッシュを使用することで成果を上げることができます。葉の状態空間が可逆である場合の優位性チェックを回避します。優勢関係の推移性を利用して、訪問した分離状態の関連するサブセットに対してのみチェックします。私たちは、すべての改善が実際に多くの標準ベンチマークドメインにわたって有益であることを経験的に示しています。,https://d3i71xaburhd42.cloudfront.net/4e245d17f57bfbfd97319e6961d8d6f69be38c9b/4-Figure1-1.png
Meta-Transfer Learning for Low-Resource Abstractive Summarization,"['Yi-Syuan Chen', 'Hong-Han Shuai']",,,,
Structured Co-Reference Graph Attention for Video-Grounded Dialogue,"['Junyeong Kim', 'Sunjae Yoon', 'DaHyun Kim', 'Chang D. Yoo']",,,,
Dual-Octave Convolution for Accelerated Parallel MR Image Reconstruction,"['Chunmei Feng', 'Zhanyuan Yang', 'Geng Chen', 'Yong Xu', 'Ling Shao']",,,,
Interpretable Embedding Procedure Knowledge Transfer via Stacked Principal Component Analysis and Graph Neural Network,"['Seunghyun Lee', 'Byung Cheol Song']",,,,
NuQClq: An Effective Local Search Algorithm for Maximum Quasi-Clique Problem,"['Jiejiang Chen', 'Shaowei Cai', 'Shiwei Pan', 'Yiyuan Wang', 'Qingwei Lin', 'Mengyu Zhao', 'Minghao Yin']",,,,
MiniSeg: An Extremely Minimum Network for Efficient COVID-19 Segmentation,"['Yu Qiu', 'Yun Liu', 'Shijie Li', 'Jing Xu']",https://arxiv.org/abs/2004.09750,"The rapid spread of the new pandemic, coronavirus disease 2019 (COVID-19), has seriously threatened global health. The gold standard for COVID-19 diagnosis is the tried-and-true polymerase chain reaction (PCR), but PCR is a laborious, time-consuming and complicated manual process that is in short supply. Deep learning based computer-aided screening, e.g., infection segmentation, is thus viewed as an alternative due to its great successes in medical imaging. However, the publicly available COVID-19 training data are limited, which would easily cause overfitting of traditional deep learning methods that are usually data-hungry with millions of parameters. On the other hand, fast training/testing and low computational cost are also important for quick deployment and development of computer-aided COVID-19 screening systems, but traditional deep learning methods, especially for image segmentation, are usually computationally intensive. To address the above problems, we propose MiniSeg, a lightweight deep learning model for efficient COVID-19 segmentation. Compared with traditional segmentation methods, MiniSeg has several significant strengths: i) it only has 472K parameters and is thus not easy to overfit; ii) it has high computational efficiency and is thus convenient for practical deployment; iii) it can be fast retrained by other users using their private COVID-19 data for further improving performance. In addition, we build a comprehensive COVID-19 segmentation benchmark for comparing MiniSeg with traditional methods. Code and models will be released to promote the research and practical deployment for computer-aided COVID-19 screening.",新しいパンデミックであるコロナウイルス病2019（COVID-19）の急速な蔓延は、世界の健康を深刻に脅かしています。 COVID-19診断のゴールドスタンダードは、実証済みのポリメラーゼ連鎖反応（PCR）ですが、PCRは面倒で時間のかかる複雑な手動プロセスであり、不足しています。したがって、深層学習ベースのコンピュータ支援スクリーニング、たとえば感染セグメンテーションは、医用画像処理で大きな成功を収めているため、代替手段と見なされています。ただし、公開されているCOVID-19トレーニングデータは限られているため、通常は数百万のパラメータでデータを大量に消費する従来の深層学習手法の過剰適合が発生しやすくなります。一方、コンピュータ支援COVID-19スクリーニングシステムの迅速な展開と開発には、高速なトレーニング/テストと低い計算コストも重要ですが、従来の深層学習方法、特に画像セグメンテーションは、通常、計算量が多くなります。上記の問題に対処するために、効率的なCOVID-19セグメンテーションのための軽量ディープラーニングモデルであるMiniSegを提案します。従来のセグメンテーション方法と比較して、MiniSegにはいくつかの重要な長所があります。i）472Kのパラメーターしかないため、過剰適合が容易ではありません。 ii）計算効率が高いため、実際の展開に便利です。 iii）パフォーマンスをさらに向上させるために、他のユーザーがプライベートCOVID-19データを使用して高速に再トレーニングできます。さらに、MiniSegを従来の方法と比較するための包括的なCOVID-19セグメンテーションベンチマークを構築します。コンピュータ支援COVID-19スクリーニングの研究と実用化を促進するためのコードとモデルがリリースされます。,https://d3i71xaburhd42.cloudfront.net/fb34b5fcdfe317e8787349dd7a7286117850c218/3-Figure1-1.png
AttaNet: Attention-Augmented Network for Fast and Accurate Scene Parsing,"['Qi Song', 'Kangfu Mei', 'Rui Huang']",,,,
Learning to Copy Coherent Knowledge for Response Generation,"['Jiaqi Bai', 'Ze Yang', 'Xinnian Liang', 'Wei Wang', 'Zhoujun Li']",,,,
PANTHER: Pathway Augmented Nonnegative Tensor Factorization for HighER-Order Feature Learning,"['Yuan Luo', 'Chengsheng Mao']",https://arxiv.org/abs/2012.08580,"Genetic pathways usually encode molecular mechanisms that can inform targeted interventions. It is often challenging for existing machine learning approaches to jointly model genetic pathways (higher-order features) and variants (atomic features), and present to clinicians interpretable models. In order to build more accurate and better interpretable machine learning models for genetic medicine, we introduce Pathway Augmented Nonnegative Tensor factorization for HighER-order feature learning (PANTHER). PANTHER selects informative genetic pathways that directly encode molecular mechanisms. We apply genetically motivated constrained tensor factorization to group pathways in a way that reflects molecular mechanism interactions. We then train a softmax classifier for disease types using the identified pathway groups. We evaluated PANTHER against multiple state-of-the-art constrained tensor/matrix factorization models, as well as group guided and Bayesian hierarchical models. PANTHER outperforms all state-of-the-art comparison models significantly (p<0.05). Our experiments on large scale Next Generation Sequencing (NGS) and whole-genome genotyping datasets also demonstrated wide applicability of PANTHER. We performed feature analysis in predicting disease types, which suggested insights and benefits of the identified pathway groups.",遺伝的経路は通常、標的を絞った介入に情報を与えることができる分子メカニズムをコードします。遺伝子経路（高次の特徴）とバリアント（原子の特徴）を共同でモデル化し、臨床医に解釈可能なモデルを提示することは、既存の機械学習アプローチにとってしばしば困難です。遺伝医学のためのより正確でより解釈しやすい機械学習モデルを構築するために、高次特徴学習（PANTHER）のためのPathway Augmented NonnegativeTensor因数分解を導入します。 PANTHERは、分子メカニズムを直接コードする有益な遺伝子経路を選択します。分子メカニズムの相互作用を反映する方法で、遺伝的に動機付けられた制約付きテンソル分解をグループ経路に適用します。次に、特定された経路グループを使用して、疾患タイプのソフトマックス分類器をトレーニングします。 PANTHERを、複数の最先端の制約付きテンソル/行列因数分解モデル、およびグループガイドモデルとベイズ階層モデルに対して評価しました。 PANTHERは、すべての最先端の比較モデルを大幅に上回っています（p &lt;0.05）。大規模な次世代シーケンシング（NGS）および全ゲノムジェノタイピングデータセットに関する実験でも、PANTHERの幅広い適用性が実証されました。疾患の種類を予測する際に特徴分析を実行しました。これにより、特定された経路グループの洞察と利点が示唆されました。,https://d3i71xaburhd42.cloudfront.net/303149806dc5be379b4c1fc7070092437b3a6ad0/3-Figure1-1.png
Knowledge Refactoring for Inductive Program Synthesis,"['Sebastijan Dumancic', 'Tias Guns', 'Andrew Cropper']",https://arxiv.org/abs/2004.09931,"Humans constantly restructure knowledge to use it more efficiently. Our goal is to give a machine learning system similar abilities so that it can learn more efficiently. We introduce the \textit{knowledge refactoring} problem, where the goal is to restructure a learner's knowledge base to reduce its size and to minimise redundancy in it. We focus on inductive logic programming, where the knowledge base is a logic program. We introduce Knorf, a system which solves the refactoring problem using constraint optimisation. We evaluate our approach on two program induction domains: real-world string transformations and building Lego structures. Our experiments show that learning from refactored knowledge can improve predictive accuracies fourfold and reduce learning times by half.",人間は常に知識を再構築して、知識をより効率的に使用します。私たちの目標は、機械学習システムに同様の機能を提供して、より効率的に学習できるようにすることです。知識リファクタリングの問題を紹介します。ここでの目標は、学習者の知識ベースを再構築してサイズを縮小し、冗長性を最小限に抑えることです。知識ベースが論理プログラムである帰納論理プログラミングに焦点を当てています。制約最適化を使用してリファクタリング問題を解決するシステムであるKnorfを紹介します。実世界の文字列変換とレゴ構造の構築という2つのプログラム帰納ドメインでアプローチを評価します。私たちの実験は、リファクタリングされた知識から学習することで、予測精度を4倍向上させ、学習時間を半分に短縮できることを示しています。,
LCollision: Fast Generation of Collision-Free Human Poses Using Learned Non-Penetration Constraints,"['Qingyang Tan', 'Zherong Pan', 'Dinesh Manocha']",https://arxiv.org/abs/2011.03632,"We present a learning-based method (LCollision) that synthesizes collision-free 3D human poses. At the crux of our approach is a novel deep architecture that simultaneously decodes new human poses from the latent space and classifies the collision status. These two components of our architecture are used as the objective function and surrogate hard-constraints in a constrained-optimization algorithm for collision-free human pose generation. A novel aspect of our approach is the use of a bilevel autoencoder that decomposes whole-body collisions into groups of collisions between localized body parts. We show that solving our constrained optimization formulation can resolve significantly more collision artifacts than prior learning algorithms. Furthermore, in a large test set of $2.5\times 10^6$ randomized poses from three major datasets, our architecture achieves a collision-prediction accuracy of $94.1\%$ with $80\times$ speedup over exact collision detection algorithms. To the best of our knowledge, LCollision is the first approach that can obtain high accuracy in terms of handling non-penetration and collision constraints in a learning framework.",衝突のない3D人間のポーズを合成する学習ベースの方法（LCollision）を紹介します。私たちのアプローチの核心は、潜在空間から新しい人間のポーズを同時にデコードし、衝突状態を分類する新しい深いアーキテクチャです。私たちのアーキテクチャのこれらの2つのコンポーネントは、衝突のない人間のポーズ生成のための制約付き最適化アルゴリズムで、目的関数および代理ハード制約として使用されます。私たちのアプローチの新しい側面は、全身の衝突を局所的な身体部分間の衝突のグループに分解するバイレベルオートエンコーダの使用です。制約付き最適化の定式化を解くことで、以前の学習アルゴリズムよりもはるかに多くの衝突アーティファクトを解決できることを示します。さらに、3つの主要なデータセットからの2.5 106のランダム化されたポーズの大規模なテストセットで、私たちのアーキテクチャは、正確な衝突検出アルゴリズムよりも80スピードアップし、94.1％の衝突予測精度を達成します。私たちの知る限り、LCollisionは、学習フレームワークで非侵入および衝突の制約を処理するという点で高精度を得ることができる最初のアプローチです。,https://d3i71xaburhd42.cloudfront.net/3f1db35aa06afeff6bf2f00ae85a8ceb1febf27e/3-Figure1-1.png
Incremental Embedding Learning via Zero-Shot Translation,"['Kun Wei', 'Cheng Deng', 'Xu Yang', 'Maosen Li']",https://arxiv.org/abs/2012.15497,"Modern deep learning methods have achieved great success in machine learning and computer vision fields by learning a set of pre-defined datasets. Howerver, these methods perform unsatisfactorily when applied into real-world situations. The reason of this phenomenon is that learning new tasks leads the trained model quickly forget the knowledge of old tasks, which is referred to as catastrophic forgetting. Current state-of-the-art incremental learning methods tackle catastrophic forgetting problem in traditional classification networks and ignore the problem existing in embedding networks, which are the basic networks for image retrieval, face recognition, zero-shot learning, etc. Different from traditional incremental classification networks, the semantic gap between the embedding spaces of two adjacent tasks is the main challenge for embedding networks under incremental learning setting. Thus, we propose a novel class-incremental method for embedding network, named as zero-shot translation class-incremental method (ZSTCI), which leverages zero-shot translation to estimate and compensate the semantic gap without any exemplars. Then, we try to learn a unified representation for two adjacent tasks in sequential learning process, which captures the relationships of previous classes and current classes precisely. In addition, ZSTCI can easily be combined with existing regularization-based incremental learning methods to further improve performance of embedding networks. We conduct extensive experiments on CUB200-2011 and CIFAR100, and the experiment results prove the effectiveness of our method. The code of our method has been released.",最新の深層学習手法は、事前定義されたデータセットのセットを学習することにより、機械学習とコンピュータービジョンの分野で大きな成功を収めています。ただし、これらの方法は、実際の状況に適用すると不十分に機能します。この現象の理由は、新しいタスクを学習すると、トレーニングされたモデルが古いタスクの知識をすぐに忘れてしまうためです。これは、壊滅的な忘却と呼ばれます。現在の最先端のインクリメンタル学習方法は、従来の分類ネットワークにおける壊滅的な忘却の問題に取り組み、画像検索、顔認識、ゼロショット学習などの基本ネットワークである埋め込みネットワークに存在する問題を無視します。従来とは異なります。インクリメンタル分類ネットワークでは、2つの隣接するタスクの埋め込みスペース間のセマンティックギャップが、インクリメンタル学習設定でネットワークを埋め込むための主な課題です。したがって、ゼロショット変換を活用してエグザンプラなしでセマンティックギャップを推定および補正する、ゼロショット変換クラスインクリメンタルメソッド（ZSTCI）と呼ばれる、ネットワークを埋め込むための新しいクラスインクリメンタルメソッドを提案します。次に、前のクラスと現在のクラスの関係を正確にキャプチャする、順次学習プロセスで2つの隣接するタスクの統一された表現を学習しようとします。さらに、ZSTCIは、既存の正則化ベースの増分学習方法と簡単に組み合わせて、埋め込みネットワークのパフォーマンスをさらに向上させることができます。私たちはCUB200-2011とCIFAR100で広範な実験を行い、実験結果は私たちの方法の有効性を証明しています。メソッドのコードがリリースされました。,https://d3i71xaburhd42.cloudfront.net/773aab0cf44aab244b989963da30db914437b97a/1-Figure1-1.png
Weakly-Supervised Temporal Action Localization by Uncertainty Modeling,"['Pilhyeon Lee', 'Jinglu Wang', 'Yan Lu', 'Hyeran Byun']",https://arxiv.org/abs/2006.07006,"Weakly-supervised temporal action localization aims to learn detecting temporal intervals of action classes with only video-level labels. To this end, it is crucial to separate frames of action classes from the background frames (i.e., frames not belonging to any action classes). In this paper, we present a new perspective on background frames where they are modeled as out-of-distribution samples regarding their inconsistency. Then, background frames can be detected by estimating the probability of each frame being out-of-distribution, known as uncertainty, but it is infeasible to directly learn uncertainty without frame-level labels. To realize the uncertainty learning in the weakly-supervised setting, we leverage the multiple instance learning formulation. Moreover, we further introduce a background entropy loss to better discriminate background frames by encouraging their in-distribution (action) probabilities to be uniformly distributed over all action classes. Experimental results show that our uncertainty modeling is effective at alleviating the interference of background frames and brings a large performance gain without bells and whistles. We demonstrate that our model significantly outperforms state-of-the-art methods on the benchmarks, THUMOS'14 and ActivityNet (1.2 & 1.3). Our code is available at https://github.com/Pilhyeon/WTAL-Uncertainty-Modeling.",弱教師あり時間アクションローカリゼーションは、ビデオレベルのラベルのみを使用してアクションクラスの時間間隔を検出することを学習することを目的としています。このためには、アクションクラスのフレームをバックグラウンドフレーム（つまり、どのアクションクラスにも属していないフレーム）から分離することが重要です。この論文では、背景フレームが不整合に関して分布外のサンプルとしてモデル化されている場合の新しい視点を示します。次に、不確実性と呼ばれる、各フレームが分布外になる確率を推定することで背景フレームを検出できますが、フレームレベルのラベルなしで不確実性を直接学習することは不可能です。弱教師あり設定での不確実性学習を実現するために、複数インスタンス学習の定式化を活用します。さらに、バックグラウンドエントロピー損失を導入して、バックグラウンドフレームをより適切に区別するために、それらの分布内（アクション）確率がすべてのアクションクラスに均一に分散されるようにします。実験結果は、不確実性モデリングがバックグラウンドフレームの干渉を軽減するのに効果的であり、ベルやホイッスルなしで大幅なパフォーマンスの向上をもたらすことを示しています。私たちのモデルは、ベンチマークであるTHUMOS14およびActivityNet（1.2および1.3）の最先端の方法を大幅に上回っていることを示しています。私たちのコードはhttps://github.com/Pilhyeon/WTAL-Uncertainty-Modelingで入手できます。,
CAKES: Channel-Wise Automatic Kernel Shrinking for Efficient 3D Networks,"['Qihang Yu', 'Yingwei Li', 'Jieru Mei', 'Yuyin Zhou', 'Alan Yuille']",https://arxiv.org/abs/2003.12798,"3D Convolution Neural Networks (CNNs) have been widely applied to 3D scene understanding, such as video analysis and volumetric image recognition. However, 3D networks can easily lead to over-parameterization which incurs expensive computation cost. In this paper, we propose Channel-wise Automatic KErnel Shrinking (CAKES), to enable efficient 3D learning by shrinking standard 3D convolutions into a set of economic operations (e.g., 1D, 2D convolutions). Unlike previous methods, our proposed CAKES performs channel-wise kernel shrinkage, which enjoys the following benefits: 1) encouraging operations deployed in every layer to be heterogeneous, so that they can extract diverse and complementary information to benefit the learning process; and 2) allowing for an efficient and flexible replacement design, which can be generalized to both spatial-temporal and volumetric data. Together with a neural architecture search framework, by applying CAKES to 3D C2FNAS and ResNet50, we achieve the state-of-the-art performance with much fewer parameters and computational costs on both 3D medical imaging segmentation and video action recognition.",3D畳み込みニューラルネットワーク（CNN）は、ビデオ分析や体積画像認識などの3Dシーンの理解に広く適用されています。ただし、3Dネットワークはパラメータ化の過剰につながりやすく、計算コストが高くなります。この論文では、チャネルごとの自動カーネル縮小（CAKES）を提案し、標準の3D畳み込みを一連の経済的操作（1D、2D畳み込みなど）に縮小することで効率的な3D学習を可能にします。以前の方法とは異なり、提案されたCAKESはチャネルごとのカーネル縮小を実行します。これには、次の利点があります。1）すべてのレイヤーにデプロイされた操作が異種になるように促し、多様で補完的な情報を抽出して学習プロセスに役立てることができます。 2）効率的で柔軟な置換設計を可能にします。これは、時空間データと体積データの両方に一般化できます。ニューラルアーキテクチャ検索フレームワークとともに、CAKESを3D C2FNASおよびResNet50に適用することにより、3D医用画像セグメンテーションとビデオアクション認識の両方で、はるかに少ないパラメーターと計算コストで最先端のパフォーマンスを実現します。,https://d3i71xaburhd42.cloudfront.net/08f985bdde257b0814a93af7d3254023e8d2d067/2-Figure1-1.png
Landmark Generation in HTN Planning,"['Daniel Höller', 'Pascal T Bercher']",,"Landmarks are state features that need to be made true or tasks that need to be contained in every solution of a planning problem. They are a valuable source of information in planning and can be exploited in various ways. Landmarks have been used both in classical and hierarchical planning, but while there is much work in classical planning, the techniques in hierarchical planning are less evolved. In this paper we introduce a novel landmark generation method for Hierarchical Task Network (HTN) planning and show that it is sound and incomplete. We show that every complete approach is as hard as the underlying HTN problem. Since we make relaxations during landmark generation, this means NP-hard for our setting (while our approach is in P). On a widely used benchmark set, our approach finds more than twice the number of landmarks than the approach from the literature. Though our focus is on landmark generation, we show that the newly discovered landmarks bear information beneficial for solvers.",ランドマークは、真にする必要のある州の特徴、または計画問題のすべてのソリューションに含める必要のあるタスクです。これらは計画における貴重な情報源であり、さまざまな方法で活用できます。ランドマークは、古典的計画と階層的計画の両方で使用されてきましたが、古典的計画には多くの作業がありますが、階層的計画の手法はあまり進化していません。この論文では、階層的タスクネットワーク（HTN）計画のための新しいランドマーク生成方法を紹介し、それが健全で不完全であることを示します。すべての完全なアプローチは、根本的なHTNの問題と同じくらい難しいことを示しています。ランドマークの生成中にリラクゼーションを行うため、これは、設定に対してNP困難を意味します（アプローチがPである間）。広く使用されているベンチマークセットでは、私たちのアプローチは、文献からのアプローチの2倍以上のランドマークを見つけます。私たちの焦点はランドマークの生成にありますが、新しく発見されたランドマークがソルバーにとって有益な情報を持っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/3dbab99ec5abdb85423af170e2d211ef529d09ed/4-Figure1-1.png
On Online Optimization: Dynamic Regret Analysis of Strongly Convex and Smooth Problems,"['Ting-Jui Chang', 'Shahin Shahrampour']",,,,
Ethical Dilemmas in Strategic Games,"['Pavel Naumov', 'Rui-Jie Yew']",https://arxiv.org/abs/1911.00786,"An agent, or a coalition of agents, faces an ethical dilemma between several statements if she is forced to make a conscious choice between which of these statements will be true. This paper proposes to capture ethical dilemmas as a modality in strategic game settings with and without limit on sacrifice and for perfect and imperfect information games. The authors show that the dilemma modality cannot be defined through the earlier proposed blameworthiness modality. The main technical result is a sound and complete axiomatization of the properties of this modality with sacrifice in games with perfect information.",エージェント、またはエージェントの連合は、これらのステートメントのどれが正しいかを意識的に選択することを余儀なくされた場合、いくつかのステートメント間の倫理的ジレンマに直面します。この論文は、犠牲の制限の有無にかかわらず、そして完全および不完全な情報ゲームのための戦略的ゲーム設定におけるモダリティとして倫理的ジレンマを捉えることを提案します。著者らは、ジレンマのモダリティは、以前に提案された非難に値するモダリティでは定義できないことを示しています。主な技術的結果は、完全情報を備えたゲームで犠牲を払って、このモダリティのプロパティの健全で完全な公理化です。,
Comprehension and Knowledge,"['Pavel Naumov', 'Kevin Ros']",https://arxiv.org/abs/2012.06561,The ability of an agent to comprehend a sentence is tightly connected to the agent's prior experiences and background knowledge. The paper suggests to interpret comprehension as a modality and proposes a complete bimodal logical system that describes an interplay between comprehension and knowledge modalities.,文章を理解するエージェントの能力は、エージェントの以前の経験と背景知識と密接に関連しています。この論文は、理解をモダリティとして解釈することを提案し、理解と知識モダリティの間の相互作用を説明する完全なバイモーダル論理システムを提案しています。,https://d3i71xaburhd42.cloudfront.net/6828898c23040833e7f167ba80c38acad1af8cb3/2-Figure1-1.png
Epistemic Logic of Know-Who,"['Sophia Epstein', 'Pavel Naumov']",https://arxiv.org/abs/2012.06651,"The paper suggests a definition of ""know who"" as a modality using Grove-Halpern semantics of names. It also introduces a logical system that describes the interplay between modalities ""knows who"", ""knows"", and ""for all agents"". The main technical result is a completeness theorem for the proposed system.",この論文は、名前のGrove-Halpernセマンティクスを使用したモダリティとしての「knowwho」の定義を提案しています。また、「誰を知っている」、「知っている」、「すべてのエージェントのために」というモダリティ間の相互作用を説明する論理システムも紹介します。主な技術的結果は、提案されたシステムの完全性定理です。,https://d3i71xaburhd42.cloudfront.net/24b8b7f638aae07491d0ddf8644505d20e17d35a/2-Figure1-1.png
Deep Switching Auto-Regressive Factorization: Application to Time Series Forecasting,"['Amirreza Farnoosh', 'Bahar Azari', 'Sarah Ostadabbas']",https://arxiv.org/abs/2009.05135,"We introduce deep switching auto-regressive factorization (DSARF), a deep generative model for spatio-temporal data with the capability to unravel recurring patterns in the data and perform robust short- and long-term predictions. Similar to other factor analysis methods, DSARF approximates high dimensional data by a product between time dependent weights and spatially dependent factors. These weights and factors are in turn represented in terms of lower dimensional latent variables that are inferred using stochastic variational inference. DSARF is different from the state-of-the-art techniques in that it parameterizes the weights in terms of a deep switching vector auto-regressive likelihood governed with a Markovian prior, which is able to capture the non-linear inter-dependencies among weights to characterize multimodal temporal dynamics. This results in a flexible hierarchical deep generative factor analysis model that can be extended to (i) provide a collection of potentially interpretable states abstracted from the process dynamics, and (ii) perform short- and long-term vector time series prediction in a complex multi-relational setting. Our extensive experiments, which include simulated data and real data from a wide range of applications such as climate change, weather forecasting, traffic, infectious disease spread and nonlinear physical systems attest the superior performance of DSARF in terms of long- and short-term prediction error, when compared with the state-of-the-art methods.",ディープスイッチング自己回帰因数分解（DSARF）を紹介します。これは、データ内の繰り返しパターンを解明し、堅牢な短期および長期予測を実行する機能を備えた、時空間データのディープ生成モデルです。他の因子分析方法と同様に、DSARFは、時間依存の重みと空間依存の因子の間の積によって高次元データを近似します。これらの重みと因子は、確率的変分推論を使用して推論される低次元の潜在変数の観点から表されます。 DSARFは、重み間の非線形相互依存性をキャプチャできるマルコフ事前分布で制御される深いスイッチングベクトルの自己回帰尤度の観点から重みをパラメーター化するという点で、最先端の手法とは異なります。マルチモーダル時間ダイナミクスを特徴づける。これにより、（i）プロセスダイナミクスから抽象化された潜在的に解釈可能な状態のコレクションを提供し、（ii）複合体で短期および長期のベクトル時系列予測を実行するために拡張できる、柔軟な階層型の深い生成因子分析モデルが得られます。マルチリレーショナル設定。気候変動、天気予報、交通、感​​染症の蔓延、非線形物理システムなどの幅広いアプリケーションからのシミュレーションデータと実際のデータを含む当社の広範な実験は、長期および短期予測の観点からDSARFの優れたパフォーマンスを証明しています最先端の方法と比較した場合のエラー。,https://d3i71xaburhd42.cloudfront.net/ab9c2121338151dfd0056666135cc5113b4809d6/3-Figure1-1.png
Treatment Effect Estimation with Disentangled Latent Factors,"['Weijia Zhang', 'Lin Liu', 'Jiuyong Li']",https://arxiv.org/abs/2001.10652,"A common challenge of many scientific studies is to determine whether a treatment is effective for an outcome. When considering a binary treatment, this problem can be addressed by estimating the average treatment effect using the potential outcome framework. Moreover, since different individuals often respond differently to the same treatment due to their distinct characteristics. In order to understand the heterogeneous treatment effect for different individuals, practitioners need to estimate the conditional average treatment effects conditioning on the variables describing the distinct characteristics of individuals. 
Much research has been devoted to the estimation of treatment effects from observational data; however, most of them assume that the set of observed variables contains exactly all the confounders that affect both the treatment and the outcome. Unfortunately, this assumption is frequently violated in real-world applications not only because some of the observed variables only affect the treatment or the outcome, but also due to the fact that in many cases only the proxy variables of the underlying confounding factors can be observed. In this work, we first show the importance of differentiating confounding factors from instrumental and risk factors for average and conditional average treatment effect estimation, and then we propose a variational inference approach to simultaneously infer latent factors from the observed variables and disentangle the factors into three disjoint sets corresponding to the instrumental, confounding, and risk factors. Experimental results demonstrate the effectiveness of the proposed method on synthetic, benchmark, and real-world datasets for treatment effect estimation.",多くの科学的研究に共通する課題は、治療が結果に効果的かどうかを判断することです。バイナリ治療を検討する場合、この問題は、潜在的な結果フレームワークを使用して平均治療効果を推定することで対処できます。さらに、異なる個人は、彼らの異なる特徴のために、同じ治療に対して異なる反応をすることが多いので。さまざまな個人の不均一な治療効果を理解するために、開業医は、個人の明確な特性を説明する変数を条件として、条件付き平均治療効果を推定する必要があります。多くの研究が、観察データからの治療効果の推定に向けられてきました。ただし、それらのほとんどは、観測された変数のセットに、治療と結果の両方に影響を与えるすべての交絡因子が正確に含まれていると想定しています。残念ながら、実際のアプリケーションでは、観察された変数の一部が治療または結果にのみ影響を与えるだけでなく、多くの場合、根底にある交絡因子の代理変数しか観察できないため、この仮定に違反することがよくあります。 。この作業では、最初に、平均および条件付き平均治療効果推定のために、交絡因子を機器およびリスク因子から区別することの重要性を示し、次に、観察された変数から潜在因子を同時に推定し、因子を3つに解きほぐす変分推論アプローチを提案します。手段、交絡、およびリスク要因に対応する互いに素なセット。実験結果は、治療効果推定のための合成、ベンチマーク、および実世界のデータセットに対する提案された方法の有効性を示しています。,https://d3i71xaburhd42.cloudfront.net/f00aa9294dc90bc73c496835a6ad666dee9ce0f3/2-Figure1-1.png
Exploration via State Influence Modeling,"['Yongxin Kang', 'Enmin Zhao', 'Kai Li', 'Junliang Xing']",,,,
How to Train Your Agent to Read and Write,"['Li Liu', 'Mengge He', 'Guanghui Xu', 'Mingkui Tan', 'Qi Wu']",https://arxiv.org/abs/2101.00916,"Reading and writing research papers is one of the most privileged abilities that a qualified researcher should master. However, it is difficult for new researchers (e.g., students) to fully grasp this ability. It would be fascinating if we could train an intelligent agent to help people read and summarize papers, and perhaps even discover and exploit the potential knowledge clues to write novel papers. Although there have been existing works focusing on summarizing (i.e., reading) the knowledge in a given text or generating (i.e., writing) a text based on the given knowledge, the ability of simultaneously reading and writing is still under development. Typically, this requires an agent to fully understand the knowledge from the given text materials and generate correct and fluent novel paragraphs, which is very challenging in practice. In this paper, we propose a Deep ReAder-Writer (DRAW) network, which consists of a Reader that can extract knowledge graphs (KGs) from input paragraphs and discover potential knowledge, a graph-to-text Writer that generates a novel paragraph, and a Reviewer that reviews the generated paragraph from three different aspects. Extensive experiments show that our DRAW network outperforms considered baselines and several state-of-the-art methods on AGENDA and M-AGENDA datasets. Our code and supplementary are released at https://github.com/menggehe/DRAW.",研究論文の読み書きは、資格のある研究者が習得すべき最も特権的な能力の1つです。しかし、新しい研究者（学生など）がこの能力を十分に理解することは困難です。人々が論文を読んで要約するのを助け、おそらく新しい論文を書くための潜在的な知識の手がかりを発見して活用するのを助ける知的エージェントを訓練できれば、それは魅力的でしょう。与えられたテキストの知識を要約する（つまり読む）こと、または与えられた知識に基づいてテキストを生成する（つまり書く）ことに焦点を当てた既存の作品がありますが、同時に読み書きする能力はまだ開発中です。通常、これには、エージェントが特定のテキスト資料からの知識を完全に理解し、正確で流暢な新しい段落を生成する必要がありますが、これは実際には非常に困難です。本稿では、入力段落から知識グラフ（KG）を抽出し、潜在的な知識を発見できるリーダー、新しい段落を生成するグラフからテキストへのライターで構成されるDeep ReAder-Writer（DRAW）ネットワークを提案します。生成された段落を3つの異なる側面からレビューするレビューア。広範な実験により、DRAWネットワークは、AGENDAおよびM-AGENDAデータセットで考慮されたベースラインおよびいくつかの最先端の方法よりも優れていることが示されています。私たちのコードと補足はhttps://github.com/menggehe/DRAWでリリースされています。,https://d3i71xaburhd42.cloudfront.net/eae436d899684f2885af7bc68926d490190b6dde/1-Figure1-1.png
Why Do Attributes Propagate in Graph Convolutional Neural Networks?,"['Liang Yang', 'Chuan Wang', 'Junhua Gu', 'Xiaochun Cao', 'Bingxin Niu']",,"Many efforts have been paid to enhance Graph Convolutional Network from the perspective of propagation under the philosophy that “Propagation is the essence of the GCNNs”. Unfortunately, its adverse effect is over-smoothing, which makes the performance dramatically drop. To prevent the over-smoothing, many variants are presented. However, the perspective of propagation can’t provide an intuitive and unified interpretation to their effect on prevent over-smoothing. In this paper, we aim at providing a novel explanation to the question of “Why do attributes propagate in GCNNs?”. which not only gives the essence of the oversmoothing, but also illustrates why the GCN extensions, including multiscale GCN and GCN with initial residual, can improve the performance. To this end, an intuitive Graph Representation Learning (GRL) framework is presented. GRL simply constrains the node representation similar with the original attribute, and encourages the connected nodes possess similar representations (pairwise constraint). Based on the proposed GRL, exiting GCN and its extensions can be proved as different numerical optimization algorithms, such as gradient descent, of our proposed GRL framework. Inspired by the superiority of conjugate gradient descent compared to common gradient descent, a novel Graph Conjugate Convolutional (GCC) network is presented to approximate the solution to GRL with fast convergence. Specifically, GCC adopts the obtained information of the last layer, which can be represented as the difference between the input and output of the last layer, as the input to the next layer. Extensive experiments demonstrate the superior performance of GCC. Introduction Graph Neural Networks (GNNs) (Wu et al. 2020; Xu et al. 2019) have become a hot topic in deep learning for their potentials in modeling irregular data. GNNs have been widely used and achieved state-of-the-art performance in many fields, such as computer vision, natural language processing (Yang et al. 2020), traffic forecasting, chemistry and medical analysis, etc. Existing GNNs fall into two categories, spectral methods (Defferrard, Bresson, and Vandergheynst 2016) and spatial ones (Hamilton, Ying, and Leskovec 2017; Gilmer et al. 2017; Yang et al. 2019b,a; Jin et al. 2019, 2020, 2021). ∗Corresponding author. Copyright c © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Graph Convolutional Network (GCN) (Kipf and Welling 2017), which is a simple, well-behaved and insightful GNN, bridges above two perspectives by proving that the propagation can be motivated from a first-order approximation of spectral graph convolutions. Recently progress also demonstrates the equivalent of spatial and spectral ones (Balcilar et al. 2020). Many efforts have been paid to enhance GCN from the perspective of propagation (Gilmer et al. 2017), such as learnable propagation weights in Graph Attention Network (GAT) (Velickovic et al. 2018), Gated Attention Network (GaAN) (Zhang et al. 2018) and Probabilistic GCN (Yang et al. 2020), structural neighbourhood in Geom-GCN (Pei et al. 2020) and multi-scale (multi-hop) combination in N-GCN (Abu-El-Haija et al. 2019a), MixHop (Abu-El-Haija et al. 2019b), LanczosNet (Liao et al. 2019) and Krylov GCN (Luan et al. 2019). The common philosophy of them is: “Propagation is the essence of the GCNNs”. And, the success of GCNs attributes to the Laplacian smoothing induced by the propagation (Li, Han, and Wu 2018). Unfortunately, the most serious issue of GNNs is the over-smoothing, which makes the performance dramatically drop, caused by the multiple propagations via stacking multiple graph convolution layers. Recently, (Oono and Suzuki 2020) shows the the exponential loss of expressive power of GNNs by generalizing the forward propagation of a GCN as a specific dynamical system. To prevent over-smoothing, two kinds of methods are proposed. On one hand, methods in the first category constrain the propagation. Disentangled GCN (Ma et al. 2019) makes each attribute only be propagated on part of the edges. DropEdge (Rong et al. 2020) randomly removes a certain number of edges from the input graph at each training epoch to reduce the adverse effect of message passing. On the other hand, methods in the second category constrain the propagation result with the original attributes. PageRank-GCN (Klicpera, Bojchevski, and Günnemann 2019) integrates personalized PageRank to GCN to combine the original attribute. JKNet (Xu et al. 2018) employs dense connections for multi-hop message passing, while DeepGCN (Li et al. 2019) and (GCNII) (Chen et al. 2020) incorporates residual layers into GCNs to facilitate the development of deep architectures. However, the perspective of propagation can’t provide an intuitive and unified interpretation to their effect on preventing over-smoothing. In this paper, we aim at providing a novel explanation to the question of Why do attributes propagate in GCNNs? which not only gives the essence of the oversmoothing, but also illustrates why the GCN extensions, including multiscale GCN and GCN with initial residual, can improve the performance. To this end, an intuitive Graph Representation Learning (GRL) framework is presented by assuming the topology is accuracy. GRL simply constrains the node representation similar with the original attributes, and encourages the connected nodes possess similar representations (pairwise constraint). Then, by taking consideration the noisy topology, a Robust GRL is obtained by introducing a robust estimation to the pairwise (similarity) constraint. The solution to GRL can be obtained by solving a positive semidefinite linear system, while that to Robust GRL iteratively solves linear system and refines pairwise similarity. According to the proposed GRL and Robust GRL, exiting GCN and its extensions can be proved as different numerical optimization algorithms, such as gradient descent, of our proposed Graph Representation Learning framework. Specifically, GCN with initial residual can be seen as the gradient descent solution of GRL, multi-scale GCN as the high-order approximation to the analytic solution of GRL. Furthermore, the attention mechanism adopted in GCNNs can be regarded as the gradient descent solution to Robust GRL. Therefore, it provides insights of GCN and its variants from the perspective of numerical optimization that: The propagation as well as its weight learning are not the essence of the GCNs, but induced by the numerical optimization of pairwise similarity requirement. Based on this finding, a novel Graph Conjugate Convolutional (GCC) network is presented to approximate the solution to GRL with fast convergence. Specifically, inspired by the superiority of conjugate gradient descent compared to common gradient descent, the GCC building block, i.e., Graph Conjugate Convolutional layer, adopts the obtained information of the last layer, which can be represented as the difference between the input and output of the last layer, as the input to the next layer. It can significantly alleviates the overfitting issue caused by the accumulation effect of residual connection in GCN. The main contribution of this paper are summarized as follows: • We introduce a novel Graph Representation Learning (GRL) framework and its extension, Robust GRL, to take consideration of noisy topology. • We explain the GCN and its variants from the perspective of the numerical optimization of pairwise similarity requirement, under GRL framework. • We propose the Graph Conjugate Convolutional (GCC) network, which essentially sublimes the propagation. • We experimentally verify the superiority of GCC on trasductive and inductive tasks. Preliminaries In this section, the notations are given. Then, gradient descent for linear system, which will be used to explain some existing graph neural networks (GNNs), is provided. Finally, some classic and recently proposed GNNs are reviewed. Notations A network can be represented by an attributed graph G = (V, E ,X). V = {vi|i = 1, ..., N} is a set of |V| = N vertices, where vn is associated with a feature xn ∈ R . X ∈ RK×N is the collection of the features, each column of which corresponds to one node. E stands for a set of edges, each of which connects two vertices in V . The adjacency matrix A = [aij ] ∈ RN×N is employed to represent the network topology, where aij = 1 if an edge exists between the vertices vi and vj , and vice versa. If the network is allowed to contain self-edges, then ann = 1, otherwise ann = 0. an, which denotes the n column of A, can be utilized to represent the neighbourhood of vertex vn. dn = ∑ j anj is the degree of vertex vn, and D = diag(d1, d2, ..., dN ) is the degree matrix of the adjacency matrix A. The graph Laplacian and its normalized form are defined as L = D−A and L = D− 1 2 LD− 1 2 , respectively. Gradient Descent for Linear System Symmetric positive definite linear systems",伝播はGCNNの本質であるという哲学の下で、伝播の観点からグラフ畳み込みネットワークを強化するために多くの努力が払われてきました。残念ながら、その悪影響は過度の平滑化であり、パフォーマンスが劇的に低下します。過度の平滑化を防ぐために、多くのバリエーションが提示されています。ただし、伝播の観点からは、過度の平滑化を防ぐ効果について、直感的で統一された解釈を提供することはできません。この論文では、なぜ属性がGCNNで伝播するのかという質問に新しい説明を提供することを目的としています。これは、過度の平滑化の本質を与えるだけでなく、マルチスケールGCNおよび初期残差のあるGCNを含むGCN拡張がパフォーマンスを向上させることができる理由も示しています。この目的のために、直感的なグラフ表現学習（GRL）フレームワークが提示されます。 GRLは、元の属性と同様のノード表現を単純に制約し、接続されたノードが同様の表現を持つことを推奨します（ペアワイズ制約）。提案されたGRLに基づいて、既存のGCNとその拡張は、提案されたGRLフレームワークの最急降下法などのさまざまな数値最適化アルゴリズムとして証明できます。一般的な勾配降下法と比較した共役勾配降下法の優位性に触発されて、新しいグラフ共役畳み込み（GCC）ネットワークが提示され、高速収束でGRLの解を近似します。具体的には、GCCは、最後の層の入力と出力の差として表すことができる最後の層の取得された情報を次の層への入力として採用します。広範な実験により、GCCの優れたパフォーマンスが実証されています。はじめにグラフニューラルネットワーク（GNN）（Wuetal。2020; Xu etal。2019）は、不規則なデータのモデリングにおける可能性について、ディープラーニングのホットトピックになっています。 GNNは広く使用されており、コンピュータービジョン、自然言語処理（Yang etal。2020）、交通予測、化学、医療分析など、多くの分野で最先端のパフォーマンスを実現しています。既存のGNNは2つに分類されます。カテゴリ、スペクトル法（Defferrard、Bresson、およびVandergheynst 2016）および空間法（Hamilton、Ying、およびLeskovec 2017; Gilmer et al.2017; Yang et al.2019b、a; Jin et al.2019、2020、2021）。対応する著者。 Copyright c 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。全著作権所有。グラフ畳み込みネットワーク（GCN）（Kipf and Welling 2017）は、シンプルで行儀の良い洞察に満ちたGNNであり、スペクトルグラフ畳み込みの1次近似から伝播を動機付けることができることを証明することにより、2つの視点を橋渡しします。最近の進歩は、空間的およびスペクトル的なものと同等であることも示しています（Balcilar et al.2020）。グラフアテンションネットワーク（GAT）（Velickovic etal。2018）、ゲートアテンションネットワーク（GaAN）（Zhang et al。）で学習可能な伝播重みなど、伝播の観点からGCNを強化するために多くの努力が払われてきました（Gilmer et al.2017）。 al.2018）および確率的GCN（Yang et al.2020）、Geom-GCNの構造的近隣（Pei et al.2020）およびN-GCNのマルチスケール（マルチホップ）の組み合わせ（Abu-El-Haija et al。 .2019a）、MixHop（Abu-El-Haija et al.2019b）、LanczosNet（Liao et al.2019）およびKrylov GCN（Luan et al.2019）。それらの共通の哲学は次のとおりです。伝播はGCNNの本質です。そして、GCNの成功は、伝播によって引き起こされたラプラシアン平滑化に起因します（Li、Han、およびWu 2018）。残念ながら、GNNの最も深刻な問題は、過度の平滑化です。これは、複数のグラフ畳み込みレイヤーのスタックを介した複数の伝播によって、パフォーマンスが劇的に低下します。最近（Oono and Suzuki 2020）は、GCNの順伝播を特定の動的システムとして一般化することにより、GNNの表現力の指数関数的な損失を示しています。過度の平滑化を防ぐために、2種類の方法が提案されています。一方では、最初のカテゴリのメソッドは伝播を制約します。解きほぐされたGCN（Ma etal。2019）は、各属性がエッジの一部でのみ伝播されるようにします。 DropEdge（Rong etal。2020）は、メッセージパッシングの悪影響を減らすために、各トレーニングエポックで入力グラフから特定の数のエッジをランダムに削除します。一方、2番目のカテゴリのメソッドは、伝播結果を元の属性で制約します。 PageRank-GCN（Klicpera、Bojchevski、およびGunnemann 2019）は、パーソナライズされたPageRankをGCNに統合して、元の属性を結合します。 JKNet（Xu etal。2018）は、マルチホップメッセージパッシングに高密度接続を採用していますが、DeepGCN（Li etal。2019）および（GCNII）（Chen etal。2020）は、残余層をGCNに組み込んで、ディープアーキテクチャの開発を促進しています。 。ただし、伝播の観点からは、過度の平滑化の防止に対する効果を直感的かつ統一的に解釈することはできません。この論文では、なぜ属性がGCNNで伝播するのかという質問に新しい説明を提供することを目的としています。これは、過度の平滑化の本質を与えるだけでなく、マルチスケールGCNおよび初期残差のあるGCNを含むGCN拡張がパフォーマンスを向上させることができる理由も示しています。この目的のために、トポロジーが正確であると仮定することにより、直感的なグラフ表現学習（GRL）フレームワークが提示されます。 GRLは、元の属性と同様のノード表現を単純に制約し、接続されたノードが同様の表現を持つことを推奨します（ペアワイズ制約）。次に、ノイズの多いトポロジを考慮して、ペアワイズ（類似性）制約にロバスト推定を導入することにより、ロバストGRLが取得されます。 GRLの解は、正の半定値線形システムを解くことによって取得できますが、ロバストGRLの解は、線形システムを繰り返し解き、ペアワイズ類似性を改良します。提案されたGRLとロバストGRLによると、既存のGCNとその拡張は、提案されたグラフ表現学習フレームワークの最急降下法などのさまざまな数値最適化アルゴリズムとして証明できます。具体的には、初期残余のあるGCNは、GRLの最急降下法の解として、マルチスケールGCNはGRLの解析解の高次近似として見ることができます。さらに、GCNNで採用されている注意メカニズムは、ロバストGRLの最急降下法と見なすことができます。したがって、数値最適化の観点からGCNとそのバリアントの洞察を提供します。伝播とその重み学習はGCNの本質ではなく、ペアワイズ類似性要件の数値最適化によって誘導されます。この発見に基づいて、新しいグラフ共役畳み込み（GCC）ネットワークが提示され、高速収束でGRLの解を近似します。具体的には、一般的な勾配降下法と比較した共役勾配降下法の優位性に触発されて、GCCビルディングブロック、つまりグラフ共役畳み込み層は、最後の層の取得情報を採用します。これは、の入力と出力の差として表すことができます。次のレイヤーへの入力としての最後のレイヤー。これにより、GCNでの残留接続の蓄積効果によって引き起こされる過剰適合の問題を大幅に軽減できます。このホワイトペーパーの主な貢献は次のとおりです。ノイズの多いトポロジを考慮して、新しいグラフ表現学習（GRL）フレームワークとその拡張機能であるRobustGRLを紹介します。 GRLフレームワークの下で、ペアワイズ類似性要件の数値最適化の観点からGCNとそのバリアントについて説明します。本質的に伝搬を昇華させるグラフ共役畳み込み（GCC）ネットワークを提案します。トランスダクティブおよびインダクティブタスクにおけるGCCの優位性を実験的に検証します。予備知識このセクションでは、表記法を示します。次に、いくつかの既存のグラフニューラルネットワーク（GNN）を説明するために使用される線形システムの勾配降下法が提供されます。最後に、いくつかの古典的で最近提案されたGNNをレビューします。表記法ネットワークは、属性付きグラフG =（V、E、X）で表すことができます。 V = vi | i = 1、...、Nは| V |のセットです= N個の頂点。ここで、vnはフィーチャxnRに関連付けられています。 X RKNは機能のコレクションであり、各列は1つのノードに対応します。 Eはエッジのセットを表し、それぞれがVの2つの頂点を接続します。隣接行列A = [aij] RNNは、ネットワークトポロジを表すために使用されます。ここで、頂点viとvjの間にエッジが存在する場合はaij = 1であり、その逆も同様です。ネットワークに自己エッジを含めることが許可されている場合、ann = 1、それ以外の場合はann = 0です。Aのn列を表すanを使用して、頂点vnの近傍を表すことができます。 dn = j anjは頂点vnの次数であり、D = diag（d1、d2、...、dN）は隣接行列Aの次数行列です。グラフラプラシアンとその正規化された形式は、L = DAおよびL = D 1 2 LD 1 2、それぞれ。線形システムの最急降下法対称正定線形システム,https://d3i71xaburhd42.cloudfront.net/a39193f071efed10af6704133061c15818a27edc/6-Figure1-1.png
Learning Modulated Loss for Rotated Object Detection,"['Wen Qian', 'Xue Yang', 'Silong Peng', 'Junchi Yan', 'Yue Guo']",https://arxiv.org/abs/1911.08299,"Popular rotated detection methods usually use five parameters (coordinates of the central point, width, height, and rotation angle) to describe the rotated bounding box and l1-loss as the loss function. In this paper, we argue that the aforementioned integration can cause training instability and performance degeneration, due to the loss discontinuity resulted from the inherent periodicity of angles and the associated sudden exchange of width and height. This problem is further pronounced given the regression inconsistency among five parameters with different measurement units. We refer to the above issues as rotation sensitivity error (RSE) and propose a modulated rotation loss to dismiss the loss discontinuity. Our new loss is combined with the eight-parameter regression to further solve the problem of inconsistent parameter regression. Experiments show the state-of-art performances of our method on the public aerial image benchmark DOTA and UCAS-AOD. Its generalization abilities are also verified on ICDAR2015, HRSC2016, and FDDB. Qualitative improvements can be seen in Fig 1, and the source code will be released with the publication of the paper.",一般的な回転検出方法では、通常、5つのパラメーター（中心点、幅、高さ、回転角度の座標）を使用して、回転した境界ボックスとl1-損失を損失関数として記述します。この論文では、前述の統合は、角度の固有の周期性とそれに伴う幅と高さの突然の交換に起因する損失の不連続性のために、トレーニングの不安定性とパフォーマンスの低下を引き起こす可能性があると主張します。この問題は、測定単位が異なる5つのパラメーター間の回帰の不一致を考えるとさらに顕著になります。上記の問題を回転感度エラー（RSE）と呼び、損失の不連続性を解消するために変調された回転損失を提案します。新しい損失を8パラメーター回帰と組み合わせて、一貫性のないパラメーター回帰の問題をさらに解決します。実験は、公共の航空画像ベンチマークDOTAおよびUCAS-AODでの私たちの方法の最先端のパフォーマンスを示しています。その一般化能力は、ICDAR2015、HRSC2016、およびFDDBでも検証されています。定性的な改善は図1に見ることができ、ソースコードは論文の公開とともにリリースされます。,https://d3i71xaburhd42.cloudfront.net/014c268f8cc0705345fc02abf78d90c794771491/1-Figure1-1.png
Spatiotemporal Graph Neural Network Based Mask Reconstruction for Video Object Segmentation,"['Daizong Liu', 'Shuangjie Xu', 'Xiao-Yang Liu', 'Zichuan Xu', 'Wei Wei', 'Pan Zhou']",https://arxiv.org/abs/2012.05499,"This paper addresses the task of segmenting class-agnostic objects in semi-supervised setting. Although previous detection based methods achieve relatively good performance, these approaches extract the best proposal by a greedy strategy, which may lose the local patch details outside the chosen candidate. In this paper, we propose a novel spatiotemporal graph neural network (STG-Net) to reconstruct more accurate masks for video object segmentation, which captures the local contexts by utilizing all proposals. In the spatial graph, we treat object proposals of a frame as nodes and represent their correlations with an edge weight strategy for mask context aggregation. To capture temporal information from previous frames, we use a memory network to refine the mask of current frame by retrieving historic masks in a temporal graph. The joint use of both local patch details and temporal relationships allow us to better address the challenges such as object occlusion and missing. Without online learning and fine-tuning, our STG-Net achieves state-of-the-art performance on four large benchmarks (DAVIS, YouTube-VOS, SegTrack-v2, and YouTube-Objects), demonstrating the effectiveness of the proposed approach.",このホワイトペーパーでは、半教師あり設定でクラスに依存しないオブジェクトをセグメント化するタスクについて説明します。以前の検出ベースの方法は比較的良好なパフォーマンスを達成しますが、これらのアプローチは貪欲な戦略によって最良の提案を抽出します。これにより、選択した候補の外部のローカルパッチの詳細が失われる可能性があります。本論文では、すべての提案を利用してローカルコンテキストをキャプチャするビデオオブジェクトセグメンテーションのより正確なマスクを再構築するための新しい時空間グラフニューラルネットワーク（STG-Net）を提案します。空間グラフでは、フレームのオブジェクト提案をノードとして扱い、マスクコンテキスト集約のエッジ重み戦略との相関関係を表します。前のフレームから時間情報をキャプチャするために、メモリネットワークを使用して、時間グラフで履歴マスクを取得することにより、現在のフレームのマスクを調整します。ローカルパッチの詳細と時間的関係の両方を併用することで、オブジェクトのオクルージョンや欠落などの課題により適切に対処できます。オンライン学習と微調整なしで、STG-Netは4つの大きなベンチマーク（DAVIS、YouTube-VOS、SegTrack-v2、およびYouTube-Objects）で最先端のパフォーマンスを達成し、提案されたアプローチの有効性を示しています。,https://d3i71xaburhd42.cloudfront.net/5ec6620a09b1f573fc5351d4d4fe2d5e07ef7f47/1-Figure1-1.png
Multi-Task Learning by Leveraging the Semantic Information,"['Fan Zhou', 'Brahim Chaib-draa', 'Boyu Wang']",,,,
F2Net: Learning to Focus on the Foreground for Unsupervised Video Object Segmentation,"['Daizong Liu', 'Dongdong Yu', 'Changhu Wang', 'Pan Zhou']",https://arxiv.org/abs/2012.02534,"Although deep learning based methods have achieved great progress in unsupervised video object segmentation, difficult scenarios (e.g., visual similarity, occlusions, and appearance changing) are still not well-handled. To alleviate these issues, we propose a novel Focus on Foreground Network (F2Net), which delves into the intra-inter frame details for the foreground objects and thus effectively improve the segmentation performance. Specifically, our proposed network consists of three main parts: Siamese Encoder Module, Center Guiding Appearance Diffusion Module, and Dynamic Information Fusion Module. Firstly, we take a siamese encoder to extract the feature representations of paired frames (reference frame and current frame). Then, a Center Guiding Appearance Diffusion Module is designed to capture the inter-frame feature (dense correspondences between reference frame and current frame), intra-frame feature (dense correspondences in current frame), and original semantic feature of current frame. Specifically, we establish a Center Prediction Branch to predict the center location of the foreground object in current frame and leverage the center point information as spatial guidance prior to enhance the inter-frame and intra-frame feature extraction, and thus the feature representation considerably focus on the foreground objects. Finally, we propose a Dynamic Information Fusion Module to automatically select relatively important features through three aforementioned different level features. Extensive experiments on DAVIS2016, Youtube-object, and FBMS datasets show that our proposed F2Net achieves the state-of-the-art performance with significant improvement.",ディープラーニングベースの方法は、教師なしビデオオブジェクトのセグメンテーションで大きな進歩を遂げましたが、困難なシナリオ（視覚的な類似性、オクルージョン、外観の変化など）はまだ適切に処理されていません。これらの問題を軽減するために、フォアグラウンドオブジェクトのフレーム間詳細を掘り下げてセグメンテーションパフォーマンスを効果的に向上させる、新しいフォーカスオンフォアグラウンドネットワーク（F2Net）を提案します。具体的には、提案されたネットワークは、シャムエンコーダモジュール、センターガイド外観拡散モジュール、および動的情報融合モジュールの3つの主要部分で構成されています。まず、シャムエンコーダーを使用して、ペアのフレーム（参照フレームと現在のフレーム）の特徴表現を抽出します。次に、センターガイド外観拡散モジュールは、フレーム間機能（参照フレームと現在のフレーム間の密な対応）、フレーム内機能（現在のフレーム内の密な対応）、および現在のフレームの元のセマンティック機能をキャプチャするように設計されています。具体的には、現在のフレーム内の前景オブジェクトの中心位置を予測し、フレーム間およびフレーム内の特徴抽出を強化する前に、中心点情報を空間ガイダンスとして活用するための中心予測ブランチを確立します。これにより、特徴表現にかなり焦点が当てられます。フォアグラウンドオブジェクト。最後に、前述の3つの異なるレベルの機能を通じて、比較的重要な機能を自動的に選択する動的情報融合モジュールを提案します。 DAVIS2016、Youtube-object、およびFBMSデータセットでの広範な実験は、提案されたF2Netが大幅な改善を伴う最先端のパフォーマンスを達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/69107a71c9533e204790890591a72fda88d4669a/1-Figure1-1.png
Learning to Count via Unbalanced Optimal Transport,"['Zhiheng Ma', 'Xing Wei', 'Xiaopeng Hong', 'Hui Lin', 'Yunfeng Qiu', 'Yihong Gong']",,,,
Error-Aware Density Isomorphism Reconstruction for Unsupervised Cross-Domain Crowd Counting,"['Yuhang He', 'Zhiheng Ma', 'Xing Wei', 'Xiaopeng Hong', 'Wei Ke', 'Yihong Gong']",,,,
MangaGAN: Unpaired Photo-to-Manga Translation Based on the Methodology of Manga Drawing,"['Hao Su', 'Jianwei Niu', 'Xuefeng Liu', 'Qingfeng Li', 'Jiahe Cui', 'Ji Wan']",https://arxiv.org/abs/2004.10634,"Manga is a world popular comic form originated in Japan, which typically employs black-and-white stroke lines and geometric exaggeration to describe humans' appearances, poses, and actions. In this paper, we propose MangaGAN, the first method based on Generative Adversarial Network (GAN) for unpaired photo-to-manga translation. Inspired by how experienced manga artists draw manga, MangaGAN generates the geometric features of manga face by a designed GAN model and delicately translates each facial region into the manga domain by a tailored multi-GANs architecture. For training MangaGAN, we construct a new dataset collected from a popular manga work, containing manga facial features, landmarks, bodies, and so on. Moreover, to produce high-quality manga faces, we further propose a structural smoothing loss to smooth stroke-lines and avoid noisy pixels, and a similarity preserving module to improve the similarity between domains of photo and manga. Extensive experiments show that MangaGAN can produce high-quality manga faces which preserve both the facial similarity and a popular manga style, and outperforms other related state-of-the-art methods.",マンガは日本発祥の世界的に人気のある漫画で、通常、白黒のストロークラインと幾何学的な誇張を使用して、人間の外観、ポーズ、アクションを表現します。本論文では、対になっていない写真からマンガへの翻訳のための生成的敵対的ネットワーク（GAN）に基づく最初の方法であるMangaGANを提案する。経験豊富なマンガ家がマンガを描く方法に触発されたMangaGANは、設計されたGANモデルによってマンガの顔の幾何学的特徴を生成し、調整されたマルチGANアーキテクチャによって各顔の領域をマンガドメインに繊細に変換します。 MangaGANをトレーニングするために、人気のあるマンガ作品から収集された、マンガの顔の特徴、ランドマーク、ボディなどを含む新しいデータセットを構築します。さらに、高品質のマン​​ガの顔を作成するために、ストロークラインを滑らかにしてノイズの多いピクセルを回避するための構造平滑化損失と、写真とマンガのドメイン間の類似性を向上させる類似性保存モジュールをさらに提案します。広範な実験により、MangaGANは、顔の類似性と人気のあるマンガスタイルの両方を維持し、他の関連する最先端の方法よりも優れた高品質のマン​​ガの顔を作成できることが示されています。,https://d3i71xaburhd42.cloudfront.net/55f45f009bdf4f8ec0bbf5c1c0da6db0e39508da/3-Figure2-1.png
Rain Streak Removal via Dual Graph Convolutional Network,"['Xueyang Fu', 'Qi Qi', 'Yurui Zhu', 'Xinghao Ding', 'Zheng-Jun Zha']",,"Deep convolutional neural networks (CNNs) have become dominant in the single image de-raining area. However, most deep CNNs-based de-raining methods are designed by stacking vanilla convolutional layers, which can only be used to model local relations. Therefore, long-range contextual information is rarely considered for this specific task. To address the above problem, we propose a simple yet effective dual graph convolutional network (GCN) for single image rain removal. Specifically, we design two graphs to perform global relational modeling and reasoning. The first GCN is used to explore global spatial relations among pixels in feature maps, while the second GCN models the global relations across the channels. Compared to standard convolutional operations, the proposed two graphs enable the network to extract representations from new dimensions. To achieve the image rain removal, we further embed these two graphs and multi-scale dilated convolution into a symmetrically skip-connected network architecture. Therefore, our dual graph convolutional network is able to well handle complex and spatially long rain streaks by exploring multiple representations, e.g., multi-scale local feature, global spatial coherence and cross-channel correlation. Meanwhile, our model is easy to implement, end-to-end trainable and computationally efficient. Extensive experiments on synthetic and real data demonstrate that our method achieves significant improvements over the recent state-of-the-art methods.",深い畳み込みニューラルネットワーク（CNN）は、単一画像の降雨防止領域で支配的になっています。ただし、ほとんどのディープCNNベースの降雨除去方法は、バニラ畳み込み層を積み重ねることによって設計されています。これは、ローカル関係のモデル化にのみ使用できます。したがって、この特定のタスクで長距離のコンテキスト情報が考慮されることはめったにありません。上記の問題に対処するために、単一画像の雨を除去するためのシンプルで効果的なデュアルグラフ畳み込みネットワーク（GCN）を提案します。具体的には、グローバルなリレーショナルモデリングと推論を実行するために2つのグラフを設計します。最初のGCNは、特徴マップ内のピクセル間のグローバルな空間関係を調査するために使用され、2番目のGCNは、チャネル全体のグローバルな関係をモデル化します。標準の畳み込み演算と比較して、提案された2つのグラフにより、ネットワークは新しい次元から表現を抽出できます。画像の雨の除去を実現するために、これら2つのグラフとマルチスケールの拡張畳み込みを、対称的にスキップ接続されたネットワークアーキテクチャにさらに埋め込みます。したがって、双対グラフ畳み込みネットワークは、マルチスケールの局所的特徴、グローバルな空間コヒーレンス、クロスチャネル相関などの複数の表現を探索することにより、複雑で空間的に長い雨の筋をうまく処理できます。一方、私たちのモデルは実装が簡単で、エンドツーエンドでトレーニング可能で、計算効率が高いです。合成データと実際のデータに関する広範な実験は、私たちの方法が最近の最先端の方法よりも大幅に改善されていることを示しています。,https://d3i71xaburhd42.cloudfront.net/0794cd16b9c60ffb1f162f37b28005151024253b/3-Figure1-1.png
RevMan: Revenue-Aware Multi-Task Online Insurance Recommendation,"['Yu Li', 'Yi Zhang', 'Lu Gan', 'GengWei Hong', 'Zimu Zhou', 'Qiang Li']",,,,
Tailoring Embedding Function to Heterogeneous Few-Shot Tasks by Global and Local Feature Adaptors,"['Su Lu', 'Han-Jia Ye', 'De-Chuan Zhan']",,,,
Topic-Oriented Spoken Dialogue Summarization for Customer Service with Saliency-Aware Topic Modeling,"['Yicheng Zou', 'Lujun Zhao', 'Yangyang Kang', 'Jun Lin', 'Minlong Peng', 'Zhuoren Jiang', 'Changlong Sun', 'Qi Zhang', 'Xuanjing Huang', 'Xiaozhong Liu']",https://arxiv.org/abs/2012.07311,"In a customer service system, dialogue summarization can boost service efficiency by automatically creating summaries for long spoken dialogues in which customers and agents try to address issues about specific topics. In this work, we focus on topic-oriented dialogue summarization, which generates highly abstractive summaries that preserve the main ideas from dialogues. In spoken dialogues, abundant dialogue noise and common semantics could obscure the underlying informative content, making the general topic modeling approaches difficult to apply. In addition, for customer service, role-specific information matters and is an indispensable part of a summary. To effectively perform topic modeling on dialogues and capture multi-role information, in this work we propose a novel topic-augmented two-stage dialogue summarizer (TDS) jointly with a saliency-aware neural topic model (SATM) for topic-oriented summarization of customer service dialogues. Comprehensive studies on a real-world Chinese customer service dataset demonstrated the superiority of our method against several strong baselines.",カスタマーサービスシステムでは、ダイアログの要約は、顧客とエージェントが特定のトピックに関する問題に対処しようとする長い口頭のダイアログの要約を自動的に作成することにより、サービスの効率を高めることができます。この作業では、トピック指向の対話要約に焦点を当てます。これは、対話からの主要なアイデアを保持する非常に抽象的な要約を生成します。口頭の会話では、豊富な会話のノイズと一般的なセマンティクスが、基礎となる有益なコンテンツを覆い隠し、一般的なトピックモデリングアプローチの適用を困難にする可能性があります。さらに、顧客サービスにとって、役割固有の情報は重要であり、要約の不可欠な部分です。対話のトピックモデリングを効果的に実行し、マルチロール情報をキャプチャするために、この作業では、トピック指向の要約のための顕著性認識ニューラルトピックモデル（SATM）と共同で、新しいトピック拡張2段階対話サマライザ（TDS）を提案します。カスタマーサービスの対話。実世界の中国の顧客サービスデータセットに関する包括的な研究は、いくつかの強力なベースラインに対する私たちの方法の優位性を示しました。,https://d3i71xaburhd42.cloudfront.net/922cb8275609411bf3f894420a814cc9faa31e02/1-Figure1-1.png
Boundary-Aware Geometric Encoding for Semantic Segmentation of Point Clouds,"['Jingyu Gong', 'Jiachen Xu', 'Xin Tan', 'Jie Zhou', 'Yanyun Qu', 'Yuan Xie', 'Lizhuang Ma']",https://arxiv.org/abs/2101.02381,"Boundary information plays a significant role in 2D image segmentation, while usually being ignored in 3D point cloud segmentation where ambiguous features might be generated in feature extraction, leading to misclassification in the transition area between two objects. In this paper, firstly, we propose a Boundary Prediction Module (BPM) to predict boundary points. Based on the predicted boundary, a boundary-aware Geometric Encoding Module (GEM) is designed to encode geometric information and aggregate features with discrimination in a neighborhood, so that the local features belonging to different categories will not be polluted by each other. To provide extra geometric information for boundary-aware GEM, we also propose a light-weight Geometric Convolution Operation (GCO), making the extracted features more distinguishing. Built upon the boundary-aware GEM, we build our network and test it on benchmarks like ScanNet v2, S3DIS. Results show our methods can significantly improve the baseline and achieve state-of-the-art performance. Code is available at https://github.com/JchenXu/BoundaryAwareGEM.",境界情報は2D画像セグメンテーションで重要な役割を果たしますが、特徴抽出であいまいな特徴が生成され、2つのオブジェクト間の遷移領域で誤分類が発生する可能性がある3D点群セグメンテーションでは通常無視されます。本論文では、まず、境界点を予測するための境界予測モジュール（BPM）を提案します。予測された境界に基づいて、境界対応の幾何学的エンコーディングモジュール（GEM）は、幾何学的情報をエンコードし、近隣の識別を使用して特徴を集約するように設計されているため、異なるカテゴリに属する​​ローカル特徴が互いに汚染されることはありません。境界を意識したGEMに追加の幾何学的情報を提供するために、軽量の幾何学的畳み込み演算（GCO）も提案し、抽出された特徴をより際立たせます。境界を意識したGEMに基づいて構築され、ネットワークを構築し、ScanNet v2、S3DISなどのベンチマークでテストします。結果は、私たちの方法がベースラインを大幅に改善し、最先端のパフォーマンスを達成できることを示しています。コードはhttps://github.com/JchenXu/BoundaryAwareGEMで入手できます。,https://d3i71xaburhd42.cloudfront.net/3f4b0c80346cfb2a8ae224ff2beda943eb00d0e4/2-Figure1-1.png
Task Aligned Generative Meta-Learning for Zero-Shot Learning,"['Zhe Liu', 'Yun Li', 'Lina Yao', 'Xianzhi Wang', 'Guodong Long']",,,,
When Hashing Met Matching: Efficient Spatio-Temporal Search for Ridesharing,['Chinmoy Dutta'],,"Carpooling, or sharing a ride with other passengers, holds immense potential for urban transportation. Ridesharing platforms enable such sharing of rides using real-time data. Finding ride matches in real-time at urban scale is a difficult combinatorial optimization task and mostly heuristic approaches are applied. In this work, we mathematically model the problem as that of finding near-neighbors and devise a novel efficient spatio-temporal search algorithm based on the theory of locality sensitive hashing for Maximum Inner Product Search (MIPS). The proposed algorithm can find $k$ near-optimal potential matches for every ride from a pool of $n$ rides in time $O(n^{1 + \rho} (k + \log n) \log k)$ and space $O(n^{1 + \rho} \log k)$ for a small $\rho < 1$. Our algorithm can be extended in several useful and interesting ways increasing its practical appeal. Experiments with large NY yellow taxi trip datasets show that our algorithm consistently outperforms state-of-the-art heuristic methods thereby proving its practical applicability.",相乗り、または他の乗客との乗車の共有は、都市交通の大きな可能性を秘めています。ライドシェアリングプラットフォームは、リアルタイムデータを使用してライドのそのような共有を可能にします。都市規模でリアルタイムでライドマッチを見つけることは、難しい組み合わせ最適化タスクであり、ほとんどの場合、ヒューリスティックなアプローチが適用されます。この作業では、問題を数学的に近傍を見つける問題としてモデル化し、Maximum Inner Product Search（MIPS）の局所性鋭敏型ハッシュの理論に基づいた新しい効率的な時空間検索アルゴリズムを考案します。提案されたアルゴリズムは、時間O（n ^（1 +）（k + log n）log k）および空間O（n ^（1 +）log）のn回のライドのプールからすべてのライドに対してk個のほぼ最適な潜在的一致を見つけることができます。 k）小さい&lt;1の場合。私たちのアルゴリズムは、いくつかの有用で興味深い方法で拡張でき、実用的な魅力を高めます。大規模なニューヨークの黄色いタクシー旅行データセットを使った実験は、私たちのアルゴリズムが常に最先端のヒューリスティック手法を上回っていることを示しており、それによってその実用性が証明されています。,https://d3i71xaburhd42.cloudfront.net/2644fa1dca35b9d708d50cc4b903f1a00233412c/7-Figure1-1.png
SHOT-VAE: Semi-Supervised Deep Generative Models with Label-Aware ELBO Approximations,"['Haozhe Feng', 'Minghao Chen', 'Minfeng Zhu', 'Kezhi Kong', 'Tianye Zhang', 'Wei Chen']",https://arxiv.org/abs/2011.10684,"Semi-supervised variational autoencoders (VAEs) have obtained strong results, but have also encountered the challenge that good ELBO values do not always imply accurate inference results. In this paper, we investigate and propose two causes of this problem: (1) The ELBO objective cannot utilize the label information directly. (2) A bottleneck value exists and continuing to optimize ELBO after this value will not improve inference accuracy. On the basis of the experiment results, we propose SHOT-VAE to address these problems without introducing additional prior knowledge. The SHOT-VAE offers two contributions: (1) A new ELBO approximation named smooth-ELBO that integrates the label predictive loss into ELBO. (2) An approximation based on optimal interpolation that breaks the ELBO value bottleneck by reducing the margin between ELBO and the data likelihood. The SHOT-VAE achieves good performance with a 25.30% error rate on CIFAR-100 with 10k labels and reduces the error rate to 6.11% on CIFAR-10 with 4k labels.",半教師あり変分オートエンコーダー（VAE）は強力な結果を得ていますが、良好なELBO値が必ずしも正確な推論結果を意味するとは限らないという課題にも直面しています。この論文では、この問題の2つの原因を調査し、提案します。（1）ELBO目的では、ラベル情報を直接利用できません。 （2）ボトルネック値が存在し、この値の後でELBOを最適化し続けても、推論の精度は向上しません。実験結果に基づいて、追加の事前知識を導入することなくこれらの問題に対処するためにSHOT-VAEを提案します。 SHOT-VAEは、次の2つの貢献を提供します。（1）ラベル予測損失をELBOに統合するsmooth-ELBOという名前の新しいELBO近似。 （2）ELBOとデータ尤度の間のマージンを減らすことにより、ELBO値のボトルネックを解消する最適な内挿に基づく近似。 SHOT-VAEは25.30で良好なパフォーマンスを達成します,https://d3i71xaburhd42.cloudfront.net/e06e573edffdc741c2e9e232b7ee6ee87229cfe1/2-Figure1-1.png
Many-to-One Distribution Learning and K-Nearest Neighbor Smoothing for Thoracic Disease Identification,"['Yi Zhou', 'Lei Huang', 'Tianfei Zhou', 'Ling Shao']",,,,
Asynchronous Teacher Guided Bit-wise Hard Mining for Online Hashing,"['Sheng Jin', 'Qin Zhou', 'Hongxun Yao', 'Yao Liu', 'Xian-Sheng Hua']",,,,
Secure Bilevel Asynchronous Vertical Federated Learning with Backward Updating,"['Qingsong Zhang', 'Bin Gu', 'Cheng Deng', 'Heng Huang']",,,,
Detecting Beneficial Feature Interactions for Recommender Systems,"['Yixin Su', 'Rui Zhang', 'Sarah Erfani', 'Zhenghua Xu']",https://arxiv.org/abs/2008.00404,"Feature interactions are essential for achieving high accuracy in recommender systems. Many studies take into account the interaction between every pair of features. However, this is suboptimal because some feature interactions may not be that relevant to the recommendation result, and taking them into account may introduce noise and decrease recommendation accuracy. To make the best out of feature interactions, we propose a graph neural network approach to effectively model them, together with a novel technique to automatically detect those feature interactions that are beneficial in terms of recommendation accuracy. The automatic feature interaction detection is achieved via edge prediction with an L0 activation regularization. Our proposed model is proved to be effective through the information bottleneck principle and statistical interaction theory. Experimental results show that our model (i) outperforms existing baselines in terms of accuracy, and (ii) automatically identifies beneficial feature interactions.",レコメンダーシステムで高精度を達成するには、機能の相互作用が不可欠です。多くの研究では、機能のすべてのペア間の相互作用が考慮されています。ただし、一部の機能の相互作用は推奨結果に関連しない可能性があり、それらを考慮に入れるとノイズが発生し、推奨の精度が低下する可能性があるため、これは最適ではありません。機能の相互作用を最大限に活用するために、推奨精度の点で有益な機能の相互作用を自動的に検出する新しい手法とともに、それらを効果的にモデル化するグラフニューラルネットワークアプローチを提案します。自動機能相互作用検出は、L0アクティベーション正則化を使用したエッジ予測によって実現されます。提案されたモデルは、情報ボトルネック原理と統計的相互作用理論を通じて効果的であることが証明されています。実験結果は、私たちのモデルが（i）精度の点で既存のベースラインを上回り、（ii）有益な機能の相互作用を自動的に識別することを示しています。,
Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval,"['Jinpeng Wang', 'Bin Chen', 'Qiang Zhang', 'Zaiqiao Meng', 'Shangsong Liang', 'Shutao Xia']",,,,
Agreement-Discrepancy-Selection: Active Learning with Progressive Distribution Alignment,"['Mengying Fu', 'Tianning Yuan', 'Fang Wan', 'Songcen Xu', 'Qixiang Ye']",,,,
Optimizing Information Theory Based Bitwise Bottlenecks for Efficient Mixed-Precision Activation Quantization,"['Xichuan Zhou', 'Kui Liu', 'Cong Shi', 'Haijun Liu', 'Ji Liu']",,,,
A Global Occlusion-Aware Approach to Self-Supervised Monocular Visual Odometry,"['Yao Lu', 'Xiaoli Xu', 'Mingyu Ding', 'Zhiwu Lu', 'Tao Xiang']",,,,
Traffic Flow Prediction with Vehicle Trajectories,"['Mingqian Li', 'Panrong Tong', 'Mo Li', 'Zhongming Jin', 'Jianqiang Huang', 'Xian-Sheng Hua']",,,,
Camera-Aware Proxies for Unsupervised Person Re-Identification,"['Menglin Wang', 'Baisheng Lai', 'Jianqiang Huang', 'Xiaojin Gong', 'Xian-Sheng Hua']",https://arxiv.org/abs/2012.10674,"This paper tackles the purely unsupervised person reidentification (Re-ID) problem that requires no annotations. Some previous methods adopt clustering techniques to generate pseudo labels and use the produced labels to train ReID models progressively. These methods are relatively simple but effective. However, most clustering-based methods take each cluster as a pseudo identity class, neglecting the large intra-ID variance caused mainly by the change of camera views. To address this issue, we propose to split each single cluster into multiple proxies and each proxy represents the instances coming from the same camera. These camera-aware proxies enable us to deal with large intra-ID variance and generate more reliable pseudo labels for learning. Based on the camera-aware proxies, we design both intraand inter-camera contrastive learning components for our Re-ID model to effectively learn the ID discrimination ability within and across cameras. Meanwhile, a proxy-balanced sampling strategy is also designed, which facilitates our learning further. Extensive experiments on three large-scale Re-ID datasets show that our proposed approach outperforms most unsupervised methods by a significant margin. Especially, on the challenging MSMT17 dataset, we gain 14.3% Rank-1 and 10.2% mAP improvements when compared to the second place.",このホワイトペーパーでは、注釈を必要としない、純粋に教師なしの人物再識別（Re-ID）の問題に取り組んでいます。以前のいくつかの方法では、クラスタリング手法を採用して疑似ラベルを生成し、生成されたラベルを使用してReIDモデルを段階的にトレーニングします。これらの方法は比較的単純ですが効果的です。ただし、ほとんどのクラスタリングベースの方法では、各クラスターを疑似IDクラスとして受け取り、主にカメラビューの変更によって引き起こされるID内の大きな変動を無視します。この問題に対処するために、各単一クラスターを複数のプロキシに分割し、各プロキシが同じカメラからのインスタンスを表すことを提案します。これらのカメラ対応プロキシにより、ID内の大きな変動に対処し、学習用のより信頼性の高い疑似ラベルを生成できます。カメラ対応プロキシに基づいて、Re-IDモデルのカメラ内およびカメラ間の対照学習コンポーネントを設計し、カメラ内およびカメラ間のID識別能力を効果的に学習します。一方、プロキシバランスのとれたサンプリング戦略も設計されているため、学習がさらに容易になります。 3つの大規模なRe-IDデータセットでの広範な実験は、提案されたアプローチがほとんどの教師なし手法よりも大幅に優れていることを示しています。特に、やりがいのあるMSMT17データセットでは、14.3が得られます。,https://d3i71xaburhd42.cloudfront.net/c81aac4d1bbc5f835359ece24ef19ff748995a6f/1-Figure1-1.png
Large Norms of CNN Layers Do Not Hurt Adversarial Robustness,"['Youwei Liang', 'Dong Huang']",https://arxiv.org/abs/2009.08435,"Since the Lipschitz properties of convolutional neural network (CNN) are widely considered to be related to adversarial robustness, we theoretically characterize the $\ell_1$ norm and $\ell_\infty$ norm of 2D multi-channel convolutional layers and provide efficient methods to compute the exact $\ell_1$ norm and $\ell_\infty$ norm. Based on our theorem, we propose a novel regularization method termed norm decay, which can effectively reduce the norms of CNN layers. Experiments show that norm-regularization methods, including norm decay, weight decay, and singular value clipping, can improve generalization of CNNs. However, we are surprised to find that they can slightly hurt adversarial robustness. Furthermore, we compute the norms of layers in the CNNs trained with three different adversarial training frameworks and find that adversarially robust CNNs have comparable or even larger norms than their non-adversarially robust counterparts. Moreover, we prove that under a mild assumption, adversarially robust classifiers can be achieved with neural networks and an adversarially robust neural network can have arbitrarily large Lipschitz constant. For these reasons, enforcing small norms of CNN layers may be neither effective nor necessary in achieving adversarial robustness. Our code is available at this https URL.",畳み込みニューラルネットワーク（CNN）のLipschitzプロパティは、敵対的なロバスト性に関連していると広く考えられているため、2Dマルチチャネル畳み込み層のl1ノルムとl（）ノルムを理論的に特徴付け、正確なl1ノルムを計算する効率的な方法を提供します。 l（）ノルム。私たちの定理に基づいて、CNN層のノルムを効果的に減らすことができるノルム減衰と呼ばれる新しい正則化法を提案します。実験は、ノルム減衰、重み減衰、特異値クリッピングなどのノルム正則化手法がCNNの一般化を改善できることを示しています。ただし、敵の堅牢性をわずかに損なう可能性があることに驚いています。さらに、3つの異なる敵対的トレーニングフレームワークでトレーニングされたCNNのレイヤーのノルムを計算し、敵対的にロバストなCNNは、非敵対的にロバストなCNNと同等またはそれ以上のノルムを持っていることがわかります。さらに、穏やかな仮定の下で、敵対的にロバストな分類器がニューラルネットワークで達成でき、敵対的にロバストなニューラルネットワークが任意に大きなリプシッツ定数を持つことができることを証明します。これらの理由から、CNN層の小さな基準を適用することは、敵対的なロバスト性を達成するのに効果的でも必要でもない可能性があります。私たちのコードはこのhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/3af4973f9790bafbdd2181e836e12bbfa76468de/3-Figure1-1.png
CIA-SSD: Confident IoU-Aware Single-Stage Object Detector From Point Cloud,"['Wu Zheng', 'Weiliang Tang', 'Sijin Chen', 'Li Jiang', 'Chi-Wing Fu']",https://arxiv.org/abs/2012.03015,"Existing single-stage detectors for locating objects in point clouds often treat object localization and category classification as separate tasks, so the localization accuracy and classification confidence may not well align. To address this issue, we present a new single-stage detector named the Confident IoU-Aware Single-Stage object Detector (CIA-SSD). First, we design the lightweight Spatial-Semantic Feature Aggregation module to adaptively fuse high-level abstract semantic features and low-level spatial features for accurate predictions of bounding boxes and classification confidence. Also, the predicted confidence is further rectified with our designed IoU-aware confidence rectification module to make the confidence more consistent with the localization accuracy. Based on the rectified confidence, we further formulate the Distance-variant IoU-weighted NMS to obtain smoother regressions and avoid redundant predictions. We experiment CIA-SSD on 3D car detection in the KITTI test set and show that it attains top performance in terms of the official ranking metric (moderate AP 80.28%) and above 32 FPS inference speed, outperforming all prior single-stage detectors. The code is available at https://github.com/Vegeta2020/CIA-SSD.",点群内のオブジェクトを特定するための既存の単一ステージ検出器は、オブジェクトのローカリゼーションとカテゴリ分類を別々のタスクとして扱うことが多いため、ローカリゼーションの精度と分類の信頼性がうまく一致しない場合があります。この問題に対処するために、Confident IoU-Aware Single-Stage object Detector（CIA-SSD）という名前の新しいシングルステージ検出器を紹介します。まず、軽量の空間セマンティック機能集約モジュールを設計して、高レベルの抽象的なセマンティック機能と低レベルの空間機能を適応的に融合し、境界ボックスと分類の信頼性を正確に予測します。また、予測された信頼度は、設計されたIoU対応の信頼度修正モジュールを使用してさらに修正され、信頼度がローカリゼーションの精度とより一致するようになります。修正された信頼度に基づいて、距離バリアントIoU加重NMSをさらに定式化して、よりスムーズな回帰を取得し、冗長な予測を回避します。 KITTIテストセットで3D車の検出についてCIA-SSDを実験し、公式のランキング指標（中程度のAP 80.28）の観点から最高のパフォーマンスを達成することを示します。,https://d3i71xaburhd42.cloudfront.net/65a60ace6af2c061d5000688727d712c2755e955/1-Figure1-1.png
How Does Data Augmentation Affect Privacy in Machine Learning?,"['Da Yu', 'Huishuai Zhang', 'Wei Chen', 'Jian Yin', 'Tie-Yan Liu']",https://arxiv.org/abs/2007.10567,"It is observed in the literature that data augmentation can significantly mitigate membership inference (MI) attack. However, in this work, we challenge this observation by proposing new MI attacks to utilize the information of augmented data. MI attack is widely used to measure the model's information leakage of the training set. We establish the optimal membership inference when the model is trained with augmented data, which inspires us to formulate the MI attack as a set classification problem, i.e., classifying a set of augmented instances instead of a single data point, and design input permutation invariant features. Empirically, we demonstrate that the proposed approach universally outperforms original methods when the model is trained with data augmentation. Even further, we show that the proposed approach can achieve higher MI attack success rates on models trained with some data augmentation than the existing methods on models trained without data augmentation. Notably, we achieve a 70.1% MI attack success rate on CIFAR10 against a wide residual network while the previous best approach only attains 61.9%. This suggests the privacy risk of models trained with data augmentation could be largely underestimated.",データの増強により、メンバーシップ推論（MI）攻撃を大幅に軽減できることが文献で観察されています。ただし、この作業では、拡張データの情報を利用するための新しいMI攻撃を提案することにより、この観察に挑戦します。 MI攻撃は、トレーニングセットのモデル情報漏えいを測定するために広く使用されています。モデルが拡張データでトレーニングされるときに最適なメンバーシップ推論を確立します。これにより、MI攻撃をセット分類問題として定式化するようになります。つまり、単一のデータポイントではなく、拡張インスタンスのセットを分類し、入力順列不変機能を設計します。 。経験的に、モデルがデータ拡張でトレーニングされた場合、提案されたアプローチが元の方法よりも普遍的に優れていることを示します。さらに、提案されたアプローチは、データ拡張なしでトレーニングされたモデルの既存の方法よりも、いくつかのデータ拡張でトレーニングされたモデルで高いMI攻撃成功率を達成できることを示します。特に、70.1を達成しています,
Achieving Envy-Freeness and Equitability with Monetary Transfers,['Haris Aziz'],https://arxiv.org/abs/2003.08125,"When allocating indivisible resources or tasks, an envy-free allocation or equitable allocation may not exist. We present a sufficient condition and an algorithm to achieve envy-freeness and equitability when monetary transfers are allowed. The approach works for any agent valuation functions (positive or negative) as long as they satisfy superadditivity. For the case of additive utilities, we present a characterization of allocations that can simultaneously be made equitable and envy-free via payments.",分割できないリソースまたはタスクを割り当てる場合、羨望のない割り当てまたは公平な割り当てが存在しない可能性があります。送金が許可されている場合に、羨望の自由と公平性を達成するための十分条件とアルゴリズムを提示します。このアプローチは、優加法性を満たす限り、エージェントの評価関数（正または負）に対して機能します。付加的な効用の場合、支払いを介して公平かつ羨望のないものにすることができる割り当ての特性を示します。,https://d3i71xaburhd42.cloudfront.net/efaa1bb26c224d355611b5b1710731564da29716/8-Figure5-1.png
R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object,"['Xue Yang', 'Junchi Yan', 'Ziming Feng', 'Tao He']",https://arxiv.org/abs/1908.05612,"Rotation detection is a challenging task due to the difficulties of locating the multi-angle objects and separating them accurately and quickly from the background. Though considerable progress has been made, for practical settings, there still exist challenges for rotating objects with large aspect ratio, dense distribution and category extremely imbalance. In this paper, we propose an end-to-end refined single-stage rotation detector for fast and accurate positioning objects. Considering the shortcoming of feature misalignment in existing refined single-stage detector, we design a feature refinement module to improve detection performance by getting more accurate features. The key idea of feature refinement module is to re-encode the position information of the current refined bounding box to the corresponding feature points through feature interpolation to realize feature reconstruction and alignment. Extensive experiments on two remote sensing public datasets DOTA, HRSC2016 as well as scene text data ICDAR2015 show the state-of-the-art accuracy and speed of our detector. Code is available at this https URL.",回転の検出は、マルチアングルオブジェクトの位置を特定し、それらを背景から正確かつ迅速に分離することが難しいため、困難な作業です。かなりの進歩が見られましたが、実際の設定では、アスペクト比が大きく、分布が密で、カテゴリが極端に不均衡なオブジェクトを回転させるという課題が依然として存在します。この論文では、高速で正確な測位オブジェクトのためのエンドツーエンドの洗練された単段回転検出器を提案します。既存の洗練された単段検出器の特徴の不整合の欠点を考慮して、より正確な特徴を取得することによって検出性能を向上させる特徴洗練モジュールを設計します。特徴改良モジュールの重要なアイデアは、現在の改良された境界ボックスの位置情報を、特徴の再構成と位置合わせを実現するために、特徴の補間によって対応する特徴点に再エンコードすることです。 2つのリモートセンシング公開データセットDOTA、HRSC2016、およびシーンテキストデータICDAR2015での広範な実験は、検出器の最先端の精度と速度を示しています。コードはこのhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/edada2363969e3929366df06aad8a8e9c73ba32f/1-Figure1-1.png
EECBS: A Bounded-Suboptimal Search for Multi-Agent Path Finding,"['Jiaoyang Li', 'Wheeler Ruml', 'Sven Koenig']",https://arxiv.org/abs/2010.01367,"Multi-Agent Path Finding (MAPF), i.e., finding collision-free paths for multiple robots, is important for many applications where small runtimes are important, including the kind of automated warehouses operated by Amazon. CBS is a leading two-level search algorithm for solving MAPF optimally. ECBS is a bounded-suboptimal variant of CBS that uses focal search to speed up CBS by sacrificing optimality and instead guaranteeing that the costs of its solution are within a given factor of optimal. In this paper, we study how to decrease its runtime even further using inadmissible heuristics. Motivated by Explicit Estimation Search (EES), we propose Explicit Estimation CBS (EECBS), a new bounded-suboptimal variant of CBS, that uses online learning to inadmissibly estimate the cost of the solution under each high-level node and uses EES to choose which high-level node to expand next. We also investigate recent improvements to CBS and adapt them to EECBS. We find that EECBS with the improvements runs significantly faster than the MAPF algorithms ECBS, BCP-7, and eMDD-SAT on a variety of MAPF instances. We hope that the scalability of EECBS enables wider adoption of MAPF formulations in practical applications.",マルチエージェントパスファインディング（MAPF）、つまり複数のロボットの衝突のないパスを見つけることは、Amazonが運営する自動倉庫の種類など、小さなランタイムが重要な多くのアプリケーションにとって重要です。 CBSは、MAPFを最適に解決するための主要な2レベルの検索アルゴリズムです。 ECBSは、CBSの有界準最適バリアントであり、フォーカルサーチを使用して、最適性を犠牲にし、代わりにそのソリューションのコストが特定の最適係数内にあることを保証することにより、CBSを高速化します。このホワイトペーパーでは、許容できないヒューリスティックを使用して、ランタイムをさらに短縮する方法を研究します。明示的推定検索（EES）を動機として、CBSの新しい有界準最適バリアントである明示的推定CBS（EECBS）を提案します。これは、オンライン学習を使用して、各高レベルノードでのソリューションのコストを許容できないほど推定し、EESを使用して選択します。次に展開する高レベルノード。また、CBSの最近の改善点を調査し、それらをEECBSに適合させます。改善されたEECBSは、さまざまなMAPFインスタンスでMAPFアルゴリズムECBS、BCP-7、およびeMDD-SATよりも大幅に高速に実行されることがわかりました。 EECBSのスケーラビリティにより、実際のアプリケーションでMAPF定式化をより広く採用できるようになることを願っています。,https://d3i71xaburhd42.cloudfront.net/0a36a23ec07e9702fc8359a3219cda9f5930d1e3/2-Figure1-1.png
Fine-Grained Generalization Analysis of Vector-Valued Learning,"['Liang Wu', 'Antoine Ledent', 'Yunwen Lei', 'Marius Kloft']",,,,
Hand-Model-Aware Sign Language Recognition,"['Hezhen Hu', 'Wengang Zhou', 'Houqiang Li']",,,,
Endomorphisms of Classical Planning Tasks,"['Rostislav Horčík', 'Daniel Fišer']",,,,
TransTailor: Pruning the Pre-Trained Model for Improved Transfer Learning,"['Bingyan Liu', 'Yifeng Cai', 'Yao Guo', 'Xiangqun Chen']",,,,
Dual Quaternion Knowledge Graph Embeddings,"['Zongsheng Cao', 'Qianqian Xu', 'Zhiyong Yang', 'Xiaochun Cao', 'Qingming Huang']",,,,
Defending against Contagious Attacks on a Network with Resource Reallocation,"['Rufan Bai', 'Haoxing Lin', 'Xinyu Yang', 'Xiaowei Wu', 'Minming Li', 'Weijia Jia']",https://arxiv.org/abs/2012.01036,"In classic network security games, the defender distributes defending resources to the nodes of the network, and the attacker attacks a node, with the objective to maximize the damage caused. Existing models assume that the attack at node u causes damage only at u. However, in many real-world security scenarios, the attack at a node u spreads to the neighbors of u and can cause damage at multiple nodes, e.g., for the outbreak of a virus. In this paper, we consider the network defending problem against contagious attacks. 
Existing works that study shared resources assume that the resource allocated to a node can be shared or duplicated between neighboring nodes. However, in real world, sharing resource naturally leads to a decrease in defending power of the source node, especially when defending against contagious attacks. To this end, we study the model in which resources allocated to a node can only be transferred to its neighboring nodes, which we refer to as a reallocation process. 
We show that this more general model is difficult in two aspects: (1) even for a fixed allocation of resources, we show that computing the optimal reallocation is NP-hard; (2) for the case when reallocation is not allowed, we show that computing the optimal allocation (against contagious attack) is also NP-hard. For positive results, we give a mixed integer linear program formulation for the problem and a bi-criteria approximation algorithm. Our experimental results demonstrate that the allocation and reallocation strategies our algorithm computes perform well in terms of minimizing the damage due to contagious attacks.",従来のネットワークセキュリティゲームでは、防御側が防御リソースをネットワークのノードに分散し、攻撃者がノードを攻撃して、発生する被害を最大化することを目的としています。既存のモデルは、ノードuでの攻撃がuでのみダメージを与えると想定しています。ただし、実際のセキュリティシナリオの多くでは、ノードuでの攻撃がuの隣接ノードに広がり、ウイルスの発生など、複数のノードで損害を引き起こす可能性があります。この論文では、伝染性の攻撃に対するネットワーク防御の問題について考察します。共有リソースを研究する既存の作業では、ノードに割り当てられたリソースを隣接ノード間で共有または複製できることを前提としています。ただし、現実の世界では、特に伝染性の攻撃から防御する場合、リソースを共有すると、当然、ソースノードの防御力が低下します。この目的のために、ノードに割り当てられたリソースが隣接ノードにのみ転送できるモデルを研究します。これを再割り当てプロセスと呼びます。このより一般的なモデルは、次の2つの側面で困難であることを示します。（1）リソースの固定割り当ての場合でも、最適な再割り当ての計算はNP困難であることを示します。 （2）再割り当てが許可されていない場合、最適な割り当ての計算（伝染性攻撃に対する）もNP困難であることを示します。肯定的な結果を得るために、問題の混合整数線形計画定式化と2基準近似アルゴリズムを示します。私たちの実験結果は、私たちのアルゴリズムが計算する割り当ておよび再割り当て戦略が、伝染性の攻撃による被害を最小限に抑えるという点でうまく機能することを示しています。,https://d3i71xaburhd42.cloudfront.net/a01152175fde708abaedad4fcb6d018d71d7e56e/4-Figure1-1.png
Robust Model Compression Using Deep Hypotheses,"['Omri Armstrong', 'Ran Gilad-Bachrach']",,,,
Semi-Supervised Metric Learning: A Deep Resurrection,"['Ujjal Kr Dutta', 'Mehrtash Harandi', 'C Chandra Shekhar']",,,,
Non-Autoregressive Coarse-to-Fine Video Captioning,"['Bang Yang', 'Yuexian Zou', 'Fenglin Liu', 'Can Zhang']",https://arxiv.org/abs/1911.12018,"It is encouraged to see that many progresses have been made to bridge videos and natural language. However, mainstream video captioning methods depend heavily on autoregressive decoding to generate captions sequentially, raising issues like slow inference speed and the lack of relevant details or diversity in generated descriptions. In this paper, we propose a non-autoregressive decoding based model with a coarse-to-fine captioning procedure, i.e., Non-Autoregressive Coarse-to-Fine model, to alleviate these defects. In implementations, we employ a bi-directional self-attention based network as our language model for achieving parallelization to speed up inference, based on which we decompose the captioning procedure into two stages, where the model has different focuses. Specifically, given that visual words (e.g., nouns and verbs) directly determine the semantic correctness of captions, we design a mechanism of generating visual words to require the model to capture relevant details from videos, which will manifest as a coarse-grained sentence ""template"". Thereafter, we devise dedicated decoding algorithms that not only fill in the ""template"" with suitable words but also modify inappropriate expressions via iterative refinement to obtain a fine-grained description. Extensive experiments on two mainstream video captioning benchmarks, i.e., MSVD and MSR-VTT, demonstrate that our approach achieves state-of-the-art performance, generates diverse descriptions, and obtains high inference efficiency.",ビデオと自然言語を橋渡しするために多くの進歩が見られることを確認することをお勧めします。ただし、主流のビデオキャプション方法は、キャプションを順番に生成するために自己回帰デコードに大きく依存しているため、推論速度が遅い、関連する詳細がない、生成された説明が多様であるなどの問題が発生します。この論文では、これらの欠陥を軽減するために、粗いものから細かいものへのキャプション手順を備えた非自己回帰デコードベースのモデル、すなわち非自己回帰粗いものから細かいものへのモデルを提案します。実装では、並列化を実現するための言語モデルとして双方向の自己注意ベースのネットワークを採用して推論を高速化します。これに基づいて、キャプション手順を2つの段階に分解し、モデルの焦点が異なります。具体的には、視覚的な単語（名詞や動詞など）がキャプションの意味の正確さを直接決定することを前提として、視覚的な単語を生成するメカニズムを設計し、モデルがビデオから関連する詳細をキャプチャすることを要求します。これは、粗い文として現れます。テンプレート&quot;。その後、「テンプレート」に適切な単語を入力するだけでなく、反復的な改良によって不適切な表現を変更して、きめ細かい説明を取得する専用のデコードアルゴリズムを考案します。 2つの主流のビデオキャプションベンチマーク、つまりMSVDとMSR-VTTでの広範な実験は、私たちのアプローチが最先端のパフォーマンスを達成し、多様な記述を生成し、高い推論効率を獲得することを示しています。,
Explicitly Modeled Attention Maps for Image Classification,"['Andong Tan', 'Duc Tam Nguyen', 'Dax Maximillian', 'Matthias Niessner', 'Thomas Brox']",https://arxiv.org/abs/2006.07872,"Self-attention networks have shown remarkable progress in computer vision tasks such as image classification. The main benefit of the self-attention mechanism is the ability to capture long-range feature interactions in attention-maps. However, the computation of attention-maps requires a learnable key, query, and positional encoding, whose usage is often not intuitive and computationally expensive. To mitigate this problem, we propose a novel self-attention module with explicitly modeled attention-maps using only a single learnable parameter for low computational overhead. The design of explicitly modeled attention-maps using geometric prior is based on the observation that the spatial context for a given pixel within an image is mostly dominated by its neighbors, while more distant pixels have a minor contribution. Concretely, the attention-maps are parametrized via simple functions (e.g., Gaussian kernel) with a learnable radius, which is modeled independently of the input content. Our evaluation shows that our method achieves an accuracy improvement of up to 2.2% over the ResNet-baselines in ImageNet ILSVRC and outperforms other self-attention methods such as AA-ResNet152 (Bello et al., 2019) in accuracy by 0.9% with 6.4% fewer parameters and 6.7% fewer GFLOPs.",自己注意ネットワークは、画像分類などのコンピュータビジョンタスクで目覚ましい進歩を示しています。自己注意メカニズムの主な利点は、注意マップで長距離の特徴の相互作用をキャプチャできることです。ただし、アテンションマップの計算には、学習可能なキー、クエリ、および位置エンコーディングが必要です。これらの使用法は、直感的でなく、計算コストがかかることがよくあります。この問題を軽減するために、計算のオーバーヘッドを低くするために単一の学習可能なパラメーターのみを使用して、明示的にモデル化された注意マップを備えた新しい自己注意モジュールを提案します。幾何学的事前分布を使用して明示的にモデル化されたアテンションマップの設計は、画像内の特定のピクセルの空間コンテキストがその隣接ピクセルによってほとんど支配されている一方で、より離れたピクセルはわずかな寄与しか持たないという観察に基づいています。具体的には、アテンションマップは、入力コンテンツとは独立してモデル化された学習可能な半径を持つ単純な関数（ガウスカーネルなど）を介してパラメーター化されます。私たちの評価は、私たちの方法が最大2.2の精度向上を達成することを示しています,https://d3i71xaburhd42.cloudfront.net/59eccbe007ccf92172499db8420c12ea0933e24b/2-Figure1-1.png
Representative Proxy Voting,"['Elliot Anshelevich', 'Zack Fitzsimmons', 'Rohit Vaish', 'Lirong Xia']",https://arxiv.org/abs/2012.06747,"We study a model of proxy voting where the candidates, voters, and proxies are all located on the real line, and instead of voting directly, each voter delegates its vote to the closest proxy. The goal is to find a set of proxies that is $\theta$-representative, which entails that for any voter located anywhere on the line, its favorite candidate is within a distance $\theta$ of the favorite candidate of its closest proxy. This property guarantees a strong form of representation as the set of voters is not required to be fixed in advance, or even be finite. We show that for candidates located on a line, an optimal proxy arrangement can be computed in polynomial time. Moreover, we provide upper and lower bounds on the number of proxies required to form a $\theta$-representative set, thus showing that a relatively small number of proxies is enough to capture the preferences of any set of voters. An additional beneficial property of a $\theta$-representative proxy arrangement is that for strict-Condorcet voting rules, the outcome of proxy voting is similarly close to the outcome of direct voting.",候補者、有権者、および代理人がすべて実数直線上に配置され、直接投票する代わりに、各有権者が最も近い代理人に投票を委任する代理投票のモデルを研究します。目標は、代表的なプロキシのセットを見つけることです。これは、ライン上のどこかにいる有権者にとって、そのお気に入りの候補者が最も近いプロキシのお気に入りの候補者の距離内にあることを意味します。このプロパティは、投票者のセットを事前に固定する必要がない、または有限である必要がないため、強力な表現形式を保証します。線上にある候補について、最適なプロキシ配置を多項式時間で計算できることを示します。さらに、代表的なセットを形成するために必要なプロキシの数の上限と下限を提供します。したがって、比較的少数のプロキシで、任意の投票者のセットの選好を取得するのに十分であることを示しています。代表的な代理契約の追加の有益な特性は、厳密なコンドルセ投票ルールの場合、代理投票の結果が直接投票の結果に同様に近いことです。,https://d3i71xaburhd42.cloudfront.net/2ae4ab85f221ff83615b435975bd2a962df867f2/6-Figure1-1.png
Audio-Oriented Multimodal Machine Comprehension via Dynamic Inter- and Intra-Modality Attention,"['Zhiqi Huang', 'Fenglin Liu', 'Xian Wu', 'Shen Ge', 'Helin Wang', 'Wei Fan', 'Yuexian Zou']",,,,
Robust Reinforcement Learning: A Case Study in Linear Quadratic Regulation,"['Bo Pang', 'Zhong-Ping Jiang']",https://arxiv.org/abs/2008.11592,"This paper studies the robustness aspect of reinforcement learning algorithms in the presence of errors. Specifically, we revisit the benchmark problem of discrete-time linear quadratic regulation (LQR) and study the long-standing open question: Under what conditions is the policy iteration method robustly stable for dynamical systems with unbounded, continuous state and action spaces? Using advanced stability results in control theory, it is shown that policy iteration for LQR is inherently robust to small errors and enjoys local input-to-state stability: whenever the error in each iteration is bounded and small, the solutions of the policy iteration algorithm are also bounded, and, moreover, enter and stay in a small neighborhood of the optimal LQR solution. As an application, a novel off-policy optimistic least-squares policy iteration for the LQR problem is proposed, when the system dynamics are subjected to additive stochastic disturbances. The proposed new results in robust reinforcement learning are validated by a numerical example.",この論文は、エラーが存在する場合の強化学習アルゴリズムのロバスト性の側面を研究します。具体的には、離散時間線形二次調整（LQR）のベンチマーク問題を再検討し、長年の未解決の質問を研究します。どのような条件下で、ポリシー反復法は、無制限の連続状態およびアクション空間を持つ動的システムに対して堅牢に安定していますか？制御理論で高度な安定性の結果を使用すると、LQRのポリシー反復は本質的に小さなエラーに対してロバストであり、ローカルの入力から状態への安定性を享受することが示されます。各反復のエラーが制限されて小さい場合は常に、ポリシー反復アルゴリズムのソリューションまた、制限があり、さらに、最適なLQRソリューションの小さな近傍に入り、そこにとどまります。アプリケーションとして、システムダイナミクスが相加的な確率的外乱にさらされる場合に、LQR問題の新しいポリシー外の楽観的最小二乗ポリシー反復が提案されます。堅牢な強化学習で提案された新しい結果は、数値例によって検証されます。,https://d3i71xaburhd42.cloudfront.net/79da145c480aca3aedca05b4daf44ebf1789ca90/6-Figure1-1.png
High-Resolution Deep Image Matting,"['Haichao Yu', 'Ning Xu', 'Zilong Huang', 'Yuqian Zhou', 'Humphrey Shi']",https://arxiv.org/abs/2009.06613,"Image matting is a key technique for image and video editing and composition. Conventionally, deep learning approaches take the whole input image and an associated trimap to infer the alpha matte using convolutional neural networks. Such approaches set state-of-the-arts in image matting; however, they may fail in real-world matting applications due to hardware limitations, since real-world input images for matting are mostly of very high resolution. In this paper, we propose HDMatt, a first deep learning based image matting approach for high-resolution inputs. More concretely, HDMatt runs matting in a patch-based crop-and-stitch manner for high-resolution inputs with a novel module design to address the contextual dependency and consistency issues between different patches. Compared with vanilla patch-based inference which computes each patch independently, we explicitly model the cross-patch contextual dependency with a newly-proposed Cross-Patch Contextual module (CPC) guided by the given trimap. Extensive experiments demonstrate the effectiveness of the proposed method and its necessity for high-resolution inputs. Our HDMatt approach also sets new state-of-the-art performance on Adobe Image Matting and AlphaMatting benchmarks and produce impressive visual results on more real-world high-resolution images.",画像マットは、画像とビデオの編集と合成の重要な手法です。従来、深層学習アプローチでは、入力画像全体と関連するトライマップを使用して、畳み込みニューラルネットワークを使用してアルファマットを推測していました。このようなアプローチは、画像マットの最先端を設定します。ただし、マット用の実際の入力画像はほとんどが非常に高解像度であるため、ハードウェアの制限により、実際のマットアプリケーションでは失敗する可能性があります。この論文では、高解像度入力のための最初の深層学習ベースの画像マットアプローチであるHDMattを提案します。より具体的には、HDMattは、パッチベースのクロップアンドステッチ方式でマットを実行し、新しいモジュールデザインを使用して高解像度の入力を行い、異なるパッチ間のコンテキスト依存性と一貫性の問題に対処します。各パッチを個別に計算するバニラパッチベースの推論と比較して、指定されたトライマップによってガイドされる新しく提案されたクロスパッチコンテキストモジュール（CPC）を使用して、パッチ間のコンテキスト依存関係を明示的にモデル化します。広範な実験は、提案された方法の有効性と高解像度入力の必要性を示しています。また、HDMattアプローチは、Adobe Image MattingおよびAlphaMattingベンチマークで新しい最先端のパフォーマンスを設定し、より現実的な高解像度画像で印象的な視覚的結果を生み出します。,https://d3i71xaburhd42.cloudfront.net/a4c6605e1f8941218268f38084bb907185818a92/1-Figure1-1.png
Any-Precision Deep Neural Networks,"['Haichao Yu', 'Haoxiang Li', 'Humphrey Shi', 'Thomas Huang', 'Gang Hua']",https://arxiv.org/abs/1911.07346,"We present Any-Precision Deep Neural Networks (Any-Precision DNNs), which are trained with a new method that empowers learned DNNs to be flexible in any numerical precision during inference. The same model in runtime can be flexibly and directly set to different bit-width, by truncating the least significant bits, to support dynamic speed and accuracy trade-off. When all layers are set to low-bits, we show that the model achieved accuracy comparable to dedicated models trained at the same precision. This nice property facilitates flexible deployment of deep learning models in real-world applications, where in practice trade-offs between model accuracy and runtime efficiency are often sought. Previous literature presents solutions to train models at each individual fixed efficiency/accuracy trade-off point. But how to produce a model flexible in runtime precision is largely unexplored. When the demand of efficiency/accuracy trade-off varies from time to time or even dynamically changes in runtime, it is infeasible to re-train models accordingly, and the storage budget may forbid keeping multiple models. Our proposed framework achieves this flexibility without performance degradation. More importantly, we demonstrate that this achievement is agnostic to model architectures. We experimentally validated our method with different deep network backbones (AlexNet-small, Resnet-20, Resnet-50) on different datasets (SVHN, Cifar-10, ImageNet) and observed consistent results. Code and models will be available at this https URL.",Any-Precision Deep Neural Networks（Any-Precision DNN）を紹介します。これは、学習したDNNが推論中に任意の数値精度で柔軟になるようにする新しい方法でトレーニングされています。実行時の同じモデルは、動的な速度と精度のトレードオフをサポートするために、最下位ビットを切り捨てることにより、柔軟かつ直接異なるビット幅に設定できます。すべてのレイヤーが低ビットに設定されている場合、モデルが同じ精度でトレーニングされた専用モデルに匹敵する精度を達成したことを示します。この優れたプロパティにより、実際にはモデルの精度と実行時の効率の間のトレードオフが求められることが多い、実際のアプリケーションでの深層学習モデルの柔軟な展開が容易になります。以前の文献は、個々の固定効率/精度のトレードオフポイントでモデルをトレーニングするためのソリューションを示しています。しかし、実行時の精度に柔軟なモデルを作成する方法は、ほとんど検討されていません。効率と精度のトレードオフの要求が時々変化する場合、または実行時に動的に変化する場合でも、それに応じてモデルを再トレーニングすることは不可能であり、ストレージの予算によって複数のモデルを維持することが禁止される場合があります。提案されたフレームワークは、パフォーマンスを低下させることなくこの柔軟性を実現します。さらに重要なことに、この成果がモデルアーキテクチャにとらわれないことを示しています。さまざまなデータセット（SVHN、Cifar-10、ImageNet）でさまざまなディープネットワークバックボーン（AlexNet-small、Resnet-20、Resnet-50）を使用してメソッドを実験的に検証し、一貫した結果を観察しました。コードとモデルは、このhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/36562c6788e3d5c56ae5db738170ca32b04b6d50/1-Figure1-1.png
Regret Bounds for Batched Bandits,"['Hossein Esfandiari', 'Amin Karbasi', 'Abbas Mehrabian', 'Vahab Mirrokni']",https://arxiv.org/abs/1910.04959,"We present simple and efficient algorithms for the batched stochastic multi-armed bandit and batched stochastic linear bandit problems. We prove bounds for their expected regrets that improve over the best-known regret bounds for any number of batches. In particular, our algorithms in both settings achieve the optimal expected regrets by using only a logarithmic number of batches. We also study the batched adversarial multi-armed bandit problem for the first time and find the optimal regret, up to logarithmic factors, of any algorithm with predetermined batch sizes.",バッチ確率的多腕バンディットとバッチ化確率的線形バンディット問題のためのシンプルで効率的なアルゴリズムを提示します。予想される後悔の範囲が、任意の数のバッチで最もよく知られている後悔の範囲を上回っていることを証明します。特に、両方の設定のアルゴリズムは、対数のバッチ数のみを使用することで、予想される最適な後悔を実現します。また、バッチ処理された敵対的多腕バンディット問題を初めて研究し、事前に決定されたバッチサイズのアルゴリズムの対数因子までの最適な後悔を見つけます。,
Sample Selection for Universal Domain Adaptation,"['Omri Lifshitz', 'Lior Wolf']",,,,
Bayesian Distributional Policy Gradients,"['Luchen Li', 'Aldo A Faisal']",,,,
SMIL: Multimodal Learning with Severely Missing Modality,"['Mengmeng Ma', 'Jian Ren', 'Long Zhao', 'Sergey Tulyakov', 'Cathy Wu', 'Xi Peng']",,,,
FedRec++: Lossless Federated Recommendation with Explicit Feedback,"['Feng Liang', 'Weike Pan', 'Zhong Ming']",,,,
UAG: Uncertainty-Aware Attention Graph Neural Network for Defending Adversarial Attacks,"['Boyuan Feng', 'Yuke Wang', 'Yufei Ding']",https://arxiv.org/abs/2009.10235,"With the increasing popularity of graph-based learning, graph neural networks (GNNs) emerge as the essential tool for gaining insights from graphs. However, unlike the conventional CNNs that have been extensively explored and exhaustively tested, people are still worrying about the GNNs' robustness under the critical settings, such as financial services. The main reason is that existing GNNs usually serve as a black-box in predicting and do not provide the uncertainty on the predictions. On the other side, the recent advancement of Bayesian deep learning on CNNs has demonstrated its success of quantifying and explaining such uncertainties to fortify CNN models. Motivated by these observations, we propose UAG, the first systematic solution to defend adversarial attacks on GNNs through identifying and exploiting hierarchical uncertainties in GNNs. UAG develops a Bayesian Uncertainty Technique (BUT) to explicitly capture uncertainties in GNNs and further employs an Uncertainty-aware Attention Technique (UAT) to defend adversarial attacks on GNNs. Intensive experiments show that our proposed defense approach outperforms the state-of-the-art solutions by a significant margin.",グラフベースの学習の人気が高まるにつれ、グラフニューラルネットワーク（GNN）は、グラフから洞察を得るための不可欠なツールとして浮上しています。ただし、広範囲にわたって調査され、徹底的にテストされた従来のCNNとは異なり、人々は依然として、金融サービスなどの重要な設定の下でのGNNの堅牢性について心配しています。主な理由は、既存のGNNは通常、予測のブラックボックスとして機能し、予測の不確実性を提供しないためです。一方、CNNに関するベイズ深層学習の最近の進歩は、CNNモデルを強化するためにそのような不確実性を定量化して説明することに成功したことを示しています。これらの観察に動機付けられて、GNNの階層的な不確実性を特定して活用することにより、GNNに対する敵対的攻撃を防御する最初の体系的なソリューションであるUAGを提案します。 UAGは、GNNの不確実性を明示的にキャプチャするためにベイジアン不確実性手法（BUT）を開発し、さらにGNNに対する敵対的攻撃を防御するために不確実性を意識した注意手法（UAT）を採用しています。集中的な実験により、提案された防御アプローチは、最先端のソリューションを大幅に上回っています。,https://d3i71xaburhd42.cloudfront.net/9bf050287e0cd8df167cc345878335fc5a8d045e/2-Figure1-1.png
Self-Supervised Bilingual Syntactic Alignment for Neural Machine Translation,"['Tianfu Zhang', 'Heyan Huang', 'Chong Feng', 'Longbing Cao']",,,,
Addressing Domain Gap via Content Invariant Representation for Semantic Segmentation,"['Li Gao', 'Lefei Zhang', 'Qian Zhang']",,,,
Stereopagnosia: Fooling Stereo Networks with Adversarial Perturbations,"['Alex Wong', 'Mukund Mundhra', 'Stefano Soatto']",https://arxiv.org/abs/2009.10142,"We study the effect of adversarial perturbations of images on the estimates of disparity by deep learning models trained for stereo. We show that imperceptible additive perturbations can significantly alter the disparity map, and correspondingly the perceived geometry of the scene. These perturbations not only affect the specific model they are crafted for, but transfer to models with different architecture, trained with different loss functions. We show that, when used for adversarial data augmentation, our perturbations result in trained models that are more robust, without sacrificing overall accuracy of the model. This is unlike what has been observed in image classification, where adding the perturbed images to the training set makes the model less vulnerable to adversarial perturbations, but to the detriment of overall accuracy. We test our method using the most recent stereo networks and evaluate their performance on public benchmark datasets.",ステレオ用にトレーニングされた深層学習モデルによる視差の推定に対する画像の敵対的摂動の影響を研究します。知覚できない加法摂動が視差マップを大幅に変更し、それに応じてシーンの知覚されるジオメトリを変更する可能性があることを示します。これらの摂動は、それらが作成された特定のモデルに影響を与えるだけでなく、さまざまな損失関数でトレーニングされたさまざまなアーキテクチャのモデルに転送されます。敵対的なデータ拡張に使用すると、摂動により、モデルの全体的な精度を犠牲にすることなく、より堅牢なトレーニング済みモデルが得られることを示します。これは、摂動された画像をトレーニングセットに追加すると、モデルが敵対的な摂動に対して脆弱ではなくなり、全体的な精度が低下する画像分類で観察されたものとは異なります。最新のステレオネットワークを使用してメソッドをテストし、公開ベンチマークデータセットでのパフォーマンスを評価します。,https://d3i71xaburhd42.cloudfront.net/090e227b01a96340e683a6f661f64c7eb93c3741/3-Figure1-1.png
Deep Metric Learning with Self-Supervised Ranking,"['Zheren Fu', 'Yan Li', 'Zhendong Mao', 'Quan Wang', 'Yongdong Zhang']",,,,
Learning from Noisy Labels with Complementary Loss Functions,"['Deng-Bao Wang', 'Yong Wen', 'Lujia Pan', 'Min-Ling Zhang']",,,,
Context-Guided Adaptive Network for Efficient Human Pose Estimation,"['Lei Zhao', 'Jun Wen', 'Pengfei Wang', 'Nenggan Zheng']",,,,
Context-Aware Graph Convolution Network for Target Re-Identification,"['Deyi Ji', 'Haoran Wang', 'Hanzhe Hu', 'Weihao Gan', 'Wei Wu', 'Junjie Yan']",https://arxiv.org/abs/2012.04298,"Most existing re-identification methods focus on learning robust and discriminative features with deep convolution networks. However, many of them consider content similarity separately and fail to utilize the context information of the query and gallery sets, e.g. probe-gallery and gallery-gallery relations, thus hard samples may not be well solved due tothe limited or even misleading information. In this paper,we present a novel Context-Aware Graph Convolution Net-work (CAGCN), where the probe-gallery relations are encoded into the graph nodes and the graph edge connections are well controlled by the gallery-gallery relations. In this way, hard samples can be addressed with the context information flows among other easy samples during the graph reasoning. Specifically, we adopt an effective hard gallery sampler to obtain high recall for positive samples while keeping a reasonable graph size, which can also weaken the imbalanced problem in training process with low computation complexity. Experiments show that the proposed method achieves state-of-the-art performance on both person and vehicle re-identification datasets in a plug and play fashion with limited overhead.",ほとんどの既存の再識別方法は、深い畳み込みネットワークを使用した堅牢で識別可能な特徴の学習に重点を置いています。ただし、それらの多くはコンテンツの類似性を個別に考慮し、クエリとギャラリーセットのコンテキスト情報（プローブ-ギャラリーとギャラリー-ギャラリーの関係など）を利用できないため、情報が限られているか誤解を招く可能性があるため、ハードサンプルを十分に解決できない場合があります。この論文では、プローブとギャラリーの関係がグラフノードにエンコードされ、グラフのエッジ接続がギャラリーとギャラリーの関係によって適切に制御される、新しいコンテキスト認識グラフ畳み込みネットワーク（CAGCN）を紹介します。このようにして、ハードサンプルは、グラフの推論中に他の簡単なサンプルの中でコンテキスト情報フローを使用して対処できます。具体的には、効果的なハードギャラリーサンプラーを採用して、妥当なグラフサイズを維持しながらポジティブサンプルの高い再現率を取得します。これにより、計算の複雑さが低いトレーニングプロセスでの不均衡な問題を弱めることもできます。実験は、提案された方法が、限られたオーバーヘッドでプラグアンドプレイ方式で人と車両の両方の再識別データセットで最先端のパフォーマンスを達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/423d5effcbd0aac7b047b52a34385bfd4ebd915d/4-Figure1-1.png
Adaptive Knowledge Driven Regularization for Deep Neural Networks,"['Zhaojing Luo', 'Shaofeng Cai', 'Can Cui', 'Beng Chin Ooi', 'Yang Yang']",,,,
On the Approximation of Nash Equilibria in Sparse Win-Lose Multi-Player Games,"['Zhengyang Liu', 'Jiawei Li', 'Xiaotie Deng']",,,,
Unsupervised Summarization for Chat Logs with Topic-Oriented Ranking and Context-Aware Auto-Encoders,"['Yicheng Zou', 'Jun Lin', 'Lujun Zhao', 'Yangyang Kang', 'Zhuoren Jiang', 'Changlong Sun', 'Qi Zhang', 'Xuanjing Huang', 'Xiaozhong Liu']",https://arxiv.org/abs/2012.07300,"Automatic chat summarization can help people quickly grasp important information from numerous chat messages. Unlike conventional documents, chat logs usually have fragmented and evolving topics. In addition, these logs contain a quantity of elliptical and interrogative sentences, which make the chat summarization highly context dependent. In this work, we propose a novel unsupervised framework called RankAE to perform chat summarization without employing manually labeled data. RankAE consists of a topic-oriented ranking strategy that selects topic utterances according to centrality and diversity simultaneously, as well as a denoising auto-encoder that is carefully designed to generate succinct but context-informative summaries based on the selected utterances. To evaluate the proposed method, we collect a large-scale dataset of chat logs from a customer service environment and build an annotated set only for model evaluation. Experimental results show that RankAE significantly outperforms other unsupervised methods and is able to generate high-quality summaries in terms of relevance and topic coverage.",自動チャット要約は、人々が多数のチャットメッセージから重要な情報をすばやく把握するのに役立ちます。従来のドキュメントとは異なり、チャットログには通常、断片化され進化するトピックがあります。さらに、これらのログには大量の楕円形の質問文が含まれているため、チャットの要約はコンテキストに大きく依存します。この作業では、手動でラベル付けされたデータを使用せずにチャットの要約を実行する、RankAEと呼ばれる新しい教師なしフレームワークを提案します。 RankAEは、中心性と多様性に応じてトピックの発話を同時に選択するトピック指向のランキング戦略と、選択された発話に基づいて簡潔でありながらコンテキストに役立つ要約を生成するように注意深く設計されたノイズ除去オートエンコーダで構成されます。提案手法を評価するために、顧客サービス環境からチャットログの大規模なデータセットを収集し、モデル評価専用の注釈付きセットを作成します。実験結果は、RankAEが他の教師なし手法を大幅に上回り、関連性とトピックカバレッジの点で高品質の要約を生成できることを示しています。,https://d3i71xaburhd42.cloudfront.net/48f93c470f83d225a27a81196d1e4d30ec6ccce9/1-Figure1-1.png
Delving into Variance Transmission and Normalization: Shift of Average Gradient Makes the Network Collapse,"['Yuxiang Liu', 'Jidong Ge', 'Chuanyi Li', 'Jie Gui']",,,,
Empirical Regularization for Synthetic Sentence Pairs in Unsupervised Neural Machine Translation,"['Xi Ai', 'Bin Fang']",,,,
Learning Intact Features by Erasing-Inpainting for Few-Shot Classification,"['Junjie Li', 'Zilei Wang', 'Xiaoming Hu']",,,,
Time to Transfer: Predicting and Evaluating Machine-Human Chatting Handoff,"['Jiawei Liu', 'Zhe Gao', 'Yangyang Kang', 'Zhuoren Jiang', 'Guoxiu He', 'Changlong Sun', 'Xiaozhong Liu', 'Wei Lu']",https://arxiv.org/abs/2012.07610,"Is chatbot able to completely replace the human agent? The short answer could be - ""it depends..."". For some challenging cases, e.g., dialogue's topical spectrum spreads beyond the training corpus coverage, the chatbot may malfunction and return unsatisfied utterances. This problem can be addressed by introducing the Machine-Human Chatting Handoff (MHCH), which enables human-algorithm collaboration. To detect the normal/transferable utterances, we propose a Difficulty-Assisted Matching Inference (DAMI) network, utilizing difficulty-assisted encoding to enhance the representations of utterances. Moreover, a matching inference mechanism is introduced to capture the contextual matching features. A new evaluation metric, Golden Transfer within Tolerance (GT-T), is proposed to assess the performance by considering the tolerance property of the MHCH. To provide insights into the task and validate the proposed model, we collect two new datasets. Extensive experimental results are presented and contrasted against a series of baseline models to demonstrate the efficacy of our model on MHCH.",チャットボットはヒューマンエージェントを完全に置き換えることができますか？簡単な答えは、「状況によって異なります...」です。会話のトピックの範囲がトレーニングコーパスの範囲を超えて広がるなど、いくつかの困難なケースでは、チャットボットが誤動作し、満足できない発話を返す可能性があります。この問題は、人間とアルゴリズムのコラボレーションを可能にするMachine-Human Chatting Handoff（MHCH）を導入することで解決できます。通常の/転送可能な発話を検出するために、難易度支援エンコーディングを利用して発話の表現を強化する、難易度支援マッチング推論（DAMI）ネットワークを提案します。さらに、コンテキストマッチング機能をキャプチャするために、マッチング推論メカニズムが導入されています。 MHCHの許容特性を考慮してパフォーマンスを評価するために、新しい評価メトリックである許容範囲内のゴールデン転送（GT-T）が提案されています。タスクへの洞察を提供し、提案されたモデルを検証するために、2つの新しいデータセットを収集します。広範な実験結果が提示され、一連のベースラインモデルと対比されて、MHCHに対するモデルの有効性が実証されています。,https://d3i71xaburhd42.cloudfront.net/5f5e1a745358981dc2953d2d1718c552eda9adc9/1-Figure1-1.png
Lifelong Multi-Agent Path Finding in Large-Scale Warehouses,"['Jiaoyang Li', 'Andrew Tinka', 'Scott Kiesel', 'Joseph W Durham', 'T. K. Satish Kumar', 'Sven Koenig']",https://arxiv.org/abs/2005.07371,"Multi-Agent Path Finding (MAPF) is the problem of moving a team of agents to their goal locations without collisions. In this paper, we study the lifelong variant of MAPF where agents are constantly engaged with new goal locations, such as in large-scale warehouses. We propose a new framework for solving lifelong MAPF by decomposing the problem into a sequence of Windowed MAPF instances, where a Windowed MAPF solver resolves collisions among the paths of the agents only within a finite time horizon and ignores collisions beyond it. Our framework is particularly well suited to generating pliable plans that adapt to continually arriving new goal locations. Theoretically, we analyze the advantages and disadvantages of our framework. Empirically, we evaluate our framework with a variety of MAPF solvers and show that it can produce high-quality solutions for up to 1,000 agents, significantly outperforming existing methods.","マルチエージェントパスファインディング（MAPF）は、エージェントのチームを衝突することなく目標の場所に移動する問題です。この論文では、エージェントが大規模な倉庫などの新しい目標の場所に絶えず従事している、MAPFの生涯にわたる変種を研究します。問題をウィンドウ化されたMAPFインスタンスのシーケンスに分解することにより、生涯にわたるMAPFを解決するための新しいフレームワークを提案します。ここで、ウィンドウ化されたMAPFソルバーは、有限の時間範囲内でのみエージェントのパス間の衝突を解決し、それを超える衝突を無視します。私たちのフレームワークは、継続的に到着する新しい目標の場所に適応する柔軟な計画を生成するのに特に適しています。理論的には、フレームワークの長所と短所を分析します。経験的に、さまざまなMAPFソルバーを使用してフレームワークを評価し、最大1,000のエージェントに対して高品質のソリューションを生成でき、既存の方法を大幅に上回っていることを示しています。",https://d3i71xaburhd42.cloudfront.net/dc6219278e481591b478904a755fbcb1db675399/2-Figure1-1.png
Learning to Purify Noisy Labels via Meta Soft Label Corrector,"['Yichen Wu', 'Jun Shu', 'Qi Xie', 'Qian Zhao', 'Deyu Meng']",,,,
Rethinking Boundaries: End-To-End Recognition of Discontinuous Mentions with Pointer Networks,"['Hao Fei', 'Fei Li', 'Bobo Li', 'Yijiang Liu', 'Yafeng Ren', 'Donghong Ji']",,,,
Graph and Temporal Convolutional Network for Spatio-Temporal 3D Multi-Person Pose Estimation in Monocular Videos,"['Yu Cheng', 'Bo Wang', 'Bo Yang', 'Robby T. Tan']",https://arxiv.org/abs/2012.11806,"Despite the recent progress, 3D multi-person pose estimation from monocular videos is still challenging due to the commonly encountered problem of missing information caused by occlusion, partially out-of-frame target persons, and inaccurate person detection. To tackle this problem, we propose a novel framework integrating graph convolutional networks (GCNs) and temporal convolutional networks (TCNs) to robustly estimate camera-centric multi-person 3D poses that does not require camera parameters. In particular, we introduce a human-joint GCN, which unlike the existing GCN, is based on a directed graph that employs the 2D pose estimator’s confidence scores to improve the pose estimation results. We also introduce a human-bone GCN, which models the bone connections and provides more information beyond human joints. The two GCNs work together to estimate the spatial frame-wise 3D poses, and can make use of both visible joint and bone information in the target frame to estimate the occluded or missing human-part information. To further refine the 3D pose estimation, we use our temporal convolutional networks (TCNs) to enforce the temporal and human-dynamics constraints. We use a joint-TCN to estimate person-centric 3D poses across frames, and propose a velocity-TCN to estimate the speed of 3D joints to ensure the consistency of the 3D pose estimation in consecutive frames. Finally, to estimate the 3D human poses for multiple persons, we propose a root-TCN that estimates camera-centric 3D poses without requiring camera parameters. Quantitative and qualitative evaluations demonstrate the effectiveness of the proposed method. Our code and models are available at https://github.com/3dpose/GnTCN.",最近の進歩にもかかわらず、単眼ビデオからの3D多人ポーズ推定は、オクルージョン、部分的にフレーム外のターゲット人物、および不正確な人物検出によって引き起こされる情報の欠落という一般的に遭遇する問題のため、依然として困難です。この問題に取り組むために、グラフ畳み込みネットワーク（GCN）と時間畳み込みネットワーク（TCN）を統合して、カメラパラメーターを必要としないカメラ中心の複数人の3Dポーズをロバストに推定する新しいフレームワークを提案します。特に、既存のGCNとは異なり、2Dポーズ推定器の信頼スコアを使用してポーズ推定結果を改善する有向グラフに基づく人間関節GCNを紹介します。また、骨の接続をモデル化し、人間の関節を超えてより多くの情報を提供する人間の骨のGCNを紹介します。 2つのGCNは連携して、フレームごとの空間3Dポーズを推定し、ターゲットフレーム内の目に見える関節と骨の両方の情報を利用して、遮られた、または欠落している人間の部分の情報を推定できます。 3Dポーズ推定をさらに洗練するために、時間畳み込みネットワーク（TCN）を使用して、時間的および人間のダイナミクスの制約を適用します。ジョイントTCNを使用して、フレーム全体で人中心の3Dポーズを推定し、速度TCNを提案して3Dジョイントの速度を推定し、連続するフレームでの3Dポーズ推定の一貫性を確保します。最後に、複数の人物の3D人間のポーズを推定するために、カメラパラメータを必要とせずにカメラ中心の3Dポーズを推定するルートTCNを提案します。定量的および定性的評価は、提案された方法の有効性を示しています。コードとモデルはhttps://github.com/3dpose/G​​nTCNで入手できます。,https://d3i71xaburhd42.cloudfront.net/bc8cdc249a1157a72d07fb46ef7bc46843641c73/1-Figure1-1.png
PSSM-Distil: Protein Secondary Structure Prediction (PSSP) on Low-Quality PSSM by Knowledge Distillation with Contrastive Learning,"['Qin Wang', 'Boyuan Wang', 'Zhenlei Xu', 'Jiaxiang Wu', 'Peilin Zhao', 'Zhen Li', 'Sheng Wang', 'Junzhou Huang', 'Shuguang Cui']",,,,
Learning to Attack Real-World Models for Person Re-Identification via Virtual-Guided Meta-Learning,"['Fengxiang Yang', 'Zhun Zhong', 'Hong Liu', 'Zheng Wang', 'Zhiming Luo', 'Shaozi Li', 'Nicu Sebe', ""Shin'ichi Satoh""]",,,,
Efficient License Plate Recognition via Holistic Position Attention,"['Yesheng Zhang', 'Zilei Wang', 'Jiafan Zhuang']",,,,
Stability and Generalization for Decentralized Stochastic Gradient Descent,"['Tao Sun', 'Dongsheng Li', 'Bao Wang']",https://arxiv.org/abs/2102.01302,"The stability and generalization of stochastic gradient-based methods provide valuable insights into understanding the algorithmic performance of machine learning models. As the main workhorse for deep learning, stochastic gradient descent has received a considerable amount of studies. Nevertheless, the community paid little attention to its decentralized variants. In this paper, we provide a novel formulation of the decentralized stochastic gradient descent. Leveraging this formulation together with (non)convex optimization theory, we establish the first stability and generalization guarantees for the decentralized stochastic gradient descent. Our theoretical results are built on top of a few common and mild assumptions and reveal that the decentralization deteriorates the stability of SGD for the first time. We verify our theoretical findings by using a variety of decentralized settings and benchmark machine learning models. Introduction The great success of deep learning (LeCun, Bengio, and Hinton 2015) gives impetus to the development of stochastic gradient descent (SGD) (Robbins and Monro 1951) and its variants (Nemirovski et al. 2009; Duchi, Hazan, and Singer 2011; Rakhlin, Shamir, and Sridharan 2012; Kingma and Ba 2014; Wang et al. 2020). Although the convergence results of SGD are abundant, the effects caused by the training data is absent. To this end, the generalization error (Hardt, Recht, and Singer 2016; Lin, Camoriano, and Rosasco 2016; Bottou and Bousquet 2008; Bousquet and Elisseeff 2002) is developed as an alternative method to analyze SGD. The generalization bound reveals the performance of stochastic algorithms and characterizes how the training data and stochastic algorithm jointly affect the target machine learning model. To mathematically describe generalization, Hardt, Recht, and Singer (2016); Bousquet and Elisseeff (2002); Elisseeff, Evgeniou, and Pontil (2005) introduce the *This work is sponsored in part by National Key R&D Program of China (2018YFB0204300), and the National Science Foundation of China (No. 61932001 and 61906200). Corresponding author. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. algorithmic stability for SGD, which mainly depends on the landscape of the underlying loss function, to study the generalization bound of SGD. The stability theory of SGD has been further developed (Charles and Papailiopoulos 2018; Kuzborskij and Lampert 2018; Lei and Ying 2020). SGD has already been widely used in parallel and distributed settings (Agarwal and Duchi 2011; Dekel et al. 2012; Recht et al. 2011), e.g., the decentralized SGD (D-SGD) (Ram, Nedić, and Veeravalli 2010b; Lan, Lee, and Zhou 2020; Srivastava and Nedic 2011; Lian et al. 2017). D-SGD is implemented without a centralized parameter server, and all nodes are connected through an undirected graph. Compared to the centralized SGD, the decentralized one requires much less communication with the busiest node (Lian et al. 2017), accelerating the whole computational system. From the theoretical viewpoint, although there exist plenty of convergence analysis of D-SGD (Sirb and Ye 2016; Lan, Lee, and Zhou 2020; Lian et al. 2017, 2018), the stability and generalization analysis of D-SGD remains rare. Contributions In this paper, we establish the first theoretical result on the stability and generalization of the D-SGD. We elaborate on our contributions below. 1. Stability of D-SGD: We provide the uniform stability of D-SGD in the general convex, strongly convex, and nonconvex cases. Our theory shows that besides the learning rate, data size, and iteration number, the stability and generalization of D-SGD are also dependent on the connected graph structure. To the best of our knowledge, our result is the first theoretical stability guarantee for D-SGD. In the general convex setting, we also present the stability of D-SGD in terms of the ergodic average instead of the last iteration for the excess generalization analysis. 2. Computational errors for D-SGD with convexity and projection: We consider more general schemes of DSGD, that is, D-SGD with projection. In the previous work (Ram, Nedić, and Veeravalli 2010b), to get the convergence rate, the authors need to make additional assumptions on the graph ([Assumptions 2 and 3, (Ram, Nedić, and Veeravalli 2010b)]). In this paper, we remove these assumptions, and we present the computational errors of D-SGD with projections in the strongly convex setting. 3. Generalization bounds for D-SGD with convexity: We derive (excess) generalization bounds for convex D-SGD. The excess generalization is controlled by the computational error and the generalization bound, which can be directly obtained from the stability. 4. Numerical results: We numerically verify our theoretical results by using various benchmark machine learning models, ranging from strongly convex and convex to nonconvex settings, in different decentralized settings. Prior Art In this section, we briefly review two kinds of related works: decentralized optimization and stability and generalization analysis of SGD. Decentralized optimization Decentralized algorithms arise in calculating the mean of data distributed over multiple sensors (Boyd et al. 2005; Olfati-Saber, Fax, and Murray 2007). The decentralized (sub)gradient descent (DGD) algorithms are propose and studied by (Nedic and Ozdaglar 2009; Yuan, Ling, and Yin 2016). Recently, DGD has been generalized to the stochastic settings. With a local Poisson clock assumption on each agent, Ram, Nedić, and Veeravalli (2010a) proposes an asynchronous gossip algorithm. The decentralized algorithm with a random communication graph is proposed in (Srivastava and Nedic 2011; Ram, Nedić, and Veeravalli 2010b). Sirb and Ye (2016); Lan, Lee, and Zhou (2020); Lian et al. (2017) consider the randomness caused by the stochastic gradients and proposed the decentralized SGD (D-SGD). The complexity analysis of D-SGD has been done in (Sirb and Ye 2016). In (Lan, Lee, and Zhou 2020), the authors propose another kind of D-SGD that leverages dual information, and provide the related computational complexity. In the paper (Lian et al. 2017), the authors show the advantage of DSGD compared to the centralized SGD. In a recent paper (Lian et al. 2018), the authors developed asynchronous DSGD with theoretical convergence guarantees. The biased decentralized SGD is proposed and studied by (Sun et al. 2020). Stability and Generalization of SGD In (Shalev-Shwartz et al. 2010), on-average stability is proposed and further studied by Kuzborskij and Lampert (2018). The uniform stability of empirical risk minimization (ERM) under strongly convex objectives is considered by Bousquet and Elisseeff (2002). Extended results are proved with the pointwise-hypothesis assumption, which shows that a class of learning algorithms is convergent with global optimum (Charles and Papailiopoulos 2018). In order to prove uniform stability of SGD, Hardt, Recht, and Singer (2016) reformulate SGD as a contractive iteration. In (Lei and Ying 2020), a new stability notion is proposed to remove the bounded gradient assumptions. In (Bottou and Bousquet 2008), the authors establish a framework for the generalization performance of SGD. Hardt, Recht, and Singer (2016) connects the uniform stability with generalization error. The generalization errors with strong convexity are established in (Hardt, Recht, and Singer 2016; Lin, Camoriano, and Rosasco 2016). The stability and generalization are also studied for the Langevin dynamics (Li, Luo, and Qiao 2019; Mou et al. 2018). Setup This part contains preliminaries and mathematical descriptions of our problem. Analyzing the stability of D-SGD is more complicated than that of SGD due to the challenge arises from the mixing matrix in D-SGD. We cannot directly adapt the analysis for SGD to D-SGD. To this end, we reformulate D-SGD as an operator iteration with an error term, which is followed by bounding the error in each iteration. Stability and Generalization The population risk minimization is an important model in machine learning and statistics, whose mathematical formulation reads as min x∈R R(x) := Eξ∼Df(x; ξ), where f(x; ξ) denotes the loss of the model associated with data ξ and D is the data distribution. Due to the fact that D is usually unknown or very complicated, we consider the following surrogate ERM min x∈R RS(x) := 1 N N ∑",確率的勾配ベースの方法の安定性と一般化は、機械学習モデルのアルゴリズムパフォーマンスを理解するための貴重な洞察を提供します。深層学習の主な主力として、確率的勾配降下法はかなりの量の研究を受けています。それにもかかわらず、コミュニティはその分散型バリアントにほとんど注意を払っていませんでした。この論文では、分散型確率的勾配降下法の新しい定式化を提供します。この定式化を（非）凸最適化理論と一緒に活用して、分散型確率的勾配降下法の最初の安定性と一般化の保証を確立します。私たちの理論的結果は、いくつかの一般的で穏やかな仮定に基づいて構築されており、分散化がSGDの安定性を初めて低下させることを明らかにしています。さまざまな分散設定とベンチマーク機械学習モデルを使用して、理論上の発見を検証します。はじめに深層学習の大成功（LeCun、Bengio、およびHinton 2015）は、確率的勾配降下法（SGD）（Robbins and Monro 1951）およびその変形（Nemirovskietal。2009; Duchi、Hazan、およびSinger）の開発に弾みをつけます。 2011; Rakhlin、Shamir、およびSridharan 2012; Kingma and Ba 2014; Wang et al.2020）。 SGDの収束結果は豊富ですが、トレーニングデータによる影響はありません。この目的のために、汎化誤差（Hardt、Recht、およびSinger 2016、Lin、Camoriano、およびRosasco 2016、Bottou and Bousquet 2008、Bousquet and Elisseeff 2002）が、SGDを分析するための代替方法として開発されています。一般化の限界は、確率的アルゴリズムのパフォーマンスを明らかにし、トレーニングデータと確率的アルゴリズムがターゲットの機械学習モデルにどのように共同で影響するかを特徴づけます。一般化を数学的に説明するには、Hardt、Recht、およびSinger（2016）; Bousquet and Elisseeff（2002）; Elisseeff、Evgeniou、およびPontil（2005）が紹介します。*この作品は、中国国家自然科学基金委員会（2018YFB0204300）および中国国家科学財団（No. 61932001および61906200）によって部分的に後援されています。対応する著者。 Copyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。全著作権所有。 SGDの一般化限界を研究するための、主に基礎となる損失関数のランドスケープに依存するSGDのアルゴリズムの安定性。 SGDの安定性理論はさらに発展しました（Charles and Papailiopoulos 2018; Kuzborskij and Lampert 2018; Lei and Ying 2020）。 SGDは、並列および分散設定ですでに広く使用されています（Agarwal and Duchi 2011; Dekeletal。2012; Recht etal。2011）、たとえば、分散型SGD（D-SGD）（Ram、Nedic、およびVeeravalli 2010b; Lan 、Lee、およびZhou 2020; Srivastava and Nedic 2011; Lian et al.2017）。 D-SGDは、集中型パラメーターサーバーなしで実装され、すべてのノードは無向グラフを介して接続されます。集中型SGDと比較して、分散型SGDは、最もビジーなノードとの通信がはるかに少なくて済み（Lian etal。2017）、計算システム全体を高速化します。理論的な観点から、D-SGDの収束分析はたくさんありますが（Sirb and Ye 2016; Lan、Lee、and Zhou 2020; Lian et al。2017、2018）、D-SGDの安定性と一般化分析はまれなままです。 。貢献この論文では、D-SGDの安定性と一般化に関する最初の理論的結果を確立します。以下に、私たちの貢献について詳しく説明します。 1. D-SGDの安定性：一般的な凸面、強凸面、および非凸面の場合に、D-SGDの均一な安定性を提供します。私たちの理論は、学習率、データサイズ、反復回数に加えて、D-SGDの安定性と一般化も接続されたグラフ構造に依存することを示しています。私たちの知る限りでは、私たちの結果はD-SGDの最初の理論的安定性保証です。一般的な凸型の設定では、過剰一般化分析の最後の反復ではなく、エルゴード平均の観点からD-SGDの安定性も示します。 2.凸性と射影を伴うD-SGDの計算誤差：DSGDのより一般的なスキーム、つまり射影を伴うD-SGDを検討します。前の作業（Ram、Nedic、およびVeeravalli 2010b）では、収束率を取得するために、作成者はグラフに追加の仮定を行う必要があります（[仮定2および3、（Ram、Nedic、およびVeeravalli 2010b）]）。この論文では、これらの仮定を取り除き、D-SGDの計算誤差を強く凸の設定での射影で提示します。 3.凸性のあるD-SGDの一般化限界：凸型D-SGDの（過剰な）一般化限界を導出します。過剰な一般化は、安定性から直接取得できる計算誤差と一般化限界によって制御されます。 4.数値結果：さまざまな分散設定で、強凸および凸から非凸の設定に至るまで、さまざまなベンチマーク機械学習モデルを使用して、理論結果を数値的に検証します。先行技術このセクションでは、分散最適化と安定性、およびSGDの一般化分析という2種類の関連する作業について簡単に説明します。分散型最適化分散型アルゴリズムは、複数のセンサーに分散されたデータの平均を計算するときに発生します（Boydetal。2005; Olfati-Sabre、Fax、and Murray2007）。分散型（劣）勾配降下（DGD）アルゴリズムは、（Nedic and Ozdaglar 2009; Yuan、Ling、and Yin 2016）によって提案および研究されています。最近、DGDは確率的設定に一般化されました。 Ram、Nedic、およびVeeravalli（2010a）は、各エージェントにローカルのポアソンクロックを想定して、非同期ゴシップアルゴリズムを提案しています。ランダム通信グラフを使用した分散アルゴリズムは、（Srivastava and Nedic 2011; Ram、Nedic、and Veeravalli 2010b）で提案されています。 Sirb and Ye（2016）; Lan、Lee、およびZhou（2020）; Lian etal。 （2017）確率的勾配によって引き起こされるランダム性を考慮し、分散型SGD（D-SGD）を提案しました。 D-SGDの複雑さの分析は、（Sirb and Ye 2016）で行われました。 （Lan、Lee、およびZhou 2020）で、著者は、二重情報を活用し、関連する計算の複雑さを提供する別の種類のD-SGDを提案しています。論文（Lian etal。2017）で、著者は集中型SGDと比較したDSGDの利点を示しています。最近の論文（Lian etal。2018）で、著者は理論的な収束が保証された非同期DSGDを開発しました。偏った分散型SGDは、（Sun etal。2020）によって提案および研究されています。 SGDの安定性と一般化In（Shalev-Shwartz etal。2010）では、平均的な安定性が提案され、Kuzborskij and Lampert（2018）によってさらに研究されています。 Bousquet and Elisseeff（2002）は、強く凸の目的の下での経験的リスク最小化（ERM）の均一な安定性を考慮しています。拡張された結果は、学習アルゴリズムのクラスがグローバル最適に収束していることを示す、点ごとの仮説の仮定で証明されます（Charles and Papailiopoulos2018）。 SGDの均一な安定性を証明するために、Hardt、Recht、およびSinger（2016）は、SGDを収縮反復として再定式化します。 （Lei and Ying 2020）では、有界勾配の仮定を削除するための新しい安定性の概念が提案されています。 （Bottou and Bousquet 2008）では、著者はSGDの一般化パフォーマンスのフレームワークを確立しています。 Hardt、Recht、およびSinger（2016）は、均一な安定性と汎化誤差を結び付けています。強い凸性を持つ汎化誤差は、（Hardt、Recht、およびSinger 2016; Lin、Camoriano、およびRosasco 2016）で確立されています。ランジュバン動力学の安定性と一般化についても研究されています（Li、Luo、およびQiao 2019; Mou et al.2018）。セットアップこのパートには、問題の予備知識と数学的説明が含まれています。 D-SGDの安定性の分析は、D-SGDの混合マトリックスから生じる課題のため、SGDの安定性よりも複雑です。 SGDの分析をD-SGDに直接適応させることはできません。この目的のために、D-SGDを誤差項を伴う演算子反復として再定式化し、その後に各反復で誤差を制限します。安定性と一般化人口リスクの最小化は、機械学習と統計における重要なモデルであり、その数学的定式化はmin xR R（x）：= EDf（x;）として読み取られます。ここで、f（x;）は関連するモデルの損失を示します。データとDはデータ分布です。 Dは通常不明または非常に複雑であるため、次の代理ERM min xR RS（x）：= 1NNを検討します。,https://d3i71xaburhd42.cloudfront.net/23972111eb8a980d00619c27e91349bb7c63cf94/5-Figure1-1.png
Domain General Face Forgery Detection by Learning to Weight,"['Ke Sun', 'Hong Liu', 'Qixiang Ye', 'Yue Gao', 'Jianzhuang Liu', 'Ling Shao', 'Rongrong Ji']",,,,
Fast and Compact Bilinear Pooling by Shifted Random Maclaurin,"['Tan Yu', 'Xiaoyun Li', 'Ping Li']",,,,
Sparse Single Sweep LiDAR Point Cloud Segmentation via Learning Contextual Shape Priors from Scene Completion,"['Xu Yan', 'Jiantao Gao', 'Jie Li', 'Ruimao Zhang', 'Zhen Li', 'Rui Huang', 'Shuguang Cui']",https://arxiv.org/abs/2012.03762,"LiDAR point cloud analysis is a core task for 3D computer vision, especially for autonomous driving. However, due to the severe sparsity and noise interference in the single sweep LiDAR point cloud, the accurate semantic segmentation is non-trivial to achieve. In this paper, we propose a novel sparse LiDAR point cloud semantic segmentation framework assisted by learned contextual shape priors. In practice, an initial semantic segmentation (SS) of a single sweep point cloud can be achieved by any appealing network and then flows into the semantic scene completion (SSC) module as the input. By merging multiple frames in the LiDAR sequence as supervision, the optimized SSC module has learned the contextual shape priors from sequential LiDAR data, completing the sparse single sweep point cloud to the dense one. Thus, it inherently improves SS optimization through fully end-to-end training. Besides, a Point-Voxel Interaction (PVI) module is proposed to further enhance the knowledge fusion between SS and SSC tasks, i.e., promoting the interaction of incomplete local geometry of point cloud and complete voxel-wise global structure. Furthermore, the auxiliary SSC and PVI modules can be discarded during inference without extra burden for SS. Extensive experiments confirm that our JS3C-Net achieves superior performance on both SemanticKITTI and SemanticPOSS benchmarks, i.e., 4% and 3% improvement correspondingly.",LiDARポイントクラウド分析は、3Dコンピュータービジョン、特に自動運転のコアタスクです。ただし、シングルスイープLiDARポイントクラウドではスパース性とノイズ干渉が深刻であるため、正確なセマンティックセグメンテーションを実現するのは簡単ではありません。この論文では、学習したコンテキスト形状の事前分布によって支援される、新しいスパースLiDARポイントクラウドセマンティックセグメンテーションフレームワークを提案します。実際には、単一のスイープポイントクラウドの初期セマンティックセグメンテーション（SS）は、魅力的なネットワークによって実現でき、入力としてセマンティックシーン完了（SSC）モジュールに流れ込みます。監視としてLiDARシーケンス内の複数のフレームをマージすることにより、最適化されたSSCモジュールは、シーケンシャルLiDARデータからコンテキスト形状の事前分布を学習し、疎な単一スイープポイントクラウドを密なものに完成させます。したがって、完全なエンドツーエンドのトレーニングを通じて、本質的にSSの最適化を改善します。さらに、ポイント-ボクセル相互作用（PVI）モジュールは、SSタスクとSSCタスク間の知識融合をさらに強化するために提案されています。つまり、ポイントクラウドの不完全なローカルジオメトリと完全なボクセルごとのグローバル構造の相互作用を促進します。さらに、補助SSCおよびPVIモジュールは、SSに余分な負担をかけることなく、推論中に破棄できます。広範な実験により、JS3C-NetがSemanticKITTIとSemanticPOSSの両方のベンチマークで優れたパフォーマンスを達成していることが確認されています。,https://d3i71xaburhd42.cloudfront.net/601ad774f6305f8a78e878665b3623f2239687c5/1-Figure1-1.png
Social-DPF: Socially Acceptable Distribution Prediction of Futures,"['Xiaodan Shi', 'Xiaowei Shao', 'Guangming Wu', 'Haoran Zhang', 'Zhiling Guo', 'Renhe Jiang', 'Ryosuke Shibasaki']",,,,
Ordered Counterfactual Explanation by Mixed-Integer Linear Optimization,"['Kentaro Kanamori', 'Takuya Takagi', 'Ken Kobayashi', 'Yuichi Ike', 'Kento Uemura', 'Hiroki Arimura']",https://arxiv.org/abs/2012.11782,"Post-hoc explanation methods for machine learning models have been widely used to support decisionmaking. One of the popular methods is Counterfactual Explanation (CE), which provides a user with a perturbation vector of features that alters the prediction result. Given a perturbation vector, a user can interpret it as an “action” for obtaining one’s desired decision result. In practice, however, showing only a perturbation vector is often insufficient for users to execute the action. The reason is that if there is an asymmetric interaction among features, such as causality, the total cost of the action is expected to depend on the order of changing features. Therefore, practical CE methods are required to provide an appropriate order of changing features in addition to a perturbation vector. For this purpose, we propose a new framework called Ordered Counterfactual Explanation (OrdCE). We introduce a new objective function that evaluates a pair of an action and an order based on feature interaction. To extract an optimal pair, we propose a mixed-integer linear optimization approach with our objective function. Numerical experiments on real datasets demonstrated the effectiveness of our OrdCE in comparison with unordered CE methods.",機械学習モデルの事後説明方法は、意思決定をサポートするために広く使用されています。一般的な方法の1つは、反事実条件節（CE）です。これは、予測結果を変更する特徴の摂動ベクトルをユーザーに提供します。摂動ベクトルが与えられると、ユーザーはそれを目的の決定結果を得るためのアクションとして解釈できます。ただし、実際には、摂動ベクトルのみを表示するだけでは、ユーザーがアクションを実行するには不十分なことがよくあります。その理由は、因果関係など、機能間に非対称の相互作用がある場合、アクションの総コストは機能の変更順序に依存すると予想されるためです。したがって、摂動ベクトルに加えて特徴を変更する適切な順序を提供するには、実用的なCEメソッドが必要です。この目的のために、Ordered Counterfactual Description（OrdCE）と呼ばれる新しいフレームワークを提案します。機能の相互作用に基づいてアクションと順序のペアを評価する新しい目的関数を紹介します。最適なペアを抽出するために、目的関数を使用した混合整数線形最適化アプローチを提案します。実際のデータセットでの数値実験により、順序付けられていないCEメソッドと比較したOrdCEの有効性が実証されました。,https://d3i71xaburhd42.cloudfront.net/8a3f00a874123a397885aa8d1e7a6420070ec697/2-Figure1-1.png
Graph Heterogeneous Multi-Relational Recommendation,"['Chong Chen', 'Weizhi Ma', 'Min Zhang', 'Zhaowei Wang', 'Xiuqiang He', 'Chenyang Wang', 'Yiqun Liu', 'Shaoping Ma']",,,,
Semi-Supervised Medical Image Segmentation through Dual-Task Consistency,"['Xiangde Luo', 'Jieneng Chen', 'Tao Song', 'Guotai Wang']",https://arxiv.org/abs/2009.04448,"Deep learning-based semi-supervised learning (SSL) algorithms have led to promising results in medical images segmentation and can alleviate doctors' expensive annotations by leveraging unlabeled data. However, most of the existing SSL algorithms in literature tend to regularize the model training by perturbing networks and/or data. Observing that multi/dual-task learning attends to various levels of information which have inherent prediction perturbation, we ask the question in this work: can we explicitly build task-level regularization rather than implicitly constructing networks- and/or data-level perturbation-and-transformation for SSL? To answer this question, we propose a novel dual-task-consistency semi-supervised framework for the first time. Concretely, we use a dual-task deep network that jointly predicts a pixel-wise segmentation map and a geometry-aware level set representation of the target. The level set representation is converted to an approximated segmentation map through a differentiable task transform layer. Simultaneously, we introduce a dual-task consistency regularization between the level set-derived segmentation maps and directly predicted segmentation maps for both labeled and unlabeled data. Extensive experiments on two public datasets show that our method can largely improve the performance by incorporating the unlabeled data. Meanwhile, our framework outperforms the state-of-the-art semi-supervised medical image segmentation methods. Code is available at: this https URL",ディープラーニングベースの半教師あり学習（SSL）アルゴリズムは、医用画像のセグメンテーションで有望な結果をもたらし、ラベルのないデータを活用することで医師の高価な注釈を軽減できます。ただし、文献にある既存のSSLアルゴリズムのほとんどは、ネットワークやデータを混乱させることによってモデルトレーニングを正規化する傾向があります。マルチ/デュアルタスク学習が固有の予測摂動を持つさまざまなレベルの情報に関与することを観察して、この作業で質問します：ネットワークおよび/またはデータレベルの摂動を暗黙的に構築するのではなく、タスクレベルの正則化を明示的に構築できますか？および-SSLの変換？この質問に答えるために、新しいデュアルタスク整合性半教師ありフレームワークを初めて提案します。具体的には、ピクセル単位のセグメンテーションマップとターゲットのジオメトリ対応レベルセット表現を共同で予測するデュアルタスクディープネットワークを使用します。レベルセット表現は、微分可能なタスク変換レイヤーを介して近似セグメンテーションマップに変換されます。同時に、レベルセットから派生したセグメンテーションマップと、ラベル付きデータとラベルなしデータの両方の直接予測されたセグメンテーションマップの間にデュアルタスク整合性正則化を導入します。 2つの公開データセットでの広範な実験は、私たちの方法がラベルのないデータを組み込むことによってパフォーマンスを大幅に改善できることを示しています。一方、私たちのフレームワークは、最先端の半教師あり医療画像セグメンテーション手法よりも優れています。コードは次のURLで入手できます：このhttps URL,https://d3i71xaburhd42.cloudfront.net/c0d07d38712e8ae94e2897d6778384bf3c59764a/3-Figure1-1.png
Interpreting Neural Networks as Quantitative Argumentation Frameworks,['Nico Potyka'],,,,
Inferring Camouflage Objects by Texture-Aware Interactive Guidance Network,"['Jinchao Zhu', 'Xiaoyu Zhang', 'Shuo Zhang', 'Junnan Liu']",,,,
Parallel Constraint Acquisition,['Nadjib Lazaar'],,,,
Group-Wise Semantic Mining for Weakly Supervised Semantic Segmentation,"['Xueyi Li', 'Tianfei Zhou', 'Jianwu Li', 'Yi Zhou', 'Zhaoxiang Zhang']",,,,
PTN: A Poisson Transfer Network for Semi-Supervised Few-Shot Learning,"['Huaxi Huang', 'Junjie Zhang', 'Jian Zhang', 'Qiang Wu', 'Chang Xu']",https://arxiv.org/abs/2012.10844,"The predicament in semi-supervised few-shot learning (SSFSL) is to maximize the value of the extra unlabeled data to boost the few-shot learner. In this paper, we propose a Poisson Transfer Network (PTN) to mine the unlabeled information for SSFSL from two aspects. First, the Poisson Merriman–Bence–Osher (MBO) model builds a bridge for the communications between labeled and unlabeled examples. This model serves as a more stable and informative classifier than traditional graph-based SSFSL methods in the message-passing process of the labels. Second, the extra unlabeled samples are employed to transfer the knowledge from base classes to novel classes through contrastive learning. Specifically, we force the augmented positive pairs close while push the negative ones distant. Our contrastive transfer scheme implicitly learns the novel-class embeddings to alleviate the over-fitting problem on the few labeled data. Thus, we can mitigate the degeneration of embedding generality in novel classes. Extensive experiments indicate that PTN outperforms the state-of-the-art few-shot and SSFSL models on miniImageNet and tieredImageNet benchmark datasets.",半教師あり数ショット学習（SSFSL）の苦境は、追加のラベルなしデータの値を最大化して、数ショット学習者を後押しすることです。この論文では、2つの側面からSSFSLのラベルなし情報をマイニングするためのポアソン転送ネットワーク（PTN）を提案します。まず、Poisson MerrimanBenceOsher（MBO）モデルは、ラベル付きの例とラベルなしの例の間の通信のためのブリッジを構築します。このモデルは、ラベルのメッセージパッシングプロセスにおいて、従来のグラフベースのSSFSLメソッドよりも安定した有益な分類子として機能します。次に、対照的な学習を通じて、知識を基本クラスから新規クラスに転送するために、追加のラベルなしサンプルが使用されます。具体的には、拡張された正のペアを強制的に閉じ、負のペアを遠ざけます。私たちの対照的な転送スキームは、いくつかのラベル付きデータの過剰適合問題を軽減するために、新しいクラスの埋め込みを暗黙的に学習します。したがって、新しいクラスに一般性を埋め込むことの退化を軽減することができます。広範な実験により、PTNは、miniImageNetおよびtieredImageNetベンチマークデータセットの最先端の数ショットモデルおよびSSFSLモデルよりも優れていることが示されています。,https://d3i71xaburhd42.cloudfront.net/35a5fd61a69ee5ad3bc25ed80666ab3038bf3b1c/3-Figure1-1.png
Beating Attackers at Their Own Games: Adversarial Example Detection Using Adversarial Gradient Directions,"['Yuhang Wu', 'Sunpreet S Arora', 'Yanhong Wu', 'Hao Yang']",https://arxiv.org/abs/2012.15386,"Adversarial examples are input examples that are specifically crafted to deceive machine learning classifiers. State-of-theart adversarial example detection methods characterize an input example as adversarial either by quantifying the magnitude of feature variations under multiple perturbations or by measuring its distance from estimated benign example distribution. Instead of using such metrics, the proposed method is based on the observation that the directions of adversarial gradients when crafting (new) adversarial examples play a key role in characterizing the adversarial space. Compared to detection methods that use multiple perturbations, the proposed method is efficient as it only applies a single random perturbation on the input example. Experiments conducted on two different databases, CIFAR-10 and ImageNet, show that the proposed detection method achieves, respectively, 97.9% and 98.6% AUC-ROC (on average) on five different adversarial attacks, and outperforms multiple state-of-the-art detection methods. Results demonstrate the effectiveness of using adversarial gradient directions for adversarial example detection.",敵対的な例は、機械学習分類器を欺くために特別に作成された入力例です。最先端の敵対的例の検出方法は、複数の摂動下での特徴の変動の大きさを定量化するか、推定された良性の例の分布からの距離を測定することによって、入力例を敵対的として特徴付けます。そのような測定基準を使用する代わりに、提案された方法は、（新しい）敵対的な例を作成するときの敵対的な勾配の方向が敵対的な空間を特徴付ける上で重要な役割を果たすという観察に基づいています。複数の摂動を使用する検出方法と比較して、提案された方法は、入力例に単一のランダムな摂動のみを適用するため、効率的です。 2つの異なるデータベース、CIFAR-10とImageNetで実施された実験は、提案された検出方法がそれぞれ97.9を達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/df326f0b6d109282f41bc5cc1fbd125437b65341/1-Figure1-1.png
Contrastive Triple Extraction with Generative Transformer,"['Hongbin Ye', 'Ningyu Zhang', 'Shumin Deng', 'Mosha Chen', 'Chuanqi Tan', 'Fei Huang', 'Huajun Chen']",https://arxiv.org/abs/2009.06207,"Triple extraction is an essential task in information extraction for natural language processing and knowledge graph construction. In this paper, we revisit the end-to-end triple extraction task for sequence generation. Since generative triple extraction may struggle to capture long-term dependencies and generate unfaithful triples, we introduce a novel model, contrastive triple extraction with a generative transformer. Specifically, we introduce a single shared transformer module for encoder-decoder-based generation. To generate faithful results, we propose a novel triplet contrastive training object. Moreover, We introduce two mechanisms to further improve model performance (i.e., batch-wise dynamic attention-masking and triple-wise calibration). Experimental results on three datasets (i.e., NYT, WebNLG, and MIE) show that our approach achieves better performance than that of baselines. Our code and datasets will be released after publication.",トリプル抽出は、自然言語処理と知識グラフ構築のための情報抽出に不可欠なタスクです。この論文では、シーケンス生成のためのエンドツーエンドのトリプル抽出タスクを再検討します。生成的トリプル抽出は、長期的な依存関係をキャプチャして不忠実なトリプルを生成するのに苦労する可能性があるため、生成的トランスフォーマーを使用した対照的なトリプル抽出という新しいモデルを紹介します。具体的には、エンコーダ-デコーダベースの生成用の単一の共有トランスモジュールを紹介します。忠実な結果を生成するために、新しいトリプレット対照トレーニングオブジェクトを提案します。さらに、モデルのパフォーマンスをさらに向上させる2つのメカニズム（バッチごとの動的注意マスキングとトリプルごとのキャリブレーション）を紹介します。 3つのデータセット（つまり、NYT、WebNLG、およびMIE）での実験結果は、私たちのアプローチがベースラインよりも優れたパフォーマンスを達成することを示しています。コードとデータセットは公開後にリリースされます。,
Revealing Hidden Preconditions and Effects of Compound HTN Planning Tasks – A Complexity Analysis,"['Conny Olz', 'Susanne Biundo', 'Pascal T Bercher']",,,,
Scalable First-Order Methods for Robust MDPs,"['Julien Grand Clement', 'Christian Kroer']",,,,
Justicia: A Stochastic SAT Approach to Formally Verify Fairness,"['Bishwamittra Ghosh', 'Debabrota Basu', 'Kuldeep S Meel']",,,,
Multi-Level Distance Regularization for Deep Metric Learning,"['Yonghyun Kim', 'Wonpyo Park']",,,,
Semantics Altering Modifications for Evaluating Comprehension in Machine Reading,"['Viktor Schlegel', 'Goran Nenadic', 'Riza Batista-Navarro']",,,,
Exploring Transfer Learning for End-to-End Spoken Language Understanding,"['Subendhu Rongali', 'Beiye Liu', 'Liwei Cai', 'Konstantine Arkoudas', 'Chengwei Su', 'Wael Hamza']",,,,
A General Setting for Gradual Semantics Dealing with Similarity,"['Leila Amgoud', 'Victor David']",,,,
Maintenance of Social Commitments in Multiagent Systems,"['Pankaj Telang', 'Munindar Singh', 'Neil Yorke-Smith']",,,,
Teacher Guided Neural Architecture Search for Face Recognition,['Xiaobo Wang'],,,,
Initiative Defense against Facial Manipulation,"['Qidong Huang', 'Wenbo Zhou', 'Jie Zhang', 'Weiming Zhang', 'Nenghai Yu']",,,,
Very Important Person Localization in Unconstrained Conditions: A New Benchmark,"['Xiao Wang', 'Zheng Wang', 'Toshihiko Yamasaki', 'Wenjun Zeng']",,,,
Sample-Efficient L0-L2 Constrained Structure Learning of Sparse Ising Models,"['Antoine Dedieu', 'Miguel Lázaro-Gredilla', 'Dileep George']",,,,
Step-Ahead Error Feedback for Distributed Training with Compressed Gradient,"['An Xu', 'Zhouyuan Huo', 'Heng Huang']",,,,
RpBERT: A Text-Image Relation Propagation-Based BERT Model for Multimodal NER,"['Lin Sun', 'Jiquan Wang', 'Kai Zhang', 'Yindu Su', 'Fangsheng Weng']",,,,
Solution Concepts in Hierarchical Games under Bounded Rationality with Applications to Autonomous Driving,"['Atrisha Sarkar', 'Krzysztof Czarnecki']",,,,
Evolution Strategies for Approximate Solution of Bayesian Games,"['Zun Li', 'Michael Wellman']",,,,
LREN: Low-Rank Embedded Network for Sample-Free Hyperspectral Anomaly Detection,"['Kai Jiang', 'Weiying Xie', 'Jie Lei', 'Tao Jiang', 'Yunsong Li']",,,,
Contrastive Transformation for Self-Supervised Correspondence Learning,"['Ning Wang', 'Wengang Zhou', 'Houqiang Li']",https://arxiv.org/abs/2012.05057,"In this paper, we focus on the self-supervised learning of visual correspondence using unlabeled videos in the wild. Our method simultaneously considers intra- and inter-video representation associations for reliable correspondence estimation. The intra-video learning transforms the image contents across frames within a single video via the frame pair-wise affinity. To obtain the discriminative representation for instance-level separation, we go beyond the intra-video analysis and construct the inter-video affinity to facilitate the contrastive transformation across different videos. By forcing the transformation consistency between intra- and inter-video levels, the fine-grained correspondence associations are well preserved and the instance-level feature discrimination is effectively reinforced. Our simple framework outperforms the recent self-supervised correspondence methods on a range of visual tasks including video object tracking (VOT), video object segmentation (VOS), pose keypoint tracking, etc. It is worth mentioning that our method also surpasses the fully-supervised affinity representation (e.g., ResNet) and performs competitively against the recent fully-supervised algorithms designed for the specific tasks (e.g., VOT and VOS).",この論文では、野生のラベルのないビデオを使用した視覚的対応の自己教師あり学習に焦点を当てます。私たちの方法は、信頼できる対応推定のために、ビデオ内およびビデオ間の表現の関連付けを同時に考慮します。ビデオ内学習は、フレームペアワイズアフィニティを介して、単一のビデオ内のフレーム間で画像コンテンツを変換します。インスタンスレベルの分離の識別表現を取得するには、ビデオ内分析を超えて、ビデオ間の親和性を構築し、異なるビデオ間の対照的な変換を容易にします。ビデオ内レベルとビデオ間レベルの間で変換の一貫性を強制することにより、きめ細かい対応の関連付けが適切に保持され、インスタンスレベルの機能の識別が効果的に強化されます。私たちのシンプルなフレームワークは、ビデオオブジェクトトラッキング（VOT）、ビデオオブジェクトセグメンテーション（VOS）、ポーズキーポイントトラッキングなど、さまざまな視覚的タスクで最近の自己監視通信方式よりも優れています。私たちの手法も完全に監視ありアフィニティ表現（ResNetなど）であり、特定のタスク（VOTやVOSなど）用に設計された最近の完全監視ありアルゴリズムに対して競合的に実行されます。,https://d3i71xaburhd42.cloudfront.net/367b424aed91745cf79c1d29670b16a64a31967a/1-Figure1-1.png
Model Uncertainty Guides Visual Object Tracking,"['Lijun Zhou', 'Antoine Ledent', 'Qintao Hu', 'Ting Liu', 'Jianlin Zhang', 'Marius Kloft']",,,,
RSGNet: Relation Based Skeleton Graph Network for Crowded Scenes Pose Estimation,"['Yan Dai', 'Xuanhan Wang', 'Jingkuan Song', 'Lianli Gao', 'Heng Tao Shen']",,,,
Adversarial Pose Regression Network for Pose-Invariant Face Recognitions,"['Pengyu Li', 'Biao Wang', 'Lei Zhang']",,,,
MIEHDR CNN: Main Image Enhancement Based Ghost-Free High Dynamic Range Imaging Using Dual-Lens Systems,"['Xuan Dong', 'Xiaoyan Hu', 'Weixin Li', 'Xiaojie Wang', 'Yunhong Wang']",,,,
Time-Independent Planning for Multiple Moving Agents,"['Keisuke Okumura', 'Yasumasa Tamura', 'Xavier Defago']",https://arxiv.org/abs/2005.13187,"Typical Multi-agent Path Finding (MAPF) solvers assume that agents move synchronously, thus neglecting the reality gap in timing assumptions, e.g., delays caused by an imperfect execution of asynchronous moves. So far, two policies enforce a robust execution of MAPF plans taken as input, namely, either by forcing agents to synchronize, or by executing plans while preserving temporal dependencies. This paper proposes a third approach, called time-independent planning, which is both online and distributed. We represent reality as a transition system that changes configurations according to atomic actions of agents, and use it to generate a time-independent schedule. Empirical results in a simulated environment with stochastic delays of agents' moves support the validity of our proposal.",典型的なマルチエージェントパスファインディング（MAPF）ソルバーは、エージェントが同期的に移動することを前提としているため、非同期移動の不完全な実行によって引き起こされる遅延など、タイミングの想定における現実のギャップを無視します。これまでのところ、2つのポリシーは、入力として取得されたMAPFプランの堅牢な実行を強制します。つまり、エージェントに同期を強制するか、時間的な依存関係を維持しながらプランを実行します。このホワイトペーパーでは、時間に依存しない計画と呼ばれる、オンラインと分散の両方の3番目のアプローチを提案します。現実をエージェントのアトミックアクションに応じて構成を変更する遷移システムとして表現し、それを使用して時間に依存しないスケジュールを生成します。エージェントの動きが確率的に遅れるシミュレーション環境での経験的結果は、私たちの提案の妥当性を裏付けています。,https://d3i71xaburhd42.cloudfront.net/f303619dfd7814f4d37b9c27dbc946fde64bf85b/2-Figure1-1.png
MeInGame: Create a Game Character Face from a Single Portrait,"['Jiangke Lin', 'Yi Yuan', 'Zhengxia Zou']",https://arxiv.org/abs/2102.02371,"Many deep learning based 3D face reconstruction methods have been proposed recently, however, few of them have applications in games. Current game character customization systems either require players to manually adjust considerable face attributes to obtain the desired face, or have limited freedom of facial shape and texture. In this paper, we propose an automatic character face creation method that predicts both facial shape and texture from a single portrait, and it can be integrated into most existing 3D games. Although 3D Morphable Face Model (3DMM) based methods can restore accurate 3D faces from single images, the topology of 3DMM mesh is different from the meshes used in most games. To acquire fidelity texture, existing methods require a large amount of face texture data for training, while building such datasets is time-consuming and laborious. Besides, such a dataset collected under laboratory conditions may not generalized well to in-the-wild situations. To tackle these problems, we propose 1) a low-cost facial texture acquisition method, 2) a shape transfer algorithm that can transform the shape of a 3DMM mesh to games, and 3) a new pipeline for training 3D game face reconstruction networks. The proposed method not only can produce detailed and vivid game characters similar to the input portrait, but can also eliminate the influence of Code and dataset are available at https://github.com/FuxiCV/ MeInGame. lighting and occlusions. Experiments show that our method outperforms state-of-the-art methods used in games.",最近、多くの深層学習ベースの3D顔再構成法が提案されていますが、ゲームに適用できるものはほとんどありません。現在のゲームキャラクターのカスタマイズシステムでは、プレーヤーが必要な顔を取得するためにかなりの顔属性を手動で調整する必要があるか、顔の形状とテクスチャの自由度が制限されています。本稿では、1つのポートレートから顔の形と質感の両方を予測する自動キャラクター顔作成方法を提案し、既存のほとんどの3Dゲームに統合することができます。 3D Morphable Face Model（3DMM）ベースの方法では、単一の画像から正確な3D顔を復元できますが、3DMMメッシュのトポロジは、ほとんどのゲームで使用されるメッシュとは異なります。忠実度のテクスチャを取得するために、既存の方法ではトレーニングのために大量の顔のテクスチャデータが必要ですが、そのようなデータセットの構築には時間と手間がかかります。さらに、実験室の条件下で収集されたそのようなデータセットは、実際の状況にうまく一般化されない可能性があります。これらの問題に取り組むために、1）低コストの顔のテクスチャ取得方法、2）3DMMメッシュの形状をゲームに変換できる形状転送アルゴリズム、3）3Dゲームの顔再構成ネットワークをトレーニングするための新しいパイプラインを提案します。提案された方法は、入力されたポートレートに似た詳細で鮮やかなゲームキャラクターを生成できるだけでなく、コードの影響を排除することもできます。データセットはhttps://github.com/FuxiCV/MeInGameで入手できます。照明と咬合。実験によると、私たちの方法は、ゲームで使用されている最先端の方法よりも優れています。,https://d3i71xaburhd42.cloudfront.net/e532172848febb7a0a42b853279ad948a2afdb5b/3-Figure2-1.png
The Price of Connectivity in Fair Division,"['Xiaohui Bei', 'Ayumi Igarashi', 'Xinhang Lu', 'Warut Suksompong']",https://arxiv.org/abs/1908.05433,"We study the allocation of indivisible goods that form an undirected graph and quantify the loss of fairness when we impose a constraint that each agent must receive a connected subgraph. Our focus is on well-studied fairness notions including envy-freeness and maximin share fairness. We introduce the price of connectivity to capture the largest gap between the graph-specific and the unconstrained maximin share, and derive bounds on this quantity which are tight for large classes of graphs in the case of two agents and for paths and stars in the general case. For instance, with two agents we show that for biconnected graphs it is possible to obtain at least $3/4$ of the maximin share with connected allocations, while for the remaining graphs the guarantee is at most $1/2$. In addition, we determine the optimal relaxation of envy-freeness that can be obtained with each graph for two agents, and characterize the set of trees and complete bipartite graphs that always admit an allocation satisfying envy-freeness up to one good (EF1) for three agents. Our work demonstrates several applications of graph-theoretic tools and concepts to fair division problems.",無向グラフを形成する不可分な商品の割り当てを調査し、各エージェントが接続されたサブグラフを受信する必要があるという制約を課した場合の公平性の喪失を定量化します。私たちの焦点は、羨望のないことやマキシミンシェアの公平性など、よく研究された公平性の概念にあります。グラフ固有の最大シェアと制約のないマキシミンシェアの間の最大のギャップをキャプチャするための接続の価格を紹介し、2つのエージェントの場合の大規模なクラスのグラフ、および一般的なパスとスターに対して厳しいこの量の限界を導き出します。場合。たとえば、2つのエージェントを使用すると、2連結グラフの場合、接続された割り当てで最大シェアの少なくとも3/4を取得でき、残りのグラフの場合、保証は最大で1/2であることを示します。さらに、2つのエージェントの各グラフで取得できる羨望のない最適な緩和を決定し、ツリーのセットと、1つの良い（EF1）までの羨望のないことを満たす割り当てを常に許可する完全2部グラフを特徴付けます。 3つのエージェント。私たちの仕事は、公平分割問題へのグラフ理論ツールと概念のいくつかの応用を示しています。,https://d3i71xaburhd42.cloudfront.net/53387c9ef2eea608eebeade4e8480ff50937f075/11-Figure1-1.png
Hierarchical Multiple Kernel Clustering,"['Jiyuan Liu', 'Xinwang Liu', 'Siwei Wang', 'Sihang Zhou', 'Yuexiang Yang']",,,,
Generalizable Representation Learning for Mixture Domain Face Anti-Spoofing,"['Zhihong Chen', 'Taiping Yao', 'Kekai Sheng', 'Shouhong Ding', 'Ying Tai', 'Jilin Li', 'Feiyue Huang', 'Xinyu Jin']",,,,
Interpretable Clustering on Dynamic Graphs with Recurrent Graph Neural Networks,"['Yuhang Yao', 'Carlee Joe-Wong']",https://arxiv.org/abs/2012.08740,"We study the problem of clustering nodes in a dynamic graph, where the connections between nodes and nodes' cluster memberships may change over time, e.g., due to community migration. We first propose a dynamic stochastic block model that captures these changes, and a simple decay-based clustering algorithm that clusters nodes based on weighted connections between them, where the weight decreases at a fixed rate over time. This decay rate can then be interpreted as signifying the importance of including historical connection information in the clustering. However, the optimal decay rate may differ for clusters with different rates of turnover. We characterize the optimal decay rate for each cluster and propose a clustering method that achieves almost exact recovery of the true clusters. We then demonstrate the efficacy of our clustering algorithm with optimized decay rates on simulated graph data. Recurrent neural networks (RNNs), a popular algorithm for sequence learning, use a similar decay-based method, and we use this insight to propose two new RNN-GCN (graph convolutional network) architectures for semi-supervised graph clustering. We finally demonstrate that the proposed architectures perform well on real data compared to state-of-the-art graph clustering algorithms.",動的グラフでノードをクラスタリングする問題を調査します。この場合、ノードとノードのクラスターメンバーシップ間の接続は、コミュニティの移行などにより、時間の経過とともに変化する可能性があります。最初に、これらの変化をキャプチャする動的確率ブロックモデルと、ノード間の重み付き接続に基づいてノードをクラスター化する単純な減衰ベースのクラスタリングアルゴリズムを提案します。このアルゴリズムでは、重みは時間の経過とともに一定の割合で減少します。この減衰率は、クラスタリングに履歴接続情報を含めることの重要性を示していると解釈できます。ただし、最適な減衰率は、ターンオーバー率が異なるクラスターでは異なる場合があります。各クラスターの最適な減衰率を特徴づけ、真のクラスターのほぼ正確な回復を実現するクラスタリング手法を提案します。次に、シミュレートされたグラフデータで最適化された減衰率を使用してクラスタリングアルゴリズムの有効性を示します。シーケンス学習の一般的なアルゴリズムであるリカレントニューラルネットワーク（RNN）は、同様の減衰ベースの方法を使用し、この洞察を使用して、半教師ありグラフクラスタリング用の2つの新しいRNN-GCN（グラフ畳み込みネットワーク）アーキテクチャを提案します。最後に、提案されたアーキテクチャが、最先端のグラフクラスタリングアルゴリズムと比較して、実際のデータで良好に機能することを示します。,https://d3i71xaburhd42.cloudfront.net/4eb4b82115ba3506c9867fccdb23413e9e6fbe2a/4-Figure1-1.png
Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise,"['Pengfei Chen', 'JunJie Ye', 'Guangyong Chen', 'Jingwei Zhao', 'Pheng-Ann Heng']",https://arxiv.org/abs/2012.05458,"Supervised learning under label noise has seen numerous advances recently, while existing theoretical findings and empirical results broadly build up on the class-conditional noise (CCN) assumption that the noise is independent of input features given the true label. In this work, we present a theoretical hypothesis testing and prove that noise in real-world dataset is unlikely to be CCN, which confirms that label noise should depend on the instance and justifies the urgent need to go beyond the CCN assumption.The theoretical results motivate us to study the more general and practical-relevant instance-dependent noise (IDN). To stimulate the development of theory and methodology on IDN, we formalize an algorithm to generate controllable IDN and present both theoretical and empirical evidence to show that IDN is semantically meaningful and challenging. As a primary attempt to combat IDN, we present a tiny algorithm termed self-evolution average label (SEAL), which not only stands out under IDN with various noise fractions, but also improves the generalization on real-world noise benchmark Clothing1M. Our code is released. Notably, our theoretical analysis in Section 2 provides rigorous motivations for studying IDN, which is an important topic that deserves more research attention in future.",ラベルノイズの下での教師あり学習は最近多くの進歩を遂げましたが、既存の理論的発見と経験的結果は、ノイズが真のラベルを与えられた入力特徴から独立しているというクラス条件付きノイズ（CCN）の仮定に広く基づいています。この作業では、理論的な仮説検定を提示し、実際のデータセットのノイズがCCNである可能性が低いことを証明します。これにより、ラベルノイズはインスタンスに依存する必要があり、CCNの仮定を超える緊急の必要性が正当化されます。理論的な結果より一般的で実用的なインスタンス依存ノイズ（IDN）を研究するように私たちを動機付けます。 IDNに関する理論と方法論の開発を促進するために、アルゴリズムを形式化して制御可能なIDNを生成し、理論的証拠と経験的証拠の両方を提示して、IDNが意味的に意味があり挑戦的であることを示します。 IDNと戦うための主要な試みとして、自己進化平均ラベル（SEAL）と呼ばれる小さなアルゴリズムを提示します。これは、さまざまなノイズの割合でIDNの下で際立つだけでなく、実際のノイズベンチマークClothing1Mの一般化も改善します。コードがリリースされました。特に、セクション2の理論的分析は、IDNを研究するための厳密な動機を提供します。これは、今後さらに研究の注目に値する重要なトピックです。,https://d3i71xaburhd42.cloudfront.net/4945fb6bc967179b8d9a19e1b2f87a62720d79c7/1-Figure1-1.png
FaceController: Controllable Attribute Editing for Face in the Wild,"['Zhiliang Xu', 'Xiyu Yu', 'Zhibin Hong', 'Zhen Zhu', 'Junyu Han', 'Jingtuo Liu', 'Errui Ding', 'Xiang Bai']",,,,
Diffusion Network Inference from Partial Observations,"['Ting Gan', 'Keqi Han', 'Hao Huang', 'Shi Ying', 'Yunjun Gao', 'Zongpeng Li']",,,,
SPIN: Structure-Preserving Inner Offset Network for Scene Text Recognition,"['Chengwei Zhang', 'Yunlu Xu', 'Zhanzhan Cheng', 'Shiliang Pu', 'Yi Niu', 'Fei Wu', 'Futai Zou']",https://arxiv.org/abs/2005.13117,"Arbitrary text appearance poses a great challenge in scene text recognition tasks. Existing works mostly handle with the problem in consideration of the shape distortion, including perspective distortions, line curvature or other style variations. Therefore, methods based on spatial transformers are extensively studied. However, chromatic difficulties in complex scenes have not been paid much attention on. In this work, we introduce a new learnable geometric-unrelated module, the Structure-Preserving Inner Offset Network (SPIN), which allows the color manipulation of source data within the network. This differentiable module can be inserted before any recognition architecture to ease the downstream tasks, giving neural networks the ability to actively transform input intensity rather than the existing spatial rectification. It can also serve as a complementary module to known spatial transformations and work in both independent and collaborative ways with them. Extensive experiments show that the use of SPIN results in a significant improvement on multiple text recognition benchmarks compared to the state-of-the-arts.",任意のテキストの外観は、シーンのテキスト認識タスクに大きな課題をもたらします。既存の作品は、遠近法による歪み、線の曲率、その他のスタイルの変化など、形状の歪みを考慮して問題を処理することがほとんどです。したがって、空間トランスに基づく方法が広く研究されています。ただし、複雑なシーンでの色の問題はあまり注目されていません。この作業では、新しい学習可能な幾何学的に無関係なモジュールである構造保存内部オフセットネットワーク（SPIN）を紹介します。これにより、ネットワーク内のソースデータの色操作が可能になります。この微分可能なモジュールを認識アーキテクチャの前に挿入して、ダウンストリームタスクを容易にし、ニューラルネットワークに既存の空間整流ではなく入力強度をアクティブに変換する機能を提供します。また、既知の空間変換を補完するモジュールとして機能し、独立した方法と協調的な方法の両方で機能します。広範な実験により、SPINを使用すると、最新技術と比較して、複数のテキスト認識ベンチマークが大幅に改善されることが示されています。,https://d3i71xaburhd42.cloudfront.net/1ba1f20fa3b06e4de4e47cb739b6fbc9a0483c7b/2-Figure1-1.png
High-Dimensional Bayesian Optimization via Tree-Structured Additive Models,"['Eric LW Han', 'Ishank Arora', 'Jonathan Scarlett']",,,,
Split then Refine: Stacked Attention-Guided ResUNets for Blind Single Image Visible Watermark Removal,"['Xiaodong Cun', 'Chi-Man Pun']",,,,
SARG: A Novel Semi Autoregressive Generator for Multi-Turn Incomplete Utterance Restoration,"['Mengzuo Huang', 'Feng Li', 'Wuhe Zou', 'Weidong Zhang']",https://arxiv.org/abs/2008.01474,"Dialogue systems in the open domain have achieved great success due to large conversation data and the development of deep learning, but multi-turn scenarios are still a challenge because of the frequent coreference and information omission. In this paper, we investigate the incomplete utterance restoration since it has brought general improvement over multi-turn dialogue systems in recent studies. Inspired by the autoregression for generation and the sequence labeling for text editing, we propose a novel semi autoregressive generator (SARG) with the high efficiency and flexibility. Moreover, experiments on Restoration-200k show that our proposed model significantly outperforms the state-of-the-art models with faster inference speed.",オープンドメインの対話システムは、大量の会話データと深層学習の開発により大きな成功を収めていますが、頻繁な共参照と情報の欠落のため、マルチターンシナリオは依然として課題です。この論文では、最近の研究でマルチターン対話システムに一般的な改善をもたらしたため、不完全な発話復元を調査します。生成のための自己回帰とテキスト編集のためのシーケンスラベリングに触発されて、高効率と柔軟性を備えた新しい半自己回帰ジェネレータ（SARG）を提案します。さらに、Restoration-200kでの実験は、提案されたモデルが、より速い推論速度で最先端のモデルを大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/cddcac0ae0c5573ab4adc0e307df862df076dd63/4-Figure1-1.png
DPFPS: Dynamic and Progressive Filter Pruning for Compressing Convolutional Neural Networks from Scratch,"['Xiaofeng Ruan', 'Yufan Liu', 'Bing Li', 'Chunfeng Yuan', 'Weiming Hu']",,,,
Boosting Image-Based Mutual Gaze Detection Using Pseudo 3D Gaze,"['Bardia Doosti', 'Ching-Hui Chen', 'Raviteja Vemulapalli', 'Xuhui Jia', 'Yukun Zhu', 'Bradley Green']",https://arxiv.org/abs/2010.07811,"Mutual gaze detection, i.e., predicting whether or not two people are looking at each other, plays an important role in understanding human interactions. In this work, we focus on the task of image-based mutual gaze detection, and propose a simple and effective approach to boost the performance by using an auxiliary 3D gaze estimation task during training. We achieve the performance boost without additional labeling cost by training the 3D gaze estimation branch using pseudo 3D gaze labels deduced from mutual gaze labels. By sharing the head image encoder between the 3D gaze estimation and the mutual gaze detection branches, we achieve better head features than learned by training the mutual gaze detection branch alone. Experimental results on three image datasets show that the proposed approach improves the detection performance significantly without additional annotations. This work also introduces a new image dataset that consists of 33.1K pairs of humans annotated with mutual gaze labels in 29.2K images.",相互の視線検出、つまり2人がお互いを見ているかどうかを予測することは、人間の相互作用を理解する上で重要な役割を果たします。この作業では、画像ベースの相互視線検出のタスクに焦点を当て、トレーニング中に補助的な3D視線推定タスクを使用してパフォーマンスを向上させるためのシンプルで効果的なアプローチを提案します。相互注視ラベルから推定される疑似3D注視ラベルを使用して3D注視推定ブランチをトレーニングすることにより、追加のラベリングコストなしでパフォーマンスの向上を実現します。 3D視線推定と相互視線検出ブランチ間で頭部画像エンコーダーを共有することにより、相互視線検出ブランチのみをトレーニングすることで学習するよりも優れた頭部機能を実現します。 3つの画像データセットでの実験結果は、提案されたアプローチが追加の注釈なしで検出性能を大幅に改善することを示しています。この作品はまた、29.2Kの画像で相互注視ラベルで注釈が付けられた33.1Kの人間のペアで構成される新しい画像データセットを紹介します。,https://d3i71xaburhd42.cloudfront.net/f4837e527820a736a415f7f887e0a3052ed9afdc/3-Figure1-1.png
Partially Non-Autoregressive Image Captioning,['Zhengcong Fei'],,,,
MANGO: A Mask Attention Guided One-Stage Scene Text Spotter,"['Liang Qiao', 'Ying Chen', 'Zhanzhan Cheng', 'Yunlu Xu', 'Yi Niu', 'Shiliang Pu', 'Fei Wu']",https://arxiv.org/abs/2012.04350,"Recently end-to-end scene text spotting has become a popular research topic due to its advantages of global optimization and high maintainability in real applications. Most methods attempt to develop various region of interest (RoI) operations to concatenate the detection part and the sequence recognition part into a two-stage text spotting framework. However, in such framework, the recognition part is highly sensitive to the detected results (\emph{e.g.}, the compactness of text contours). To address this problem, in this paper, we propose a novel Mask AttentioN Guided One-stage text spotting framework named MANGO, in which character sequences can be directly recognized without RoI operation. Concretely, a position-aware mask attention module is developed to generate attention weights on each text instance and its characters. It allows different text instances in an image to be allocated on different feature map channels which are further grouped as a batch of instance features. Finally, a lightweight sequence decoder is applied to generate the character sequences. It is worth noting that MANGO inherently adapts to arbitrary-shaped text spotting and can be trained end-to-end with only coarse position information (\emph{e.g.}, rectangular bounding box) and text annotations. Experimental results show that the proposed method achieves competitive and even new state-of-the-art performance on both regular and irregular text spotting benchmarks, i.e., ICDAR 2013, ICDAR 2015, Total-Text, and SCUT-CTW1500.",最近、エンドツーエンドのシーンテキストスポッティングは、グローバルな最適化と実際のアプリケーションでの高い保守性という利点により、人気のある研究トピックになっています。ほとんどの方法は、さまざまな関心領域（RoI）操作を開発して、検出部分とシーケンス認識部分を2段階のテキストスポッティングフレームワークに連結しようとします。しかしながら、そのようなフレームワークでは、認識部分は、検出された結果（例えば、テキストの輪郭のコンパクトさ）に非常に敏感である。この問題に対処するために、本論文では、RoI操作なしで文字シーケンスを直接認識できるMANGOという名前の新しいMask AttentioN GuidedOne-stageテキストスポッティングフレームワークを提案します。具体的には、位置認識マスク注意モジュールが開発され、各テキストインスタンスとその文字に注意の重みが生成されます。これにより、画像内のさまざまなテキストインスタンスを、インスタンス機能のバッチとしてさらにグループ化されたさまざまな機能マップチャネルに割り当てることができます。最後に、軽量シーケンスデコーダーを適用して文字シーケンスを生成します。 MANGOは本質的に任意の形状のテキストスポッティングに適応し、粗い位置情報（たとえば、長方形の境界ボックス）とテキスト注釈のみでエンドツーエンドでトレーニングできることは注目に値します。実験結果は、提案された方法が、定期的および不規則なテキストスポッティングベンチマーク、すなわちICDAR 2013、ICDAR 2015、Total-Text、およびSCUT-CTW1500の両方で、競争力のある、さらには新しい最先端のパフォーマンスを達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/a506cba3b392a8845fa3c22531f002230257be95/1-Figure1-1.png
Augmenting Policy Learning with Routines Discovered from a Single Demonstration,"['Zelin Zhao', 'Chuang Gan', 'Jiajun Wu', 'Xiaoxiao Guo', 'Joshua Tenenbaum']",https://arxiv.org/abs/2012.12469,"Humans can abstract prior knowledge from very little data and use it to boost skill learning. In this paper, we propose routineaugmented policy learning (RAPL), which discovers routines composed of primitive actions from a single demonstration and uses discovered routines to augment policy learning. To discover routines from the demonstration, we first abstract routine candidates by identifying grammar over the demonstrated action trajectory. Then, the best routines measured by length and frequency are selected to form a routine library. We propose to learn policy simultaneously at primitive-level and routine-level with discovered routines, leveraging the temporal structure of routines. Our approach enables imitating expert behavior at multiple temporal scales for imitation learning and promotes reinforcement learning exploration. Extensive experiments on Atari games demonstrate that RAPL improves the state-of-the-art imitation learning method SQIL and reinforcement learning method A2C. Further, we show that discovered routines can generalize to unseen levels and difficulties on the CoinRun benchmark.",人間は、ごくわずかなデータから事前知識を抽象化し、それを使用してスキル学習を促進することができます。この論文では、単一のデモンストレーションからプリミティブアクションで構成されるルーチンを検出し、検出されたルーチンを使用してポリシー学習を拡張する、ルーチン拡張ポリシー学習（RAPL）を提案します。デモンストレーションからルーチンを発見するために、最初に、デモンストレーションされたアクションの軌跡で文法を特定することにより、ルーチンの候補を抽象化します。次に、長さと頻度で測定された最適なルーチンが選択され、ルーチンライブラリが形成されます。ルーチンの時間的構造を活用して、発見されたルーチンと同時にプリミティブレベルとルーチンレベルでポリシーを学習することを提案します。私たちのアプローチは、模倣学習のために複数の時間スケールで専門家の行動を模倣することを可能にし、強化学習の探索を促進します。 Atariゲームでの広範な実験は、RAPLが最先端の模倣学習方法SQILと強化学習方法A2Cを改善することを示しています。さらに、発見されたルーチンがCoinRunベンチマークで目に見えないレベルと困難に一般化する可能性があることを示します。,https://d3i71xaburhd42.cloudfront.net/ec8eee61f42e07228bc78faac9817cff3e000ebf/2-Figure1-1.png
Protecting the Protected Group: Circumventing Harmful Fairness,"['Omer Ben-Porat', 'Moshe Tennenholtz', 'Fedor Sandomirskiy']",https://arxiv.org/abs/1905.10546,"Machine Learning (ML) algorithms shape our lives. Banks use them to determine if we are good borrowers; IT companies delegate them recruitment decisions; police apply ML for crime-prediction, and judges base their verdicts on ML. However, real-world examples show that such automated decisions tend to discriminate against protected groups. This potential discrimination generated a huge hype both in media and in the research community. Quite a few formal notions of fairness were proposed, which take a form of constraints a ""fair"" algorithm must satisfy. We focus on scenarios where fairness is imposed on a self-interested party (e.g., a bank that maximizes its revenue). We find that the disadvantaged protected group can be worse off after imposing a fairness constraint. We introduce a family of \textit{Welfare-Equalizing} fairness constraints that equalize per-capita welfare of protected groups, and include \textit{Demographic Parity} and \textit{Equal Opportunity} as particular cases. In this family, we characterize conditions under which the fairness constraint helps the disadvantaged group. We also characterize the structure of the optimal \textit{Welfare-Equalizing} classifier for the self-interested party, and provide an algorithm to compute it. Overall, our \textit{Welfare-Equalizing} fairness approach provides a unified framework for discussing fairness in classification in the presence of a self-interested party.",機械学習（ML）アルゴリズムは、私たちの生活を形作ります。銀行はそれらを使用して、私たちが良い借り手であるかどうかを判断します。 IT企業は彼らに採用決定を委任します。警察は犯罪予測にMLを適用し、裁判官はMLに基づいて評決を下します。ただし、実際の例では、そのような自動化された決定が保護されたグループを差別する傾向があることが示されています。この潜在的な差別は、メディアと研究コミュニティの両方で大きな誇大宣伝を生み出しました。 「公正な」アルゴリズムが満たさなければならない制約の形をとる、かなりの数の正式な公平性の概念が提案されました。私たちは、自己利益のある当事者（たとえば、収益を最大化する銀行）に公平性が課せられるシナリオに焦点を当てています。公平性の制約を課した後、不利な立場にある保護されたグループが悪化する可能性があることがわかりました。保護されたグループの一人当たりの福祉を平等にする福祉平準化の公平性制約のファミリーを紹介し、特定のケースとして人口統計学的平等と機会均等を含めます。この家族では、公平性の制約が不利な立場にあるグループを助ける条件を特徴づけます。また、利害関係者に最適な福祉平準化分類器の構造を特徴付け、それを計算するためのアルゴリズムを提供します。全体として、私たちの福祉平準化公平性アプローチは、利害関係者の存在下での分類における公平性を議論するための統一されたフレームワークを提供します。,https://d3i71xaburhd42.cloudfront.net/01568d72f87012233c7ecf2952b2abfa4b22fffb/10-Figure1-1.png
RGB-D Salient Object Detection via 3D Convolutional Neural Networks,"['Qian Chen', 'Ze Liu', 'Yi Zhang', 'Keren Fu', 'Qijun Zhao', 'Hongwei Du']",https://arxiv.org/abs/2101.10241,"RGB-D salient object detection (SOD) recently has attracted increasing research interest and many deep learning methods based on encoder-decoder architectures have emerged. However, most existing RGB-D SOD models conduct feature fusion either in the single encoder or the decoder stage, which hardly guarantees sufficient cross-modal fusion ability. In this paper, we make the first attempt in addressing RGB-D SOD through 3D convolutional neural networks. The proposed model, named RD3D, aims at pre-fusion in the encoder stage and in-depth fusion in the decoder stage to effectively promote the full integration of RGB and depth streams. Specifically, RD3D first conducts pre-fusion across RGB and depth modalities through an inflated 3D encoder, and later provides in-depth feature fusion by designing a 3D decoder equipped with rich back-projection paths (RBPP) for leveraging the extensive aggregation ability of 3D convolutions. With such a progressive fusion strategy involving both the encoder and decoder, effective and thorough interaction between the two modalities can be exploited and boost the detection accuracy. Extensive experiments on six widely used benchmark datasets demonstrate that RD3D performs favorably against 14 state-of-the-art RGB-D SOD approaches in terms of four key evaluation metrics. Our code will be made publicly available: https://github.com/PPOLYpubki/RD3D.",RGB-D顕著なオブジェクト検出（SOD）は最近、ますます研究の関心を集めており、エンコーダ-デコーダアーキテクチャに基づく多くの深層学習方法が出現しています。ただし、ほとんどの既存のRGB-D SODモデルは、単一のエンコーダーまたはデコーダーステージのいずれかで特徴融合を実行するため、十分なクロスモーダル融合能力はほとんど保証されません。この論文では、3D畳み込みニューラルネットワークを介してRGB-DSODに対処する最初の試みを行います。 RD3Dという名前の提案されたモデルは、エンコーダー段階での事前融合とデコーダー段階での詳細な融合を目的としており、RGBと深度ストリームの完全な統合を効果的に促進します。具体的には、RD3Dは、最初に膨張した3Dエンコーダーを介してRGBと深度モダリティ全体で事前融合を実行し、その後、3Dの広範な集約機能を活用するための豊富な逆投影パス（RBPP）を備えた3Dデコーダーを設計することにより、詳細な特徴融合を提供します畳み込み。エンコーダーとデコーダーの両方を含むこのようなプログレッシブフュージョン戦略により、2つのモダリティ間の効果的かつ完全な相互作用を活用して、検出精度を高めることができます。広く使用されている6つのベンチマークデータセットでの広範な実験により、RD3Dは、4つの主要な評価指標の観点から14の最先端のRGB-DSODアプローチに対して良好に機能することが示されています。私たちのコードは一般に公開されます：https：//github.com/PPOLYpubki/RD3D。,https://d3i71xaburhd42.cloudfront.net/609c315d881f8277991abce44706bfc41129bb2e/1-Figure1-1.png
Probing Product Description Generation via Posterior Distillation,"['Haolan Zhan', 'Hainan Zhang', 'Hongshen Chen', 'Lei Shen', 'Zhuoye Ding', 'Yongjun Bao', 'Weipeng Yan', 'Yanyan Lan']",,,,
Evidence Inference Networks for Interpretable Claim Verification,"['Lianwei Wu', 'Yuan Rao', 'Ling Sun', 'Wangbo He']",,,,
Enhanced Audio Tagging via Multi- to Single-Modal Teacher-Student Mutual Learning,"['Yifang Yin', 'Harsh Shrivastava', 'Ying Zhang', 'Zhenguang Liu', 'Rajiv Ratn Shah', 'Roger Zimmermann']",,,,
In-Game Residential Home Planning via Visual Context-Aware Global Relation Learning,"['Lijuan Liu', 'Yin Yang', 'Yi Yuan', 'Tianjia Shao', 'He E Wang', 'Kun Zhou']",,,,
Invariant Teacher and Equivariant Student for Unsupervised 3D Human Pose Estimation,"['Chenxin Xu', 'Siheng Chen', 'Maosen Li', 'Ya Zhang']",https://arxiv.org/abs/2012.09398,"We propose a novel method based on teacher-student learning framework for 3D human pose estimation without any 3D annotation or side information. To solve this unsupervised-learning problem, the teacher network adopts pose-dictionary-based modeling for regularization to estimate a physically plausible 3D pose. To handle the decomposition ambiguity in the teacher network, we propose a cycle-consistent architecture promoting a 3D rotation-invariant property to train the teacher network. To further improve the estimation accuracy, the student network adopts a novel graph convolution network for flexibility to directly estimate the 3D coordinates. Another cycle-consistent architecture promoting 3D rotation-equivariant property is adopted to exploit geometry consistency, together with knowledge distillation from the teacher network to improve the pose estimation performance. We conduct extensive experiments on Human3.6M and MPI-INF-3DHP. Our method reduces the 3D joint prediction error by 11.4% compared to state-of-the-art unsupervised methods and also outperforms many weakly-supervised methods that use side information on Human3.6M. Code will be available at this https URL.",3D注釈やサイド情報なしで3D人間の姿勢を推定するための教師と学生の学習フレームワークに基づく新しい方法を提案します。この教師なし学習の問題を解決するために、教師ネットワークは、正則化のためにポーズ辞書ベースのモデリングを採用して、物理的にもっともらしい3Dポーズを推定します。教師ネットワークの分解のあいまいさを処理するために、教師ネットワークをトレーニングするために3D回転不変プロパティを促進するサイクル整合性のあるアーキテクチャを提案します。推定精度をさらに向上させるために、学生ネットワークは、3D座標を直接推定する柔軟性を備えた新しいグラフ畳み込みネットワークを採用しています。ジオメトリの一貫性を活用するために、3D回転等価プロパティを促進する別のサイクル一貫性のあるアーキテクチャが採用され、教師ネットワークからの知識の蒸留により、ポーズ推定のパフォーマンスが向上します。 Human3.6MとMPI-INF-3DHPで広範な実験を行っています。私たちの方法は、3D関節予測誤差を11.4減少させます,https://d3i71xaburhd42.cloudfront.net/feeca807fc480d7175d16427531b64ea007b7672/1-Figure1-1.png
One-Shot Face Reenactment Using Appearance Adaptive Normalization,"['Guangming Yao', 'Yi Yuan', 'Tianjia Shao', 'Shuang Li', 'Shanqi Liu', 'Yong Liu', 'Mengmeng Wang', 'Kun Zhou']",https://arxiv.org/abs/2102.03984,"The paper proposes a novel generative adversarial network for one-shot face reenactment, which can animate a single face image to a different pose-and-expression (provided by a driving image) while keeping its original appearance. The core of our network is a novel mechanism called appearance adaptive normalization, which can effectively integrate the appearance information from the input image into our face generator by modulating the feature maps of the generator using the learned adaptive parameters. Furthermore, we specially design a local net to reenact the local facial components (i.e., eyes, nose and mouth) first, which is a much easier task for the network to learn and can in turn provide explicit anchors to guide our face generator to learn the global appearance and pose-and-expression. Extensive quantitative and qualitative experiments demonstrate the significant efficacy of our model compared with prior one-shot methods.",この論文は、ワンショットの顔の再現のための新しい生成的敵対的ネットワークを提案します。これは、元の外観を維持しながら、単一の顔の画像を異なるポーズと表現（運転画像によって提供される）にアニメーション化できます。私たちのネットワークの中核は、外観適応正規化と呼ばれる新しいメカニズムです。これは、学習した適応パラメータを使用してジェネレータの特徴マップを変調することにより、入力画像からの外観情報を顔ジェネレータに効果的に統合できます。さらに、ローカルネットを特別に設計して、最初にローカルの顔のコンポーネント（つまり、目、鼻、口）を再現します。これは、ネットワークが学習するのがはるかに簡単なタスクであり、フェイスジェネレーターが学習するようにガイドする明示的なアンカーを提供できます。グローバルな外観とポーズと表現。広範な定量的および定性的実験は、以前のワンショット法と比較して、私たちのモデルの重要な有効性を示しています。,https://d3i71xaburhd42.cloudfront.net/f49040a6c34eab6d26ffcbfb08d6c9643ceb0fb1/2-Figure1-1.png
Dividing a Graphical Cake,"['Xiaohui Bei', 'Warut Suksompong']",https://arxiv.org/abs/1910.14129,"We consider the classical cake-cutting problem where we wish to fairly divide a heterogeneous resource, often modeled as a cake, among interested agents. Work on the subject typically assumes that the cake is represented by an interval. In this paper, we introduce a generalized setting where the cake can be in the form of the set of edges of an undirected graph. This allows us to model the division of road or cable networks. Unlike in the canonical setting, common fairness criteria such as proportionality cannot always be satisfied in our setting if each agent must receive a connected subgraph. We determine the optimal approximation of proportionality that can be obtained for any number of agents with arbitrary valuations, and exhibit tight guarantees for each graph in the case of two agents. In addition, when more than one connected piece per agent is allowed, we establish the best egalitarian welfare guarantee for each total number of connected pieces. We also study a number of variants and extensions, including when approximate equitability is considered, or when the item to be divided is undesirable (also known as chore division).",関心のあるエージェント間で、ケーキとしてモデル化されることが多い異種リソースを公平に分割したいという古典的なケーキカットの問題を検討します。主題に関する作業は、通常、ケーキが間隔で表されることを前提としています。この論文では、ケーキが無向グラフのエッジのセットの形をとることができる一般化された設定を紹介します。これにより、道路またはケーブルネットワークの分割をモデル化できます。正規の設定とは異なり、各エージェントが接続されたサブグラフを受信する必要がある場合、比例などの一般的な公平性の基準が常に満たされるとは限りません。任意の評価で任意の数のエージェントに対して取得できる比例の最適な近似を決定し、2つのエージェントの場合に各グラフに対して厳密な保証を示します。さらに、エージェントごとに複数の接続されたピースが許可されている場合、接続されたピースの総数ごとに最高の平等主義的福祉保証を確立します。また、おおよその公平性が考慮される場合や、分割されるアイテムが望ましくない場合（雑用分割とも呼ばれます）など、さまざまなバリエーションや拡張機能についても調査します。,https://d3i71xaburhd42.cloudfront.net/2260aef18efdd391080d4aa810948b316e60dbdf/9-Figure1-1.png
Differentially Private Stochastic Coordinate Descent,"['Georgios Damaskinos', 'Celestine Mendler-Dünner', 'Rachid Guerraoui', 'Nikolaos Papandreou', 'Thomas Parnell']",https://arxiv.org/abs/2006.07272,"In this paper we tackle the challenge of making the stochastic coordinate descent algorithm differentially private. Compared to the classical gradient descent algorithm where updates operate on a single model vector and controlled noise addition to this vector suffices to hide critical information about individuals, stochastic coordinate descent crucially relies on keeping auxiliary information in memory during training. This auxiliary information provides an additional privacy leak and poses the major challenge addressed in this work. Driven by the insight that under independent noise addition, the consistency of the auxiliary information holds in expectation, we present DP-SCD, the first differentially private stochastic coordinate descent algorithm. We analyze our new method theoretically and argue that decoupling and parallelizing coordinate updates is essential for its utility. On the empirical side we demonstrate competitive performance against the popular stochastic gradient descent alternative (DP-SGD) while requiring significantly less tuning.",この論文では、確率的座標降下アルゴリズムを差分的にプライベートにするという課題に取り組んでいます。更新が単一のモデルベクトルで動作し、このベクトルへの制御されたノイズの追加が個人に関する重要な情報を隠すのに十分である古典的な勾配降下アルゴリズムと比較して、確率的座標降下は、トレーニング中に補助情報をメモリに保持することに決定的に依存します。この補助情報は、追加のプライバシーリークを提供し、この作業で対処される主要な課題を提起します。独立したノイズの追加の下で、補助情報の一貫性が期待どおりに保持されるという洞察に駆り立てられて、最初の差分プライベート確率座標降下アルゴリズムであるDP-SCDを提示します。私たちは新しい方法を理論的に分析し、座標更新のデカップリングと並列化がその有用性に不可欠であると主張します。経験的側面では、一般的な確率的勾配降下法（DP-SGD）に対して競争力のあるパフォーマンスを示しますが、必要な調整は大幅に少なくなります。,https://d3i71xaburhd42.cloudfront.net/44da7215f5fac1a7d60e1e7b7ecd201742f3fa79/14-Figure1-1.png
Few-Shot Lifelong Learning,"['Pratik Mazumder', 'Pravendra Singh', 'Piyush Rai']",,,,
"Positions, Channels, and Layers: Fully Generalized Non-Local Network for Singer Identification","['I-Yuan Kuo', 'Wen-Li Wei', 'Jen-Chun Lin']",,,,
Auto-Encoding Transformations in Reparameterized Lie Groups for Unsupervised Learning,"['Feng Lin', 'Haohang Xu', 'Houqiang Li', 'Hongkai Xiong', 'Guo-Jun Qi']",,,,
Conditional Inference under Disjunctive Rationality,"['Richard Booth', 'Ivan J Varzinczak']",,,,
Object-Centric Image Generation from Layouts,"['Tristan Sylvain', 'Pengchuan Zhang', 'Yoshua Bengio', 'R Devon Hjelm', 'Shikhar Sharma']",https://arxiv.org/abs/2003.07449,"Despite recent impressive results on single-object and single-domain image generation, the generation of complex scenes with multiple objects remains challenging. In this paper, we start with the idea that a model must be able to understand individual objects and relationships between objects in order to generate complex scenes well. Our layout-to-image-generation method, which we call Object-Centric Generative Adversarial Network (or OC-GAN), relies on a novel Scene-Graph Similarity Module (SGSM). The SGSM learns representations of the spatial relationships between objects in the scene, which lead to our model's improved layout-fidelity. We also propose changes to the conditioning mechanism of the generator that enhance its object instance-awareness. Apart from improving image quality, our contributions mitigate two failure modes in previous approaches: (1) spurious objects being generated without corresponding bounding boxes in the layout, and (2) overlapping bounding boxes in the layout leading to merged objects in images. Extensive quantitative evaluation and ablation studies demonstrate the impact of our contributions, with our model outperforming previous state-of-the-art approaches on both the COCO-Stuff and Visual Genome datasets. Finally, we address an important limitation of evaluation metrics used in previous works by introducing SceneFID -- an object-centric adaptation of the popular Fr{e}chet Inception Distance metric, that is better suited for multi-object images.",単一オブジェクトおよび単一ドメインの画像生成に関する最近の印象的な結果にもかかわらず、複数のオブジェクトを含む複雑なシーンの生成は依然として困難です。この論文では、複雑なシーンをうまく生成するために、モデルが個々のオブジェクトとオブジェクト間の関係を理解できなければならないという考えから始めます。 Object-Centric Generative Adversarial Network（またはOC-GAN）と呼ばれる、レイアウトから画像への生成方法は、新しいシーングラフ類似性モジュール（SGSM）に依存しています。 SGSMは、シーン内のオブジェクト間の空間的関係の表現を学習します。これにより、モデルのレイアウトの忠実度が向上します。また、オブジェクトのインスタンス認識を強化するジェネレーターの条件付けメカニズムの変更を提案します。画質の向上とは別に、私たちの貢献は、以前のアプローチの2つの失敗モードを軽減します。（1）レイアウト内の対応する境界ボックスなしで生成されるスプリアスオブジェクト、および（2）画像内のマージされたオブジェクトにつながるレイアウト内の重複する境界ボックス。広範な定量的評価とアブレーション研究は、COCO-StuffとVisual Genomeの両方のデータセットで、モデルが以前の最先端のアプローチを上回っており、私たちの貢献の影響を示しています。最後に、SceneFIDを導入することにより、以前の作業で使用された評価メトリックの重要な制限に対処します。これは、マルチオブジェクト画像により適した人気のあるFrechet InceptionDistanceメトリックのオブジェクト中心の適応です。,https://d3i71xaburhd42.cloudfront.net/f19acef3c95e2f454c0afaed317518c19ab3db00/2-Figure1-1.png
Matching on Sets: Conquer Occluded Person Re-Identification Without Alignment,"['Mengxi Jia', 'Xinhua Cheng', 'Yunpeng Zhai', 'Shijian Lu', 'Siwei Ma', 'Yonghong Tian', 'Jian Zhang']",,,,
Verifiable Machine Ethics in Changing Contexts,"['Louise A Dennis', 'Martin Bentzen', 'Felix Lindner', 'Michael Fisher']",,,,
Exploiting Relationship for Complex-Scene Image Generation,"['Tianyu Hua', 'Hongdong Zheng', 'Yalong Bai', 'Wei Zhang', 'Xiao-Ping Zhang', 'Tao Mei']",,,,
Pragmatic Code Autocomplete,"['Gabriel Poesia Reis e Silva', 'Noah Goodman']",,,,
Confidence-Aware Non-Repetitive Multimodal Transformers for TextCaps,"['Zhaokai Wang', 'Renda Bao', 'Qi Wu', 'Si Liu']",https://arxiv.org/abs/2012.03662,"When describing an image, reading text in the visual scene is crucial to understand the key information. Recent work explores the TextCaps task, i.e. image captioning with reading Optical Character Recognition (OCR) tokens, which requires models to read text and cover them in generated captions. Existing approaches fail to generate accurate descriptions because of their (1) poor reading ability; (2) inability to choose the crucial words among all extracted OCR tokens; (3) repetition of words in predicted captions. To this end, we propose a Confidence-aware Non-repetitive Multimodal Transformers (CNMT) to tackle the above challenges. Our CNMT consists of a reading, a reasoning and a generation modules, in which Reading Module employs better OCR systems to enhance text reading ability and a confidence embedding to select the most noteworthy tokens. To address the issue of word redundancy in captions, our Generation Module includes a repetition mask to avoid predicting repeated word in captions. Our model outperforms state-of-the-art models on TextCaps dataset, improving from 81.0 to 93.0 in CIDEr. Our source code is publicly available.",画像を説明するとき、重要な情報を理解するには、視覚的なシーンでテキストを読むことが重要です。最近の作業では、TextCapsタスク、つまり光学式文字認識（OCR）トークンを読み取る画像キャプションを調査しています。このタスクでは、モデルがテキストを読み取り、生成されたキャプションでカバーする必要があります。既存のアプローチは、（1）読解力が低いため、正確な説明を生成できません。 （2）抽出されたすべてのOCRトークンから重要な単語を選択できない。 （3）予測されたキャプション内の単語の繰り返し。この目的のために、上記の課題に取り組むために、信頼性を意識した非反復型マルチモーダル変圧器（CNMT）を提案します。私たちのCNMTは、リーディング、推論、生成モジュールで構成されており、リーディングモジュールはより優れたOCRシステムを採用してテキストのリーディング能力を強化し、最も注目に値するトークンを選択するための信頼埋め込みを採用しています。キャプション内の単語の冗長性の問題に対処するために、生成モジュールには、キャプション内の繰り返し単語の予測を回避するための繰り返しマスクが含まれています。私たちのモデルは、TextCapsデータセットの最先端のモデルよりも優れており、CIDErでは81.0から93.0に向上しています。当社のソースコードは公開されています。,https://d3i71xaburhd42.cloudfront.net/b1fe7a16266cf2316f436688e0df6c6350c885ef/1-Figure1-1.png
Partial Is Better Than All: Revisiting Fine-Tuning Strategy for Few-Shot Learning,"['Zhiqiang Shen', 'Zechun Liu', 'Jie Qin', 'Marios Savvides', 'Kwang-Ting Cheng']",https://arxiv.org/abs/2102.03983,"The goal of few-shot learning is to learn a classifier that can recognize unseen classes from limited support data with labels. A common practice for this task is to train a model on the base set first and then transfer to novel classes through fine-tuning or meta-learning. However, as the base classes have no overlap to the novel set, simply transferring whole knowledge from base data is not an optimal solution since some knowledge in the base model may be biased or even harmful to the novel class. In this paper, we propose to transfer partial knowledge by freezing or fine-tuning particular layer(s) in the base model. Specifically, layers will be imposed different learning rates if they are chosen to be fine-tuned, to control the extent of preserved transferability. To determine which layers to be recast and what values of learning rates for them, we introduce an evolutionary search based method that is efficient to simultaneously locate the target layers and determine their individual learning rates. We conduct extensive experiments on CUB and mini-ImageNet to demonstrate the effectiveness of our proposed method. It achieves the state-of-the-art performance on both meta-learning and non-meta based frameworks. Furthermore, we extend our method to the conventional pre-training + fine-tuning paradigm and obtain consistent improvement.",数ショット学習の目標は、ラベル付きの限られたサポートデータから見えないクラスを認識できる分類器を学習することです。このタスクの一般的な方法は、最初にベースセットでモデルをトレーニングしてから、微調整またはメタ学習を通じて新しいクラスに転送することです。ただし、基本クラスは新規セットと重複しないため、基本データから知識全体を転送するだけでは最適なソリューションではありません。基本モデルの一部の知識は、新規クラスに偏りがあるか、有害でさえある可能性があるためです。この論文では、基本モデルの特定のレイヤーをフリーズまたは微調整することにより、部分的な知識を伝達することを提案します。具体的には、レイヤーが微調整されるように選択された場合、保存された転送可能性の範囲を制御するために、レイヤーに異なる学習率が課されます。再キャストするレイヤーとその学習率の値を決定するために、ターゲットレイヤーの位置を特定し、個々の学習率を決定するのに効率的な進化的検索ベースの方法を導入します。提案手法の有効性を実証するために、CUBとmini-ImageNetで広範な実験を行っています。メタ学習フレームワークと非メタベースのフレームワークの両方で最先端のパフォーマンスを実現します。さらに、従来の事前トレーニング+微調整パラダイムにメソッドを拡張し、一貫した改善を実現します。,https://d3i71xaburhd42.cloudfront.net/7bb3a96078c854f03d6e9c2032ad6efe6873d974/1-Figure1-1.png
PDO-eS2CNNs: Partial Differential Operator Based Equivariant Spherical CNNs,"['Zhengyang Shen', 'Tiancheng Shen', 'Zhouchen Lin', 'Jinwen Ma']",,,,
OPQ: Compressing Deep Neural Networks with One-Shot Pruning-Quantization,"['Peng Hu', 'Xi Peng', 'Hongyuan Zhu', 'Mohamed M. Sabry Aly', 'Jie Lin']",,"As Deep Neural Networks (DNNs) usually are overparameterized and have millions of weight parameters, it is challenging to deploy these large DNN models on resourceconstrained hardware platforms, e.g., smartphones. Numerous network compression methods such as pruning and quantization are proposed to reduce the model size significantly, of which the key is to find suitable compression allocation (e.g., pruning sparsity and quantization codebook) of each layer. Existing solutions obtain the compression allocation in an iterative/manual fashion while finetuning the compressed model, thus suffering from the efficiency issue. Different from the prior art, we propose a novel One-shot PruningQuantization (OPQ) in this paper, which analytically solves the compression allocation with pre-trained weight parameters only. During finetuning, the compression module is fixed and only weight parameters are updated. To our knowledge, OPQ is the first work that reveals pre-trained model is sufficient for solving pruning and quantization simultaneously, without any complex iterative/manual optimization at the finetuning stage. Furthermore, we propose a unified channelwise quantization method that enforces all channels of each layer to share a common codebook, which leads to low bitrate allocation without introducing extra overhead brought by traditional channel-wise quantization. Comprehensive experiments on ImageNet with AlexNet/MobileNet-V1/ResNet-50 show that our method improves accuracy and training efficiency while obtains significantly higher compression rates compared to the state-of-the-art.",ディープニューラルネットワーク（DNN）は通常、パラメーターが多すぎて数百万の重みパラメーターがあるため、これらの大規模なDNNモデルをスマートフォンなどのリソースに制約のあるハードウェアプラットフォームに展開することは困難です。モデルサイズを大幅に削減するために、プルーニングや量子化などの多数のネットワーク圧縮方法が提案されています。その重要な点は、各レイヤーの適切な圧縮割り当て（プルーニングスパース性や量子化コードブックなど）を見つけることです。既存のソリューションは、圧縮モデルを微調整しながら、反復/手動で圧縮割り当てを取得するため、効率の問題が発生します。従来技術とは異なり、本論文では、事前にトレーニングされた重みパラメータのみを使用して圧縮割り当てを分析的に解決する、新しいワンショットプルーニング量子化（OPQ）を提案します。微調整中、圧縮モジュールは固定され、重量パラメータのみが更新されます。私たちの知る限り、OPQは、微調整段階で複雑な反復/手動最適化を行うことなく、事前トレーニング済みモデルが剪定と量子化を同時に解決するのに十分であることを明らかにした最初の作業です。さらに、各層のすべてのチャネルが共通のコードブックを共有するように強制する統合チャネルごとの量子化方法を提案します。これにより、従来のチャネルごとの量子化によってもたらされる余分なオーバーヘッドを導入することなく、ビットレートの割り当てを低くすることができます。 AlexNet / MobileNet-V1 / ResNet-50を使用したImageNetでの包括的な実験は、最新の方法と比較して大幅に高い圧縮率が得られる一方で、この方法が精度とトレーニング効率を改善することを示しています。,https://d3i71xaburhd42.cloudfront.net/7b16367b575d951a98f1762d8f45d7c0eb840581/2-Figure1-1.png
Doubly Residual Neural Decoder: Towards Low-Complexity High-Performance Channel Decoding,"['Siyu Liao', 'Chunhua Deng', 'Miao Yin', 'Bo Yuan']",https://arxiv.org/abs/2102.03959,"Recently deep neural networks have been successfully applied in channel coding to improve the decoding performance. However, the state-of-the-art neural channel decoders cannot achieve high decoding performance and low complexity simultaneously. To overcome this challenge, in this paper we propose doubly residual neural (DRN) decoder. By integrating both the residual input and residual learning to the design of neural channel decoder, DRN enables significant decoding performance improvement while maintaining low complexity. Extensive experiment results show that on different types of channel codes, our DRN decoder consistently outperform the state-of-the-art decoders in terms of decoding performance, model sizes and computational cost.",最近、ディープニューラルネットワークがチャネルコーディングにうまく適用され、デコードパフォーマンスが向上しています。ただし、最先端のニューラルチャネルデコーダーは、高いデコードパフォーマンスと低い複雑さを同時に達成することはできません。この課題を克服するために、この論文では、二重残差ニューラル（DRN）デコーダーを提案します。残余入力と残余学習の両方をニューラルチャネルデコーダーの設計に統合することにより、DRNは、複雑さを低く抑えながら、デコードパフォーマンスを大幅に向上させることができます。広範な実験結果は、さまざまなタイプのチャネルコードで、DRNデコーダーが、デコードパフォーマンス、モデルサイズ、および計算コストの点で、常に最先端のデコーダーよりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/ee935013cfc1758892e982541dda854e2c8e5ec8/1-Figure1-1.png
Knowledge-Driven Data Construction for Zero-Shot Evaluation in Commonsense Question Answering,"['Kaixin Ma', 'Filip Ilievski', 'Jonathan M Francis', 'Yonatan Bisk', 'Eric Nyberg', 'Alessandro Oltramari']",https://arxiv.org/abs/2011.03863,"Recent developments in pre-trained neural language modeling have led to leaps in accuracy on commonsense question-answering benchmarks. However, there is increasing concern that models overfit to specific tasks, without learning to utilize external knowledge or perform general semantic reasoning. In contrast, zero-shot evaluations have shown promise as a more robust measure of a model's general reasoning abilities. In this paper, we propose a novel neuro-symbolic framework for zero-shot question answering across commonsense tasks. Guided by a set of hypotheses, the framework studies how to transform various pre-existing knowledge resources into a form that is most effective for pre-training models. We vary the set of language models, training regimes, knowledge sources, and data generation strategies, and measure their impact across tasks. Extending on prior work, we devise and compare four constrained distractor-sampling strategies. We provide empirical results across five commonsense question-answering tasks with data generated from five external knowledge resources. We show that, while an individual knowledge graph is better suited for specific tasks, a global knowledge graph brings consistent gains across different tasks. In addition, both preserving the structure of the task as well as generating fair and informative questions help language models learn more effectively.",事前にトレーニングされたニューラル言語モデリングの最近の開発により、常識的な質問応答ベンチマークの精度が飛躍的に向上しました。ただし、外部の知識を利用したり、一般的な意味論的推論を実行したりすることを学習せずに、モデルが特定のタスクに適合しすぎるという懸念が高まっています。対照的に、ゼロショット評価は、モデルの一般的な推論能力のより堅牢な尺度として有望であることを示しています。この論文では、常識的なタスク全体でゼロショットの質問応答のための新しい神経記号フレームワークを提案します。このフレームワークは、一連の仮説に基づいて、さまざまな既存の知識リソースを事前トレーニングモデルに最も効果的な形式に変換する方法を研究します。言語モデル、トレーニングレジーム、知識ソース、およびデータ生成戦略のセットを変更し、タスク全体でそれらの影響を測定します。以前の作業を拡張して、4つの制約付きディストラクタサンプリング戦略を考案して比較します。 5つの外部知識リソースから生成されたデータを使用して、5つの常識的な質問応答タスクにわたる経験的な結果を提供します。個々の知識グラフは特定のタスクに適していますが、グローバル知識グラフはさまざまなタスク間で一貫した利益をもたらすことを示しています。さらに、タスクの構造を維持することと、公正で有益な質問を生成することの両方が、言語モデルがより効果的に学習するのに役立ちます。,
Characterizing the Loss Landscape in Non-Negative Matrix Factorization,"['Johan Björck', 'Anmol Kabra', 'Kilian Weinberger', 'Carla P Gomes']",,,,
TabNet: Attentive Interpretable Tabular Learning,"['Sercan O. Arik', 'Tomas Pfister']",https://arxiv.org/abs/1908.07442,"We propose a novel high-performance and interpretable canonical deep tabular data learning architecture, TabNet. TabNet uses sequential attention to choose which features to reason from at each decision step, enabling interpretability and more efficient learning as the learning capacity is used for the most salient features. We demonstrate that TabNet outperforms other neural network and decision tree variants on a wide range of non-performance-saturated tabular datasets and yields interpretable feature attributions plus insights into the global model behavior. Finally, for the first time to our knowledge, we demonstrate self-supervised learning for tabular data, significantly improving performance with unsupervised representation learning when unlabeled data is abundant.",新しい高性能で解釈可能な標準的な深い表形式のデータ学習アーキテクチャであるTabNetを提案します。 TabNetは、各決定ステップで推論する機能を選択するために順次注意を使用し、学習能力が最も顕著な機能に使用されるため、解釈可能性とより効率的な学習を可能にします。 TabNetは、パフォーマンスが飽和していないさまざまな表形式データセットで他のニューラルネットワークやディシジョンツリーバリアントよりも優れており、解釈可能な機能属性に加えて、グローバルモデルの動作に関する洞察が得られることを示しています。最後に、私たちの知る限り初めて、表形式データの教師あり学習を示し、ラベルのないデータが豊富な場合に教師な​​し表現学習でパフォーマンスを大幅に向上させます。,https://d3i71xaburhd42.cloudfront.net/efbd8e7a45cac8f025ba8a4de95b492d8d392c95/2-Figure1-1.png
New Length Dependent Algorithm for Maximum Satisfiability Problem,"['Vasily Alferov', 'Ivan Bliznets']",,,,
Copy That! Editing Sequences by Copying Spans,"['Sheena L Panthaplackel', 'Miltiadis Allamanis', 'Marc Brockschmidt']",,,,
Dynamic Gaussian Mixture Based Deep Generative Model for Robust Forecasting on Sparse Multivariate Time Series,"['Yinjun Wu', 'Jingchao Ni', 'Wei Cheng', 'Bo Zong', 'Dongjin Song', 'Zhengzhang Chen', 'Yanchi Liu', 'Xuchao Zhang', 'Haifeng Chen', 'Susan B Davidson']",,,,
Subtype-Aware Unsupervised Domain Adaptation for Medical Diagnosis,"['Xiaofeng Liu', 'Xiongchang Liu', 'Wenxuan Ji', 'Bo Hu', 'Fangxu Xing', 'Jun Lu', 'Jane You', 'C.-C. Jay Kuo', 'Georges El Fakhri', 'Jonghye Woo']",https://arxiv.org/abs/2101.00318,"Recent advances in unsupervised domain adaptation (UDA) show that transferable prototypical learning presents a powerful means for class conditional alignment, which encourages the closeness of cross-domain class centroids. However, the cross-domain inner-class compactness and the underlying fine-grained subtype structure remained largely underexplored. In this work, we propose to adaptively carry out the fine-grained subtype-aware alignment by explicitly enforcing the class-wise separation and subtype-wise compactness with intermediate pseudo labels. Our key insight is that the unlabeled subtypes of a class can be divergent to one another with different conditional and label shifts, while inheriting the local proximity within a subtype. The cases with or without the prior information on subtype numbers are investigated to discover the underlying subtype structure in an online fashion. The proposed subtype-aware dynamic UDA achieves promising results on a medical diagnosis task.",教師なしドメイン適応（UDA）の最近の進歩は、転送可能なプロトタイプ学習がクラス条件付きアラインメントの強力な手段を提供し、クロスドメインクラス重心の近さを促進することを示しています。ただし、クロスドメインの内部クラスのコンパクトさと基になる細粒度のサブタイプ構造は、大部分が未踏のままでした。この作業では、中間の疑似ラベルを使用してクラスごとの分離とサブタイプごとのコンパクトさを明示的に適用することにより、細粒度のサブタイプ対応のアラインメントを適応的に実行することを提案します。私たちの重要な洞察は、クラスのラベルのないサブタイプは、サブタイプ内のローカルな近接性を継承しながら、異なる条件シフトとラベルシフトで互いに発散する可能性があるということです。サブタイプ番号に関する事前情報がある場合とない場合を調査して、オンラインで基礎となるサブタイプ構造を発見します。提案されたサブタイプを意識した動的UDAは、医療診断タスクで有望な結果を達成します。,https://d3i71xaburhd42.cloudfront.net/3c354b347db3e74f7d7dfd4c8fc5183e3d56b0c7/1-Figure1-1.png
Welfare Guarantees in Schelling Segregation,"['Martin Bullinger', 'Warut Suksompong', 'Alexandros Voudouris']",https://arxiv.org/abs/2012.02086,"Schelling's model is an influential model that reveals how individual perceptions and incentives can lead to racial segregation. Inspired by a recent stream of work, we study welfare guarantees and complexity in this model with respect to several welfare measures. First, we show that while maximizing the social welfare is NP-hard, computing an assignment with approximately half of the maximum welfare can be done in polynomial time. We then consider Pareto optimality and introduce two new optimality notions, and establish mostly tight bounds on the worst-case welfare loss for assignments satisfying these notions. In addition, we show that for trees, it is possible to decide whether there exists an assignment that gives every agent a positive utility in polynomial time; moreover, when every node in the topology has degree at least $2$, such an assignment always exists and can be found efficiently.",Schellingsモデルは、個人の認識とインセンティブが人種差別にどのようにつながるかを明らかにする影響力のあるモデルです。最近の一連の作業に触発されて、私たちはいくつかの福祉措置に関して、このモデルの福祉保証と複雑さを研究しています。まず、社会福祉の最大化はNP困難ですが、最大福祉の約半分の割り当ての計算は多項式時間で実行できることを示します。次に、パレート最適性を検討し、2つの新しい最適性の概念を導入し、これらの概念を満たす割り当ての最悪の場合の厚生損失にほぼ厳しい境界を確立します。さらに、ツリーの場合、すべてのエージェントに多項式時間で正の効用を与える割り当てが存在するかどうかを判断できることを示します。さらに、トポロジ内のすべてのノードの次数が2以上の場合、そのような割り当ては常に存在し、効率的に見つけることができます。,https://d3i71xaburhd42.cloudfront.net/72f409bd1e666cf198cfc185d50013ff9f18e0ae/5-Figure1-1.png
Deep Verifier Networks: Verification of Deep Discriminative Models with Deep Generative Models,"['Tong Che', 'Xiaofeng Liu', 'Site Li', 'Yubin Ge', 'Ruixiang Zhang', 'Caiming Xiong', 'Yoshua Bengio']",https://arxiv.org/abs/1911.07421,"AI Safety is a major concern in many deep learning applications such as autonomous driving. Given a trained deep learning model, an important natural problem is how to reliably verify the model's prediction. In this paper, we propose a novel framework --- deep verifier networks (DVN) to verify the inputs and outputs of deep discriminative models with deep generative models. Our proposed model is based on conditional variational auto-encoders with disentanglement constraints. We give both intuitive and theoretical justifications of the model. Our verifier network is trained independently with the prediction model, which eliminates the need of retraining the verifier network for a new model. We test the verifier network on out-of-distribution detection and adversarial example detection problems, as well as anomaly detection problems in structured prediction tasks such as image caption generation. We achieve state-of-the-art results in all of these problems.",AIの安全性は、自動運転などの多くの深層学習アプリケーションにおける主要な関心事です。訓練された深層学習モデルを考えると、重要な自然の問題は、モデルの予測を確実に検証する方法です。本論文では、深層生成モデルを用いて深層識別モデルの入力と出力を検証するための新しいフレームワーク深層検証ネットワーク（DVN）を提案します。私たちが提案するモデルは、解きほぐし制約のある条件付き変分オートエンコーダに基づいています。モデルの直感的および理論的正当化の両方を提供します。当社の検証者ネットワークは、予測モデルを使用して独立してトレーニングされているため、新しいモデルのために検証者ネットワークを再トレーニングする必要がありません。検証者ネットワークを、分布外の検出と敵対的な例の検出の問題、および画像キャプションの生成などの構造化された予測タスクにおける異常検出の問題についてテストします。私たちはこれらすべての問題で最先端の結果を達成しています。,https://d3i71xaburhd42.cloudfront.net/e37f1435a3881d7a90d2175ab68b085828b93a72/1-Figure1-1.png
Learning with Retrospection,"['Xiang Deng', 'Zhongfei Zhang']",https://arxiv.org/abs/2012.13098,"Deep neural networks have been successfully deployed in various domains of artificial intelligence, including computer vision and natural language processing. We observe that the current standard procedure for training DNNs discards all the learned information in the past epochs except the current learned weights. An interesting question is: is this discarded information indeed useless? We argue that the discarded information can benefit the subsequent training. In this paper, we propose learning with retrospection (LWR) which makes use of the learned information in the past epochs to guide the subsequent training. LWR is a simple yet effective training framework to improve accuracies, calibration, and robustness of DNNs without introducing any additional network parameters or inference cost, only with a negligible training overhead. Extensive experiments on several benchmark datasets demonstrate the superiority of LWR for training DNNs.",ディープニューラルネットワークは、コンピュータービジョンや自然言語処理など、人工知能のさまざまなドメインで正常に展開されています。 DNNをトレーニングするための現在の標準手順では、現在の学習された重みを除いて、過去のエポックで学習されたすべての情報が破棄されることがわかります。興味深い質問は、この破棄された情報は本当に役に立たないのかということです。破棄された情報は、その後のトレーニングに役立つ可能性があると私たちは主張します。本論文では、過去の時代に学んだ情報を活用して、その後の訓練を導く、振り返りによる学習（LWR）を提案する。 LWRは、追加のネットワークパラメータや推論コストを導入することなく、ごくわずかなトレーニングオーバーヘッドで、DNNの精度、キャリブレーション、および堅牢性を向上させるシンプルで効果的なトレーニングフレームワークです。いくつかのベンチマークデータセットでの広範な実験は、DNNのトレーニングに対するLWRの優位性を示しています。,https://d3i71xaburhd42.cloudfront.net/ca73f80bd7f2865cbd63f7345efd24f8d0d0a29a/1-Figure1-1.png
RT3D: Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices,"['Wei Niu', 'Mengshu Sun', 'Zhengang Li', 'Jou-An Chen', 'Jiexiong Guan', 'Xipeng Shen', 'Yanzhi Wang', 'Sijia Liu', 'Xue Lin', 'Bin Ren']",https://arxiv.org/abs/2007.09835,"Mobile devices are becoming an important carrier for deep learning tasks, as they are being equipped with powerful, high-end mobile CPUs and GPUs. However, it is still a challenging task to execute 3D Convolutional Neural Networks (CNNs) targeting for real-time performance, besides high inference accuracy. The reason is more complex model structure and higher model dimensionality overwhelm the available computation/storage resources on mobile devices. A natural way may be turning to deep learning weight pruning techniques. However, the direct generalization of existing 2D CNN weight pruning methods to 3D CNNs is not ideal for fully exploiting mobile parallelism while achieving high inference accuracy. 
This paper proposes RT3D, a model compression and mobile acceleration framework for 3D CNNs, seamlessly integrating neural network weight pruning and compiler code generation techniques. We propose and investigate two structured sparsity schemes i.e., the vanilla structured sparsity and kernel group structured (KGS) sparsity that are mobile acceleration friendly. The vanilla sparsity removes whole kernel groups, while KGS sparsity is a more fine-grained structured sparsity that enjoys higher flexibility while exploiting full on-device parallelism. We propose a reweighted regularization pruning algorithm to achieve the proposed sparsity schemes. The inference time speedup due to sparsity is approaching the pruning rate of the whole model FLOPs (floating point operations). RT3D demonstrates up to 29.1$\times$ speedup in end-to-end inference time comparing with current mobile frameworks supporting 3D CNNs, with moderate 1%-1.5% accuracy loss. The end-to-end inference time for 16 video frames could be within 150 ms, when executing representative C3D and R(2+1)D models on a cellphone. For the first time, real-time execution of 3D CNNs is achieved on off-the-shelf mobiles.",モバイルデバイスは、強力なハイエンドモバイルCPUとGPUを搭載しているため、ディープラーニングタスクの重要なキャリアになりつつあります。ただし、高い推論精度に加えて、リアルタイムパフォーマンスを対象とした3D畳み込みニューラルネットワーク（CNN）を実行することは依然として困難な作業です。その理由は、モデル構造がより複雑であり、モデルの次元が高いと、モバイルデバイスで利用可能な計算/ストレージリソースが圧倒されるためです。自然な方法は、ディープラーニングのウェイト剪定技術に目を向けることかもしれません。ただし、既存の2DCNN重みプルーニング手法を3DCNNに直接一般化することは、高い推論精度を達成しながらモバイル並列処理を十分に活用するには理想的ではありません。このホワイトペーパーでは、3D CNNのモデル圧縮およびモバイルアクセラレーションフレームワークであるRT3Dを提案し、ニューラルネットワークの重みプルーニングとコンパイラコード生成技術をシームレスに統合します。 2つの構造化スパース性スキーム、つまり、モバイルアクセラレーションに適したバニラ構造化スパース性とカーネルグループ構造化（KGS）スパース性を提案して調査します。バニラスパース性はカーネルグループ全体を削除しますが、KGSスパース性はよりきめ細かい構造化されたスパース性であり、デバイス上の完全な並列処理を活用しながら、より高い柔軟性を享受します。提案されたスパース性スキームを実現するために、再重み付けされた正則化プルーニングアルゴリズムを提案します。スパース性による推論時間の高速化は、モデルFLOP（浮動小数点演算）全体の剪定率に近づいています。 RT3Dは、3D CNNをサポートする現在のモバイルフレームワークと比較して、エンドツーエンドの推論時間で最大29.1のスピードアップを示しています。,https://d3i71xaburhd42.cloudfront.net/b2f44d0cd05ccc1db98af5fabf96e0f4ebd86d9c/4-Figure1-1.png
BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search,"['Colin White', 'Willie Neiswanger', 'Yash Savani']",https://arxiv.org/abs/1910.11858,"Neural Architecture Search (NAS) has seen an explosion of research in the past few years, with techniques spanning reinforcement learning, evolutionary search, Gaussian process (GP) Bayesian optimization (BO), and gradient descent. While BO with GPs has seen great success in hyperparameter optimization, there are many challenges applying BO to NAS, such as the requirement of a distance function between neural networks. In this work, we develop a suite of techniques for high-performance BO applied to NAS that allows us to achieve state-of-the-art NAS results. We develop a BO procedure that leverages a novel architecture representation (which we term the path encoding) and a neural network-based predictive uncertainty model on this representation. 
On popular search spaces, we can predict the validation accuracy of a new architecture to within one percent of its true value using only 200 training points. This may be of independent interest beyond NAS. We also show experimentally and theoretically that our method scales far better than existing techniques. We test our algorithm on the NASBench (Ying et al. 2019) and DARTS (Liu et al. 2018) search spaces and show that our algorithm outperforms a variety of NAS methods including regularized evolution, reinforcement learning, BOHB, and DARTS. Our method achieves state-of-the-art performance on the NASBench dataset and is over 100x more efficient than random search. We adhere to the recent NAS research checklist (Lindauer and Hutter 2019) to facilitate NAS research. In particular, our implementation is publicly available and includes all details needed to fully reproduce our results.",ニューラルアーキテクチャ検索（NAS）は、強化学習、進化的検索、ガウス過程（GP）ベイズ最適化（BO）、最急降下法にまたがる手法で、過去数年間で爆発的な研究を行ってきました。 GPを使用したBOはハイパーパラメータの最適化で大きな成功を収めていますが、ニューラルネットワーク間の距離関数の要件など、BOをNASに適用する際には多くの課題があります。この作業では、NASに適用される高性能BOの一連の手法を開発し、最先端のNAS結果を達成できるようにします。新しいアーキテクチャ表現（パスエンコーディングと呼びます）と、この表現に対するニューラルネットワークベースの予測不確実性モデルを活用するBOプロシージャを開発します。人気のある検索スペースでは、わずか200のトレーニングポイントを使用して、新しいアーキテクチャの検証精度を真の値の1％以内に予測できます。これは、NAS以外の独立した関心事かもしれません。また、実験的および理論的に、私たちの方法が既存の手法よりもはるかに優れていることを示しています。 NASBench（Ying etal。2019）およびDARTS（Liu etal。2018）検索スペースでアルゴリズムをテストし、アルゴリズムが正則化進化、強化学習、BOHB、DARTSなどのさまざまなNASメソッドよりも優れていることを示しています。私たちの方法は、NASBenchデータセットで最先端のパフォーマンスを実現し、ランダム検索よりも100倍以上効率的です。 NASの調査を容易にするために、最近のNAS調査チェックリスト（Lindauer and Hutter 2019）を順守しています。特に、私たちの実装は公開されており、結果を完全に再現するために必要なすべての詳細が含まれています。,https://d3i71xaburhd42.cloudfront.net/72b45d35aaa3a8f66b63fa88e9e289e078e5eadd/3-Figure1.1-1.png
SnapMix: Semantically Proportional Mixing for Augmenting Fine-Grained Data,"['Shaoli Huang', 'Xinchao Wang', 'Dacheng Tao']",https://arxiv.org/abs/2012.04846,"Data mixing augmentation has proved effective in training deep models. Recent methods mix labels mainly based on the mixture proportion of image pixels. As the main discriminative information of a fine-grained image usually resides in subtle regions, methods along this line are prone to heavy label noise in fine-grained recognition. We propose in this paper a novel scheme, termed as Semantically Proportional Mixing (SnapMix), which exploits class activation map (CAM) to lessen the label noise in augmenting fine-grained data. SnapMix generates the target label for a mixed image by estimating its intrinsic semantic composition, and allows for asymmetric mixing operations and ensures semantic correspondence between synthetic images and target labels. Experiments show that our method consistently outperforms existing mixed-based approaches on various datasets and under different network depths. Furthermore, by incorporating the mid-level features, the proposed SnapMix achieves top-level performance, demonstrating its potential to serve as a solid baseline for fine-grained recognition. Our code is available at https://github.com/Shaoli-Huang/SnapMix.git.",データ混合の増強は、深いモデルのトレーニングに効果的であることが証明されています。最近の方法は、主に画像ピクセルの混合比率に基づいてラベルを混合します。きめの細かい画像の主な識別情報は通常、微妙な領域に存在するため、この線に沿った方法では、きめの細かい認識でラベルノイズが大きくなる傾向があります。この論文では、Semantically Proportional Mixing（SnapMix）と呼ばれる新しいスキームを提案します。これは、クラスアクティベーションマップ（CAM）を利用して、きめ細かいデータを拡張する際のラベルノイズを低減します。 SnapMixは、固有のセマンティック構成を推定することによって混合画像のターゲットラベルを生成し、非対称の混合操作を可能にし、合成画像とターゲットラベル間のセマンティック対応を保証します。実験によると、私たちの方法は、さまざまなデータセットやさまざまなネットワーク深度で、既存の混合ベースのアプローチよりも一貫して優れています。さらに、中間レベルの機能を組み込むことにより、提案されたSnapMixはトップレベルのパフォーマンスを実現し、きめ細かい認識の確かなベースラインとして機能する可能性を示しています。私たちのコードはhttps://github.com/Shaoli-Huang/SnapMix.gitで入手できます。,https://d3i71xaburhd42.cloudfront.net/c3379bbe58886d8d66c0be777fc7416415617435/2-Figure1-1.png
Clustering Ensemble Meets Low-Rank Tensor Approximation,"['Yuheng Jia', 'Hui Liu', 'Junhui Hou', 'Qingfu Zhang']",https://arxiv.org/abs/2012.08916,"This paper explores the problem of clustering ensemble, which aims to combine multiple base clusterings to produce better performance than that of the individual one. The existing clustering ensemble methods generally construct a co-association matrix, which indicates the pairwise similarity between samples, as the weighted linear combination of the connective matrices from different base clusterings, and the resulting co-association matrix is then adopted as the input of an off-the-shelf clustering algorithm, e.g., spectral clustering. However, the co-association matrix may be dominated by poor base clusterings, resulting in inferior performance. In this paper, we propose a novel low-rank tensor approximation-based method to solve the problem from a global perspective. Specifically, by inspecting whether two samples are clustered to an identical cluster under different base clusterings, we derive a coherent-link matrix, which contains limited but highly reliable relationships between samples. We then stack the coherent-link matrix and the co-association matrix to form a three-dimensional tensor, the low-rankness property of which is further explored to propagate the information of the coherent-link matrix to the co-association matrix, producing a refined co-association matrix. We formulate the proposed method as a convex constrained optimization problem and solve it efficiently. Experimental results over 7 benchmark data sets show that the proposed model achieves a breakthrough in clustering performance, compared with 12 state-of-the-art methods. To the best of our knowledge, this is the first work to explore the potential of low-rank tensor on clustering ensemble, which is fundamentally different from previous approaches.",このホワイトペーパーでは、複数のベースクラスタリングを組み合わせて、個々のクラスタリングよりも優れたパフォーマンスを実現することを目的とした、クラスタリングアンサンブルの問題について説明します。既存のクラスタリングアンサンブル法は、一般に、異なるベースクラスタリングからの結合行列の加重線形結合として、サンプル間のペアワイズ類似性を示す共連想行列を構築し、結果の共連想行列は、次の入力として採用されます。既製のクラスタリングアルゴリズム、例えば、スペクトルクラスタリング。ただし、共関連マトリックスは、不十分なベースクラスタリングによって支配され、パフォーマンスが低下する可能性があります。本論文では、グローバルな視点から問題を解決するための新しい低ランクテンソル近似ベースの方法を提案した。具体的には、2つのサンプルが異なるベースクラスタリングの下で​​同一のクラスターにクラスター化されているかどうかを調べることにより、サンプル間の限定的で信頼性の高い関係を含むコヒーレントリンクマトリックスを導出します。次に、コヒーレントリンク行列とコアアソシエーション行列をスタックして3次元テンソルを形成します。このテンソルの低ランク性をさらに調べて、コヒーレントリンク行列の情報をコアアソシエーション行列に伝播します。洗練された相互関連マトリックス。提案した方法を凸型制約付き最適化問題として定式化し、効率的に解きます。 7つのベンチマークデータセットを超える実験結果は、提案されたモデルが12の最先端の方法と比較してクラスタリングパフォーマンスのブレークスルーを達成することを示しています。私たちの知る限り、これは、以前のアプローチとは根本的に異なる、クラスタリングアンサンブルでの低ランクテンソルの可能性を調査する最初の作業です。,https://d3i71xaburhd42.cloudfront.net/841dfc6985668e78fcc2e44e19788d2ab9c6307e/2-Figure1-1.png
Learning Hybrid Relationships for Person Re-Identification,"['Shuang Liu', 'Wenmin Huang', 'Zhong Zhang']",,,,
Consistent Right-Invariant Fixed-Lag Smoother with Application to Visual Inertial SLAM,"['Jianzhu Huai', 'Yukai Lin', 'Yuan Zhuang', 'Min Shi']",,,,
Robust Spatio-Temporal Purchase Prediction via Deep Meta Learning,"['Huiling Qin', 'Songyu Ke', 'Xiaodu Yang', 'Haoran Xu', 'Xianyuan Zhan', 'Yu Zheng']",,,,
Deep Frequency Principle Towards Understanding Why Deeper Learning Is Faster,"['Zhiqin John Xu', 'Hanxu Zhou']",,,,
Scalable Affinity Propagation for Massive Datasets,['Hiroaki Shiokawa'],,,,
Self-Supervised Attention-Aware Reinforcement Learning,"['Haiping Wu', 'Khimya Khetarpal', 'Doina Precup']",,,,
A Fast Exact Algorithm for the Resource Constrained Shortest Path Problem,"['Saman Ahmadi', 'Guido Tack', 'Daniel Harabor', 'Philip Kilby']",,,,
ePointDA: An End-to-End Simulation-to-Real Domain Adaptation Framework for LiDAR Point Cloud Segmentation,"['Sicheng Zhao', 'Yezhen Wang', 'Bo Li', 'Bichen Wu', 'Yang Gao', 'Pengfei Xu', 'Trevor Darrell', 'Kurt Keutzer']",https://arxiv.org/abs/2009.03456,"Due to its robust and precise distance measurements, LiDAR plays an important role in scene understanding for autonomous driving. Training deep neural networks (DNNs) on LiDAR data requires large-scale point-wise annotations, which are time-consuming and expensive to obtain. Instead, simulation-to-real domain adaptation (SRDA) trains a DNN using unlimited synthetic data with automatically generated labels and transfers the learned model to real scenarios. Existing SRDA methods for LiDAR point cloud segmentation mainly employ a multi-stage pipeline and focus on feature-level alignment. They require prior knowledge of real-world statistics and ignore the pixel-level dropout noise gap and the spatial feature gap between different domains. In this paper, we propose a novel end-to-end framework, named ePointDA, to address the above issues. Specifically, ePointDA consists of three components: self-supervised dropout noise rendering, statistics-invariant and spatially-adaptive feature alignment, and transferable segmentation learning. The joint optimization enables ePointDA to bridge the domain shift at the pixel-level by explicitly rendering dropout noise for synthetic LiDAR and at the feature-level by spatially aligning the features between different domains, without requiring the real-world statistics. Extensive experiments adapting from synthetic GTA-LiDAR to real KITTI and SemanticKITTI demonstrate the superiority of ePointDA for LiDAR point cloud segmentation.",LiDARは、堅牢で正確な距離測定により、自動運転のシーン理解において重要な役割を果たします。 LiDARデータでディープニューラルネットワーク（DNN）をトレーニングするには、大規模なポイントごとの注釈が必要です。これは、取得に時間と費用がかかります。代わりに、シミュレーションから実際のドメインへの適応（SRDA）は、自動生成されたラベルを使用して無制限の合成データを使用してDNNをトレーニングし、学習したモデルを実際のシナリオに転送します。 LiDARポイントクラウドセグメンテーションの既存のSRDAメソッドは、主に多段階パイプラインを採用し、機能レベルの調整に重点を置いています。それらは、実際の統計に関する事前の知識を必要とし、ピクセルレベルのドロップアウトノイズギャップと異なるドメイン間の空間的特徴ギャップを無視します。この論文では、上記の問題に対処するために、ePointDAという名前の新しいエンドツーエンドのフレームワークを提案します。具体的には、ePointDAは、自己教師ありドロップアウトノイズレンダリング、統計的に不変で空間的に適応可能な特徴の配置、および転送可能なセグメンテーション学習の3つのコンポーネントで構成されます。共同最適化により、ePointDAは、実際の統計を必要とせずに、合成LiDARのドロップアウトノイズを明示的にレンダリングすることでピクセルレベルで、異なるドメイン間で機能を空間的に調整することで機能レベルでドメインシフトを橋渡しできます。合成GTA-LiDARから実際のKITTIおよびSemanticKITTIに適応する広範な実験は、LiDARポイントクラウドセグメンテーションに対するePointDAの優位性を示しています。,https://d3i71xaburhd42.cloudfront.net/8c73a599b571c4625cc9239bd8c4f5b6c0d87d8c/2-Figure1-1.png
CompFeat: Comprehensive Feature Aggregation for Video Instance Segmentation,"['Yang Fu', 'Linjie Yang', 'Ding Liu', 'Thomas Huang', 'Humphrey Shi']",https://arxiv.org/abs/2012.03400,"Video instance segmentation is a complex task in which we need to detect, segment, and track each object for any given video. Previous approaches only utilize single-frame features for the detection, segmentation, and tracking of objects and they suffer in the video scenario due to several distinct challenges such as motion blur and drastic appearance change. To eliminate ambiguities introduced by only using single-frame features, we propose a novel comprehensive feature aggregation approach (CompFeat) to refine features at both frame-level and object-level with temporal and spatial context information. The aggregation process is carefully designed with a new attention mechanism which significantly increases the discriminative power of the learned features. We further improve the tracking capability of our model through a siamese design by incorporating both feature similarities and spatial similarities. Experiments conducted on the YouTube-VIS dataset validate the effectiveness of proposed CompFeat. Our code will be available at https://github.com/SHI-Labs/CompFeat-for-Video-Instance-Segmentation.",ビデオインスタンスのセグメンテーションは複雑なタスクであり、特定のビデオの各オブジェクトを検出、セグメント化、追跡する必要があります。以前のアプローチでは、オブジェクトの検出、セグメンテーション、および追跡に単一フレーム機能のみを使用しており、モーションブラーや大幅な外観の変更など、いくつかの明確な課題が原因で、ビデオシナリオで問題が発生します。単一フレームの特徴のみを使用することによってもたらされる曖昧さを排除するために、時間的および空間的コンテキスト情報を使用してフレームレベルとオブジェクトレベルの両方で特徴を洗練する新しい包括的な特徴集約アプローチ（CompFeat）を提案します。集約プロセスは、学習された特徴の識別力を大幅に向上させる新しい注意メカニズムを使用して慎重に設計されています。機能の類似性と空間の類似性の両方を組み込むことにより、シャムデザインを通じてモデルの追跡機能をさらに向上させます。 YouTube-VISデータセットで実施された実験は、提案されたCompFeatの有効性を検証します。私たちのコードはhttps://github.com/SHI-Labs/CompFeat-for-Video-Instance-Segmentationで入手できます。,https://d3i71xaburhd42.cloudfront.net/0742b295a4bb83f3e28990e2f87545819dcc9e1a/1-Figure1-1.png
Flow-Based Generative Models for Learning Manifold to Manifold Mappings,"['Xingjian Zhen', 'Rudrasis Chakraborty', 'Liu Yang', 'Vikas Singh']",https://arxiv.org/abs/2012.10013,"Many measurements or observations in computer vision and machine learning manifest as non-Euclidean data. While recent proposals (like spherical CNN) have extended a number of deep neural network architectures to manifold-valued data, and this has often provided strong improvements in performance, the literature on generative models for manifold data is quite sparse. Partly due to this gap, there are also no modality transfer/translation models for manifold-valued data whereas numerous such methods based on generative models are available for natural images. This paper addresses this gap, motivated by a need in brain imaging – in doing so, we expand the operating range of certain generative models (as well as generative models for modality transfer) from natural images to images with manifold-valued measurements. Our main result is the design of a two-stream version of GLOW (flow-based invertible generative models) that can synthesize information of a field of one type of manifold-valued measurements given another. On the theoretical side, we introduce three kinds of invertible layers for manifold-valued data, which are not only analogous to their functionality in flow-based generative models (e.g., GLOW) but also preserve the key benefits (determinants of the Jacobian are easy to calculate). For experiments, on a large dataset from the Human Connectome Project (HCP), we show promising results where we can reliably and accurately reconstruct brain images of a field of orientation distribution functions (ODF) from diffusion tensor images (DTI), where the latter has a 5× faster acquisition time but at the expense of worse angular resolution.",コンピュータビジョンと機械学習における多くの測定または観察は、非ユークリッドデータとして現れます。最近の提案（球形CNNなど）は、多数のディープニューラルネットワークアーキテクチャをマニフォールド値データに拡張し、これによりパフォーマンスが大幅に向上することがよくありますが、マニフォールドデータの生成モデルに関する文献は非常に少ないです。部分的にこのギャップのために、多様体値データのモダリティ転送/変換モデルもありませんが、生成モデルに基づく多くのそのような方法が自然画像に利用できます。この論文では、脳イメージングの必要性に動機付けられたこのギャップに対処し、特定の生成モデル（およびモダリティ転送の生成モデル）の動作範囲を自然画像から多様体値測定の画像に拡大します。私たちの主な結果は、あるタイプの多様体値測定のフィールドの情報を別のタイプに合成できるGLOW（フローベースの可逆生成モデル）の2ストリームバージョンの設計です。理論的には、多様体値データ用に3種類の可逆層を導入します。これらは、フローベースの生成モデル（GLOWなど）の機能に類似しているだけでなく、主要な利点も保持しています（ヤコビアンの行列式は簡単です）。計算する）。実験では、ヒューマンコネクトームプロジェクト（HCP）の大規模なデータセットで、拡散テンソル画像（DTI）から方向分布関数（ODF）のフィールドの脳画像を確実かつ正確に再構築できる有望な結果を示します。取得時間は5速くなりますが、角度分解能が低下します。,https://d3i71xaburhd42.cloudfront.net/5c5df399a570954be5985c3e38c2544f2bc3a9a1/2-Figure1-1.png
BoW Pooling: A Plug-and-Play Unit for Feature Aggregation of Point Clouds,"['Xiang Zhang', 'Xiao Sun', 'Zhouhui Lian']",,,,
Hierarchical Reinforcement Learning for Integrated Recommendation,"['Ruobing Xie', 'Shaoliang Zhang', 'Rui Wang', 'Feng Xia', 'Leyu Lin']",,,,
Proactive Privacy-Preserving Learning for Retrieval,"['Peng-Fei Zhang', 'Zi Huang', 'Xin-Shun Xu']",,,,
Weakly Supervised Semantic Segmentation for Large-Scale Point Cloud,"['Yachao Zhang', 'Zonghao Li', 'Yuan Xie', 'Yanyun Qu', 'Li Cui-hua', 'Tao Mei']",,,,
Self-Supervised Prototype Representation Learning for Event-Based Corporate Profiling,"['Zixuan Yuan', 'Hao Liu', 'Renjun Hu', 'Denghui Zhang', 'Hui Xiong']",,,,
DeepDT: Learning Geometry from Delaunay Triangulation for Surface Reconstruction,"['Yiming Luo', 'Zhenxing Mi', 'Wenbing Tao']",https://arxiv.org/abs/2101.10353,"In this paper, a novel learning-based network, named DeepDT, is proposed to reconstruct the surface from Delaunay triangulation of point cloud. DeepDT learns to predict inside/outside labels of Delaunay tetrahedrons directly from a point cloud and corresponding Delaunay triangulation. The local geometry features are first extracted from the input point cloud and aggregated into a graph deriving from the Delaunay triangulation. Then a graph filtering is applied on the aggregated features in order to add structural regularization to the label prediction of tetrahedrons. Due to the complicated spatial relations between tetrahedrons and the triangles, it is impossible to directly generate ground truth labels of tetrahedrons from ground truth surface. Therefore, we propose a multilabel supervision strategy which votes for the label of a tetrahedron with labels of sampling locations inside it. The proposed DeepDT can maintain abundant geometry details without generating overly complex surfaces , especially for inner surfaces of open scenes. Meanwhile, the generalization ability and time consumption of the proposed method is acceptable and competitive compared with the state-of-the-art methods. Experiments demonstrate the superior performance of the proposed DeepDT.",この論文では、DeepDTという名前の新しい学習ベースのネットワークを提案して、点群のドロネー三角形分割から表面を再構築します。 DeepDTは、点群と対応するドロネー三角形分割から直接、ドロネー四面体の内側/外側のラベルを予測することを学習します。ローカルジオメトリの特徴は、最初に入力ポイントクラウドから抽出され、ドロネー三角形分割から派生したグラフに集約されます。次に、四面体のラベル予測に構造正則化を追加するために、集約された特徴にグラフフィルタリングが適用されます。四面体と三角形の間の複雑な空間関係のため、グラウンドトゥルースサーフェスからテトラヘドロンのグラウンドトゥルースラベルを直接生成することは不可能です。したがって、サンプリング位置のラベルが内部にある四面体のラベルに投票するマルチラベル監視戦略を提案します。提案されたDeepDTは、特にオープンシーンの内面に対して、過度に複雑な表面を生成することなく、豊富なジオメトリの詳細を維持できます。一方、提案された方法の一般化能力と時間消費は、最先端の方法と比較して許容可能であり、競争力がある。実験は、提案されたDeepDTの優れたパフォーマンスを示しています。,https://d3i71xaburhd42.cloudfront.net/26a22bded2e64a2e95613a744a9f5ad12b082e1e/1-Figure1-1.png
Disentangled Information Bottleneck,"['Ziqi Pan', 'Li Niu', 'Jianfu Zhang', 'Liqing Zhang']",https://arxiv.org/abs/2012.07372,"The information bottleneck (IB) method is a technique for extracting information that is relevant for predicting the target random variable from the source random variable, which is typically implemented by optimizing the IB Lagrangian that balances the compression and prediction terms. However, the IB Lagrangian is hard to optimize, and multiple trials for tuning values of Lagrangian multiplier are required. Moreover, we show that the prediction performance strictly decreases as the compression gets stronger during optimizing the IB Lagrangian. In this paper, we implement the IB method from the perspective of supervised disentangling. Specifically, we introduce Disentangled Information Bottleneck (DisenIB) that is consistent on compressing source maximally without target prediction performance loss (maximum compression). Theoretical and experimental results demonstrate that our method is consistent on maximum compression, and performs well in terms of generalization, robustness to adversarial attack, out-of-distribution detection, and supervised disentangling.",情報ボトルネック（IB）法は、ソース確率変数からターゲット確率変数の予測に関連する情報を抽出する手法です。これは通常、圧縮項と予測項のバランスをとるIBラグランジアンを最適化することによって実装されます。ただし、IBラグランジュは最適化が難しく、ラグランジュ乗数の値を調整するために複数の試行が必要です。さらに、IBラグランジアンの最適化中に圧縮が強くなると、予測パフォーマンスが厳密に低下することを示します。本論文では、教師あり解きほぐしの観点からIB法を実装する。具体的には、ターゲット予測のパフォーマンスを損なうことなくソースを最大限に圧縮すること（最大圧縮）で一貫性のあるDisentangled Information Bottleneck（DisenIB）を紹介します。理論的および実験的結果は、私たちの方法が最大圧縮で一貫しており、一般化、敵対的攻撃に対するロバスト性、分布外検出、および監視された解きほぐしの点でうまく機能することを示しています。,https://d3i71xaburhd42.cloudfront.net/925792be475b1297e75b9193a78b6c063a790799/18-Figure1-1.png
GIF Thumbnails: Attract More Clicks to Your Videos,"['Yi Xu', 'Fan Bai', 'Yingxuan Shi', 'Qiuyu Chen', 'Longwen Gao', 'Kai Tian', 'Shuigeng Zhou', 'Huyang Sun']",,,,
An Improved Upper Bound for SAT,"['Huairui Chu', 'Mingyu Xiao', 'Zhe Zhang']",https://arxiv.org/abs/2007.03829,"We show that the CNF satisfiability problem can be solved $O^*(1.2226^m)$ time, where $m$ is the number of clauses in the formula, improving the known upper bounds $O^*(1.234^m)$ given by Yamamoto 15 years ago and $O^*(1.239^m)$ given by Hirsch 22 years ago. By using an amortized technique and careful case analysis, we successfully avoid the bottlenecks in previous algorithms and get the improvement.",CNF充足可能性問題がO ^（*）（1.2226 ^（m））時間で解けることを示します。ここで、mは式の節の数であり、既知の上限O ^（*）（1.234 ^（m ））15年前に山本から、22年前にヒルシュからO ^（*）（1.239 ^（m））が与えられました。償却手法と慎重なケース分析を使用することで、以前のアルゴリズムのボトルネックを回避し、改善を実現しました。,https://d3i71xaburhd42.cloudfront.net/4c08526c25b3e40d29666af2a641d540a0110e80/2-Table1-1.png
Towards More Practical and Efficient Automatic Dominance Breaking,"['Jimmy H.M. Lee', 'Allen Z. W. Zhong']",,"Dominance breaking is shown to be an effective technique to improve the solving speed of Constraint Optimization Problems (COPs). The paper proposes separate techniques to generalize and make more efficient the nogood generation phase of an automated dominance breaking framework by Lee and Zhong’s. The first contribution is in giving conditions that allow skipping the checking of non-efficiently checkable constraints and yet still produce sufficient useful nogoods, thus opening up possibilities to apply the technique on COPs that were previously impractical. The second contribution identifies and avoids the generation of dominance breaking nogoods that are both logically and propagation redundant. The nogood generation model is strengthened using the notion of Common Assignment Elimination to avoid generation of nogoods that are subsumed by other nogoods, thus reducing the search space substantially. Extensive experimentation confirms the benefits of the new proposals.",ドミナンスブレイクは、制約最適化問題（COP）の解決速度を向上させる効果的な手法であることが示されています。この論文は、LeeとZhongsによる自動化された支配破壊フレームワークの不適切な生成フェーズを一般化し、より効率的にするための個別の手法を提案しています。最初の貢献は、非効率的にチェック可能な制約のチェックをスキップできる条件を与えることですが、それでも十分な有用な不良品を生成するため、以前は実用的ではなかったCOPにこの手法を適用する可能性が広がります。 2番目の貢献は、論理的にも伝播も冗長である優勢を破る不良品の生成を識別して回避します。不良品生成モデルは、他の不良品に含まれる不良品の生成を回避するために、共通割り当て除去の概念を使用して強化されているため、検索スペースが大幅に削減されます。広範な実験により、新しい提案の利点が確認されます。,https://d3i71xaburhd42.cloudfront.net/82a6fc9028ec6c2d27ec1b90e73d7d60bc0547ae/7-Figure1-1.png
Who You Would Like to Share With? A Study of Share Recommendation in Social E-Commerce,"['Houye Ji', 'Junxiong Zhu', 'Xiao Wang', 'Chuan Shi', 'Bai Wang', 'Xiaoye Tan', 'Yanghua Li', 'Shaojian He']",,,,
Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation,"['Shuai Lin', 'Pan Zhou', 'Xiaodan Liang', 'Jianheng Tang', 'Ruihui Zhao', 'Ziliang Chen', 'Liang Lin']",https://arxiv.org/abs/2012.11988,"Human doctors with well-structured medical knowledge can diagnose a disease merely via a few conversations with patients about symptoms. In contrast, existing knowledgegrounded dialogue systems often require a large number of dialogue instances to learn as they fail to capture the correlations between different diseases and neglect the diagnostic experience shared among them. To address this issue, we propose a more natural and practical paradigm, i.e., low-resource medical dialogue generation, which can transfer the diagnostic experience from source diseases to target ones with a handful of data for adaptation. It is capitalized on a commonsense knowledge graph to characterize the prior disease-symptom relations. Besides, we develop a Graph-Evolving Meta-Learning (GEML) framework that learns to evolve the commonsense graph for reasoning disease-symptom correlations in a new disease, which effectively alleviates the needs of a large number of dialogues. More importantly, by dynamically evolving disease-symptom graphs, GEML also well addresses the realworld challenges that the disease-symptom correlations of each disease may vary or evolve along with more diagnostic cases. Extensive experiment results on the CMDD dataset and our newly-collected Chunyu dataset testify the superiority of our approach over state-of-the-art approaches. Besides, our GEML can generate an enriched dialogue-sensitive knowledge graph in an online manner, which could benefit other tasks grounded on knowledge graph.",十分に構造化された医学的知識を持つ人間の医師は、症状について患者と数回会話するだけで病気を診断できます。対照的に、既存の知識に基づいた対話システムは、さまざまな疾患間の相関関係を把握できず、それらの間で共有される診断経験を無視するため、学習するために多数の対話インスタンスを必要とすることがよくあります。この問題に対処するために、より自然で実用的なパラダイム、つまり、診断経験をソース疾患から適応のための少数のデータでターゲット疾患に転送できる低リソースの医療対話生成を提案します。これは、常識的な知識グラフを利用して、以前の病気と症状の関係を特徴づけます。さらに、新しい疾患における疾患と症状の相関関係を推論するための常識的なグラフの進化を学習するグラフ進化メタ学習（GEML）フレームワークを開発します。これにより、多数の対話の必要性が効果的に軽減されます。さらに重要なことに、GEMLは、動的に進化する疾患症状グラフによって、各疾患の疾患症状相関がより多くの診断ケースとともに変化または進化する可能性があるという現実の課題にもうまく対処します。 CMDDデータセットと新しく収集されたChunyuデータセットに関する広範な実験結果は、最先端のアプローチに対する私たちのアプローチの優位性を証明しています。さらに、GEMLは、対話に敏感な豊富な知識グラフをオンラインで生成できます。これは、知識グラフに基づく他のタスクに役立つ可能性があります。,https://d3i71xaburhd42.cloudfront.net/2ad565fb0ce9cda15a9e5ce37b5678ec09b134b9/1-Figure1-1.png
SD-Pose: Semantic Decomposition for Cross-Domain 6D Object Pose Estimation,"['Zhigang Li', 'Yinlin Hu', 'Mathieu Salzmann', 'Xiangyang Ji']",,,,
TDAF: Top-Down Attention Framework for Vision Tasks,"['Bo Pang', 'Yizhuo Li', 'Jiefeng Li', 'Muchen Li', 'Hanwen Cao', 'Cewu Lu']",https://arxiv.org/abs/2012.07248,"Human attention mechanisms often work in a top-down manner, yet it is not well explored in vision research. Here, we propose the Top-Down Attention Framework (TDAF) to capture top-down attentions, which can be easily adopted in most existing models. The designed Recursive Dual-Directional Nested Structure in it forms two sets of orthogonal paths, recursive and structural ones, where bottom-up spatial features and top-down attention features are extracted respectively. Such spatial and attention features are nested deeply, therefore, the proposed framework works in a mixed top-down and bottom-up manner. Empirical evidence shows that our TDAF can capture effective stratified attention information and boost performance. ResNet with TDAF achieves 2.0% improvements on ImageNet. For object detection, the performance is improved by 2.7% AP over FCOS. For pose estimation, TDAF improves the baseline by 1.6%. And for action recognition, the 3D-ResNet adopting TDAF achieves improvements of 1.7% accuracy.",人間の注意メカニズムはトップダウン方式で機能することがよくありますが、視覚研究では十分に検討されていません。ここでは、トップダウンの注意を取り込むためのトップダウン注意フレームワーク（TDAF）を提案します。これは、ほとんどの既存のモデルで簡単に採用できます。その中で設計された再帰的二重方向ネスト構造は、再帰的パスと構造的パスの2セットの直交パスを形成し、ボトムアップの空間的特徴とトップダウンの注意の特徴がそれぞれ抽出されます。このような空間機能と注意機能は深くネストされているため、提案されたフレームワークはトップダウンとボトムアップの混合方式で機能します。経験的証拠は、私たちのTDAFが効果的な層別注意情報を取得してパフォーマンスを向上させることができることを示しています。 TDAFを備えたResNetは2.0を達成します,https://d3i71xaburhd42.cloudfront.net/965571810fcb79fdaaed7329ff57b3720508a241/1-Figure1-1.png
A Spatial Regulated Patch-Wise Approach for Cervical Dysplasia Diagnosis,"['Ying Zhang', 'Yifang Yin', 'Zhenguang Liu', 'Roger Zimmermann']",,,,
Reinforced History Backtracking for Conversational Question Answering,"['Minghui Qiu', 'Xinjing Huang', 'Cen Chen', 'Feng Ji', 'Chen Qu', 'Wei Wei', 'Jun Huang', 'Yin Zhang']",,,,
Compressing Deep Convolutional Neural Networks by Stacking Low-Dimensional Binary Convolution Filters,"['Weichao Lan', 'Liang Lan']",https://arxiv.org/abs/2010.02778,"Deep Convolutional Neural Networks (CNN) have been successfully applied to many real-life problems. However, the huge memory cost of deep CNN models poses a great challenge of deploying them on memory-constrained devices (e.g., mobile phones). One popular way to reduce the memory cost of deep CNN model is to train binary CNN where the weights in convolution filters are either 1 or -1 and therefore each weight can be efficiently stored using a single bit. However, the compression ratio of existing binary CNN models is upper bounded by around 32. To address this limitation, we propose a novel method to compress deep CNN model by stacking low-dimensional binary convolution filters. Our proposed method approximates a standard convolution filter by selecting and stacking filters from a set of low-dimensional binary convolution filters. This set of low-dimensional binary convolution filters is shared across all filters for a given convolution layer. Therefore, our method will achieve much larger compression ratio than binary CNN models. In order to train our proposed model, we have theoretically shown that our proposed model is equivalent to select and stack intermediate feature maps generated by low-dimensional binary filters. Therefore, our proposed model can be efficiently trained using the split-transform-merge strategy. We also provide detailed analysis of the memory and computation cost of our model in model inference. We compared the proposed method with other five popular model compression techniques on two benchmark datasets. Our experimental results have demonstrated that our proposed method achieves much higher compression ratio than existing methods while maintains comparable accuracy.",Deep Convolutional Neural Networks（CNN）は、多くの現実の問題にうまく適用されてきました。ただし、ディープCNNモデルの膨大なメモリコストは、メモリに制約のあるデバイス（携帯電話など）にモデルを展開するという大きな課題をもたらします。ディープCNNモデルのメモリコストを削減する一般的な方法の1つは、畳み込みフィルターの重みが1または-1であるバイナリCNNをトレーニングすることです。したがって、各重みは1ビットを使用して効率的に格納できます。ただし、既存のバイナリCNNモデルの圧縮率の上限は約32です。この制限に対処するために、低次元のバイナリ畳み込みフィルターをスタックすることにより、ディープCNNモデルを圧縮する新しい方法を提案します。提案された方法は、低次元のバイナリ畳み込みフィルターのセットからフィルターを選択して積み重ねることにより、標準の畳み込みフィルターを近似します。この低次元のバイナリ畳み込みフィルターのセットは、特定の畳み込みレイヤーのすべてのフィルターで共有されます。したがって、私たちの方法は、バイナリCNNモデルよりもはるかに大きな圧縮率を実現します。提案されたモデルをトレーニングするために、提案されたモデルが低次元のバイナリフィルターによって生成された中間特徴マップを選択してスタックすることと同等であることを理論的に示しました。したがって、提案されたモデルは、分割-変換-マージ戦略を使用して効率的にトレーニングできます。また、モデル推論におけるモデルのメモリと計算コストの詳細な分析も提供します。提案された方法を、2つのベンチマークデータセットで他の5つの一般的なモデル圧縮手法と比較しました。我々の実験結果は、我々の提案した方法が同等の精度を維持しながら、既存の方法よりもはるかに高い圧縮比を達成することを示した。,https://d3i71xaburhd42.cloudfront.net/bbace99bbe05345c2b2bbe35fdb9007bab398228/2-Figure1-1.png
Model-Agnostic Fits for Understanding Information Seeking Patterns in Humans,"['Soumya Chatterjee', 'Pradeep Shenoy']",https://arxiv.org/abs/2012.04858,"In decision making tasks under uncertainty, humans display characteristic biases in seeking, integrating, and acting upon information relevant to the task. Here, we reexamine data from previous carefully designed experiments, collected at scale, that measured and catalogued these biases in aggregate form. We design deep learning models that replicate these biases in aggregate, while also capturing individual variation in behavior. A key finding of our work is that paucity of data collected from each individual subject can be overcome by sampling large numbers of subjects from the population, while still capturing individual differences. In addition, we can predict human behavior with high accuracy without making any assumptions about task goals, reward structure, or individual biases, thus providing a model-agnostic fit to human behavior in the task. Such an approach can sidestep potential limitations in modeler-specified inductive biases, and has implications for computational modeling of human cognitive function in general, and of human-AI interfaces in particular.",不確実性の下での意思決定タスクでは、人間は、タスクに関連する情報を探し、統合し、それに基づいて行動する際に特徴的なバイアスを示します。ここでは、これらのバイアスを集計形式で測定およびカタログ化した、大規模に収集された以前の慎重に設計された実験からのデータを再検討します。行動の個人差を捉えながら、これらのバイアスを集約して再現する深層学習モデルを設計します。私たちの仕事の重要な発見は、個々の被験者から収集されたデータの不足は、個人差を捉えながら、母集団から多数の被験者をサンプリングすることによって克服できるということです。さらに、タスクの目標、報酬の構造、または個々のバイアスについて何も仮定することなく、人間の行動を高精度で予測できるため、タスクにおける人間の行動にモデルにとらわれない適合を提供します。このようなアプローチは、モデラーが指定した誘導バイアスの潜在的な制限を回避することができ、一般に人間の認知機能、特に人間とAIのインターフェースの計算モデリングに影響を及ぼします。,https://d3i71xaburhd42.cloudfront.net/bf4f673f7e483c35693f989af7d1fd0b4a3c7861/2-Figure1-1.png
Generalising without Forgetting for Lifelong Person Re-Identification,"['Guile Wu', 'Shaogang Gong']",,,,
Proxy Synthesis: Learning with Synthetic Classes for Deep Metric Learning,"['Geonmo Gu', 'Byungsoo Ko', 'Han-Gyu Kim']",,,,
Bi-Classifier Determinacy Maximization for Unsupervised Domain Adaptation,"['Shuang Li', 'Fangrui Lv', 'Binhui Xie', 'Chi Harold Liu', 'Jian Liang', 'Chen Qin']",https://arxiv.org/abs/2012.06995,"Unsupervised domain adaptation challenges the problem of transferring knowledge from a well-labelled source domain to an unlabelled target domain. Recently,adversarial learning with bi-classifier has been proven effective in pushing cross-domain distributions close. Prior approaches typically leverage the disagreement between bi-classifier to learn transferable representations, however, they often neglect the classifier determinacy in the target domain, which could result in a lack of feature discriminability. In this paper, we present a simple yet effective method, namely Bi-Classifier Determinacy Maximization(BCDM), to tackle this problem. Motivated by the observation that target samples cannot always be separated distinctly by the decision boundary, here in the proposed BCDM, we design a novel classifier determinacy disparity (CDD) metric, which formulates classifier discrepancy as the class relevance of distinct target predictions and implicitly introduces constraint on the target feature discriminability. To this end, the BCDM can generate discriminative representations by encouraging target predictive outputs to be consistent and determined, meanwhile, preserve the diversity of predictions in an adversarial manner. Furthermore, the properties of CDD as well as the theoretical guarantees of BCDM's generalization bound are both elaborated. Extensive experiments show that BCDM compares favorably against the existing state-of-the-art domain adaptation methods.",教師なしドメイン適応は、適切にラベル付けされたソースドメインからラベル付けされていないターゲットドメインに知識を転送するという問題に挑戦します。最近、bi-classifierを使用した敵対的学習は、クロスドメイン分布を近づけるのに効果的であることが証明されています。以前のアプローチでは、通常、バイクラシファイア間の不一致を利用して転送可能な表現を学習しますが、ターゲットドメインでのクラシファイアの決定性を無視することが多く、機能の識別性が失われる可能性があります。この論文では、この問題に取り組むための、シンプルでありながら効果的な方法、すなわちBi-Classifier Determinacy Maximization（BCDM）を紹介します。ターゲットサンプルが決定境界によって常に明確に分離できるとは限らないという観察に動機付けられて、ここで提案されたBCDMで、新しい分類器決定性視差（CDD）メトリックを設計します。これは、分類器の不一致を個別のターゲット予測のクラス関連性として定式化し、暗黙的に導入します。ターゲット機能の識別可能性に対する制約。この目的のために、BCDMは、ターゲットの予測出力が一貫して決定されるように促すことにより、識別表現を生成できます。その一方で、敵対的な方法で予測の多様性を維持します。さらに、CDDの特性と、BCDMの一般化限界の理論的保証の両方が詳しく説明されています。広範な実験により、BCDMは既存の最先端のドメイン適応方法と比べて遜色がないことが示されています。,https://d3i71xaburhd42.cloudfront.net/fdb6bbec092061d6d4729e016f3277795170adaf/2-Figure1-1.png
Question-Driven Span Labeling Model for Aspect–Opinion Pair Extraction,"['Lei Gao', 'Yulong Wang', 'Tongcun Liu', 'Jingyu Wang', 'Lei Zhang', 'Jianxin Liao']",,,,
A Primal-Dual Online Algorithm for Online Matching Problem in Dynamic Environments,"['Yu-Hang Zhou', 'Peng Hu', 'Chen Liang', 'Huan Xu', 'Guangda Huzhang', 'Yinfu Feng', 'Qing Da', 'XInshang Wang', 'An-Xiang Zeng']",,,,
Semi-Supervised Knowledge Amalgamation for Sequence Classification,"['Jidapa Thadajarassiri', 'Thomas Hartvigsen', 'Xiangnan Kong', 'Elke Rundensteiner']",,"Sequence classification is essential for domains from medical diagnosis to online advertising. In these settings, data are typically proprietary and annotations are expensive to acquire. Often times, so few annotations are available that training a robust model from scratch is impractical. Recently, knowledge amalgamation (KA) has emerged as a promising strategy for training models without this hard-to-come-by labeled training dataset. To achieve this, KA methods combine the knowledge of multiple pre-trained teacher models (trained on different classification tasks and proprietary datasets) into one student model that becomes an expert on the union of all teachers’ classes. However, we demonstrate that the state-ofthe-art solutions fail in the presence of overconfident teachers, which make confident but incorrect predictions for instances from classes upon which they were not trained. Additionally, to-date no work has explored KA for sequence models. Therefore, we propose and then solve the open problem of semi-supervised KA for sequence classification (SKA). Our SKA approach first learns to estimate how trustworthy each teacher is for a given instance, then rescales the predicted probabilities from all teachers to supervise a student model. Our solution overcomes overconfident teachers through careful use of a very small amount of labeled instances. We demonstrate that this approach beats eight state-of-the-art alternatives on four real-world datasets by on average 15% in accuracy with as little as 2% of training data being annotated.",シーケンス分類は、医療診断からオンライン広告までのドメインに不可欠です。これらの設定では、データは通常独自のものであり、注釈の取得には費用がかかります。多くの場合、利用できるアノテーションが非常に少ないため、堅牢なモデルを最初からトレーニングすることは実用的ではありません。最近、知識の融合（KA）が、この入手困難なラベル付きトレーニングデータセットなしでモデルをトレーニングするための有望な戦略として浮上しています。これを実現するために、KAメソッドは、事前にトレーニングされた複数の教師モデル（さまざまな分類タスクと独自のデータセットでトレーニングされた）の知識を1つの学生モデルに結合し、すべての教師クラスの統合の専門家になります。ただし、自信過剰の教師がいると、最先端のソリューションが失敗することを示します。教師は、トレーニングを受けていないクラスのインスタンスについて、自信を持ってはいるものの誤った予測を行います。さらに、これまでのところ、シーケンスモデルのKAを調査した研究はありません。したがって、シーケンス分類（SKA）の半教師ありKAの未解決の問題を提案して解決します。私たちのSKAアプローチは、最初に各教師が特定のインスタンスに対してどれだけ信頼できるかを推定することを学習し、次にすべての教師から予測された確率を再スケーリングして、学生モデルを監督します。私たちのソリューションは、非常に少量のラベル付きインスタンスを注意深く使用することで、自信過剰な教師を克服します。このアプローチは、4つの実世界のデータセットで8つの最先端の代替案を平均15で上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/0dd0bc246775e667da10a38867dfa4d975c055aa/1-Figure1-1.png
Scalable Verification of Quantized Neural Networks,"['Thomas Henzinger', 'Mathias Lechner', 'Djordje Zikelic']",,,,
Deep Metric Learning with Graph Consistency,"['Binghui Chen', 'Pengyu Li', 'Zhaoyi Yan', 'Biao Wang', 'Lei Zhang']",,,,
Living without Beth and Craig: Definitions and Interpolants in Description Logics with Nominals and Role Inclusions,"['Alessandro Artale', 'Jean Jung', 'Andrea Mazzullo', 'Ana Ozaki', 'Frank Wolter']",https://arxiv.org/abs/2007.02736,"The Craig interpolation property (CIP) states that an interpolant for an implication exists iff it is valid. The projective Beth definability property (PBDP) states that an explicit definition exists iff a formula stating implicit definability is valid. Thus, the CIP and PBDP transform potentially hard existence problems into deduction problems in the underlying logic. Description Logics with nominals and/or role inclusions do not enjoy the CIP nor PBDP, but interpolants and explicit definitions have many potential applications in ontology engineering and ontology-based data management. In this article we show the following: even without Craig and Beth, the existence of interpolants and explicit definitions is decidable in description logics with nominals and/or role inclusions such as ALCO, ALCH and ALCHIO. However, living without Craig and Beth makes this problem harder than deduction: we prove that the existence problems become 2ExpTime-complete, thus one exponential harder than validity. The existence of explicit definitions is 2ExpTime-hard even if one asks for a definition of a nominal using any symbol distinct from that nominal, but it becomes ExpTime-complete if one asks for a definition of a concept name using any symbol distinct from that concept name.",クレイグ補間プロパティ（CIP）は、含意の補間が有効である場合に存在することを示します。射影ベス定義可能性プロパティ（PBDP）は、暗黙的な定義可能性を示す式が有効である場合に、明示的な定義が存在することを示します。したがって、CIPとPBDPは、潜在的に困難な存在の問題を、基礎となるロジックの演繹問題に変換します。説明名義および/または役割の包含を伴う論理は、CIPまたはPBDPを享受しませんが、補間および明示的な定義は、オントロジー工学およびオントロジーベースのデータ管理において多くの潜在的なアプリケーションを持っています。この記事では、次のことを示します。CraigとBethがなくても、ALCO、ALCH、ALCHIOなどの名義および/または役割を含む記述論理では、補間子と明示的な定義の存在を決定できます。ただし、CraigとBethなしで生活すると、この問題は演繹よりも難しくなります。存在の問題が2ExpTime-completeになることを証明します。したがって、有効性よりも指数関数的に1つ難しくなります。明示的な定義の存在は2ExpTimeです-その名義とは異なる記号を使用して名義の定義を要求しても難しいですが、その概念とは異なる記号を使用して概念名の定義を要求するとExpTime-completeになります名前。,
HR-Depth : High Resolution Self-Supervised Monocular Depth Estimation,"['Xiaoyang Lyu', 'Liang Liu', 'Mengmeng Wang', 'Xin Kong', 'Lina Liu', 'Yong Liu', 'Xinxin Chen', 'Yi Yuan']",https://arxiv.org/abs/2012.07356,"Self-supervised learning shows great potential in monoculardepth estimation, using image sequences as the only source ofsupervision. Although people try to use the high-resolutionimage for depth estimation, the accuracy of prediction hasnot been significantly improved. In this work, we find thecore reason comes from the inaccurate depth estimation inlarge gradient regions, making the bilinear interpolation er-ror gradually disappear as the resolution increases. To obtainmore accurate depth estimation in large gradient regions, itis necessary to obtain high-resolution features with spatialand semantic information. Therefore, we present an improvedDepthNet, HR-Depth, with two effective strategies: (1) re-design the skip-connection in DepthNet to get better high-resolution features and (2) propose feature fusion Squeeze-and-Excitation(fSE) module to fuse feature more efficiently.Using Resnet-18 as the encoder, HR-Depth surpasses all pre-vious state-of-the-art(SoTA) methods with the least param-eters at both high and low resolution. Moreover, previousstate-of-the-art methods are based on fairly complex and deepnetworks with a mass of parameters which limits their realapplications. Thus we also construct a lightweight networkwhich uses MobileNetV3 as encoder. Experiments show thatthe lightweight network can perform on par with many largemodels like Monodepth2 at high-resolution with only20%parameters. All codes and models will be available at this https URL.",自己教師あり学習は、画像シーケンスを唯一の教師ありソースとして使用して、単眼深度推定に大きな可能性を示します。深度推定には高解像度の画像を使おうとしていますが、予測の精度は大幅に向上していません。この作業では、主要な理由は、大きな勾配領域での不正確な深度推定に起因し、解像度が上がるにつれて双一次内挿エラーが徐々に消えていくことがわかります。大きな勾配領域でより正確な深度推定を取得するには、空間情報と意味情報を使用して高解像度の特徴を取得する必要があります。したがって、2つの効果的な戦略で改善されたDepthNet、HR-Depthを提示します：（1）より良い高解像度機能を取得するためにDepthNetのスキップ接続を再設計し、（2）機能融合スクイーズアンドエキサイト（fSE）を提案しますエンコーダーとしてResnet-18を使用することで、HR-Depthは、高解像度と低解像度の両方で最小のパラメーターで、これまでのすべての最先端（SoTA）メソッドを上回ります。さらに、以前の最先端の方法は、実際のアプリケーションを制限する大量のパラメータを持つかなり複雑で深いネットワークに基づいています。したがって、MobileNetV3をエンコーダーとして使用する軽量ネットワークも構築します。実験によると、軽量ネットワークは、Monodepth2のような多くの大型モデルと同等の高解像度でわずか20のパフォーマンスを発揮します。,https://d3i71xaburhd42.cloudfront.net/1c7a149cbddff67b48a6c045692fd194b404d4e8/1-Figure1-1.png
Pyramidal Feature Shrinking for Salient Object Detection,"['Mingcan Ma', 'Changqun Xia', 'Jia Li']",,,,
Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network,"['Jiayi Ji', 'Yunpeng Luo', 'Xiaoshuai Sun', 'Fuhai Chen', 'Gen Luo', 'Yongjian Wu', 'Yue Gao', 'Rongrong Ji']",https://arxiv.org/abs/2012.07061,"Transformer-based architectures have shown great success in image captioning, where object regions are encoded and then attended into the vectorial representations to guide the caption decoding. However, such vectorial representations only contain region-level information without considering the global information reflecting the entire image, which fails to expand the capability of complex multi-modal reasoning in image captioning. In this paper, we introduce a Global Enhanced Transformer (termed GET) to enable the extraction of a more comprehensive global representation, and then adaptively guide the decoder to generate high-quality captions. In GET, a Global Enhanced Encoder is designed for the embedding of the global feature, and a Global Adaptive Decoder are designed for the guidance of the caption generation. The former models intra- and inter-layer global representation by taking advantage of the proposed Global Enhanced Attention and a layer-wise fusion module. The latter contains a Global Adaptive Controller that can adaptively fuse the global information into the decoder to guide the caption generation. Extensive experiments on MS COCO dataset demonstrate the superiority of our GET over many state-of-the-arts.",Transformerベースのアーキテクチャは、画像のキャプションで大きな成功を収めています。オブジェクト領域がエンコードされてから、ベクトル表現に参加してキャプションのデコードをガイドします。ただし、このようなベクトル表現には、画像全体を反映するグローバル情報を考慮せずに領域レベルの情報のみが含まれるため、画像のキャプションにおける複雑なマルチモーダル推論の機能を拡張できません。この論文では、より包括的なグローバル表現の抽出を可能にするグローバル拡張トランスフォーマー（GETと呼ばれる）を紹介し、次にデコーダーを適応的にガイドして高品質のキャプションを生成します。 GETでは、グローバル拡張エンコーダーはグローバル機能の埋め込み用に設計されており、グローバルアダプティブデコーダーはキャプション生成のガイダンス用に設計されています。前者は、提案されたGlobal Enhanced Attentionとレイヤーワイズフュージョンモジュールを利用して、レイヤー内およびレイヤー間のグローバル表現をモデル化します。後者には、グローバル情報をデコーダーに適応的に融合してキャプションの生成をガイドできるグローバルアダプティブコントローラーが含まれています。 MS COCOデータセットに関する広範な実験は、多くの最先端技術に対するGETの優位性を示しています。,https://d3i71xaburhd42.cloudfront.net/7217b5d8d0fb753532026cc36b0aaa056960c6f8/1-Figure1-1.png
Enhancing Balanced Graph Edge Partition with Effective Local Search,"['Zhenyu Guo', 'Mingyu Xiao', 'Yi Zhou', 'Dongxiang Zhang', 'Kian-Lee Tan']",https://arxiv.org/abs/2012.09451,"Graph partition is a key component to achieve workload balance and reduce job completion time in parallel graph processing systems. Among the various partition strategies, edge partition has demonstrated more promising performance in power-law graphs than vertex partition and thereby has been more widely adopted as the default partition strategy by existing graph systems. The graph edge partition problem, which is to split the edge set into multiple balanced parts to minimize the total number of copied vertices, has been widely studied from the view of optimization and algorithms. In this paper, we study local search algorithms for this problem to further improve the partition results from existing methods. More specifically, we propose two novel concepts, namely adjustable edges and blocks. Based on these, we develop a greedy heuristic as well as an improved search algorithm utilizing the property of the max-flow model. To evaluate the performance of our algorithms, we first provide adequate theoretical analysis in terms of the approximation quality. We significantly improve the previously known approximation ratio for this problem. Then we conduct extensive experiments on a large number of benchmark datasets and state-of-the-art edge partition strategies. The results show that our proposed local search framework can further improve the quality of graph partition by a wide margin.",グラフパーティションは、並列グラフ処理システムでワークロードのバランスを取り、ジョブの完了時間を短縮するための重要なコンポーネントです。さまざまなパーティション戦略の中で、エッジパーティションは、頂点パーティションよりもべき乗則グラフでより有望なパフォーマンスを示しているため、既存のグラフシステムによってデフォルトのパーティション戦略として広く採用されています。コピーされた頂点の総数を最小化するためにエッジセットを複数の平衡部分に分割することであるグラフエッジ分割問題は、最適化とアルゴリズムの観点から広く研究されてきました。この論文では、既存の方法からの分割結果をさらに改善するために、この問題の局所探索アルゴリズムを研究します。より具体的には、2つの新しい概念、つまり調整可能なエッジとブロックを提案します。これらに基づいて、最大フローモデルの特性を利用して、貪欲なヒューリスティックと改良された検索アルゴリズムを開発します。アルゴリズムのパフォーマンスを評価するために、最初に近似品質の観点から適切な理論的分析を提供します。この問題について、これまでに知られている近似比を大幅に改善します。次に、多数のベンチマークデータセットと最先端のエッジパーティション戦略について広範な実験を行います。結果は、提案されたローカル検索フレームワークがグラフ分割の品質を大幅に改善できることを示しています。,https://d3i71xaburhd42.cloudfront.net/b7db8bb8309d420e1a0321888d209ae2d1481c55/3-Figure1-1.png
A Bayesian Approach for Subset Selection in Contextual Bandits,"['Jialian Li', 'Chao Du', 'Jun Zhu']",,,,
Object Relation Attention for Image Paragraph Captioning,"['Li-Chuan Yang', 'Chih-Yuan Yang', 'Jane Yung-jen Hsu']",,,,
Fair and Truthful Mechanisms for Dichotomous Valuations,"['Moshe Babaioff', 'Tomer Ezra', 'Uriel Feige']",https://arxiv.org/abs/2002.10704,"We consider the problem of allocating a set on indivisible items to players with private preferences in an efficient and fair way. We focus on valuations that have dichotomous marginals, in which the added value of any item to a set is either 0 or 1, and aim to design truthful allocation mechanisms (without money) that maximize welfare and are fair. For the case that players have submodular valuations with dichotomous marginals, we design such a deterministic truthful allocation mechanism. The allocation output by our mechanism is Lorenz dominating, and consequently satisfies many desired fairness properties, such as being envy-free up to any item (EFX), and maximizing the Nash Social Welfare (NSW). We then show that our mechanism with random priorities is envy-free ex-ante, while having all the above properties ex-post. Furthermore, we present several impossibility results precluding similar results for the larger class of XOS valuations. 
To gauge the robustness of our positive results, we also study $\epsilon$-dichotomous valuations, in which the added value of any item to a set is either non-positive, or in the range $[1, 1 + \epsilon]$. We show several impossibility results in this setting, and also a positive result: for players that have additive $\epsilon$-dichotomous valuations with sufficiently small $\epsilon$, we design a randomized truthful mechanism with strong ex-post guarantees. For $\rho = \frac{1}{1 + \epsilon}$, the allocations that it produces generate at least a $\rho$-fraction of the maximum welfare, and enjoy $\rho$-approximations for various fairness properties, such as being envy-free up to one item (EF1), and giving each player at least her maximin share.",分割できないアイテムのセットを、個人的な好みを持つプレーヤーに効率的かつ公正な方法で割り当てる問題を検討します。セットへのアイテムの付加価値が0または1である、二分された周辺分布を持つ評価に焦点を当て、福祉を最大化し、公平である真実の割り当てメカニズム（お金なし）を設計することを目指しています。プレーヤーが二分周辺分布を持つ劣モジュラ評価を持っている場合、私たちはそのような決定論的な真実の割り当てメカニズムを設計します。私たちのメカニズムによって出力される割り当ては、ローレンツが支配的であり、その結果、あらゆるアイテム（EFX）まで羨望のない、ナッシュ社会福祉（NSW）の最大化など、多くの望ましい公平性の特性を満たします。次に、上記のすべてのプロパティを事後的に保持しながら、ランダムな優先順位を持つメカニズムが事前に羨望のないものであることを示します。さらに、より大きなクラスのXOS評価について同様の結果を排除するいくつかの不可能な結果を​​提示します。肯定的な結果の頑健性を評価するために、セットへのアイテムの付加価値が肯定的でないか、[1、1 +]の範囲にある二分評価も調べます。この設定でいくつかの不可能な結果と肯定的な結果を示します。十分に小さい加法二分評価を持つプレーヤーのために、強力な事後保証を備えたランダム化された真実のメカニズムを設計します。 $ \ rho = \ frac {1} {1 + \ epsilon} $の場合、それが生成する割り当ては、最大福祉の少なくとも一部を生成し、羨望のないようにするなど、さまざまな公平性プロパティの近似を享受します。 1つのアイテム（EF1）に追加し、各プレーヤーに少なくとも最大のシェアを与えます。,
Enhancing Parameter-Free Frank Wolfe with an Extra Subproblem,"['Bingcong Li', 'Lingda Wang', 'Georgios B. Giannakis', 'Zhizhen Zhao']",https://arxiv.org/abs/2012.05284,"Aiming at convex optimization under structural constraints, this work introduces and analyzes a variant of the Frank Wolfe (FW) algorithm termed ExtraFW. The distinct feature of ExtraFW is the pair of gradients leveraged per iteration, thanks to which the decision variable is updated in a prediction-correction (PC) format. Relying on no problem dependent parameters in the step sizes, the convergence rate of ExtraFW for general convex problems is shown to be ${\cal O}(\frac{1}{k})$, which is optimal in the sense of matching the lower bound on the number of solved FW subproblems. However, the merit of ExtraFW is its faster rate ${\cal O}\big(\frac{1}{k^2} \big)$ on a class of machine learning problems. Compared with other parameter-free FW variants that have faster rates on the same problems, ExtraFW has improved rates and fine-grained analysis thanks to its PC update. Numerical tests on binary classification with different sparsity-promoting constraints demonstrate that the empirical performance of ExtraFW is significantly better than FW, and even faster than Nesterov's accelerated gradient on certain datasets. For matrix completion, ExtraFW enjoys smaller optimality gap, and lower rank than FW.",構造的制約の下での凸最適化を目指して、この作業では、ExtraFWと呼ばれるフランクウルフ（FW）アルゴリズムの変形を紹介して分析します。 ExtraFWの際立った特徴は、反復ごとに活用される勾配のペアです。これにより、決定変数が予測修正（PC）形式で更新されます。ステップサイズの問題に依存しないパラメーターに依存すると、一般的な凸問題に対するExtraFWの収束率は$ {\ cal O}（\ frac {1} {k}）$であることが示され、これはマッチングの意味で最適です。解決されたFWサブ問題の数の下限。ただし、ExtraFWのメリットは、機械学習の問題のクラスでのレートが速い$ {\ cal O} \ big（\ frac {1} {k ^ 2} \ big）$です。同じ問題でより速いレートを持つ他のパラメーターフリーのFWバリアントと比較して、ExtraFWは、PCの更新のおかげで、レートときめ細かい分析を改善しました。さまざまなスパース性を促進する制約を使用した二項分類の数値テストは、ExtraFWの経験的パフォーマンスがFWよりも大幅に優れており、特定のデータセットでNesterovs加速勾配よりもさらに高速であることを示しています。行列補完の場合、ExtraFWは最適性のギャップが小さく、FWよりもランクが低くなります。,https://d3i71xaburhd42.cloudfront.net/fde3ce79d4866297a27600ccb22321f80537cb1d/8-Figure1-1.png
Contrastive Clustering,"['Yunfan Li', 'Peng Hu', 'Zitao Liu', 'Dezhong Peng', 'Joey Tianyi Zhou', 'Xi Peng']",,,,
Dec-SGTS: Decentralized Sub-Goal Tree Search for Multi-Agent Coordination,"['Minglong Li', 'Zhongxuan Cai', 'Wenjing Yang', 'Lixia Wu', 'Yinghui Xu', 'Ji Wang']",,,,
GoT: a Growing Tree Model for Clustering Ensemble,"['Feijiang Li', 'Yuhua Qian', 'Jieting Wang']",,,,
Searching for Alignment in Face Recognition,"['Xiaqing Xu', 'Qiang Meng', 'Yunxiao Qin', 'Jianzhu Guo', 'Chenxu Zhao', 'Feng Zhou', 'Zhen Lei']",,,,
Attentive Neural Point Processes for Event Forecasting,['Yulong Gu'],,,,
GRASP: Generic Framework for Health Status Representation Learning Based on Incorporating Knowledge from Similar Patients,"['Chaohe Zhang', 'Xin Gao', 'Liantao Ma', 'Yasha Wang', 'Jiangtao Wang', 'Wen Tang']",,,,
Efficient Object-Level Visual Context Modeling for Multimodal Machine Translation: Masking Irrelevant Objects Helps Grounding,"['Dexin Wang', 'Deyi Xiong']",,,,
Class-Incremental Instance Segmentation via Multi-Teacher Networks,"['Yanan Gu', 'Cheng Deng', 'Kun Wei']",,,,
Dynamically Grown Generative Adversarial Networks,"['Lanlan Liu', 'Yuting Zhang', 'Jia Deng', 'Stefano Soatto']",,,,
Few-Shot Font Generation with Localized Style Representations and Factorization,"['Song Park', 'Sanghyuk Chun', 'Junbum Cha', 'Bado Lee', 'Hyunjung Shim']",,,,
ACT: An Attentive Convolutional Transformer for Efficient Text Classification,"['Pengfei Li', 'Peixiang Zhong', 'Kezhi Mao', 'Dongzhe Wang', 'Xuefeng Yang', 'Yunfeng Liu', 'Jianxiong (Terry) Yin', 'Simon See']",,,,
Generalized Zero-Shot Learning via Disentangled Representation,"['Xiangyu Li', 'Zhe Xu', 'Kun Wei', 'Cheng Deng']",,,,
Revisiting Co-Occurring Directions: Sharper Analysis and Efficient Algorithm for Sparse Matrices,"['Luo Luo', 'Cheng Chen', 'Guangzeng Xie', 'Haishan Ye']",,,,
Narrative Plan Generation with Self-Supervised Learning,"['Mihai Polceanu', 'Julie Porteous', 'Alan Lindsay', 'Marc Cavazza']",,,,
Action Candidate Based Clipped Double Q-Learning for Discrete and Continuous Action Tasks,"['Haobo Jiang', 'Jin Xie', 'Jian Yang']",,,,
Self-Supervised Sketch-to-Image Synthesis,"['Bingchen A Liu', 'Yizhe Zhu', 'Kunpeng Song', 'Ahmed Elgammal']",https://arxiv.org/abs/2012.09290,"Imagining a colored realistic image from an arbitrarily drawn sketch is one of the human capabilities that we eager machines to mimic. Unlike previous methods that either requires the sketch-image pairs or utilize low-quantity detected edges as sketches, we study the exemplar-based sketch-to-image (s2i) synthesis task in a self-supervised learning manner, eliminating the necessity of the paired sketch data. To this end, we first propose an unsupervised method to efficiently synthesize line-sketches for general RGB-only datasets. With the synthetic paired-data, we then present a self-supervised Auto-Encoder (AE) to decouple the content/style features from sketches and RGB-images, and synthesize images that are both content-faithful to the sketches and style-consistent to the RGB-images. While prior works employ either the cycle-consistence loss or dedicated attentional modules to enforce the content/style fidelity, we show AE's superior performance with pure self-supervisions. To further improve the synthesis quality in high resolution, we also leverage an adversarial network to refine the details of synthetic images. Extensive experiments on 1024*1024 resolution demonstrate a new state-of-art-art performance of the proposed model on CelebA-HQ and Wiki-Art datasets. Moreover, with the proposed sketch generator, the model shows a promising performance on style mixing and style transfer, which require synthesized images to be both style-consistent and semantically meaningful. Our code is available on this https URL, and please visit this https URL for an online demo of our model.",任意に描かれたスケッチから色付きのリアルな画像を想像することは、私たちが機械に模倣したいと思っている人間の能力の1つです。スケッチと画像のペアを必要とする、またはスケッチとして少量の検出されたエッジを利用する以前の方法とは異なり、私たちは自己教師あり学習方法で模範ベースのスケッチから画像（s2i）合成タスクを研究し、ペアのスケッチデータ。この目的のために、最初に、一般的なRGBのみのデータセットのラインスケッチを効率的に合成するための教師なし方法を提案します。次に、合成ペアデータを使用して、自己監視型オートエンコーダー（AE）を提示し、コンテンツ/スタイルの特徴をスケッチやRGB画像から切り離し、スケッチにコンテンツに忠実でスタイルに一貫性のある画像を合成します。 RGB画像に。以前の作品では、コンテンツ/スタイルの忠実度を強化するためにサイクル整合性の喪失または専用の注意モジュールのいずれかを採用していますが、純粋な自己監視でAEの優れたパフォーマンスを示しています。高解像度での合成品質をさらに向上させるために、敵対的ネットワークを活用して合成画像の詳細を改善します。 1024 * 1024解像度での広範な実験は、CelebA-HQおよびWiki-Artデータセットで提案されたモデルの新しい最先端のパフォーマンスを示しています。さらに、提案されたスケッチジェネレータを使用すると、モデルはスタイルの混合とスタイルの転送で有望なパフォーマンスを示します。これには、合成された画像がスタイルの一貫性と意味的に意味のあるものである必要があります。コードはこのhttpsURLで入手できます。モデルのオンラインデモについては、このhttpsURLにアクセスしてください。,https://d3i71xaburhd42.cloudfront.net/e5956dc1c3e93a37d80aeb908b8a7e76c2185856/2-Figure1-1.png
The LOB Recreation Model: Predicting the Limit Order Book from TAQ History Using an Ordinary Differential Equation Recurrent Neural Network,"['Zijian Shi', 'Yu Chen', 'John Cartlidge']",,,,
TIME: Text and Image Mutual-Translation Adversarial Networks,"['Bingchen A Liu', 'Kunpeng Song', 'Yizhe Zhu', 'Gerard de Melo', 'Ahmed Elgammal']",https://arxiv.org/abs/2005.13192,"Focusing on text-to-image (T2I) generation, we propose Text and Image Mutual-Translation Adversarial Networks (TIME), a lightweight but effective model that jointly learns a T2I generator $G$ and an image captioning discriminator $D$ under the Generative Adversarial Network framework. While previous methods tackle the T2I problem as a uni-directional task and use pre-trained language models to enforce the image-text consistency, TIME requires neither extra modules nor pre-training. We show that the performance of $G$ can be boosted substantially by training it jointly with $D$ as a language model. Specifically, we adopt Transformers to model the cross-modal connections between the image features and word embeddings, and design a hinged and annealing conditional loss that dynamically balances the adversarial learning. In our experiments, TIME establishes the new state-of-the-art Inception Score of 4.88 on the CUB dataset, and shows competitive performance on MS-COCO on both text-to-image and image captioning tasks.",テキストから画像（T2I）の生成に焦点を当て、生成的敵対的ネットワークフレームワークの下でT2IジェネレーターGと画像キャプション弁別子Dを共同で学習する軽量で効果的なモデルであるテキストと画像の相互翻訳敵対的ネットワーク（TIME）を提案します。 。以前の方法では、T2Iの問題に一方向のタスクとして取り組み、事前にトレーニングされた言語モデルを使用して画像とテキストの一貫性を強化しましたが、TIMEでは追加のモジュールも事前トレーニングも必要ありません。言語モデルとしてDと共同でトレーニングすることにより、Gのパフォーマンスを大幅に向上できることを示します。具体的には、トランスフォーマーを採用して、画像の特徴と単語の埋め込みの間のクロスモーダル接続をモデル化し、敵対的な学習のバランスを動的にとるヒンジ付きのアニーリング条件付き損失を設計します。私たちの実験では、TIMEはCUBデータセットで4.88の新しい最先端のインセプションスコアを確立し、テキストから画像へのタスクと画像のキャプションタスクの両方でMS-COCOの競争力のあるパフォーマンスを示しています。,https://d3i71xaburhd42.cloudfront.net/343178bf426aacc051a8ea547c4189579635ab09/2-Figure1-1.png
DIBS: Diversity Inducing Information Bottleneck in Model Ensembles,"['Samarth Sinha', 'Homanga Bharadhwaj', 'Anirudh Goyal', 'Hugo Larochelle', 'Animesh Garg', 'Florian Shkurti']",,"Although deep learning models have achieved state-of-the-art performance on a number of vision tasks, generalization over high dimensional multi-modal data, and reliable predictive uncertainty estimation are still active areas of research. Bayesian approaches including Bayesian Neural Nets (BNNs) do not scale well to modern computer vision tasks, as they are difficult to train, and have poor generalization under dataset-shift. This motivates the need for effective ensembles which can generalize and give reliable uncertainty estimates. In this paper, we target the problem of generating effective ensembles of neural networks by encouraging diversity in prediction. We explicitly optimize a diversity inducing adversarial loss for learning the stochastic latent variables and thereby obtain diversity in the output predictions necessary for modeling multi-modal data. We evaluate our method on benchmark datasets: MNIST, CIFAR100, TinyImageNet and MIT Places 2, and compared to the most competitive baselines show significant improvements in classification accuracy, under a shift in the data distribution and in out-of-distribution detection. Code will be released in this url this https URL",ディープラーニングモデルは、多くのビジョンタスクで最先端のパフォーマンスを実現していますが、高次元のマルチモーダルデータの一般化、および信頼性の高い予測不確実性の推定は、依然として活発な研究分野です。ベイジアンニューラルネット（BNN）を含むベイジアンアプローチは、トレーニングが難しく、データセットシフト下での一般化が不十分であるため、最新のコンピュータービジョンタスクにうまく対応できません。これは、一般化して信頼できる不確実性の推定値を与えることができる効果的なアンサンブルの必要性を動機付けます。この論文では、予測の多様性を促進することにより、ニューラルネットワークの効果的なアンサンブルを生成する問題を対象としています。確率的潜在変数を学習するための敵対的損失を誘発する多様性を明示的に最適化し、それによってマルチモーダルデータのモデリングに必要な出力予測の多様性を取得します。ベンチマークデータセット（MNIST、CIFAR100、TinyImageNet、MIT Places 2）でメソッドを評価し、最も競合するベースラインと比較して、データ分布の変化と分布外の検出において、分類精度が大幅に向上していることを示しています。コードはこのURLでリリースされますこのhttpsURL,https://d3i71xaburhd42.cloudfront.net/99fbd94538d9568a04196e055d286ffae32cf58f/3-Figure1-1.png
Simple or Complex? Learning to Predict Readability of Bengali Texts,"['Susmoy Chakraborty', 'Mir Tafseer Nayeem', 'Wasi U Ahmad']",https://arxiv.org/abs/2012.07701,"Determining the readability of a text is the first step to its simplification. In this paper, we present a readability analysis tool capable of analyzing text written in the Bengali language to provide in-depth information on its readability and complexity. Despite being the 7th most spoken language in the world with 230 million native speakers, Bengali suffers from a lack of fundamental resources for natural language processing. Readability related research of the Bengali language so far can be considered to be narrow and sometimes faulty due to the lack of resources. Therefore, we correctly adopt document-level readability formulas traditionally used for U.S. based education system to the Bengali language with a proper age-to-age comparison. Due to the unavailability of large-scale human-annotated corpora, we further divide the document-level task into sentence-level and experiment with neural architectures, which will serve as a baseline for the future works of Bengali readability prediction. During the process, we present several human-annotated corpora and dictionaries such as a document-level dataset comprising 618 documents with 12 different grade levels, a large-scale sentence-level dataset comprising more than 96K sentences with simple and complex labels, a consonant conjunct count algorithm and a corpus of 341 words to validate the effectiveness of the algorithm, a list of 3,396 easy words, and an updated pronunciation dictionary with more than 67K words. These resources can be useful for several other tasks of this low-resource language. We make our Code & Dataset publicly available at this https URL} for reproduciblity.","テキストの読みやすさを判断することは、その単純化への第一歩です。この論文では、ベンガル語で書かれたテキストを分析して、その読みやすさと複雑さに関する詳細な情報を提供できる読みやすさ分析ツールを紹介します。ベンガル語は、2億3000万人のネイティブスピーカーがいる世界で7番目に話されている言語であるにもかかわらず、自然言語処理のための基本的なリソースの不足に苦しんでいます。これまでのベンガル語の読みやすさに関する研究は、リソースが不足しているために狭く、時には欠陥があると見なすことができます。したがって、米国を拠点とする教育システムで伝統的に使用されているドキュメントレベルの読みやすさの公式をベンガル語に正しく採用し、適切な年齢と年齢を比較します。大規模な人間の注釈付きコーパスが利用できないため、ドキュメントレベルのタスクを文レベルにさらに分割し、ベンガル語の読みやすさ予測の将来の作業のベースラインとして機能するニューラルアーキテクチャを実験します。その過程で、人間が注釈を付けたコーパスと辞書をいくつか紹介します。たとえば、12の異なるグレードレベルの618のドキュメントで構成されるドキュメントレベルのデータセット、単純なラベルと複雑なラベルのある96Kを超える文で構成される大規模なセンテンスレベルのデータセット、子孫などです。結合カウントアルゴリズムと、アルゴリズムの有効性を検証するための341ワードのコーパス、3,396の簡単なワードのリスト、および67Kワードを超える更新された発音辞書。これらのリソースは、この低リソース言語の他のいくつかのタスクに役立ちます。コードとデータセットは、再現性のためにこのhttpsURL}で公開されています。",https://d3i71xaburhd42.cloudfront.net/0174d608bd44ad7148e1c44612f8f31cfd9f3c42/1-Figure1-1.png
Type-Augmented Relation Prediction in Knowledge Graphs,"['Zijun Cui', 'Pavan Kapanipathi', 'Kartik Talamadupula', 'Tian Gao', 'Qiang Ji']",https://arxiv.org/abs/2009.07938,"Knowledge graphs (KGs) are of great importance to many real world applications, but they generally suffer from incomplete information in the form of missing relations between entities. Knowledge graph completion (also known as relation prediction) is the task of inferring missing facts given existing ones. Most of the existing work is proposed by maximizing the likelihood of observed instance-level triples. Not much attention, however, is paid to the ontological information, such as type information of entities and relations. In this work, we propose a type-augmented relation prediction (TaRP) method, where we apply both the type information and instance-level information for relation prediction. In particular, type information and instance-level information are encoded as prior probabilities and likelihoods of relations respectively, and are combined by following Bayes' rule. Our proposed TaRP method achieves significantly better performance than state-of-the-art methods on three benchmark datasets: FB15K, YAGO26K-906, and DB111K-174. In addition, we show that TaRP achieves significantly improved data efficiency. More importantly, the type information extracted from a specific dataset can generalize well to other datasets through the proposed TaRP model.",知識グラフ（KG）は、多くの実際のアプリケーションにとって非常に重要ですが、一般に、エンティティ間の関係が欠落しているという形で情報が不完全であるという問題があります。知識グラフの完成（関係予測とも呼ばれます）は、既存の事実が与えられた場合に欠落している事実を推測するタスクです。既存の作業のほとんどは、観測されたインスタンスレベルのトリプルの可能性を最大化することによって提案されます。ただし、エンティティのタイプ情報や関係などのオントロジー情報にはあまり注意が払われていません。この作業では、タイプ情報とインスタンスレベルの情報の両方を関係予測に適用する、タイプ拡張関係予測（TaRP）メソッドを提案します。特に、タイプ情報とインスタンスレベルの情報は、それぞれ事前確率と関係の可能性としてエンコードされ、ベイズの規則に従って結合されます。提案されたTaRPメソッドは、FB15K、YAGO26K-906、およびDB111K-174の3つのベンチマークデータセットで、最先端のメソッドよりも大幅に優れたパフォーマンスを実現します。さらに、TaRPが大幅に改善されたデータ効率を達成することを示します。さらに重要なことに、特定のデータセットから抽出されたタイプ情報は、提案されたTaRPモデルを通じて他のデータセットにうまく一般化できます。,https://d3i71xaburhd42.cloudfront.net/b1800cca5431984e4e704f315d96fd712d171ea4/1-Figure1-1.png
Forming Better Stable Solutions in Group Formation Games Inspired by Internet Exchange Points (IXPs),"['Elliot Anshelevich', 'Wennan Zhu']",https://arxiv.org/abs/2008.12235,"We study a coordination game motivated by the formation of Internet Exchange Points (IXPs), in which agents choose which facilities to join. Joining the same facility as other agents you communicate with has benefits, but different facilities have different costs for each agent. Thus, the players wish to join the same facilities as their ""friends"", but this is balanced by them not wanting to pay the cost of joining a facility. We first show that the Price of Stability ($PoS$) of this game is at most 2, and more generally there always exists an $\alpha$-approximate equilibrium with cost at most $\frac{2}{\alpha}$ of optimum. We then focus on how better stable solutions can be formed. If we allow agents to pay their neighbors to prevent them from deviating (i.e., a player $i$ voluntarily pays another player $j$ so that $j$ joins the same facility), then we provide a payment scheme which stabilizes the solution with minimum social cost $s^*$, i.e. PoS is 1. In our main technical result, we consider how much a central coordinator would have to pay the players in order to form good stable solutions. Let $\Delta$ denote the total amount of payments needed to be paid to the players in order to stabilize $s^*$, i.e., these are payments that a player would lose if they changed their strategy from the one in $s^*$. We prove that there is a tradeoff between $\Delta$ and the Price of Stability: $\frac{\Delta}{cost(s^*)} \le 1 - \frac{2}{5} PoS$. Thus when there are no good stable solutions, only a small amount of extra payment is needed to stabilize $s^*$; and when good stable solutions already exist (i.e., $PoS$ is small), then we should be happy with those solutions instead. Finally, we consider the computational complexity of finding the optimum solution $s^*$, and design a polynomial time $O(\log n)$ approximation algorithm for this problem.",私たちは、エージェントが参加する施設を選択するインターネットエクスチェンジポイント（IXP）の形成を動機とする協調ゲームを研究しています。通信する他のエージェントと同じ施設に参加することには利点がありますが、施設が異なればエージェントごとにコストも異なります。したがって、プレイヤーは「友達」と同じ施設に参加したいのですが、施設に参加するための費用を払いたくないというバランスが取れています。最初に、このゲームの安定性の価格（PoS）が最大2であることを示します。より一般的には、コストが最大$ \ frac {2} {\ alpha} $の最適な近似平衡が常に存在します。次に、より安定したソリューションを形成する方法に焦点を当てます。エージェントが隣人に支払いをして逸脱を防ぐことを許可する場合（つまり、プレーヤーiが別のプレーヤーjに自発的に支払い、jが同じ施設に参加する）、最小の社会的費用s ^（でソリューションを安定させる支払いスキームを提供します） *）、つまりPoSは1です。私たちの主な技術的結果では、優れた安定したソリューションを形成するために、中央コーディネーターがプレーヤーに支払う必要のある金額を考慮しています。 s ^（*）を安定させるためにプレイヤーに支払う必要のある支払いの合計額を示します。つまり、これらは、プレイヤーがs ^（*）の戦略から戦略を変更した場合に失う支払いです。と安定性の価格の間にはトレードオフがあることを証明します：$ \ frac {\ Delta} {cost（s ^ *）} \ le 1- \ frac {2} {5} PoS $。したがって、適切な安定したソリューションがない場合、s ^（*）を安定させるために必要な追加の支払いはわずかです。そして、優れた安定したソリューションがすでに存在する場合（つまり、PoSが小さい場合）、代わりにそれらのソリューションに満足する必要があります。最後に、最適解s ^（*）を見つける計算の複雑さを考慮し、この問題の多項式時間O（log n）近似アルゴリズムを設計します。,https://d3i71xaburhd42.cloudfront.net/cd5631e12fc741998addfd35e2ee637b27d03bc8/3-Figure1-1.png
Learning of Structurally Unambiguous Probabilistic Grammars,"['Dolav Nitay', 'Dana Fisman', 'Michal Ziv-Ukelson']",https://arxiv.org/abs/2011.07472,"The problem of identifying a probabilistic context free grammar has two aspects: the first is determining the grammar's topology (the rules of the grammar) and the second is estimating probabilistic weights for each rule. Given the hardness results for learning context-free grammars in general, and probabilistic grammars in particular, most of the literature has concentrated on the second problem. In this work we address the first problem. We restrict attention to structurally unambiguous weighted context-free grammars (SUWCFG) and provide a query learning algorithm for structurally unambiguous probabilistic context-free grammars (SUPCFG). We show that SUWCFG can be represented using co-linear multiplicity tree automata (CMTA), and provide a polynomial learning algorithm that learns CMTAs. We show that the learned CMTA can be converted into a probabilistic grammar, thus providing a complete algorithm for learning a structurally unambiguous probabilistic context free grammar (both the grammar topology and the probabilistic weights) using structured membership queries and structured equivalence queries. We demonstrate the usefulness of our algorithm in learning PCFGs over genomic data.",確率的文脈自由文法を識別する問題には2つの側面があります。1つは文法トポロジー（文法の規則）を決定することであり、もう1つは各規則の確率的重みを推定することです。一般に文脈自由文法、特に確率文法を学習するための硬さの結果を考えると、ほとんどの文献は2番目の問題に集中しています。この作業では、最初の問題に対処します。構造的に明確な重み付き文脈自由文法（SUWCFG）への注意を制限し、構造的に明確な確率的文脈自由文法（SUPCFG）のクエリ学習アルゴリズムを提供します。 SUWCFGは、共線形多重度ツリーオートマトン（CMTA）を使用して表現できることを示し、CMTAを学習する多項式学習アルゴリズムを提供します。学習したCMTAを確率文法に変換できることを示します。これにより、構造化メンバーシップクエリと構造化等価クエリを使用して、構造的に明確な確率文脈自由文法（文法トポロジと確率的重みの両方）を学習するための完全なアルゴリズムが提供されます。ゲノムデータを介してPCFGを学習する際のアルゴリズムの有用性を示します。,https://d3i71xaburhd42.cloudfront.net/5f32c39de3f36834994d1eab701c791f04b8aabf/3-Figure2-1.png
Automatic Generation of Flexible Plans via Diverse Temporal Planning,"['Yotam Amitai', 'Ayal Taitler', 'Erez Karpas']",,"Robots operating in the real world must deal with uncertainty, be it due to working with humans who are unpredictable, or simply because they must operate in a dynamic environment. Ignoring the uncertainty could be dangerous, while accounting for all possible outcomes, as in contingent planning, is often computationally infeasible. One possibility, which lies between ignoring the uncertainty completely and addressing it completely is to use flexible plans with choice, formulated as Temporal Planning Networks (TPNs). This approach has been successfully demonstrated to work in human-robot teaming using the Pike executive, an online executive that unifies intent recognition and plan adaptation. However, one of the main challenges to using Pike is the need to manually specify the TPN. In this paper, we address this challenge by describing a technique for automatically synthesizing a TPN which covers multiple possible executions for a given temporal planning problem specified in PDDL 2.1. Our approach starts by using a diverse planner to generate multiple plans, and then merges them into a single TPN. As there were no available diverse planners for temporal planning, we first show how to adapt existing diverse planning based on top-k planning to the temporal setting. We then show how to merge the diverse plans into a single TPN using constraint optimization. Finally, an empirical evaluation on a set of IPC benchmarks shows that our approach scales well, and generates TPNs which can generalize the set of plans they are",現実の世界で動作するロボットは、予測不可能な人間との作業によるものであれ、単に動的な環境で動作する必要があるためであれ、不確実性に対処する必要があります。不確実性を無視することは危険である可能性がありますが、条件付き計画の場合のように、考えられるすべての結果を考慮することは、多くの場合、計算上実行不可能です。不確実性を完全に無視することとそれに完全に対処することの間にある1つの可能性は、時間的計画ネットワーク（TPN）として策定された柔軟な計画を選択して使用することです。このアプローチは、意図の認識と計画の適応を統合するオンラインエグゼクティブであるPikeエグゼクティブを使用して、人間とロボットのチーム化で機能することが実証されています。ただし、Pikeを使用する際の主な課題の1つは、TPNを手動で指定する必要があることです。このホワイトペーパーでは、PDDL 2.1で指定された特定の時間計画問題に対して可能な複数の実行をカバーする、TPNを自動的に合成する手法を説明することでこの課題に対処します。私たちのアプローチは、多様なプランナーを使用して複数のプランを生成することから始まり、次にそれらを単一のTPNにマージします。時間的計画に利用できる多様なプランナーがなかったため、最初に、トップK計画に基づく既存の多様な計画を時間的設定に適応させる方法を示します。次に、制約最適化を使用して、さまざまな計画を単一のTPNにマージする方法を示します。最後に、一連のIPCベンチマークの実証的評価は、私たちのアプローチが適切に拡張され、一連の計画を一般化できるTPNを生成することを示しています。,https://d3i71xaburhd42.cloudfront.net/c2a54fe5cff534bfde1e0e4980cce9776b3c84dc/3-Figure1-1.png
Physarum Powered Differentiable Linear Programming Layers and Applications,"['Zihang Meng', 'Sathya Ravi', 'Vikas Singh']",https://arxiv.org/abs/2004.14539,"Consider a learning algorithm, which involves an internal call to an optimization routine such as a generalized eigenvalue problem, a cone programming problem or even sorting. Integrating such a method as layers within a trainable deep network in a numerically stable way is not simple -- for instance, only recently, strategies have emerged for eigendecomposition and differentiable sorting. We propose an efficient and differentiable solver for general linear programming problems which can be used in a plug and play manner within deep neural networks as a layer. Our development is inspired by a fascinating but not widely used link between dynamics of slime mold (physarum) and mathematical optimization schemes such as steepest descent. We describe our development and demonstrate the use of our solver in a video object segmentation task and meta-learning for few-shot learning. We review the relevant known results and provide a technical analysis describing its applicability for our use cases. Our solver performs comparably with a customized projected gradient descent method on the first task and outperforms the very recently proposed differentiable CVXPY solver on the second task. Experiments show that our solver converges quickly without the need for a feasible initial point. Interestingly, our scheme is easy to implement and can easily serve as layers whenever a learning procedure needs a fast approximate solution to a LP, within a larger network.",一般化された固有値問題、錐計画問題、さらにはソートなどの最適化ルーチンへの内部呼び出しを含む学習アルゴリズムについて考えてみます。トレーニング可能なディープネットワーク内のレイヤーなどの方法を数値的に安定した方法で統合することは簡単ではありません。たとえば、最近になって、固有分解と微分可能な並べ替えの戦略が登場しました。ディープニューラルネットワーク内でレイヤーとしてプラグアンドプレイ方式で使用できる、一般的な線形計画問題の効率的で微分可能なソルバーを提案します。私たちの開発は、粘菌（フィサラム）のダイナミクスと最急降下法などの数学的最適化スキームとの間の魅力的ではあるが広く使用されていないリンクに触発されています。開発について説明し、ビデオオブジェクトセグメンテーションタスクでのソルバーの使用と、数ショット学習のためのメタ学習を示します。関連する既知の結果を確認し、ユースケースへの適用性を説明するテクニカル分析を提供します。私たちのソルバーは、最初のタスクでカスタマイズされた投影勾配降下法と同等のパフォーマンスを発揮し、2番目のタスクで最近提案された微分可能なCVXPYソルバーよりも優れています。実験によると、ソルバーは実行可能な初期点を必要とせずにすばやく収束します。興味深いことに、私たちのスキームは実装が簡単で、学習手順がより大きなネットワーク内でLPの高速近似ソリューションを必要とするときはいつでも、レイヤーとして簡単に機能できます。,https://d3i71xaburhd42.cloudfront.net/4dc0005f92af861d024746ae37f448203a743d81/6-Figure1-1.png
Neural Sentence Ordering Based on Constraint Graphs,"['Yutao Zhu', 'Kun Zhou', 'Jian-Yun Nie', 'Shengchao Liu', 'Zhicheng Dou']",https://arxiv.org/abs/2101.11178,"Sentence ordering aims at arranging a list of sentences in the correct order. Based on the observation that sentence order at different distances may rely on different types of information, we devise a new approach based on multi-granular orders between sentences. These orders form multiple constraint graphs, which are then encoded by Graph Isomorphism Networks and fused into sentence representations. Finally, sentence order is determined using the order-enhanced sentence representations. Our experiments on five benchmark datasets show that our method outperforms all the existing baselines significantly, achieving a new state-of-the-art performance. The results demonstrate the advantage of considering multiple types of order information and using graph neural networks to integrate sentence content and order information for the task. Our code is available at https://github.com/ DaoD/ConstraintGraph4NSO.",文の順序付けは、文のリストを正しい順序で配置することを目的としています。異なる距離での文の順序は異なるタイプの情報に依存する可能性があるという観察に基づいて、文間のマルチグラニュラー順序に基づく新しいアプローチを考案します。これらの順序は複数の制約グラフを形成し、グラフ同型ネットワークによってエンコードされて、文の表現に融合されます。最後に、文の順序は、順序が強化された文の表現を使用して決定されます。 5つのベンチマークデータセットでの実験は、私たちの方法が既存のすべてのベースラインを大幅に上回り、新しい最先端のパフォーマンスを達成していることを示しています。結果は、複数のタイプの注文情報を検討し、グラフニューラルネットワークを使用してタスクの文の内容と注文情報を統合することの利点を示しています。私たちのコードはhttps://github.com/DaoD/ConstraintGraph4NSOで入手できます。,https://d3i71xaburhd42.cloudfront.net/607b61b6b64bec4f97e9e22bc7c670696da9bf91/4-Figure1-1.png
Federated Multi-Armed Bandits,"['Chengshuai Shi', 'Cong Shen']",https://arxiv.org/abs/2101.12204,"Federated multi-armed bandits (FMAB) is a new bandit paradigm that parallels the federated learning (FL) framework in supervised learning. It is inspired by practical applications in cognitive radio and recommender systems, and enjoys features that are analogous to FL. This paper proposes a general framework of FMAB and then studies two specific federated bandit models. We first study the approximate model where the heterogeneous local models are random realizations of the global model from an unknown distribution. This model introduces a new uncertainty of client sampling, as the global model may not be reliably learned even if the finite local models are perfectly known. Furthermore, this uncertainty cannot be quantified a priori without knowledge of the suboptimality gap. We solve the approximate model by proposing Federated Double UCB (Fed2-UCB), which constructs a novel “double UCB” principle accounting for uncertainties from both arm and client sampling. We show that gradually admitting new clients is critical in achieving an O(log(T )) regret while explicitly considering the communication cost. The exact model, where the global bandit model is the exact average of heterogeneous local models, is then studied as a special case. We show that, somewhat surprisingly, the order-optimal regret can be achieved independent of the number of clients with a careful choice of the update periodicity. Experiments using both synthetic and real-world datasets corroborate the theoretical analysis and demonstrate the effectiveness and efficiency of the proposed algorithms.",連合型多腕バンディット（FMAB）は、教師あり学習における連合学習（FL）フレームワークに対応する新しいバンディットパラダイムです。コグニティブ無線およびレコメンダーシステムの実用的なアプリケーションに触発され、FLに類似した機能を楽しんでいます。この論文では、FMABの一般的なフレームワークを提案し、2つの特定の連合バンディットモデルを研究します。最初に、異種ローカルモデルが未知の分布からのグローバルモデルのランダムな実現である近似モデルを研究します。このモデルは、有限のローカルモデルが完全にわかっている場合でも、グローバルモデルが確実に学習されない可能性があるため、クライアントサンプリングの新しい不確実性をもたらします。さらに、この不確実性は、準最適性のギャップに関する知識がなければ、事前に定量化することはできません。アームとクライアントの両方のサンプリングからの不確実性を説明する新しいダブルUCB原理を構築する、フェデレーションダブルUCB（Fed2-UCB）を提案することにより、近似モデルを解決します。通信コストを明示的に考慮しながら、O（log（T））後悔を達成するには、新しいクライアントを徐々に受け入れることが重要であることを示します。次に、グローバルバンディットモデルが異種ローカルモデルの正確な平均である正確なモデルが、特別な場合として研究されます。やや意外なことに、更新の周期を慎重に選択することで、クライアントの数に関係なく、順序が最適な後悔を実現できることを示しています。合成データセットと実世界のデータセットの両方を使用した実験は、理論的分析を裏付け、提案されたアルゴリズムの有効性と効率を実証します。,https://d3i71xaburhd42.cloudfront.net/19531ac63010c70607e2ea7d6c2f2d282d7a0eb8/2-Figure1-1.png
Encoder-Decoder Based Unified Semantic Role Labeling with Label-Aware Syntax,"['Hao Fei', 'Fei Li', 'Bobo Li', 'Donghong Ji']",,,,
Uncertainty Quantification in CNN through the Bootstrap of Convex Neural Networks,"['Hongfei Du', 'Emre Barut', 'Fang Jin']",,,,
Temporal Relational Modeling with Self-Supervision for Action Segmentation,"['Dong Wang', 'Di Hu', 'Xingjian Li', 'Dejing Dou']",https://arxiv.org/abs/2012.07508,"Temporal relational modeling in video is essential for human action understanding, such as action recognition and action segmentation. Although Graph Convolution Networks (GCNs) have shown promising advantages in relation reasoning on many tasks, it is still a challenge to apply graph convolution networks on long video sequences effectively. The main reason is that large number of nodes (i.e., video frames) makes GCNs hard to capture and model temporal relations in videos. To tackle this problem, in this paper, we introduce an effective GCN module, Dilated Temporal Graph Reasoning Module (DTGRM), designed to model temporal relations and dependencies between video frames at various time spans. In particular, we capture and model temporal relations via constructing multi-level dilated temporal graphs where the nodes represent frames from different moments in video. Moreover, to enhance temporal reasoning ability of the proposed model, an auxiliary self-supervised task is proposed to encourage the dilated temporal graph reasoning module to find and correct wrong temporal relations in videos. Our DTGRM model outperforms state-of-the-art action segmentation models on three challenging datasets: 50Salads, Georgia Tech Egocentric Activities (GTEA), and the Breakfast dataset. The code is available at this https URL.",ビデオでの時間的リレーショナルモデリングは、行動認識や行動セグメンテーションなどの人間の行動を理解するために不可欠です。グラフ畳み込みネットワーク（GCN）は、多くのタスクの関係推論において有望な利点を示していますが、長いビデオシーケンスにグラフ畳み込みネットワークを効果的に適用することは依然として課題です。主な理由は、ノード（つまり、ビデオフレーム）の数が多いと、GCNがビデオの時間的関係をキャプチャしてモデル化するのが困難になるためです。この問題に取り組むために、この論文では、さまざまな時間間隔でのビデオフレーム間の時間的関係と依存関係をモデル化するように設計された効果的なGCNモジュールである拡張時間グラフ推論モジュール（DTGRM）を紹介します。特に、ノードがビデオのさまざまな瞬間からのフレームを表すマルチレベルの拡張時間グラフを作成することにより、時間関係をキャプチャしてモデル化します。さらに、提案されたモデルの時間的推論能力を強化するために、補助的な自己監視タスクが提案され、拡張された時間的グラフ推論モジュールがビデオ内の誤った時間的関係を見つけて修正することを奨励する。私たちのDTGRMモデルは、50Salads、Georgia Tech Egocentric Activities（GTEA）、Breakfastデータセットの3つの挑戦的なデータセットで最先端のアクションセグメンテーションモデルよりも優れています。コードはこのhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/b20ccb5e53bcc5e76d05d173149d3926bec952fd/3-Figure1-1.png
Differentially Private and Communication Efficient Collaborative Learning,"['Jiahao Ding', 'Guannan Liang', 'Jinbo Bi', 'Miao Pan']",,,,
Debiasing Evaluations That Are Biased by Evaluations,"['Jingyan Wang', 'Ivan Stelmakh', 'Yuting Wei', 'Nihar Shah']",,,,
Contrastive Adversarial Learning for Person Independent Facial Emotion Recognition,"['Daeha Kim', 'Byung Cheol Song']",,,,
Self-Supervised Pre-Training and Contrastive Representation Learning for Multiple-Choice Video QA,"['Seonhoon Kim', 'Seohyeong Jeong', 'Eunbyul Kim', 'Inho Kang', 'Nojun Kwak']",https://arxiv.org/abs/2009.08043,"Video Question Answering (Video QA) requires fine-grained understanding of both video and language modalities to answer the given questions. In this paper, we propose novel training schemes for multiple-choice video question answering with a self-supervised pre-training stage and a supervised contrastive learning in the main stage as an auxiliary learning. In the self-supervised pre-training stage, we transform the original problem format of predicting the correct answer into the one that predicts the relevant question to provide a model with broader contextual inputs without any further dataset or annotation. For contrastive learning in the main stage, we add a masking noise to the input corresponding to the ground-truth answer, and consider the original input of the ground-truth answer as a positive sample, while treating the rest as negative samples. By mapping the positive sample closer to the masked input, we show that the model performance is improved. We further employ locally aligned attention to focus more effectively on the video frames that are particularly relevant to the given corresponding subtitle sentences. We evaluate our proposed model on highly competitive benchmark datasets related to multiple-choice videoQA: TVQA, TVQA+, and DramaQA. Experimental results show that our model achieves state-of-the-art performance on all datasets. We also validate our approaches through further analyses.",ビデオ質問応答（ビデオQA）では、特定の質問に回答するために、ビデオと言語の両方のモダリティをきめ細かく理解する必要があります。本論文では、補助学習として、自己監視事前訓練段階と主段階での教師あり対照学習を用いた多肢選択式ビデオ質問応答のための新しい訓練スキームを提案した。自己教師あり事前トレーニング段階では、正解を予測する元の問題形式を、関連する質問を予測する形式に変換して、データセットや注釈を追加せずに、モデルに幅広いコンテキスト入力を提供します。メインステージでの対照学習では、グラウンドトゥルース回答に対応する入力にマスキングノイズを追加し、グラウンドトゥルース回答の元の入力を正のサンプルと見なし、残りを負のサンプルとして扱います。正のサンプルをマスクされた入力の近くにマッピングすることにより、モデルのパフォーマンスが向上することを示します。さらに、特定の対応する字幕文に特に関連するビデオフレームにより効果的に焦点を合わせるために、ローカルに調整された注意を採用しています。多肢選択式のvideoQAに関連する競争の激しいベンチマークデータセット（TVQA、TVQA +、およびDramaQA）で、提案されたモデルを評価します。実験結果は、私たちのモデルがすべてのデータセットで最先端のパフォーマンスを達成していることを示しています。また、さらなる分析を通じてアプローチを検証します。,https://d3i71xaburhd42.cloudfront.net/40e086bd10391913afb53ac2093a25ae550ba0e4/1-Figure1-1.png
MVFNet: Multi-View Fusion Network for Efficient Video Recognition,"['Wenhao Wu', 'Dongliang He', 'Tianwei Lin', 'Fu Li', 'Chuang Gan', 'Errui Ding']",https://arxiv.org/abs/2012.06977,"Conventionally, spatiotemporal modeling network and its complexity are the two most concentrated research topics in video action recognition. Existing state-of-the-art methods have achieved excellent accuracy regardless of the complexity meanwhile efficient spatiotemporal modeling solutions are slightly inferior in performance. In this paper, we attempt to acquire both efficiency and effectiveness simultaneously. First of all, besides traditionally treating H x W x T video frames as space-time signal (viewing from the Height-Width spatial plane), we propose to also model video from the other two Height-Time and Width-Time planes, to capture the dynamics of video thoroughly. Secondly, our model is designed based on 2D CNN backbones and model complexity is well kept in mind by design. Specifically, we introduce a novel multi-view fusion (MVF) module to exploit video dynamics using separable convolution for efficiency. It is a plug-and-play module and can be inserted into off-the-shelf 2D CNNs to form a simple yet effective model called MVFNet. Moreover, MVFNet can be thought of as a generalized video modeling framework and it can specialize to be existing methods such as C2D, SlowOnly, and TSM under different settings. Extensive experiments are conducted on popular benchmarks (i.e., Something-Something V1 & V2, Kinetics, UCF-101, and HMDB-51) to show its superiority. The proposed MVFNet can achieve state-of-the-art performance with 2D CNN's complexity.",従来、時空間モデリングネットワークとその複雑さは、ビデオアクション認識における2つの最も集中した研究トピックです。既存の最先端の方法は、複雑さに関係なく優れた精度を達成していますが、効率的な時空間モデリングソリューションはパフォーマンスがわずかに劣っています。この論文では、効率と有効性の両方を同時に獲得することを試みます。まず、従来のH x W x Tビデオフレームを時空間信号（高さ-幅空間平面からの表示）として扱うことに加えて、他の2つの高さ-時間平面と幅-時間平面からのビデオもモデル化することを提案します。ビデオのダイナミクスを徹底的にキャプチャします。次に、モデルは2D CNNバックボーンに基づいて設計されており、モデルの複雑さは設計によって十分に考慮されています。具体的には、効率のために分離可能な畳み込みを使用してビデオダイナミクスを活用するための新しいマルチビューフュージョン（MVF）モジュールを紹介します。これはプラグアンドプレイモジュールであり、既成の2D CNNに挿入して、MVFNetと呼ばれるシンプルで効果的なモデルを形成できます。さらに、MVFNetは、一般化されたビデオモデリングフレームワークと考えることができ、さまざまな設定でのC2D、SlowOnly、TSMなどの既存のメソッドに特化することができます。その優位性を示すために、人気のあるベンチマーク（つまり、Something-Something V1＆V2、Kinetics、UCF-101、およびHMDB-51）で広範な実験が行われます。提案されたMVFNetは、2DCNNの複雑さで最先端のパフォーマンスを実現できます。,https://d3i71xaburhd42.cloudfront.net/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a/1-Figure1-1.png
Robust Knowledge Transfer via Hybrid Forward on the Teacher-Student Model,"['Liangchen Song', 'Jialian Wu', 'Ming Yang', 'Qian Zhang', 'Yuan Li', 'Junsong Yuan']",,"When adopting deep neural networks for a new vision task, a common practice is to start with fine-tuning some offthe-shelf well-trained network models from the community. Since a new task may require training a different network architecture with new domain data, taking advantage of off-theshelf models is not trivial and generally requires considerable try-and-error and parameter tuning. In this paper, we denote a well-trained model as a teacher network and a model for the new task as a student network. We aim to ease the efforts of transferring knowledge from the teacher to the student network, robust to the gaps between their network architectures, domain data, and task definitions. Specifically, we propose a hybrid forward scheme in training the teacher-student models, alternately updating layer weights of the student model. The key merit of our hybrid forward scheme is on the dynamical balance between the knowledge transfer loss and task specific loss in training. We demonstrate the effectiveness of our method on a variety of tasks, e.g, model compression, segmentation, and detection, under a variety of knowledge transfer settings.",新しいビジョンタスクにディープニューラルネットワークを採用する場合、一般的な方法は、コミュニティからの既製の十分に訓練されたネットワークモデルを微調整することから始めることです。新しいタスクでは、新しいドメインデータを使用して別のネットワークアーキテクチャをトレーニングする必要がある場合があるため、既製のモデルを利用することは簡単ではなく、通常、かなりの試行錯誤とパラメータの調整が必要です。この論文では、よく訓練されたモデルを教師ネットワークと呼び、新しいタスクのモデルを学生ネットワークと呼びます。私たちは、教師から生徒のネットワークに知識を転送する作業を容易にし、ネットワークアーキテクチャ、ドメインデータ、およびタスク定義の間のギャップに対応することを目指しています。具体的には、教師と生徒のモデルをトレーニングし、生徒のモデルのレイヤーの重みを交互に更新するハイブリッドフォワードスキームを提案します。ハイブリッドフォワードスキームの主なメリットは、トレーニングにおける知識の伝達の損失とタスク固有の損失の間の動的なバランスにあります。さまざまな知識伝達設定の下で、モデルの圧縮、セグメンテーション、検出など、さまざまなタスクでのメソッドの有効性を示します。,https://d3i71xaburhd42.cloudfront.net/e67acfc16e7adca719d568a14a3d8f6f14d8a25f/1-Figure1-1.png
RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning,"['Peihao Chen', 'Deng Huang', 'Dongliang He', 'Xiang Long', 'Runhao Zeng', 'Shilei Wen', 'Mingkui Tan', 'Chuang Gan']",https://arxiv.org/abs/2011.07949,"We study unsupervised video representation learning that seeks to learn both motion and appearance features from unlabeled video only, which can be reused for downstream tasks such as action recognition. This task, however, is extremely challenging due to 1) the highly complex spatial-temporal information in videos; and 2) the lack of labeled data for training. Unlike the representation learning for static images, it is difficult to construct a suitable self-supervised task to well model both motion and appearance features. More recently, several attempts have been made to learn video representation through video playback speed prediction. However, it is non-trivial to obtain precise speed labels for the videos. More critically, the learnt models may tend to focus on motion pattern and thus may not learn appearance features well. In this paper, we observe that the relative playback speed is more consistent with motion pattern, and thus provide more effective and stable supervision for representation learning. Therefore, we propose a new way to perceive the playback speed and exploit the relative speed between two video clips as labels. In this way, we are able to well perceive speed and learn better motion features. Moreover, to ensure the learning of appearance features, we further propose an appearance-focused task, where we enforce the model to perceive the appearance difference between two video clips. We show that optimizing the two tasks jointly consistently improves the performance on two downstream tasks, namely action recognition and video retrieval. Remarkably, for action recognition on UCF101 dataset, we achieve 93.7% accuracy without the use of labeled data for pre-training, which outperforms the ImageNet supervised pre-trained model.",ラベルのないビデオのみから動きと外観の両方の特徴を学習しようとする教師なしビデオ表現学習を研究します。これは、アクション認識などのダウンストリームタスクに再利用できます。ただし、このタスクは、1）ビデオ内の非常に複雑な時空間情報のために非常に困難です。 2）トレーニング用のラベル付きデータの欠如。静止画像の表現学習とは異なり、動きと外観の両方の特徴を適切にモデル化するための適切な自己教師ありタスクを構築することは困難です。最近では、ビデオ再生速度予測を通じてビデオ表現を学習するためのいくつかの試みが行われています。ただし、ビデオの正確な速度ラベルを取得することは簡単ではありません。さらに重要なことに、学習したモデルはモーションパターンに焦点を合わせる傾向があるため、外観の特徴をうまく学習できない可能性があります。この論文では、相対的な再生速度がモーションパターンとより一致していることを観察し、したがって、表現学習のためのより効果的で安定した監視を提供します。したがって、再生速度を認識し、2つのビデオクリップ間の相対速度をラベルとして活用する新しい方法を提案します。このようにして、速度をよく認識し、より良いモーション機能を学習することができます。さらに、外観の特徴を確実に学習するために、外観に焦点を当てたタスクをさらに提案します。このタスクでは、2つのビデオクリップ間の外観の違いを認識するようにモデルを強制します。 2つのタスクを共同で最適化すると、2つのダウンストリームタスク、つまりアクション認識とビデオ検索のパフォーマンスが一貫して向上することを示します。注目すべきことに、UCF101データセットでの行動認識については、93.7を達成しています,https://d3i71xaburhd42.cloudfront.net/2336388131b3cb41eb44e927aeac10a1dabbedad/1-Figure1-1.png
Anticipating Future Relations via Graph Growing for Action Prediction,"['Xinxiao Wu', 'Jianwei Zhao', 'Ruiqi Wang']",,,,
TaLNet: Voice Reconstruction from Tongue and Lip Articulation with Transfer Learning from Text-to-Speech Synthesis,"['Jing-Xuan Zhang', 'Korin Richmond', 'Zhen-Hua Ling', 'Lirong Dai']",,,,
Unified Tensor Framework for Incomplete Multi-View Clustering and Missing-View Inferring,"['Jie Wen', 'Zheng Zhang', 'Zhao Zhang', 'Lei Zhu', 'Lunke Fei', 'Bob Zhang', 'Yong Xu']",,,,
Spatial-Temporal Causal Inference for Partial Image-to-Video Adaptation,"['Jin Chen', 'Xinxiao Wu', 'Yao Hu', 'Jiebo Luo']",,,,
Similarity Reasoning and Filtration for Image-Text Matching,"['Haiwen Diao', 'Ying Zhang', 'Huchuan Lu', 'Lin Ma']",https://arxiv.org/abs/2101.01368,"Image-text matching plays a critical role in bridging the vision and language, and great progress has been made by exploiting the global alignment between image and sentence, or local alignments between regions and words. However, how to make the most of these alignments to infer more accurate matching scores is still underexplored. In this paper, we propose a novel Similarity Graph Reasoning and Attention Filtration (SGRAF) network for image-text matching. Specifically, the vector-based similarity representations are firstly learned to characterize the local and global alignments in a more comprehensive manner, and then the Similarity Graph Reasoning (SGR) module relying on one graph convolutional neural network is introduced to infer relationaware similarities with both the local and global alignments. The Similarity Attention Filtration (SAF) module is further developed to integrate these alignments effectively by selectively attending on the significant and representative alignments and meanwhile casting aside the interferences of nonmeaningful alignments. We demonstrate the superiority of the proposed method with achieving state-of-the-art performances on the Flickr30K and MSCOCO datasets, and the good interpretability of SGR and SAF modules with extensive qualitative experiments and analyses. Introduction Image-text matching refers to measuring the visual-semantic similarity between image and text, which is becoming increasingly significant for various vision-and-language tasks, such as cross-modal retrieval (Wang et al. 2020), image captioning (Anderson et al. 2018), text-to-image synthesis (Xu et al. 2018), and multimodal neural machine translation (Toyama et al. 2017). Although great progress has been made in recent years, image-text matching remains a challenging problem due to complex matching patterns and large semantic discrepancies between image and text. To accurately establish the association between the visual and textual observations, a large proportion of methods (Liu et al. 2017; Nam, Ha, and Kim 2017; Lee et al. 2018; Song and Soleymani 2019; Wang et al. 2019c; Li et al. 2019; Wang et al. 2020) utilize deep neural networks to firstly encode image and text into compact representations, and then *Corresponding author Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. water in splashes child A SGR Global&Local Alignments",画像とテキストのマッチングは、ビジョンと言語の橋渡しに重要な役割を果たし、画像と文の間のグローバルな配置、または地域と単語の間のローカルな配置を活用することで大きな進歩が見られました。ただし、これらのアラインメントを最大限に活用して、より正確なマッチングスコアを推測する方法はまだ検討されていません。この論文では、画像とテキストのマッチングのための新しい類似性グラフ推論と注意フィルタリング（SGRAF）ネットワークを提案します。具体的には、ベクトルベースの類似性表現を最初に学習して、ローカルおよびグローバルのアラインメントをより包括的な方法で特徴付けます。次に、1つのグラフ畳み込みニューラルネットワークに依存する類似性グラフ推論（SGR）モジュールを導入して、両方との関係認識類似性を推測します。ローカルおよびグローバルアラインメント。類似性アテンションフィルトレーション（SAF）モジュールは、重要で代表的なアラインメントに選択的に参加し、意味のないアラインメントの干渉を排除することにより、これらのアラインメントを効果的に統合するためにさらに開発されています。 Flickr30KおよびMSCOCOデータセットで最先端のパフォーマンスを実現することで、提案された方法の優位性と、広範な定性的実験および分析によるSGRおよびSAFモジュールの優れた解釈可能性を示します。はじめに画像とテキストのマッチングとは、画像とテキストの視覚的意味的類似性を測定することを指します。これは、クロスモーダル検索（Wang etal。2020）、画像キャプション（Anderson）など、さまざまな視覚と言語のタスクでますます重要になっています。 et al.2018）、テキストから画像への合成（Xu et al.2018）、およびマルチモーダルニューラル機械翻訳（Toyama et al.2017）。近年大きな進歩が見られましたが、画像とテキストのマッチングは、複雑なマッチングパターンと、画像とテキストの間の大きな意味の不一致のために、依然として困難な問題です。視覚的観察とテキスト的観察の間の関連を正確に確立するために、大部分の方法（Liu et al.2017; Nam、Ha、and Kim 2017; Lee et al.2018; Song and Soleymani 2019; Wang et al.2019c; Li etal。2019; Wang etal。2020）は、ディープニューラルネットワークを利用して、最初に画像とテキストをコンパクトな表現にエンコードし、次に*対応する著者Copyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。全著作権所有。水しぶきの子の水ASGR Global＆Local Alignments,https://d3i71xaburhd42.cloudfront.net/6d864a6659e2c503cd6d28d05593f0603b9a48bd/1-Figure1-1.png
BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation,"['Haisheng Su', 'Weihao Gan', 'Wei Wu', 'Yu Qiao', 'Junjie Yan']",https://arxiv.org/abs/2009.07641,"Generating human action proposals in untrimmed videos is an important yet challenging task with wide applications. Current methods often suffer from the noisy boundary locations and the inferior quality of confidence scores used for proposal retrieving. In this paper, we present BSN++, a new framework which exploits complementary boundary regressor and relation modeling for temporal proposal generation. First, we propose a novel boundary regressor based on the complementary characteristics of both starting and ending boundary classifiers. Specifically, we utilize the U-shaped architecture with nested skip connections to capture rich contexts and introduce bi-directional boundary matching mechanism to improve boundary precision. Second, to account for the proposal-proposal relations ignored in previous methods, we devise a proposal relation block to which includes two self-attention modules from the aspects of position and channel. Furthermore, we find that there inevitably exists data imbalanced problems in the positive/negative proposals and temporal durations, which harm the model performance on tail distributions. To relieve this issue, we introduce the scale-balanced re-sampling strategy. Extensive experiments are conducted on two popular benchmarks: ActivityNet-1.3 and THUMOS14, which demonstrate that BSN++ achieves the state-of-the-art performance.",トリミングされていないビデオで人間の行動の提案を生成することは、幅広いアプリケーションで重要でありながら挑戦的なタスクです。現在の方法は、多くの場合、ノイズの多い境界位置と、提案の取得に使用される信頼スコアの品質の低下に悩まされています。この論文では、時間的提案生成のために補完的な境界リグレッサと関係モデリングを活用する新しいフレームワークであるBSN ++を紹介します。最初に、開始境界分類器と終了境界分類器の両方の相補的特性に基づいて、新しい境界回帰子を提案します。具体的には、ネストされたスキップ接続を備えたU字型アーキテクチャを利用して、豊富なコンテキストをキャプチャし、双方向の境界マッチングメカニズムを導入して境界の精度を向上させます。第二に、以前の方法で無視された提案-提案関係を説明するために、位置とチャネルの観点から2つの自己注意モジュールを含む提案関係ブロックを考案します。さらに、正/負の提案と時間的期間にデータの不均衡な問題が必然的に存在し、裾の分布でのモデルのパフォーマンスに悪影響を与えることがわかりました。この問題を軽減するために、スケールバランスの取れたリサンプリング戦略を導入します。 2つの人気のあるベンチマークであるActivityNet-1.3とTHUMOS14で広範な実験が行われ、BSN ++が最先端のパフォーマンスを達成していることを示しています。,https://d3i71xaburhd42.cloudfront.net/1ea2373840d4a5079ecb0132fc47ed37e423bd96/1-Figure1-1.png
Dynamic Hybrid Relation Exploration Network for Cross-Domain Context-Dependent Semantic Parsing,"['Binyuan Hui', 'Ruiying Geng', 'Qiyu Ren', 'Binhua Li', 'Yongbin Li', 'Jian Sun', 'Fei Huang', 'Luo Si', 'Pengfei Zhu', 'Xiaodan Zhu']",https://arxiv.org/abs/2101.01686,"Semantic parsing has long been a fundamental problem in natural language processing. Recently, cross-domain contextdependent semantic parsing has become a new focus of research. Central to the problem is the challenge of leveraging contextual information of both natural language utterance and database schemas in the interaction history. In this paper, we present a dynamic graph framework that is capable of effectively modelling contextual utterances, tokens, database schemas, and their complicated interaction as the conversation proceeds. The framework employs a dynamic memory decay mechanism that incorporates inductive bias to integrate enriched contextual relation representation, which is further enhanced with a powerful reranking model. At the time of writing, we demonstrate that the proposed framework outperforms all existing models by large margins, achieving new state-of-the-art performance on two large-scale benchmarks, the SParC and CoSQL datasets. Specifically, the model attains a 55.8% question-match and 30.8% interaction-match accuracy on SParC, and a 46.8% question-match and 17.0% interaction-match accuracy on CoSQL.",意味解析は、自然言語処理において長い間根本的な問題でした。最近、クロスドメインのコンテキスト依存のセマンティック解析が新しい研究の焦点になっています。問題の中心となるのは、対話履歴で自然言語の発話とデータベーススキーマの両方のコンテキスト情報を活用するという課題です。このホワイトペーパーでは、会話の進行に伴うコンテキスト発話、トークン、データベーススキーマ、およびそれらの複雑な相互作用を効果的にモデル化できる動的グラフフレームワークを紹介します。フレームワークは、強力な再ランク付けモデルでさらに強化された、強化されたコンテキスト関係表現を統合するために誘導バイアスを組み込んだ動的メモリ減衰メカニズムを採用しています。これを書いている時点で、提案されたフレームワークが既存のすべてのモデルを大幅に上回り、2つの大規模ベンチマークであるSParCおよびCoSQLデータセットで新しい最先端のパフォーマンスを達成していることを示しています。具体的には、モデルは55.8を達成します,https://d3i71xaburhd42.cloudfront.net/d64192da0b6d43c91c902105c089b18b76f9fe77/1-Figure1-1.png
Deep Unsupervised Image Hashing by Maximizing Bit Entropy,"['Yunqiang Li', 'Jan van Gemert']",https://arxiv.org/abs/2012.12334,"Unsupervised hashing is important for indexing huge image or video collections without having expensive annotations available. Hashing aims to learn short binary codes for compact storage and efficient semantic retrieval. We propose an unsupervised deep hashing layer called Bi-half Net that maximizes entropy of the binary codes. Entropy is maximal when both possible values of the bit are uniformly (half-half) distributed. To maximize bit entropy, we do not add a term to the loss function as this is difficult to optimize and tune. Instead, we design a new parameter-free network layer to explicitly force continuous image features to approximate the optimal half-half bit distribution. This layer is shown to minimize a penalized term of the Wasserstein distance between the learned continuous image features and the optimal half-half bit distribution. Experimental results on the image datasets Flickr25k, Nus-wide, Cifar-10, Mscoco, Mnist and the video datasets Ucf-101 and Hmdb-51 show that our approach leads to compact codes and compares favorably to the current stateof-the-art.",教師なしハッシュは、高価なアノテーションを使用せずに膨大な画像やビデオのコレクションにインデックスを付けるために重要です。ハッシュは、コンパクトなストレージと効率的なセマンティック検索のための短いバイナリコードを学習することを目的としています。バイナリコードのエントロピーを最大化するBi-halfNetと呼ばれる教師なしディープハッシュレイヤーを提案します。エントロピーは、ビットの両方の可能な値が均一に（半分）分布しているときに最大になります。ビットエントロピーを最大化するために、損失関数に項を追加しません。これは、最適化と調整が難しいためです。代わりに、パラメータのない新しいネットワークレイヤーを設計して、連続画像の特徴を明示的に強制し、最適なハーフハーフビット分布を近似します。この層は、学習された連続画像の特徴と最適なハーフハーフビット分布との間のワッサースタイン距離のペナルティ項を最小化することが示されています。画像データセットFlickr25k、Nus-wide、Cifar-10、Mscoco、Mnist、およびビデオデータセットUcf-101とHmdb-51の実験結果は、私たちのアプローチがコンパクトなコードにつながり、現在の最先端技術と比べて遜色がないことを示しています。,https://d3i71xaburhd42.cloudfront.net/48f33710063f1cdf74abe298245e4cd3834800c9/1-Figure1-1.png
Pre-Training Context and Time Aware Location Embeddings from Spatial-Temporal Trajectories for User Next Location Prediction,"['Yan Lin', 'Huaiyu Wan', 'Shengnan Guo', 'Youfang Lin']",,,,
GradingNet: Towards Providing Reliable Supervisions for Weakly Supervised Object Detection by Grading the Box Candidates,"['Qifei Jia', 'Shikui Wei', 'Tao Ruan', 'Zhao Yufeng', 'Yao Zhao']",,,,
Learning Comprehensive Motion Representation for Action Recognition,"['Mingyu Wu', 'Boyuan Jiang', 'Donghao Luo', 'Junchi Yan', 'Yabiao Wang', 'Ying Tai', 'Chengjie Wang', 'Jilin Li', 'Feiyue Huang', 'Xiaokang Yang']",,,,
Dual-Level Collaborative Transformer for Image Captioning,"['Yunpeng Luo', 'Jiayi Ji', 'Xiaoshuai Sun', 'Liujuan Cao', 'Yongjian Wu', 'Feiyue Huang', 'Chia-Wen Lin', 'Rongrong Ji']",https://arxiv.org/abs/2101.06462,"Descriptive region features extracted by object detection networks have played an important role in the recent advancements of image captioning. However, they are still criticized for the lack of contextual information and fine-grained details, which in contrast are the merits of traditional grid features. In this paper, we introduce a novel Dual-Level Collaborative Transformer (DLCT) network to realize the complementary advantages of the two features. Concretely, in DLCT, these two features are first processed by a novel Dualway Self Attenion (DWSA) to mine their intrinsic properties, where a Comprehensive Relation Attention component is also introduced to embed the geometric information. In addition, we propose a Locality-Constrained Cross Attention module to address the semantic noises caused by the direct fusion of these two features, where a geometric alignment graph is constructed to accurately align and reinforce region and grid features. To validate our model, we conduct extensive experiments on the highly competitive MS-COCO dataset, and achieve new state-of-the-art performance on both local and online test sets, i.e., 133.8% CIDEr on Karpathy split and 135.4% CIDEr on the official split. Code is available at https://github.com/luo3300612/image-captioning-DLCT.",オブジェクト検出ネットワークによって抽出された記述領域の特徴は、画像キャプションの最近の進歩において重要な役割を果たしてきました。ただし、従来のグリッド機能のメリットであるコンテキスト情報と詳細の不足については、依然として批判されています。このホワイトペーパーでは、2つの機能の補完的な利点を実現するために、新しいデュアルレベルコラボレーティブトランス（DLCT）ネットワークを紹介します。具体的には、DLCTでは、これら2つの機能は最初に新しいDualway Self Attenion（DWSA）によって処理され、固有のプロパティがマイニングされます。ここでは、包括的な関係注意コンポーネントも導入され、幾何学的情報が埋め込まれます。さらに、これら2つの特徴の直接融合によって引き起こされるセマンティックノイズに対処するために、局所性制約付きクロスアテンションモジュールを提案します。幾何学的整列グラフは、領域とグリッドの特徴を正確に整列および強化するために構築されます。モデルを検証するために、競争の激しいMS-COCOデータセットで広範な実験を行い、ローカルテストセットとオンラインテストセットの両方で新しい最先端のパフォーマンス、つまり133.8を実現します。,https://d3i71xaburhd42.cloudfront.net/edb772f6ffb97b8e20013652dc4633801cd6b9b9/1-Figure1-1.png
Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence,"['Siyue Yu', 'Bingfeng Zhang', 'Jimin Xiao', 'Eng Gee Lim']",,,,
Robustness of Accuracy Metric and its Inspirations in Learning with Noisy Labels,"['Pengfei Chen', 'JunJie Ye', 'Guangyong Chen', 'Jingwei Zhao', 'Pheng-Ann Heng']",https://arxiv.org/abs/2012.04193,"For multi-class classification under class-conditional label noise, we prove that the accuracy metric itself can be robust. We concretize this finding's inspiration in two essential aspects: training and validation, with which we address critical issues in learning with noisy labels. For training, we show that maximizing training accuracy on sufficiently many noisy samples yields an approximately optimal classifier. For validation, we prove that a noisy validation set is reliable, addressing the critical demand of model selection in scenarios like hyperparameter-tuning and early stopping. Previously, model selection using noisy validation samples has not been theoretically justified. We verify our theoretical results and additional claims with extensive experiments. We show characterizations of models trained with noisy labels, motivated by our theoretical results, and verify the utility of a noisy validation set by showing the impressive performance of a framework termed noisy best teacher and student (NTS). Our code is released.",クラス条件付きラベルノイズの下でのマルチクラス分類の場合、精度メトリック自体が堅牢である可能性があることを証明します。この調査結果のインスピレーションは、トレーニングと検証という2つの重要な側面で具体化されています。これにより、ノイズの多いラベルを使用した学習における重要な問題に対処します。トレーニングについては、十分な数のノイズの多いサンプルでトレーニングの精度を最大化すると、ほぼ最適な分類器が得られることを示します。検証では、ノイズの多い検証セットが信頼できることを証明し、ハイパーパラメータ調整や早期停止などのシナリオでのモデル選択の重要な要求に対応します。以前は、ノイズの多い検証サンプルを使用したモデル選択は理論的に正当化されていませんでした。理論的な結果と追加の主張を広範な実験で検証します。理論的な結果に動機付けられた、ノイズの多いラベルでトレーニングされたモデルの特性を示し、ノイズの多い最高の教師と学生（NTS）と呼ばれるフレームワークの印象的なパフォーマンスを示すことによってノイズのある検証セットの有用性を検証します。コードがリリースされました。,https://d3i71xaburhd42.cloudfront.net/1fbff5f28ac4851011a0c86f72c1c6126a984c07/2-Figure1-1.png
Mind the Gap: Cake Cutting with Separation,"['Edith Elkind', 'Erel Segal-Halevi', 'Warut Suksompong']",https://arxiv.org/abs/2012.06682,"We study the problem of fairly allocating a divisible resource, also known as cake cutting, with an additional requirement that the shares that different agents receive should be sufficiently separated from one another. This captures, for example, constraints arising from social distancing guidelines. While it is sometimes impossible to allocate a proportional share to every agent under the separation requirement, we show that the well-known criterion of maximin share fairness can always be attained. We then establish several computational properties of maximin share fairness -- for instance, the maximin share of an agent cannot be computed exactly by any finite algorithm, but can be approximated with an arbitrarily small error. In addition, we consider the division of a pie (i.e., a circular cake) and show that an ordinal relaxation of maximin share fairness can be achieved.",ケーキカットとも呼ばれる分割可能なリソースを公平に割り当てる問題を調査します。さらに、さまざまなエージェントが受け取るシェアを互いに十分に分離する必要があります。これは、たとえば、社会的距離のガイドラインから生じる制約をキャプチャします。分離要件の下ですべてのエージェントに比例シェアを割り当てることが不可能な場合もありますが、最大シェアの公平性というよく知られた基準は常に達成できることを示しています。次に、マキシミンシェアの公平性のいくつかの計算プロパティを確立します。たとえば、エージェントのマキシミンシェアは、有限アルゴリズムでは正確に計算できませんが、任意の小さな誤差で近似できます。さらに、パイ（つまり、円形のケーキ）の分割を検討し、マキシミンシェアの公平性の通常の緩和が達成できることを示します。,https://d3i71xaburhd42.cloudfront.net/47fb6bb71cc22125361d8a1137c61b4a798dfb87/8-Figure1-1.png
Quantum-Inspired Neural Network for Conversational Emotion Recognition,"['Qiuchi Li', 'Dimitris Gkoumas', 'Alessandro Sordoni', 'Jian-Yun Nie', 'Massimo Melucci']",,,,
Memory-Augmented Image Captioning,['Zhengcong Fei'],,,,
AutoLR: Layer-Wise Pruning and Auto-Tuning of Learning Rates in Fine-Tuning of Deep Networks,"['Youngmin Ro', 'Jin Young Choi']",https://arxiv.org/abs/2002.06048,"Existing fine-tuning methods use a single learning rate over all layers. In this paper, first, we discuss that trends of layer-wise weight variations by fine-tuning using a single learning rate do not match the well-known notion that lower-level layers extract general features and higher-level layers extract specific features. Based on our discussion, we propose an algorithm that improves fine-tuning performance and reduces network complexity through layer-wise pruning and auto-tuning of layer-wise learning rates. The proposed algorithm has verified the effectiveness by achieving state-of-the-art performance on the image retrieval benchmark datasets (CUB-200, Cars-196, Stanford online product, and Inshop). Code is available at https://github.com/youngminPIL/AutoLR.",既存の微調整方法は、すべてのレイヤーで単一の学習率を使用します。この論文では、最初に、単一の学習率を使用して微調整することによる層ごとの重みの変動の傾向が、低レベルの層が一般的な特徴を抽出し、高レベルの層が特定の特徴を抽出するというよく知られた概念と一致しないことを説明します。私たちの議論に基づいて、レイヤーごとのプルーニングとレイヤーごとの学習率の自動調整を通じて、微調整のパフォーマンスを向上させ、ネットワークの複雑さを軽減するアルゴリズムを提案します。提案されたアルゴリズムは、画像検索ベンチマークデータセット（CUB-200、Cars-196、スタンフォードオンライン製品、およびInshop）で最先端のパフォーマンスを達成することにより、有効性を検証しました。コードはhttps://github.com/youngminPIL/AutoLRで入手できます。,
How Does the Combined Risk Affect the Performance of Unsupervised Domain Adaptation Approaches?,"['Li Zhong', 'Zhen Fang', 'Feng Liu', 'Bo Yuan', 'Guangquan Zhang', 'Jie Lu']",https://arxiv.org/abs/2101.01104,"Unsupervised domain adaptation (UDA) aims to train a target classifier with labeled samples from the source domain and unlabeled samples from the target domain. Classical UDA learning bounds show that target risk is upper bounded by three terms: source risk, distribution discrepancy, and combined risk. Based on the assumption that the combined risk is a small fixed value, methods based on this bound train a target classifier by only minimizing estimators of the source risk and the distribution discrepancy. However, the combined risk may increase when minimizing both estimators, which makes the target risk uncontrollable. Hence the target classifier cannot achieve ideal performance if we fail to control the combined risk. To control the combined risk, the key challenge takes root in the unavailability of the labeled samples in the target domain. To address this key challenge, we propose a method named E-MixNet. E-MixNet employs enhanced mixup, a generic vicinal distribution, on the labeled source samples and pseudo-labeled target samples to calculate a proxy of the combined risk. Experiments show that the proxy can effectively curb the increase of the combined risk when minimizing the source risk and distribution discrepancy. Furthermore, we show that if the proxy of the combined risk is added into loss functions of four representative UDA methods, their performance is also improved.",教師なしドメイン適応（UDA）は、ソースドメインからのラベル付きサンプルとターゲットドメインからのラベルなしサンプルを使用してターゲット分類器をトレーニングすることを目的としています。従来のUDAの学習限界は、ターゲットリスクが、ソースリスク、分布の不一致、および複合リスクの3つの用語によって上限が定められていることを示しています。結合されたリスクが小さな固定値であるという仮定に基づいて、この限界に基づく方法は、ソースリスクと分布の不一致の推定量を最小化するだけでターゲット分類器をトレーニングします。ただし、両方の推定量を最小化すると、複合リスクが増加する可能性があり、ターゲットリスクを制御できなくなります。したがって、複合リスクを制御できない場合、ターゲット分類器は理想的なパフォーマンスを達成できません。複合リスクを制御するための重要な課題は、ターゲットドメインでラベル付けされたサンプルが利用できないことに根ざしています。この重要な課題に対処するために、E-MixNetという名前の方法を提案します。 E-MixNetは、ラベル付けされたソースサンプルと疑似ラベル付けされたターゲットサンプルに強化された混合、一般的な隣接分布を採用して、複合リスクのプロキシを計算します。実験によると、プロキシは、ソースリスクと分布の不一致を最小限に抑えると、複合リスクの増加を効果的に抑えることができます。さらに、4つの代表的なUDAメソッドの損失関数に複合リスクのプロキシを追加すると、それらのパフォーマンスも向上することを示します。,https://d3i71xaburhd42.cloudfront.net/c66aa46cdf3e748c4176c4c99bdc829ec31a0f29/1-Figure1-1.png
Retrospective Reader for Machine Reading Comprehension,"['Zhuosheng Zhang', 'Junjie Yang', 'Hai Zhao']",,,,
Oral-3D: Reconstructing the 3D Structure of Oral Cavity from Panoramic X-ray,"['Weinan Song', 'Yuan Liang', 'Jiawei Yang', 'Kun Wang', 'Lei He']",,,,
Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs,"['Yanlin Wang', 'Hui Li']",,,,
Ranking Sets of Defeasible Elements in Preferential Approaches to Structured,"['Argumentation: Postulates', 'Relations', 'and Characterizations Jan Maly', 'Johannes Peter Wallner']",,,,
Translate the Facial Regions You Like Using Self-Adaptive Region Translation,"['Wenshuang Liu', 'Wenting Chen', 'Zhanjia Yang', 'Linlin Shen']",,,,
LRC-BERT: Latent-Representation Contrastive Knowledge Distillation for Natural Language Understanding,"['Hao Fu', 'Shaojun Zhou', 'Qihong Yang', 'Junjie Tang', 'Liu GuiQuan', 'Kaikui Liu', 'Xiaolong Li']",https://arxiv.org/abs/2012.07335,"The pre-training models such as BERT have achieved great results in various natural language processing problems. However, a large number of parameters need significant amounts of memory and the consumption of inference time, which makes it difficult to deploy them on edge devices. In this work, we propose a knowledge distillation method LRC-BERT based on contrastive learning to fit the output of the intermediate layer from the angular distance aspect, which is not considered by the existing distillation methods. Furthermore, we introduce a gradient perturbation-based training architecture in the training phase to increase the robustness of LRC-BERT, which is the first attempt in knowledge distillation. Additionally, in order to better capture the distribution characteristics of the intermediate layer, we design a two-stage training method for the total distillation loss. Finally, by verifying 8 datasets on the General Language Understanding Evaluation (GLUE) benchmark, the performance of the proposed LRC-BERT exceeds the existing state-of-the-art methods, which proves the effectiveness of our method.",BERTなどの事前トレーニングモデルは、さまざまな自然言語処理の問題で優れた結果を達成しています。ただし、パラメータの数が多いと、大量のメモリと推論時間が消費されるため、エッジデバイスにパラメータを展開することが困難になります。本研究では、既存の蒸留法では考慮されていない、角距離の観点から中間層の出力を適合させるための対照学習に基づく知識蒸留法LRC-BERTを提案します。さらに、トレーニングフェーズで勾配摂動ベースのトレーニングアーキテクチャを導入して、知識蒸留の最初の試みであるLRC-BERTの堅牢性を向上させます。さらに、中間層の分布特性をより適切に把握するために、総蒸留損失の2段階トレーニング方法を設計します。最後に、一般言語理解評価（GLUE）ベンチマークで8つのデータセットを検証することにより、提案されたLRC-BERTのパフォーマンスは、既存の最先端の方法を上回り、私たちの方法の有効性を証明します。,https://d3i71xaburhd42.cloudfront.net/4c3b044cc98def3defc3d562e5c0d811f7b0d200/3-Figure1-1.png
A Unified Framework for Planning with Learned Neural Network Transition Models,['Buser Say'],,,,
Disentangled Multi-Relational Graph Convolutional Network for Pedestrian Trajectory Prediction,"['Inhwan Bae', 'Hae-Gon Jeon']",,,,
Inferring Emotion from Large-Scale Internet Voice Data: A Semi-Supervised Curriculum Augmentation Based Deep Learning Approach,"['Suping Zhou', 'Jia Jia', 'Zhiyong Wu', 'Zhihan Yang', 'Yanfeng Wang', 'Wei Chen', 'Fanbo Meng', 'Shuo Huang', 'Jialie Shen', 'Xiaochuan Wang']",,,,
CardioGAN: Attentive Generative Adversarial Network with Dual Discriminators for Synthesis of ECG from PPG,"['Pritam Sarkar', 'Ali Etemad']",https://arxiv.org/abs/2010.00104,"Electrocardiogram (ECG) is the electrical measurement of cardiac activity, whereas Photoplethysmogram (PPG) is the optical measurement of volumetric changes in blood circulation. While both signals are used for heart rate monitoring, from a medical perspective, ECG is more useful as it carries additional cardiac information. Despite many attempts toward incorporating ECG sensing in smartwatches or similar wearable devices for continuous and reliable cardiac monitoring, PPG sensors are the main feasible sensing solution available. In order to tackle this problem, we propose CardioGAN, an adversarial model which takes PPG as input and generates ECG as output. The proposed network utilizes an attention-based generator to learn local salient features, as well as dual discriminators to preserve the integrity of generated data in both time and frequency domains. Our experiments show that the ECG generated by CardioGAN provides more reliable heart rate measurements compared to the original input PPG, reducing the error from 9.74 beats per minute (measured from the PPG) to 2.89 (measured from the generated ECG).",心電図（ECG）は心臓活動の電気的測定であり、フォトプレチスモグラム（PPG）は血液循環の体積変化の光学的測定です。両方の信号は心拍数の監視に使用されますが、医療の観点からは、ECGは追加の心臓情報を伝達するため、より有用です。継続的で信頼性の高い心臓モニタリングのためにスマートウォッチまたは同様のウェアラブルデバイスにECGセンシングを組み込むことに向けた多くの試みにもかかわらず、PPGセンサーは利用可能な主要な実行可能なセンシングソリューションです。この問題に取り組むために、PPGを入力として、ECGを出力として生成する敵対モデルであるCardioGANを提案します。提案されたネットワークは、注意ベースのジェネレーターを利用してローカルの顕著な特徴を学習し、デュアルディスクリミネーターを使用して、時間ドメインと周波数ドメインの両方で生成されたデータの整合性を維持します。私たちの実験は、CardioGANによって生成されたECGが、元の入力PPGと比較してより信頼性の高い心拍数測定を提供し、エラーを9.74ビート/分（PPGから測定）から2.89（生成されたECGから測定）に減らすことを示しています。,https://d3i71xaburhd42.cloudfront.net/61b661386940a48c1f66a22473e73561de530a01/3-Figure1-1.png
Towards Domain Invariant Single Image Dehazing,"['Pranjay Shyam', 'Kuk-Jin Yoon', 'Kyung-Soo Kim']",https://arxiv.org/abs/2101.10449,"Presence of haze in images obscures underlying information, which is undesirable in applications requiring accurate environment information. To recover such an image, a dehazing algorithm should localize and recover affected regions while ensuring consistency between recovered and its neighboring regions. However owing to fixed receptive field of convolutional kernels and non uniform haze distribution, assuring consistency between regions is difficult. In this paper, we utilize an encoder-decoder based network architecture to perform the task of dehazing and integrate an spatially aware channel attention mechanism to enhance features of interest beyond the receptive field of traditional conventional kernels. To ensure performance consistency across diverse range of haze densities, we utilize greedy localized data augmentation mechanism. Synthetic datasets are typically used to ensure a large amount of paired training samples, however the methodology to generate such samples introduces a gap between them and real images while accounting for only uniform haze distribution and overlooking more realistic scenario of nonuniform haze distribution resulting in inferior dehazing performance when evaluated on real datasets. Despite this, the abundance of paired samples within synthetic datasets cannot be ignored. Thus to ensure performance consistency across diverse datasets, we train the proposed network within an adversarial prior-guided framework that relies on a generated image along with its low and high frequency components to determine if properties of dehazed images matches those of ground truth. We preform extensive experiments to validate the dehazing and domain invariance performance of proposed framework across diverse domains and report state-of-the-art (SoTA) results. The source code with pretrained models will be available at https://github.com/PS06/DIDH.",画像にヘイズが存在すると、基礎となる情報が不明瞭になります。これは、正確な環境情報を必要とするアプリケーションでは望ましくありません。このような画像を復元するには、ヘイズ除去アルゴリズムで影響を受ける領域をローカライズして復元すると同時に、復元された領域とその隣接領域の間の一貫性を確保する必要があります。ただし、畳み込みカーネルの固定された受容野と不均一なヘイズ分布のため、領域間の一貫性を保証することは困難です。この論文では、エンコーダ-デコーダベースのネットワークアーキテクチャを利用して、ヘイズ除去のタスクを実行し、空間認識チャネル注意メカニズムを統合して、従来の従来のカーネルの受容野を超えて関心のある機能を強化します。さまざまな範囲のヘイズ密度にわたってパフォーマンスの一貫性を確保するために、貪欲なローカライズされたデータ拡張メカニズムを利用します。合成データセットは通常、大量のペアトレーニングサンプルを確保するために使用されますが、そのようなサンプルを生成する方法論では、均一なヘイズ分布のみを考慮し、不均一なヘイズ分布のより現実的なシナリオを見落としながら、サンプルと実際の画像の間にギャップが生じます。実際のデータセットで評価した場合のパフォーマンス。それにもかかわらず、合成データセット内のペアのサンプルの豊富さは無視できません。したがって、さまざまなデータセット間でパフォーマンスの一貫性を確保するために、生成された画像とその低周波数成分および高周波数成分に依存する敵対的な事前ガイドフレームワーク内で提案されたネットワークをトレーニングし、デヘイズされた画像のプロパティがグラウンドトゥルースのプロパティと一致するかどうかを判断します。さまざまなドメインにわたって提案されたフレームワークのデヘイズとドメイン不変性のパフォーマンスを検証し、最先端の（SoTA）結果を報告するために、広範な実験を実行します。事前にトレーニングされたモデルのソースコードは、https：//github.com/PS06/DIDHで入手できます。,https://d3i71xaburhd42.cloudfront.net/d3faa88ddedd47d5d2acb05a706dc5c6f5d14743/3-Figure1-1.png
Instrumental Variable-Based Identification for Causal Dffects Using Covariate Information,['Yuta Kawakami'],,,,
Choosing the Initial State for Online Replanning,"['Maximilian Fickert', 'Ivan Gavran', 'Ivan Fedotov', 'Joerg Hoffmann', 'Rupak Majumdar', 'Wheeler Ruml']",,"The need to replan arises in many applications. However, in the context of planning as heuristic search, it raises an annoying problem: if the previous plan is still executing, what should the new plan search take as its initial state? If it were possible to accurately predict how long replanning would take, it would be easy to find the appropriate state at which control will transfer from the previous plan to the new one. But as planning problems can vary enormously in their difficulty, this prediction can be challenging. Many current systems merely use a manually chosen constant duration. In this paper, we show how such ad hoc solutions can be avoided by integrating the choice of the appropriate initial state into the search process itself. The search is initialized with multiple candidate initial states and a time-aware evaluation function is used to prefer plans whose total goal achievement time is minimal. Experimental results show that this approach yields better behavior than either guessing a constant or trying to predict replanning time in advance. By making replanning more effective and easier to implement, this work aids in creating planning systems that can better handle the inevitable exigencies of real-world execution.",再計画の必要性は、多くのアプリケーションで発生します。ただし、ヒューリスティック検索としての計画のコンテキストでは、厄介な問題が発生します。前の計画がまだ実行されている場合、新しい計画検索は初期状態として何をとるべきでしょうか。再計画にかかる時間を正確に予測できれば、以前の計画から新しい計画に制御が移行する適切な状態を簡単に見つけることができます。しかし、計画の問題はその難易度が大きく異なる可能性があるため、この予測は困難な場合があります。現在の多くのシステムは、手動で選択された一定の期間を使用するだけです。このホワイトペーパーでは、適切な初期状態の選択を検索プロセス自体に統合することで、このようなアドホックソリューションを回避する方法を示します。検索は複数の候補初期状態で初期化され、時間認識評価関数を使用して、合計目標達成時間が最小のプランを優先します。実験結果は、このアプローチが定数を推測したり、事前に再計画時間を予測しようとしたりするよりも優れた動作をもたらすことを示しています。再計画をより効果的かつ実装しやすくすることにより、この作業は、現実世界の実行の避けられない緊急事態をより適切に処理できる計画システムの作成を支援します。,https://d3i71xaburhd42.cloudfront.net/e3148251691d6e0441f355d3046d240d31ed25f8/6-Figure1-1.png
Second Order Techniques for Learning Time-Series with Structural Breaks,['Takayuki Osogami'],,,,
What to Select: Pursuing Consistent Motion Segmentation from Multiple Geometric Models,"['Yangbangyan Jiang', 'Qianqian Xu', 'Ke Ma', 'Zhiyong Yang', 'Xiaochun Cao', 'Qingming Huang']",,,,
Neural Sentence Simplification with Semantic Dependency Information,"['Zhe Lin', 'Xiaojun Wan']",,,,
Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts,"['Hanmeng Liu', 'Leyang Cui', 'Jian Liu', 'Yue Zhang']",https://arxiv.org/abs/2011.04864,"Natural language inference (NLI) is a fundamental NLP task, investigating the entailment relationship between two texts. Popular NLI datasets present the task at sentence-level. While adequate for testing semantic representations, they fall short for testing contextual reasoning over long texts, which is a natural part of the human inference process. We introduce ConTRoL, a new dataset for ConTextual Reasoning over Long texts. Consisting of 8,325 expert-designed ""context-hypothesis"" pairs with gold labels, ConTRoL is a passage-level NLI dataset with a focus on complex contextual reasoning types such as logical reasoning. It is derived from competitive selection and recruitment test (verbal reasoning test) for police recruitment, with expert level quality. Compared with previous NLI benchmarks, the materials in ConTRoL are much more challenging, involving a range of reasoning types. Empirical results show that state-of-the-art language models perform by far worse than educated humans. Our dataset can also serve as a testing-set for downstream tasks like Checking Factual Correctness of Summaries.","自然言語推論（NLI）は、2つのテキスト間の含意関係を調査する基本的なNLPタスクです。人気のあるNLIデータセットは、文レベルでタスクを提示します。セマンティック表現のテストには十分ですが、人間の推論プロセスの自然な部分である長いテキストに対するコンテキスト推論のテストには不十分です。長いテキストに対するConTextualReasoningの新しいデータセットであるConTRoLを紹介します。 ConTRoLは、専門家が設計した8,325の「コンテキスト仮説」ペアとゴールドラベルで構成され、論理的推論などの複雑なコンテキスト推論タイプに焦点を当てたパッセージレベルのNLIデータセットです。これは、専門家レベルの品質で、警察の採用のための競争力のある選択と採用テスト（口頭の推論テスト）から派生しています。以前のNLIベンチマークと比較して、ConTRoLの資料ははるかに困難であり、さまざまな推論タイプが含まれます。経験的な結果は、最先端の言語モデルが教育を受けた人間よりもはるかに悪いパフォーマンスを示すことを示しています。私たちのデータセットは、要約の事実上の正しさのチェックなどのダウンストリームタスクのテストセットとしても機能します。",https://d3i71xaburhd42.cloudfront.net/ffbfce72f12aa0be619be5e49698c2657853409f/1-Figure1-1.png
HiABP: Hierarchical Initialized ABP for Unsupervised Representation Learning,"['Jiankai Sun', 'Rui Liu', 'Bolei Zhou']",,,,
HINT: Hierarchical Invertible Neural Transport for Density Estimation and Bayesian Inference,"['Jakob Kruse', 'Gianluca Detommaso', 'Robert Scheichl', 'Ullrich Köthe']",,"A large proportion of recent invertible neural architectures is based on a coupling block design. It operates by dividing incoming variables into two sub-spaces, one of which parameterizes an easily invertible (usually affine) transformation that is applied to the other. While the Jacobian of such a transformation is triangular, it is very sparse and thus may lack expressiveness. This work presents a simple remedy by noting that (affine) coupling can be repeated recursively within the resulting sub-spaces, leading to an efficiently invertible block with dense triangular Jacobian. By formulating our recursive coupling scheme via a hierarchical architecture, HINT allows sampling from a joint distribution p(y,x) and the corresponding posterior p(x|y) using a single invertible network. We demonstrate the power of our method for density estimation and Bayesian inference on a novel data set of 2D shapes in Fourier parameterization, which enables consistent visualization of samples for different dimensionalities.",最近の可逆ニューラルアーキテクチャの大部分は、結合ブロック設計に基づいています。これは、入力変数を2つのサブスペースに分割することによって動作し、一方は他方に適用される簡単に反転可能な（通常はアフィン）変換をパラメーター化します。このような変換のヤコビアンは三角形ですが、非常にまばらであるため、表現力に欠ける可能性があります。この作業は、（アフィン）結合が結果のサブスペース内で再帰的に繰り返され、密な三角形のヤコビアンを含む効率的に反転可能なブロックにつながることに注意することで、簡単な解決策を示します。階層アーキテクチャを介して再帰的結合スキームを定式化することにより、HINTは、単一の可逆ネットワークを使用して、同時分布p（y、x）および対応する事後p（x | y）からのサンプリングを可能にします。さまざまな次元のサンプルの一貫した視覚化を可能にする、フーリエパラメータ化における2D形状の新しいデータセットに対する密度推定とベイズ推定の方法の威力を示します。,
Targeted Negative Campaigning: Complexity and Approximations,"['Avishai Zagoury', 'Orgad Keller', 'Noam Hazon', 'Avinatan Hassidim']",,,,
FracBits: Mixed Precision Quantization via Fractional Bit-Widths,"['Linjie Yang', 'Qing Jin']",https://arxiv.org/abs/2007.02017,"Model quantization helps to reduce model size and latency of deep neural networks. Mixed precision quantization is favorable with customized hardwares supporting arithmetic operations at multiple bit-widths to achieve maximum efficiency. We propose a novel learning-based algorithm to derive mixed precision models end-to-end under target computation constraints and model sizes. During the optimization, the bit-width of each layer / kernel in the model is at a fractional status of two consecutive bit-widths which can be adjusted gradually. With a differentiable regularization term, the resource constraints can be met during the quantization-aware training which results in an optimized mixed precision model. Further, our method can be naturally combined with channel pruning for better computation cost allocation. Our final models achieve comparable or better performance than previous quantization methods with mixed precision on MobilenetV1/V2, ResNet18 under different resource constraints on ImageNet dataset.",モデルの量子化は、ディープニューラルネットワークのモデルサイズと遅延を削減するのに役立ちます。混合精度の量子化は、最大の効率を達成するために複数のビット幅で算術演算をサポートするカスタマイズされたハードウェアで有利です。ターゲット計算の制約とモデルサイズの下でエンドツーエンドの混合精度モデルを導出するための新しい学習ベースのアルゴリズムを提案します。最適化中、モデル内の各レイヤー/カーネルのビット幅は、段階的に調整できる2つの連続するビット幅の小数ステータスになります。微分可能な正則化項を使用すると、量子化を意識したトレーニング中にリソースの制約を満たすことができ、最適化された混合精度モデルが得られます。さらに、私たちの方法は、計算コストの割り当てを改善するために、チャネルプルーニングと自然に組み合わせることができます。私たちの最終モデルは、ImageNetデータセットのさまざまなリソース制約の下で、MobilenetV1 / V2、ResNet18で混合精度を使用して、以前の量子化方法と同等またはそれ以上のパフォーマンスを実現します。,https://d3i71xaburhd42.cloudfront.net/5bbb9dfc449f77a8c95de0bdd4a70fd96953308e/5-Figure1-1.png
Few-Shot One-Class Classification via Meta-Learning,"['Ahmed Frikha', 'Denis Krompass', 'Hans-Georg Koepken', 'Volker Tresp']",https://arxiv.org/abs/2007.04146,"Although few-shot learning and one-class classification (OCC), i.e. learning a binary classifier with data from only one class, have been separately well studied, their intersection remains rather unexplored. Our work addresses the few-shot OCC problem and presents a method to modify the episodic data sampling strategy of the model-agnostic meta-learning (MAML) algorithm to learn a model initialization particularly suited for learning few-shot OCC tasks. This is done by explicitly optimizing for an initialization which only requires few gradient steps with one-class minibatches to yield a performance increase on class-balanced test data. We provide a theoretical analysis that explains why our approach works in the few-shot OCC scenario, while other meta-learning algorithms, including MAML, fail. Our experiments on eight datasets from the image and time-series domains show that our method leads to higher results than classical OCC and few-shot classification approaches, and demonstrate the ability to learn unseen tasks from only few normal class samples. Moreover, we successfully train anomaly detectors for a real-world application on sensor readings recorded during industrial manufacturing of workpieces with a CNC milling machine using few normal examples. Finally, we empirically demonstrate that the proposed data sampling technique increases the performance of more recent meta-learning algorithms in few-shot OCC.",少数ショット学習と1クラス分類（OCC）、つまり1つのクラスのみのデータを使用して二項分類器を学習することは、個別に十分に研究されていますが、それらの共通部分は未踏のままです。私たちの仕事は、数ショットのOCC問題に対処し、モデルにとらわれないメタ学習（MAML）アルゴリズムのエピソードデータサンプリング戦略を変更して、数ショットのOCCタスクの学習に特に適したモデルの初期化を学習する方法を示します。これは、初期化を明示的に最適化することによって行われます。初期化では、クラスバランスのとれたテストデータのパフォーマンスを向上させるために、1クラスのミニバッチでわずかな勾配ステップしか必要ありません。 MAMLを含む他のメタ学習アルゴリズムが失敗する一方で、私たちのアプローチが数ショットのOCCシナリオで機能する理由を説明する理論的分析を提供します。画像および時系列ドメインからの8つのデータセットでの実験は、私たちの方法が従来のOCCおよび数ショット分類アプローチよりも高い結果をもたらし、わずかな通常のクラスサンプルから見えないタスクを学習する能力を示しています。さらに、いくつかの通常の例を使用して、CNCフライス盤を使用したワークピースの工業生産中に記録されたセンサー読み取り値に関する実際のアプリケーション用の異常検出器のトレーニングに成功しました。最後に、提案されたデータサンプリング手法が、数ショットのOCCでより最近のメタ学習アルゴリズムのパフォーマンスを向上させることを経験的に示します。,https://d3i71xaburhd42.cloudfront.net/11c461ab41234d56f7495306244fa50e16a366fe/4-Figure1-1.png
Joint Demosaicking and Denoising in the Wild: The Case of Training under Ground Truth Uncertainty,"['Jierun Chen', 'Song Wen', 'Gary Chan']",https://arxiv.org/abs/2101.04442,"Image demosaicking and denoising are the two key fundamental steps in digital camera pipelines, aiming to reconstruct clean color images from noisy luminance readings. In this paper, we propose and study Wild-JDD, a novel learning framework for joint demosaicking and denoising in the wild. In contrast to previous works which generally assume the ground truth of training data is a perfect reflection of the reality, we consider here the more common imperfect case of ground truth uncertainty in the wild. We first illustrate its manifestation as various kinds of artifacts including zipper effect, color moire and residual noise. Then we formulate a two-stage data degradation process to capture such ground truth uncertainty, where a conjugate prior distribution is imposed upon a base distribution. After that, we derive an evidence lower bound (ELBO) loss to train a neural network that approximates the parameters of the conjugate prior distribution conditioned on the degraded input. Finally, to further enhance the performance for out-of-distribution input, we design a simple but effective fine-tuning strategy by taking the input as a weakly informative prior. Taking into account ground truth uncertainty, Wild-JDD enjoys good interpretability during optimization. Extensive experiments validate that it outperforms state-of-the-art schemes on joint demosaicking and denoising tasks on both synthetic and realistic raw datasets. Introduction Modern digital cameras use a single sensor overlaid with a color filter array (CFA) to capture an image. This means that only one color channel’s value is recorded for each pixel location. LetN be the number of pixels in an image, the raw data acquisition process can be simply modeled as x = Az + n, (1) where x ∈ R is a noisy raw data vector of luminance readings, A ∈ RN×3N is a mosaicking operation, z ∈ R is an unknown clean image with three color channels, and n ∈ R is a noise vector. Before the final “cooked” image is ready for the users, the raw data undergoes a series of processing steps, known as the image processing pipeline. Among those, demosaicking and denoising (DM&DN) are two of the very early and Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. (a) Zipper effect. (b) Color moire. (c) Residual noise. Figure 1: Imperfect ground truth examples (electronic zoomin recommended): (a) A ground truth image from CBSD dataset (Arbeláez et al. 2011) suffering from zipper effect, an artificial jagged pattern around edges; (b) Color moire in an image from ImageNet dataset (Russakovsky et al. 2015). Such artifact appears as false coloring due to interpolation error; (c) Noticeable residual noise in the collected “clean” image from Renoir dataset (Anaya and Barbu 2018). most crucial steps. Demosaicking aims to undo the mosaicking operation A by interpolating the missing two-thirds of each pixel’s color channels, while denoising removes the inevitable noise n from the measurement x. Due to their modular property, substantial traditional literature takes them as independent tasks and executes them in a sequential manner. This yields potentially suboptimal performance, and inspires several works on jointly addressing the DM&DN tasks (Liu et al. 2020; Kokkinos and Lefkimmiatis 2019; Tan et al. 2017a). Among the joint DM&DN works, data-driven approaches (Liu et al. 2020; Tan et al. 2018; Kokkinos and Lefkimmiatis 2018) have been shown more effective than applying handcrafted priors and filters. These approaches usually require a collection of paired data, which are the mosaicked noisy images x and the demosaicked clean “ground truth” counterparts y. However, it is often costly and tedious to collect a large amount of high quality real-life data. Furthermore, the collected y is not perfect without artifacts or noise. We illustrate this in Figure 1. For demosaicking, many approaches (Syu, Chen, and Chuang 2018; Tan et al. 2017b) take the output from a camera pipeline as y, possibly introducing artifacts like zipper effect or color moire in regions with rich textures and sharp edges. For denoising, the ar X iv :2 10 1. 04 44 2v 1 [ cs .C V ] 1 2 Ja n 20 21 “clean” images are often collected by either setting a lowISO (Plotz and Roth 2017; Anaya and Barbu 2018) or averaging a set of repeated shots of the same scene (Abdelhamed, Lin, and Brown 2018), which still contain noticeable noise. Moreover, such denoising data collecting process usually assumes the captured objects to be perfectly still, or requires a precise spatial alignment and intensity calibration among a burst of images. Potential failure cases would introduce additional error into the collected dataset. Therefore, all these in-the-wild issues means that the “ground truth” y deviates from the needed authentic z, limiting the performance of DM&DN model. To account for the fact that the collected ground truth y is not a perfect reflection of z, we propose Wild-JDD, a novel joint demosaiking and denoising learning framework to enable training under ground truth uncertainty. In WildJDD, we first formulate a two-stage data degradation process, where a conjugate prior distribution is imposed upon a base Gaussian distribution. Then, we derive an ELBO loss from a variational perspective. In this way, the optimization process is aware of the target uncertainty and prevents the trained neural network from over-fitting to those randomness errors. Beyond that, when the testing image falls outside of the training range, we further enhance the performance by regarding the input as a weakly informative prior. Our main contributions are summarized as follows: • We identify in existing DM&DN datasets the ground truth uncertainty issues, manifesting themselves as various artifacts in the wild, such as zipper effect, color moire and residual noise. • We introduce a novel learning framework for joint demosaicking and denoising in the wild (Wild-JDD), where a two-stage data degradation and an ELBO loss are formulated for optimization. We also propose a simple but effective fine-tuning strategy for out-of-distribution input. • Instead of simply generating a demosaicked clean image, networks instantiated from our framework are capable of estimating all the parameters involved in data degradation and reconstruction, which provides better interpretability of the optimization process. • We conduct extensive experiments on both synthetic and realistic datasets. Quantitative and qualitative comparisons show that Wild-JDD substantially outperforms state-of-the-art works.",画像のデモザイキングとノイズ除去は、デジタルカメラパイプラインの2つの重要な基本ステップであり、ノイズの多い輝度の読み取り値からクリーンなカラー画像を再構築することを目的としています。この論文では、Wild-JDDを提案し、研究します。これは、野生での共同デモザイキングとノイズ除去のための新しい学習フレームワークです。トレーニングデータのグラウンドトゥルースが現実を完全に反映していると一般に想定している以前の作品とは対照的に、ここでは、野生のグラウンドトゥルースの不確実性のより一般的な不完全なケースを検討します。最初に、ジッパー効果、カラーモアレ、残留ノイズなど、さまざまな種類のアーティファクトとしてその兆候を示します。次に、2段階のデータ劣化プロセスを定式化して、このようなグラウンドトゥルースの不確実性をキャプチャします。ここで、共役事前分布が基本分布に課されます。その後、劣化した入力を条件とする共役事前分布のパラメーターを近似するニューラルネットワークをトレーニングするために、証拠の下限（ELBO）損失を導出します。最後に、分布外入力のパフォーマンスをさらに向上させるために、入力を情報量の少ない事前確率として使用することにより、単純で効果的な微調整戦略を設計します。グラウンドトゥルースの不確実性を考慮に入れると、Wild-JDDは最適化中に優れた解釈可能性を享受します。広範な実験により、合成および現実的な生データセットの両方で、共同のデモザイキングおよびノイズ除去タスクに関する最先端のスキームよりも優れていることが検証されています。はじめに最新のデジタルカメラは、カラーフィルターアレイ（CFA）でオーバーレイされた単一のセンサーを使用して画像をキャプチャします。これは、ピクセル位置ごとに1つのカラーチャネル値のみが記録されることを意味します。 Nを画像のピクセル数とすると、生データ収集プロセスはx = Az + nとして簡単にモデル化できます。（1）ここで、x Rは輝度測定値のノイズの多い生データベクトル、A RN3Nはモザイク操作、zです。 Rは3つのカラーチャネルを持つ未知のクリーンな画像であり、nRはノイズベクトルです。最終的に調理された画像がユーザーに提供される前に、生データは画像処理パイプラインと呼ばれる一連の処理ステップを経ます。それらの中で、デモザイッキングとノイズ除去（DM＆DN）は、非常に初期の2つであり、Copyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）です。全著作権所有。 （a）ジッパー効果。 （b）カラーモアレ。 （c）残留ノイズ。図1：不完全なグラウンドトゥルースの例（電子ズームインを推奨）:( a）ジッパー効果（エッジの周りの人工的なギザギザのパターン）に悩まされているCBSDデータセット（Arbelaez etal。2011）からのグラウンドトゥルース画像。 （b）ImageNetデータセットからの画像のカラーモアレ（Russakovsky et al.2015）。このようなアーティファクトは、補間エラーによる偽色として表示されます。 （c）Renoirデータセットから収集されたクリーンな画像の顕著な残留ノイズ（Anaya and Barbu 2018）。最も重要なステップ。デモザイキングは、各ピクセルのカラーチャネルの欠落している3分の2を補間することにより、モザイク化操作Aを元に戻すことを目的としています。一方、ノイズ除去は、測定値xから不可避のノイズnを除去します。それらのモジュール式の特性により、実質的な伝統的な文献はそれらを独立したタスクと見なし、順次実行します。これにより、パフォーマンスが最適化されない可能性があり、DM＆DNタスクに共同で取り組むためのいくつかの作業が促進されます（Liuetal。2020; Kokkinos and Lefkimmiatis 2019; Tan et al.2017a）。 DM＆DNの共同作業の中で、データ駆動型アプローチ（Liuetal。2020; Tanetal。2018; Kokkinos and Lefkimmiatis 2018）は、手作りの事前確率とフィルターを適用するよりも効果的であることが示されています。これらのアプローチは通常、ペアのデータのコレクションを必要とします。これは、モザイク化されたノイズの多い画像xとデモザイックされたクリーングラウンドトゥルースの対応物yです。ただし、高品質の実際のデータを大量に収集することは、多くの場合、コストと手間がかかります。さらに、収集されたyは、アーティファクトやノイズがなければ完全ではありません。これを図1に示します。デモザイキングの場合、多くのアプローチ（Syu、Chen、およびChuang 2018; Tan etal。2017b）は、カメラパイプラインからの出力をyとして受け取り、ジッパー効果やカラーモアレなどのアーティファクトをリッチな領域に導入する可能性がありますテクスチャと鋭いエッジ。ノイズ除去の場合、ar X iv：2 10 1. 04 44 2v 1 [cs .CV] 1 2 Ja n 20 21クリーンな画像は、lowISO（Plotz and Roth 2017; Anaya and Barbu 2018）を設定するか、平均化することによって収集されることがよくあります。同じシーン（Abdelhamed、Lin、Brown 2018）の繰り返しショットのセットで、まだ目立つノイズが含まれています。さらに、このようなノイズ除去データ収集プロセスは、通常、キャプチャされたオブジェクトが完全に静止していることを前提としているか、画像のバースト間で正確な空間アライメントと強度キャリブレーションを必要とします。潜在的な障害のケースは、収集されたデータセットに追加のエラーをもたらします。したがって、これらすべての現実的な問題は、グラウンドトゥルースyが必要な本物のzから逸脱し、DM＆DNモデルのパフォーマンスを制限することを意味します。収集されたグラウンドトゥルースyがzを完全に反映していないという事実を説明するために、グラウンドトゥルースの不確実性の下でのトレーニングを可能にする新しい共同デモサイキングおよびノイズ除去学習フレームワークであるWild-JDDを提案します。 WildJDDでは、最初に2段階のデータ劣化プロセスを定式化します。このプロセスでは、共役事前分布が基本ガウス分布に課されます。次に、変分法の観点からELBO損失を導き出します。このようにして、最適化プロセスはターゲットの不確実性を認識し、トレーニングされたニューラルネットワークがこれらのランダム性エラーに過剰適合するのを防ぎます。さらに、テスト画像がトレーニング範囲外にある場合、入力を情報量の少ない事前確率と見なすことで、パフォーマンスをさらに向上させます。私たちの主な貢献は次のように要約されます。既存のDM＆DNデータセットで、グラウンドトゥルースの不確実性の問題を特定し、ジッパー効果、カラーモアレ、残留ノイズなど、野生のさまざまなアーティファクトとして現れます。野生での共同デモザイキングとノイズ除去（Wild-JDD）のための新しい学習フレームワークを紹介します。ここでは、最適化のために2段階のデータ劣化とELBO損失が定式化されます。また、配布外の入力に対して、シンプルで効果的な微調整戦略を提案します。フレームワークからインスタンス化されたネットワークは、デモザイクされたクリーンな画像を単に生成するのではなく、データの劣化と再構築に関連するすべてのパラメーターを推定できるため、最適化プロセスの解釈が容易になります。合成データセットと現実的なデータセットの両方で広範な実験を行っています。定量的および定性的な比較は、Wild-JDDが最先端の作品を大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/2396a969d45b13072526758f8a3cb6bc119631b6/1-Figure1-1.png
Learning to Resolve Conflicts for Multi-Agent Path Finding with Conflict-Based Search,"['Taoan Huang', 'Sven Koenig', 'Bistra Dilkina']",https://arxiv.org/abs/2012.06005,"Conflict-Based Search (CBS) is a state-of-the-art algorithm for multi-agent path finding. At the high level, CBS repeatedly detects conflicts and resolves one of them by splitting the current problem into two subproblems. Previous work chooses the conflict to resolve by categorizing the conflict into three classes and always picking a conflict from the highest-priority class. In this work, we propose an oracle for conflict selection that results in smaller search tree sizes than the one used in previous work. However, the computation of the oracle is slow. Thus, we propose a machine-learning framework for conflict selection that observes the decisions made by the oracle and learns a conflict-selection strategy represented by a linear ranking function that imitates the oracle's decisions accurately and quickly. Experiments on benchmark maps indicate that our method significantly improves the success rates, the search tree sizes and runtimes over the current state-of-the-art CBS solver.",競合ベースの検索（CBS）は、マルチエージェントパス検索のための最先端のアルゴリズムです。高レベルでは、CBSは競合を繰り返し検出し、現在の問題を2つのサブ問題に分割することで競合の1つを解決します。前の作業では、競合を3つのクラスに分類し、常に最も優先度の高いクラスから競合を選択することにより、解決する競合を選択します。この作業では、前の作業で使用したものよりも検索ツリーのサイズが小さくなる競合選択のオラクルを提案します。ただし、オラクルの計算は遅いです。したがって、オラクルによって行われた決定を観察し、オラクルの決定を正確かつ迅速に模倣する線形ランキング関数によって表される競合選択戦略を学習する、競合選択のための機械学習フレームワークを提案します。ベンチマークマップでの実験は、私たちの方法が現在の最先端のCBSソルバーよりも成功率、検索ツリーのサイズ、および実行時間を大幅に改善することを示しています。,https://d3i71xaburhd42.cloudfront.net/c6a24e9ef8d78128c78406dd33597ad080ce2772/5-Figure1-1.png
Correlative Channel-Aware Fusion for Multi-View Time Series Classification,"['Yue Bai', 'Lichen Wang', 'Zhiqiang Tao', 'Sheng Li', 'Yun Fu']",,,,
GAN Ensemble for Anomaly Detection,"['Xiaohui Chen', 'Xu Han', 'Liping Liu']",,,,
Self-Supervised Hypergraph Convolutional Networks for Session-Based Recommendation,"['Xin Xia', 'Hongzhi Yin', 'Junliang Yu', 'Qinyong Wang', 'Lizhen Cui', 'Xiangliang Zhang']",https://arxiv.org/abs/2012.06852,"Session-based recommendation (SBR) focuses on next-item prediction at a certain time point. As user profiles are generally not available in this scenario, capturing the user intent lying in the item transitions plays a pivotal role. Recent graph neural networks (GNNs) based SBR methods regard the item transitions as pairwise relations, which neglect the complex high-order information among items. Hypergraph provides a natural way to capture beyond-pairwise relations, while its potential for SBR has remained unexplored. In this paper, we fill this gap by modeling session-based data as a hypergraph and then propose a dual channel hypergraph convolutional network -- DHCN to improve SBR. Moreover, to enhance hypergraph modeling, we innovatively integrate self-supervised learning into the training of our network by maximizing mutual information between the session representations learned via the two channels in DHCN, serving as an auxiliary task to improve the recommendation task. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over the SOTA methods, and the ablation study validates the effectiveness and rationale of hypergraph modeling and self-supervised task. The implementation of our model is available via this https URL.",セッションベースの推奨（SBR）は、特定の時点での次のアイテムの予測に焦点を当てています。このシナリオでは通常、ユーザープロファイルを使用できないため、アイテムの遷移にあるユーザーの意図を把握することが極めて重要な役割を果たします。最近のグラフニューラルネットワーク（GNN）ベースのSBRメソッドは、アイテムの遷移をペアワイズ関係と見なし、アイテム間の複雑な高次情報を無視します。ハイパーグラフは、ペアワイズを超えた関係をキャプチャする自然な方法を提供しますが、SBRの可能性は未踏のままです。この論文では、セッションベースのデータをハイパーグラフとしてモデル化することでこのギャップを埋め、SBRを改善するためのデュアルチャネルハイパーグラフ畳み込みネットワークDHCNを提案します。さらに、ハイパーグラフモデリングを強化するために、DHCNの2つのチャネルを介して学習したセッション表現間の相互情報量を最大化することにより、自己教師あり学習をネットワークのトレーニングに革新的に統合し、推奨タスクを改善するための補助タスクとして機能します。 3つのベンチマークデータセットでの広範な実験は、SOTAメソッドに対するモデルの優位性を示しており、アブレーション研究は、ハイパーグラフモデリングと自己監視タスクの有効性と理論的根拠を検証します。モデルの実装は、このhttpsURLから入手できます。,https://d3i71xaburhd42.cloudfront.net/51d300555e4ade0af9659a54edb3b278bf3f9052/3-Figure1-1.png
Post-training Quantization with Multiple Points: Mixed Precision without Mixed Precision,"['Xingchao Liu', 'Mao Ye', 'Denny Zhou', 'Qiang Liu']",https://arxiv.org/abs/2002.09049,"We consider the post-training quantization problem, which discretizes the weights of pre-trained deep neural networks without re-training the model. We propose multipoint quantization, a quantization method that approximates a full-precision weight vector using a linear combination of multiple vectors of low-bit numbers; this is in contrast to typical quantization methods that approximate each weight using a single low precision number. Computationally, we construct the multipoint quantization with an efficient greedy selection procedure, and adaptively decides the number of low precision points on each quantized weight vector based on the error of its output. This allows us to achieve higher precision levels for important weights that greatly influence the outputs, yielding an 'effect of mixed precision' but without physical mixed precision implementations (which requires specialized hardware accelerators). Empirically, our method can be implemented by common operands, bringing almost no memory and computation overhead. We show that our method outperforms a range of state-of-the-art methods on ImageNet classification and it can be generalized to more challenging tasks like PASCAL VOC object detection.",モデルを再トレーニングせずに、事前にトレーニングされた深層ニューラルネットワークの重みを離散化するトレーニング後の量子化問題を検討します。低ビット数の複数のベクトルの線形結合を使用して全精度の重みベクトルを近似する量子化方法であるマルチポイント量子化を提案します。これは、単一の低精度の数値を使用して各重みを概算する一般的な量子化方法とは対照的です。計算上、効率的な欲張り選択手順を使用して多点量子化を構築し、出力の誤差に基づいて、量子化された各重みベクトル上の低精度点の数を適応的に決定します。これにより、出力に大きな影響を与える重要な重みに対してより高い精度レベルを達成でき、物理的な混合精度の実装（特殊なハードウェアアクセラレータが必要）なしで、混合精度の効果が得られます。経験的に、私たちの方法は共通のオペランドで実装でき、メモリと計算のオーバーヘッドはほとんどありません。私たちの方法は、ImageNet分類に関する一連の最先端の方法よりも優れており、PASCALVOCオブジェクト検出などのより困難なタスクに一般化できることを示しています。,https://d3i71xaburhd42.cloudfront.net/9d21f01e08ee928130f41d378746a14ca2cdfdf3/2-Figure1-1.png
Longitudinal Deep Kernel Gaussian Process Regression,"['Junjie Liang', 'Yanting Wu', 'Dongkuan Xu', 'Vasant G Honavar']",https://arxiv.org/abs/2005.11770,"Gaussian processes offer an attractive framework for predictive modeling from longitudinal data, i.e., irregularly sampled, sparse observations from a set of individuals over time. However, such methods have two key shortcomings: (i) They rely on ad hoc heuristics or expensive trial and error to choose the effective kernels, and (ii) They fail to handle multilevel correlation structure in the data. We introduce Longitudinal deep kernel Gaussian process regression (L-DKGPR), which to the best of our knowledge, is the only method to overcome these limitations by fully automating the discovery of complex multilevel correlation structure from longitudinal data. Specifically, L-DKGPR eliminates the need for ad hoc heuristics or trial and error using a novel adaptation of deep kernel learning that combines the expressive power of deep neural networks with the flexibility of non-parametric kernel methods. L-DKGPR effectively learns the multilevel correlation with a novel addictive kernel that simultaneously accommodates both time-varying and the time-invariant effects. We derive an efficient algorithm to train L-DKGPR using latent space inducing points and variational inference. Results of extensive experiments on several benchmark data sets demonstrate that L-DKGPR significantly outperforms the state-of-the-art longitudinal data analysis (LDA) methods.",ガウス過程は、縦断的データからの予測モデリング、つまり、時間の経過に伴う一連の個人からの不規則にサンプリングされたまばらな観測のための魅力的なフレームワークを提供します。ただし、このような方法には2つの重要な欠点があります。（i）効果的なカーネルを選択するためにアドホックヒューリスティックまたは費用のかかる試行錯誤に依存し、（ii）データ内のマルチレベル相関構造を処理できません。縦断的ディープカーネルガウス過程回帰（L-DKGPR）を紹介します。これは、私たちの知る限り、縦断的データからの複雑なマルチレベル相関構造の発見を完全に自動化することによってこれらの制限を克服する唯一の方法です。具体的には、L-DKGPRは、ディープニューラルネットワークの表現力とノンパラメトリックカーネル法の柔軟性を組み合わせたディープカーネル学習の新しい適応を使用して、アドホックヒューリスティックや試行錯誤の必要性を排除します。 L-DKGPRは、時不変効果と時不変効果の両方に同時に対応する、新しい中毒性のあるカーネルとのマルチレベル相関を効果的に学習します。潜在空間誘導点と変分推論を使用してL-DKGPRをトレーニングするための効率的なアルゴリズムを導出します。いくつかのベンチマークデータセットでの広範な実験の結果は、L-DKGPRが最先端の縦断的データ分析（LDA）手法を大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/8e94f990bdb7e40dbb41ab6cb5ea2cf613a23bf4/3-Figure1-1.png
Generalized Adversarially Learned Inference,"['Yatin Dandi', 'Homanga Bharadhwaj', 'Abhishek Kumar', 'Piyush Rai']",,"Allowing effective inference of latent vectors while training GANs can greatly increase their applicability in various downstream tasks. Recent approaches, such as ALI and BiGAN frameworks, develop methods of inference of latent variables in GANs by adversarially training an image generator along with an encoder to match two joint distributions of image and latent vector pairs. We generalize these approaches to incorporate multiple layers of feedback on reconstructions, self-supervision, and other forms of supervision based on prior or learned knowledge about the desired solutions. We achieve this by modifying the discriminator's objective to correctly identify more than two joint distributions of tuples of an arbitrary number of random variables consisting of images, latent vectors, and other variables generated through auxiliary tasks, such as reconstruction and inpainting or as outputs of suitable pre-trained models. We design a non-saturating maximization objective for the generator-encoder pair and prove that the resulting adversarial game corresponds to a global optimum that simultaneously matches all the distributions. Within our proposed framework, we introduce a novel set of techniques for providing self-supervised feedback to the model based on properties, such as patch-level correspondence and cycle consistency of reconstructions. Through comprehensive experiments, we demonstrate the efficacy, scalability, and flexibility of the proposed approach for a variety of tasks.",GANのトレーニング中に潜在ベクトルの効果的な推論を可能にすると、さまざまなダウンストリームタスクでの適用性を大幅に高めることができます。 ALIやBiGANフレームワークなどの最近のアプローチでは、画像と潜在ベクトルのペアの2つの同時分布に一致するように、エンコーダとともに画像ジェネレータを敵対的にトレーニングすることにより、GANの潜在変数を推論する方法を開発しています。これらのアプローチを一般化して、再構築、自己監視、および目的のソリューションに関する事前または学習済みの知識に基づく他の形式の監視に関するフィードバックの複数のレイヤーを組み込みます。これは、画像、潜在ベクトル、および再構成や修復などの補助タスクを通じて、または適切な出力として生成されたその他の変数で構成される任意の数の確率変数のタプルの3つ以上の同時分布を正しく識別するように弁別子の目的を変更することによって実現します。事前トレーニング済みモデル。ジェネレーターとエンコーダーのペアの非飽和最大化目標を設計し、結果として得られる敵対的なゲームが、すべての分布に同時に一致するグローバル最適化に対応することを証明します。提案されたフレームワーク内で、パッチレベルの対応や再構成のサイクルの一貫性などのプロパティに基づいて、モデルに自己監視フィードバックを提供するための新しい一連の手法を紹介します。包括的な実験を通じて、さまざまなタスクに対して提案されたアプローチの有効性、スケーラビリティ、および柔軟性を示します。,
Spectral Distribution Aware Image Generation,"['Steffen Jung', 'Margret Keuper']",https://arxiv.org/abs/2012.03110,"Recent advances in deep generative models for photo-realistic images have led to high quality visual results. Such models learn to generate data from a given training distribution such that generated images can not be easily distinguished from real images by the human eye. Yet, recent work on the detection of such fake images pointed out that they are actually easily distinguishable by artifacts in their frequency spectra. In this paper, we propose to generate images according to the frequency distribution of the real data by employing a spectral discriminator. The proposed discriminator is lightweight, modular and works stably with different commonly used GAN losses. We show that the resulting models can better generate images with realistic frequency spectra, which are thus harder to detect by this cue.",フォトリアリスティックな画像の深い生成モデルの最近の進歩により、高品質の視覚的結果が得られています。このようなモデルは、生成された画像を人間の目で実際の画像と簡単に区別できないように、特定のトレーニング分布からデータを生成することを学習します。しかし、そのような偽の画像の検出に関する最近の研究は、それらが周波数スペクトルのアーティファクトによって実際に容​​易に区別できることを指摘しました。本論文では、スペクトル弁別器を用いて実データの頻度分布に従って画像を生成することを提案した。提案された弁別器は軽量でモジュール式であり、一般的に使用されるさまざまなGAN損失に対して安定して機能します。結果として得られるモデルは、現実的な周波数スペクトルを使用して画像をより適切に生成できることを示します。このため、このキューでは検出が困難です。,
DAST: Unsupervised Domain Adaptation in Semantic Segmentation Based on Discriminator Attention and Self-Training,"['Fei Yu', 'Mo Zhang', 'Hexin Dong', 'Sheng Hu', 'Bin Dong', 'Li Zhang']",,,,
On Scalar Embedding of Relative Positions in Attention Models,"['Junshuang Wu', 'Richong Zhang', 'Yongyi Mao', 'Junfan Chen']",,,,
I3DOL: Incremental 3D Object Learning without Catastrophic Forgetting,"['Jiahua Dong', 'Yang Cong', 'Gan Sun', 'Bingtao Ma', 'Lichen Wang']",https://arxiv.org/abs/2012.09014,"3D object classification has attracted appealing attentions in academic researches and industrial applications. However, most existing methods need to access the training data of past 3D object classes when facing the common real-world scenario: new classes of 3D objects arrive in a sequence. Moreover, the performance of advanced approaches degrades dramatically for past learned classes (i.e., catastrophic forgetting), due to the irregular and redundant geometric structures of 3D point cloud data. To address these challenges, we propose a new Incremental 3D Object Learning (i.e., I3DOL) model, which is the first exploration to learn new classes of 3D object continually. Specifically, an adaptive-geometric centroid module is designed to construct discriminative local geometric structures, which can better characterize the irregular point cloud representation for 3D object. Afterwards, to prevent the catastrophic forgetting brought by redundant geometric information, a geometric-aware attention mechanism is developed to quantify the contributions of local geometric structures, and explore unique 3D geometric characteristics with high contributions for classes incremental learning. Meanwhile, a score fairness compensation strategy is proposed to further alleviate the catastrophic forgetting caused by unbalanced data between past and new classes of 3D object, by compensating biased prediction for new classes in the validation phase. Experiments on 3D representative datasets validate the superiority of our I3DOL framework.",3Dオブジェクト分類は、学術研究や産業用途で魅力的な注目を集めています。ただし、ほとんどの既存のメソッドは、一般的な現実のシナリオに直面したときに、過去の3Dオブジェクトクラスのトレーニングデータにアクセスする必要があります。3Dオブジェクトの新しいクラスが順番に到着します。さらに、高度なアプローチのパフォーマンスは、3D点群データの不規則で冗長な幾何学的構造のために、過去に学習したクラス（つまり、壊滅的な忘却）では劇的に低下します。これらの課題に対処するために、新しいインクリメンタル3Dオブジェクト学習（つまり、I3DOL）モデルを提案します。これは、3Dオブジェクトの新しいクラスを継続的に学習する最初の調査です。具体的には、適応幾何学的重心モジュールは、3Dオブジェクトの不規則な点群表現をより適切に特徴付けることができる識別可能な局所幾何学的構造を構築するように設計されています。その後、冗長な幾何学的情報によってもたらされる壊滅的な忘却を防ぐために、幾何学的な注意メカニズムが開発され、局所的な幾何学的構造の寄与を定量化し、クラスの増分学習に大きく寄与する独自の3D幾何学的特性を探索します。一方、スコアの公平性補償戦略は、検証フェーズで新しいクラスの偏った予測を補償することにより、3Dオブジェクトの過去と新しいクラス間の不均衡なデータによって引き起こされる壊滅的な忘却をさらに軽減するために提案されます。 3Dの代表的なデータセットでの実験により、I3DOLフレームワークの優位性が検証されます。,https://d3i71xaburhd42.cloudfront.net/e175fbed816f04a36030f53b0ce926a1f4f47ac9/1-Figure1-1.png
Embedding Heterogeneous Networks into Hyperbolic Space without Meta-Path,"['Lili Wang', 'Chongyang Gao', 'Chenghan Huang', 'Ruibo Liu', 'Weicheng Ma', 'Soroush Vosoughi']",,,,
Anomaly Attribution with Likelihood Compensation,"['Tsuyoshi Ide', 'Amit Dhurandhar', 'Jiri Navratil', 'Moninder Singh', 'Naoki Abe']",,,,
Gradient Descent Averaging and Primal-Dual Averaging for Strongly Convex Optimization,"['Wei Tao', 'Wei Li', 'Zhisong Pan', 'Qing Tao']",https://arxiv.org/abs/2012.14558,"Averaging scheme has attracted extensive attention in deep learning as well as traditional machine learning. It achieves theoretically optimal convergence and also improves the empirical model performance. However, there is still a lack of sufficient convergence analysis for strongly convex optimization. Typically, the convergence about the last iterate of gradient descent methods, which is referred to as individual convergence, fails to attain its optimality due to the existence of logarithmic factor. In order to remove this factor, we first develop gradient descent averaging (GDA), which is a general projection-based dual averaging algorithm in the strongly convex setting. We further present primal-dual averaging for strongly convex cases (SC-PDA), where primal and dual averaging schemes are simultaneously utilized. We prove that GDA yields the optimal convergence rate in terms of output averaging, while SC-PDA derives the optimal individual convergence. Several experiments on SVMs and deep learning models validate the correctness of theoretical analysis and effectiveness of algorithms. Introduction Averaging scheme has been widely adopted from different angles. It always helps to reduce variance and improve generalization of learning algorithms. In fact, there exist various averaging techniques, such as dual averaging (DA) (Nesterov 2009), weight averaging (WA) (Izmailov et al. 2018), output averaging (OA) (Nemirovsky and Yudin 1983; Polyak and Juditsky 1992), primal averaging (PA) (Nesterov and Shikhman 2015; Tao et al. 2020), etc. DA was initially proposed by Nesterov (Nesterov 2009), which averages all past gradient information at each iteration. In comparison with gradient descent (GD) and mirror descent (MD) (Beck and Teboulle 2003), it avoids new gradients to be considered with less weight than previous ones (Flammarion and Bach 2017). DA has been successfully extended to the stochastic composite scenario and it’s well-suited for large-scale learning problems (Xiao 2009; Dekel et al. 2012). The superiority of regularized dual averaging (RDA) in efficiently promoting regularizer structure (e.g., sparsity) has been elaborated by Xiao and also earned test of time award at NeurIPS (Xiao 2009). *Corresponding authors Recently, averaging has also been frequently employed in training deep neural networks. WA averages weights of the networks based on training epochs (Izmailov et al. 2018). Since then, a series of contribution: SWALP (Yang et al. 2019), Fast-SWA (Athiwaratkun et al. 2018), SWA-Guassian (Maddox et al. 2019) have been successfully applied to a wide range of applications. Besides, exponential moving average (EMA), which has been used to exponentially decay the weights for previous iterate, can be regarded as a particular example of WA (Kingma and Ba 2014; Reddi, Kale, and Kumar 2019; Ma and Yarats 2018). OA is a classical way about how to output the final solution for iterative algorithms. Existing convergence analyses mostly center on it due to some superior theoretical guarantees (Dimitri P., Angelia., and Asuman E. 2003). Actually, running algorithms for t iterations, and returning the last iterate, is a very intuitive idea in practice. Therefore, there are still some gaps about individual output between theoretical analyses and practical implementations. Several works on stochastic gradient descent (SGD) develop different OA techniques to achieve the optimal convergence rate, especially for strongly convex optimization, such as suffix averaging (Rakhlin, Shamir, and Sridharan 2011), non-uniform averaging (Lacoste-Julien, Schmidt, and Bach 2012; Harvey, Liaw, and Randhawa 2019), increasing weighted averaging (Guo et al. 2020), etc. The optimal convergence for strongly convex problems has become a challenging problem after the well-known work (Hazan et al. 2006). This is because conventional SGD cannot attain the optimal convergence even when we take the uniform average of all past iterates. An open question early posed by (Shamir 2012) is that whether OA is needed at all to attain optimal convergence rate. Partially addressing this question, Shamir et al. (Shamir and Zhang 2013) showed that SGD with polynomial-decay averaging has an O(log t/ √ t) individual convergence rate in the general strongly convex cases and anO(log t/t) rate in strongly convex cases, respectively. Recent works (Harvey et al. 2019; Jain, Nagaraj, and Netrapalli 2019) provide the affirmative answer that the logarithmic term in the convergence bound is necessary for any plain SGD in both general convex and strongly convex cases. However, they leave us a new challenging problem. Can we achieve the optimal rate of O(1/t) by slightly modifying any classical algorithms? From these observations, there are mainly two ways to achieve the optimal rate without the logarithmic factor. One is to modify the original steps of the algorithms. The other is to employ the averaging strategy. PA is an interesting gradient operation step, in which the gradient evaluation is imposed on the weighted average of all past iterative solutions (Tao et al. 2020). In fact, this averaging scheme was first used in PDA (Nesterov and Shikhman 2015), which exploits simultaneously in both primal and dual space per-iteration, and succeeds in deriving the optimal individual rate for minimizing non-smooth general convex objectives. Later, (Tao et al. 2020) formally named it as PA, and they focus on projected subgradient (PSG) method. Its individual convergence rate doesn’t suffer from the extra logarithmic factor. Overall, PDA is the closest solution to eliminate the log t factor about DA. Unfortunately, (Nesterov and Shikhman 2015) partially addressed the optimal convergence problem only in the general convex scenario. Optimal-RDA (Chen, Lin, and Pena 2012) proposed earlier than PDA, requires two gradient operations per-iteration, which is different from conventional DA with only one operation. Similarly, (Cutkosky 2019) and (Joulani et al. 2020) add an auxiliary PA scheme into their algorithms, which are able to achieve the optimal regret bound in the online setting. This paper is motivated by the breakthrough work of (Nesterov and Shikhman 2015). Our original intention is to derive the optimal individual convergence of DA with minor changes in gradient operations. The main contributions can be summarized as follows: • We present a general GDA algorithm, which includes the strongly convex algorithm in (Cutkosky 2019) as one special case of our method. Our GDA gains a deeper insight into the connection between DA and GD. Moreover, we prove that this algorithm no longer suffers from the logarithmic factor and attains the optimal convergence rate O(1/t) coupled with OA. • We incorporate PA into GDA, and develop a novel SCPDA algorithm so as to achieve optimal individual convergence rate O(1/t). Moreover, our convergence analysis of SC-PDA is obviously different from Nesterov’s PDA. Thus, our work theoretically completes the task about individual convergence of DA under different convexity situations. Preliminaries and Notations Many convex optimization algorithms in machine learning can be formulated as a constrained black-box problem: min f(w), s.t. w ∈ Q. (1) where Q is a bounded convex domain, and f (·) is a convex function on Q. Denote that w∗ is an optimal solution. We use ∇f(w) to denote the (sub)gradient of f at w and ĝ is an unbiased estimate of (sub)gradient of f at w. Following (Shamir and Zhang 2013), we first provide the definitions of strong convexity, individual convergence, and averaged convergence. Definition 1. A function f is called μ-strongly convex with respect to the norm ‖ · ‖ if there is a constant μ > 0 such that f(w) ≥ f(u) + 〈∇f(u),w − u〉+ μ 2 ‖w− u‖, (2) for all u,w. Note that the strong convexity parameter μ is a measure of the curvature of f , 〈·, ·〉 stands for the Euclidean inner product, and the quadratic lower bound in (2) can be also satisfied with μ = 0 for a convex function. Generally, the convergence about the last iterate is often referred to as individual convergence for simplicity (Tao et al. 2020). Definition 2. Given a convex function f , let {wt}t>0 be generated by optimization algorithms, the individual convergence is defined as f(wt)− f(w∗) ≤ ǫ(t). (3) Definition 3. Given a convex function f with uniform averaged output w̄t = 1 t ∑t i=1 wi, let wt be generated by optimization algorithms, we can define averaged convergence as f(w̄t)− f(w∗) ≤ ǫ(t). (4) The convergence bound ǫ is related to t. In particular, the optimal bound is O(1/ √ t) in the non-smooth convex cases and O(1/t) in the strongly convex cases, respectively (Nesterov 1983; Nemirovsky and Yudin 1983). Related Work In this section, we briefly review some related algorithms and their convergence rates. PSG is one of the most fundamental algorithms for solving (1), and the iteration of which is, wt+1 = P [wt − at∇f(wt)], (5) where P is the projection operator on Q, at > 0 is the stepsize parameter. More generally, mirror descent (MD) is a direct extension of the PSG by using a mirror map, and it iterates as follows, wt+1 = arg min w∈Q {at〈∇f(wt),w〉 +B(w,wt)}, (6) where t > 0, B is the Bregman divergence. MD recovers PSG by taking 1 2 ‖w−wt‖. Based on MD, DA is also a powerful first-order gradient algorithm (Nesterov 2009). The standard DA updates the solution according to wt+1 = arg min w∈Q { t",平均化スキームは、従来の機械学習だけでなく、ディープラーニングでも大きな注目を集めています。理論的に最適な収束を実現し、経験的なモデルのパフォーマンスも向上させます。ただし、強力な凸最適化のための十分な収束分析がまだ不足しています。通常、最急降下法の最後の反復に関する収束は、個々の収束と呼ばれ、対数因子が存在するため、その最適性を達成できません。この要因を取り除くために、最初に勾配降下平均（GDA）を開発します。これは、強凸の設定での一般的な投影ベースの二重平均アルゴリズムです。さらに、プライマルとデュアルの平均化スキームが同時に利用される、強く凸状のケース（SC-PDA）のプライマル-デュアル平均化を示します。 GDAが出力平均の観点から最適な収束率をもたらすのに対し、SC-PDAは最適な個々の収束をもたらすことを証明します。 SVMと深層学習モデルに関するいくつかの実験は、理論的分析の正確さとアルゴリズムの有効性を検証します。はじめに平均化スキームは、さまざまな角度から広く採用されています。それは常に分散を減らし、学習アルゴリズムの一般化を改善するのに役立ちます。実際、二重平均（DA）（Nesterov 2009）、重み平均（WA）（Izmailov etal。2018）、出力平均（OA）（Nemirovsky and Yudin 1983; Polyak and Juditsky 1992）などのさまざまな平均手法が存在します。 、主平均（PA）（Nesterov and Shikhman 2015; Tao etal。2020）など。DAは当初Nesterov（Nesterov 2009）によって提案され、各反復で過去のすべての勾配情報を平均します。最急降下法（GD）および最急降下法（MD）（Beck and Teboulle 2003）と比較して、以前の勾配よりも軽い重みで新しい勾配が考慮されることを回避します（Flammarion and Bach2017）。 DAは確率的複合シナリオにうまく拡張されており、大規模な学習問題に最適です（Xiao 2009; Dekel et al.2012）。正則化構造（スパース性など）を効率的に促進する上での正則化二重平均化（RDA）の優位性は、Xiaoによって詳しく説明されており、NeurIPSで時間テスト賞を受賞しています（Xiao2009）。 *対応する著者最近、平均化はディープニューラルネットワークのトレーニングにも頻繁に使用されています。 WAは、トレーニングエポックに基づいてネットワークの重みを平均します（Izmailov et al.2018）。それ以来、一連の貢献：SWALP（Yang etal。2019）、Fast-SWA（Athiwaratkun etal。2018）、SWA-Guassian（Maddox etal。2019）は、幅広いアプリケーションに正常に適用されています。さらに、以前の反復の重みを指数関数的に減衰させるために使用された指数移動平均（EMA）は、WAの特定の例と見なすことができます（Kingma and Ba 2014; Reddi、Kale、and Kumar 2019; Ma and Yarats 2018） 。 OAは、反復アルゴリズムの最終的なソリューションを出力する方法に関する古典的な方法です。既存の収束分析は、いくつかの優れた理論的保証のために、ほとんどがそれに集中しています（Dimitri P.、Angelia。、およびAsuman E.2003）。実際、t回の反復でアルゴリズムを実行し、最後の反復を返すことは、実際には非常に直感的なアイデアです。したがって、理論的分析と実際の実装の間には、個々の出力についてまだいくつかのギャップがあります。確率的勾配降下法（SGD）に関するいくつかの研究では、最適な収束率を達成するために、特に接尾辞平均（Rakhlin、Shamir、およびSridharan 2011）、不均一平均（Lacoste-Julien、Schmidt）などの強い凸最適化のためにさまざまなOA手法を開発しています、およびBach 2012; Harvey、Liaw、およびRandhawa 2019）、加重平均の増加（Guo etal。2020）など。強く凸の問題の最適収束は、よく知られた研究（Hazan etal。 2006）。これは、過去のすべての反復の均一な平均​​を取っても、従来のSGDでは最適な収束を達成できないためです。 （Shamir 2012）によって初期に提起された未解決の質問は、最適な収束率を達成するためにOAがまったく必要かどうかということです。この質問に部分的に対処する、Shamir等。 （Shamir and Zhang 2013）は、多項式減衰平均を使用したSGDは、一般的な強凸の場合にO（log t /√t）の個別収束率、強凸の場合にそれぞれO（log t / t）率を持つことを示しました。最近の研究（Harveyetal。2019; Jain、Nagaraj、and Netrapalli 2019）は、一般的な凸型と強凸型の両方の単純なSGDには、収束限界の対数項が必要であるという肯定的な答えを提供しています。しかし、それらは私たちに新たな挑戦的な問題を残します。古典的なアルゴリズムを少し変更することで、O（1 / t）の最適なレートを達成できますか？これらの観察から、対数係数なしで最適なレートを達成するための主に2つの方法があります。 1つは、アルゴリズムの元のステップを変更することです。もう1つは、平均化戦略を採用することです。 PAは興味深い勾配操作ステップであり、過去のすべての反復解の加重平均に勾配評価が課されます（Tao et al.2020）。実際、この平均化スキームはPDA（Nesterov and Shikhman 2015）で最初に使用されました。これは、主空間と双対空間の両方の反復で同時に活用し、滑らかでない一般的な凸型の目的を最小化するための最適な個別レートを導出することに成功します。その後、（Tao etal。2020）正式にPAと名付けられ、彼らは射影劣勾配（PSG）法に焦点を合わせています。その個々の収束率は、余分な対数係数の影響を受けません。全体として、PDAはDAに関するlogtファクターを排除するための最も近いソリューションです。残念ながら、（Nesterov and Shikhman 2015）は、一般的な凸型シナリオでのみ最適な収束問題に部分的に対処しました。 PDAより前に提案されたOptimal-RDA（Chen、Lin、およびPena 2012）は、反復ごとに2つの勾配操作を必要とします。これは、1つの操作のみの従来のDAとは異なります。同様に、（Cutkosky 2019）と（Joulani etal。2020）は、アルゴリズムに補助PAスキームを追加します。これにより、オンライン設定で最適な後悔を実現できます。この論文は、（Nesterov and Shikhman 2015）の画期的な研究に動機付けられています。私たちの当初の意図は、勾配操作を少し変更して、DAの最適な個々の収束を導き出すことです。主な貢献は次のように要約できます。•一般的なGDAアルゴリズムを示します。これには、（Cutkosky 2019）の強凸アルゴリズムがメソッドの特殊なケースの1つとして含まれています。私たちのGDAは、DAとGDの関係についてより深い洞察を得ています。さらに、このアルゴリズムが対数係数の影響を受けなくなり、OAと組み合わせて最適な収束率O（1 / t）を達成することを証明します。 •PAをGDAに組み込み、最適な個別収束率O（1 / t）を達成するために新しいSCPDAアルゴリズムを開発します。さらに、SC-PDAの収束分析は、ネステロフのPDAとは明らかに異なります。したがって、私たちの仕事は、理論的には、さまざまな凸面の状況下でのDAの個々の収束に関するタスクを完了します。予備知識と表記法機械学習の多くの凸最適化アルゴリズムは、制約付きブラックボックス問題として定式化できます。minf（w）、stw∈Q。（1）ここで、Qは有界凸領域、f（・）はQの凸関数。w∗が最適解であることを示します。 ∇f（w）を使用してwでのfの（劣）勾配を示し、ĝはwでのfの（劣）勾配の不偏推定です。 （Shamir and Zhang 2013）に続いて、最初に強い凸性、個々の収束、および平均収束の定義を提供します。定義1.関数fはμと呼ばれます-f（w）≥f（u）+ 〈∇f（u）、w − uとなるような定数μ&gt; 0がある場合、ノルム‖・‖に対して強く凸です。 〉 + μ2‖w−u‖、（2）すべてのu、w。強い凸性パラメーターμはfの曲率の尺度であり、〈・、・〉はユークリッド内積を表し、（2）の2次下限も凸関数のμ= 0で満たすことができることに注意してください。一般に、最後の反復に関する収束は、単純化のために個別収束と呼ばれることがよくあります（Tao et al.2020）。定義2.凸関数fが与えられた場合、最適化アルゴリズムによって{wt} t&gt; 0が生成されるとすると、個々の収束はf（wt）− f（w ∗）≤ǫ（t）として定義されます。 （3）定義3.均一な平均​​出力w̄t= 1 t ∑ti = 1 wiの凸関数fが与えられ、wtが最適化アルゴリズムによって生成されるとすると、平均収束をf（w̄t）− f（w ∗）≤として定義できます。 ǫ（t）。 （4）収束限界ǫはtに関連しています。特に、最適な境界は、滑らかでない凸の場合はO（1 /√t）、強く凸の場合はO（1 / t）です（Nesterov 1983; Nemirovsky and Yudin1983）。関連作業このセクションでは、いくつかの関連アルゴリズムとそれらの収束率を簡単に確認します。 PSGは、（1）を解くための最も基本的なアルゴリズムの1つであり、その反復は、wt + 1 = P [wt −at∇f（wt）]、（5）です。ここで、PはQの射影演算子です。 &gt; 0はstepsizeパラメーターです。より一般的には、ミラー降下（MD）は、ミラーマップを使用したPSGの直接拡張であり、次のように繰り返されます。wt+ 1 =argminw∈Q{at &lt;∇f（wt）、w&gt; + B（ w、wt）}、（6）ここで、t&gt; 0、Bはブレグマン発散です。 MDは12‖w−wt‖を取ることによってPSGを回復します。 MDに基づくDAは、強力な1次勾配アルゴリズムでもあります（Nesterov2009）。標準DAは、wt + 1 =argminw∈Q{tに従って解を更新します。,https://d3i71xaburhd42.cloudfront.net/09fac8aae6e8a1238dfdd72f4a8b8947f719b520/7-Figure1-1.png
Cascade Network with Guided Loss and Hybrid Attention for Finding Good Correspondences,"['Zhi Chen', 'Fan Yang', 'Wenbing Tao']",https://arxiv.org/abs/2102.00411,"Finding good correspondences is a critical prerequisite in many feature based tasks. Given a putative correspondence set of an image pair, we propose a neural network which finds correct correspondences by a binary-class classifier and estimates relative pose through classified correspondences. First, we analyze that due to the imbalance in the number of correct and wrong correspondences, the loss function has a great impact on the classification results. Thus, we propose a new Guided Loss that can directly use evaluation criterion (Fn-measure) as guidance to dynamically adjust the objective function during training. We theoretically prove that the perfect negative correlation between the Guided Loss and Fnmeasure, so that the network is always trained towards the direction of increasing Fn-measure to maximize it. We then propose a hybrid attention block to extract feature, which integrates the Bayesian attentive context normalization (BACN) and channel-wise attention (CA). BACN can mine the prior information to better exploit global context and CA can capture complex channel context to enhance the channel awareness of the network. Finally, based on our Guided Loss and hybrid attention block, a cascade network is designed to gradually optimize the result for more superior performance. Experiments have shown that our network achieves the state-ofthe-art performance on benchmark datasets. Our code will be available in https://github.com/wenbingtao/GLHA.",良好な対応を見つけることは、多くの機能ベースのタスクにおける重要な前提条件です。画像ペアの推定対応セットを前提として、バイナリクラス分類器によって正しい対応を見つけ、分類された対応を通じて相対ポーズを推定するニューラルネットワークを提案します。まず、正誤対応数の不均衡により、損失関数が分類結果に大きな影響を与えることを分析します。したがって、トレーニング中に目的関数を動的に調整するためのガイダンスとして評価基準（Fn-measure）を直接使用できる新しいガイド付き損失を提案します。理論的には、ガイド付き損失とFnmeasureの間の完全な負の相関関係を証明します。そのため、ネットワークは常にFn-measureを最大化する方向にトレーニングされます。次に、ベイジアン注意コンテキスト正規化（BACN）とチャネルごとの注意（CA）を統合する、特徴を抽出するためのハイブリッド注意ブロックを提案します。 BACNは以前の情報をマイニングしてグローバルコンテキストをより有効に活用でき、CAは複雑なチャネルコンテキストをキャプチャしてネットワークのチャネル認識を強化できます。最後に、ガイド付き損失とハイブリッドアテンションブロックに基づいて、カスケードネットワークは、結果を徐々に最適化してより優れたパフォーマンスを実現するように設計されています。実験により、私たちのネットワークはベンチマークデータセットで最先端のパフォーマンスを達成していることが示されています。私たちのコードはhttps://github.com/wenbingtao/GLHAで入手できます。,https://d3i71xaburhd42.cloudfront.net/3aab67fe32c12ae4cdcccdac4f938b3aa0918e45/1-Figure1-1.png
Neural Sequence-to-Grid Module for Learning Symbolic Rules,"['Segwang Kim', 'Hyoungwook Nam', 'Joonyoung Kim', 'Kyomin Jung']",https://arxiv.org/abs/2101.04921,"Logical reasoning tasks over symbols, such as learning arithmetic operations and computer program evaluations, have become challenges to deep learning. In particular, even stateof-the-art neural networks fail to achieve out-of-distribution (OOD) generalization of symbolic reasoning tasks, whereas humans can easily extend learned symbolic rules. To resolve this difficulty, we propose a neural sequence-to-grid (seq2grid) module, an input preprocessor that automatically segments and aligns an input sequence into a grid. As our module outputs a grid via a novel differentiable mapping, any neural network structure taking a grid input, such as ResNet or TextCNN, can be jointly trained with our module in an end-to-end fashion. Extensive experiments show that neural networks having our module as an input preprocessor achieve OOD generalization on various arithmetic and algorithmic problems including number sequence prediction problems, algebraic word problems, and computer program evaluation problems while other state-of-the-art sequence transduction models cannot. Moreover, we verify that our module enhances TextCNN to solve the bAbI QA tasks without external memory. Symbolic reasoning tasks such as learning arithmetic operations or evaluating computer programs offer solid standards for validating the logical inference abilities of deep learning models. Among machine learning tasks, symbolic reasoning problems are apt for testing mathematical, algorithmic, and systematic reasoning as they have strict rules mapping a given input to a well-defined unique target. In particular, a large body of works on deep learning has considered sequence transduction problems for symbolic reasoning. Some symbolic problems such as copying sequences (Dehghani et al. 2018; Graves, Wayne, and Danihelka 2014; Grefenstette et al. 2015; Rae et al. 2016; Zaremba and Sutskever 2014) and arithmetic addition (Graves, Wayne, and Danihelka 2014; Joulin and Mikolov 2015; Kaiser and Sutskever 2015; Kalchbrenner, Danihelka, and Graves 2015; Saxton et al. 2019; Wangperawong 2018) can be solved after understanding simple rules regardless of the inputs. Others demand a deep learning model to discover necessary rules and apply them depending on inputs given as natural language words (Li et al. 2019; Wang, Liu, and Shi 2017; WeCopyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. ston et al. 2015), complex mathematical equations (Lample and Charton 2019), or programming snippets (Zaremba and Sutskever 2014). Among them, symbolic reasoning problems can test whether a trained deep learning model can systematically extend rules to out-of-distribution (OOD) data that follow a distinct distribution from the training data (Keysers et al. 2019; Lake and Baroni 2017; Saxton et al. 2019). For instance, a model for the addition problem whose training inputs are a pair of numbers up to five digits, say 5872+13, can face an OOD input of a pair of two 6-digit numbers upon the testing phase, e.g., 641436+135321. Human intelligence with algebraic mind can naturally extend learned rules (Marcus 2001), yet it is non-trivial to equip deep learning models for sequence transduction problems to handle OOD generalization. However, it has been found that popular sequence transduction neural networks, such as LSTM seq2seq model (Sutskever, Vinyals, and Le 2014) and Transformer (Vaswani et al. 2017), rarely extend learned rules in that they are inclined to mimic the training data distribution (Dehghani et al. 2018; Lake and Baroni 2017). There have been significant initial efforts to improve a model’s abilities to extend learned rules. However, their success has been dependent on the direct use of numerical values (Trask et al. 2018) or has been limited to rudimentary logic such as copying sequences (Dehghani et al. 2018; Graves, Wayne, and Danihelka 2014; Grefenstette et al. 2015; Rae et al. 2016; Zaremba and Sutskever 2014) and binary arithmetic (Graves, Wayne, and Danihelka 2014; Joulin and Mikolov 2015; Kaiser and Sutskever 2015). Furthermore, OOD generalization on symbolic problems for complex or contextdependent logic forms such as decimal arithmetic, algebraic word problems, computer program evaluation problems has not been tackled. Our objective is to fill this gap and design a module that helps neural networks to achieve OOD generalization in these problems. One observation from a previous study (Nam, Kim, and Jung 2019) is that typical sequence transduction neural networks cannot process OOD instances of number sequence prediction problems, such as predicting a Fibonacci sequence. However, when an input sequence is manually segmented and aligned into a grid of digits, a CNN can easily process OOD instances. This means providing the aligned ar X iv :2 10 1. 04 92 1v 1 [ cs .L G ] 1 3 Ja n 20 21 grid input enables to exploit inductive bias by the convolution’s local and parallel computation. The grid, however, must be handcrafted in the study, which is inapplicable for general sequence transduction tasks. Overcoming this limitation requires a new input preprocessing module that automatically aligns an input sequence into a grid without supervision for the alignment. In this work, we propose a neural sequence-to-grid (seq2grid) module, an input preprocessor that learns how to segment and align an input sequence into a grid. The grid syntactically aligned by our module is then semantically decoded by a neural network. In particular, our module produces a grid by a novel differentiable mapping called nested list operation inspired by Stack RNN (Joulin and Mikolov 2015). This mapping enables a joint training of our module and the neural network in an end-to-end fashion via a backpropagation. Experimental results show that ResNets with our seq2grid module achieve OOD generalization on various arithmetic and algorithmic reasoning problems, such as number sequence prediction problems, algebraic word problems, and computer program evaluation problems. These are nearly impossible for other contemporary sequence-to-sequence models including LSTM seq2seq models and Transformerbased models. Specifically, we find that the seq2grid can infuse an input context into a grid so that doing arithmetic under linguistic instructions or selecting the true branch of if/else statements in code snippets become possible. Further, we demonstrate that the seq2grid module can enhance TextCNN to solve the bAbI QA tasks without the help of external memory. From all the aforementioned problems, we verify the generality of the seq2grid module in that it automatically preprocesses the sequential input into the grid input in a data-driven way. Motivation for Sequence-to-grid Method To demonstrate the benefits of the sequence-to-grid preprocessing method for symbolic reasoning tasks, we devise a toy decimal addition problem in two different setups: sequential and grid-structured. Figure 1 illustrates how the problem is defined in both setups and shows why alignment on a grid makes it easier. If the lengths of the numbers increase, the temporal distances between corresponding digits, e.g., 2 and 3, also increase in the sequential setup. However, the spatial distances between them remain constant in the grid-structured setup since they are manually aligned according to their digits. Therefore, we can expect that the local and parallel nature of convolution will extend the rule to longer inputs, while sequence transduction models will struggle to handle the increased distances. To see this, we trained deep learning models1 using numbers up to five digits and validate on six separate validation sets, each of which contains only k-digit (k=3, . . . , 8) numbers. Hence, the validation results from the former three sets tested in-distribution (ID) generalization, whereas the latThe models had the same configurations used in arithmetic and algorithmic problems (refer to experiments) except for the CNN that was the grid decoder of the S2G-CNN. 5 8 2 2 + 1 3 . 5 8 2 2 + 1 3 . Sequential Input",算術演算の学習やコンピュータープログラムの評価など、記号を介した論理的推論タスクは、深層学習の課題になっています。特に、最先端のニューラルネットワークでさえ、シンボリック推論タスクのアウトオブディストリビューション（OOD）の一般化を達成できませんが、人間は学習したシンボリックルールを簡単に拡張できます。この問題を解決するために、入力シーケンスをグリッドに自動的にセグメント化して整列させる入力プリプロセッサであるニューラルシーケンスからグリッド（seq2grid）モジュールを提案します。モジュールが新しい微分可能なマッピングを介してグリッドを出力するため、ResNetやTextCNNなどのグリッド入力を受け取るニューラルネットワーク構造は、エンドツーエンドの方法でモジュールと共同でトレーニングできます。広範な実験により、入力プリプロセッサとしてモジュールを使用するニューラルネットワークは、数列予測問題、代数的単語問題、コンピュータプログラム評価問題など、さまざまな算術およびアルゴリズムの問​​題でOODの一般化を実現しますが、他の最先端のシーケンス変換モデルでは実現できません。 。さらに、モジュールがTextCNNを拡張して、外部メモリなしでbAbIQAタスクを解決することを確認します。算術演算の学習やコンピュータープログラムの評価などのシンボリック推論タスクは、深層学習モデルの論理的推論能力を検証するための確かな基準を提供します。機械学習タスクの中で、シンボリック推論の問題は、特定の入力を明確に定義された一意のターゲットにマッピングする厳密なルールがあるため、数学、アルゴリズム、および体系的な推論をテストするのに適しています。特に、深層学習に関する多くの研究では、記号的推論のためにシーケンス変換の問題が検討されています。シーケンスのコピー（Dehghani et al.2018; Graves、Wayne、and Danihelka 2014; Grefenstette et al.2015; Rae et al.2016; Zaremba and Sutskever 2014）や算術加算（Graves、Wayne、and Danihelka 2014）などの象徴的な問題; Joulin and Mikolov 2015; Kaiser and Sutskever 2015; Kalchbrenner、Danihelka、and Graves 2015; Saxtonetal。2019; Wangperawong 2018）は、入力に関係なく単純なルールを理解した後で解決できます。他の人は、必要なルールを発見し、自然言語の単語として与えられた入力に応じてそれらを適用するための深層学習モデルを要求します（Lietal。2019; Wang、Liu、and Shi 2017; WeCopyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai .org）。Allrightsreserved。stonetal。2015）、複雑な数式（Lample and Charton 2019）、またはプログラミングスニペット（Zaremba and Sutskever 2014）。それらの中で、象徴的な推論の問題は、訓練された深層学習モデルが、訓練データとは異なる分布に従う分布外（OOD）データに規則を体系的に拡張できるかどうかをテストできます（Keysers et al.2019; Lake and Baroni 2017; Saxton et al.2019）。たとえば、トレーニング入力が5桁までの数字のペア、たとえば5872 + 13である加算問題のモデルは、テストフェーズで2つの6桁の数字のペアのOOD入力に直面する可能性があります（例：641436+）。 135321。代数的精神を備えた人間の知性は、学習したルールを自然に拡張できますが（Marcus 2001）、OODの一般化を処理するためにシーケンス変換問題の深層学習モデルを装備することは簡単ではありません。ただし、LSTM seq2seqモデル（Sutskever、Vinyals、およびLe 2014）やTransformer（Vaswani etal。2017）などの一般的なシーケンス変換ニューラルネットワークは、トレーニングを模倣する傾向があるという点で、学習したルールを拡張することはめったにないことがわかっています。データ分布（Dehghani et al.2018; Lake and Baroni 2017）。学習したルールを拡張するモデルの能力を向上させるための重要な初期の取り組みがありました。ただし、それらの成功は、数値の直接使用に依存しているか（Trask etal。2018）、またはシーケンスのコピーなどの基本的なロジックに限定されています（Dehghani et al.2018; Graves、Wayne、and Danihelka 2014; Grefenstette et al .2015; Raeetal。2016; Zaremba and Sutskever 2014）およびバイナリ演算（Graves、Wayne、and Danihelka 2014; Joulin and Mikolov 2015; Kaiser and Sutskever 2015）。さらに、10進算術、代数的文章題、コンピュータプログラム評価問題などの複雑なまたは文脈依存の論理形式の記号問題に関するOODの一般化は取り組まれていません。私たちの目的は、このギャップを埋め、ニューラルネットワークがこれらの問題でOODの一般化を達成するのに役立つモジュールを設計することです。以前の研究（Nam、Kim、およびJung 2019）からの1つの観察は、典型的なシーケンス変換ニューラルネットワークは、フィボナッチ数列の予測など、数列予測問題のOODインスタンスを処理できないことです。ただし、入力シーケンスを手動でセグメント化して数字のグリッドに揃えると、CNNはOODインスタンスを簡単に処理できます。これは、整列されたar X iv：2 10 1. 04 92 1v 1 [cs .LG] 1 3 Ja n 20 21グリッド入力を提供することにより、畳み込みローカルおよび並列計算による誘導バイアスを利用できることを意味します。ただし、グリッドは調査で手作りする必要があり、一般的なシーケンス変換タスクには適用できません。この制限を克服するには、位置合わせを監視せずに入力シーケンスをグリッドに自動的に位置合わせする新しい入力前処理モジュールが必要です。この作業では、入力シーケンスをグリッドにセグメント化して整列する方法を学習する入力プリプロセッサである、ニューラルシーケンスからグリッド（seq2grid）モジュールを提案します。モジュールによって構文的に整列されたグリッドは、ニューラルネットワークによって意味的にデコードされます。特に、私たちのモジュールは、スタックRNNに触発されたネストされたリスト操作と呼ばれる新しい微分可能なマッピングによってグリッドを生成します（Joulin and Mikolov2015）。このマッピングにより、バックプロパゲーションを介したエンドツーエンドの方法で、モジュールとニューラルネットワークの共同トレーニングが可能になります。実験結果は、seq2gridモジュールを備えたResNetが、数列予測問題、代数的単語問題、コンピュータープログラム評価問題などのさまざまな算術およびアルゴリズム推論問題でOOD一般化を達成することを示しています。これらは、LSTMseq2seqモデルやTransformerベースのモデルを含む他の最新のシーケンス間モデルではほぼ不可能です。具体的には、seq2gridが入力コンテキストをグリッドに注入できるため、言語命令の下で算術演算を実行したり、コードスニペットでif / elseステートメントの真のブランチを選択したりできることがわかりました。さらに、seq2gridモジュールがTextCNNを拡張して、外部メモリを使用せずにbAbIQAタスクを解決できることを示します。前述のすべての問題から、データ駆動型の方法でグリッド入力へのシーケンシャル入力を自動的に前処理するという点で、seq2gridモジュールの一般性を検証します。シーケンスからグリッドへの方法の動機シンボリック推論タスクに対するシーケンスからグリッドへの前処理方法の利点を示すために、2つの異なるセットアップ（シーケンシャルとグリッド構造）でおもちゃの小数加算問題を考案します。図1は、両方のセットアップで問題がどのように定義されているかを示し、グリッド上の位置合わせによって問題が簡単になる理由を示しています。数字の長さが長くなると、対応する数字間の時間的距離、たとえば2と3も、順次設定で増加します。ただし、グリッド構造のセットアップでは、数字に従って手動で位置合わせされるため、それらの間の空間距離は一定のままです。したがって、畳み込みの局所的かつ並列的な性質により、ルールがより長い入力に拡張され、シーケンス変換モデルは増加した距離を処理するのに苦労することが予想されます。これを確認するために、最大5桁の数値を使用して深層学習モデル1をトレーニングし、それぞれがk桁（k = 3、。。。、8）の数値のみを含む6つの個別の検証セットで検証しました。したがって、前の3セットの検証結果は、分布内（ID）の一般化をテストしましたが、latTheモデルは、S2GのグリッドデコーダーであるCNNを除いて、算術およびアルゴリズムの問​​題（実験を参照）で使用されたものと同じ構成でした。 -CNN。 5 8 2 2 + 13。 5 8 2 2 + 13。シーケンシャル入力,https://d3i71xaburhd42.cloudfront.net/2c0a266f9cb88bb914c138ece0deaab8cf528f78/2-Figure1-1.png
Local Relation Learning for Face Forgery Detection,"['Shen Chen', 'Taiping Yao', 'Yang Chen', 'Shouhong Ding', 'Jilin Li', 'Rongrong Ji']",,,,
Contrastive and Generative Graph Convolutional Networks for Graph-Based Semi-Supervised Learning,"['Sheng Wan', 'Shirui Pan', 'Jian Yang', 'Chen Gong']",https://arxiv.org/abs/2009.07111,"Graph-based Semi-Supervised Learning (SSL) aims to transfer the labels of a handful of labeled data to the remaining massive unlabeled data via a graph. As one of the most popular graph-based SSL approaches, the recently proposed Graph Convolutional Networks (GCNs) have gained remarkable progress by combining the sound expressiveness of neural networks with graph structure. Nevertheless, the existing graph-based methods do not directly address the core problem of SSL, i.e., the shortage of supervision, and thus their performances are still very limited. To accommodate this issue, a novel GCN-based SSL algorithm is presented in this paper to enrich the supervision signals by utilizing both data similarities and graph structure. Firstly, by designing a semi-supervised contrastive loss, improved node representations can be generated via maximizing the agreement between different views of the same data or the data from the same class. Therefore, the rich unlabeled data and the scarce yet valuable labeled data can jointly provide abundant supervision information for learning discriminative node representations, which helps improve the subsequent classification result. Secondly, the underlying determinative relationship between the data features and input graph topology is extracted as supplementary supervision signals for SSL via using a graph generative loss related to the input features. Intensive experimental results on a variety of real-world datasets firmly verify the effectiveness of our algorithm compared with other state-of-the-art methods.",グラフベースの半教師あり学習（SSL）は、少数のラベル付きデータのラベルを、グラフを介して残りの大量のラベルなしデータに転送することを目的としています。最も人気のあるグラフベースのSSLアプローチの1つとして、最近提案されたグラフ畳み込みネットワーク（GCN）は、ニューラルネットワークの健全な表現力とグラフ構造を組み合わせることで目覚ましい進歩を遂げました。それにもかかわらず、既存のグラフベースの方法は、SSLのコア問題、つまり監視の不足に直接対処しておらず、したがって、それらのパフォーマンスは依然として非常に制限されています。この問題に対応するために、このペーパーでは、データの類似性とグラフ構造の両方を利用して監視信号を強化する、新しいGCNベースのSSLアルゴリズムを紹介します。まず、半教師あり対照損失を設計することにより、同じデータまたは同じクラスのデータの異なるビュー間の一致を最大化することにより、改善されたノード表現を生成できます。したがって、豊富なラベルなしデータと希少でありながら価値のあるラベル付きデータは、識別ノード表現を学習するための豊富な監視情報を共同で提供でき、その後の分類結果の改善に役立ちます。次に、データ特徴と入力グラフトポロジの間の基本的な決定的関係が、入力特徴に関連するグラフ生成損失を使用して、SSLの補足監視信号として抽出されます。さまざまな実世界のデータセットに関する集中的な実験結果により、他の最先端の方法と比較して、アルゴリズムの有効性がしっかりと検証されています。,https://d3i71xaburhd42.cloudfront.net/b09d52bcbea21b3428f8eb4de16c1461d937842f/4-Figure1-1.png
Spatio-Temporal Difference Descriptor for Skeleton-Based Action Recognition,"['Chongyang Ding', '凯 刘', 'Jari Korhonen', 'Evgeny Belyaev']",,,,
Dual Sparse Attention Network for Session-Based Recommendation,"['Jiahao Yuan', 'Mingyou Sun', 'Zihan Song', 'Xiaoling Wang', 'Wayne Xin Zhao']",,,,
EQG-RACE: Examination-Type Question Generation,"['Xin Jia', 'Wenjie Zhou', 'Xu Sun', 'Yunfang Wu']",https://arxiv.org/abs/2012.06106,"Question Generation (QG) is an essential component of the automatic intelligent tutoring systems, which aims to generate high-quality questions for facilitating the reading practice and assessments. However, existing QG technologies encounter several key issues concerning the biased and unnatural language sources of datasets which are mainly obtained from the Web (e.g. SQuAD). In this paper, we propose an innovative Examination-type Question Generation approach (EQG-RACE) to generate exam-like questions based on a dataset extracted from RACE. Two main strategies are employed in EQG-RACE for dealing with discrete answer information and reasoning among long contexts. A Rough Answer and Key Sentence Tagging scheme is utilized to enhance the representations of input. An Answer-guided Graph Convolutional Network (AG-GCN) is designed to capture structure information in revealing the inter-sentences and intra-sentence relations. Experimental results show a state-of-the-art performance of EQG-RACE, which is apparently superior to the baselines. In addition, our work has established a new QG prototype with a reshaped dataset and QG method, which provides an important benchmark for related research in future work. We will make our data and code publicly available for further research.",質問生成（QG）は、自動インテリジェント家庭教師システムの重要なコンポーネントであり、読書の練習と評価を容易にするための高品質の質問を生成することを目的としています。ただし、既存のQGテクノロジでは、主にWebから取得されるデータセット（SQuADなど）の偏った不自然な言語ソースに関するいくつかの重要な問題が発生します。本稿では、RACEから抽出したデータセットに基づいて、試験のような質問を生成する革新的な試験型質問生成アプローチ（EQG-RACE）を提案します。 EQG-RACEでは、離散的な回答情報を処理し、長いコンテキスト間で推論するために、2つの主要な戦略が採用されています。大まかな回答とキーセンテンスのタグ付けスキームは、入力の表現を強化するために利用されます。回答ガイド付きグラフ畳み込みネットワーク（AG-GCN）は、文間および文内の関係を明らかにする際に構造情報をキャプチャするように設計されています。実験結果は、EQG-RACEの最先端のパフォーマンスを示しています。これは、ベースラインよりも明らかに優れています。さらに、私たちの仕事は、再形成されたデータセットとQGメソッドを備えた新しいQGプロトタイプを確立しました。これは、将来の研究における関連研究の重要なベンチマークを提供します。データとコードは、今後の調​​査のために公開されます。,https://d3i71xaburhd42.cloudfront.net/f84b531135acc19191310537065a804c00814cdd/3-Figure1-1.png
Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis,"['Wenmeng Yu', 'Hua Xu', 'Ziqi Yuan', 'Jiele Wu']",https://arxiv.org/abs/2102.04830,"Representation Learning is a significant and challenging task in multimodal learning. Effective modality representations should contain two parts of characteristics: the consistency and the difference. Due to the unified multimodal annotation, existing methods are restricted in capturing differentiated information. However, additional uni-modal annotations are high timeand labor-cost. In this paper, we design a label generation module based on the self-supervised learning strategy to acquire independent unimodal supervisions. Then, joint training the multi-modal and uni-modal tasks to learn the consistency and difference, respectively. Moreover, during the training stage, we design a weight-adjustment strategy to balance the learning progress among different subtasks. That is to guide the subtasks to focus on samples with a larger difference between modality supervisions. Last, we conduct extensive experiments on three public multimodal baseline datasets. The experimental results validate the reliability and stability of auto-generated unimodal supervisions. On MOSI and MOSEI datasets, our method surpasses the current state-of-the-art methods. On the SIMS dataset, our method achieves comparable performance than humanannotated unimodal labels. The full codes are available at https://github.com/thuiar/Self-MM.",表現学習は、マルチモーダル学習において重要でやりがいのあるタスクです。効果的なモダリティ表現には、一貫性と違いという2つの特性部分が含まれている必要があります。統一されたマルチモーダルアノテーションにより、既存の方法では差別化された情報の取得が制限されます。ただし、追加のユニモーダルアノテーションは、時間と人件費が高くなります。この論文では、独立した単峰性の監督を取得するために、自己教師あり学習戦略に基づいてラベル生成モジュールを設計します。次に、マルチモーダルタスクとユニモーダルタスクを共同でトレーニングして、それぞれ一貫性と違いを学習します。さらに、トレーニング段階では、さまざまなサブタスク間で学習の進行状況のバランスをとるための重み調整戦略を設計します。これは、モダリティ監視の差が大きいサンプルに焦点を合わせるようにサブタスクをガイドすることです。最後に、3つのパブリックマルチモーダルベースラインデータセットで広範な実験を行います。実験結果は、自動生成された単峰性監視の信頼性と安定性を検証します。 MOSIおよびMOSEIデータセットでは、私たちの方法は現在の最先端の方法を上回っています。 SIMSデータセットでは、私たちの方法は、人間が注釈を付けた単峰性ラベルと同等のパフォーマンスを達成します。完全なコードはhttps://github.com/thuiar/Self-MMで入手できます。,https://d3i71xaburhd42.cloudfront.net/897937116ac0645e7d8f0d539b68545a6116191f/3-Figure1-1.png
Coupled Layer-Wise Graph Convolution for Transportation Demand Prediction,"['Junchen Ye', 'Leilei Sun', 'Bowen Du', 'Yanjie Fu', 'Hui Xiong']",https://arxiv.org/abs/2012.08080,"Graph Convolutional Network (GCN) has been widely applied in transportation demand prediction due to its excellent ability to capture non-Euclidean spatial dependence among station-level or regional transportation demands. However, in most of the existing research, the graph convolution was implemented on a heuristically generated adjacency matrix, which could neither reflect the real spatial relationships of stations accurately, nor capture the multi-level spatial dependence of demands adaptively. To cope with the above problems, this paper provides a novel graph convolutional network for transportation demand prediction. Firstly, a novel graph convolution architecture is proposed, which has different adjacency matrices in different layers and all the adjacency matrices are self-learned during the training process. Secondly, a layer-wise coupling mechanism is provided, which associates the upper-level adjacency matrix with the lower-level one. It also reduces the scale of parameters in our model. Lastly, a unitary network is constructed to give the final prediction result by integrating the hidden spatial states with gated recurrent unit, which could capture the multi-level spatial dependence and temporal dynamics simultaneously. Experiments have been conducted on two real-world datasets, NYC Citi Bike and NYC Taxi, and the results demonstrate the superiority of our model over the state-of-the-art ones.",グラフ畳み込みネットワーク（GCN）は、ステーションレベルまたは地域の輸送需要間の非ユークリッド空間依存性をキャプチャする優れた機能により、輸送需要予測に広く適用されています。ただし、既存の研究のほとんどでは、グラフの畳み込みは、ヒューリスティックに生成された隣接行列に実装されていました。これは、ステーションの実際の空間関係を正確に反映することも、需要のマルチレベルの空間依存性を適応的にキャプチャすることもできませんでした。上記の問題に対処するために、この論文は輸送需要予測のための新しいグラフ畳み込みネットワークを提供します。最初に、異なる層に異なる隣接行列があり、すべての隣接行列がトレーニングプロセス中に自己学習される、新しいグラフ畳み込みアーキテクチャが提案されます。次に、上位レベルの隣接行列を下位レベルの隣接行列に関連付けるレイヤーワイズ結合メカニズムが提供されます。また、モデルのパラメーターのスケールも縮小します。最後に、単一ネットワークを構築して、隠れた空間状態をゲート付き回帰ユニットと統合することにより、最終的な予測結果を提供します。これにより、マルチレベルの空間依存性と時間的ダイナミクスを同時にキャプチャできます。 NYC CitiBikeとNYCTaxiの2つの実世界のデータセットで実験が行われ、その結果は、最先端のモデルに対するモデルの優位性を示しています。,https://d3i71xaburhd42.cloudfront.net/c5826aec6709f12940307d67bf5ea21ed71da974/1-Figure1-1.png
Distributed Ranking with Communications: Approximation Analysis and Applications,"['Hong Chen', 'Yingjie Wang', 'Yulong Wang', 'Feng Zheng']",,,,
Tied Block Convolution: Leaner and Better CNNs with Shared Thinner Filters,"['Xudong Wang', 'Stella X Yu']",https://arxiv.org/abs/2009.12021,"Convolution is the main building block of convolutional neural networks (CNN). We observe that an optimized CNN often has highly correlated filters as the number of channels increases with depth, reducing the expressive power of feature representations. We propose Tied Block Convolution (TBC) that shares the same thinner filters over equal blocks of channels and produces multiple responses with a single filter. The concept of TBC can also be extended to group convolution and fully connected layers, and can be applied to various backbone networks and attention modules. Our extensive experimentation on classification, detection, instance segmentation, and attention demonstrates TBC's significant across-the-board gain over standard convolution and group convolution. The proposed TiedSE attention module can even use 64 times fewer parameters than the SE module to achieve comparable performance. In particular, standard CNNs often fail to accurately aggregate information in the presence of occlusion and result in multiple redundant partial object proposals. By sharing filters across channels, TBC reduces correlation and can effectively handle highly overlapping instances. TBC increases the average precision for object detection on MS-COCO by 6% when the occlusion ratio is 80%. Our code will be released.",畳み込みは、畳み込みニューラルネットワーク（CNN）の主要な構成要素です。最適化されたCNNには、チャネル数が深さとともに増加するにつれて相関性の高いフィルターが含まれることが多く、特徴表現の表現力が低下することがわかります。チャネルの等しいブロック上で同じ薄いフィルターを共有し、単一のフィルターで複数の応答を生成するTied Block Convolution（TBC）を提案します。 TBCの概念は、グループ畳み込みおよび完全に接続されたレイヤーに拡張することもでき、さまざまなバックボーンネットワークおよびアテンションモジュールに適用できます。分類、検出、インスタンスのセグメンテーション、および注意に関する広範な実験により、TBCは、標準の畳み込みおよびグループの畳み込みよりも全体的に大幅に向上していることがわかります。提案されたTiedSEアテンションモジュールは、SEモジュールの64分の1のパラメーターを使用して、同等のパフォーマンスを実現することもできます。特に、標準のCNNは、オクルージョンが存在する場合に情報を正確に集約できず、複数の冗長な部分オブジェクトの提案が発生することがよくあります。 TBCは、チャネル間でフィルターを共有することにより、相関関係を減らし、重複の多いインスタンスを効果的に処理できます。 TBCは、MS-COCOでのオブジェクト検出の平均精度を6向上させます,https://d3i71xaburhd42.cloudfront.net/8de987b2baafd4a873351528787c60fb9af77e97/1-Figure1-1.png
Learnable Dynamic Temporal Pooling for Time Series Classification,"['Dongha Lee', 'Seonghyeon Lee', 'Hwanjo Yu']",,,,
Learning to Check Contract Inconsistencies,"['Shuo Zhang', 'Junzhou Zhao', 'Pinghui Wang', 'Nuo Xu', 'Yang Yang', 'Yiting Liu', 'Yi Huang', 'Junlan Feng']",https://arxiv.org/abs/2012.08150,"Contract consistency is important in ensuring the legal validity of the contract. In many scenarios, a contract is written by filling the blanks in a precompiled form. Due to carelessness, two blanks that should be filled with the same (or different)content may be incorrectly filled with different (or same) content. This will result in the issue of contract inconsistencies, which may severely impair the legal validity of the contract. Traditional methods to address this issue mainly rely on manual contract review, which is labor-intensive and costly. In this work, we formulate a novel Contract Inconsistency Checking (CIC) problem, and design an end-to-end framework, called Pair-wise Blank Resolution (PBR), to solve the CIC problem with high accuracy. Our PBR model contains a novel BlankCoder to address the challenge of modeling meaningless blanks. BlankCoder adopts a two-stage attention mechanism that adequately associates a meaningless blank with its relevant descriptions while avoiding the incorporation of irrelevant context words. Experiments conducted on real-world datasets show the promising performance of our method with a balanced accuracy of 94.05% and an F1 score of 90.90% in the CIC problem.",契約の一貫性は、契約の法的有効性を確保する上で重要です。多くのシナリオでは、事前にコンパイルされたフォームに空白を埋めることによって契約が作成されます。不注意により、同じ（または異なる）コンテンツで埋められるべき2つの空白が、異なる（または同じ）コンテンツで誤って埋められる可能性があります。これにより、契約の不整合が発生し、契約の法的有効性が著しく損なわれる可能性があります。この問題に対処する従来の方法は、主に手動の契約レビューに依存しており、これは労働集約的でコストがかかります。この作業では、新しい契約不整合チェック（CIC）問題を定式化し、ペアワイズブランク解決（PBR）と呼ばれるエンドツーエンドのフレームワークを設計して、CIC問題を高精度で解決します。私たちのPBRモデルには、無意味なブランクのモデリングの課題に対処するための新しいBlankCoderが含まれています。 BlankCoderは、意味のない空白を関連する説明に適切に関連付ける2段階の注意メカニズムを採用し、関連性のないコンテキストワードの組み込みを回避します。実世界のデータセットで実施された実験は、94.05のバランスの取れた精度で私たちの方法の有望なパフォーマンスを示しています,https://d3i71xaburhd42.cloudfront.net/890c7548aab4152223235eeff6c067bcccd5f54e/1-Figure1-1.png
Sparsity Aware Normalization for GANs,"['Idan Kligvasser', 'Tomer Michaeli']",,"Generative adversarial networks (GANs) are known to benefit from regularization or normalization of their critic (discriminator) network during training. In this paper, we analyze the popular spectral normalization scheme, find a significant drawback and introduce sparsity aware normalization (SAN), a new alternative approach for stabilizing GAN training. As opposed to other normalization methods, our approach explicitly accounts for the sparse nature of the feature maps in convolutional networks with ReLU activations. We illustrate the effectiveness of our method through extensive experiments with a variety of network architectures. As we show, sparsity is particularly dominant in critics used for image-to-image translation settings. In these cases our approach improves upon existing methods, in less training epochs and with smaller capacity networks, while requiring practically no computational overhead.",生成的敵対的ネットワーク（GAN）は、トレーニング中に批評家（弁別者）ネットワークの正則化または正規化の恩恵を受けることが知られています。このホワイトペーパーでは、一般的なスペクトル正規化スキームを分析し、重大な欠点を見つけて、GANトレーニングを安定させるための新しい代替アプローチであるスパース性認識正規化（SAN）を紹介します。他の正規化方法とは対照的に、私たちのアプローチは、ReLUアクティベーションを使用した畳み込みネットワークの特徴マップのまばらな性質を明示的に説明します。さまざまなネットワークアーキテクチャを使用した広範な実験を通じて、この方法の有効性を説明します。私たちが示すように、スパース性は、画像から画像への変換設定に使用される批評家で特に支配的です。これらの場合、私たちのアプローチは、トレーニングのエポックが少なく、ネットワークの容量が小さい既存の方法を改善しますが、計算のオーバーヘッドはほとんど必要ありません。,https://d3i71xaburhd42.cloudfront.net/48e714e7f7e98e62596704eea3950f9341517db2/2-Figure1-1.png
Improving Generative Moment Matching Networks with Distribution Partition,"['Yong Ren', 'Yucen Luo', 'Jun Zhu']",,,,
Overcoming Catastrophic Forgetting in Graph Neural Networks,"['Huihui Liu', 'Yiding Yang', 'Xinchao Wang']",https://arxiv.org/abs/2012.06002,"Catastrophic forgetting refers to the tendency that a neural network ""forgets"" the previous learned knowledge upon learning new tasks. Prior methods have been focused on overcoming this problem on convolutional neural networks (CNNs), where the input samples like images lie in a grid domain, but have largely overlooked graph neural networks (GNNs) that handle non-grid data. In this paper, we propose a novel scheme dedicated to overcoming catastrophic forgetting problem and hence strengthen continual learning in GNNs. At the heart of our approach is a generic module, termed as topology-aware weight preserving~(TWP), applicable to arbitrary form of GNNs in a plug-and-play fashion. Unlike the main stream of CNN-based continual learning methods that rely on solely slowing down the updates of parameters important to the downstream task, TWP explicitly explores the local structures of the input graph, and attempts to stabilize the parameters playing pivotal roles in the topological aggregation. We evaluate TWP on different GNN backbones over several datasets, and demonstrate that it yields performances superior to the state of the art. Code is publicly available at \url{https://github.com/hhliu79/TWP}.",壊滅的な忘却とは、ニューラルネットワークが新しいタスクを学習するときに以前に学習した知識を「忘れる」傾向を指します。以前の方法は、画像のような入力サンプルがグリッドドメインにある畳み込みニューラルネットワーク（CNN）でこの問題を克服することに焦点を当てていましたが、非グリッドデータを処理するグラフニューラルネットワーク（GNN）を見落としていました。この論文では、壊滅的な忘却問題を克服し、それによってGNNの継続的な学習を強化することに専念する新しいスキームを提案します。私たちのアプローチの中心は、トポロジ対応の重み保存（TWP）と呼ばれる汎用モジュールであり、プラグアンドプレイ方式で任意の形式のGNNに適用できます。ダウンストリームタスクにとって重要なパラメータの更新を遅くするだけに依存するCNNベースの継続的な学習方法のメインストリームとは異なり、TWPは入力グラフのローカル構造を明示的に調査し、トポロジで重要な役割を果たすパラメータを安定させようとします。集約。いくつかのデータセットにわたってさまざまなGNNバックボーンでTWPを評価し、最先端のパフォーマンスよりも優れたパフォーマンスが得られることを示しています。コードはhttps://github.com/hhliu79/TWPで公開されています。,https://d3i71xaburhd42.cloudfront.net/e41a28daa05cc955e00690c20a3fa15ba2d11cdc/1-Figure1-1.png
Synergetic Learning of Heterogeneous Temporal Sequences for Multi-Horizon Probabilistic Forecasting,"['Longyuan Li', 'Jihai Zhang', 'Junchi Yan', 'Yaohui Jin', 'Yunhao Zhang', 'Yanjie Duan', 'Guangjian Tian']",https://arxiv.org/abs/2102.00431,"Time-series is ubiquitous across applications, such as transportation, finance and healthcare. Time-series is often influenced by external factors, especially in the form of asynchronous events, making forecasting difficult. However, existing models are mainly designated for either synchronous time-series or asynchronous event sequence, and can hardly provide a synthetic way to capture the relation between them. We propose Variational Synergetic Multi-Horizon Network (VSMHN), a novel deep conditional generative model. To learn complex correlations across heterogeneous sequences, a tailored encoder is devised to combine the advances in deep point processes models and variational recurrent neural networks. In addition, an aligned time coding and an auxiliary transition scheme are carefully devised for batched training on unaligned sequences. Our model can be trained effectively using stochastic variational inference and generates probabilistic predictions with Monte-Carlo simulation. Furthermore, our model produces accurate, sharp and more realistic probabilistic forecasts. We also show that modeling asynchronous event sequences is crucial for multi-horizon time-series forecasting.",時系列は、運輸、金融、医療などのアプリケーション全体に遍在しています。時系列は、特に非同期イベントの形で、外部要因の影響を受けることが多く、予測が困難になります。ただし、既存のモデルは主に同期時系列または非同期イベントシーケンスのいずれかに指定されており、それらの間の関係をキャプチャするための総合的な方法を提供することはほとんどできません。新規の深い条件付き生成モデルである変分相乗マルチホライズンネットワーク（VSMHN）を提案します。異種シーケンス間の複雑な相関関係を学習するために、ディープポイントプロセスモデルと変分リカレントニューラルネットワークの進歩を組み合わせるように調整されたエンコーダーが考案されています。さらに、整列された時間コーディングと補助的な遷移スキームは、整列されていないシーケンスのバッチトレーニングのために注意深く考案されています。私たちのモデルは、確率的変分推論を使用して効果的にトレーニングでき、モンテカルロシミュレーションで確率的予測を生成します。さらに、私たちのモデルは、正確で、シャープで、より現実的な確率的予測を生成します。また、非同期イベントシーケンスのモデリングが、マルチホライズン時系列予測にとって重要であることも示しています。,https://d3i71xaburhd42.cloudfront.net/41de3027e358b39597faa646e8c2baf7ed58cb8c/2-Figure1-1.png
Efficient Classification with Adaptive KNN,"['Puning Zhao', 'Lifeng Lai']",,,,
ExGAN: Adversarial Generation of Extreme Samples,"['Siddharth Bhatia', 'Arjit Jain', 'Bryan Hooi']",https://arxiv.org/abs/2009.08454,"Mitigating the risk arising from extreme events is a fundamental goal with many applications, such as the modelling of natural disasters, financial crashes, epidemics, and many others. To manage this risk, a vital step is to be able to understand or generate a wide range of extreme scenarios. Existing approaches based on Generative Adversarial Networks (GANs) excel at generating realistic samples, but seek to generate typical samples, rather than extreme samples. Hence, in this work, we propose ExGAN, a GAN-based approach to generate realistic and extreme samples. To model the extremes of the training distribution in a principled way, our work draws from Extreme Value Theory (EVT), a probabilistic approach for modelling the extreme tails of distributions. For practical utility, our framework allows the user to specify both the desired extremeness measure, as well as the desired extremeness probability they wish to sample at. Experiments on real US Precipitation data show that our method generates realistic samples, based on visual inspection and quantitative measures, in an efficient manner. Moreover, generating increasingly extreme examples using ExGAN can be done in constant time (with respect to the extremeness probability), as opposed to the exponential time required by the baseline approach.",極端なイベントから生じるリスクを軽減することは、自然災害、金融危機、エピデミックなどの多くのアプリケーションの基本的な目標です。このリスクを管理するための重要なステップは、さまざまな極端なシナリオを理解または生成できるようにすることです。 Generative Adversarial Networks（GAN）に基づく既存のアプローチは、現実的なサンプルの生成に優れていますが、極端なサンプルではなく、典型的なサンプルの生成を目指しています。したがって、この作業では、現実的で極端なサンプルを生成するためのGANベースのアプローチであるExGANを提案します。原理的な方法でトレーニング分布の極値をモデル化するために、私たちの作業は、分布の極値テールをモデル化するための確率的アプローチである極値理論（EVT）を利用しています。実用性のために、私たちのフレームワークでは、ユーザーが希望の極値測定値と、サンプリングしたい希望の極値確率の両方を指定できます。実際の米国の降水量データでの実験は、私たちの方法が、目視検査と定量的測定に基づいて、効率的な方法で現実的なサンプルを生成することを示しています。さらに、ExGANを使用してますます極端な例を生成することは、ベースラインアプローチで必要とされる指数関数的な時間とは対照的に、一定の時間で（極端な確率に関して）実行できます。,https://d3i71xaburhd42.cloudfront.net/a0e447a465a8b4729c976214368c172d2b272959/2-Figure1-1.png
Coalition Formation in Multi-Defender Security Games,"['Dolev Mutzari', 'Jiarui Gan', 'Sarit Kraus']",,"We study Stackelberg security game (SSG) with multiple defenders, where heterogeneous defenders need to allocate security resources to protect a set of targets against a strategic attacker. In such games, coordination and cooperation between the defenders can increase their ability to protect their assets, but the heterogeneous preferences of the selfinterested defenders often make such cooperation very difficult. In this paper, we approach the problem from the perspective of cooperative game theory and study coalition formation among the defenders. Our main contribution is a number of algorithmic results for the computation problems that arise in this model. We provide a poly-time algorithm for computing a solution in the core of the game and show that all of the elements in the core are Pareto efficient. We show that the problem of computing the entire core is NP-hard and then delve into a special setting where the size of a coalition is limited up to some threshold. We analyse the parameterized complexity of deciding if a coalition structure is in the core under this special setting, and provide a poly-time algorithm for computing successful deviation strategies for a given coalition.",複数のディフェンダーを使用してStackelbergセキュリティゲーム（SSG）を研究します。このゲームでは、異種のディフェンダーがセキュリティリソースを割り当てて、戦略的な攻撃者から一連のターゲットを保護する必要があります。そのようなゲームでは、ディフェンダー間の調整と協力は彼らの資産を保護する能力を高めることができますが、利己的なディフェンダーの異質な好みはしばしばそのような協力を非常に困難にします。本論文では、協力ゲーム理論の観点から問題に取り組み、防御側間の連合形成を研究する。私たちの主な貢献は、このモデルで発生する計算問題のアルゴリズム結果の数です。ゲームのコアでソリューションを計算するためのポリタイムアルゴリズムを提供し、コアのすべての要素がパレート効率的であることを示します。コア全体の計算の問題がNP困難であることを示してから、連合のサイズが特定のしきい値まで制限される特別な設定を掘り下げます。連合構造がこの特別な設定の下でコアにあるかどうかを決定するパラメータ化された複雑さを分析し、特定の連合の成功した偏差戦略を計算するためのポリタイムアルゴリズムを提供します。,https://d3i71xaburhd42.cloudfront.net/4aaee2dafc878bfacef7f99af99336a5763ce326/4-Figure1-1.png
Terrace-Based Food Counting and Segmentation,"['Huu-Thanh Nguyen', 'Chong-Wah Ngo']",,,,
SIMPLE: Single-Network with Mimicking and Point Learning for Bottom-Up Human Pose Estimation,"['Jiabin Zhang', 'Zheng Zhu', 'Jiwen Lu', 'Junjie Huang', 'Guan Huang', 'Jie Zhou']",,,,
Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problem,"['Jiongzhi Zheng', 'Kun He', 'Jianrong Zhou', 'Yan Jin', 'Chumin Li']",https://arxiv.org/abs/2012.04461,"We address the Traveling Salesman Problem (TSP), a famous NP-hard combinatorial optimization problem. And we propose a variable strategy reinforced approach, denoted as VSR-LKH, which combines three reinforcement learning methods (Q-learning, Sarsa and Monte Carlo) with the well-known TSP algorithm, called Lin-Kernighan-Helsgaun (LKH). VSR-LKH replaces the inflexible traversal operation in LKH, and lets the program learn to make choice at each search step by reinforcement learning. Experimental results on 111 TSP benchmarks from the TSPLIB with up to 85,900 cities demonstrate the excellent performance of the proposed method.","有名なNP困難な組み合わせ最適化問題である巡回セールスマン問題（TSP）に対処します。そして、VSR-LKHと呼ばれる可変戦略強化アプローチを提案します。これは、3つの強化学習方法（Q学習、Sarsa、Monte Carlo）とLin-Kernighan-Helsgaun（LKH）と呼ばれるよく知られたTSPアルゴリズムを組み合わせたものです。 VSR-LKHは、LKHの柔軟性のないトラバーサル操作に代わるものであり、強化学習によって各検索ステップで選択を行うことをプログラムに学習させます。最大85,900都市のTSPLIBからの111TSPベンチマークの実験結果は、提案された方法の優れたパフォーマンスを示しています。",https://d3i71xaburhd42.cloudfront.net/87fa4e906465fc2d8f8331a3165a9fe3ba05ed91/3-Figure1-1.png
FCFR-Net: Feature Fusion Based Coarse-to-Fine Residual Learning for Depth Completion,"['Lina Liu', 'Xibin Song', 'Xiaoyang Lyu', 'Junwei Diao', 'Mengmeng Wang', 'Yong Liu', 'Liangjun Zhang']",https://arxiv.org/abs/2012.08270,"Depth completion aims to recover a dense depth map from a sparse depth map with the corresponding color image as input. Recent approaches mainly formulate the depth completion as a one-stage end-to-end learning task, which outputs dense depth maps directly. However, the feature extraction and supervision in one-stage frameworks are insufficient, limiting the performance of these approaches. To address this problem, we propose a novel end-to-end residual learning framework, which formulates the depth completion as a two-stage learning task, i.e., a sparse-to-coarse stage and a coarse-to-fine stage. First, a coarse dense depth map is obtained by a simple CNN framework. Then, a refined depth map is further obtained using a residual learning strategy in the coarse-to-fine stage with coarse depth map and color image as input. Specially, in the coarse-to-fine stage, a channel shuffle extraction operation is utilized to extract more representative features from color image and coarse depth map, and an energy based fusion operation is exploited to effectively fuse these features obtained by channel shuffle operation, thus leading to more accurate and refined depth maps. We achieve SoTA performance in RMSE on KITTI benchmark. Extensive experiments on other datasets future demonstrate the superiority of our approach over current state-of-the-art depth completion approaches.",深度補完は、対応するカラー画像を入力として、疎な深度マップから高密度の深度マップを復元することを目的としています。最近のアプローチは、主に、高密度の深度マップを直接出力する1段階のエンドツーエンドの学習タスクとして深度の完了を定式化します。ただし、1段階のフレームワークでの特徴抽出と監視は不十分であり、これらのアプローチのパフォーマンスが制限されます。この問題に対処するために、我々は、深さの完了を2段階の学習タスク、つまり、疎から粗い段階と粗いから細かい段階として定式化する、新しいエンドツーエンドの残余学習フレームワークを提案します。まず、単純なCNNフレームワークによって粗密な深度マップが取得されます。次に、粗い深度マップとカラー画像を入力として、粗い段階から細かい段階で残余学習戦略を使用して、洗練された深度マップがさらに取得されます。特に、粗い段階から細かい段階では、チャネルシャッフル抽出操作を利用してカラー画像と粗い深度マップからより代表的な特徴を抽出し、エネルギーベースの融合操作を利用して、チャネルシャッフル操作によって得られたこれらの特徴を効果的に融合します。したがって、より正確で洗練された深度マップにつながります。 KITTIベンチマークのRMSEでSoTAパフォーマンスを達成します。将来の他のデータセットでの広範な実験は、現在の最先端の深度補完アプローチに対する私たちのアプローチの優位性を示しています。,https://d3i71xaburhd42.cloudfront.net/a8bf0b04611acdb23aafed137f7786f430c64dfa/1-Figure1-1.png
Robust Lightweight Facial Expression Recognition Network with Label Distribution Training,"['Zengqun Zhao', 'Qingshan Liu', 'Feng Zhou']",,,,
U-BERT: Pre-Training User Representations for Improved Recommendation,"['Zhaopeng Qiu', 'Xian Wu', 'Jingyue Gao', 'Wei Fan']",,,,
Efficient Deep Image Denoising via Class Specific Convolution,"['Lu XU', 'Jiawei Zhang', 'Xuanye Cheng', 'Feng Zhang', 'Xing Wei', 'Jimmy Ren']",,,,
Estimation of Spectral Risk Measures,"['Ajay Kumar Pandey', 'Prashanth L.A.', 'Sanjay P. P. Bhat']",,,,
Stochastic Graphical Bandits with Adversarial Corruptions,"['Shiyin Lu', 'Guanghui Wang', 'Lijun Zhang']",,,,
Learning to Reweight Imaginary Transitions for Model-Based Reinforcement Learning,"['Wenzhen Huang', 'Qiyue Yin', 'Junge Zhang', 'KAIQI HUANG']",,,,
Strong Explanations in Abstract Argumentation,"['Markus Ulbricht', 'Johannes Peter Wallner']",,,,
C2F-FWN: Coarse-to-Fine Flow Warping Network for Spatial-Temporal Consistent Motion Transfer,"['Dongxu Wei', 'Xiaowei Xu', 'Haibin Shen', 'Kejie Huang']",https://arxiv.org/abs/2012.08976,"Human video motion transfer (HVMT) aims to synthesize videos that one person imitates other persons' actions. Although existing GAN-based HVMT methods have achieved great success, they either fail to preserve appearance details due to the loss of spatial consistency between synthesized and exemplary images, or generate incoherent video results due to the lack of temporal consistency among video frames. In this paper, we propose Coarse-to-Fine Flow Warping Network (C2F-FWN) for spatial-temporal consistent HVMT. Particularly, C2F-FWN utilizes coarse-to-fine flow warping and Layout-Constrained Deformable Convolution (LC-DConv) to improve spatial consistency, and employs Flow Temporal Consistency (FTC) Loss to enhance temporal consistency. In addition, provided with multi-source appearance inputs, C2F-FWN can support appearance attribute editing with great flexibility and efficiency. Besides public datasets, we also collected a large-scale HVMT dataset named SoloDance for evaluation. Extensive experiments conducted on our SoloDance dataset and the iPER dataset show that our approach outperforms state-of-art HVMT methods in terms of both spatial and temporal consistency. Source code and the SoloDance dataset are available at this https URL.",ヒューマンビデオモーショントランスファー（HVMT）は、ある人が他の人の行動を模倣するビデオを合成することを目的としています。既存のGANベースのHVMT手法は大きな成功を収めていますが、合成画像と例示的な画像の間の空間的一貫性が失われるために外観の詳細を保持できないか、ビデオフレーム間の時間的一貫性がないために一貫性のないビデオ結果を生成します。本論文では、時空間一貫性のあるHVMTのための粗密フローワーピングネットワーク（C2F-FWN）を提案する。特に、C2F-FWNは、粗いものから細かいものへのフローワーピングとレイアウト制約付き変形可能畳み込み（LC-DConv）を利用して空間の一貫性を改善し、フローの時間的一貫性（FTC）損失を使用して時間的一貫性を高めます。さらに、マルチソースの外観入力を備えたC2F-FWNは、外観属性の編集を非常に柔軟かつ効率的にサポートできます。公開データセットに加えて、評価のためにSoloDanceという名前の大規模なHVMTデータセットも収集しました。 SoloDanceデータセットとiPERデータセットで実施された広範な実験は、私たちのアプローチが空間的および時間的一貫性の両方の点で最先端のHVMTメソッドよりも優れていることを示しています。ソースコードとSoloDanceデータセットは、このhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/6f00163263f974b9d38b5bd399b1ed15d085cecd/2-Figure1-1.png
Dynamic Modeling Cross- and Self-Lattice Attention Network for Chinese NER,"['Shan Zhao', 'Minghao Hu', 'Zhiping Cai', 'Haiwen Chen', 'Fang Liu']",,,,
Structure-Aware Person Image Generation with Pose Decomposition and Semantic Correlation,"['Jilin Tang', 'Yi Yuan', 'Tianjia Shao', 'Yong Liu', 'Mengmeng Wang', 'Kun Zhou']",,,,
A Model of Winners Allocation,['Yongjie Yang'],,,,
Discovering Fully Oriented Causal Networks,"['Osman A Mian', 'Alexander Marx', 'Jilles Vreeken']",,,,
PC-HMR: Pose Calibration for 3D Human Mesh Recovery from 2D Images/Videos,"['Tianyu Luan', 'Yali Wang', 'Junhao Zhang', 'Zhe Wang', 'Zhipeng Zhou', 'Yu Qiao']",,,,
RESA: Recurrent Feature-Shift Aggregator for Lane Detection,"['Tu Zheng', 'Hao Fang', 'Yi Zhang', 'Wenjian Tang', 'Zheng Yang', 'Haifeng Liu', 'Deng Cai']",,,,
Teaching Active Human Learners,"['Zizhe Wang', 'Hailong Sun']",,,,
An Adaptive Hybrid Framework for Cross-Domain Aspect-Based Sentiment Analysis,"['Yan Zhou', 'Fuqing Zhu', 'pu song', 'Jizhong Han', 'Tao Guo', 'Songlin Hu']",,,,
Warm Starting CMA-ES for Hyperparameter Optimization,"['Masahiro Nomura', 'Shuhei Watanabe', 'Youhei Akimoto', 'Yoshihiko Ozaki', 'Masaki Onishi']",,,,
Learning to Cascade: Confidence Calibration for Improving the Accuracy and Computational Cost of Cascade Inference Systems,"['Shohei Enomoro', 'Takeharu Eda']",,,,
From Label Smoothing to Label Relaxation,"['Julian Lienen', 'Eyke Hüllermeier']",,,,
Kernel-Convoluted Deep Neural Networks with Data Augmentation,"['Minjin Kim', 'Young-geun Kim', 'Dongha Kim', 'Yongdai Kim', 'Myunghee Cho Paik']",https://arxiv.org/abs/2012.02521,"The Mixup method (Zhang et al. 2018), which uses linearly interpolated data, has emerged as an effective data augmentation tool to improve generalization performance and the robustness to adversarial examples. The motivation is to curtail undesirable oscillations by its implicit model constraint to behave linearly at in-between observed data points and promote smoothness. In this work, we formally investigate this premise, propose a way to explicitly impose smoothness constraints, and extend it to incorporate with implicit model constraints. First, we derive a new function class composed of kernel-convoluted models (KCM) where the smoothness constraint is directly imposed by locally averaging the original functions with a kernel function. Second, we propose to incorporate the Mixup method into KCM to expand the domains of smoothness. In both cases of KCM and the KCM adapted with the Mixup, we provide risk analysis, respectively, under some conditions for kernels. We show that the upper bound of the excess risk is not slower than that of the original function class. The upper bound of the KCM with the Mixup remains dominated by that of the KCM if the perturbation of the Mixup vanishes faster than \(O(n^{-1/2})\) where \(n\) is a sample size. Using CIFAR-10 and CIFAR-100 datasets, our experiments demonstrate that the KCM with the Mixup outperforms the Mixup method in terms of generalization and robustness to adversarial examples.",線形補間されたデータを使用するMixupメソッド（Zhang etal。2018）は、一般化のパフォーマンスと敵対的な例に対する堅牢性を向上させるための効果的なデータ拡張ツールとして登場しました。動機は、観測されたデータポイント間で線形に動作し、滑らかさを促進する暗黙のモデル制約によって、望ましくない振動を削減することです。この作業では、この前提を正式に調査し、滑らかさの制約を明示的に課す方法を提案し、それを拡張して暗黙のモデル制約を組み込みます。まず、カーネル関数を使用して元の関数を局所的に平均化することにより、滑らかさの制約が直接課されるカーネル畳み込みモデル（KCM）で構成される新しい関数クラスを導出します。次に、MixupメソッドをKCMに組み込んで、滑らかさの領域を拡張することを提案します。 KCMとMixupに適合したKCMの両方の場合で、カーネルのいくつかの条件下で、それぞれリスク分析を提供します。超過リスクの上限は、元の関数クラスの上限よりも遅くないことを示します。ミックスアップの摂動がO（n ^（1/2））よりも速く消失する場合、ミックスアップを使用したKCMの上限はKCMの上限によって支配されたままになります。ここで、nはサンプルサイズです。 CIFAR-10およびCIFAR-100データセットを使用して、私たちの実験は、Mixupを使用したKCMが、敵対的な例に対する一般化と堅牢性の点でMixupメソッドよりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/46bfb0a8ed89d71d0ec3ae9b535b831dc91fe8a2/2-Figure1-1.png
Regret Bounds for Online Kernel Selection in Continuous Kernel Space,"['Xiao Zhang', 'Shizhong Liao', 'Jun Xu', 'Ji-Rong Wen']",,,,
Relative and Absolute Location Embedding for Few-Shot Node Classification on Graph,"['Zemin Liu', 'Yuan Fang', 'Chenghao Liu', 'Steven Hoi']",,,,
Proportionally Representative Participatory Budgeting with Ordinal Preferences,"['Haris Aziz', 'Barton Lee']",https://arxiv.org/abs/1911.00864,"Participatory budgeting (PB) is a democratic paradigm whereby voters decide on which projects to fund. We consider PB in which voters may be asymmetric, and they report ordinal preferences over projects. We propose proportional representation axioms for the setting and clarify how they fit into other preference aggregation settings. As a result of our study, we also discover a new solution concept that is stronger than proportional justified representation (PJR) for approval-based multi-winner voting.",参加型予算（PB）は、有権者がどのプロジェクトに資金を提供するかを決定する民主的なパラダイムです。有権者が非対称である可能性のあるPBを検討し、プロジェクトよりも序数の好みを報告します。設定の比例代表公理を提案し、それらが他の選好集計設定にどのように適合するかを明確にします。私たちの調査の結果、承認ベースの複数勝者投票の比例正当化表現（PJR）よりも強力な新しいソリューションの概念も発見しました。,https://d3i71xaburhd42.cloudfront.net/2889190d818cc8f192e91797808991c9f96c829e/3-Figure1-1.png
FL-MSRE: A Few-Shot Learning Based Approach to Multimodal Social Relation Extraction,"['Hai Wan', 'Manrong Zhang', 'Jianfeng Du', 'Ziling Huang', 'Yufei Yang', 'Jeff Z. Pan']",,,,
Merging Statistical Feature via Adaptive Gate for Improved Text Classification,"['Xianming Li', 'Zongxi Li', 'Haoran Xie', 'Qing Li']",,,,
Gaussian Process Priors for View-Aware Inference,"['Yuxin Hou', 'Ari Heljakka', 'Arno Solin']",,,,
BT Expansion: A Sound and Complete Algorithm for Behavior Planning of Intelligent Robots with Behavior Trees,"['Zhongxuan Cai', 'Minglong Li', 'Wanrong Huang', 'Wenjing Yang']",,,,
Better Bounds on the Adaptivity Gap of Influence Maximization under Full-Adoption Feedback,"[""Gianlorenzo D'Angelo"", 'Debashmita Poddar', 'Cosimo Vinci']",,,,
Training Binary Neural Network without Batch Normalization for Image Super-Resolution,"['Xinrui Jiang', 'Nannan Wang', 'Jingwei Xin', 'Keyu Li', 'Xi Yang', 'Xinbo Gao']",,,,
Reasoning in Dialog: Improving Response Generation by Context Reading Comprehension,"['Xiuying Chen', 'Zhi Cui', 'Jiayi Zhang', 'Chen Wei', 'Jianwei Cui', 'Bin Wang', 'Dongyan Zhao', 'Rui Yan']",https://arxiv.org/abs/2012.07410,"In multi-turn dialog, utterances do not always take the full form of sentences \cite{Carbonell1983DiscoursePA}, which naturally makes understanding the dialog context more difficult. However, it is essential to fully grasp the dialog context to generate a reasonable response. Hence, in this paper, we propose to improve the response generation performance by examining the model's ability to answer a reading comprehension question, where the question is focused on the omitted information in the dialog. Enlightened by the multi-task learning scheme, we propose a joint framework that unifies these two tasks, sharing the same encoder to extract the common and task-invariant features with different decoders to learn task-specific features. To better fusing information from the question and the dialog history in the encoding part, we propose to augment the Transformer architecture with a memory updater, which is designed to selectively store and update the history dialog information so as to support downstream tasks. For the experiment, we employ human annotators to write and examine a large-scale dialog reading comprehension dataset. Extensive experiments are conducted on this dataset, and the results show that the proposed model brings substantial improvements over several strong baselines on both tasks. In this way, we demonstrate that reasoning can indeed help better response generation and vice versa. We release our large-scale dataset for further research.",マルチターンダイアログでは、発話が必ずしも完全な形の文になるとは限らないため、当然、ダイアログのコンテキストを理解するのが難しくなります。ただし、適切な応答を生成するには、ダイアログのコンテキストを完全に把握することが不可欠です。したがって、本論文では、ダイアログの省略された情報に焦点を当てた読解質問に答えるモデルの能力を調べることにより、応答生成のパフォーマンスを改善することを提案します。マルチタスク学習スキームによって啓発され、タスク固有の機能を学習するために異なるデコーダーで共通のタスク不変の機能を抽出するために同じエンコーダーを共有し、これら2つのタスクを統合する共同フレームワークを提案します。質問からの情報とエンコード部分のダイアログ履歴をより適切に融合するために、ダウンストリームタスクをサポートするために履歴ダイアログ情報を選択的に保存および更新するように設計されたメモリアップデーターでTransformerアーキテクチャを拡張することを提案します。実験では、人間のアノテーターを使用して、大規模なダイアログ読解データセットを作成および調査します。このデータセットに対して広範な実験が行われ、その結果は、提案されたモデルが両方のタスクのいくつかの強力なベースラインに対して大幅な改善をもたらすことを示しています。このようにして、推論が実際により良い応答生成に役立つこと、およびその逆が可能であることを示します。さらなる研究のために大規模なデータセットをリリースします。,https://d3i71xaburhd42.cloudfront.net/bd64364e7f14086545a968b2291e785b75b4368b/4-Figure1-1.png
Learning a Few-Shot Embedding Model with Contrastive Learning,"['Chen Liu', 'Li Zhang', 'Chengming Xu', 'Siqian Yang', 'Yanwei Fu', 'Jilin Li', 'Chengjie Wang']",,,,
KGDet: Keypoint-Guided Fashion Detection,"['Shenhan Qian', 'Dongze Lian', 'Binqiang Zhao', 'Tong Liu', 'Bohui Zhu', 'Hai Li', 'Shenghua Gao']",,,,
Arbitrary Video Style Transfer via Multi-Channel Correlation,"['Yingying Deng', 'Fan Tang', 'Weiming Dong', 'Haibin Huang', 'Chongyang Ma', 'Changsheng Xu']",https://arxiv.org/abs/2009.08003,"Video style transfer is getting more attention in AI community for its numerous applications such as augmented reality and animation productions. Compared with traditional image style transfer, performing this task on video presents new challenges: how to effectively generate satisfactory stylized results for any specified style, and maintain temporal coherence across frames at the same time. Towards this end, we propose Multi-Channel Correction network (MCCNet), which can be trained to fuse the exemplar style features and input content features for efficient style transfer while naturally maintaining the coherence of input videos. Specifically, MCCNet works directly on the feature space of style and content domain where it learns to rearrange and fuse style features based on their similarity with content features. The outputs generated by MCC are features containing the desired style patterns which can further be decoded into images with vivid style textures. Moreover, MCCNet is also designed to explicitly align the features to input which ensures the output maintains the content structures as well as the temporal continuity. To further improve the performance of MCCNet under complex light conditions, we also introduce the illumination loss during training. Qualitative and quantitative evaluations demonstrate that MCCNet performs well in both arbitrary video and image style transfer tasks.",ビデオスタイルの転送は、拡張現実やアニメーション制作などの多数のアプリケーションでAIコミュニティでますます注目を集めています。従来の画像スタイルの転送と比較して、ビデオでこのタスクを実行すると、新しい課題が発生します。指定したスタイルに対して満足のいく定型化された結果を効果的に生成し、同時にフレーム間で時間的コヒーレンスを維持する方法です。この目的に向けて、入力ビデオの一貫性を自然に維持しながら、効率的なスタイル転送のために模範的なスタイル機能と入力コンテンツ機能を融合するようにトレーニングできるマルチチャネル補正ネットワーク（MCCNet）を提案します。具体的には、MCCNetは、スタイルおよびコンテンツドメインの機能空間で直接機能し、コンテンツ機能との類似性に基づいてスタイル機能を再配置および融合することを学習します。 MCCによって生成される出力は、鮮やかなスタイルのテクスチャを持つ画像にさらにデコードできる目的のスタイルパターンを含むフィーチャです。さらに、MCCNetは、機能を入力に明示的に配置するようにも設計されているため、出力はコンテンツ構造と時間的連続性を維持します。複雑な光条件下でのMCCNetのパフォーマンスをさらに向上させるために、トレーニング中の照明損失も導入します。定性的および定量的評価は、MCCNetが任意のビデオおよび画像スタイルの転送タスクの両方で良好に機能することを示しています。,https://d3i71xaburhd42.cloudfront.net/6c6aa5974edccd33117bdd1f6d2a8b6b3d0b44da/1-Figure1-1.png
"UBAR: Towards Fully End-to-End Task-Oriented Dialog System with GPT-2: Yunyi Yang,","['Yunhao Li', 'Xiaojun Quan']",,,,
Learning a Gradient-Free Riemannian Optimizer on Tangent Spaces,"['Xiaomeng Fan', 'Zhi Gao', 'Yuwei WU', 'Yunde Jia', 'Mehrtash Harandi']",,,,
DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition,"['Weizhou Shen', 'Junqing Chen', 'Xiaojun Quan', 'Zhixian Xie']",https://arxiv.org/abs/2012.08695,"This paper presents our pioneering effort for emotion recognition in conversation (ERC) with pre-trained language models. Unlike regular documents, conversational utterances appear alternately from different parties and are usually organized as hierarchical structures in previous work. Such structures are not conducive to the application of pre-trained language models such as XLNet. To address this issue, we propose an all-in-one XLNet model, namely DialogXL, with enhanced memory to store longer historical context and dialog-aware self-attention to deal with the multi-party structures. Specifically, we first modify the recurrence mechanism of XLNet from segment-level to utterance-level in order to better model the conversational data. Second, we introduce dialog-aware self-attention in replacement of the vanilla self-attention in XLNet to capture useful intra- and inter-speaker dependencies. Extensive experiments are conducted on four ERC benchmarks with mainstream models presented for comparison. The experimental results show that the proposed model outperforms the baselines on all the datasets. Several other experiments such as ablation study and error analysis are also conducted and the results confirm the role of the critical modules of DialogXL.",このホワイトペーパーでは、事前にトレーニングされた言語モデルを使用した会話における感情認識（ERC）の先駆的な取り組みについて説明します。通常の文書とは異なり、会話の発話は異なる当事者から交互に表示され、通常、前の作業では階層構造として編成されます。このような構造は、XLNetなどの事前にトレーニングされた言語モデルの適用を助長しません。この問題に対処するために、より長い履歴コンテキストを格納するための拡張メモリと、マルチパーティ構造を処理するためのダイアログ対応の自己注意を備えたオールインワンXLNetモデル、つまりDialogXLを提案します。具体的には、会話データをより適切にモデル化するために、最初にXLNetの繰り返しメカニズムをセグメントレベルから発話レベルに変更します。次に、XLNetのバニラ自己注意の代わりにダイアログ対応の自己注意を導入して、スピーカー内およびスピーカー間の有用な依存関係をキャプチャします。比較のために提示された主流モデルを使用して、4つのERCベンチマークで広範な実験が行われます。実験結果は、提案されたモデルがすべてのデータセットのベースラインを上回っていることを示しています。アブレーション研究やエラー分析などの他のいくつかの実験も実施され、その結果はDialogXLの重要なモジュールの役割を確認しています。,https://d3i71xaburhd42.cloudfront.net/bed629bc6ed311418dc8b870a1ee2b79576066b2/3-Figure1-1.png
Maximin Fairness with Mixed Divisible and Indivisible Goods,"['Xiaohui Bei', 'Shengxin Liu', 'Xinhang Lu', 'Hongao Wang']",https://arxiv.org/abs/2002.05245,"We study fair resource allocation when the resources contain a mixture of divisible and indivisible goods, focusing on the well-studied fairness notion of maximin share fairness (MMS). With only indivisible goods, a full MMS allocation may not exist, but a constant multiplicative approximate allocation always does. We analyze how the MMS approximation guarantee would be affected when the resources to be allocated also contain divisible goods. In particular, we show that the worst-case MMS approximation guarantee with mixed goods is no worse than that with only indivisible goods. However, there exist problem instances to which adding some divisible resources would strictly decrease the MMS approximation ratio of the instance. On the algorithmic front, we propose a constructive algorithm that will always produce an $\alpha$-MMS allocation for any number of agents, where $\alpha$ takes values between $1/2$ and $1$ and is a monotone increasing function determined by how agents value the divisible goods relative to their MMS values.",マキシミンシェアフェアネス（MMS）のよく研究されたフェアネスの概念に焦点を当てて、リソースに分割可能な商品と分割できない商品が混在している場合の公平なリソース割り当てを調査します。分割できない商品のみの場合、完全なMMS割り当てが存在しない可能性がありますが、一定の乗法近似割り当ては常に存在します。割り当てられるリソースに分割可能な商品も含まれている場合に、MMS近似保証がどのように影響を受けるかを分析します。特に、混合商品での最悪の場合のMMS近似保証は、分割できない商品のみでの保証よりも悪くないことを示します。ただし、分割可能なリソースを追加すると、インスタンスのMMS近似比が厳密に低下する問題のあるインスタンスが存在します。アルゴリズムの面では、任意の数のエージェントに対して常に-MMS割り当てを生成する建設的なアルゴリズムを提案します。ここで、値は1/2から1の間であり、エージェントが分割可能な商品をエージェントに対してどのように評価するかによって決定される単調増加関数です。 MMS値。,
On Lipschitz Regularization of Convolutional Layers Using Toeplitz Matrix Theory,"['Alexandre Araujo', 'Benjamin Negrevergne', 'Yann Chevaleyre', 'Jamal Atif']",https://arxiv.org/abs/2006.08391,"This paper tackles the problem of Lipschitz regularization of Convolutional Neural Networks. Lipschitz regularity is now established as a key property of modern deep learning with implications in training stability, generalization, robustness against adversarial examples, etc. However, computing the exact value of the Lipschitz constant of a neural network is known to be NP-hard. Recent attempts from the literature introduce upper bounds to approximate this constant that are either efficient but loose or accurate but computationally expensive. In this work, by leveraging the theory of Toeplitz matrices, we introduce a new upper bound for convolutional layers that is both tight and easy to compute. Based on this result we devise an algorithm to train Lipschitz regularized Convolutional Neural Networks.",この論文は、畳み込みニューラルネットワークのリプシッツ正則化の問題に取り組んでいます。リプシッツの規則性は、トレーニングの安定性、一般化、敵対的な例に対するロバスト性などに影響を与える現代の深層学習の重要なプロパティとして確立されています。ただし、ニューラルネットワークのリプシッツ定数の正確な値の計算はNP困難であることが知られています。文献からの最近の試みは、この定数を近似するための上限を導入しています。これは、効率的であるが緩い、または正確であるが計算コストが高いものです。この作業では、テプリッツ行列の理論を活用することにより、タイトで計算が容易な畳み込み層の新しい上限を導入します。この結果に基づいて、リプシッツ正則化畳み込みニューラルネットワークをトレーニングするアルゴリズムを考案します。,
The Style-Content Duality of Attractiveness: Learning to Write Eye-Catching Headlines via Disentanglement,"['Mingzhe Li', 'Xiuying Chen', 'Min Yang', 'Shen Gao', 'Dongyan Zhao', 'Rui Yan']",,,,
Efficient Optimal Selection for Composited Advertising Creatives with Tree Structure,"['Jin Chen', 'Tiezheng Ge', 'Gangwei Jiang', 'Zhiqiang Zhang', 'Defu Lian', 'Kai Zheng']",,,,
Exploration-Exploitation in Multi-Agent Learning: Catastrophe Theory Meets Game Theory,"['Stefanos Leonardos', 'Georgios Piliouras']",https://arxiv.org/abs/2012.03083,"Exploration-exploitation is a powerful and practical tool in multi-agent learning (MAL), however, its effects are far from understood. To make progress in this direction, we study a smooth analogue of Q-learning. We start by showing that our learning model has strong theoretical justification as an optimal model for studying exploration-exploitation. Specifically, we prove that smooth Q-learning has bounded regret in arbitrary games for a cost model that explicitly captures the balance between game and exploration costs and that it always converges to the set of quantal-response equilibria (QRE), the standard solution concept for games under bounded rationality, in weighted potential games with heterogeneous learning agents. In our main task, we then turn to measure the effect of exploration in collective system performance. We characterize the geometry of the QRE surface in low-dimensional MAL systems and link our findings with catastrophe (bifurcation) theory. In particular, as the exploration hyperparameter evolves over-time, the system undergoes phase transitions where the number and stability of equilibria can change radically given an infinitesimal change to the exploration parameter. Based on this, we provide a formal theoretical treatment of how tuning the exploration parameter can provably lead to equilibrium selection with both positive as well as negative (and potentially unbounded) effects to system performance.",探索-探索はマルチエージェント学習（MAL）の強力で実用的なツールですが、その効果は理解されていません。この方向に進むために、Q学習のスムーズな類似物を研究します。まず、学習モデルが、探索-探索を研究するための最適なモデルとして強力な理論的正当性を持っていることを示すことから始めます。具体的には、スムーズなQ学習が、ゲームと探索のコストのバランスを明示的にキャプチャするコストモデルについて、任意のゲームで後悔を制限し、標準ソリューションの概念である質的応答均衡（QRE）のセットに常に収束することを証明します。限定合理性の下でのゲームの場合、異種の学習エージェントを使用した加重潜在的ゲーム。次に、メインタスクでは、集合的なシステムパフォーマンスにおける探索の効果を測定します。低次元MALシステムのQRE表面の形状を特徴づけ、その結果を大災害（分岐）理論と関連付けます。特に、探索ハイパーパラメータが時間の経過とともに進化するにつれて、システムは相転移を起こし、探索パラメータにごくわずかな変化があれば、平衡の数と安定性が根本的に変化する可能性があります。これに基づいて、探索パラメーターの調整が、システムパフォーマンスにプラスとマイナス（および潜在的に無制限）の両方の影響を伴う平衡選択にどのようにつながるかについての正式な理論的取り扱いを提供します。,https://d3i71xaburhd42.cloudfront.net/6ddc6b09d3da565fa75b5e08c581fb2f71b8638b/3-Figure1-1.png
On the Complexity of Finding Justifications for Collective Decisions,"['Arthur Boixel', 'Ronald de Haan']",,"In a collective decision-making process, having the possibility to provide non-expert agents with a justification for why a target outcome is a good compromise given their individual preferences, is an appealing idea. Such questions have recently been addressed in the computational social choice community at large—whether it was to explain the outcomes of a specific rule in voting theory or to seek transparency and accountability in multi-criteria decision making. Ultimately, the development of real-life applications based on these notions depends on their practical feasibility and on the scalability of the approach taken. In this paper, we provide computational complexity results that address the problem of finding and verifying justifications for collective decisions. In particular, we focus on the recent development of a general notion of justification for outcomes in voting theory. Such a justification consists of a step-by-step explanation, grounded in a normative basis, showing how the selection of the target outcome follows from the normative principles considered. We consider a language in which normative principles can be encoded—either as an explicit list of instances of the principles (by means of quantifier-free sentences), or in a succinct fashion (using quantifiers). We then analyse the computational complexity of identifying and checking justifications. For the case where the normative principles are given in the form of a list of instances, verifying the correctness of a justification is DP-complete and deciding on the existence of such a justification is Σ2 -complete. For the case where the normative principles are given succinctly, deciding whether a justification is correct is in NEXP ∧ coNEXP, and NEXPhard, and deciding whether a justification exists is in EXP",集合的な意思決定プロセスでは、専門家ではないエージェントに、個々の好みを考慮して目標の結果が適切な妥協点である理由を正当化する可能性を提供する可能性があることは、魅力的なアイデアです。このような質問は、投票理論における特定のルールの結果を説明することであろうと、多基準意思決定における透明性と説明責任を追求することであろうと、計算社会選択コミュニティ全体で最近取り上げられました。最終的に、これらの概念に基づく実際のアプリケーションの開発は、それらの実際的な実現可能性と採用されたアプローチのスケーラビリティに依存します。このホワイトペーパーでは、集合的な意思決定の正当性を見つけて検証する問題に対処する計算の複雑さの結果を提供します。特に、投票理論における結果の正当化の一般的な概念の最近の発展に焦点を当てています。そのような正当化は、規範に基づいた段階的な説明で構成され、考慮された規範的な原則からターゲットの結果の選択がどのように続くかを示します。規範的な原則を、原則のインスタンスの明示的なリストとして（数量詞のない文を使用して）、または簡潔な方法で（数量詞を使用して）エンコードできる言語を検討します。次に、正当化を識別してチェックする計算の複雑さを分析します。規範的原則がインスタンスのリストの形で与えられている場合、正当化の正しさを検証することはDP完全であり、そのような正当化の存在を決定することは2完全です。規範的原則が簡潔に与えられている場合、正当化が正しいかどうかの決定はNEXP coNEXPとNEXPhardにあり、正当化が存在するかどうかの決定はEXPにあります。,https://d3i71xaburhd42.cloudfront.net/4ef3a8660bc4aadc7ea6205eebf49dc51d2ede0c/2-Table1-1.png
Fast PCA in 1-D Wasserstein Spaces via B-splines Representation and Metric Projection,"['Matteo Pegoraro', 'Mario Beraha']",,,,
Task-Independent Knowledge Makes for Transferable Representations for Generalized Zero-Shot Learning,"['Chaoqun Wang', 'Xuejin Chen', 'Shaobo Min', 'Xiaoyan Sun', 'Houqiang Li']",,,,
An Efficient Algorithm for Deep Stochastic Contextual Bandits,"['Tan Zhu', 'Guannan Liang', 'Chunjiang Zhu', 'Haining Li', 'Jinbo Bi']",,,,
Computing the Proportional Veto Core,"['Egor Ianovski', 'Aleksei Y Kondratev']",,,,
Investigate Indistinguishable Points in Semantic Segmentation of 3D Point Cloud,"['Mingye Xu', 'Zhipeng Zhou', 'Junhao Zhang', 'Yu Qiao']",,,,
TripleTree: A Versatile Interpretable Representation of Black Box Agents and their Environments,"['Tom Bewley', 'Jonathan Lawry']",https://arxiv.org/abs/2009.04743,"In explainable artificial intelligence, there is increasing interest in understanding the behaviour of autonomous agents to build trust and validate performance. Modern agent architectures, such as those trained by deep reinforcement learning, are currently so lacking in interpretable structure as to effectively be black boxes, but insights may still be gained from an external, behaviourist perspective. Inspired by conceptual spaces theory, we suggest that a versatile first step towards general understanding is to discretise the state space into convex regions, jointly capturing similarities over the agent's action, value function and temporal dynamics within a dataset of observations. We create such a representation using a novel variant of the CART decision tree algorithm, and demonstrate how it facilitates practical understanding of black box agents through prediction, visualisation and rule-based explanation.",説明可能な人工知能では、信頼を構築し、パフォーマンスを検証するための自律エージェントの動作を理解することに関心が高まっています。深層強化学習によって訓練されたものなどの最新のエージェントアーキテクチャは、現在、効果的にブラックボックスになるほど解釈可能な構造が不足していますが、外部の行動主義的観点から洞察を得ることができます。概念空間理論に触発されて、一般的な理解に向けた多目的な最初のステップは、状態空間を凸状領域に離散化し、観測のデータセット内のエージェントのアクション、値関数、および時間的ダイナミクスの類似性を共同でキャプチャすることです。 CARTデシジョンツリーアルゴリズムの新しいバリアントを使用してこのような表現を作成し、予測、視覚化、およびルールベースの説明を通じてブラックボックスエージェントの実用的な理解を促進する方法を示します。,https://d3i71xaburhd42.cloudfront.net/9e97187ed5570861c4c5e1694cd4a0ed350c5a4c/2-Figure1-1.png
Spherical Image Generation from a Single Image by Considering Scene Symmetry,"['Takayuki Hara', 'Yusuke Mukuta', 'Tatsuya Harada']",,,,
Relative Variational Intrinsic Control,"['Kate A Baumli', 'David Warde-Farley', 'Steven Hansen', 'Vlad Mnih']",https://arxiv.org/abs/2012.07827,"In the absence of external rewards, agents can still learn useful behaviors by identifying and mastering a set of diverse skills within their environment. Existing skill learning methods use mutual information objectives to incentivize each skill to be diverse and distinguishable from the rest. However, if care is not taken to constrain the ways in which the skills are diverse, trivially diverse skill sets can arise. To ensure useful skill diversity, we propose a novel skill learning objective, Relative Variational Intrinsic Control (RVIC), which incentivizes learning skills that are distinguishable in how they change the agent's relationship to its environment. The resulting set of skills tiles the space of affordances available to the agent. We qualitatively analyze skill behaviors on multiple environments and show how RVIC skills are more useful than skills discovered by existing methods when used in hierarchical reinforcement learning.",外部からの報酬がない場合でも、エージェントは、環境内のさまざまなスキルのセットを識別して習得することにより、有用な行動を学ぶことができます。既存のスキル学習方法は、相互情報量の目的を使用して、各スキルが他のスキルと多様で区別できるようにインセンティブを与えます。ただし、スキルの多様性を制限するように注意を払わないと、自明に多様なスキルセットが発生する可能性があります。有用なスキルの多様性を確保するために、新しいスキル学習目標である相対変分固有制御（RVIC）を提案します。これは、エージェントとその環境との関係をどのように変化させるかで区別できる学習スキルを奨励します。結果として得られるスキルのセットは、エージェントが利用できるアフォーダンスのスペースを並べて表示します。複数の環境でのスキルの振る舞いを定性的に分析し、階層型強化学習で使用した場合に、RVICスキルが既存の方法で発見されたスキルよりもどのように役立つかを示します。,
Hierarchical Graph Capsule Network,"['Jinyu Yang', 'Peilin Zhao', 'Yu Rong', 'Chaochao Yan', 'Chunyuan Li', 'Hehuan Ma', 'Junzhou Huang']",https://arxiv.org/abs/2012.08734,"Graph Neural Networks (GNNs) draw their strength from explicitly modeling the topological information of structured data. However, existing GNNs suffer from limited capability in capturing the hierarchical graph representation which plays an important role in graph classification. In this paper, we innovatively propose hierarchical graph capsule network (HGCN) that can jointly learn node embeddings and extract graph hierarchies. Specifically, disentangled graph capsules are established by identifying heterogeneous factors underlying each node, such that their instantiation parameters represent different properties of the same entity. To learn the hierarchical representation, HGCN characterizes the part-whole relationship between lower-level capsules (part) and higher-level capsules (whole) by explicitly considering the structure information among the parts. Experimental studies demonstrate the effectiveness of HGCN and the contribution of each component.",グラフニューラルネットワーク（GNN）は、構造化データのトポロジ情報を明示的にモデル化することでその強みを引き出します。ただし、既存のGNNは、グラフ分類で重要な役割を果たす階層グラフ表現をキャプチャする機能が制限されています。本論文では、ノード埋め込みを共同で学習し、グラフ階層を抽出できる階層グラフカプセルネットワーク（HGCN）を革新的に提案します。具体的には、解きほぐされたグラフカプセルは、各ノードの基礎となる異種要因を識別することによって確立され、そのインスタンス化パラメーターは同じエンティティの異なるプロパティを表します。階層表現を学習するために、HGCNは、パーツ間の構造情報を明示的に考慮することにより、下位レベルのカプセル（パーツ）と上位レベルのカプセル（全体）の間のパーツ全体の関係を特徴付けます。実験的研究は、HGCNの有効性と各コンポーネントの貢献を示しています。,https://d3i71xaburhd42.cloudfront.net/cce173204b1ea9f41635bd7efa81c4ca2d8b7dfd/4-Figure1-1.png
Improving Commonsense Causal Reasoning by Adversarial Training and Data Augmentation,"['Ignacio Iacobacci', 'Ieva Staliūnaitė', 'Philip John Gorinski']",,,,
Graph Neural Network to Dilute Outliers for Refactoring Monolith Application,"['Utkarsh Desai', 'Sambaran Bandyopadhyay', 'Srikanth Tamilselvam']",https://arxiv.org/abs/2102.03827,"Microservices are becoming the defacto design choice for software architecture. It involves partitioning the software components into finer modules such that the development can happen independently. It also provides natural benefits when deployed on the cloud since resources can be allocated dynamically to necessary components based on demand. Therefore, enterprises as part of their journey to cloud, are increasingly looking to refactor their monolith application into one or more candidate microservices; wherein each service contains a group of software entities (e.g., classes) that are responsible for a common functionality. Graphs are a natural choice to represent a software system. Each software entity can be represented as nodes and its dependencies with other entities as links. Therefore, this problem of refactoring can be viewed as a graph based clustering task. In this work, we propose a novel method to adapt the recent advancements in graph neural networks in the context of code to better understand the software and apply them in the clustering task. In that process, we also identify the outliers in the graph which can be directly mapped to top refactor candidates in the software. Our solution is able to improve state-of-the-art performance compared to works from both software engineering and existing graph representation based techniques.",マイクロサービスは、ソフトウェアアーキテクチャの事実上の設計上の選択肢になりつつあります。これには、開発が独立して行われるように、ソフトウェアコンポーネントをより細かいモジュールに分割することが含まれます。また、リソースを需要に基づいて必要なコンポーネントに動的に割り当てることができるため、クラウドにデプロイすると自然なメリットが得られます。したがって、企業はクラウドへの道のりの一環として、モノリスアプリケーションを1つ以上の候補マイクロサービスにリファクタリングすることをますます求めています。ここで、各サービスには、共通の機能を担当するソフトウェアエンティティ（クラスなど）のグループが含まれています。グラフは、ソフトウェアシステムを表すための自然な選択です。各ソフトウェアエンティティはノードとして表すことができ、他のエンティティとの依存関係はリンクとして表すことができます。したがって、このリファクタリングの問題は、グラフベースのクラスタリングタスクと見なすことができます。この作業では、ソフトウェアをよりよく理解し、クラスタリングタスクに適用するために、コードのコンテキストでグラフニューラルネットワークの最近の進歩を適応させる新しい方法を提案します。そのプロセスでは、ソフトウェアの上位リファクタリング候補に直接マッピングできるグラフ内の外れ値も特定します。私たちのソリューションは、ソフトウェアエンジニアリングと既存のグラフ表現ベースの技術の両方からの作品と比較して、最先端のパフォーマンスを向上させることができます。,https://d3i71xaburhd42.cloudfront.net/95f4ed97e39673a1d1c98ba636a69f322177e0d4/2-Figure1-1.png
Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model,"['Qizhou Wang', 'Bo Han', 'Chen Gong', 'Tongliang Liu', 'Gang Niu', 'Jian Yang']",https://arxiv.org/abs/2101.05467,"The drastic increase of data quantity often brings the severe decrease of data quality, such as incorrect label annotations, which poses a great challenge for robustly training Deep Neural Networks (DNNs). Existing learning methods with label noise either employ ad-hoc heuristics or restrict to specific noise assumptions. However, more general situations, such as instance-dependent label noise, have not been fully explored, as scarce studies focus on their label corruption process. By categorizing instances into confusing and unconfusing instances, this paper proposes a simple yet universal probabilistic model, which explicitly relates noisy labels to their instances. The resultant model can be realized by DNNs, where the training procedure is accomplished by employing an alternating optimization algorithm. Experiments on datasets with both synthetic and real-world label noise verify that the proposed method yields significant improvements on robustness over state-of-the-art counterparts. Introduction DNNs have gained much popularity in the literature of machine learning (He et al. 2017; Jaderberg et al. 2015). However, one of the prominent factors for their success is the availability of large-scale training sample with clean annotations (Deng et al. 2009), where the acquisition process might be prohibitively expensive in practice. Hence, various low-cost surrogate strategies are provided to automatically collect labels (Li et al. 2017a; Xiao et al. 2015). These approaches make the acquisition of large-scale annotated data possible, but will also inevitably lead to noisy labels due to the imperfect results of search engines and crawling algorithms. Previous studies have suggested that noisy labels will hurt the test accuracy of DNNs (Arpit et al. 2017; Zhang et al. 2017). Thus, it would be desirable to develop robust methods for training DNNs with label noise. In learning with noisy labels, existing robust learning methods consist of two general categories, according to whether the generation process for noisy labels is specified. The first category usually employs heuristic and ad-hoc †Corresponding authors. Emails: bhanml@comp.hkbu.edu.hk, chen.gong@njust.edu.cn. Copyright c © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. rules without explicitly modeling the process of label corruption. For example, data cleansing techniques remove potential mislabeled instances before training (Angelova, AbuMostafam, and Perona 2005; Sun et al. 2007); risk reweighting strategies demote the adverse impact of un-trustworthy labels (Guo et al. 2018; Han et al. 2018b; Jiang et al. 2017; Lee et al. 2018; Wang et al. 2018; Han et al. 2020); label correction methods revise noisy labels based on model prediction (Reed et al. 2015; Tanaka et al. 2018; Yi and Wu 2019) or prior information (Gao et al. 2017; Li et al. 2017b; Veit et al. 2017). These methods have gained extensive popularity in the literature. However, without specifying the generation of label noise, these methods may lead to inferior or biased results (Xia et al. 2019; Berthon et al. 2020). The above issue motivates us to explore the second category, which makes various assumptions on the process of label-noise generation. For example, the random classification noise (RCN) model assumes that labels are randomly corrupted without any relationship with their real classes and instance features. To handle this simple situation, various noise-tolerant loss functions (Ghosh, Kumar, and Sastry 2017; Manwani and Sastry 2013; Van Rooyen, Menon, and Williamson 2015) have been explored in the literature. Subsequently, the class-conditional noise (CCN) model is proposed to relate noisy labels to true labels, i.e., some pairs of classes are more prone to be mislabeled. To depict such phenomenon, the noise transition matrix is introduced, which represents the probability of true labels flipping into noisy ones (Patrini et al. 2017; Chen et al. 2020). This matrix plays a significant role in attacking CCN, and its elements can be either tuned by cross validation (Natarajan et al. 2013) or estimated by various algorithms (Liu and Tao 2015; Goldberger and Ben-Reuven 2017; Han et al. 2018a; Xia et al. 2019; Yao et al. 2020). However, (Xiao et al. 2015) suggest that mis-annotation is highly related to instance features in reality. In other words, some instances may be confusing subjectively, and thus suffer from mislabeling. This brings us the instancedependent noise (IDN) model recently. To tackle this challenging problem, (Du and Cai 2015) consider the predetermined noise function that assumes mislabeled instances are close to the decision boundary; (Menon, Van Rooyen, and UNCON FU S I NG CON FU S I NG (a) DOG UNCON FU S I NG CON FU S I NG (b) DOG UNCON FU S I NG CON FU S I NG",データ量が大幅に増加すると、ラベルの注釈が正しくないなど、データ品質が大幅に低下することがよくあります。これは、ディープニューラルネットワーク（DNN）を堅牢にトレーニングするための大きな課題です。ラベルノイズを使用する既存の学習方法は、アドホックヒューリスティックを採用するか、特定のノイズの仮定に制限します。ただし、インスタンスに依存するラベルノイズなどのより一般的な状況は、ラベルの破損プロセスに焦点を当てた研究がほとんどないため、十分に調査されていません。インスタンスを紛らわしいインスタンスと紛らわしくないインスタンスに分類することにより、このペーパーでは、ノイズの多いラベルをインスタンスに明示的に関連付ける、シンプルでありながら普遍的な確率モデルを提案します。結果として得られるモデルは、DNNによって実現できます。この場合、トレーニング手順は、交互の最適化アルゴリズムを使用して実行されます。合成と実世界の両方のラベルノイズを使用したデータセットでの実験により、提案された方法が最先端の方法よりも堅牢性が大幅に向上することが確認されました。はじめにDNNは、機械学習の文献で非常に人気があります（Heetal。2017; Jaderberg et al.2015）。ただし、成功の主な要因の1つは、クリーンな注釈付きの大規模なトレーニングサンプルが利用できることです（Deng etal。2009）。この場合、取得プロセスは実際には法外に費用がかかる可能性があります。したがって、ラベルを自動的に収集するために、さまざまな低コストの代理戦略が提供されます（Lietal。2017a; Xiao et al.2015）。これらのアプローチは、大規模な注釈付きデータの取得を可能にしますが、検索エンジンとクロールアルゴリズムの不完全な結果のために、必然的にノイズの多いラベルにつながります。以前の研究では、ノイズの多いラベルはDNNのテスト精度を損なうことが示唆されています（Arpit et al.2017; Zhang et al.2017）。したがって、ラベルノイズを使用してDNNをトレーニングするための堅牢な方法を開発することが望ましいでしょう。ノイズの多いラベルを使用した学習では、ノイズの多いラベルの生成プロセスが指定されているかどうかに応じて、既存の堅牢な学習方法は2つの一般的なカテゴリで構成されます。最初のカテゴリは通常、ヒューリスティックでアドホックな対応する著者を採用しています。 Eメール：bhanml @ comp.hkbu.edu.hk、chen.gong @ njust.edu.cn。 Copyright c 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。全著作権所有。ラベル破損のプロセスを明示的にモデル化せずにルール。たとえば、データクレンジング技術は、トレーニングの前に潜在的な誤ったラベルのインスタンスを削除します（Angelova、AbuMostafam、およびPerona 2005; Sun et al.2007）。リスクの再重み付け戦略は、信頼できないラベルの悪影響を軽減します（Guo et al.2018; Han et al.2018b; Jiang et al.2017; Lee et al.2018; Wang et al.2018; Han et al.2020）;ラベル修正方法は、モデル予測（Reed et al.2015; Tanaka et al.2018; Yi and Wu 2019）または事前情報（Gao et al.2017; Li et al.2017b; Veit et al.2017）に基づいてノイズの多いラベルを修正します。これらの方法は、文献で広く普及しています。ただし、ラベルノイズの生成を指定しないと、これらの方法は結果が劣ったり偏ったりする可能性があります（Xiaetal。2019; Berthon et al.2020）。上記の問題は、ラベルノイズ生成のプロセスについてさまざまな仮定を行う2番目のカテゴリを調査する動機になります。たとえば、ランダム分類ノイズ（RCN）モデルは、ラベルが実際のクラスやインスタンス機能とは関係なくランダムに破損していることを前提としています。この単純な状況を処理するために、さまざまなノイズ耐性損失関数（Ghosh、Kumar、およびSastry 2017、ManwaniおよびSastry 2013、Van Rooyen、Menon、およびWilliamson 2015）が文献で調査されています。続いて、ノイズの多いラベルを真のラベルに関連付けるために、クラス条件付きノイズ（CCN）モデルが提案されます。つまり、クラスの一部のペアは、誤ってラベル付けされる傾向があります。このような現象を描写するために、ノイズ遷移行列が導入されます。これは、真のラベルがノイズの多いラベルに反転する確率を表します（Patrinietal。2017; Chen et al.2020）。このマトリックスはCCNの攻撃に重要な役割を果たし、その要素は相互検証によって調整するか（Natarajan etal。2013）、さまざまなアルゴリズムによって推定することができます（Liu and Tao 2015; Goldberger and Ben-Reuven 2017; Han et al.2018a ; Xia et al.2019; Yao et al.2020）。ただし、（Xiao etal。2015）は、誤った注釈が実際のインスタンス機能に大きく関連していることを示唆しています。言い換えれば、いくつかのインスタンスは主観的に混乱している可能性があり、したがって誤ったラベル付けに苦しんでいます。これにより、最近、インスタンス依存ノイズ（IDN）モデルがもたらされます。この困難な問題に取り組むために、（Du and Cai 2015）は、誤ってラベル付けされたインスタンスが決定境界に近いと想定する所定のノイズ関数を検討します。 （Menon、Van Rooyen、およびUNCON FU SI NG CON FU SI NG（a）DOG UNCON FU SI NG CON FU SI NG（b）DOG UNCON FU SI NG CON FU SI NG,https://d3i71xaburhd42.cloudfront.net/fde5afcab0731d751bb1ecca773b9bca7914db53/2-Figure1-1.png
Multi-Document Transformer for Personality Detection,"['Feifan Yang', 'Xiaojun Quan', 'Yunyi Yang', 'Jianxing Yu']",,,,
Learning with Group Noise,"['Qizhou Wang', 'Jiangchao Yao', 'Chen Gong', 'Tongliang Liu', 'Mingming Gong', 'Hongxia Yang', 'Bo Han']",,"Machine learning in the context of noise is a challenging but practical setting to plenty of real-world applications. Most of the previous approaches in this area focus on the pairwise relation (casual or correlational relationship) with noise, such as learning with noisy labels. However, the group noise, which is parasitic on the coarse-grained accurate relation with the fine-grained uncertainty, is also universal and has not been well investigated. The challenge under this setting is how to discover true pairwise connections concealed by the group relation with its fine-grained noise. To overcome this issue, we propose a novel Max-Matching method for learning with group noise. Specifically, it utilizes a matching mechanism to evaluate the relation confidence of each object (cf. Figure 1) w.r.t. the target, meanwhile considering the Non-IID characteristics among objects in the group. Only the most confident object is considered to learn the model, so that the fine-grained noise is mostly dropped. The performance on a range of real-world datasets in the area of several learning paradigms demonstrates the effectiveness of Max-Matching.",ノイズのコンテキストでの機械学習は、多くの実際のアプリケーションにとって挑戦的ですが実用的な設定です。この分野でのこれまでのアプローチのほとんどは、ノイズの多いラベルを使用した学習など、ノイズとのペアワイズ関係（カジュアルまたは相関関係）に焦点を当てています。ただし、細粒度の不確実性との粗粒度の正確な関係に寄生するグループノイズも普遍的であり、十分に調査されていません。この設定での課題は、きめ細かいノイズとのグループ関係によって隠された真のペアワイズ接続をどのように発見するかです。この問題を克服するために、グループノイズで学習するための新しいMax-Matching法を提案します。具体的には、マッチングメカニズムを利用して、グループ内のオブジェクト間の非IID特性を考慮しながら、ターゲットに対する各オブジェクトの関係の信頼度を評価します（図1を参照）。モデルを学習するために最も信頼できるオブジェクトのみが考慮されるため、きめの細かいノイズはほとんど除去されます。いくつかの学習パラダイムの領域におけるさまざまな実世界のデータセットでのパフォーマンスは、Max-Matchingの有効性を示しています。,https://d3i71xaburhd42.cloudfront.net/ccbcacc4fcde0eebcf27a774a874db7d1b391319/1-Figure1-1.png
Gaining Insight into SARS-CoV-2 Infection and COVID-19 Severity Using Self-Supervised Edge Features and Graph Neural Networks,"['Arijit Sehanobish', 'Neal G Ravindra', 'David van Dijk']",https://arxiv.org/abs/2006.12971,"Graph Neural Networks (GNN) have been extensively used to extract meaningful representations from graph structured data and to perform predictive tasks such as node classification and link prediction. In recent years, there has been a lot of work incorporating edge features along with node features for prediction tasks. In this work, we present a framework for creating new edge features, via a combination of self-supervised and unsupervised learning which we then use along with node features for node classification tasks. We validate our work on two biological datasets comprising of single-cell RNA sequencing data of \textit{in vitro} SARS-CoV-2 infection and human COVID-19 patients. We demonstrate that our method achieves better performance over baseline Graph Attention Network (GAT) and Graph Convolutional Network (GCN) models. Furthermore, given the attention mechanism on edge and node features, we are able to interpret the cell types and genes that determine the course and severity of COVID-19, contributing to a growing list of potential disease biomarkers and therapeutic targets.",グラフニューラルネットワーク（GNN）は、グラフ構造化データから意味のある表現を抽出し、ノード分類やリンク予測などの予測タスクを実行するために広く使用されています。近年、予測タスクのためにノード機能とともにエッジ機能を組み込む作業が数多く行われています。この作業では、自己教師あり学習と教師なし学習を組み合わせて新しいエッジ特徴を作成するためのフレームワークを紹介します。この学習は、ノード分類タスクのノード特徴とともに使用します。 in vitroSARS-CoV-2感染とヒトCOVID-19患者のシングルセルRNAシーケンスデータで構成される2つの生物学的データセットでの作業を検証します。私たちの方法がベースラインのグラフ注意ネットワーク（GAT）およびグラフ畳み込みネットワーク（GCN）モデルよりも優れたパフォーマンスを達成することを示します。さらに、エッジとノードの機能に関する注意メカニズムを考えると、COVID-19の経過と重症度を決定する細胞の種類と遺伝子を解釈することができ、潜在的な疾患バイオマーカーと治療標的のリストの増加に貢献しています。,https://d3i71xaburhd42.cloudfront.net/6fe2e8b464a53e29cff47e57215ddfe9674dd0b0/4-Figure1-1.png
Incentivizing Truthfulness through Audits in Strategic Classification,"['Andrew Estornell', 'Sanmay Das', 'Yevgeniy Vorobeychik']",https://arxiv.org/abs/2012.09147,"In many societal resource allocation domains, machine learning methods are increasingly used to either score or rank agents in order to decide which ones should receive either resources (e.g., homeless services) or scrutiny (e.g., child welfare investigations) from social services agencies. An agency's scoring function typically operates on a feature vector that contains a combination of self-reported features and information available to the agency about individuals or households.This can create incentives for agents to misrepresent their self-reported features in order to receive resources or avoid scrutiny, but agencies may be able to selectively audit agents to verify the veracity of their reports. 
We study the problem of optimal auditing of agents in such settings. When decisions are made using a threshold on an agent's score, the optimal audit policy has a surprisingly simple structure, uniformly auditing all agents who could benefit from lying. While this policy can, in general, be hard to compute because of the difficulty of identifying the set of agents who could benefit from lying given a complete set of reported types, we also present necessary and sufficient conditions under which it is tractable. We show that the scarce resource setting is more difficult, and exhibit an approximately optimal audit policy in this case. In addition, we show that in either setting verifying whether it is possible to incentivize exact truthfulness is hard even to approximate. However, we also exhibit sufficient conditions for solving this problem optimally, and for obtaining good approximations.",多くの社会的リソース割り当てドメインでは、社会サービス機関からリソース（ホームレスサービスなど）または精査（児童福祉調査など）のどちらを受け取るべきかを決定するために、エージェントのスコアリングまたはランク付けに機械学習手法がますます使用されています。代理店のスコアリング関数は通常、自己申告の特徴と、個人または世帯について代理店が利用できる情報の組み合わせを含む特徴ベクトルで動作します。これにより、エージェントがリソースを受け取ったり回避したりするために、自己申告の特徴を誤って表現するインセンティブが生じる可能性があります。精査しますが、代理店はエージェントを選択的に監査して、レポートの信憑性を検証できる場合があります。そのような状況でのエージェントの最適な監査の問題を研究します。エージェントスコアのしきい値を使用して決定を下す場合、最適な監査ポリシーは驚くほど単純な構造になり、嘘をつくことで利益を得る可能性のあるすべてのエージェントを一律に監査します。このポリシーは、報告されたタイプの完全なセットを考えると嘘をつくことから利益を得ることができるエージェントのセットを特定するのが難しいため、一般に計算するのが難しい場合がありますが、それが扱いやすい必要十分条件も提示します。不足しているリソースの設定はより困難であり、この場合はほぼ最適な監査ポリシーを示します。さらに、どちらの設定でも、正確な真実性を奨励することが可能かどうかを検証することは、概算することさえ難しいことを示しています。ただし、この問題を最適に解決し、適切な近似を取得するための十分条件も示しています。,
DASZL: Dynamic Action Signatures for Zero-Shot Learning,"['Tae Soo Kim', 'Jonathan D Jones', 'Michael Peven', 'Zihao Xiao', 'Jin Bai', 'Yi Zhang', 'Weichao Qiu', 'Alan Yuille', 'Gregory D. Hager']",,,,
Enhancing Scientific Papers Summarization with Citation Graph,"['Chenxin An', 'Ming Zhong', 'Yiran Chen', 'Danqing Wang', 'Xipeng Qiu', 'Xuanjing Huang']",,,,
XraySyn: Realistic View Synthesis from a Single Radiograph through CT Prior,"['Cheng Peng', 'Haofu Liao', 'Gina Wong', 'Jiebo Luo', 'S. Kevin Zhou', 'Rama Chellappa']",https://arxiv.org/abs/2012.02407,"A radiograph visualizes the internal anatomy of a patient through the use of X-ray, which projects 3D information onto a 2D plane. Hence, radiograph analysis naturally requires physicians to relate the prior about 3D human anatomy to 2D radiographs. Synthesizing novel radiographic views in a small range can assist physicians in interpreting anatomy more reliably; however, radiograph view synthesis is heavily ill-posed, lacking in paired data, and lacking in differentiable operations to leverage learning-based approaches. To address these problems, we use Computed Tomography (CT) for radiograph simulation and design a differentiable projection algorithm, which enables us to achieve geometrically consistent transformations between the radiography and CT domains. Our method, XraySyn, can synthesize novel views on real radiographs through a combination of realistic simulation and finetuning on real radiographs. To the best of our knowledge, this is the first work on radiograph view synthesis. We show that by gaining an understanding of radiography in 3D space, our method can be applied to radiograph bone extraction and suppression without groundtruth bone labels.",レントゲン写真は、3D情報を2D平面に投影するX線を使用して、患者の内部構造を視覚化します。したがって、X線写真の分析では、当然、医師は3Dの人体構造に関する以前の情報を2DのX線写真に関連付ける必要があります。狭い範囲で新しいX線写真ビューを合成すると、医師が解剖学的構造をより確実に解釈するのに役立ちます。ただし、X線写真ビューの合成は非常に不適切であり、ペアのデータが不足しており、学習ベースのアプローチを活用するための差別化可能な操作が不足しています。これらの問題に対処するために、X線写真のシミュレーションにコンピューター断層撮影（CT）を使用し、X線撮影とCTドメイン間で幾何学的に一貫した変換を実現できる微分可能な投影アルゴリズムを設計します。私たちの方法であるXraySynは、現実的なシミュレーションと実際のX線写真の微調整を組み合わせることで、実際のX線写真の新しいビューを合成できます。私たちの知る限り、これはX線写真ビューの合成に関する最初の作業です。 3D空間でのレントゲン写真を理解することにより、私たちの方法が、グラウンドトゥルース骨ラベルなしでレントゲン写真の骨の抽出と抑制に適用できることを示します。,https://d3i71xaburhd42.cloudfront.net/25861eef41058d4e5dc1a240d3fe51fe731783a2/1-Figure1-1.png
Value-Decomposition Multi-Agent Actor-Critics,"['Jianyu Su', 'Stephen Adams', 'Peter Beling']",https://arxiv.org/abs/2007.12306,"The exploitation of extra state information has been an active research area in multi-agent reinforcement learning (MARL). QMIX represents the joint action-value using a non-negative function approximator and achieves the best performance, by far, on multi-agent benchmarks, StarCraft II micromanagement tasks. However, our experiments show that, in some cases, QMIX is incompatible with A2C, a training paradigm that promotes algorithm training efficiency. To obtain a reasonable trade-off between training efficiency and algorithm performance, we extend value-decomposition to actor-critics that are compatible with A2C and propose a novel actor-critic framework, value-decomposition actor-critics (VDACs). We evaluate VDACs on the testbed of StarCraft II micromanagement tasks and demonstrate that the proposed framework improves median performance over other actor-critic methods. Furthermore, we use a set of ablation experiments to identify the key factors that contribute to the performance of VDACs.",余分な状態情報の活用は、マルチエージェント強化学習（MARL）の活発な研究分野です。 QMIXは、非負の関数近似器を使用して共同アクション値を表し、マルチエージェントベンチマークであるStarCraftIIマイクロ管理タスクで群を抜いて最高のパフォーマンスを実現します。ただし、私たちの実験では、QMIXがアルゴリズムのトレーニング効率を促進するトレーニングパラダイムであるA2Cと互換性がない場合があることが示されています。トレーニング効率とアルゴリズムパフォーマンスの間の合理的なトレードオフを得るために、A2Cと互換性のあるアクター批評家に価値分解を拡張し、新しいアクター批評家フレームワークである価値分解アクター批評家（VDAC）を提案します。 StarCraft IIマイクロマネジメントタスクのテストベッドでVDACを評価し、提案されたフレームワークが他のアクタークリティカルな方法よりもパフォーマンスの中央値を改善することを示します。さらに、一連のアブレーション実験を使用して、VDACのパフォーマンスに寄与する主要な要因を特定します。,https://d3i71xaburhd42.cloudfront.net/f4239a50e632be33c74f791e47cd1a2d9eba2d35/7-Figure2-1.png
Multi-Party Campaigning,"['Martin Koutecky', 'Nimrod Talmon']",https://arxiv.org/abs/2005.04455,"We study a social choice setting of manipulation in elections and extend the usual model in two major ways: first, instead of considering a single manipulating agent, in our setting there are several, possibly competing ones; second, instead of evaluating an election after the first manipulative action, we allow several back-and-forth rounds to take place. We show that in certain situations, such as in elections with only a few candidates, optimal strategies for each of the manipulating agents can be computed efficiently. 
Our algorithmic results rely on formulating the problem of finding an optimal strategy as sentences of Presburger arithmetic that are short and only involve small coefficients, which we show is fixed-parameter tractable -- indeed, one of our contributions is a general result regarding fixed-parameter tractability of Presburger arithmetic that might be useful in other settings. Following our general theorem, we design quite general algorithms; in particular, we describe how to design efficient algorithms for various settings, including settings in which we model diffusion of opinions in a social network, complex budgeting schemes available to the manipulating agents, and various realistic restrictions on adversary actions.",私たちは選挙における操作の社会的選択設定を研究し、2つの主要な方法で通常のモデルを拡張します。1つは、単一の操作エージェントを考慮する代わりに、私たちの設定では、いくつかの、おそらく競合するものがあります。第2に、最初の操作アクションの後に選挙を評価する代わりに、数回の往復ラウンドを許可します。候補者が少ない選挙など、特定の状況では、各操作エージェントの最適な戦略を効率的に計算できることを示します。私たちのアルゴリズムの結果は、プレスバーガー算術の文として最適な戦略を見つける問題を定式化することに依存しています。プレスバーガー算術の文は短く、小さな係数しか含まれていません。これは、固定パラメータの扱いやすさを示しています。私たちの貢献の1つは、固定パラメータの扱いやすさに関する一般的な結果です。他の設定で役立つかもしれないプレスバーガー算術の。一般的な定理に従って、非常に一般的なアルゴリズムを設計します。特に、ソーシャルネットワークでの意見の拡散をモデル化する設定、操作エージェントが利用できる複雑な予算編成スキーム、敵対者の行動に対するさまざまな現実的な制限など、さまざまな設定に対して効率的なアルゴリズムを設計する方法について説明します。,
Solving Infinite-Domain CSPs Using the Patchwork Property,"['Konrad K Dabrowski', 'Peter Jonsson', 'Sebastian Ordyniak', 'George Osipov']",,,,
Disjunctive Temporal Problems under Structural Restrictions,"['Konrad K Dabrowski', 'Peter Jonsson', 'Sebastian Ordyniak', 'George Osipov']",,,,
Advice-Guided Reinforcement Learning in a Non-Markovian Environment,"['Daniel Neider', 'Jean-Raphaël Gaglione', 'Ivan Gavran', 'Ufuk Topcu', 'Bo Wu', 'Zhe Xu']",,"We study a class of reinforcement learning tasks in which the agent receives its reward for complex, temporally-extended behaviors sparsely. For such tasks, the problem is how to augment the state-space so as to make the reward function Markovian in an efficient way. While some existing solutions assume that the reward function is explicitly provided to the learning algorithm (e.g., in the form of a reward machine), the others learn the reward function from the interactions with the environment, assuming no prior knowledge provided by the user. In this paper, we generalize both approaches and enable the user to give advice to the agent, representing the user’s best knowledge about the reward function, potentially fragmented, partial, or even incorrect. We formalize advice as a set of DFAs and present a reinforcement learning algorithm that takes advantage of such advice, with optimal convergence guarantee. The experiments show that using wellchosen advice can reduce the number of training steps needed for convergence to optimal policy, and can decrease the computation time to learn the reward function by up to two orders of magnitude.",エージェントが複雑で時間的に拡張された行動に対して報酬をまばらに受け取る強化学習タスクのクラスを研究します。このようなタスクの場合、問題は、報酬関数を効率的な方法でマルコフにするために、状態空間をどのように拡張するかです。一部の既存のソリューションは、報酬関数が学習アルゴリズムに明示的に提供されることを前提としていますが（たとえば、報酬マシンの形式で）、他のソリューションは、ユーザーが事前の知識を提供しないと仮定して、環境との相互作用から報酬関数を学習します。このホワイトペーパーでは、両方のアプローチを一般化し、ユーザーがエージェントにアドバイスを提供できるようにします。これにより、ユーザーは、断片化、部分的、または不正確な報酬機能に関する最良の知識を表すことができます。アドバイスをDFAのセットとして形式化し、最適な収束保証を備えた、そのようなアドバイスを利用する強化学習アルゴリズムを提示します。実験では、適切に選択されたアドバイスを使用すると、最適なポリシーへの収束に必要なトレーニングステップの数を減らし、報酬関数を学習するための計算時間を最大2桁減らすことができることが示されています。,https://d3i71xaburhd42.cloudfront.net/4a5cbc5e734130c9aac28c6195f8c2b1ec305654/2-Figure1-1.png
Adaptive Teaching of Temporal Logic Formulas to Preference-Based Learners,"['Zhe Xu', 'Yuxin Chen', 'Ufuk Topcu']",,,,
Content Masked Loss: Human-Like Brush Stroke Planning in a Reinforcement Learning Painting Agent,"['Peter Schaldenbrand', 'Jean Oh']",https://arxiv.org/abs/2012.10043,"The objective of most Reinforcement Learning painting agents is to minimize the loss between a target image and the paint canvas. Human painter artistry emphasizes important features of the target image rather than simply reproducing it (DiPaola 2007). Using adversarial or L2 losses in the RL painting models, although its final output is generally a work of finesse, produces a stroke sequence that is vastly different from that which a human would produce since the model does not have knowledge about the abstract features in the target image. In order to increase the human-like planning of the model without the use of expensive human data, we introduce a new loss function for use with the model’s reward function: Content Masked Loss. In the context of robot painting, Content Masked Loss employs an object detection model to extract features which are used to assign higher weight to regions of the canvas that a human would find important for recognizing content. The results, based on 332 human evaluators, show that the digital paintings produced by our Content Masked model show detectable subject matter earlier in the stroke sequence than existing methods without compromising on the quality of the final painting.",ほとんどの強化学習ペイントエージェントの目的は、ターゲットイメージとペイントキャンバスの間の損失を最小限に抑えることです。人間の画家の芸術性は、単にそれを再現するのではなく、ターゲット画像の重要な特徴を強調しています（DiPaola2007）。 RLペイントモデルで敵対的損失またはL2損失を使用すると、最終的な出力は一般にフィネスの作業ですが、モデルには抽象的な特徴に関する知識がないため、人間が生成するストロークシーケンスとは大きく異なるストロークシーケンスが生成されます。ターゲット画像。高価な人間のデータを使用せずにモデルの人間のような計画を増やすために、モデルの報酬関数で使用する新しい損失関数であるコンテンツマスク損失を導入します。ロボットペインティングのコンテキストでは、Content Masked Lossは、オブジェクト検出モデルを使用して、人間がコンテンツを認識するために重要であると考えるキャンバスの領域により高い重みを割り当てるために使用される特徴を抽出します。 332人の人間の評価者に基づく結果は、コンテンツマスクモデルによって生成されたデジタル絵画が、最終的な絵画の品質を損なうことなく、既存の方法よりもストロークシーケンスの早い段階で検出可能な主題を示していることを示しています。,https://d3i71xaburhd42.cloudfront.net/b1768048e4ba6eb782ca3935b245967ae9a35ae9/1-Figure1-1.png
CARPe Posterum: A Convolutional Approach for Real-Time Pedestrian Path Prediction,"['Matias Mendieta', 'Hamed Tabkhi']",https://arxiv.org/abs/2005.12469,"Pedestrian path prediction is an essential topic in computer vision and video understanding. Having insight into the movement of pedestrians is crucial for ensuring safe operation in a variety of applications including autonomous vehicles, social robots, and environmental monitoring. Current works in this area utilize complex generative or recurrent methods to capture many possible futures. However, despite the inherent real-time nature of predicting future paths, little work has been done to explore accurate and computationally efficient approaches for this task. To this end, we propose a convolutional approach for real-time pedestrian path prediction, CARPe. It utilizes a variation of Graph Isomorphism Networks in combination with an agile convolutional neural network design to form a fast and accurate path prediction approach. Notable results in both inference speed and prediction accuracy are achieved, improving FPS by at least 8x in comparison to current state-of-the-art methods while delivering competitive accuracy on well-known path prediction datasets.",歩行者の経路予測は、コンピュータビジョンとビデオの理解に不可欠なトピックです。自動運転車、ソーシャルロボット、環境モニタリングなど、さまざまなアプリケーションで安全な操作を確保するには、歩行者の動きを洞察することが重要です。この分野での現在の作業は、複雑な生成的または反復的な方法を利用して、多くの可能な未来を捉えています。ただし、将来のパスを予測する固有のリアルタイムの性質にもかかわらず、このタスクの正確で計算効率の高いアプローチを探索するための作業はほとんど行われていません。この目的のために、リアルタイムの歩行者経路予測のための畳み込みアプローチ、CARPeを提案します。グラフ同型ネットワークのバリエーションをアジャイル畳み込みニューラルネットワーク設計と組み合わせて利用して、高速で正確なパス予測アプローチを形成します。推論速度と予測精度の両方で顕著な結果が達成され、既知のパス予測データセットで競争力のある精度を提供しながら、現在の最先端の方法と比較してFPSが少なくとも8倍向上します。,https://d3i71xaburhd42.cloudfront.net/8e613cb5f8268e8e18fc99e5c22dd2a8287169e9/2-Figure1-1.png
Modeling Voters in Multi-Winner Approval Voting,"['Jaelle Scheuerman', 'Jason Harman', 'Nicholas Mattei', 'Brent Venable']",https://arxiv.org/abs/2012.02811,"In many real world situations, collective decisions are made using voting and, in scenarios such as committee or board elections, employing voting rules that return multiple winners. In multi-winner approval voting (AV), an agent submits a ballot consisting of approvals for as many candidates as they wish, and winners are chosen by tallying up the votes and choosing the top-$k$ candidates receiving the most approvals. In many scenarios, an agent may manipulate the ballot they submit in order to achieve a better outcome by voting in a way that does not reflect their true preferences. In complex and uncertain situations, agents may use heuristics instead of incurring the additional effort required to compute the manipulation which most favors them. In this paper, we examine voting behavior in single-winner and multi-winner approval voting scenarios with varying degrees of uncertainty using behavioral data obtained from Mechanical Turk. We find that people generally manipulate their vote to obtain a better outcome, but often do not identify the optimal manipulation. There are a number of predictive models of agent behavior in the COMSOC and psychology literature that are based on cognitively plausible heuristic strategies. We show that the existing approaches do not adequately model real-world data. We propose a novel model that takes into account the size of the winning set and human cognitive constraints, and demonstrate that this model is more effective at capturing real-world behaviors in multi-winner approval voting scenarios.",多くの現実の状況では、集合的な決定は投票を使用して行われ、委員会や取締役会の選挙などのシナリオでは、複数の勝者を返す投票ルールを採用します。複数勝者の承認投票（AV）では、エージェントが希望する数の候補者の承認からなる投票を提出し、投票を集計し、最も多くの承認を受けた上位k人の候補者を選択して勝者を選択します。多くのシナリオでは、エージェントは、実際の好みを反映しない方法で投票することにより、より良い結果を達成するために、提出する投票を操作する場合があります。複雑で不確実な状況では、エージェントは、最も有利な操作を計算するために必要な追加の労力を負担する代わりに、ヒューリスティックを使用する場合があります。このホワイトペーパーでは、Mechanical Turkから取得した行動データを使用して、さまざまな程度の不確実性を伴う単一勝者および複数勝者の承認投票シナリオでの投票行動を調べます。一般に、人々はより良​​い結果を得るために投票を操作しますが、最適な操作を特定しないことがよくあります。 COMSOCおよび心理学の文献には、認知的にもっともらしいヒューリスティック戦略に基づくエージェントの行動の予測モデルがいくつかあります。既存のアプローチが実際のデータを適切にモデル化していないことを示します。勝者セットのサイズと人間の認知的制約を考慮した新しいモデルを提案し、このモデルが複数の勝者の承認投票シナリオで実際の行動をキャプチャするのにより効果的であることを示します。,https://d3i71xaburhd42.cloudfront.net/15931520cce546bbf19b4cebeb4161c4debeabe7/5-Figure1-1.png
Metrics and Continuity in Reinforcement Learning,"['Charline Le Lan', 'Marc G. Bellemare', 'Pablo Samuel Castro']",,,,
Meta Learning for Causal Direction,"['Jean-Francois Ton', 'Dino Sejdinovic', 'Kenji Fukumizu']",https://arxiv.org/abs/2007.02809,"The inaccessibility of controlled randomized trials due to inherent constraints in many fields of science has been a fundamental issue in causal inference. In this paper, we focus on distinguishing the cause from effect in the bivariate setting under limited observational data. Based on recent developments in meta learning as well as in causal inference, we introduce a novel generative model that allows distinguishing cause and effect in the small data setting. Using a learnt task variable that contains distributional information of each dataset, we propose an end-to-end algorithm that makes use of similar training datasets at test time. We demonstrate our method on various synthetic as well as real-world data and show that it is able to maintain high accuracy in detecting directions across varying dataset sizes.",科学の多くの分野に固有の制約のために制御されたランダム化試験にアクセスできないことは、因果推論の根本的な問題でした。この論文では、限られた観測データの下で、二変量設定で原因と結果を区別することに焦点を当てます。メタ学習と因果推論の最近の進展に基づいて、小さなデータ設定で原因と結果を区別できる新しい生成モデルを紹介します。各データセットの分布情報を含む学習済みタスク変数を使用して、テスト時に同様のトレーニングデータセットを利用するエンドツーエンドのアルゴリズムを提案します。さまざまな合成データと実際のデータでこの方法を示し、さまざまなデータセットサイズで方向を検出する際に高精度を維持できることを示します。,https://d3i71xaburhd42.cloudfront.net/738cde0911f9155ee7940fe1a8062311799dde7d/4-Figure1-1.png
The Undergraduate Games Corpus: A Dataset for Machine Perception of Interactive Media,"['Barrett R Anderson', 'Adam M Smith']",,,,
Implicit Kernel Attention,"['Kyungwoo Song', 'Yohan Jung', 'Dongjun Kim', 'Il-Chul Moon']",https://arxiv.org/abs/2006.06147,"\textit{Attention} computes the dependency between representations, and it encourages the model to focus on the important selective features. Attention-based models, such as Transformers and graph attention networks (GAT) are widely utilized for sequential data and graph-structured data. This paper suggests a new interpretation and generalized structure of the attention in Transformer and GAT. For the attention in Transformer and GAT, we derive that the attention is a product of two parts: 1) the RBF kernel to measure the similarity of two instances and 2) the exponential of $L^{2}$ norm to compute the importance of individual instances. From this decomposition, we generalize the attention in three ways. First, we propose implicit kernel attention with an implicit kernel function, instead of manual kernel selection. Second, we generalize $L^{2}$ norm as the $L^{p}$ norm. Third, we extend our attention to structured multi-head attention. Our generalized attention shows better performance on classification, translation, and regression tasks.",注意は表現間の依存関係を計算し、モデルが重要な選択的特徴に焦点を合わせるように促します。トランスフォーマーやグラフアテンションネットワーク（GAT）などのアテンションベースのモデルは、シーケンシャルデータやグラフ構造化データに広く利用されています。この論文は、TransformerとGATにおける注意の新しい解釈と一般化された構造を示唆しています。 TransformerとGATでの注意については、注意は2つの部分の積であることがわかります。1）2つのインスタンスの類似性を測定するRBFカーネル、および2）個々のインスタンスの重要性を計算するL2ノルムの指数。この分解から、3つの方法で注意を一般化します。まず、手動のカーネル選択ではなく、暗黙のカーネル関数を使用して暗黙のカーネル注意を提案します。次に、L2ノルムをL ^（p）ノルムとして一般化します。第三に、構造化されたマルチヘッド注意に注意を広げます。私たちの一般的な注意は、分類、翻訳、および回帰タスクでより良いパフォーマンスを示しています。,https://d3i71xaburhd42.cloudfront.net/a32ed7f632e087c92ecd8f7a1080cba23aa6ea99/3-Figure1-1.png
Unsupervised Active Learning via Subspace Learning,"['Changsheng Li', 'KaiHang Mao', 'Lingyan Liang', 'Dongchun Ren', 'Wei Zhang', 'Ye Yuan', 'Guoren Wang']",,,,
Fairness-Aware News Recommendation with Decomposed Adversarial Learning,"['Chuhan Wu', 'Fangzhao Wu', 'Xiting Wang', 'Yongfeng Huang', 'Xing Xie']",https://arxiv.org/abs/2006.16742,"News recommendation is important for online news services. Most news recommendation methods model users' interests from their news click behaviors. Usually the behaviors of users with the same sensitive attributes have similar patterns, and existing news recommendation models can inherit these biases and encode them into news ranking results. Thus, their recommendation results may be heavily influenced by the biases related to sensitive user attributes, which is unfair since users cannot receive sufficient news information that they are interested in. In this paper, we propose a fairness-aware news recommendation approach with decomposed adversarial learning and orthogonality regularization, which can alleviate unfairness in news recommendation brought by the biases of sensitive user attributes. For model training, we propose to learn a bias-aware user embedding that captures the bias information on user attributes from click behaviors, and learn a bias-free user embedding that only encodes attribute-independent user interest information for fairness-aware news recommendation. In addition, we propose to apply an attribute prediction task to the bias-aware user embedding to enhance its ability on bias modeling, and we apply adversarial learning to the bias-free user embedding to remove the bias information from it. Moreover, we propose an orthogonality regularization method to encourage the bias-free user embeddings to be orthogonal to the bias-aware one to further purify the bias-free user embedding. For fairness-aware news ranking, we only use the bias-free user embedding. Extensive experiments on benchmark dataset show that our approach can effectively improve fairness in news recommendation with acceptable performance loss.",ニュースの推奨は、オンラインニュースサービスにとって重要です。ほとんどのニュース推奨方法は、ニュースのクリック行動からユーザーの関心をモデル化します。通常、同じ機密属性を持つユーザーの行動は同様のパターンを持ち、既存のニュース推奨モデルはこれらのバイアスを継承して、ニュースのランキング結果にエンコードできます。したがって、彼らの推薦結果は、ユーザーが興味のある十分なニュース情報を受け取ることができないため不公平である、機密性の高いユーザー属性に関連するバイアスに大きく影響される可能性があります。この論文では、分解された敵対者による公平性を意識したニュース推薦アプローチを提案します。学習と直交性の正規化。これにより、機密性の高いユーザー属性のバイアスによってもたらされるニュース推奨の不公平を軽減できます。モデルトレーニングでは、クリック動作からユーザー属性のバイアス情報をキャプチャするバイアス認識ユーザー埋め込みを学習し、公平性を意識したニュース推奨のために属性に依存しないユーザー関心情報のみをエンコードするバイアスのないユーザー埋め込みを学習することを提案します。さらに、バイアスを意識したユーザー埋め込みに属性予測タスクを適用してバイアスモデリングの能力を強化することを提案し、バイアスのないユーザー埋め込みに敵対的学習を適用してバイアス情報を削除します。さらに、バイアスのないユーザー埋め込みをバイアス認識の埋め込みに直交するように促す直交正則化方法を提案し、バイアスのないユーザー埋め込みをさらに浄化します。公平性を意識したニュースランキングでは、バイアスのないユーザー埋め込みのみを使用します。ベンチマークデータセットでの広範な実験は、私たちのアプローチが許容できるパフォーマンスの低下を伴うニュース推奨の公平性を効果的に改善できることを示しています。,https://d3i71xaburhd42.cloudfront.net/e468ddc0cfe7441c7a23f9f076fa83b105e5b623/1-Figure1-1.png
Exploring the Vulnerability of Deep Neural Networks: A Study of Parameter Corruption,"['Xu Sun', 'Zhiyuan Zhang', 'Xuancheng Ren', 'Ruixuan Luo', 'Liangyou Li']",https://arxiv.org/abs/2006.05620,"We argue that the vulnerability of model parameters is of crucial value to the study of model robustness and generalization but little research has been devoted to understanding this matter. In this work, we propose an indicator to measure the robustness of neural network parameters by exploiting their vulnerability via parameter corruption. The proposed indicator describes the maximum loss variation in the non-trivial worst-case scenario under parameter corruption. For practical purposes, we give a gradient-based estimation, which is far more effective than random corruption trials that can hardly induce the worst accuracy degradation. Equipped with theoretical support and empirical validation, we are able to systematically investigate the robustness of different model parameters and reveal vulnerability of deep neural networks that has been rarely paid attention to before. Moreover, we can enhance the models accordingly with the proposed adversarial corruption-resistant training, which not only improves the parameter robustness but also translates into accuracy elevation.",モデルパラメータの脆弱性は、モデルの堅牢性と一般化の研究にとって決定的な価値があると主張しますが、この問題を理解するための研究はほとんど行われていません。この作業では、パラメータの破損を介してそれらの脆弱性を悪用することにより、ニューラルネットワークパラメータの堅牢性を測定するための指標を提案します。提案された指標は、パラメータの破損の下での重要な最悪のシナリオでの最大損失変動を説明します。実用的な目的のために、勾配ベースの推定を行います。これは、最悪の精度低下を引き起こすことはほとんどないランダムな破損試行よりもはるかに効果的です。理論的サポートと経験的検証を備えており、さまざまなモデルパラメータの堅牢性を体系的に調査し、これまでほとんど注目されていなかったディープニューラルネットワークの脆弱性を明らかにすることができます。さらに、提案された敵対的な腐敗防止トレーニングを使用してモデルを拡張できます。これにより、パラメーターの堅牢性が向上するだけでなく、精度が向上します。,https://d3i71xaburhd42.cloudfront.net/d3db091942ac3c1fe6af69275a318c25d7b4ed11/1-Figure1-1.png
Self-Supervised Multi-View Stereo via Effective Co-Segmentation and Data-Augmentation,"['Hongbin Xu', 'Zhipeng Zhou', 'Yu Qiao', 'Wenxiong Kang', 'Qiuxia Wu']",,,,
Multi-Modal Multi-Label Emotion Recognition with Heterogeneous Hierarchical Message Passing,"['Dong Zhang', 'Xincheng Ju', 'Wei Zhang', 'Junhui Li', 'Shoushan Li', 'Zhu Qiaoming', 'Zhou Guodong']",,,,
NASGEM: Neural Architecture Search via Graph Embedding Method,"['Hsin-Pai Cheng', 'Tunhou Zhang', 'Yixing Zhang', 'Shiyu Li', 'Feng Liang', 'Feng Yan', 'Meng Li', 'Vikas Chandra', 'Hai Li', 'Yiran Chen']",https://arxiv.org/abs/2007.04452,"Neural Architecture Search (NAS) automates and prospers the design of neural networks. Recent studies show that mapping the discrete neural architecture search space into a continuous space which is more compact, more representative, and easier to optimize can significantly reduce the exploration cost. However, existing differentiable methods cannot preserve the graph information when projecting a neural architecture into a continuous space, causing inaccuracy and/or reduced representation capability in the mapped space. Moreover, existing methods can explore only a very limited inner-cell search space due to the cell representation limitation or poor scalability. To enable quick search of more sophisticated neural architectures while preserving graph information, we propose NASGEM which stands for Neural Architecture Search via Graph Embedding Method. NASGEM is driven by a novel graph embedding method integrated with similarity estimation to capture the inner-cell information in the discrete space. Thus, NASGEM is able to search a wider space (e.g., 30 nodes in a cell). By precisely estimating the graph distance, NASGEM can efficiently explore a large amount of candidate cells to enable a more flexible cell design while still keeping the search cost low. GEMNet, which is a set of networks discovered by NASGEM, has higher accuracy while less parameters (up to 62% less) and Multiply-Accumulates (up to 20.7% less) compared to networks crafted by existing differentiable search methods. Our ablation study on NASBench-101 further validates the effectiveness of the proposed graph embedding method, which is complementary to many existing NAS approaches and can be combined to achieve better performance.",ニューラルアーキテクチャ検索（NAS）は、ニューラルネットワークの設計を自動化して繁栄させます。最近の研究では、離散ニューラルアーキテクチャの検索空間を、よりコンパクトで、より代表的で、最適化が容易な連続空間にマッピングすることで、探索コストを大幅に削減できることが示されています。ただし、既存の微分可能な方法では、ニューラルアーキテクチャを連続空間に投影するときにグラフ情報を保存できないため、マップされた空間の表現能力が不正確になったり、低下したりします。さらに、既存の方法では、セル表現の制限またはスケーラビリティが低いため、非常に限られたセル内検索スペースしか探索できません。グラフ情報を保存しながら、より洗練されたニューラルアーキテクチャの迅速な検索を可能にするために、グラフ埋め込み法によるニューラルアーキテクチャ検索の略であるNASGEMを提案します。 NASGEMは、類似性推定と統合された新しいグラフ埋め込み方法によって駆動され、離散空間内のセル内情報をキャプチャします。したがって、NASGEMはより広いスペース（たとえば、セル内の30ノード）を検索できます。 NASGEMは、グラフの距離を正確に推定することにより、大量の候補セルを効率的に探索し、検索コストを低く抑えながら、より柔軟なセル設計を可能にします。 NASGEMによって発見されたネットワークのセットであるGEMNetは、より少ないパラメータ（最大62）でより高い精度を持っています,https://d3i71xaburhd42.cloudfront.net/8d58ba4e876cdcc3fc9debf9b5a9e5262b87c49a/3-Figure1-1.png
Semantic-Guided Reinforced Region Embedding for Generalized Zero-Shot Learning,"['Jiannan Ge', 'Hongtao Xie', 'Shaobo Min', 'Yongdong Zhang']",,,,
SMART Frame Selection for Action Recognition,"['Shreyank N Gowda', 'Marcus Rohrbach', 'Laura Sevilla-Lara']",https://arxiv.org/abs/2012.10671,"Action recognition is computationally expensive. In this paper, we address the problem of frame selection to improve the accuracy of action recognition. In particular, we show that selecting good frames helps in action recognition performance even in the trimmed videos domain. Recent work has successfully leveraged frame selection for long, untrimmed videos, where much of the content is not relevant, and easy to discard. In this work, however, we focus on the more standard short, trimmed action recognition problem. We argue that good frame selection can not only reduce the computational cost of action recognition but also increase the accuracy by getting rid of frames that are hard to classify. In contrast to previous work, we propose a method that instead of selecting frames by considering one at a time, considers them jointly. This results in a more efficient selection, where “good” frames are more effectively distributed over the video, like snapshots that tell a story. We call the proposed frame selection SMART and we test it in combination with different backbone architectures and on multiple benchmarks (Kinetics, Something-something, UCF101). We show that the SMART frame selection consistently improves the accuracy compared to other frame selection strategies while reducing the computational cost by a factor of 4 to 10 times. Additionally, we show that when the primary goal is recognition performance, our selection strategy can improve over recent state-of-the-art models and frame selection strategies on various benchmarks (UCF101, HMDB51, FCVID, and ActivityNet).",アクション認識は計算コストがかかります。本論文では、行動認識の精度を向上させるためにフレーム選択の問題に取り組む。特に、適切なフレームを選択すると、トリミングされたビデオドメインでもアクション認識のパフォーマンスに役立つことを示します。最近の作業では、コンテンツの多くが関連性がなく、簡単に破棄できる、トリミングされていない長いビデオのフレーム選択をうまく活用しています。ただし、この作業では、より標準的な短い、トリミングされた行動認識の問題に焦点を当てます。優れたフレーム選択は、行動認識の計算コストを削減するだけでなく、分類が難しいフレームを取り除くことによって精度を高めることができると主張します。これまでの研究とは対照的に、フレームを1つずつ検討して選択するのではなく、一緒に検討する方法を提案します。これにより、より効率的な選択が可能になり、ストーリーを伝えるスナップショットのように、適切なフレームがビデオ全体により効果的に分散されます。提案されたフレーム選択をSMARTと呼び、さまざまなバックボーンアーキテクチャと組み合わせて、複数のベンチマーク（Kinetics、Something-something、UCF101）でテストします。 SMARTフレーム選択は、他のフレーム選択戦略と比較して一貫して精度を向上させると同時に、計算​​コストを4〜10分の1に削減することを示しています。さらに、主な目標が認識パフォーマンスである場合、選択戦略は、さまざまなベンチマーク（UCF101、HMDB51、FCVID、およびActivityNet）での最近の最先端モデルおよびフレーム選択戦略よりも向上する可能性があることを示します。,https://d3i71xaburhd42.cloudfront.net/7c062be0a5ba96b5d0cd606d2eeacd768845a116/3-Figure1-1.png
Instance Mining with Class Feature Banks for Weakly Supervised Object Detection,"['Yufei Yin', 'Jiajun Deng', 'Wengang Zhou', 'Houqiang Li']",,,,
Ada-Segment: Automated Multi-Loss Adaptation for Panoptic Segmentation,"['Gengwei Zhang', 'Yiming Gao', 'Hang Xu', 'Hao Zhang', 'Zhenguo Li', 'Xiaodan Liang']",https://arxiv.org/abs/2012.03603,"Panoptic segmentation that unifies instance segmentation and semantic segmentation has recently attracted increasing attention. While most existing methods focus on designing novel architectures, we steer toward a different perspective: performing automated multi-loss adaptation (named Ada-Segment) on the fly to flexibly adjust multiple training losses over the course of training using a controller trained to capture the learning dynamics. This offers a few advantages: it bypasses manual tuning of the sensitive loss combination, a decisive factor for panoptic segmentation; it allows to explicitly model the learning dynamics, and reconcile the learning of multiple objectives (up to ten in our experiments); with an end-to-end architecture, it generalizes to different datasets without the need of re-tuning hyperparameters or re-adjusting the training process laboriously. Our Ada-Segment brings 2.7% panoptic quality (PQ) improvement on COCO val split from the vanilla baseline, achieving the state-of-the-art 48.5% PQ on COCO test-dev split and 32.9% PQ on ADE20K dataset. The extensive ablation studies reveal the ever-changing dynamics throughout the training process, necessitating the incorporation of an automated and adaptive learning strategy as presented in this paper.",インスタンスセグメンテーションとセマンティックセグメンテーションを統合するパノプティコンセグメンテーションは、最近ますます注目を集めています。ほとんどの既存の方法は新しいアーキテクチャの設計に焦点を当てていますが、私たちは別の視点に向かって進んでいます：自動化されたマルチロス適応（Ada-Segmentという名前）をオンザフライで実行して、トレーニング中に複数のトレーニングロスを柔軟に調整し、学習ダイナミクス。これにはいくつかの利点があります。パノラマセグメンテーションの決定的な要因である、敏感な損失の組み合わせの手動調整をバイパスします。学習ダイナミクスを明示的にモデル化し、複数の目的の学習を調整することができます（実験では最大10）。エンドツーエンドのアーキテクチャにより、ハイパーパラメータを再調整したり、トレーニングプロセスを面倒に再調整したりすることなく、さまざまなデータセットに一般化できます。私たちのAda-Segmentは2.7をもたらします,https://d3i71xaburhd42.cloudfront.net/8f00eeb1df72e286eaea0ebb3e1b342b763a70dd/1-Figure1-1.png
Accelerated Combinatorial Search for Outlier Detection with Provable Bound on Sub-Optimality,"['Guihong Wan', 'Haim Schweitzer']",,,,
Multi-View Inference for Relation Extraction with Uncertain Knowledge,"['Bo Li', 'Wei Ye', 'Canming Huang', 'Shikun Zhang']",,,,
Dual Compositional Learning in Interactive Image Retrieval,"['Jongseok Kim', 'Youngjae Yu', 'Hoeseong Kim', 'Gunhee Kim']",,,,
Disentangled Motif-Aware Graph Learning for Phrase Grounding,"['Zongshen Mu', 'Siliang Tang', 'Jie Tan', 'Qiang Yu', 'Yueting Zhuang']",,,,
SA-BNN: State-Aware Binary Neural Network,"['Chunlei Liu', 'Peng Chen', 'Bohan Zhuang', 'Chunhua Shen', 'Baochang Zhang', 'Wenrui Ding']",,,,
LRSC: Learning Representations for Subspace Clustering,"['Changsheng Li', 'Chen Yang', 'Bo Liu', 'Ye Yuan', 'Guoren Wang']",,,,
Towards Universal Physical Attacks on Single Object Tracking,"['Li Ding', 'Yongwei Wang', 'Kaiwen Yuan', 'Minyang Jiang', 'Ping Wang', 'Hua Huang', 'Z. Jane Wang']",,,,
Automated Clustering of High-Dimensional Data with a Feature Weighted Mean-Shift Algorithm,"['Saptarshi Chakraborty', 'Debolina Paul', 'Swagatam Das']",https://arxiv.org/abs/2012.10929,"Mean shift is a simple interactive procedure that gradually shifts data points towards the mode which denotes the highest density of data points in the region. Mean shift algorithms have been effectively used for data denoising, mode seeking, and finding the number of clusters in a dataset in an automated fashion. However, the merits of mean shift quickly fade away as the data dimensions increase and only a handful of features contain useful information about the cluster structure of the data. We propose a simple yet elegant feature-weighted variant of mean shift to efficiently learn the feature importance and thus, extending the merits of mean shift to high-dimensional data. The resulting algorithm not only outperforms the conventional mean shift clustering procedure but also preserves its computational simplicity. In addition, the proposed method comes with rigorous theoretical convergence guarantees and a convergence rate of at least a cubic order. The efficacy of our proposal is thoroughly assessed through experimental comparison against baseline and state-of-the-art clustering methods on synthetic as well as real-world datasets.",平均シフトは、領域内のデータポイントの密度が最も高いことを示すモードに向かってデータポイントを徐々にシフトする単純な対話型手順です。平均シフトアルゴリズムは、データのノイズ除去、モードシーク、および自動化された方法でのデータセット内のクラスター数の検索に効果的に使用されています。ただし、平均シフトのメリットは、データディメンションが増加するにつれてすぐに消え、データのクラスター構造に関する有用な情報が含まれている機能はほんの一握りです。特徴の重要性を効率的に学習し、平均シフトのメリットを高次元データに拡張するために、平均シフトのシンプルでありながらエレガントな特徴加重バリアントを提案します。結果として得られるアルゴリズムは、従来の平均シフトクラスタリング手順を上回るだけでなく、計算の単純さも維持します。さらに、提案された方法は、厳密な理論的収束保証と少なくとも3次の収束率を備えています。私たちの提案の有効性は、合成および実世界のデータセットでのベースラインおよび最先端のクラスタリング手法との実験的比較を通じて徹底的に評価されます。,https://d3i71xaburhd42.cloudfront.net/83fc94939b9cd5dd311a6b457ad865ac67783b8f/3-Figure1-1.png
Learning Visual Context for Group Activity Recognition,"['Hangjie Yuan', 'Dong Ni']",,,,
What the Role Is vs. What Plays the Role: Semi-Supervised Event Argument Extraction via Dual Question Answering,"['Yang Zhou', 'Yubo Chen', 'Jun Zhao', 'Yin Wu', 'Jiexin Xu', 'JinLong Li']",,,,
Progressive One-Shot Human Parsing,"['Haoyu He', 'Jing Zhang', 'Bhavani Thuraisingham', 'Dacheng Tao']",https://arxiv.org/abs/2012.11810,"Prior human parsing models are limited to parsing humans into classes pre-defined in the training data, which is not flexible to generalize to unseen classes, e.g., new clothing in fashion analysis. In this paper, we propose a new problem named one-shot human parsing (OSHP) that requires to parse human into an open set of reference classes defined by any single reference example. During training, only base classes defined in the training set are exposed, which can overlap with part of reference classes. In this paper, we devise a novel Progressive One-shot Parsing network (POPNet) to address two critical challenges , i.e., testing bias and small sizes. POPNet consists of two collaborative metric learning modules named Attention Guidance Module and Nearest Centroid Module, which can learn representative prototypes for base classes and quickly transfer the ability to unseen classes during testing, thereby reducing testing bias. Moreover, POPNet adopts a progressive human parsing framework that can incorporate the learned knowledge of parent classes at the coarse granularity to help recognize the descendant classes at the fine granularity, thereby handling the small sizes issue. Experiments on the ATR-OS benchmark tailored for OSHP demonstrate POPNet outperforms other representative one-shot segmentation models by large margins and establishes a strong baseline. Source code can be found at https://github.com/Charleshhy/One-shot-Human-Parsing.",以前の人間の解析モデルは、トレーニングデータで事前定義されたクラスに人間を解析することに限定されていました。これは、ファッション分析の新しい服など、目に見えないクラスに一般化する柔軟性がありません。この論文では、単一の参照例によって定義された参照クラスのオープンセットに人間を解析する必要があるワンショット人間解析（OSHP）という名前の新しい問題を提案します。トレーニング中は、トレーニングセットで定義された基本クラスのみが公開され、参照クラスの一部と重複する可能性があります。このホワイトペーパーでは、バイアスのテストとサイズの小ささという2つの重要な課題に対処するために、新しいプログレッシブワンショット解析ネットワーク（POPNet）を考案しました。 POPNetは、Attention GuidanceModuleとNearestCentroid Moduleという2つの協調的なメトリック学習モジュールで構成されています。これらは、基本クラスの代表的なプロトタイプを学習し、テスト中に見えないクラスに機能をすばやく転送して、テストのバイアスを軽減します。さらに、POPNetは、親クラスの学習した知識を粗い粒度で組み込むことができるプログレッシブヒューマン解析フレームワークを採用し、子孫クラスを細かい粒度で認識できるようにして、小さなサイズの問題を処理します。 OSHP用に調整されたATR-OSベンチマークでの実験は、POPNetが他の代表的なワンショットセグメンテーションモデルを大幅に上回り、強力なベースラインを確立していることを示しています。ソースコードはhttps://github.com/Charleshhy/One-shot-Human-Parsingにあります。,https://d3i71xaburhd42.cloudfront.net/e0711e3ed23c3d7cc2ee725d9f7b06e40ee76524/1-Figure1-1.png
Mining EL Bases with Adaptable Role Depth,"['Ricardo Guimarães', 'Ana Ozaki', 'Cosimo Persia', 'Baris Sertkaya']",,,,
Parameterized Logical Theories,['Fangzhen Lin'],,,,
Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud,"['Mutian Xu', 'Junhao Zhang', 'Zhipeng Zhou', 'Mingye Xu', 'Xiaojuan Qi', 'Yu Qiao']",https://arxiv.org/abs/2012.10921,"In 2D image processing, some attempts decompose images into high and low frequency components for describing edge and smooth parts respectively. Similarly, the contour and flat area of 3D objects, such as the boundary and seat area of a chair, describe different but also complementary geometries. However, such investigation is lost in previous deep networks that understand point clouds by directly treating all points or local patches equally. To solve this problem, we propose Geometry-Disentangled Attention Network (GDANet). GDANet introduces Geometry-Disentangle Module to dynamically disentangle point clouds into the contour and flat part of 3D objects, respectively denoted by sharp and gentle variation components. Then GDANet exploits Sharp-Gentle Complementary Attention Module that regards the features from sharp and gentle variation components as two holistic representations, and pays different attentions to them while fusing them respectively with original point cloud features. In this way, our method captures and refines the holistic and complementary 3D geometric semantics from two distinct disentangled components to supplement the local information. Extensive experiments on 3D object classification and segmentation benchmarks demonstrate that GDANet achieves the state-of-the-arts with fewer parameters.",2D画像処理では、エッジ部分と滑らかな部分をそれぞれ記述するために、画像を高周波成分と低周波成分に分解する試みがいくつかあります。同様に、椅子の境界や座席領域など、3Dオブジェクトの輪郭と平坦な領域は、異なるが補完的な形状を表します。ただし、このような調査は、すべてのポイントまたはローカルパッチを直接平等に扱うことによってポイントクラウドを理解する以前のディープネットワークでは失われます。この問題を解決するために、Geometry-Disentangled Attention Network（GDANet）を提案します。 GDANetは、Geometry-Disentangle Moduleを導入して、点群を3Dオブジェクトの輪郭部分と平坦部分に動的に解きほぐします。次に、GDANetは、シャープで穏やかなバリエーションコンポーネントの特徴を2つの全体的な表現と見なし、それぞれを元のポイントクラウドの特徴と融合させながら、それらに異なる注意を払う、Sharp-Gentle Complementary AttentionModuleを活用します。このようにして、私たちの方法は、ローカル情報を補足するために、2つの異なる解きほぐされたコンポーネントから全体的で補完的な3D幾何学的セマンティクスをキャプチャして改良します。 3Dオブジェクトの分類とセグメンテーションのベンチマークに関する広範な実験は、GDANetがより少ないパラメーターで最先端を達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/8eeebb2f74a2a12251442942b619b2846ed5796c/1-Figure1-1.png
Generalize a Small Pre-Trained Model to Arbitrarily Large TSP Instances,"['Zhang-Hua Fu', 'Kai-Bin Qiu', 'Hongyuan Zha']",https://arxiv.org/abs/2012.10658,"For the traveling salesman problem (TSP), the existing supervised learning based algorithms suffer seriously from the lack of generalization ability. To overcome this drawback, this paper tries to train (in supervised manner) a small-scale model, which could be repetitively used to build heat maps for TSP instances of arbitrarily large size, based on a series of techniques such as graph sampling, graph converting and heat maps merging. Furthermore, the heat maps are fed into a reinforcement learning approach (Monte Carlo tree search), to guide the search of high-quality solutions. Experimental results based on a large number of instances (with up to 10,000 vertices) show that, this new approach clearly outperforms the existing machine learning based TSP algorithms, and significantly improves the generalization ability of the trained","巡回セールスマン問題（TSP）の場合、既存の教師あり学習ベースのアルゴリズムは、一般化能力の欠如に深刻な問題を抱えています。この欠点を克服するために、このペーパーでは、グラフサンプリング、グラフなどの一連の手法に基づいて、任意の大きなサイズのTSPインスタンスのヒートマップを作成するために繰り返し使用できる小規模モデルを（監視された方法で）トレーニングしようとします。変換とヒートマップのマージ。さらに、ヒートマップは強化学習アプローチ（モンテカルロ木探索）に入力され、高品質のソリューションの検索をガイドします。多数のインスタンス（最大10,000個の頂点）に基づく実験結果は、この新しいアプローチが既存の機械学習ベースのTSPアルゴリズムを明らかに上回り、トレーニングを受けた一般化能力を大幅に向上させることを示しています。",https://d3i71xaburhd42.cloudfront.net/8ce9f4b263a2e8e283c304d446a9d2bacd533e1c/3-Figure1-1.png
Gradient Regularized Contrastive Learning for Continual Domain Adaptation,"['Shixiang Tang', 'Peng Su', 'Dapeng Chen', 'Wanli Ouyang']",,,,
Synthesis of Search Heuristics for Temporal Planning via Reinforcement Learning,"['Andrea Micheli', 'Alessandro Valentini']",,"Automated temporal planning is the problem of synthesizing, starting from a model of a system, a course of actions to achieve a desired goal when temporal constraints, such as deadlines, are present in the problem. Despite considerable successes in the literature, scalability is still a severe limitation for existing planners, especially when confronted with real-world, industrial scenarios. In this paper, we aim at exploiting recent advances in reinforcement learning, for the synthesis of heuristics for temporal planning. Starting from a set of problems of interest for a specific domain, we use a customized reinforcement learning algorithm to construct a value function that is able to estimate the expected reward for as many problems as possible. We use a reward schema that captures the semantics of the temporal planning problem and we show how the value function can be transformed in a planning heuristic for a semi-symbolic heuristic search exploration of the planning model. We show on two case studies how this method can be used to extend the reach of current temporal planning technology with encouraging results.",自動化された時間的計画は、システムのモデルから始めて、期限などの時間的制約が問題に存在する場合に、目的の目標を達成するための一連のアクションを合成する問題です。文献でかなりの成功を収めているにもかかわらず、スケーラビリティは、特に現実の産業シナリオに直面した場合、既存のプランナーにとって依然として厳しい制限です。この論文では、強化学習の最近の進歩を活用して、時間的計画のためのヒューリスティックを統合することを目指しています。特定のドメインに関心のある一連の問題から始めて、カスタマイズされた強化学習アルゴリズムを使用して、できるだけ多くの問題に対して期待される報酬を推定できる値関数を構築します。時間的計画問題のセマンティクスをキャプチャする報酬スキーマを使用し、計画モデルの半記号的ヒューリスティック検索探索のために、計画ヒューリスティックで値関数をどのように変換できるかを示します。 2つのケーススタディで、この方法を使用して現在の時間計画テクノロジの範囲を拡大し、有望な結果を得る方法を示します。,https://d3i71xaburhd42.cloudfront.net/e6e6da82a45728da81dadd50d03a59ca0eea7185/3-Figure1-1.png
Isolation Graph Kernel,"['Bi-Cun Xu', 'Kai Ming Ting', 'Yuan Jiang']",,,,
Scaling-Up Robust Gradient Descent Techniques,['Matthew J Holland'],,,,
Improving the Performance-Compatibility Tradeoff with Personalized Objective Functions,"['Jonathan Martinez', 'Kobi Gal', 'Ece Kamar', 'Levi H. S. Lelis']",,,,
Storage Fit Learning with Feature Evolvable Streams,"['Bo-Jian Hou', 'Yu-Hu Yan', 'Peng Zhao', 'Zhi-Hua Zhou']",https://arxiv.org/abs/2007.11280,"Feature evolvable learning has been widely studied in recent years where old features will vanish and new features will emerge when learning with streams. Conventional methods usually assume that a label will be revealed after prediction at each time step. However, in practice, this assumption may not hold whereas no label will be given at most time steps. To tackle this problem, we leverage the technique of manifold regularization to utilize the previous similar data to assist the refinement of the online model. Nevertheless, this approach needs to store all previous data which is impossible in learning with streams that arrive sequentially in large volume. Thus we need a buffer to store part of them. Considering that different devices may have different storage budgets, the learning approaches should be flexible subject to the storage budget limit. In this paper, we propose a new setting: Storage-Fit Feature-Evolvable streaming Learning (SF2EL) which incorporates the issue of rarely-provided labels into feature evolution. Our framework is able to fit its behavior to different storage budgets when learning with feature evolvable streams with unlabeled data. Besides, both theoretical and empirical results validate that our approach can preserve the merit of the original feature evolvable learning i.e., can always track the best baseline and thus perform well at any time step.",機能の進化可能な学習は近年広く研究されており、ストリームを使用して学習すると、古い機能が消え、新しい機能が出現します。従来の方法は通常、各タイムステップでの予測後にラベルが明らかになることを前提としています。ただし、実際には、この仮定は当てはまらない可能性がありますが、ほとんどのタイムステップではラベルが付けられません。この問題に取り組むために、マニフォールド正規化の手法を活用して、以前の同様のデータを利用し、オンラインモデルの改良を支援します。それにもかかわらず、このアプローチでは、以前のすべてのデータを保存する必要があります。これは、大量に順次到着するストリームでは学習できません。したがって、それらの一部を格納するためのバッファが必要です。デバイスごとにストレージバジェットが異なる可能性があることを考慮すると、学習アプローチはストレージバジェットの制限に応じて柔軟に行う必要があります。このホワイトペーパーでは、新しい設定を提案します。ストレージフィット機能-進化可能なストリーミング学習（SF2EL）は、めったに提供されないラベルの問題を機能進化に組み込みます。私たちのフレームワークは、ラベルのないデータを使用して機能を進化させることができるストリームで学習するときに、その動作をさまざまなストレージバジェットに適合させることができます。さらに、理論的結果と経験的結果の両方で、私たちのアプローチが元の機能の進化可能な学習のメリットを維持できること、つまり、常に最良のベースラインを追跡できるため、どのタイムステップでも良好に機能することが検証されます。,https://d3i71xaburhd42.cloudfront.net/38e76887033f85efa63eed48159d191cbf536a27/3-Figure1-1.png
Analysing the Noise Model Error for Realistic Noisy Label Data,"['Michael A. Hedderich', 'Dawei Zhu', 'Dietrich Klakow']",https://arxiv.org/abs/2101.09763,"Distant and weak supervision allow to obtain large amounts of labeled training data quickly and cheaply, but these automatic annotations tend to contain a high amount of errors. A popular technique to overcome the negative effects of these noisy labels is noise modelling where the underlying noise process is modelled. In this work, we study the quality of these estimated noise models from the theoretical side by deriving the expected error of the noise model. Apart from evaluating the theoretical results on commonly used synthetic noise, we also publish NoisyNER, a new noisy label dataset from the NLP domain that was obtained through a realistic distant supervision technique. It provides seven sets of labels with differing noise patterns to evaluate different noise levels on the same instances. Parallel, clean labels are available making it possible to study scenarios where a small amount of gold-standard data can be leveraged. Our theoretical results and the corresponding experiments give insights into the factors that influence the noise model estimation like the noise distribution and the sampling technique. Introduction One of the factors in the success of deep neural networks is the availability of large, labeled datasets. Where such labeled data is not available, distant and weak supervision have become popular. Related but different to semisupervised learning, in distant supervision, the unlabeled data is automatically annotated by a separate process using e.g. rules and heuristics created by expert (Ratner et al. 2016) or exploiting the context of images (Mahajan et al. 2018). For tasks like information extraction from text (Mintz et al. 2009), this has become one of the dominant techniques to overcome the lack of labeled data. While distant supervision allows generating labels in a cheap and fast way, these labels tend to contain more errors than gold standard ones and training with this additional data might even deteriorate the performance of a classifier (see e.g. Fang and Cohn (2016)). Effectively leveraging this noisily-labeled data for machine learning algorithms has, therefore, become a very active field of research. One of the major approaches is the explicit modeling of the noise. This Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. base model noise model y clean labels noisy labels ŷ Figure 1: Visualization of the general noise model architecture. The base model works directly on the clean data and predicts the clean label y. For noisily-labeled data, a noise model is added after the base model’s predictions. general concept is task-independent and can be added to existing deep learning architectures. It is visualized in Figure 1. The base model is the model that was originally developed for a specific classification task. It is directly used during testing and when dealing with other clean data. When working with noisily-labeled data during training, a noise model is added after the base model’s output. The noise model is an estimate of the underlying noise process. The training process of the base model can benefit from it as the noise model can be seen as changing the distribution of the labels from the clean to the noisy. This will be properly defined below. Many works on noise modeling assume that no manually annotated, clean data is available. The recent trend in fewshot learning and specific works like (Lauscher et al. 2020; Hedderich et al. 2020a) have shown, however, that it is both realistic and beneficial to assume a small amount of manually labeled instances. This motivates us to study in this work scenarios where a small amount of clean, gold-standard data, as well as a large amount of noisily labeled data, are available. In this paper, we focus on the quality of the noise model. The better such a model is estimated, the better it can model the relationship between clean and noisy labels. We are interested in the factors on which the quality of the noise model depends. We show, both theoretically and empirically, the influence of the clean data and the noise properties. We also propose to adapt the sampling technique to obtain more accurate estimates. Apart from helping to improve the understanding of these noise models in general, we hope that the insights can also be useful guidance for practitioners. In the noisy labels literature, theoretical insights are often evaluated only on simulated noise processes, e.g. on MNIST with added single-label-flip noise (Reed et al. 2015; Bekker ar X iv :2 10 1. 09 76 3v 1 [ cs .L G ] 2 4 Ja n 20 21 and Goldberger 2016; Goldberger and Ben-Reuven 2016; Patrini et al. 2017; Han et al. 2018). This synthetic noise has the advantage that it can be controlled completely and allows to rigorously and continuously evaluate aspects like the noise level. However, certain assumptions about the noise have to be taken. And these are usually the same assumptions that are chosen for the noise model itself. It might, therefore, not be too surprising that such a model is suited for such a noise. Recently, efforts have been taken to also evaluate on more realistic scenarios, mostly in the vision domain, e.g. the Clothing1M dataset by Xiao et al. (2015). We want to add to this by making available a noisy label dataset from the natural language processing (NLP) domain based on an existing named entity recognition (NER) corpus. It provides parallel clean and noisy labels for the full data allowing to evaluate different scenarios of resource availability of both clean and noisy data. This new dataset also contains properties that can make learning with noisy labels more challenging such as skewed label distributions and a noise level higher than the true label probability in some settings. In contrast to existing work, we provide seven different sets of noisy labels, each obtained by a realistic noise process via different heuristics in the distant supervision. This makes it possible to experiment with different noise levels for the same instances. The dataset along with the code for the experiments is made publicly available1. Our key contributions: • A derivation of the expected error of the noise model estimated from pairs of clean and noisy labels with empirical verification of the derived results on both simulated and realistic noisy labels. • A set of experiments analyzing how the noise model estimation influences the test performance of the base model. • NoisyNER, an NLP dataset with noisy labels obtained through non-synthetic, realistic distant supervision that also provides different levels of noise and parallel clean labels. Background We are given a dataset D consisting of instances (x, ŷ) where ŷ is a noisy label that can differ from the unknown, clean/true label y. Both clean and noisy label have one of k possible label values/classes. We assume that the change from the clean to the noisy label was performed by a probabilistic noise process described as p(ŷ = j|y = i). This describes the probability of a true label y being changed from value i to the noisy label ŷ with label value j. With probability p(ŷ = j|y = j) the label value is kept unchanged. This is a common approach to describe noisy label settings. Under this process, a uniform noise (Larsen et al. 1998) with noise level is obtained with puni(ŷ = j|y = i) = { 1− , for i = j k−1 , for i 6= j (1) https://github.com/uds-lsv/noise-estimation 0 2 4 6 8 noisy label y 0 2 4 6 8 cl ea n la be l y (a) uniform 0 2 4 6 8 noisy label y 0 2 4 6 8 cl ea n la be l y (b) single-flip 0 2 4 6 8 noisy label y 0 2 4 6 8 cl ea n la be l y 0.0 0.2 0.4 0.6 0.8 1.0 (c) multi-flip Figure 2: Different noise processes visualized as noise matrices M : uniform noise ( = 0.5), single-flip noise ( = 0.3) and multi-flip noise ( = 0.4). and a single label-flip noise (Reed et al. 2015) via pflip(ŷ = j|y = i) = { 1− , for i = j , for one i 6= j 0, else (2) In this work, we will use the more general form that just requires that a noise process can be described with a valid noise transition probability p(ŷ = j|y = i) (Bekker and Goldberger 2016), i.e. k ∑ j=1 p(ŷ = j|y = i) = 1 and p(ŷ = j|y = i) ≥ 0 ∀i, j. (3) This allows to model more complex noise processes where a true label can be confused with multiple other labels at different noise rates/probabilities. We call this multi-flip noise. This definition generalizes to multi-class classification what in the binary case Natarajan et al. (2013) and Scott, Blanchard, and Handy (2013) describe as class-conditional and asymmetric noise. It is called Markov label corruption by van Rooyen and Williamson (2017). The noise process can also be described as a matrix M ∈ Rk×k where Mi,j = p(ŷ = j|y = i). (4) The matrix M is called confusion or noise transition matrix. See Figure 2 for example matrices with uniform, single-flip and a more complex multi-flip noise. For a multi-class classification setting, this noise process results in the following relation: p(ŷ = j|x) = k ∑ i=1 p(ŷ = j|y = i)p(y = i|x) (5) This is used to adapt the predictions from the clean label distribution p(y = i|x) (learned by the base model) to the noisy label distribution p(ŷ = j|x) for the noisily labeled data via the noise process or model p(ŷ = j|y = i). Several ways have been proposed to estimate the noise model when only noisy data is available. This includes the use of expert insight (Mnih and Hinton 2012), EM-algorithm (Bekker and Goldberger 2016; Paul et al. 2019; Chen et al. 2019a), backpropagation with regularizers (Sukhbaatar et al. 2015; Luo et al. 2017) and the estimates of a pretrained neural network (Goldberger and Ben-Reuven 2016; Patrini et al. 2017; Dgani, Greenspan, and Goldberger 2018; Wang et al. 2019). For settings where a small portion of clean data can be used, noise model estimation methods have been proposed by Xiao et al. (2015); Fang and Cohn (2016); Hedderich and Klakow (2018); Hendrycks et al. (2018); Lange, Hedderich",遠く離れた弱い監視により、大量のラベル付きトレーニングデータを迅速かつ安価に取得できますが、これらの自動注釈には大量のエラーが含まれる傾向があります。これらのノイズの多いラベルの悪影響を克服するための一般的な手法は、基礎となるノイズプロセスをモデル化するノイズモデリングです。この作業では、ノイズモデルの予想誤差を導出することにより、理論的な側面からこれらの推定ノイズモデルの品質を調査します。一般的に使用される合成ノイズの理論的結果を評価するほかに、現実的な遠隔監視技術によって取得されたNLPドメインからの新しいノイズの多いラベルデータセットであるNoisyNERも公開しています。同じインスタンスで異なるノイズレベルを評価するために、異なるノイズパターンを持つ7セットのラベルを提供します。並行してクリーンなラベルが利用可能であるため、少量のゴールドスタンダードデータを活用できるシナリオを調査できます。私たちの理論的結果と対応する実験は、ノイズ分布やサンプリング手法などのノイズモデルの推定に影響を与える要因への洞察を提供します。はじめにディープニューラルネットワークの成功の要因の1つは、大きなラベル付きデータセットの可用性です。そのようなラベル付けされたデータが利用できない場合、遠くて弱い監視が一般的になりました。半教師あり学習に関連しますが、遠隔監視では、ラベルのないデータは、専門家によって作成されたルールやヒューリスティックス（Ratner etal。2016）を使用するか、画像のコンテキストを利用する（Mahajan et al.2018）別のプロセスによって自動的に注釈が付けられます。テキストからの情報抽出（Mintz etal。2009）のようなタスクの場合、これはラベル付けされたデータの不足を克服するための主要な手法の1つになっています。遠隔監視により、安価で高速な方法でラベルを生成できますが、これらのラベルにはゴールドスタンダードのラベルよりも多くのエラーが含まれる傾向があり、この追加データを使用してトレーニングすると、分類器のパフォーマンスが低下する可能性があります（Fang and Cohn（2016）などを参照）。したがって、このノイズの多いラベルの付いたデータを機械学習アルゴリズムに効果的に活用することは、非常に活発な研究分野になっています。主要なアプローチの1つは、ノイズの明示的なモデリングです。このCopyright©2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。全著作権所有。ベースモデルノイズモデルyクリーンラベルノイズの多いラベルŷ図1：一般的なノイズモデルアーキテクチャの視覚化。基本モデルはクリーンデータに直接作用し、クリーンラベルyを予測します。ノイズの多いラベルの付いたデータの場合、ベースモデルの予測の後にノイズモデルが追加されます。一般的な概念はタスクに依存せず、既存の深層学習アーキテクチャに追加できます。これは図1に視覚化されています。基本モデルは、特定の分類タスクのために最初に開発されたモデルです。テスト中や他のクリーンなデータを処理するときに直接使用されます。トレーニング中にノイズの多いラベルの付いたデータを操作する場合、ベースモデルの出力の後にノイズモデルが追加されます。ノイズモデルは、基礎となるノイズプロセスの推定値です。ベースモデルのトレーニングプロセスは、ノイズモデルがラベルの分布をクリーンからノイズの多いものに変更するものと見なすことができるため、このモデルから恩恵を受けることができます。これは以下で適切に定義されます。ノイズモデリングに関する多くの研究では、手動で注釈が付けられたクリーンなデータが利用できないことを前提としています。ただし、少数ショット学習や（Lauscheretal。2020; Hedderich etal。2020a）のような特定の作業の最近の傾向は、手動でラベル付けされたインスタンスを少量想定することが現実的かつ有益であることを示しています。これにより、少量のクリーンなゴールドスタンダードデータと大量のノイズの多いラベル付きデータが利用できるこの作業シナリオで研究するようになります。この論文では、ノイズモデルの品質に焦点を当てます。このようなモデルが適切に推定されるほど、クリーンなラベルとノイズの多いラベルの関係を適切にモデル化できます。ノイズモデルの品質が依存する要因に関心があります。理論的にも経験的にも、クリーンなデータとノイズ特性の影響を示します。また、より正確な推定値を取得するために、サンプリング手法を適応させることを提案します。これらのノイズモデルの一般的な理解を深めるのに役立つだけでなく、洞察が実践者にとっても役立つガイダンスになることを願っています。ノイズの多いラベルの文献では、理論的洞察は、シミュレートされたノイズプロセスでのみ評価されることがよくあります。たとえば、シングルラベルフリップノイズが追加されたMNISTで評価されます（Reedetal。2015; Bekker ar X iv：2 10 1. 09 76 3v 1 [cs .LG] 2 4 Ja n 2021およびGoldberger2016; Goldberger and Ben-Reuven 2016; Patrini et al.2017; Han et al.2018）。この合成ノイズには、完全に制御できるという利点があり、ノイズレベルなどの側面を厳密かつ継続的に評価できます。ただし、ノイズに関する特定の仮定を行う必要があります。そして、これらは通常、ノイズモデル自体に選択されたものと同じ仮定です。したがって、そのようなモデルがそのようなノイズに適していることはそれほど驚くべきことではないかもしれません。最近、Xiao et al。によるClothing1Mデータセットなど、主にビジョンドメインで、より現実的なシナリオを評価するための取り組みも行われています。 （2015）。これに、既存の固有表現抽出（NER）コーパスに基づいて、自然言語処理（NLP）ドメインからノイズの多いラベルデータセットを利用できるようにすることで追加したいと思います。完全なデータに並列のクリーンなラベルとノイズの多いラベルを提供し、クリーンなデータとノイズの多いデータの両方のリソース可用性のさまざまなシナリオを評価できるようにします。この新しいデータセットには、偏ったラベル分布や一部の設定での実際のラベル確率よりも高いノイズレベルなど、ノイズの多いラベルでの学習をより困難にする可能性のあるプロパティも含まれています。既存の作業とは対照的に、ノイズの多いラベルの7つの異なるセットを提供します。各セットは、遠隔監視におけるさまざまなヒューリスティックを介した現実的なノイズプロセスによって取得されます。これにより、同じインスタンスに対して異なるノイズレベルを試すことができます。実験用のコードとともにデータセットが公開されています1。私たちの主な貢献：•シミュレートされたノイズのあるラベルと現実的なノイズのあるラベルの両方で得られた結果の経験的検証による、クリーンなラベルとノイズのあるラベルのペアから推定されたノイズモデルの予想誤差の導出。 •ノイズモデルの推定がベースモデルのテストパフォーマンスにどのように影響するかを分析する一連の実験。 •NoisyNERは、非合成の現実的な遠隔監視によって取得されたノイズの多いラベルを含むNLPデータセットであり、さまざまなレベルのノイズと並列のクリーンなラベルも提供します。背景インスタンス（x、ŷ）で構成されるデータセットDが与えられます。ここで、ŷは、未知のクリーン/真のラベルyとは異なる可能性のあるノイズの多いラベルです。クリーンなラベルとノイズの多いラベルの両方に、k個の可能なラベル値/クラスの1つがあります。クリーンラベルからノイズの多いラベルへの変更は、p（ŷ= j | y = i）として記述される確率的ノイズプロセスによって実行されたと想定します。これは、真のラベルyが値iからラベル値jのノイズの多いラベルŷに変更される確率を表します。確率p（ŷ= j | y = j）では、ラベル値は変更されません。これは、ノイズの多いラベル設定を説明するための一般的なアプローチです。このプロセスでは、ノイズレベルの均一なノイズ（Larsen etal。1998）が、puni（ŷ= j | y = i）= {1−、i = jk-1の場合、i 6 = j（1）の場合に得られます。 https://github.com/uds-lsv/noise-estimation 0 2 4 68ノイズの多いラベルy0 2 4 6 8 cl ea n la be ly（a）均一0 2 4 68ノイズの多いラベルy0 2 4 6 8 cl ea n la be ly（b）シングルフリップ0 2 4 68ノイズの多いラベルy0 2 4 6 8 cl ea n la be ly 0.0 0.2 0.4 0.6 0.8 1.0（c）マルチフリップ図2：さまざまなノイズプロセスノイズマトリックスとして視覚化M：均一ノイズ（= 0.5）、シングルフリップノイズ（= 0.3）、マルチフリップノイズ（= 0.4）。 pflip（ŷ= j | y = i）= {1-、for i = j、for one i 6 = j 0、else（2）を介した単一のラベル反転ノイズ（Reed etal。2015） 、有効なノイズ遷移確率p（ŷ= j | y = i）（Bekker and Goldberger 2016）、つまりk ∑ j = 1p（ŷ）でノイズプロセスを記述できることを要求する、より一般的な形式を使用します。 = j | y = i）= 1およびp（ŷ= j | y = i）≥0∀i、j。 （3）これにより、真のラベルが異なるノイズ率/確率で他の複数のラベルと混同される可能性がある、より複雑なノイズプロセスをモデル化できます。これをマルチフリップノイズと呼びます。この定義は、マルチクラス分類に一般化されます。バイナリの場合、Natarajan etal。 （2013）およびScott、Blanchard、およびHandy（2013）は、クラス条件付きおよび非対称ノイズとして説明しています。これは、van Rooyen and Williamson（2017）によってマルコフラベルの破損と呼ばれています。ノイズプロセスは、行列M∈Rk×kとして説明することもできます。ここで、Mi、j = p（ŷ= j | y = i）です。 （4）行列Mは、混同またはノイズ遷移行列と呼ばれます。均一なシングルフリップノイズとより複雑なマルチフリップノイズを持つマトリックスの例については、図2を参照してください。マルチクラス分類設定の場合、このノイズプロセスは次の関係になります。p（ŷ= j | x）= k ∑ i = 1p（ŷ= j | y = i）p（y = i | x）（ 5）これは、クリーンなラベル分布p（y = i | x）（ベースモデルによって学習された）からの予測を、ノイズを介してノイズの多いラベル付けされたデータのノイズの多いラベル分布p（ŷ= j | x）に適合させるために使用されます。プロセスまたはモデルp（ŷ= j | y = i）。ノイズの多いデータしか利用できない場合にノイズモデルを推定するために、いくつかの方法が提案されています。これには、専門家の洞察（Mnih and Hinton 2012）、EMアルゴリズム（Bekker and Goldberger 2016; Pauletal。2019; Chen etal。2019a）、レギュラライザーによるバックプロパゲーション（Sukhbaataretal。2015; Luo etal。 2017）および事前トレーニング済みニューラルネットワークの推定値（Goldberger and Ben-Reuven 2016; Patrini et al.2017; Dgani、Greenspan、and Goldberger 2018; Wang et al.2019）。クリーンなデータのごく一部を使用できる設定については、Xiao etal。によってノイズモデルの推定方法が提案されています。 （2015）; Fang and Cohn（2016）; Hedderich and Klakow（2018）; Hendrycks etal。 （2018）;ランゲ、ヘデリッチ,https://d3i71xaburhd42.cloudfront.net/c95403947e6f15b12bbfd7448b9476cddccf19eb/1-Figure1-1.png
Topology Distance: A Topology Based Approach for Evaluating Generative Adversarial Networks,"['Danijela Horak', 'Simiao Yu', 'Gholamreza Salimi-Khorshidi']",https://arxiv.org/abs/2002.12054,"Automatic evaluation of the goodness of Generative Adversarial Networks (GANs) has been a challenge for the field of machine learning. In this work, we propose a distance complementary to existing measures: Topology Distance (TD), the main idea behind which is to compare the geometric and topological features of the latent manifold of real data with those of generated data. More specifically, we build Vietoris-Rips complex on image features, and define TD based on the differences in persistent-homology groups of the two manifolds. We compare TD with the most commonly used and relevant measures in the field, including Inception Score (IS), Frechet Inception Distance (FID), Kernel Inception Distance (KID) and Geometry Score (GS), in a range of experiments on various datasets. We demonstrate the unique advantage and superiority of our proposed approach over the aforementioned metrics. A combination of our empirical results and the theoretical argument we propose in favour of TD, strongly supports the claim that TD is a powerful candidate metric that researchers can employ when aiming to automatically evaluate the goodness of GANs' learning.",Generative Adversarial Networks（GAN）の良さの自動評価は、機械学習の分野での課題でした。この作業では、既存の測定値を補完する距離を提案します。トポロジ距離（TD）の背後にある主なアイデアは、実際のデータの潜在的な多様体の幾何学的およびトポロジカルな特徴を生成されたデータの特徴と比較することです。より具体的には、画像の特徴に基づいてVietoris-Rips複合体を構築し、2つの多様体の永続ホモロジーグループの違いに基づいてTDを定義します。さまざまなデータセットでのさまざまな実験で、TDを、開始スコア（IS）、フレシェ開始距離（FID）、カーネル開始距離（KID）、ジオメトリスコア（GS）など、この分野で最も一般的に使用されている関連する指標と比較します。 。前述の指標に対する提案されたアプローチの独自の利点と優位性を示します。私たちの経験的結果とTDを支持して提案する理論的議論の組み合わせは、TDがGAN学習の良さを自動的に評価することを目指すときに研究者が採用できる強力な候補指標であるという主張を強く支持します。,https://d3i71xaburhd42.cloudfront.net/57b4ca6091d0f10bd42ba3ba87fbe5d90eaea6d9/4-Figure1-1.png
MFES-HB: Efficient Hyperband with Multi-Fidelity Quality Measurements,"['Yang Li', 'Yu Shen', 'Jiawei Jiang', 'Jinyang Gao', 'Ce Zhang', 'Bin Cui']",https://arxiv.org/abs/2012.03011,"Hyperparameter optimization (HPO) is a fundamental problem in automatic machine learning (AutoML). However, due to the expensive evaluation cost of models (e.g., training deep learning models or training models on large datasets), vanilla Bayesian optimization (BO) is typically computationally infeasible. To alleviate this issue, Hyperband (HB) utilizes the early stopping mechanism to speed up configuration evaluations by terminating those badly-performing configurations in advance. This leads to two kinds of quality measurements: (1) many low-fidelity measurements for configurations that get early-stopped, and (2) few high-fidelity measurements for configurations that are evaluated without being early stopped. The state-of-the-art HB-style method, BOHB, aims to combine the benefits of both BO and HB. Instead of sampling configurations randomly in HB, BOHB samples configurations based on a BO surrogate model, which is constructed with the high-fidelity measurements only. However, the scarcity of high-fidelity measurements greatly hampers the efficiency of BO to guide the configuration search. In this paper, we present MFES-HB, an efficient Hyperband method that is capable of utilizing both the high-fidelity and low-fidelity measurements to accelerate the convergence of HPO tasks. Designing MFES-HB is not trivial as the low-fidelity measurements can be biased yet informative to guide the configuration search. Thus we propose to build a Multi- Fidelity Ensemble Surrogate (MFES) based on the generalized Product of Experts framework, which can integrate useful information from multi-fidelity measurements effectively. The empirical studies on the real-world AutoML tasks demonstrate that MFES-HB can achieve 3.3-8.9x speedups over the state-of-the-art approach - BOHB.",ハイパーパラメータ最適化（HPO）は、自動機械学習（AutoML）の基本的な問題です。ただし、モデルの評価コストが高いため（たとえば、深層学習モデルのトレーニングや大規模なデータセットでのモデルのトレーニング）、バニラベイズ最適化（BO）は通常計算上実行不可能です。この問題を軽減するために、ハイパーバンド（HB）は早期停止メカニズムを利用して、パフォーマンスの悪い構成を事前に終了することにより、構成評価を高速化します。これにより、2種類の品質測定が行われます。（1）早期停止される構成の忠実度の低い測定が多く、（2）早期停止せずに評価される構成の忠実度の高い測定がほとんどありません。最先端のHBスタイルの方法であるBOHBは、BOとHBの両方の利点を組み合わせることを目的としています。 HBで構成をランダムにサンプリングする代わりに、BOHBは、高忠実度の測定のみで構築されたBO代理モデルに基づいて構成をサンプリングします。ただし、忠実度の高い測定値が不足しているため、構成検索をガイドするBOの効率が大幅に低下します。この論文では、HPOタスクの収束を加速するために高忠実度と低忠実度の両方の測定を利用できる効率的なハイパーバンド法であるMFES-HBを紹介します。 MFES-HBの設計は簡単ではありません。忠実度の低い測定にはバイアスがかかる可能性がありますが、構成検索のガイドとして有益です。したがって、マルチフィデリティ測定からの有用な情報を効果的に統合できる、一般化されたProduct of Expertsフレームワークに基づいて、マルチフィデリティアンサンブルサロゲート（MFES）を構築することを提案します。実世界のAutoMLタスクに関する実証的研究は、MFES-HBが最先端のアプローチであるBOHBよりも3.3〜8.9倍のスピードアップを達成できることを示しています。,https://d3i71xaburhd42.cloudfront.net/5d7ed68639fed8d9c381ede0d00e8eab4fc009fb/2-Figure1-1.png
Detecting Adversarial Examples from Sensitivity Inconsistency of Spatial-Transform Domain,"['Jinyu Tian', 'Jiantao Zhou', 'Yuanman Li', 'Jia Duan']",,,,
Towards Faster Deep Collaborative Filtering via Hierarchical Decision Networks,"['Yu Chen', 'Sinno Pan']",,,,
Addressing Action Oscillations through Learning Policy Inertia,"['Chen Chen', 'Hongyao Tang', 'Jianye Hao', 'Wulong Liu', 'Zhaopeng Meng']",,,,
FIMAP: Feature Importance by Minimal Adversarial Perturbation,"['Matt Chapman-Rounds', 'Umang Bhatt', 'Erik Pazos', 'Marc-Andre Schulz', 'Konstantinos Georgatzis']",,,,
Quantification of Resource Production Incompleteness,['Yakoub Salhi'],,,,
Partial-Label and Structure-Constrained Deep Coupled Factorization Network,"['Yan Zhang', 'Zhao Zhang', 'Yang Wang', 'Zheng Zhang', 'Li Zhang', 'Shuicheng Yan', 'Meng Wang']",,,,
Time Series Domain Adaptation via Sparse Associative Structure Alignment,"['Ruichu Cai', 'Jiawei Chen', 'Zijian Li', 'Wei Chen', 'Keli Zhang', 'Junjian Ye', 'Zhuozhang Li', 'Xiaoyan Yang', 'Zhenjie Zhang']",https://arxiv.org/abs/2012.11797,"Domain adaptation on time series data is an important but challenging task. Most of the existing works in this area are based on the learning of the domain-invariant representation of the data with the help of restrictions like MMD. However, such extraction of the domain-invariant representation is a non-trivial task for time series data, due to the complex dependence among the timestamps. In detail, in the fully dependent time series, a small change of the time lags or the offsets may lead to difficulty in the domain invariant extraction. Fortunately, the stability of the causality inspired us to explore the domain invariant structure of the data. To reduce the difficulty in the discovery of causal structure, we relax it to the sparse associative structure and propose a novel sparse associative structure alignment model for domain adaptation. First, we generate the segment set to exclude the obstacle of offsets. Second, the intra-variables and inter-variables sparse attention mechanisms are devised to extract associative structure time-series data with considering time lags. Finally, the associative structure alignment is used to guide the transfer of knowledge from the source domain to the target one. Experimental studies not only verify the good performance of our methods on three real-world datasets but also provide some insightful discoveries on the transferred knowledge.",時系列データのドメイン適応は重要ですが、やりがいのある作業です。この分野の既存の作業のほとんどは、MMDのような制限の助けを借りて、データのドメイン不変表現の学習に基づいています。ただし、このようなドメイン不変表現の抽出は、タイムスタンプ間の複雑な依存関係のため、時系列データにとって重要なタスクです。詳細には、完全に依存する時系列では、タイムラグまたはオフセットの小さな変更により、ドメイン不変抽出が困難になる可能性があります。幸いなことに、因果関係の安定性により、データのドメイン不変構造を調査するようになりました。因果構造の発見の難しさを軽減するために、それをスパース連想構造に緩和し、ドメイン適応のための新しいスパース連想構造アラインメントモデルを提案します。まず、オフセットの障害物を除外するセグメントセットを生成します。第二に、変数内および変数間のスパース注意メカニズムは、タイムラグを考慮して連想構造の時系列データを抽出するために考案されています。最後に、連想構造アラインメントを使用して、ソースドメインからターゲットドメインへの知識の転送をガイドします。実験的研究は、3つの実世界のデータセットでのメソッドの優れたパフォーマンスを検証するだけでなく、転送された知識に関する洞察に満ちた発見も提供します。,https://d3i71xaburhd42.cloudfront.net/7f8c23d78fff2e5e1243659480a0eb5728361315/1-Figure1-1.png
Multi-Modal Graph Fusion for Named Entity Recognition with Targeted Visual Guidance,"['Dong Zhang', 'Suzhong Wei', 'Shoushan Li', 'Hanqian Wu', 'Zhu Qiaoming', 'Zhou Guodong']",,,,
Robust Multi-Modality Person Re-Identification,"['Aihua Zheng', 'Zihan Chen', 'Zi Wang', 'Chenglong Li', 'Jin Tang']",,,,
Learning to Truncate Ranked Lists for Information Retrieval,"['Chen Wu', 'Ruqing Zhang', 'Jiafeng Guo', 'Yixing Fan', 'Yanyan Lan', 'Xueqi Cheng']",,,,
Exploration by Maximizing Renyi Entropy for Reward-Free RL Framework,"['Chuheng Zhang', 'Yuanying Cai', 'Longbo Huang', 'Jian Li']",https://arxiv.org/abs/2006.06193,"Exploration is essential for reinforcement learning (RL). To face the challenges of exploration, we consider a reward-free RL framework that completely separates exploration from exploitation and brings new challenges for exploration algorithms. In the exploration phase, the agent learns an exploratory policy by interacting with a reward-free environment and collects a dataset of transitions by executing the policy. In the planning phase, the agent computes a good policy for any reward function based on the dataset without further interacting with the environment. This framework is suitable for the meta RL setting where there are many reward functions of interest. In the exploration phase, we propose to maximize the Renyi entropy over the state-action space and justify this objective theoretically. The success of using Renyi entropy as the objective results from its encouragement to explore the hard-to-reach state-actions. We further deduce a policy gradient formulation for this objective and design a practical exploration algorithm that can deal with complex environments. In the planning phase, we solve for good policies given arbitrary reward functions using a batch RL algorithm. Empirically, we show that our exploration algorithm is effective and sample efficient, and results in superior policies for arbitrary reward functions in the planning phase.",強化学習（RL）には探索が不可欠です。探索の課題に直面するために、探索と搾取を完全に分離し、探索アルゴリズムに新たな課題をもたらす、報酬のないRLフレームワークを検討します。探索フェーズでは、エージェントは報酬のない環境と対話することによって探索的ポリシーを学習し、ポリシーを実行することによって遷移のデータセットを収集します。計画段階では、エージェントは、環境とさらに対話することなく、データセットに基づいて報酬関数の適切なポリシーを計算します。このフレームワークは、関心のある報酬関数が多数あるメタRL設定に適しています。探索段階では、状態-アクション空間でレニーエントロピーを最大化し、この目的を理論的に正当化することを提案します。レニーエントロピーを目的として使用することに成功したのは、到達が困難な国家行動を探求することを奨励した結果です。さらに、この目的のためのポリシー勾配の定式化を推測し、複雑な環境を処理できる実用的な探索アルゴリズムを設計します。計画段階では、バッチRLアルゴリズムを使用して、任意の報酬関数が与えられた場合の適切なポリシーを解決します。経験的に、探索アルゴリズムが効果的でサンプル効率が高く、計画段階で任意の報酬関数に対して優れたポリシーが得られることを示します。,
Extracting Zero-Shot Structured Information from Form-like Documents: Pretraining with Keys and Triggers,"['Rongyu Cao', 'Ping Luo']",,,,
Dynamic Anchor Learning for Arbitrary-Oriented Object Detection,"['Qi Ming', 'Zhiqiang Zhou', 'Lingjuan Miao', 'Hongwei Zhang', 'Linhao Li']",https://arxiv.org/abs/2012.04150,"Arbitrary-oriented objects widely appear in natural scenes, aerial photographs, remote sensing images, etc., thus arbitrary-oriented object detection has received considerable attention. Many current rotation detectors use plenty of anchors with different orientations to achieve spatial alignment with ground truth boxes, then Intersection-over-Union (IoU) is applied to sample the positive and negative candidates for training. However, we observe that the selected positive anchors cannot always ensure accurate detections after regression, while some negative samples can achieve accurate localization. It indicates that the quality assessment of anchors through IoU is not appropriate, and this further lead to inconsistency between classification confidence and localization accuracy. In this paper, we propose a dynamic anchor learning (DAL) method, which utilizes the newly defined matching degree to comprehensively evaluate the localization potential of the anchors and carry out a more efficient label assignment process. In this way, the detector can dynamically select high-quality anchors to achieve accurate object detection, and the divergence between classification and regression will be alleviated. With the newly introduced DAL, we achieve superior detection performance for arbitrary-oriented objects with only a few horizontal preset anchors. Experimental results on three remote sensing datasets HRSC2016, DOTA, UCAS-AOD as well as a scene text dataset ICDAR 2015 show that our method achieves substantial improvement compared with the baseline model. Besides, our approach is also universal for object detection using horizontal bound box. The code and models are available at this https URL.",自然シーン、航空写真、リモートセンシング画像などに任意の物体が広く出現するため、任意の物体検出が注目されています。多くの現在の回転検出器は、グラウンドトゥルースボックスとの空間的位置合わせを実現するためにさまざまな方向のアンカーを多数使用します。次に、Intersection-over-Union（IoU）を適用して、トレーニングの正と負の候補をサンプリングします。ただし、一部のネガティブサンプルでは正確なローカリゼーションを実現できる一方で、選択したポジティブアンカーは回帰後の正確な検出を常に保証できるとは限りません。これは、IoUを介したアンカーの品質評価が適切ではないことを示しており、これにより、分類の信頼性とローカリゼーションの精度の間に不整合が生じます。本論文では、新たに定義されたマッチング度を利用してアンカーの局在化の可能性を包括的に評価し、より効率的なラベル割り当てプロセスを実行する動的アンカー学習（DAL）法を提案します。このようにして、検出器は高品質のアンカーを動的に選択して正確なオブジェクト検出を実現でき、分類と回帰の間の相違が緩和されます。新たに導入されたDALにより、水平方向のプリセットアンカーが少ないだけで、任意の方向のオブジェクトに対して優れた検出パフォーマンスを実現します。 3つのリモートセンシングデータセットHRSC2016、DOTA、UCAS-AOD、およびシーンテキストデータセットICDAR 2015の実験結果は、私たちの方法がベースラインモデルと比較して大幅な改善を達成していることを示しています。その上、私たちのアプローチは、水平バウンドボックスを使用したオブジェクト検出にも普遍的です。コードとモデルは、このhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/5cc2198ddbbec84f04019b1fd3f02798673dbb91/1-Figure1-1.png
f-Aware Conflict Prioritization & Improved Heuristics for Conflict-Based Search,"['Eli Boyarski', 'Ariel Felner', 'Pierre Le Bodic', 'Daniel Harabor', 'Peter Stuckey', 'Sven Koenig']",,,,
From Behavioral Theories to Econometrics: Inferring Preferences of Human Agents from Data on Repeated Interactions,['Gali Noti'],,,,
Deep Graph-Neighbor Coherence Preserving Network for Unsupervised Cross-Modal Hashing,"['Jun Yu', 'Hao Zhou', 'Yibing Zhan', 'Dacheng Tao']",,,,
Dynamic Multi-Context Attention Networks for Citation Forecasting of Scientific Publications,"['Taoran Ji', 'Nathan Self', 'Kaiqun Fu', 'Zhqian Chen', 'Naren Ramakrishnan', 'Chang-Tien Lu']",,,,
Semi-Supervised Node Classification on Graphs: Markov Random Fields vs. Graph Neural Networks,"['Binghui Wang', 'Jinyuan Jia', 'Neil Zhenqiang Gong']",https://arxiv.org/abs/2012.13085,"Semi-supervised node classification on graph-structured data has many applications such as fraud detection, fake account and review detection, user’s private attribute inference in social networks, and community detection. Various methods such as pairwise Markov Random Fields (pMRF) and graph neural networks were developed for semi-supervised node classification. pMRF is more efficient than graph neural networks. However, existing pMRF-based methods are less accurate than graph neural networks, due to a key limitation that they assume a heuristics-based constant edge potential for all edges. In this work, we aim to address the key limitation of existing pMRF-based methods. In particular, we propose to learn edge potentials for pMRF. Our evaluation results on various types of graph datasets show that our optimized pMRFbased method consistently outperforms existing graph neural networks in terms of both accuracy and efficiency. Our results highlight that previous work may have underestimated the power of pMRF for semi-supervised node classification.",グラフ構造化データの半教師ありノード分類には、不正検出、偽のアカウントとレビューの検出、ソーシャルネットワークでのユーザーのプライベート属性の推論、コミュニティの検出など、多くのアプリケーションがあります。ペアワイズマルコフ確率場（pMRF）やグラフニューラルネットワークなどのさまざまな方法が、半教師ありノード分類のために開発されました。 pMRFは、グラフニューラルネットワークよりも効率的です。ただし、既存のpMRFベースの方法は、すべてのエッジに対してヒューリスティックベースの一定のエッジポテンシャルを想定しているという重要な制限があるため、グラフニューラルネットワークよりも精度が低くなります。この作業では、既存のpMRFベースの方法の重要な制限に対処することを目指しています。特に、pMRFのエッジポテンシャルを学習することを提案します。さまざまなタイプのグラフデータセットに対する評価結果は、最適化されたpMRFベースの方法が、精度と効率の両方の点で既存のグラフニューラルネットワークを一貫して上回っていることを示しています。私たちの結果は、以前の研究が半教師ありノード分類に対するpMRFの能力を過小評価していた可能性があることを強調しています。,https://d3i71xaburhd42.cloudfront.net/48299646b03df5ed39a3e83a5bbd5c103b2591c4/6-Figure1-1.png
Improving Gradient Flow with Unrolled Highway Expectation Maximization,"['Chonghyuk Song', 'Inwook Shim', 'Eunseok Kim']",https://arxiv.org/abs/2012.04926,"Integrating model-based machine learning methods into deep neural architectures allows one to leverage both the expressive power of deep neural nets and the ability of model-based methods to incorporate domain-specific knowledge. In particular, many works have employed the expectation maximization (EM) algorithm in the form of an unrolled layer-wise structure that is jointly trained with a backbone neural network. However, it is difficult to discriminatively train the backbone network by backpropagating through the EM iterations as they are prone to the vanishing gradient problem. To address this issue, we propose Highway Expectation Maximization Networks (HEMNet), which is comprised of unrolled iterations of the generalized EM (GEM) algorithm based on the Newton-Rahpson method. HEMNet features scaled skip connections, or highways, along the depths of the unrolled architecture, resulting in improved gradient flow during backpropagation while incurring negligible additional computation and memory costs compared to standard unrolled EM. Furthermore, HEMNet preserves the underlying EM procedure, thereby fully retaining the convergence properties of the original EM algorithm. We achieve significant improvement in performance on several semantic segmentation benchmarks and empirically show that HEMNet effectively alleviates gradient decay.",モデルベースの機械学習手法をディープニューラルアーキテクチャに統合することで、ディープニューラルネットの表現力と、ドメイン固有の知識を組み込むモデルベースの手法の能力の両方を活用できます。特に、多くの研究では、バックボーンニューラルネットワークと共同でトレーニングされた展開されたレイヤーワイズ構造の形で期待値最大化（EM）アルゴリズムが採用されています。ただし、勾配消失問題が発生しやすいため、EM反復を逆伝播してバックボーンネットワークを識別的にトレーニングすることは困難です。この問題に対処するために、Newton-Rahpson法に基づく一般化EM（GEM）アルゴリズムの展開された反復で構成されるHighway Expectation Maximization Networks（HEMNet）を提案します。 HEMNetは、展開されたアーキテクチャの深さに沿ってスケーリングされたスキップ接続または高速道路を備えているため、標準の展開されたEMと比較して、追加の計算とメモリのコストはごくわずかですが、バックプロパゲーション中の勾配フローが改善されます。さらに、HEMNetは基礎となるEMプロシージャを保持するため、元のEMアルゴリズムの収束プロパティを完全に保持します。いくつかのセマンティックセグメンテーションベンチマークでパフォーマンスの大幅な向上を達成し、HEMNetが勾配減衰を効果的に軽減することを経験的に示しています。,https://d3i71xaburhd42.cloudfront.net/39a3bc57da3e8507ee0d60f074ae135aa2f649a3/3-Figure1-1.png
How to Save your Annotation Cost for Panoptic Segmentation?,"['Xuefeng Du', 'ChenHan Jiang', 'Hang Xu', 'Gengwei Zhang', 'Zhenguo Li']",,,,
Learning Representations for Incomplete Time Series Clustering,"['Qianli Ma', 'Chuxin Chen', 'Sen Li', 'Garrison Cottrell']",,,,
Regional Attention with Architecture-Rebuilt 3D Network for RGB-D Gesture Recognition,"['Benjia Zhou', 'Yunan Li', 'Jun Wan']",,,,
Coupon Design in Advertising Systems,"['Weiran Shen', 'Pingzhong Tang', 'Xun Wang', 'Yadong Xu', 'Xiwang Yang']",,,,
Adversarial Directed Graph Embedding,"['Shijie Zhu', 'Jianxin Li', 'Hao Peng', 'Senzhang Wang', 'Lifang He']",,,,
Margin of Victory in Tournaments: Structural and Experimental Results,"['Markus Brill', 'Ulrike Schmidt-Kraepelin', 'Warut Suksompong']",,,,
Commission Fee Is Not Enough: A Hierarchical Reinforced Framework for Portfolio Management,"['Rundong Wang', 'Hongxin Wei', 'Bo An', 'Zhouyan Feng', 'Jun Yao']",,,,
Hyperbolic Variational Graph Neural Network for Modeling Dynamic Graphs,"['Li Sun', 'Zhongbao Zhang', 'Jiawei Zhang', 'Feiyang Wang', 'Hao Peng', 'Sen Su', 'Philip S Yu']",,,,
On Generating Plausible Counterfactual and Semi-Factual Explanations for Deep Learning,"['Eoin Kenny', 'Mark Keane']",,,,
Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale,"['Zhengyan Tong', 'Xuanhong Chen', 'Bingbing Ni', 'Xiaohang Wang']",,,,
Recursion in Abstract Argumentation is Hard --- On the Complexity of Semantics Based on Weak Admissibility,"['Wolfgang Dvorak', 'Markus Ulbricht', 'Stefan Woltran']",,,,
A One-Size-Fits-All Solution to Conservative Bandit Problems,"['Yihan Du', 'Siwei Wang', 'Longbo Huang']",https://arxiv.org/abs/2012.07341,"In this paper, we study a family of conservative bandit problems (CBPs) with sample-path reward constraints, i.e., the learner's reward performance must be at least as well as a given baseline at any time. We propose a One-Size-Fits-All solution to CBPs and present its applications to three encompassed problems, i.e. conservative multi-armed bandits (CMAB), conservative linear bandits (CLB) and conservative contextual combinatorial bandits (CCCB). Different from previous works which consider high probability constraints on the expected reward, we focus on a sample-path constraint on the actually received reward, and achieve better theoretical guarantees ($T$-independent additive regrets instead of $T$-dependent) and empirical performance. Furthermore, we extend the results and consider a novel conservative mean-variance bandit problem (MV-CBP), which measures the learning performance with both the expected reward and variability. For this extended problem, we provide a novel algorithm with $O(1/T)$ normalized additive regrets ($T$-independent in the cumulative form) and validate this result through empirical evaluation.",このホワイトペーパーでは、サンプルパスの報酬制約を伴う保守的なバンディット問題（CBP）のファミリーを研究します。つまり、学習者の報酬パフォーマンスは、少なくとも常に所定のベースラインと同じでなければなりません。 CBPに対するOne-Size-Fits-Allソリューションを提案し、そのアプリケーションを3つの包括的な問題、つまり、保守的な多腕バンディット（CMAB）、保守的な線形バンディット（CLB）、および保守的なコンテキストコンビナトリアルバンディット（CCCB）に提示します。期待される報酬に対する高い確率の制約を考慮する以前の作業とは異なり、実際に受け取った報酬に対するサンプルパスの制約に焦点を当て、より優れた理論的保証（T依存ではなくT非依存の付加的な後悔）と経験的パフォーマンスを実現します。さらに、結果を拡張し、期待される報酬と変動性の両方で学習パフォーマンスを測定する、新しい保守的な平均分散バンディット問題（MV-CBP）を検討します。この拡張された問題に対して、O（1 / T）正規化された加法後悔（累積形式でTに依存しない）を使用した新しいアルゴリズムを提供し、経験的評価を通じてこの結果を検証します。,https://d3i71xaburhd42.cloudfront.net/ae90ae196284e210385d2847e9e02b11014cd5ff/7-Figure1-1.png
The Complexity Landscape of Claim-Augmented Argumentation Frameworks,"['Wolfgang Dvorak', 'Alexander Greßler', 'Anna Rapberger', 'Stefan Woltran']",,,,
PGNet: Real-Time Arbitrarily-Shaped Text Spotting with Point Gathering Network,"['Pengfei Wang', 'Chengquan Zhang', 'Fei Qi', 'Shanshan Liu', 'Xiaoqiang Zhang', 'Pengyuan Lyu', 'Junyu Han', 'Jingtuo Liu', 'Errui Ding', 'Guangming Shi']",,,,
Hierarchical Information Passing Based Noise-Tolerant Hybrid Learning for Semi-Supervised Human Parsing,"['Yunan Liu', 'Shanshan Zhang', 'Jian Yang', 'PongChi Yuen']",,,,
ACSNet: Action-Context Separation Network for Weakly Supervised Temporal Action Localization,"['Ziyi Liu', 'Le Wang', 'Qilin Zhang', 'Wei Tang', 'Junsong Yuan', 'Nanning Zheng', 'Gang Hua']",,"The object of Weakly-supervised Temporal Action Localization (WS-TAL) is to localize all action instances in an untrimmed video with only video-level supervision. Due to the lack of frame-level annotations during training, current WS-TAL methods rely on attention mechanisms to localize the foreground snippets or frames that contribute to the video-level classification task. This strategy frequently confuse context with the actual action, in the localization result. Separating action and context is a core problem for precise WS-TAL, but it is very challenging and has been largely ignored in the literature. In this paper, we introduce an Action-Context Separation Network (ACSNet) that explicitly takes into account context for accurate action localization. It consists of two branches (i.e., the Foreground-Background branch and the Action-Context branch). The ForegroundBackground branch first distinguishes foreground from background within the entire video while the Action-Context branch further separates the foreground as action and context. We associate video snippets with two latent components (i.e., a positive component and a negative component), and their different combinations can effectively characterize foreground, action and context. Furthermore, we introduce extended labels with auxiliary context categories to facilitate the learning of action-context separation. Experiments on THUMOS14 and ActivityNet v1.2/v1.3 datasets demonstrate the ACSNet outperforms existing state-of-the-art WS-TAL methods by a large margin.",弱教師あり時間アクションローカリゼーション（WS-TAL）の目的は、ビデオレベルの教師ありのみを使用して、トリミングされていないビデオ内のすべてのアクションインスタンスをローカライズすることです。トレーニング中にフレームレベルの注釈がないため、現在のWS-TALメソッドは、ビデオレベルの分類タスクに寄与するフォアグラウンドスニペットまたはフレームをローカライズするためにアテンションメカニズムに依存しています。この戦略は、ローカリゼーションの結果において、コンテキストと実際のアクションを混同することがよくあります。アクションとコンテキストを分離することは、正確なWS-TALの中心的な問題ですが、それは非常に困難であり、文献ではほとんど無視されています。このホワイトペーパーでは、正確なアクションのローカリゼーションのためにコンテキストを明示的に考慮するアクションコンテキスト分離ネットワーク（ACSNet）を紹介します。これは、2つのブランチ（つまり、フォアグラウンド-バックグラウンドブランチとアクション-コンテキストブランチ）で構成されます。 ForegroundBackgroundブランチは、最初にビデオ全体の中で前景と背景を区別し、Action-Contextブランチは、前景をアクションとコンテキストとしてさらに分離します。ビデオスニペットを2つの潜在的なコンポーネント（つまり、ポジティブコンポーネントとネガティブコンポーネント）に関連付け、それらのさまざまな組み合わせにより、フォアグラウンド、アクション、およびコンテキストを効果的に特徴付けることができます。さらに、アクションコンテキスト分離の学習を容易にするために、補助コンテキストカテゴリを備えた拡張ラベルを導入します。 THUMOS14およびActivityNetv1.2 / v1.3データセットでの実験は、ACSNetが既存の最先端のWS-TALメソッドを大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/a56089a2b1d9f2ad942dd5ce841d204322bd16dd/1-Figure1-1.png
Deep Multi-Task Learning for Diabetic Retinopathy Grading in Fundus Images,"['Xiaofei Wang', 'Mai Xu', 'Jicong Zhang', 'Lai Jiang', 'Liu Li']",,,,
Policy-Guided Heuristic Search with Guarantees,"['Laurent Orseau', 'Levi H. S. Lelis']",,,,
Deep Probabilistic Imaging: Uncertainty Quantification and Multi-Modal Solution Characterization for Computational Imaging,"['He Sun', 'Katherine Bouman']",https://arxiv.org/abs/2010.14462,"Computational image reconstruction algorithms generally produce a single image without any measure of uncertainty or confidence. Regularized Maximum Likelihood (RML) and feed-forward deep learning approaches for inverse problems typically focus on recovering a point estimate. This is a serious limitation when working with underdetermined imaging systems, where it is conceivable that multiple image modes would be consistent with the measured data. Characterizing the space of probable images that explain the observational data is therefore crucial. In this paper, we propose a variational deep probabilistic imaging approach to quantify reconstruction uncertainty. Deep Probabilistic Imaging (DPI) employs an untrained deep generative model to estimate a posterior distribution of an unobserved image. This approach does not require any training data; instead, it optimizes the weights of a neural network to generate image samples that fit a particular measurement dataset. Once the network weights have been learned, the posterior distribution can be efficiently sampled. We demonstrate this approach in the context of interferometric radio imaging, which is used for black hole imaging with the Event Horizon Telescope.",計算画像再構成アルゴリズムは、一般に、不確実性や信頼性を測定することなく、単一の画像を生成します。逆問題に対する正則化最尤法（RML）とフィードフォワード深層学習アプローチは、通常、点推定の回復に焦点を合わせています。これは、複数の画像モードが測定データと一致すると考えられる劣決定イメージングシステムを使用する場合の重大な制限です。したがって、観測データを説明する可能性のある画像の空間を特徴づけることが重要です。この論文では、再構成の不確実性を定量化するための変分深い確率的イメージングアプローチを提案します。 Deep Probabilistic Imaging（DPI）は、トレーニングされていない深層生成モデルを使用して、観測されていない画像の事後分布を推定します。このアプローチでは、トレーニングデータは必要ありません。代わりに、ニューラルネットワークの重みを最適化して、特定の測定データセットに適合する画像サンプルを生成します。ネットワークの重みが学習されると、事後分布を効率的にサンプリングできます。このアプローチを、事象の地平線望遠鏡によるブラックホールイメージングに使用される干渉無線イメージングのコンテキストで示します。,https://d3i71xaburhd42.cloudfront.net/0260c69e347ad2f47f65d43916425933bbde6b69/3-Figure1-1.png
OT-Flow: Fast and Accurate Continuous Normalizing Flows via Optimal Transport,"['Derek Onken', 'Samy Wu Fung', 'Xingjian Li', 'Lars Ruthotto']",https://arxiv.org/abs/2006.00104,"A normalizing flow is an invertible mapping between an arbitrary probability distribution and a standard normal distribution; it can be used for density estimation and statistical inference. Computing the flow follows the change of variables formula and thus requires invertibility of the mapping and an efficient way to compute the determinant of its Jacobian. To satisfy these requirements, normalizing flows typically consist of carefully chosen components. Continuous normalizing flows (CNFs) are mappings obtained by solving a neural ordinary differential equation (ODE). The neural ODE's dynamics can be chosen almost arbitrarily while ensuring invertibility. Moreover, the log-determinant of the flow's Jacobian can be obtained by integrating the trace of the dynamics' Jacobian along the flow. Our proposed OT-Flow approach tackles two critical computational challenges that limit a more widespread use of CNFs. First, OT-Flow leverages optimal transport (OT) theory to regularize the CNF and enforce straight trajectories that are easier to integrate. Second, OT-Flow features exact trace computation with time complexity equal to trace estimators used in existing CNFs. On five high-dimensional density estimation and generative modeling tasks, OT-Flow performs competitively to a state-of-the-art CNF while on average requiring one-fourth of the number of weights with 19x speedup in training time and 28x speedup in inference.",正規化フローは、任意の確率分布と標準正規分布の間の可逆マッピングです。密度推定と統計的推論に使用できます。フローの計算は変数変換式に従うため、マッピングの可逆性と、ヤコビアンの行列式を計算する効率的な方法が必要です。これらの要件を満たすために、正規化フローは通常、慎重に選択されたコンポーネントで構成されます。連続正規化フロー（CNF）は、神経常微分方程式（ODE）を解くことによって得られるマッピングです。ニューラルODEのダイナミクスは、可逆性を確保しながら、ほぼ任意に選択できます。さらに、フローヤコビアンの対数行列式は、フローに沿ったダイナミクスヤコビアンのトレースを積分することによって取得できます。私たちが提案するOT-Flowアプローチは、CNFのより広範な使用を制限する2つの重要な計算上の課題に取り組みます。まず、OT-Flowは、最適輸送（OT）理論を活用して、CNFを正規化し、統合が容易な直線軌道を適用します。第2に、OT-Flowは、既存のCNFで使用されているトレース推定器と同等の時間計算量を備えた正確なトレース計算を特徴としています。 5つの高次元密度推定および生成モデリングタスクで、OT-Flowは最先端のCNFに対して競争力を発揮しますが、平均して、トレーニング時間で19倍、推論で28倍のスピードアップでウェイト数の4分の1を必要とします。 。,https://d3i71xaburhd42.cloudfront.net/1ca6ef3df76c813ac63e6a14d29cfe7f9cd4d985/2-Figure1-1.png
Scarce Societal Resource Allocation and the Price of (Local) Justice,"['Quan M Nguyen', 'Sanmay Das', 'Roman Garnett']",,,,
Modeling Deep Learning Based Privacy Attacks on Physical Mail,"['Bingyao Huang', 'Ruyi Lian', 'Dimitris Samaras', 'Haibin Ling']",,,,
Vector Quantized Bayesian Neural Network Inference for Data Streams,"['Namuk Park', 'Taekyu Lee', 'Songkuk Kim']",,,,
Present-Biased Optimization,"['Fedor Fomin', 'Pierre Fraigniaud', 'Petr Golovach']",,,,
Fractal Autoencoders for Feature Selection,"['Xinxing Wu', 'Qiang Cheng']",https://arxiv.org/abs/2010.09430,"Feature selection reduces the dimensionality of data by identifying a subset of the most informative features. In this paper, we propose an innovative framework for unsupervised feature selection, called fractal autoencoders (FAE). It trains a neural network (NN) to pinpoint informative features for global exploring of representability and for local excavating of diversity. Architecturally, FAE extends autoencoders by adding a one-to-one scoring layer and a small sub-NN for feature selection in an unsupervised fashion. With such a concise architecture, FAE achieves state-of-the-art performances; extensive experimental results on fourteen datasets, including very high-dimensional data, have demonstrated the superiority of FAE over existing contemporary methods for unsupervised feature selection. In particular, FAE exhibits substantial advantages on gene expression data exploration, reducing measurement cost by about 15% over the widely used L1000 landmark genes. Further, we show that the FAE framework is easily extensible with an application.",特徴選択は、最も有益な特徴のサブセットを識別することにより、データの次元を減らします。この論文では、フラクタルオートエンコーダー（FAE）と呼ばれる教師なし特徴選択のための革新的なフレームワークを提案します。ニューラルネットワーク（NN）をトレーニングして、表現可能性のグローバルな調査と多様性のローカルな発掘のための有益な機能を特定します。アーキテクチャ上、FAEは、教師なしの方法で特徴選択のために1対1のスコアリングレイヤーと小さなサブNNを追加することにより、オートエンコーダーを拡張します。このような簡潔なアーキテクチャにより、FAEは最先端のパフォーマンスを実現します。非常に高次元のデータを含む14のデータセットに関する広範な実験結果は、教師なし特徴選択のための既存の現代的な方法に対するFAEの優位性を示しています。特に、FAEは遺伝子発現データの探索において大きな利点を示し、測定コストを約15削減します。,https://d3i71xaburhd42.cloudfront.net/73f00f748deb620788e4ced410d211c09b0b22ba/4-Figure1-1.png
Learned Bi-Resolution Image Coding Using Generalized Octave Convolutions,"['Mohammad Akbari', 'Jie Liang', 'Jingning Han', 'Chengjie Tu']",,,,
Semi-Supervised Sequence Classification through Change Point Detection,"['Nauman Ahad', 'Mark Davenport']",https://arxiv.org/abs/2009.11829,"Sequential sensor data is generated in a wide variety of practical applications. A fundamental challenge involves learning effective classifiers for such sequential data. While deep learning has led to impressive performance gains in recent years in domains such as speech, this has relied on the availability of large datasets of sequences with high-quality labels. In many applications, however, the associated class labels are often extremely limited, with precise labelling/segmentation being too expensive to perform at a high volume. However, large amounts of unlabeled data may still be available. In this paper we propose a novel framework for semi-supervised learning in such contexts. In an unsupervised manner, change point detection methods can be used to identify points within a sequence corresponding to likely class changes. We show that change points provide examples of similar/dissimilar pairs of sequences which, when coupled with labeled, can be used in a semi-supervised classification setting. Leveraging the change points and labeled data, we form examples of similar/dissimilar sequences to train a neural network to learn improved representations for classification. We provide extensive synthetic simulations and show that the learned representations are superior to those learned through an autoencoder and obtain improved results on both simulated and real-world human activity recognition datasets.",シーケンシャルセンサーデータは、さまざまな実用的なアプリケーションで生成されます。基本的な課題には、そのようなシーケンシャルデータの効果的な分類子を学習することが含まれます。ディープラーニングは、近年、音声などの分野で目覚ましいパフォーマンスの向上をもたらしましたが、これは、高品質のラベルを持つシーケンスの大規模なデータセットの可用性に依存しています。ただし、多くのアプリケーションでは、関連するクラスラベルが非常に制限されていることが多く、正確なラベル付け/セグメンテーションはコストがかかりすぎて大量に実行できません。ただし、ラベルのない大量のデータが引き続き利用できる場合があります。この論文では、そのような状況での半教師あり学習のための新しいフレームワークを提案します。教師なしの方法で、変化点検出方法を使用して、可能性のあるクラス変更に対応するシーケンス内の点を識別することができます。変化点は、ラベル付きと組み合わせると、半教師あり分類設定で使用できる、類似/非類似のシーケンスのペアの例を提供することを示します。変化点とラベル付けされたデータを活用して、類似/非類似シーケンスの例を作成し、ニューラルネットワークをトレーニングして分類の改善された表現を学習します。広範な合成シミュレーションを提供し、学習した表現がオートエンコーダーで学習した表現よりも優れていることを示し、シミュレートされた人間の行動認識データセットと実際の人間の行動認識データセットの両方で改善された結果が得られます。,https://d3i71xaburhd42.cloudfront.net/1e58c9d1153d2f25d94b3a12b785bd7abe43bd1c/3-Figure1-1.png
On Continuous Local BDD-Based Search for Hybrid SAT Solving,"['Anastasios Kyrillidis', 'Moshe Vardi', 'Zhiwei Zhang']",https://arxiv.org/abs/2012.07983,"We explore the potential of continuous local search (CLS) in SAT solving by proposing a novel approach for finding a solution of a hybrid system of Boolean constraints. The algorithm is based on CLS combined with belief propagation on binary decision diagrams (BDDs). Our framework accepts all Boolean constraints that admit compact BDDs, including symmetric Boolean constraints and small-coefficient pseudo-Boolean constraints as interesting families. We propose a novel algorithm for efficiently computing the gradient needed by CLS. We study the capabilities and limitations of our versatile CLS solver, GradSAT, by applying it on many benchmark instances. The experimental results indicate that GradSAT can be a useful addition to the portfolio of existing SAT and MaxSAT solvers for solving Boolean satisfiability and optimization problems.",ブール制約のハイブリッドシステムの解を見つけるための新しいアプローチを提案することにより、SAT解法における連続局所探索（CLS）の可能性を探ります。このアルゴリズムは、二分決定図（BDD）での信念伝搬と組み合わせたCLSに基づいています。私たちのフレームワークは、対称ブール制約や小係数の疑似ブール制約など、コンパクトなBDDを許可するすべてのブール制約を興味深いファミリとして受け入れます。 CLSに必要な勾配を効率的に計算するための新しいアルゴリズムを提案します。用途の広いCLSソルバーであるGradSATの機能と制限を、多くのベンチマークインスタンスに適用して調査します。実験結果は、GradSATが、ブール充足可能性および最適化問題を解決するための既存のSATおよびMaxSATソルバーのポートフォリオへの有用な追加になる可能性があることを示しています。,https://d3i71xaburhd42.cloudfront.net/25a69971a66563ddfb24cfa902b5066b35f4dc6f/10-Figure1-1.png
Multi-Proxy Wasserstein Classifier for Image Classification,"['Benlin Liu', 'Yongming Rao', 'Jiwen Lu', 'Jie Zhou', 'Cho-Jui Hsieh']",,,,
Lipschitz Lifelong Reinforcement Learning,"['Erwan Lecarpentier', 'David Abel', 'Kavosh Asadi', 'Yuu Jinnai', 'Emmanuel Rachelson', 'Michael L. Littman']",https://arxiv.org/abs/2001.05411,"We consider the problem of knowledge transfer when an agent is facing a series of Reinforcement Learning (RL) tasks. We introduce a novel metric between Markov Decision Processes and establish that close MDPs have close optimal value functions. Formally, the optimal value functions are Lipschitz continuous with respect to the tasks space. These theoretical results lead us to a value transfer method for Lifelong RL, which we use to build a PAC-MDP algorithm with improved convergence rate. We illustrate the benefits of the method in Lifelong RL experiments.",エージェントが一連の強化学習（RL）タスクに直面している場合、知識の伝達の問題を検討します。マルコフ決定過程の間に新しいメトリックを導入し、近いMDPが近い最適値関数を持つことを確立します。正式には、最適値関数は、タスク空間に関して連続的なリプシッツです。これらの理論的結果は、生涯RLの値転送方法につながります。これを使用して、収束率が改善されたPAC-MDPアルゴリズムを構築します。生涯RL実験におけるこの方法の利点を説明します。,https://d3i71xaburhd42.cloudfront.net/0746b7f622f99bdde8bf5d7440264ff5f662851d/2-Figure1-1.png
Decentralized Multi-Agent Linear Bandits with Safety Constraints,"['Sanae Amani', 'Christos Thrampoulidis']",https://arxiv.org/abs/2012.00314,"We study decentralized stochastic linear bandits, where a network of $N$ agents acts cooperatively to efficiently solve a linear bandit-optimization problem over a $d$-dimensional space. For this problem, we propose DLUCB: a fully decentralized algorithm that minimizes the cumulative regret over the entire network. At each round of the algorithm each agent chooses its actions following an upper confidence bound (UCB) strategy and agents share information with their immediate neighbors through a carefully designed consensus procedure that repeats over cycles. Our analysis adjusts the duration of these communication cycles ensuring near-optimal regret performance $\mathcal{O}(d\log{NT}\sqrt{NT})$ at a communication rate of $\mathcal{O}(dN^2)$ per round. The structure of the network affects the regret performance via a small additive term - coined the regret of delay - that depends on the spectral gap of the underlying graph. Notably, our results apply to arbitrary network topologies without a requirement for a dedicated agent acting as a server. In consideration of situations with high communication cost, we propose RC-DLUCB: a modification of DLUCB with rare communication among agents. The new algorithm trades off regret performance for a significantly reduced total communication cost of $\mathcal{O}(d^3N^{2.5})$ over all $T$ rounds. Finally, we show that our ideas extend naturally to the emerging, albeit more challenging, setting of safe bandits. For the recently studied problem of linear bandits with unknown linear safety constraints, we propose the first safe decentralized algorithm. Our study contributes towards applying bandit techniques in safety-critical distributed systems that repeatedly deal with unknown stochastic environments. We present numerical simulations for various network topologies that corroborate our theoretical findings.",N個のエージェントのネットワークが協調して動作し、d次元空間上の線形バンディット最適化問題を効率的に解決する分散型確率線形バンディットを研究します。この問題に対して、DLUCBを提案します。これは、ネットワーク全体にわたる累積的な後悔を最小限に抑える完全分散型アルゴリズムです。アルゴリズムの各ラウンドで、各エージェントは上限信頼限界（UCB）戦略に従ってアクションを選択し、エージェントは、サイクルにわたって繰り返される慎重に設計されたコンセンサス手順を通じて、直接の隣人と情報を共有します。私たちの分析では、これらの通信サイクルの期間を調整して、ラウンドあたりの通信速度O（dN2）でほぼ最適な後悔パフォーマンス$ \ mathcal {O}（d \ log {NT} \ sqrt {NT}）$を確保します。ネットワークの構造は、基になるグラフのスペクトルギャップに依存する小さな加法項（遅延の後悔と呼ばれる）を介して後悔のパフォーマンスに影響を与えます。特に、私たちの結果は、サーバーとして機能する専用エージェントを必要とせずに、任意のネットワークトポロジに適用されます。通信コストが高い状況を考慮して、エージェント間の通信がまれなDLUCBの修正版であるRC-DLUCBを提案します。新しいアルゴリズムは、後悔のパフォーマンスとトレードオフを行い、すべてのTラウンドで通信コストの合計をO（d3N ^（2.5））に大幅に削減します。最後に、私たちのアイデアは、より挑戦的ではありますが、安全な盗賊の新たな設定に自然に拡張されることを示します。線形安全制約が不明な線形盗賊の最近研究された問題について、最初の安全な分散アルゴリズムを提案します。私たちの研究は、未知の確率的環境を繰り返し処理するセーフティクリティカルな分散システムにバンディット技術を適用することに貢献しています。理論的発見を裏付けるさまざまなネットワークトポロジの数値シミュレーションを提示します。,https://d3i71xaburhd42.cloudfront.net/17e65ef9d81727671cc75280ee30a5e219c2956d/26-Figure2-1.png
Near-Optimal MNL Bandits Under Risk Criteria,"['Guangyu Xi', 'Chao Tao', 'Yuan Zhou']",https://arxiv.org/abs/2009.12511,"We study MNL bandits, which is a variant of the traditional multi-armed bandit problem, under risk criteria. Unlike the ordinary expected revenue, risk criteria are more general goals widely used in industries and bussiness. We design algorithms for a broad class of risk criteria, including but not limited to the well-known conditional value-at-risk, Sharpe ratio and entropy risk, and prove that they suffer a near-optimal regret. As a complement, we also conduct experiments with both synthetic and real data to show the empirical performance of our proposed algorithms.",従来の多腕バンディット問題の変形であるMNLバンディットをリスク基準の下で研究します。通常の期待収益とは異なり、リスク基準は、業界やビジネスで広く使用されているより一般的な目標です。よく知られている条件付きリスク値、シャープレシオ、エントロピーリスクなど、幅広いクラスのリスク基準のアルゴリズムを設計し、それらがほぼ最適な後悔を被っていることを証明します。補足として、提案されたアルゴリズムの経験的パフォーマンスを示すために、合成データと実際のデータの両方で実験も行います。,https://d3i71xaburhd42.cloudfront.net/3101d0360cab5007b2cae2ff79c21fb03cb58ce3/7-Figure1-1.png
A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation,"['Ervine Zheng', 'Qi Yu', 'Rui Li', 'Pengcheng Shi', 'Anne Haake']",,,,
DenserNet: Weakly Supervised Visual Localization Using Multi-Scale Feature Aggregation,"['Dongfang Liu', 'Yiming Cui', 'Liqi Yan', 'Christos Mousas', 'Baijian Yang', 'Yingjie Victor Chen']",https://arxiv.org/abs/2012.02366,"In this work, we introduce a Denser Feature Network (DenserNet) for visual localization. Our work provides three principal contributions. First, we develop a convolutional neural network (CNN) architecture which aggregates feature maps at different semantic levels for image representations. Using denser feature maps, our method can produce more keypoint features and increase image retrieval accuracy. Second, our model is trained end-to-end without pixel-level annotation other than positive and negative GPS-tagged image pairs. We use a weakly supervised triplet ranking loss to learn discriminative features and encourage keypoint feature repeatability for image representation. Finally, our method is computationally efficient as our architecture has shared features and parameters during computation. Our method can perform accurate large-scale localization under challenging conditions while remaining the computational constraint. Extensive experiment results indicate that our method sets a new state-of-the-art on four challenging large-scale localization benchmarks and three image retrieval benchmarks.",この作業では、視覚的なローカリゼーションのためのDenser Feature Network（DenserNet）を紹介します。私たちの仕事は3つの主要な貢献を提供します。まず、画像表現のさまざまなセマンティックレベルで特徴マップを集約する畳み込みニューラルネットワーク（CNN）アーキテクチャを開発します。より密度の高い特徴マップを使用することで、私たちの方法はより多くのキーポイント特徴を生成し、画像検索の精度を高めることができます。次に、モデルは、正と負のGPSタグ付き画像ペア以外のピクセルレベルの注釈なしでエンドツーエンドでトレーニングされます。弱教師ありトリプレットランキング損失を使用して、識別機能を学習し、画像表現のキーポイント機能の再現性を促進します。最後に、私たちのアーキテクチャは計算中に機能とパラメータを共有しているため、私たちの方法は計算効率が高いです。私たちの方法は、計算上の制約を残しながら、困難な条件下で正確な大規模なローカリゼーションを実行できます。広範な実験結果は、私たちの方法が4つの挑戦的な大規模ローカリゼーションベンチマークと3つの画像検索ベンチマークに新しい最先端を設定することを示しています。,https://d3i71xaburhd42.cloudfront.net/06f9e3ac57f4ffa3e50614c85599cf85b9695f84/1-Figure1-1.png
Weakly Supervised Temporal Action Localization through Learning Explicit Subspaces for Action and Context,"['Ziyi Liu', 'Le Wang', 'Wei Tang', 'Junsong Yuan', 'Nanning Zheng', 'Gang Hua']",,"Weakly-supervised Temporal Action Localization (WS-TAL) methods learn to localize temporal starts and ends of action instances in a video under only video-level supervision. Existing WS-TAL methods rely on deep features learned for action recognition. However, due to the mismatch between classification and localization, these features cannot distinguish the frequently co-occurring contextual background, i.e., the context, and the actual action instances. We term this challenge action-context confusion, and it will adversely affect the action localization accuracy. To address this challenge, we introduce a framework that learns two feature subspaces respectively for actions and their context. By explicitly accounting for action visual elements, the action instances can be localized more precisely without the distraction from the context. To facilitate the learning of these two feature subspaces with only video-level categorical labels, we leverage the predictions from both spatial and temporal streams for snippets grouping. In addition, an unsupervised learning task is introduced to make the proposed module focus on mining temporal information. The proposed approach outperforms state-of-the-art WS-TAL methods on three benchmarks, i.e., THUMOS14, ActivityNet v1.2 and v1.3 datasets.",弱教師あり時間アクションローカリゼーション（WS-TAL）メソッドは、ビデオレベルの教師のみの下で、ビデオ内のアクションインスタンスの時間的開始と終了をローカライズすることを学習します。既存のWS-TALメソッドは、アクション認識のために学習された深い機能に依存しています。ただし、分類とローカリゼーションの不一致により、これらの機能では、頻繁に発生するコンテキストの背景、つまりコンテキストと実際のアクションインスタンスを区別できません。このチャレンジをアクション-コンテキストの混乱と呼び、アクションのローカリゼーションの精度に悪影響を及ぼします。この課題に対処するために、アクションとそのコンテキストについてそれぞれ2つの機能サブスペースを学習するフレームワークを導入します。アクションの視覚的要素を明示的に考慮することにより、コンテキストから気を散らすことなく、アクションインスタンスをより正確にローカライズできます。ビデオレベルのカテゴリラベルのみを使用してこれら2つの特徴部分空間の学習を容易にするために、スニペットのグループ化に空間ストリームと時間ストリームの両方からの予測を活用します。さらに、教師なし学習タスクが導入され、提案されたモジュールが時間情報のマイニングに焦点を合わせます。提案されたアプローチは、3つのベンチマーク、つまりTHUMOS14、ActivityNet v1.2、およびv1.3データセットで最先端のWS-TALメソッドよりも優れています。,https://d3i71xaburhd42.cloudfront.net/7f0971db4836c49788a440ca7e1fd96f630cc807/2-Figure1-1.png
Aggregating Binary Judgments Ranked by Accuracy,"['Daniel Halpern', 'Gregory Kehne', 'Dominik Peters', 'Ariel D Procaccia', 'Nisarg Shah', 'Piotr Skowron']",,"We revisit the fundamental problem of predicting a binary ground truth based on independent binary judgments provided by experts. When the accuracy levels of the experts are known, the problem can be solved easily through maximum likelihood estimation. We consider, however, a setting in which we are given only a ranking of the experts by their accuracy. Motivated by the worst-case approach to handle the missing information, we consider three objective functions and design efficient algorithms for optimizing them. In particular, the recently popular distortion objective leads to an intuitive new rule. We show that our algorithms perform well empirically using real and synthetic data in collaborative filtering and political prediction domains.",専門家によって提供された独立したバイナリ判断に基づいてバイナリグラウンドトゥルースを予測するという根本的な問題を再検討します。専門家の精度レベルがわかっている場合、最尤推定によって問題を簡単に解決できます。ただし、専門家の正確さによるランキングのみが与えられる設定を検討します。欠落している情報を処理するための最悪の場合のアプローチに動機付けられて、3つの目的関数を検討し、それらを最適化するための効率的なアルゴリズムを設計します。特に、最近人気のある歪みの目的は、直感的な新しいルールにつながります。協調フィルタリングおよび政治的予測ドメインで実際のデータと合成データを使用して、アルゴリズムが経験的にうまく機能することを示します。,https://d3i71xaburhd42.cloudfront.net/776555716806327ebc9ff1460ef612a5cd7f4ead/11-Table1-1.png
Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks,"['Jinyuan Jia', 'Xiaoyu Cao', 'Neil Zhenqiang Gong']",https://arxiv.org/abs/2008.04495,"In a \emph{data poisoning attack}, an attacker modifies, deletes, and/or inserts some training examples to corrupt the learnt machine learning model. \emph{Bootstrap Aggregating (bagging)} is a well-known ensemble learning method, which trains multiple base models on random subsamples of a training dataset using a base learning algorithm and uses majority vote to predict labels of testing examples. We prove the intrinsic certified robustness of bagging against data poisoning attacks. Specifically, we show that bagging with an arbitrary base learning algorithm provably predicts the same label for a testing example when the number of modified, deleted, and/or inserted training examples is bounded by a threshold. Moreover, we show that our derived threshold is tight if no assumptions on the base learning algorithm are made. We evaluate our method on MNIST and CIFAR10. For instance, our method achieves a certified accuracy of $91.1\%$ on MNIST when arbitrarily modifying, deleting, and/or inserting 100 training examples.",データポイズニング攻撃では、攻撃者はいくつかのトレーニング例を変更、削除、および/または挿入して、学習した機械学習モデルを破壊します。 Bootstrap Aggregating（bagging）は、よく知られたアンサンブル学習方法であり、基本学習アルゴリズムを使用してトレーニングデータセットのランダムなサブサンプルで複数の基本モデルをトレーニングし、多数決を使用してテスト例のラベルを予測します。データポイズニング攻撃に対するバギングの本質的な認定された堅牢性を証明します。具体的には、任意の基本学習アルゴリズムを使用したバギングは、変更、削除、および/または挿入されたトレーニング例の数がしきい値によって制限されている場合に、テスト例の同じラベルを確実に予測することを示します。さらに、基本学習アルゴリズムに関する仮定が行われない場合、導出されたしきい値がタイトであることを示します。 MNISTとCIFAR10でメソッドを評価します。たとえば、私たちの方法は、100のトレーニング例を任意に変更、削除、および/または挿入すると、MNISTで91.1％の認定精度を達成します。,https://d3i71xaburhd42.cloudfront.net/5d15dfc3be39915a03c8d50172694613929144cf/2-Figure1-1.png
Exact Reduction of Huge Action Spaces in General Reinforcement Learning,"['Sultan Javed Majeed', 'Marcus Hutter']",https://arxiv.org/abs/2012.10200,"e reinforcement learning (RL) framework formalizes the notion of learning with interactions. Many real-world problems have large state-spaces and/or action-spaces such as in Go, StarCra, protein folding, and robotics or are non-Markovian, which cause significant challenges to RL algorithms. In this work we address the large action-space problem by sequentializing actions, which can reduce the action-space size significantly, even down to two actions at the expense of an increased planning horizon. We provide explicit and exact constructions and equivalence proofs for all quantities of interest for arbitrary history-based processes. In the case of MDPs, this could help RL algorithms that bootstrap. In this work we show how action-binarization in the non-MDP case can significantly improve Extreme State Aggregation (ESA) bounds. ESA allows casting any (nonMDP, non-ergodic, history-based) RL problem into a fixed-sized non-Markovian statespace with the help of a surrogate Markovian process. On the upside, ESA enjoys similar optimality guarantees as Markovian models do. But a downside is that the size of the aggregated state-space becomes exponential in the size of the action-space. In this work, we patch this issue by binarizing the action-space. We provide an upper bound on the number of states of this binarized ESA that is logarithmic in the original action-space size, a double-exponential improvement.",強化学習（RL）フレームワークは、相互作用を伴う学習の概念を形式化します。多くの現実世界の問題は、Go、StarCra、タンパク質フォールディング、ロボット工学などの大きな状態空間やアクション空間を持っているか、非マルコフであるため、RLアルゴリズムに重大な課題を引き起こします。この作業では、アクションをシーケンシャル化することで大きなアクションスペースの問題に対処します。これにより、計画期間が長くなる代わりに、アクションスペースのサイズを2つのアクションにまで大幅に削減できます。私たちは、任意の履歴ベースのプロセスの関心のあるすべての量に対して、明示的で正確な構造と同等性の証明を提供します。 MDPの場合、これはブートストラップするRLアルゴリズムに役立つ可能性があります。この作業では、非MDPの場合のアクションの2値化によって、Extreme State Aggregation（ESA）の範囲が大幅に改善されることを示します。 ESAを使用すると、代理マルコフプロセスを使用して、任意の（非MDP、非エルゴード、履歴ベースの）RL問題を固定サイズの非マルコフ状態空間にキャストできます。利点として、ESAはマルコフモデルと同様の最適性保証を享受しています。ただし、欠点は、集約された状態空間のサイズがアクション空間のサイズで指数関数的になることです。この作業では、アクションスペースを2値化することにより、この問題にパッチを適用します。この2値化されたESAの状態数の上限を提供します。これは、元のアクション空間サイズで対数であり、二重指数関数的な改善です。,https://d3i71xaburhd42.cloudfront.net/8769e44ab5d1c04435f895e9c97b4bcf752bb913/2-Figure1-1.png
Exploring Auxiliary Reasoning Tasks for Task-Oriented Dialog Systems with Meta Cooperative Learning,"['Bowen Qin', 'Min Yang', 'Bing Lidong', 'Qingshan Jiang', 'Chengming Li', 'Ruifeng Xu']",,,,
Hierarchical Macro Discourse Parsing Based on Topic Segmentation,"['Feng Jiang', 'Yaxin Fan', 'Xiaomin Chu', 'Li Peifeng', 'Zhu Qiaoming', 'Fang Kong']",,,,
Depth Privileged Object Detection in Indoor Scenes via Deformation Hallucination,"['Zhijie Zhang', 'Yan Liu', 'Junjie Chen', 'Li Niu', 'Liqing Zhang']",,,,
Uncertain Graph Neural Networks for Facial Action Unit Detection,"['Tengfei Song', 'Lisha Chen', 'Wenming Zheng', 'Qiang Ji']",,,,
Multiple Kernel Clustering with Kernel k-Means Coupled Graph Tensor Learning,"['Zhenwen Ren', 'Quansen Sun', 'Dong Wei']",,,,
Less Than One'-Shot Learning: Learning N Classes from M < N Samples,"['Ilia Sucholutsky', 'Matthias Schonlau']",,,,
Taxonomy Completion via Triplet Matching Network,"['Jieyu Zhang', 'Xiangchen Song', 'Ying Zeng', 'Jiaze Chen', 'Jiaming Shen', 'Yuning Mao', 'Lei Li']",https://arxiv.org/abs/2101.01896,"Automatically constructing taxonomy finds many applications in e-commerce and web search. One critical challenge is as data and business scope grow in real applications, new concepts are emerging and needed to be added to the existing taxonomy. Previous approaches focus on the taxonomy expansion, i.e. finding an appropriate hypernym concept from the taxonomy for a new query concept. In this paper, we formulate a new task, “taxonomy completion”, by discovering both the hypernym and hyponym concepts for a query. We propose Triplet Matching Network (TMN), to find the appropriate 〈hypernym, hyponym〉 pairs for a given query concept. TMN consists of one primal scorer and multiple auxiliary scorers. These auxiliary scorers capture various fine-grained signals (e.g., query to hypernym or query to hyponym semantics), and the primal scorer makes a holistic prediction on 〈query, hypernym, hyponym〉 triplet based on the internal feature representations of all auxiliary scorers. Also, an innovative channel-wise gating mechanism that retains task-specific information in concept representations is introduced to further boost model performance. Experiments on four real-world large-scale datasets show that TMN achieves the best performance on both taxonomy completion task and the previous taxonomy expansion task, outperforming existing methods. Introduction Taxonomies, formulated as directed acyclic graphs or trees, have been widely used to organize knowledge in various domains, such as news domain (Vrandecic 2012; Mao et al. 2019), scientific domain (Lipscomb 2000; Sinha et al. 2015; Shen et al. 2018c) and online commerce (Karamanolakis, Ma, and Dong 2020; Mao et al. 2020). Equipped with these curated taxonomies, researchers are able to boost the performance of numerous downstream applications such as query understanding (Hua et al. 2017; Yang, Zhang, and Han 2020), content browsing (Yang 2012), personalized recommendation (Zhang et al. 2014; Huang et al. 2019), and web search (Wu et al. 2012; Liu et al. 2019). As human knowledge is constantly growing and new concepts emerge everyday, it is needed to dynamically complete an existing taxonomy. Figure 1 shows an illustrative example where a taxonomy of “Electronic Device” is completed to Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. *This work is done while interning at ByteDance AI Lab. Existing Taxonomy New Concepts SSD Memory CPU Keyboard Smart Phone",分類法を自動的に構築すると、eコマースやWeb検索で多くのアプリケーションが見つかります。重要な課題の1つは、実際のアプリケーションでデータとビジネススコープが拡大するにつれて、新しい概念が出現し、既存の分類法に追加する必要があることです。以前のアプローチは、分類法の拡張に焦点を当てています。つまり、新しいクエリ概念の分類法から適切な上位概念を見つけることです。このホワイトペーパーでは、クエリの上位概念と下位概念の両方を発見することにより、新しいタスクである分類法の完了を定式化します。トリプレットマッチングネットワーク（TMN）を提案して、特定のクエリ概念に適した上位概念と下位概念のペアを見つけます。 TMNは、1つのプライマリスコアラーと複数の補助スコアラーで構成されます。これらの補助スコアラーは、さまざまなきめ細かい信号（たとえば、上位概念へのクエリまたは下位概念へのクエリ）をキャプチャし、主要スコアラーは、すべての補助スコアラーの内部機能表現に基づいて、クエリ、上位概念、下位概念のトリプレットに関する全体的な予測を行います。また、コンセプト表現でタスク固有の情報を保持する革新的なチャネルごとのゲーティングメカニズムが導入され、モデルのパフォーマンスがさらに向上します。 4つの実世界の大規模データセットでの実験は、TMNが分類完了タスクと前の分類拡張タスクの両方で最高のパフォーマンスを達成し、既存の方法を上回っていることを示しています。はじめに有向非巡回グラフまたはツリーとして定式化された分類法は、ニュースドメイン（Vrandecic 2012; Mao etal。2019）、科学ドメイン（Lipscomb 2000; Sinhaetal。2015; Shen）などのさまざまなドメインで知識を整理するために広く使用されています。 et al.2018c）およびオンラインコマース（Karamanolakis、Ma、and Dong 2020; Mao et al.2020）。これらの厳選された分類法を備えた研究者は、クエリの理解（Huaetal。2017; Yang、Zhang、and Han 2020）、コンテンツの閲覧（Yang 2012）、パーソナライズされた推奨（Zhang et al。）など、多数のダウンストリームアプリケーションのパフォーマンスを向上させることができます。 .2014; Huang etal。2019）、およびWeb検索（Wuetal。2012; Liu etal。2019）。人間の知識は絶えず成長し、新しい概念が毎日出現するため、既存の分類法を動的に完了する必要があります。図1は、電子デバイスの分類法がCopyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）に準拠している例を示しています。全著作権所有。 *この作業は、ByteDance AILabでのインターン中に行われます。既存の分類法新しい概念SSDメモリCPUキーボードスマートフォン,https://d3i71xaburhd42.cloudfront.net/76be63767799fa50357fab6516b668960b67aa78/1-Figure1-1.png
Proxy Graph Matching with Proximal Matching Networks,"['Haoru Tan', 'Chuang Wang', 'Sitong Wu', 'Tie-Qiang Wang', 'Xu-Yao Zhang', 'Cheng-Lin Liu']",,,,
Self-Paced Two-Dimensional PCA,"['Jiangxin Li', 'Zhao Kang', 'Chong Peng', 'Wenyu Chen']",,,,
Group Testing on a Network,"['Arlei Lopes da Silva', 'Ambuj Singh']",,,,
Tri-Level Robust Clustering Ensemble with Multiple Graph Learning,"['Peng Zhou', 'Liang Du', 'Yi-Dong Shen', 'Xuejun Li']",,"Clustering ensemble generates a consensus clustering result by integrating multiple weak base clustering results. Although it often provides more robust results compared with single clustering methods, it still suffers from the robustness problem if it does not treat the unreliability of base results carefully. Conventional clustering ensemble methods often use all data for ensemble, while ignoring the noises or outliers on the data. Although some robust clustering ensemble methods are proposed, which extract the noises on the data, they still characterize the robustness in a single level, and thus they cannot comprehensively handle the complicated robustness problem. In this paper, to address this problem, we propose a novel Tri-level Robust Clustering Ensemble (TRCE) method by transforming the clustering ensemble problem to a multiple graph learning problem. Just as its name implies, the proposed method tackles robustness problem in three levels: base clustering level, graph level and instance level. By considering the robustness problem in a more comprehensive way, the proposed TRCE can achieve a more robust consensus clustering result. Experimental results on benchmark datasets also demonstrate it. Our method often outperforms other state-ofthe-art clustering ensemble methods. Even compared with the robust ensemble methods, ours also performs better.",クラスタリングアンサンブルは、複数の弱塩基クラスタリング結果を統合することにより、コンセンサスクラスタリング結果を生成します。多くの場合、単一のクラスタリング手法と比較してより堅牢な結果が得られますが、基本結果の信頼性の低さを注意深く処理しないと、堅牢性の問題が発生します。従来のクラスタリングアンサンブル手法では、データのノイズや外れ値を無視しながら、すべてのデータをアンサンブルに使用することがよくあります。データ上のノイズを抽出するいくつかのロバストクラスタリングアンサンブル法が提案されていますが、それでも単一レベルでロバスト性を特徴付けるため、複雑なロバスト性問題を包括的に処理することはできません。本論文では、この問題に対処するために、クラスタリングアンサンブル問題を複数グラフ学習問題に変換することにより、新しい3レベルロバストクラスタリングアンサンブル（TRCE）法を提案します。その名前が示すように、提案された方法は、ベースクラスタリングレベル、グラフレベル、およびインスタンスレベルの3つのレベルでロバスト性の問題に取り組みます。堅牢性の問題をより包括的な方法で検討することにより、提案されたTRCEは、より堅牢なコンセンサスクラスタリングの結果を達成できます。ベンチマークデータセットの実験結果もそれを示しています。私たちの方法は、他の最先端のクラスタリングアンサンブル方法よりも優れていることがよくあります。堅牢なアンサンブル手法と比較しても、パフォーマンスは優れています。,https://d3i71xaburhd42.cloudfront.net/661ffe3fcb3ca15e33b038841c4a3fb4d80a3ff1/2-Figure1-1.png
Expected Value of Communication for Planning in Ad Hoc Teamwork,"['William Macke', 'Reuth Mirsky', 'Peter Stone']",,"A desirable goal for autonomous agents is to be able to coordinate on the fly with previously unknown teammates. Known as “ad hoc teamwork”, enabling such a capability has been receiving increasing attention in the research community. One of the central challenges in ad hoc teamwork is quickly recognizing the current plans of other agents and planning accordingly. In this paper, we focus on the scenario in which teammates can communicate with one another, but only at a cost. Thus, they must carefully balance plan recognition based on observations vs. that based on communication. This paper proposes a new metric for evaluating how similar are two policies that a teammate may be following the Expected Divergence Point (EDP). We then present a novel planning algorithm for ad hoc teamwork, determining which query to ask and planning accordingly. We demonstrate the effectiveness of this algorithm in a range of increasingly general communication in ad hoc teamwork problems.",自律エージェントの望ましい目標は、これまで知られていなかったチームメイトとその場で調整できるようにすることです。アドホックチームワークとして知られるこのような機能を有効にすることは、研究コミュニティでますます注目を集めています。アドホックチームワークの中心的な課題の1つは、他のエージェントの現在の計画をすばやく認識し、それに応じて計画することです。このホワイトペーパーでは、チームメイトが相互に通信できるシナリオに焦点を当てますが、コストがかかります。したがって、観察に基づく計画認識とコミュニケーションに基づく計画認識のバランスを慎重にとる必要があります。このホワイトペーパーでは、チームメイトが期待される発散点（EDP）に従う可能性のある2つのポリシーがどの程度類似しているかを評価するための新しいメトリックを提案します。次に、アドホックチームワークのための新しい計画アルゴリズムを提示し、質問するクエリを決定し、それに応じて計画します。アドホックチームワークの問題におけるますます一般的なコミュニケーションの範囲で、このアルゴリズムの有効性を示します。,https://d3i71xaburhd42.cloudfront.net/347c796de71a86724354c751bd95f6df9eaa4d6d/3-Figure1-1.png
Bridging Towers of Multi-Task Learning with a Gating Mechanism for Aspect-Based Sentiment Analysis and Sequential Metaphor Identification,"['Rui Mao', 'Xiao Li']",,,,
Exploiting Sample Uncertainty for Domain Adaptive Person Re-Identification,"['Kecheng Zheng', 'Cuiling Lan', 'Wenjun Zeng', 'Zhizheng Zhang', 'Zheng-Jun Zha']",https://arxiv.org/abs/2012.08733,"Many unsupervised domain adaptive (UDA) person re-identification (ReID) approaches combine clustering-based pseudo-label prediction with feature fine-tuning. However, because of domain gap, the pseudo-labels are not always reliable and there are noisy/incorrect labels. This would mislead the feature representation learning and deteriorate the performance. In this paper, we propose to estimate and exploit the credibility of the assigned pseudo-label of each sample to alleviate the influence of noisy labels, by suppressing the contribution of noisy samples. We build our baseline framework using the mean teacher method together with an additional contrastive loss. We have observed that a sample with a wrong pseudo-label through clustering in general has a weaker consistency between the output of the mean teacher model and the student model. Based on this finding, we propose to exploit the uncertainty (measured by consistency levels) to evaluate the reliability of the pseudo-label of a sample and incorporate the uncertainty to re-weight its contribution within various ReID losses, including the identity (ID) classification loss per sample, the triplet loss, and the contrastive loss. Our uncertainty-guided optimization brings significant improvement and achieves the state-of-the-art performance on benchmark datasets.",多くの教師なしドメイン適応（UDA）個人再識別（ReID）アプローチは、クラスタリングベースの疑似ラベル予測と機能の微調整を組み合わせたものです。ただし、ドメインギャップのため、疑似ラベルは常に信頼できるとは限らず、ノイズの多い/正しくないラベルがあります。これは、特徴表現学習を誤解させ、パフォーマンスを低下させます。本論文では、各サンプルに割り当てられた疑似ラベルの信頼性を推定および活用して、ノイズの多いサンプルの寄与を抑制することにより、ノイズのあるラベルの影響を軽減することを提案します。私たちは、追加の対照的な損失とともに平均教師法を使用してベースラインフレームワークを構築します。一般に、クラスタリングによって誤った疑似ラベルを持つサンプルは、平均教師モデルと学生モデルの出力間の一貫性が弱いことがわかりました。この発見に基づいて、不確実性（一貫性レベルで測定）を利用してサンプルの疑似ラベルの信頼性を評価し、不確実性を組み込んで、アイデンティティ（ID）を含むさまざまなReID損失内でその寄与を再重み付けすることを提案します。サンプルごとの分類損失、トリプレット損失、および対照的な損失。当社の不確実性に基づく最適化は、大幅な改善をもたらし、ベンチマークデータセットで最先端のパフォーマンスを実現します。,https://d3i71xaburhd42.cloudfront.net/d477e72f93d8b895fd0ccc38f2a1cc04bf96e3f1/1-Figure1-1.png
Knowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation,"['Lianghao Xia', 'Chao Huang', 'Yong Xu', 'Peng Dai', 'Xiyue Zhang', 'Hongsheng Yang', 'Jian Pei', 'Liefeng Bo']",,,,
Graph Game Embedding,"['Xiaobin Hong', 'Tong Zhang', 'Zhen Cui', 'Yuge Huang', 'Pengcheng Shen', 'Shaoxin Li', 'Jian Yang']",,,,
Learning Omni-Frequency Region-Adaptive Representations for Real Image Super-Resolution,"['Xin Li', 'Xin Jin', 'Tao Yu', 'Simeng Sun', 'Yingxue Pang', 'Zhizheng Zhang', 'Zhibo Chen']",https://arxiv.org/abs/2012.06131,"Traditional single image super-resolution (SISR) methods that focus on solving single and uniform degradation (i.e., bicubic down-sampling), typically suffer from poor performance when applied into real-world low-resolution (LR) images due to the complicated realistic degradations. The key to solving this more challenging real image super-resolution (RealSR) problem lies in learning feature representations that are both informative and content-aware. In this paper, we propose an Omni-frequency Region-adaptive Network (ORNet) to address both challenges, here we call features of all low, middle and high frequencies omni-frequency features. Specifically, we start from the frequency perspective and design a Frequency Decomposition (FD) module to separate different frequency components to comprehensively compensate the information lost for real LR image. Then, considering the different regions of real LR image have different frequency information lost, we further design a Region-adaptive Frequency Aggregation (RFA) module by leveraging dynamic convolution and spatial attention to adaptively restore frequency components for different regions. The extensive experiments endorse the effective, and scenario-agnostic nature of our OR-Net for RealSR.",単一の均一な劣化（つまり、バイキュービックダウンサンプリング）の解決に焦点を当てた従来の単一画像超解像（SISR）手法は、複雑で現実的なため、実際の低解像度（LR）画像に適用するとパフォーマンスが低下します。劣化。このより困難な実像超解像（RealSR）問題を解決するための鍵は、有益でコンテンツを意識した特徴表現を学習することにあります。この論文では、両方の課題に対処するために全周波数領域適応ネットワーク（ORNet）を提案します。ここでは、すべての低、中、高周波数の全周波数機能の機能と呼びます。具体的には、周波数の観点から開始し、周波数分解（FD）モジュールを設計して、さまざまな周波数成分を分離し、実際のLR画像で失われた情報を包括的に補正します。次に、実際のLR画像のさまざまな領域でさまざまな周波数情報が失われることを考慮して、動的畳み込みと空間的注意を活用してさまざまな領域の周波数成分を適応的に復元することにより、領域適応周波数集約（RFA）モジュールをさらに設計します。広範な実験は、RealSR用のOR-Netの効果的でシナリオにとらわれない性質を裏付けています。,https://d3i71xaburhd42.cloudfront.net/36fac56c02597f9ea7c9c05419fd7a7109de1056/1-Figure1-1.png
On Convergence of Gradient Expected Sarsa (lambda),"['Long Yang', 'Gang Zheng', 'Yu Zhang', 'Qian Zheng', 'Pengfei Li', 'Gang Pan']",https://arxiv.org/abs/2012.07199,"We study the convergence of $\mathtt{Expected~Sarsa}(\lambda)$ with linear function approximation. We show that applying the off-line estimate (multi-step bootstrapping) to $\mathtt{Expected~Sarsa}(\lambda)$ is unstable for off-policy learning. Furthermore, based on convex-concave saddle-point framework, we propose a convergent $\mathtt{Gradient~Expected~Sarsa}(\lambda)$ ($\mathtt{GES}(\lambda)$) algorithm. The theoretical analysis shows that our $\mathtt{GES}(\lambda)$ converges to the optimal solution at a linear convergence rate, which is comparable to extensive existing state-of-the-art gradient temporal difference learning algorithms. Furthermore, we develop a Lyapunov function technique to investigate how the step-size influences finite-time performance of $\mathtt{GES}(\lambda)$, such technique of Lyapunov function can be potentially generalized to other GTD algorithms. Finally, we conduct experiments to verify the effectiveness of our $\mathtt{GES}(\lambda)$.",線形関数近似を使用して、Expected Sarsa（）の収束を調べます。オフライン推定（マルチステップブートストラップ）をExpected Sarsa（）に適用することは、ポリシー外の学習では不安定であることを示します。さらに、凸凹サドルポイントフレームワークに基づいて、収束勾配期待Sarsa（）（GES（））アルゴリズムを提案します。理論的分析は、GES（）が線形収束率で最適解に収束することを示しています。これは、既存の広範な最新の勾配時間差学習アルゴリズムに匹敵します。さらに、ステップサイズがGES（）の有限時間パフォーマンスにどのように影響するかを調査するために、リアプノフ関数手法を開発します。このようなリアプノフ関数手法は、他のGTDアルゴリズムに一般化できる可能性があります。最後に、GES（）の有効性を検証するための実験を行います。,https://d3i71xaburhd42.cloudfront.net/3733e6677ad9dd363bf1ab2013c609a995607b67/3-Figure1-1.png
Visual Tracking via Hierarchical Deep Reinforcement Learning,"['Dawei Zhang', 'Zhonglong Zheng', 'Riheng Jia', 'Minglu Li']",,,,
Recognizing and Verifying Mathematical Equations Using Multiplicative Differential Neural Units,"['Ankur Mali', 'Alexander Ororbia', 'Daniel Kifer', 'C. Lee Giles']",,,,
Rethinking Bi-Level Optimization in Neural Architecture Search: A Gibbs Sampling Perspective,"['Chao Xue', 'Xiaoxing Wang', 'Junchi Yan', 'Yonggang Hu', 'Xiaokang Yang', 'Kewei Sun']",,,,
EvaLDA: Efficient Evasion Attacks Towards Latent Dirichlet Allocation,"['Qi Zhou', 'Haipeng Chen', 'Zheng Yitao', 'Zhen Wang']",https://arxiv.org/abs/2012.04864,"As one of the most powerful topic models, Latent Dirichlet Allocation (LDA) has been used in a vast range of tasks, including document understanding, information retrieval and peer-reviewer assignment. Despite its tremendous popularity, the security of LDA has rarely been studied. This poses severe risks to security-critical tasks such as sentiment analysis and peer-reviewer assignment that are based on LDA. In this paper, we are interested in knowing whether LDA models are vulnerable to adversarial perturbations of benign document examples during inference time. We formalize the evasion attack to LDA models as an optimization problem and prove it to be NP-hard. We then propose a novel and efficient algorithm, EvaLDA to solve it. We show the effectiveness of EvaLDA via extensive empirical evaluations. For instance, in the NIPS dataset, EvaLDA can averagely promote the rank of a target topic from 10 to around 7 by only replacing 1% of the words with similar words in a victim document. Our work provides significant insights into the power and limitations of evasion attacks to LDA models.",最も強力なトピックモデルの1つとして、潜在的ディリクレ割り当て（LDA）は、ドキュメントの理解、情報検索、ピアレビューアの割り当てなど、幅広いタスクで使用されてきました。その絶大な人気にもかかわらず、LDAのセキュリティはめったに研究されていません。これは、LDAに基づく感情分析やピアレビューアの割り当てなど、セキュリティが重要なタスクに深刻なリスクをもたらします。この論文では、LDAモデルが推論時間中に良性の文書例の敵対的摂動に対して脆弱であるかどうかを知ることに関心があります。 LDAモデルへの回避攻撃を最適化問題として形式化し、NP困難であることを証明します。次に、それを解決するための斬新で効率的なアルゴリズムEvaLDAを提案します。広範な経験的評価を通じてEvaLDAの有効性を示します。たとえば、NIPSデータセットでは、EvaLDAは、1を置き換えるだけで、ターゲットトピックのランクを平均して10から約7に昇格させることができます。,https://d3i71xaburhd42.cloudfront.net/d30ed44df0156000a343e98258e4515534745923/7-Figure1-1.png
AugSplicing: Synchronized Behavior Detection in Streaming Tensors,"['Jiabao Zhang', 'Shenghua Liu', 'Wenting Hou', 'Siddharth Bhatia', 'Huawei Shen', 'Wenjian Yu', 'Xueqi Cheng']",https://arxiv.org/abs/2012.02006,"How can we track synchronized behavior in a stream of time-stamped tuples, such as mobile devices installing and uninstalling applications in the lockstep, to boost their ranks in the app store? We model such tuples as entries in a streaming tensor, which augments attribute sizes in its modes over time. Synchronized behavior tends to form dense blocks (i.e. subtensors) in such a tensor, signaling anomalous behavior, or interesting communities. However, existing dense block detection methods are either based on a static tensor, or lack an efficient algorithm in a streaming setting. Therefore, we propose a fast streaming algorithm, AugSplicing, which can detect the top dense blocks by incrementally splicing the previous detection with the incoming ones in new tuples, avoiding re-runs over all the history data at every tracking time step. AugSplicing is based on a splicing condition that guides the algorithm (Section 4). Compared to the state-of-the-art methods, our method is (1) effective to detect fraudulent behavior in installing data of real-world apps and find a synchronized group of students with interesting features in campus Wi-Fi data; (2) robust with splicing theory for dense block detection; (3) streaming and faster than the existing streaming algorithm, with closely comparable accuracy.",ロックステップでアプリケーションをインストールおよびアンインストールするモバイルデバイスなど、タイムスタンプ付きのタプルのストリームで同期された動作を追跡して、アプリストアでのランクを上げるにはどうすればよいですか？このようなタプルをストリーミングテンソルのエントリとしてモデル化します。これにより、時間の経過とともにモードの属性サイズが増加します。同期された動作は、そのようなテンソルで密なブロック（つまりサブテンソル）を形成する傾向があり、異常な動作、または興味深いコミュニティを示します。ただし、既存の高密度ブロック検出方法は、静的テンソルに基づいているか、ストリーミング設定で効率的なアルゴリズムが不足しています。したがって、高速ストリーミングアルゴリズムであるAugSplicingを提案します。これは、前の検出を新しいタプルの着信ブロックと段階的にスプライシングすることで最上位の高密度ブロックを検出し、追跡タイムステップごとにすべての履歴データを再実行することを回避します。 AugSplicingは、アルゴリズムをガイドするスプライシング条件に基づいています（セクション4）。最先端の方法と比較して、私たちの方法は（1）実世界のアプリのデータをインストールする際の不正行為を検出し、キャンパスのWi-Fiデータに興味深い機能を備えた同期された学生のグループを見つけるのに効果的です。 （2）高密度ブロック検出のためのスプライシング理論でロバスト。 （3）ストリーミングであり、既存のストリーミングアルゴリズムよりも高速で、精度はほぼ同等です。,https://d3i71xaburhd42.cloudfront.net/3fab2fab00c05f3ff4bcf0c7819fcf5143420eb6/3-Figure1-1.png
Amodal Segmentation Based on Visible Region Segmentation and Shape Prior,"['Yuting Xiao', 'Yanyu Xu', 'Ziming Zhong', 'Weixin Luo', 'Jiawei Li', 'Shenghua Gao']",https://arxiv.org/abs/2012.05598,Almost all existing amodal segmentation methods make the inferences of occluded regions by using features corresponding to the whole image.,ほとんどすべての既存のアモーダルセグメンテーション方法は、画像全体に対応する特徴を使用して、遮蔽された領域の推論を行います。,https://d3i71xaburhd42.cloudfront.net/447d4008dc08b30a2731d898bfdbc8000c7f5b4a/2-Figure1-1.png
SCNet: Training Inference Sample Consistency for Instance Segmentation,"['Thang Van Vu', 'Haeyong Kang', 'Chang D. Yoo']",,,,
Re-TACRED: Addressing Shortcomings of the TACRED Dataset,"['George I Stoica', 'Emmanouil Antonios Platanios', 'Barnabas Poczos']",,,,
ActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces,"['Zecheng He', 'Srinivas Sunkara', 'Xiaoxue Zang', 'Ying Xu', 'Lijuan Liu', 'Nevan Wichers', 'Gabriel Schubiner', 'Ruby Lee', 'Jindong Chen']",https://arxiv.org/abs/2012.12350,"As mobile devices are becoming ubiquitous, regularly interacting with a variety of user interfaces (UIs) is a common aspect of daily life for many people. To improve the accessibility of these devices and to enable their usage in a variety of settings, building models that can assist users and accomplish tasks through the UI is vitally important. However, there are several challenges to achieve this. First, UI components of similar appearance can have different functionalities, making understanding their function more important than just analyzing their appearance. Second, domain-specific features like Document Object Model (DOM) in web pages and View Hierarchy (VH) in mobile applications provide important signals about the semantics of UI elements, but these features are not in a natural language format. Third, owing to a large diversity in UIs and absence of standard DOM or VH representations, building a UI understanding model with high coverage requires large amounts of training data. Inspired by the success of pre-training based approaches in NLP for tackling a variety of problems in a data-efficient way, we introduce a new pre-trained UI representation model called ActionBert. Our methodology is designed to leverage visual, linguistic and domain-specific features in user interaction traces to pre-train generic feature representations of UIs and their components. Our key intuition is that user actions, e.g., a sequence of clicks on different UI components, reveals important information about their functionality. We evaluate the proposed model on a wide variety of downstream tasks, ranging from icon classification to UI component retrieval based on its natural language description. Experiments show that the proposed ActionBert model outperforms multi-modal baselines across all downstream tasks by up to 15.5%.",モバイルデバイスがユビキタスになりつつあるため、さまざまなユーザーインターフェイス（UI）と定期的に対話することは、多くの人々の日常生活の一般的な側面です。これらのデバイスのアクセシビリティを改善し、さまざまな設定での使用を可能にするには、ユーザーを支援し、UIを介してタスクを実行できるモデルを構築することが非常に重要です。ただし、これを実現するにはいくつかの課題があります。まず、外観が似ているUIコンポーネントは機能が異なる可能性があるため、外観を分析するだけでなく、機能を理解することが重要になります。次に、WebページのDocument Object Model（DOM）やモバイルアプリケーションのView Hierarchy（VH）などのドメイン固有の機能は、UI要素のセマンティクスに関する重要なシグナルを提供しますが、これらの機能は自然言語形式ではありません。第3に、UIの多様性が大きく、標準のDOMまたはVH表現がないため、カバレッジの高いUI理解モデルを構築するには、大量のトレーニングデータが必要です。データ効率の高い方法でさまざまな問題に取り組むためのNLPでの事前トレーニングベースのアプローチの成功に触発されて、ActionBertと呼ばれる新しい事前トレーニング済みUI表現モデルを導入します。私たちの方法論は、ユーザーインタラクショントレースの視覚的、言語的、およびドメイン固有の機能を活用して、UIとそのコンポーネントの一般的な機能表現を事前にトレーニングするように設計されています。私たちの重要な直感は、ユーザーアクション、たとえば、さまざまなUIコンポーネントの一連のクリックによって、それらの機能に関する重要な情報が明らかになることです。提案されたモデルを、アイコンの分類から自然言語の記述に基づくUIコンポーネントの取得まで、さまざまなダウンストリームタスクで評価します。実験によると、提案されたActionBertモデルは、すべてのダウンストリームタスクでマルチモーダルベースラインを最大15.5上回っています。,https://d3i71xaburhd42.cloudfront.net/0285688c1a07e49a663d0f49ef39370fbd00d3aa/2-Figure1-1.png
Joint Color-Irrelevant Consistency Learning and Identity-Aware Modality Adaptation for Visible-Infrared Cross Modality Person Re-Identification,"['Zhiwei Zhao', 'Bin Liu', 'Qi Chu', 'Yan Lu', 'Nenghai Yu']",,,,
Cold-Start Sequential Recommendation via Meta Learner,"['Yujia Zheng', 'Siyi Liu', 'Zekun Li', 'Shu Wu']",,,,
Adaptive Prior-Dependent Correction Enhanced Reinforcement Learning for Natural Language Generation,"['Wei Cheng', 'Ziyan Luo', 'Qiyue Yin']",,,,
The Importance of Modeling Data Missingness in Algorithmic Fairness: A Causal Perspective,"['Naman Goel', 'Alfonso Amayuelas', 'Amit Deshpande', 'Amit Sharma']",https://arxiv.org/abs/2012.11448,"Training datasets for machine learning often have some form of missingness. For example, to learn a model for deciding whom to give a loan, the available training data includes individuals who were given a loan in the past, but not those who were not. This missingness, if ignored, nullifies any fairness guarantee of the training procedure when the model is deployed. Using causal graphs, we characterize the missingness mechanisms in different real-world scenarios. We show conditions under which various distributions, used in popular fairness algorithms, can or can not be recovered from the training data. Our theoretical results imply that many of these algorithms can not guarantee fairness in practice. Modeling missingness also helps to identify correct design principles for fair algorithms. For example, in multi-stage settings where decisions are made in multiple screening rounds, we use our framework to derive the minimal distributions required to design a fair algorithm. Our proposed algorithm decentralizes the decision-making process and still achieves similar performance to the optimal algorithm that requires centralization and non-recoverable distributions.",機械学習のトレーニングデータセットには、多くの場合、何らかの形で欠落があります。たとえば、誰に融資するかを決定するためのモデルを学習するために、利用可能なトレーニングデータには、過去に融資を受けた個人が含まれますが、そうでない個人は含まれません。この欠落が無視されると、モデルが展開されたときのトレーニング手順の公平性の保証が無効になります。因果グラフを使用して、さまざまな実世界のシナリオでの欠落メカニズムを特徴付けます。一般的な公平性アルゴリズムで使用されるさまざまな分布が、トレーニングデータから復元できる場合とできない場合の条件を示します。私たちの理論的結果は、これらのアルゴリズムの多くが実際の公平性を保証できないことを示唆しています。欠落のモデリングは、公正なアルゴリズムの正しい設計原則を特定するのにも役立ちます。たとえば、複数のスクリーニングラウンドで決定が行われる多段階の設定では、フレームワークを使用して、公正なアルゴリズムの設計に必要な最小限の分布を導き出します。私たちが提案するアルゴリズムは、意思決定プロセスを分散化し、集中化と回復不可能な分散を必要とする最適なアルゴリズムと同様のパフォーマンスを実現します。,https://d3i71xaburhd42.cloudfront.net/3e2822475a8669ffedd282de12f2e247e6a2b266/1-Figure1-1.png
Learning Local Neighboring Structure for Robust 3D Shape Representation,"['Zhongpai Gao', 'Junchi Yan', 'Guangtao Zhai', 'Juyong Zhang', 'Yiyan Yang', 'Xiaokang Yang']",https://arxiv.org/abs/2004.09995,"Mesh is a powerful data structure for 3D shapes. Representation learning for 3D meshes is important in many computer vision and graphics applications. The recent success of convolutional neural networks (CNNs) for structured data (e.g., images) suggests the value of adapting insight from CNN for 3D shapes. However, 3D shape data are irregular since each node's neighbors are unordered. Various graph neural networks for 3D shapes have been developed with isotropic filters or predefined local coordinate systems to overcome the node inconsistency on graphs. However, isotropic filters or predefined local coordinate systems limit the representation power. In this paper, we propose a local structure-aware anisotropic convolutional operation (LSA-Conv) that learns adaptive weighting matrices for each node according to the local neighboring structure and performs shared anisotropic filters. In fact, the learnable weighting matrix is similar to the attention matrix in random synthesizer -- a new Transformer model for natural language processing (NLP). Comprehensive experiments demonstrate that our model produces significant improvement in 3D shape reconstruction compared to state-of-the-art methods.",メッシュは、3D形状の強力なデータ構造です。 3Dメッシュの表現学習は、多くのコンピュータービジョンおよびグラフィックスアプリケーションで重要です。構造化データ（画像など）の畳み込みニューラルネットワーク（CNN）の最近の成功は、CNNからの洞察を3D形状に適応させることの価値を示唆しています。ただし、各ノードの隣接ノードが順序付けられていないため、3D形状データは不規則です。グラフ上のノードの不整合を克服するために、等方性フィルターまたは事前定義されたローカル座標系を使用して、3D形状用のさまざまなグラフニューラルネットワークが開発されています。ただし、等方性フィルターまたは事前定義されたローカル座標系は、表現力を制限します。本論文では、局所隣接構造に従って各ノードの適応加重行列を学習し、共有異方性フィルターを実行する局所構造認識異方性畳み込み演算（LSA-Conv）を提案します。実際、学習可能な重み付けマトリックスは、自然言語処理（NLP）用の新しいTransformerモデルであるランダムシンセサイザーの注意マトリックスに似ています。包括的な実験は、私たちのモデルが最先端の方法と比較して3D形状の再構築に大幅な改善をもたらすことを示しています。,
Deep Partial Rank Aggregation for Personalized Attributes,"['Qianqian Xu', 'Zhiyong Yang', 'Zuyao Chen', 'Yangbangyan Jiang', 'Xiaochun Cao', 'Yuan Yao', 'Qingming Huang']",,,,
SSD-GAN: Measuring the Realness in the Spatial and Spectral Domains,"['Yuanqi Chen', 'Ge Li', 'Cece Jin', 'Shan Liu', 'Thomas H Li']",https://arxiv.org/abs/2012.05535,"This paper observes that there is an issue of high frequencies missing in the discriminator of standard GAN, and we reveal it stems from downsampling layers employed in the network architecture. This issue makes the generator lack the incentive from the discriminator to learn high-frequency content of data, resulting in a significant spectrum discrepancy between generated images and real images. Since the Fourier transform is a bijective mapping, we argue that reducing this spectrum discrepancy would boost the performance of GANs. To this end, we introduce SSD-GAN, an enhancement of GANs to alleviate the spectral information loss in the discriminator. Specifically, we propose to embed a frequency-aware classifier into the discriminator to measure the realness of the input in both the spatial and spectral domains. With the enhanced discriminator, the generator of SSD-GAN is encouraged to learn high-frequency content of real data and generate exact details. The proposed method is general and can be easily integrated into most existing GANs framework without excessive cost. The effectiveness of SSD-GAN is validated on various network architectures, objective functions, and datasets. Code will be available at this https URL.",この論文では、標準GANの弁別器に高周波が欠落しているという問題があることを観察し、それがネットワークアーキテクチャで採用されているダウンサンプリング層に起因していることを明らかにします。この問題により、ジェネレータは、データの高周波コンテンツを学習するための弁別器からのインセンティブを欠き、生成された画像と実際の画像との間に重大なスペクトルの不一致が生じます。フーリエ変換は全単射マッピングであるため、このスペクトルの不一致を減らすとGANのパフォーマンスが向上すると主張します。この目的のために、SSD-GANを導入します。これは、ディスクリミネーターでのスペクトル情報の損失を軽減するためのGANの拡張機能です。具体的には、周波数を意識した分類器を弁別器に組み込んで、空間領域とスペクトル領域の両方で入力の現実性を測定することを提案します。強化されたディスクリミネーターにより、SSD-GANのジェネレーターは、実際のデータの高周波コンテンツを学習し、正確な詳細を生成することが推奨されます。提案された方法は一般的であり、過度のコストをかけずにほとんどの既存のGANフレームワークに簡単に統合できます。 SSD-GANの有効性は、さまざまなネットワークアーキテクチャ、目的関数、およびデータセットで検証されます。コードはこのhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/f93a162eb8014fee3feef6b03cd1dcd057e6a4e5/1-Figure1-1.png
A Novel Visual Interpretability for Deep Neural Networks by Optimizing Activation Maps with Perturbation,"['Qinglong Zhang', 'Lu Rao', 'Yubin Yang']",,,,
Scene Graph Embeddings Using Relative Similarity Supervision,"['Paridhi Maheshwari', 'Ritwick Chaudhry', 'Vishwa Vinay']",,,,
Deterministic Mini-Batch Sequencing for Training Deep Neural Networks,"['Subhankar Banerjee', 'Shayok Chakraborty']",,,,
A Complexity-Theoretic Analysis of Green Pickup-and-Delivery Problems,"['Xing Tan', 'Jimmy Huang']",,,,
Temporal Segmentation of Fine-Gained Semantic Action: A Motion-Centered Figure Skating Dataset,"['Shenglan Liu', 'Aibin Zhang', 'Yunheng Li', 'Jian Zhou', 'Li Xu', 'Zhuben Dong', 'Renhao Zhang']",,,,
Stratified Negation in Datalog with Metric Temporal Operators,"['David J Tena Cucala', 'Przemysław A Wałęga', 'Bernardo Cuenca Grau', 'Egor Kostylev']",,,,
Learning the Parameters of Bayesian Networks from Uncertain Data,"['Segev Wasserkrug', 'Radu Marinescu', 'Sergey Zeltyn', 'Evgeny Shindin', 'Yishai A Feldman']",,,,
Dense Events Grounding in Video,"['Peijun Bao', 'Qian Zheng', 'Yadong Mu']",,,,
Continuous Self-Attention Models with Neural ODE Networks,"['Jing Zhang', 'Peng Zhang', 'Baiwen Kong', 'Junqiu Wei', 'Xin Jiang']",,,,
On-the-Fly Synthesis for LTL over Finite Traces,"['Shengping Xiao', 'Jianwen Li', 'Shufang Zhu', 'Yingying Shi', 'Geguang Pu', 'Moshe Vardi']",,,,
Graph-to-Graph: Towards Accurate and Interpretable Online Handwritten Mathematical Expression Recognition,"['Jin-Wen Wu', 'Fei Yin', 'Yanming Zhang', 'Xu-Yao Zhang', 'Cheng-Lin Liu']",,,,
Peer Collaborative Learning for Online Knowledge Distillation,"['Guile Wu', 'Shaogang Gong']",https://arxiv.org/abs/2006.04147,"Traditional knowledge distillation uses a two-stage training strategy to transfer knowledge from a high-capacity teacher model to a smaller student model, which relies heavily on the pre-trained teacher. Recent online knowledge distillation alleviates this limitation by collaborative learning, mutual learning and online ensembling, following a one-stage end-to-end training strategy. However, collaborative learning and mutual learning fail to construct an online high-capacity teacher, whilst online ensembling ignores the collaboration among branches and its logit summation impedes the further optimisation of the ensemble teacher. In this work, we propose a novel Peer Collaborative Learning method for online knowledge distillation. Specifically, we employ a multi-branch network (each branch is a peer) and assemble the features from peers with an additional classifier as the peer ensemble teacher to transfer knowledge from the high-capacity teacher to peers and to further optimise the ensemble teacher. Meanwhile, we employ the temporal mean model of each peer as the peer mean teacher to collaboratively transfer knowledge among peers, which facilitates to optimise a more stable model and alleviate the accumulation of training error among peers. Integrating them into a unified framework takes full advantage of online ensembling and network collaboration for improving the quality of online distillation. Extensive experiments on CIFAR-10, CIFAR-100 and ImageNet show that the proposed method not only significantly improves the generalisation capability of various backbone networks, but also outperforms the state-of-the-art alternative methods.",従来の知識蒸留では、2段階のトレーニング戦略を使用して、大容量の教師モデルから、事前にトレーニングされた教師に大きく依存する小規模な学生モデルに知識を転送します。最近のオンライン知識の蒸留は、1段階のエンドツーエンドのトレーニング戦略に従って、共同学習、相互学習、およびオンラインアンサンブルによってこの制限を緩和します。ただし、共同学習と相互学習はオンラインの大容量の教師を構築できませんが、オンラインアンサンブルはブランチ間のコラボレーションを無視し、そのロジットの合計はアンサンブル教師のさらなる最適化を妨げます。この作業では、オンライン知識蒸留のための新しいピア共同学習方法を提案します。具体的には、マルチブランチネットワーク（各ブランチはピア）を採用し、ピアアンサンブルティーチャーとして追加の分類子を使用してピアからの機能を組み立て、大容量のティーチャーからピアに知識を転送し、アンサンブルティーチャーをさらに最適化します。一方、ピア平均教師として各ピアの時間平均モデルを採用し、ピア間で知識を協調的に伝達することで、より安定したモデルを最適化し、ピア間のトレーニングエラーの蓄積を軽減します。それらを統合フレームワークに統合すると、オンラインアンサンブルとネットワークコラボレーションを最大限に活用して、オンライン蒸留の品質を向上させることができます。 CIFAR-10、CIFAR-100、およびImageNetでの広範な実験は、提案された方法がさまざまなバックボーンネットワークの一般化機能を大幅に改善するだけでなく、最先端の代替方法よりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/a7058717ce5d37094fed32147d3b98d0edc0df16/2-Figure1-1.png
A Hybrid Stochastic Gradient Hamiltonian Monte Carlo Method,"['Chao Zhang', 'Zhijian Li', 'Zebang Shen', 'Jiahao Xie', 'Hui Qian']",,,,
DeepCollaboration: Collaborative Generative and Discriminative Models for Class Incremental Learning,"['Bo Cui', 'Guyue Hu', 'Shan Yu']",,,,
GDPNet: Refining Latent Multi-View Graph for Relation Extraction,"['Fuzhao Xue', 'Aixin Sun', 'Hao Zhang', 'Eng Siong Chng']",https://arxiv.org/abs/2012.06780,"Relation Extraction (RE) is to predict the relation type of two entities that are mentioned in a piece of text, e.g., a sentence or a dialogue. When the given text is long, it is challenging to identify indicative words for the relation prediction. Recent advances on RE task are from BERT-based sequence modeling and graph-based modeling of relationships among the tokens in the sequence. In this paper, we propose to construct a latent multi-view graph to capture various possible relationships among tokens. We then refine this graph to select important words for relation prediction. Finally, the representation of the refined graph and the BERT-based sequence representation are concatenated for relation extraction. Specifically, in our proposed GDPNet (Gaussian Dynamic Time Warping Pooling Net), we utilize Gaussian Graph Generator (GGG) to generate edges of the multi-view graph. The graph is then refined by Dynamic Time Warping Pooling (DTWPool). On DialogRE and TACRED, we show that GDPNet achieves the best performance on dialogue-level RE, and comparable performance with the state-of-the-arts on sentence-level RE.",関係抽出（RE）は、文や会話など、テキストの一部で言及されている2つのエンティティの関係タイプを予測することです。与えられたテキストが長い場合、関係予測の指標となる単語を特定することは困難です。 REタスクの最近の進歩は、BERTベースのシーケンスモデリングと、シーケンス内のトークン間の関係のグラフベースのモデリングによるものです。この論文では、トークン間のさまざまな可能な関係をキャプチャするために、潜在的なマルチビューグラフを構築することを提案します。次に、このグラフを改良して、関係予測のための重要な単語を選択します。最後に、洗練されたグラフの表現とBERTベースのシーケンス表現が連結されて関係が抽出されます。具体的には、提案されたGDPNet（Gaussian Dynamic Time Warping Pooling Net）では、Gaussian Graph Generator（GGG）を使用してマルチビューグラフのエッジを生成します。次に、動的タイムワーピングプーリング（DTWPool）によってグラフが調整されます。 DialogREとTACREDでは、GDPNetがダイアログレベルのREで最高のパフォーマンスを達成し、センテンスレベルのREで最先端のパフォーマンスと同等のパフォーマンスを達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/c3ee23ae9c6eef53ff8a6ec8169a1ebd25a36b65/3-Figure1-1.png
Argument Mining Driven Analysis of Peer-Reviews,"['Michael Fromm', 'Evgeniy Faerman', 'Max Berrendorf', 'Siddharth Bhargava', 'Ruoxia Qi', 'Yao Zhang', 'Lukas Dennert', 'Sophia Selle', 'Yang Mao', 'Thomas Seidl']",https://arxiv.org/abs/2012.07743,"Peer reviewing is a central process in modern research and essential for ensuring high quality and reliability of published work. At the same time, it is a time-consuming process and increasing interest in emerging fields often results in a high review workload, especially for senior researchers in this area. How to cope with this problem is an open question and it is vividly discussed across all major conferences. In this work, we propose an Argument Mining based approach for the assistance of editors, meta-reviewers, and reviewers. We demonstrate that the decision process in the field of scientific publications is driven by arguments and automatic argument identification is helpful in various use-cases. One of our findings is that arguments used in the peer-review process differ from arguments in other domains making the transfer of pre-trained models difficult. Therefore, we provide the community with a new peer-review dataset from different computer science conferences with annotated arguments. In our extensive empirical evaluation, we show that Argument Mining can be used to efficiently extract the most relevant parts from reviews, which are paramount for the publication decision. The process remains interpretable since the extracted arguments can be highlighted in a review without detaching them from their context.",査読は現代の研究の中心的なプロセスであり、出版された作品の高品質と信頼性を確保するために不可欠です。同時に、それは時間のかかるプロセスであり、新興分野への関心の高まりは、特にこの分野の上級研究者にとって、しばしば高いレビュー作業負荷をもたらします。この問題にどのように対処するかは未解決の問題であり、すべての主要な会議で活発に議論されています。この作業では、編集者、メタレビュー担当者、およびレビュー担当者を支援するための引数マイニングベースのアプローチを提案します。科学出版物の分野での意思決定プロセスは議論によって推進されており、自動議論識別はさまざまなユースケースで役立つことを示しています。私たちの調査結果の1つは、ピアレビュープロセスで使用される引数が他のドメインの引数と異なり、事前にトレーニングされたモデルの転送を困難にしていることです。したがって、注釈付きの引数を使用して、さまざまなコンピュータサイエンス会議からの新しいピアレビューデータセットをコミュニティに提供します。私たちの広範な経験的評価では、引数マイニングを使用して、レビューから最も関連性の高い部分を効率的に抽出できることを示しています。これは、出版の決定にとって最も重要です。抽出された引数は、コンテキストから切り離すことなくレビューで強調表示できるため、プロセスは解釈可能なままです。,https://d3i71xaburhd42.cloudfront.net/ecfac0d377db229d58bc88698ad3bfd4b384ef37/6-Figure2-1.png
Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks,"['Xiaosen Wang', 'Yichen Yang', 'Yihe Deng', 'Kun He']",https://arxiv.org/abs/2008.03709,"Adversarial training is the most empirically successful approach in improving the robustness of deep neural networks for image classification. For text classification, however, existing synonym substitution based adversarial attacks are effective but not efficient to be incorporated into practical text adversarial training. Gradient-based attacks, which are very efficient for images, are hard to be implemented for synonym substitution based text attacks due to the lexical, grammatical and semantic constraints and the discrete text input space. Thereby, we propose a fast text adversarial attack method called Fast Gradient Projection Method (FGPM) based on synonym substitution, which is about 20 times faster than existing text attack methods and could achieve similar attack performance. We then incorporate FGPM with adversarial training and propose a text defense method called Adversarial Training with FGPM enhanced by Logit pairing (ATFL). Experiments show that ATFL could significantly improve the model robustness and block the transferability of adversarial examples.",敵対的トレーニングは、画像分類のためのディープニューラルネットワークの堅牢性を向上させる上で最も経験的に成功したアプローチです。ただし、テキスト分類の場合、既存の同義語置換ベースの敵対的攻撃は効果的ですが、実際のテキスト敵対的トレーニングに組み込むには効率的ではありません。画像に対して非常に効率的なグラデーションベースの攻撃は、語彙、文法、およびセマンティックの制約と個別のテキスト入力スペースのために、同義語置換ベースのテキスト攻撃に実装するのは困難です。これにより、同義語置換に基づく高速勾配射影法（FGPM）と呼ばれる高速テキスト敵対的攻撃手法を提案します。これは、既存のテキスト攻撃手法よりも約20倍高速で、同様の攻撃パフォーマンスを実現できます。次に、FGPMを敵対的トレーニングに組み込み、ロジットペアリング（ATFL）によって強化されたFGPMを使用した敵対的トレーニングと呼ばれるテキスト防御方法を提案します。実験は、ATFLがモデルの堅牢性を大幅に改善し、敵対的な例の転送可能性をブロックできることを示しています。,
Newton Optimization on Helmholtz Decomposition for Continuous Games,"['Giorgia Ramponi', 'Marcello Restelli']",,,,
United for Change: Deliberative Coalition Formation to Change the Status Quo,"['Edith Elkind', 'Grossi Davide', 'Ehud Shapiro', 'Nimrod Talmon']",,,,
Voxel R-CNN: Towards High Performance Voxel-Based 3D Object Detection,"['Jiajun Deng', 'Shaoshuai Shi', 'Peiwei Li', 'Wengang Zhou', 'Yanyong Zhang', 'Houqiang Li']",https://arxiv.org/abs/2012.15712,"Recent advances on 3D object detection heavily rely on how the 3D data are represented, i.e., voxel-based or point-based representation. Many existing high performance 3D detectors are point-based because this structure can better retain precise point positions. Nevertheless, point-level features lead to high computation overheads due to unordered storage. In contrast, the voxel-based structure is better suited for feature extraction but often yields lower accuracy because the input data are divided into grids. In this paper, we take a slightly different viewpoint — we find that precise positioning of raw points is not essential for high performance 3D object detection and that the coarse voxel granularity can also offer sufficient detection accuracy. Bearing this view in mind, we devise a simple but effective voxel-based framework, named Voxel R-CNN. By taking full advantage of voxel features in a two stage approach, our method achieves comparable detection accuracy with state-of-the-art point-based models, but at a fraction of the computation cost. Voxel R-CNN consists of a 3D backbone network, a 2D bird-eye-view (BEV) Region Proposal Network and a detect head. A voxel RoI pooling is devised to extract RoI features directly from voxel features for further refinement. Extensive experiments are conducted on the widely used KITTI Dataset and the more recent Waymo Open Dataset. Our results show that compared to existing voxel-based methods, Voxel R-CNN delivers a higher detection accuracy while maintaining a real-time frame processing rate, i.e., at a speed of 25 FPS on an NVIDIA RTX 2080 Ti GPU. The code will be make available soon.",3Dオブジェクト検出の最近の進歩は、3Dデータの表現方法、つまりボクセルベースまたはポイントベースの表現に大きく依存しています。多くの既存の高性能3D検出器は、この構造が正確なポイント位置をより適切に保持できるため、ポイントベースです。それにもかかわらず、ポイントレベルの機能は、順序付けられていないストレージのために高い計算オーバーヘッドにつながります。対照的に、ボクセルベースの構造は特徴抽出に適していますが、入力データがグリッドに分割されているため、精度が低くなることがよくあります。この論文では、わずかに異なる視点を取り、生の点の正確な配置は高性能3Dオブジェクト検出に不可欠ではなく、粗いボクセル粒度も十分な検出精度を提供できることを発見しました。この見方を念頭に置いて、VoxelR-CNNという名前のシンプルで効果的なボクセルベースのフレームワークを考案します。 2段階のアプローチでボクセル機能を最大限に活用することにより、私たちの方法は、最先端のポイントベースのモデルと同等の検出精度を実現しますが、計算コストは​​わずかです。 Voxel R-CNNは、3Dバックボーンネットワーク、2D鳥瞰図（BEV）領域提案ネットワーク、および検出ヘッドで構成されています。ボクセルRoIプーリングは、ボクセル特徴から直接RoI特徴を抽出して、さらに改良するために考案されました。広く使用されているKITTIデータセットと最近のWaymoOpenデータセットで広範な実験が行われます。私たちの結果は、既存のボクセルベースの方法と比較して、ボクセルR-CNNは、リアルタイムのフレーム処理速度、つまりNVIDIA RTX 2080 TiGPUで25FPSの速度を維持しながら、より高い検出精度を提供することを示しています。コードはまもなく利用可能になります。,https://d3i71xaburhd42.cloudfront.net/efc669f75ad0ed2033e7c499ae2d6c8dab7489ce/1-Figure1-1.png
Optical Flow Estimation from a Single Motion-Blurred Image,"['Dawit Mureja Argaw', 'Junsik Kim', 'Francois Rameau', 'Jae Won Cho', 'In So Kweon']",,,,
Motion-Blurred Video Interpolation and Extrapolation,"['Dawit Mureja Argaw', 'Junsik Kim', 'Francois Rameau', 'In So Kweon']",,,,
Co-Mining: Self-Supervised Learning for Sparsely Annotated Object Detection,"['Tiancai Wang', 'Tong Yang', 'Jiale Cao', 'Xiangyu Zhang']",https://arxiv.org/abs/2012.01950,"Object detectors usually achieve promising results with the supervision of complete instance annotations. However, their performance is far from satisfactory with sparse instance annotations. Most existing methods for sparsely annotated object detection either re-weight the loss of hard negative samples or convert the unlabeled instances into ignored regions to reduce the interference of false negatives. We argue that these strategies are insufficient since they can at most alleviate the negative effect caused by missing annotations. In this paper, we propose a simple but effective mechanism, called Co-mining, for sparsely annotated object detection. In our Co-mining, two branches of a Siamese network predict the pseudo-label sets for each other. To enhance multi-view learning and better mine unlabeled instances, the original image and corresponding augmented image are used as the inputs of two branches of the Siamese network, respectively. Co-mining can serve as a general training mechanism applied to most of modern object detectors. Experiments are performed on MS COCO dataset with three different sparsely annotated settings using two typical frameworks: anchor-based detector RetinaNet and anchor-free detector FCOS. Experimental results show that our Co-mining with RetinaNet achieves 1.4%~2.1% improvements compared with different baselines and surpasses existing methods under the same sparsely annotated setting.",オブジェクト検出器は通常、完全なインスタンス注釈を監視することで有望な結果を達成します。ただし、それらのパフォーマンスは、スパースインスタンスアノテーションでは十分とは言えません。まばらに注釈が付けられたオブジェクト検出のほとんどの既存の方法は、ハードネガティブサンプルの損失を再重み付けするか、ラベルのないインスタンスを無視された領域に変換して、フォールスネガティブの干渉を減らします。これらの戦略は、注釈の欠落によって引き起こされる悪影響をせいぜい軽減できるため、不十分であると私たちは主張します。この論文では、まばらに注釈が付けられたオブジェクト検出のために、コマイニングと呼ばれるシンプルで効果的なメカニズムを提案します。コマイニングでは、シャムネットワークの2つのブランチが、相互の疑似ラベルセットを予測します。マルチビュー学習を強化し、ラベルのないインスタンスをより適切にマイニングするために、元の画像と対応する拡張画像が、それぞれシャムネットワークの2つのブランチの入力として使用されます。コマイニングは、最新のオブジェクト検出器のほとんどに適用される一般的なトレーニングメカニズムとして機能します。実験は、アンカーベースの検出器RetinaNetとアンカーフリー検出器FCOSの2つの典型的なフレームワークを使用して、3つの異なるまばらに注釈が付けられた設定でMSCOCOデータセットに対して実行されます。実験結果は、RetinaNetとのコマイニングが1.4を達成することを示しています,https://d3i71xaburhd42.cloudfront.net/7617f22c96c6b7ae983b070083a1ca94abf6bab5/1-Figure1-1.png
Uncertainty-Aware Multi-View Representation Learning,"['Yu Geng', 'Zongbo Han', 'Changqing Zhang', 'Qinghua Hu']",,,,
Temporal ROI Align for Video Object Recognition,"['Tao Gong', 'Kai Chen', 'Xinjiang Wang', 'Qi Chu', 'Feng Zhu', 'Dahua Lin', 'Nenghai Yu', 'Huamin Feng']",,,,
Learning from My Friends: Few-Shot Personalized Conversation Systems via Social Networks,"['Zhiliang Tian', 'Wei Bi', 'Zihan Zhang', 'Dongkyu Lee', 'Yiping Song', 'Nevin L Zhang']",,,,
"Imagine, Reason and Write: Visual Storytelling with Graph Knowledge and Relational Reasoning","['Chunpu Xu', 'Chengming Li', 'Ying Shen', 'Xiang Ao', 'Ruifeng Xu', 'Min Yang']",,,,
A User-Adaptive Layer Selection Framework for Very Deep Sequential Recommender Models,"['Lei Chen', 'Fajie Yuan', 'Jiaxi Yang', 'Xiang Ao', 'Chengming Li', 'Min Yang']",,,,
Cross-Layer Distillation with Semantic Calibration,"['Defang Chen', 'Jian-Ping Mei', 'Yuan Zhang', 'Can Wang', 'Zhe Wang', 'Yan Feng', 'Chun Chen']",https://arxiv.org/abs/2012.03236,"Recently proposed knowledge distillation approaches based on feature-map transfer validate that intermediate layers of a teacher model can serve as effective targets for training a student model to obtain better generalization ability. Existing studies mainly focus on particular representation forms for knowledge transfer between manually specified pairs of teacher-student intermediate layers. However, semantics of intermediate layers may vary in different networks and manual association of layers might lead to negative regularization caused by semantic mismatch between certain teacher-student layer pairs. To address this problem, we propose Semantic Calibration for Cross-layer Knowledge Distillation (SemCKD), which automatically assigns proper target layers of the teacher model for each student layer with an attention mechanism. With a learned attention distribution, each student layer distills knowledge contained in multiple layers rather than a single fixed intermediate layer from the teacher model for appropriate cross-layer supervision in training. Consistent improvements over state-of-the-art approaches are observed in extensive experiments with various network architectures for teacher and student models, demonstrating the effectiveness and flexibility of the proposed attention based soft layer association mechanism for cross-layer distillation.",機能マップ転送に基づく最近提案された知識蒸留アプローチは、教師モデルの中間層が、より良い一般化能力を得るために学生モデルをトレーニングするための効果的なターゲットとして役立つことができることを検証します。既存の研究は主に、手動で指定された教師と生徒の中間層のペア間の知識伝達のための特定の表現形式に焦点を当てています。ただし、中間レイヤーのセマンティクスはネットワークによって異なる場合があり、レイヤーを手動で関連付けると、特定の教師と生徒のレイヤーペア間のセマンティックの不一致によって引き起こされる負の正則化につながる可能性があります。この問題に対処するために、クロスレイヤー知識蒸留のセマンティックキャリブレーション（SemCKD）を提案します。これは、注意メカニズムを使用して、各生徒レイヤーに教師モデルの適切なターゲットレイヤーを自動的に割り当てます。学習された注意の分布により、各学生レイヤーは、トレーニングでの適切なクロスレイヤー監視のために、教師モデルから単一の固定中間レイヤーではなく、複数のレイヤーに含まれる知識を抽出します。最先端のアプローチに対する一貫した改善は、教師と学生のモデルのさまざまなネットワークアーキテクチャを使用した広範な実験で観察され、クロスレイヤー蒸留のために提案された注意ベースのソフトレイヤー関連付けメカニズムの有効性と柔軟性を示しています。,https://d3i71xaburhd42.cloudfront.net/c2d209926dcbb8076f6e102767d0d2629df6d672/3-Figure1-1.png
Hierarchical Graph Convolution Network for Traffic Forecasting,"['Kan Guo', 'Yongli Hu', 'Yanfeng Sun', 'Sean Qian', 'Junbin Gao', 'Baocai Yin']",,,,
Bayesian Dynamic Mode Decomposition with Variational Matrix Factorization,"['Takahiro Kawashima', 'Hayaru Shouno', 'Hideitsu Hino']",,,,
Sequential Generative Exploration Model for Partially Observable Reinforcement Learning,"['Haiyan Yin', 'Jianda Chen', 'Sinno Pan', 'Sebastian Tschiatschek']",,,,
Distant Transfer Learning via Deep Random Walk,"['Qiao Xiao', 'Yu Zhang']",https://arxiv.org/abs/2006.07622,"Transfer learning, which is to improve the learning performance in the target domain by leveraging useful knowledge from the source domain, often requires that those two domains are very close, which limits its application scope. Recently, distant transfer learning has been studied to transfer knowledge between two distant or even totally unrelated domains via auxiliary domains that are usually unlabeled as a bridge in the spirit of human transitive inference that it is possible to connect two completely unrelated concepts together through gradual knowledge transfer. In this paper, we study distant transfer learning by proposing a DeEp Random Walk basEd distaNt Transfer (DERWENT) method. Different from existing distant transfer learning models that implicitly identify the path of knowledge transfer between the source and target instances through auxiliary instances, the proposed DERWENT model can explicitly learn such paths via the deep random walk technique. Specifically, based on sequences identified by the random walk technique on a data graph where source and target data have no direct edges, the proposed DERWENT model enforces adjacent data points in a squence to be similar, makes the ending data point be represented by other data points in the same sequence, and considers weighted training losses of source data. Empirical studies on several benchmark datasets demonstrate that the proposed DERWENT algorithm yields the state-of-the-art performance.",ソースドメインからの有用な知識を活用してターゲットドメインの学習パフォーマンスを向上させる転送学習では、多くの場合、これら2つのドメインが非常に接近している必要があり、そのためアプリケーションの範囲が制限されます。最近、遠隔移転学習は、2つの完全に無関係な概念を段階的な知識を通じて結び付けることが可能であるという人間の他動詞推論の精神で、通常はブリッジとしてラベル付けされていない補助ドメインを介して、2つの遠隔または完全に無関係なドメイン間で知識を移転するために研究されています転送。本論文では、DeEp Random Walk basEd distaNt Transfer（DERWENT）法を提案することにより、遠隔転送学習を研究します。補助インスタンスを介してソースインスタンスとターゲットインスタンス間の知識伝達のパスを暗黙的に識別する既存の遠隔伝達学習モデルとは異なり、提案されたDERWENTモデルは、ディープランダムウォーク手法を介してそのようなパスを明示的に学習できます。具体的には、ソースデータとターゲットデータに直接エッジがないデータグラフのランダムウォーク手法によって識別されたシーケンスに基づいて、提案されたDERWENTモデルは、シーケンス内の隣接するデータポイントを類似させるように強制し、終了データポイントを他のデータで表します。同じ順序でポイントし、ソースデータの加重トレーニング損失を考慮します。いくつかのベンチマークデータセットに関する実証研究は、提案されたDERWENTアルゴリズムが最先端のパフォーマンスを生み出すことを示しています。,https://d3i71xaburhd42.cloudfront.net/2c15eed6944d33f6209fe03c8d32d2d6a1e66354/2-Figure1-1.png
Adaptive Algorithms for Multi-Armed Bandit with Composite and Anonymous Feedback,"['Siwei Wang', 'Haoyun Wang', 'Longbo Huang']",https://arxiv.org/abs/2012.07048,"We study the multi-armed bandit (MAB) problem with composite and anonymous feedback. In this model, the reward of pulling an arm spreads over a period of time (we call this period as reward interval) and the player receives partial rewards of the action, convoluted with rewards from pulling other arms, successively. Existing results on this model require prior knowledge about the reward interval size as an input to their algorithms. In this paper, we propose adaptive algorithms for both the stochastic and the adversarial cases, without requiring any prior information about the reward interval. For the stochastic case, we prove that our algorithm guarantees a regret that matches the lower bounds (in order). For the adversarial case, we propose the first algorithm to jointly handle non-oblivious adversary and unknown reward interval size. We also conduct simulations based on real-world dataset. The results show that our algorithms outperform existing benchmarks.",複合フィードバックと匿名フィードバックを使用して、多腕バンディット（MAB）問題を研究します。このモデルでは、腕を引くことによる報酬が一定期間にわたって広がり（この期間を報酬間隔と呼びます）、プレーヤーは、他の腕を引くことによる報酬と複雑なアクションの部分的な報酬を連続して受け取ります。このモデルの既存の結果には、アルゴリズムへの入力として報酬間隔のサイズに関する事前の知識が必要です。この論文では、報酬間隔に関する事前情報を必要とせずに、確率的ケースと敵対的ケースの両方に適応アルゴリズムを提案します。確率論的ケースの場合、アルゴリズムが下限に一致する後悔を（順番に）保証することを証明します。敵対的なケースについては、非忘却の敵対者と未知の報酬間隔サイズを共同で処理する最初のアルゴリズムを提案します。また、実際のデータセットに基づいてシミュレーションを実行します。結果は、私たちのアルゴリズムが既存のベンチマークを上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/18d873fb28e3e454bbd9e536fde78058bbfdaf7e/3-Figure1-1.png
Improving Tree-Structured Decoder Training for Code Generation via Mutual Learning,"['Binbin Xie', 'Jinsong Su', 'Yubin Ge', 'Xiang Li', 'Jianwei Cui', 'Junfeng Yao', 'Bin Wang']",,,,
A Hybrid Bandit Framework for Diversified Recommendation,"['Qinxu Ding', 'Yong Liu', 'Chunyan Miao', 'Fei Cheng', 'Haihong Tang']",https://arxiv.org/abs/2012.13245,"The interactive recommender systems involve users in the recommendation procedure by receiving timely user feedback to update the recommendation policy. Therefore, they are widely used in real application scenarios. Previous interactive recommendation methods primarily focus on learning users’ personalized preferences on the relevance properties of an item set. However, the investigation of users’ personalized preferences on the diversity properties of an item set is usually ignored. To overcome this problem, we propose the Linear Modular Dispersion Bandit (LMDB) framework, which is an online learning setting for optimizing a combination of modular functions and dispersion functions. Specifically, LMDB employs modular functions to model the relevance properties of each item, and dispersion functions to describe the diversity properties of an item set. Moreover, we also develop a learning algorithm, called Linear Modular Dispersion Hybrid (LMDH) to solve the LMDB problem and derive a gap-free bound on its n-step regret. Extensive experiments on real datasets are performed to demonstrate the effectiveness of the proposed LMDB framework in balancing the recommendation accuracy and diversity.",インタラクティブなレコメンダーシステムは、タイムリーなユーザーフィードバックを受信して​​レコメンデーションポリシーを更新することにより、ユーザーをレコメンデーション手順に関与させます。したがって、実際のアプリケーションシナリオで広く使用されています。以前のインタラクティブな推奨方法は、主にアイテムセットの関連性プロパティに関するユーザーのパーソナライズされた好みの学習に焦点を合わせています。ただし、アイテムセットの多様性プロパティに関するユーザーのパーソナライズされた設定の調査は通常無視されます。この問題を克服するために、モジュラー関数と分散関数の組み合わせを最適化するためのオンライン学習設定である線形モジュラー分散バンディット（LMDB）フレームワークを提案します。具体的には、LMDBはモジュラー関数を使用して各アイテムの関連性プロパティをモデル化し、分散関数を使用してアイテムセットの多様性プロパティを記述します。さらに、線形モジュラー分散ハイブリッド（LMDH）と呼ばれる学習アルゴリズムを開発して、LMDBの問題を解決し、nステップの後悔のギャップのない限界を導き出します。推奨の精度と多様性のバランスをとる上で提案されたLMDBフレームワークの有効性を実証するために、実際のデータセットで広範な実験が実行されます。,https://d3i71xaburhd42.cloudfront.net/e8318bcda63a89c1fa186f17b0fab5d0a4fff1cb/6-Figure1-1.png
One-Shot Graph Neural Architecture Search with Dynamic Search Space,"['Yanxi Li', 'Zean Wen', 'Yunhe Wang', 'Chang Xu']",,,,
Deep Mutual Information Maximin for Cross-Modal Clustering,"['Yiqiao Mao', 'Xiaoqiang Yan', 'Qiang Guo', 'Yangdong Ye']",,,,
Composite Adversarial Attacks,"['Xiaofeng Mao', 'Yuefeng Chen', 'Shuhui Wang', 'Hang Su', 'Yuan He', 'Hui Xue']",https://arxiv.org/abs/2012.05434,"Adversarial attack is a technique for deceiving Machine Learning (ML) models, which provides a way to evaluate the adversarial robustness. In practice, attack algorithms are artificially selected and tuned by human experts to break a ML system. However, manual selection of attackers tends to be sub-optimal, leading to a mistakenly assessment of model security. In this paper, a new procedure called Composite Adversarial Attack (CAA) is proposed for automatically searching the best combination of attack algorithms and their hyper-parameters from a candidate pool of \textbf{32 base attackers}. We design a search space where attack policy is represented as an attacking sequence, i.e., the output of the previous attacker is used as the initialization input for successors. Multi-objective NSGA-II genetic algorithm is adopted for finding the strongest attack policy with minimum complexity. The experimental result shows CAA beats 10 top attackers on 11 diverse defenses with less elapsed time (\textbf{6 $\times$ faster than AutoAttack}), and achieves the new state-of-the-art on $l_{\infty}$, $l_{2}$ and unrestricted adversarial attacks.",敵対的攻撃は、機械学習（ML）モデルを欺くための手法であり、敵対的生成ネットワークを評価する方法を提供します。実際には、攻撃アルゴリズムは、MLシステムを破壊するために、人間の専門家によって人為的に選択および調整されています。ただし、攻撃者を手動で選択することは最適ではない傾向があり、モデルのセキュリティを誤って評価することになります。この論文では、32のベースアタッカーの候補プールから攻撃アルゴリズムとそのハイパーパラメータの最適な組み合わせを自動的に検索するために、複合敵対的攻撃（CAA）と呼ばれる新しい手順を提案します。攻撃ポリシーが攻撃シーケンスとして表される検索スペースを設計します。つまり、前の攻撃者の出力が後続の初期化入力として使用されます。多目的NSGA-II遺伝的アルゴリズムは、最小限の複雑さで最強の攻撃ポリシーを見つけるために採用されています。実験結果は、CAAが11の多様な防御で10人の上位の攻撃者をより短い経過時間で打ち負かし（6 FASTER THAN AUTOATTACK）、l（）、l2、および無制限の敵対攻撃で新しい最先端を達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/2afc07df53deb068d5daf538e84d447224e37a7d/1-Figure1-1.png
VMLoc: Variational Fusion for Learning-Based Multimodal Camera Localization,"['Kaichen Zhou', 'Changhao Chen', 'Bing Wang', 'Muhamad Risqi U. Saputra', 'Niki Trigoni', 'Andrew Markham']",https://arxiv.org/abs/2003.07289,"Recent learning-based approaches have achieved impressive results in the field of single-shot camera localization. However, how best to fuse multiple modalities (e.g., image and depth) and to deal with degraded or missing input are less well studied. In particular, we note that previous approaches towards deep fusion do not perform significantly better than models employing a single modality. We conjecture that this is because of the naive approaches to feature space fusion through summation or concatenation which do not take into account the different strengths of each modality. To address this, we propose an end-to-end framework, termed VMLoc, to fuse different sensor inputs into a common latent space through a variational Product-of-Experts (PoE) followed by attention-based fusion. Unlike previous multimodal variational works directly adapting the objective function of vanilla variational auto-encoder, we show how camera localization can be accurately estimated through an unbiased objective function based on importance weighting. Our model is extensively evaluated on RGB-D datasets and the results prove the efficacy of our model. The source code is available at https://github.com/Zalex97/VMLoc.",最近の学習ベースのアプローチは、シングルショットカメラのローカリゼーションの分野で印象的な結果を達成しています。ただし、複数のモダリティ（画像や深度など）を融合し、入力の低下や欠落に対処するための最善の方法は、あまりよく研究されていません。特に、ディープフュージョンに向けた以前のアプローチは、単一のモダリティを採用したモデルよりも大幅に優れたパフォーマンスを発揮しないことに注意してください。これは、各モダリティのさまざまな長所を考慮に入れていない、合計または連結による特徴空間融合への素朴なアプローチによるものと推測されます。これに対処するために、VMLocと呼ばれるエンドツーエンドのフレームワークを提案し、さまざまなセンサー入力を、さまざまな専門家製品（PoE）とそれに続く注意ベースの融合によって共通の潜在空間に融合します。バニラ変分オートエンコーダーの目的関数を直接適応させる以前のマルチモーダル変分法とは異なり、重要度の重み付けに基づく偏りのない目的関数を使用して、カメラのローカリゼーションを正確に推定する方法を示します。私たちのモデルはRGB-Dデータセットで広範囲に評価されており、その結果は私たちのモデルの有効性を証明しています。ソースコードはhttps://github.com/Zalex97/VMLocで入手できます。,
Decoupled and Memory-Reinforced Networks: Towards Effective Feature Learning for One-Step Person Search,"['Chuchu Han', 'Zhedong Zheng', 'Changxin Gao', 'Nong Sang', 'Yi Yang']",,,,
Equivalent Causal Models,['Sander Beckers'],https://arxiv.org/abs/2012.05603,"The aim of this paper is to offer the first systematic exploration and definition of equivalent causal models in the context where both models are not made up of the same variables. The idea is that two models are equivalent when they agree on all ""essential"" causal information that can be expressed using their common variables. I do so by focussing on the two main features of causal models, namely their structural relations and their functional relations. In particular, I define several relations of causal ancestry and several relations of causal sufficiency, and require that the most general of these relations are preserved across equivalent models.",このホワイトペーパーの目的は、両方のモデルが同じ変数で構成されていない状況で、同等の因果モデルの最初の体系的な調査と定義を提供することです。 2つのモデルは、共通の変数を使用して表現できるすべての「本質的な」因果情報に同意する場合、同等であるという考え方です。私は因果モデルの2つの主要な特徴、すなわちそれらの構造的関係とそれらの機能的関係に焦点を当てることによってそうします。特に、因果関係のいくつかの関係と因果関係の十分性のいくつかの関係を定義し、これらの関係の最も一般的なものが同等のモデル間で保持されることを要求します。,
RTS3D: Real-Time Stereo 3D Detection From 4D Feature-Consistency Embedding Space for Autonomous Driving,"['Peixuan Li', 'Shun Su', 'Huaici Zhao']",,,,
The Counterfactual NESS Definition of Causation,['Sander Beckers'],,,,
Looking Wider for Better Adaptive Representation in Few-Shot Learning,"['Jiabao Zhao', 'Yifan Yang', 'Xin Lin', 'Jing Yang', 'Liang He']",,,,
DIRV: Dense Interaction Region Voting for End-to-End Human-Object Interaction Detection,"['Hao-Shu Fang', 'Yichen Xie', 'Dian Shao', 'Cewu Lu']",,,,
Fooling Thermal Infrared Pedestrian Detector in Real World Using Small Bulbs,"['Xiaopei Zhu', 'Xiao Li', 'Jianmin Li', 'Xiaolin Hu', 'Zheyao Wang']",,,,
Learning from the Best: Rationalizing Predictions by Adversarial information Calibration,"['Lei Sha', 'Oana-Maria Camburu', 'Thomas Lukasiewicz']",,,,
Dynamic Position-Aware Network for Fine-Grained Image Recognition,"['Shijie Wang', 'Haojie Li', 'Zhihui Wang', 'Wanli Ouyang']",,,,
Few-Shot Class-Incremental Learning via Relation Knowledge Distillation,"['Songlin Dong', 'Xiaopeng Hong', 'Xiaoyu Tao', 'Xinyuan Chang', 'Xing Wei', 'Yihong Gong']",,,,
Multi-Type Disentanglement without Adversarial Training,"['Lei Sha', 'Thomas Lukasiewicz']",,,,
Budget Feasible Mechanisms over Graphs,"['Xiang Liu', 'Weiwei Wu', 'Minming Li', 'Wanyuan Wang']",,,,
STL-SGD: Speeding Up Local SGD with Stagewise Communication Period,"['Shuheng Shen', 'Yifei Cheng', 'Jingchang Liu', 'Linli Xu']",,,,
Ethically Compliant Sequential Decision Making,"['Justin Svegliato', 'Samer Nashed', 'Shlomo Zilberstein']",,,,
Amnesiac Machine Learning,"['Laura Graves', 'Vineel Nagisetty', 'Vijay Ganesh']",,,,
Bike-Repositioning Using Volunteers: Crowd Sourcing with Choice Restriction,"['Jinjia Huang', 'Mabel C. Chou', 'Chung Piaw Teo']",,,,
Inference Fusion with Associative Semantics for Unseen Object Detection,"['Yanan Li', 'Pengyang Li', 'Han Cui', 'Donghui Wang']",,,,
SSPC-Net: Semi-Supervised Semantic 3D Point Cloud Segmentation Network,"['Mingmei Cheng', 'Le Hui', 'Jin Xie', 'Jian Yang']",,,,
Stabilizing Q Learning via Soft Mellowmax Operator,"['Yaozhong Gan', 'Zhe Zhang', 'Xiaoyang Tan']",https://arxiv.org/abs/2012.09456,"Learning complicated value functions in high dimensional state space by function approximation is a challenging task, partially due to that the max-operator used in temporal difference updates can theoretically cause instability for most linear or non-linear approximation schemes. Mellowmax is a recently proposed differentiable and non-expansion softmax operator that allows a convergent behavior in learning and planning. Unfortunately, the performance bound for the fixed point it converges to remains unclear, and in practice, its parameter is sensitive to various domains and has to be tuned case by case. Finally, the Mellowmax operator may suffer from oversmoothing as it ignores the probability being taken for each action when aggregating them. In this paper, we address all the above issues with an enhanced Mellowmax operator, named SM2 (Soft Mellowmax). Particularly, the proposed operator is reliable, easy to implement, and has provable performance guarantee, while preserving all the advantages of Mellowmax. Furthermore, we show that our SM2 operator can be applied to the challenging multi-agent reinforcement learning scenarios, leading to stable value function approximation and state of the art performance.",関数近似によって高次元状態空間で複雑な値関数を学習することは困難な作業です。これは、時間差の更新に使用される最大演算子が、ほとんどの線形または非線形近似スキームで理論的に不安定になる可能性があるためです。 Mellowmaxは、最近提案された微分可能で非拡張のソフトマックス演算子であり、学習と計画の収束動作を可能にします。残念ながら、収束する固定小数点のパフォーマンス限界は不明なままであり、実際には、そのパラメーターはさまざまなドメインに敏感であり、ケースバイケースで調整する必要があります。最後に、Mellowmaxオペレーターは、アクションを集約するときに各アクションに対して実行される確率を無視するため、過度の平滑化に悩まされる可能性があります。このホワイトペーパーでは、SM2（Soft Mellowmax）という名前の拡張されたMellowmaxオペレーターを使用して、上記のすべての問題に対処します。特に、提案されたオペレーターは、Mellowmaxのすべての利点を維持しながら、信頼性が高く、実装が容易で、実証可能なパフォーマンス保証があります。さらに、SM2演算子を挑戦的なマルチエージェント強化学習シナリオに適用して、安定した値関数近似と最先端のパフォーマンスを実現できることを示します。,https://d3i71xaburhd42.cloudfront.net/bf591da059e692cb5c2f1d6130e22fcb2fde6f54/5-Figure1-1.png
Physics-Informed Deep Learning for Traffic State Estimation: A Hybrid Paradigm Informed by Second-Order Traffic Models,"['Rongye Shi', 'Zhaobin Mo', 'Xuan Di']",,,,
Harmonized Dense Knowledge Distillation Training for Multi-Exit Architectures,"['Xinglu Wang', 'Yingming Li']",,,,
Image Captioning with Context-Aware Auxiliary Guidance,"['Zeliang Song', 'Xiaofei Zhou', 'Zhendong Mao', 'Jianlong Tan']",https://arxiv.org/abs/2012.05545,"Image captioning is a challenging computer vision task, which aims to generate a natural language description of an image. Most recent researches follow the encoder-decoder framework which depends heavily on the previous generated words for the current prediction. Such methods can not effectively take advantage of the future predicted information to learn complete semantics. In this paper, we propose Context-Aware Auxiliary Guidance (CAAG) mechanism that can guide the captioning model to perceive global contexts. Upon the captioning model, CAAG performs semantic attention that selectively concentrates on useful information of the global predictions to reproduce the current generation. To validate the adaptability of the method, we apply CAAG to three popular captioners and our proposal achieves competitive performance on the challenging Microsoft COCO image captioning benchmark, e.g. 132.2 CIDEr-D score on Karpathy split and 130.7 CIDEr-D (c40) score on official online evaluation server.",画像のキャプションは、画像の自然言語による説明を生成することを目的とした、やりがいのあるコンピュータビジョンタスクです。最近の研究は、現在の予測のために以前に生成された単語に大きく依存するエンコーダー-デコーダーフレームワークに従います。このような方法では、将来の予測情報を効果的に利用して完全なセマンティクスを学習することはできません。この論文では、グローバルコンテキストを認識するためにキャプションモデルを導くことができるコンテキストアウェア補助ガイダンス（CAAG）メカニズムを提案します。キャプションモデルに基づいて、CAAGは、現在の世代を再現するためにグローバル予測の有用な情報に選択的に集中するセマンティックアテンションを実行します。メソッドの適応性を検証するために、3つの人気のあるキャプション作成者にCAAGを適用し、提案は、挑戦的なMicrosoftCOCO画像キャプションベンチマークで競争力のあるパフォーマンスを達成します。オンライン評価サーバー。,https://d3i71xaburhd42.cloudfront.net/6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3/1-Figure1-1.png
PREMERE: Meta-Reweighting via Self-Ensembling for Point-of-Interest Recommendation,"['Minseok Kim', 'Hwanjun Song', 'Doyoung Kim', 'Kijung Shin', 'Jae-Gil Lee']",,,,
GSNet: Learning Spatial-Temporal Correlations from Geographical and Semantic Aspects for Traffic Accident Risk Forecasting,"['Beibei Wang', 'Youfang Lin', 'Shengnan Guo', 'Huaiyu Wan']",,,,
Activity Image-to-Video Retrieval by Disentangling Appearance and Motion,"['Liu Liu', 'Jiangtong Li', 'Li Niu', 'Ruicong Xu', 'Liqing Zhang']",,,,
Exploiting Diverse Characteristics and Adversarial Ambivalence for Domain Adaptive Segmentation,"['Bowen Cai', 'Huan Fu', 'Rongfei Jia', 'Binqiang Zhao', 'Hua Li', 'Yinghui Xu']",https://arxiv.org/abs/2012.05608,"Adapting semantic segmentation models to new domains is an important but challenging problem. Recently enlightening progress has been made, but the performance of existing methods are unsatisfactory on real datasets where the new target domain comprises of heterogeneous sub-domains (e.g., diverse weather characteristics). We point out that carefully reasoning about the multiple modalities in the target domain can improve the robustness of adaptation models. To this end, we propose a condition-guided adaptation framework that is empowered by a special attentive progressive adversarial training (APAT) mechanism and a novel self-training policy. The APAT strategy progressively performs condition-specific alignment and attentive global feature matching. The new self-training scheme exploits the adversarial ambivalences of easy and hard adaptation regions and the correlations among target sub-domains effectively. We evaluate our method (DCAA) on various adaptation scenarios where the target images vary in weather conditions. The comparisons against baselines and the state-of-the-art approaches demonstrate the superiority of DCAA over the competitors.",セマンティックセグメンテーションモデルを新しいドメインに適応させることは重要ですが、難しい問題です。最近、啓蒙的な進歩が見られましたが、新しいターゲットドメインが異種のサブドメイン（たとえば、多様な気象特性）で構成されている実際のデータセットでは、既存の方法のパフォーマンスは不十分です。ターゲットドメインの複数のモダリティについて注意深く推論することで、適応モデルの堅牢性を向上させることができることを指摘します。この目的のために、特別な注意深い進歩的な敵対的訓練（APAT）メカニズムと新しい自己訓練政策によって強化された条件誘導適応フレームワークを提案します。 APAT戦略は、条件固有の調整と注意深いグローバル機能マッチングを段階的に実行します。新しいセルフトレーニングスキームは、簡単な適応領域と難しい適応領域の敵対的なアンビバレンスと、ターゲットサブドメイン間の相関関係を効果的に活用します。ターゲット画像が気象条件で変化するさまざまな適応シナリオで、私たちの方法（DCAA）を評価します。ベースラインとの比較および最先端のアプローチは、競合他社に対するDCAAの優位性を示しています。,https://d3i71xaburhd42.cloudfront.net/0b315769840a70e21427ab705947802e1c54a319/2-Figure1-1.png
On the Convergence of Communication-Efficient Local SGD for Federated Learning,"['Hongchang Gao', 'An Xu', 'Heng Huang']",,,,
Universal Trading for Order Execution with Oracle Policy Distillation,"['Yuchen Fang', 'Kan Ren', 'Weiqing Liu', 'Dong Zhou', 'Weinan Zhang', 'Jiang Bian', 'Yong Yu', 'Tie-Yan Liu']",,,,
A Generative Adversarial Framework for Bounding Confounded Causal Effects,"['Yaowei Hu', 'Yongkai Wu', 'Lu Zhang', 'Xintao Wu']",,,,
Binaural Audio-Visual Localization,"['Xinyi Wu', 'Zhenyao Wu', 'Lili Ju', 'Song Wang']",,"Localizing sound sources in a visual scene has many important applications and quite a few traditional or learning-based methods have been proposed for this task. Humans have the ability to roughly localize sound sources within or beyond the range of the vision using their binaural system. However most existing methods use monaural audio, instead of binaural audio, as a modality to help the localization. In addition, prior works usually localize sound sources in the form of object-level bounding boxes in images or videos and evaluate the localization accuracy by examining the overlap between the ground-truth and predicted bounding boxes. This is too rough since a real sound source is often only a part of an object. In this paper, we propose a deep learning method for pixel-level sound source localization by leveraging both binaural recordings and the corresponding videos. Specifically, we design a novel Binaural Audio-Visual Network (BAVNet), which concurrently extracts and integrates features from binaural recordings and videos. We also propose a point-annotation strategy to construct pixel-level ground truth for network training and performance evaluation. Experimental results on Fair-Play and YT-Music datasets demonstrate the effectiveness of the proposed method and show that binaural audio can greatly improve the performance of localizing the sound sources, especially when the quality of the visual information is limited.",視覚シーンでの音源のローカライズには多くの重要なアプリケーションがあり、このタスクにはかなりの数の従来の方法または学習ベースの方法が提案されています。人間は、バイノーラルシステムを使用して、視界内または視界外の音源を大まかに定位することができます。ただし、ほとんどの既存の方法では、ローカリゼーションを支援するモダリティとして、バイノーラルオーディオではなくモノラルオーディオを使用しています。さらに、以前の研究では通常、画像またはビデオ内のオブジェクトレベルのバウンディングボックスの形式で音源をローカライズし、グラウンドトゥルースと予測バウンディングボックスのオーバーラップを調べることによってローカリゼーションの精度を評価します。実際の音源はオブジェクトの一部にすぎないことが多いため、これは粗すぎます。本論文では、バイノーラル録音と対応するビデオの両方を活用することにより、ピクセルレベルの音源定位のための深層学習法を提案します。具体的には、バイノーラル録音とビデオから機能を同時に抽出して統合する、新しいバイノーラルオーディオビジュアルネットワーク（BAVNet）を設計します。また、ネットワークトレーニングとパフォーマンス評価のためのピクセルレベルのグラウンドトゥルースを構築するためのポイントアノテーション戦略を提案します。 Fair-PlayおよびYT-Musicデータセットの実験結果は、提案された方法の有効性を示し、特に視覚情報の品質が制限されている場合に、バイノーラルオーディオが音源のローカライズのパフォーマンスを大幅に向上できることを示しています。,https://d3i71xaburhd42.cloudfront.net/21f36fa303fd70278ff038dc5bbcf2a96c5f018a/1-Figure1-1.png
Point Cloud Semantic Scene Completion from RGB-D Images,"['Shoulong Zhang', 'Shuai Li', 'Aimin Hao', 'Hong Qin']",,,,
Competitive Analysis for Two-Level Ski-Rental Problem,"['Binghan Wu', 'Wei Bao', 'Dong Yuan']",,,,
DecAug: Out-of-Distribution Generalization via Decomposed Feature Representation and Semantic Augmentation,"['Haoyue Bai', 'Rui Sun', 'Lanqing Hong', 'Fengwei Zhou', 'Nanyang Ye', 'Han-Jia Ye', 'Gary Chan', 'Zhenguo Li']",https://arxiv.org/abs/2012.09382,"While deep learning demonstrates its strong ability to handle independent and identically distributed (IID) data, it often suffers from out-of-distribution (OoD) generalization, where the test data come from another distribution (w.r.t. the training one). Designing a general OoD generalization framework to a wide range of applications is challenging, mainly due to possible correlation shift and diversity shift in the real world. Most of the previous approaches can only solve one specific distribution shift, such as shift across domains or the extrapolation of correlation. To address that, we propose DecAug, a novel decomposed feature representation and semantic augmentation approach for OoD generalization. DecAug disentangles the category-related and context-related features. Category-related features contain causal information of the target object, while context-related features describe the attributes, styles, backgrounds, or scenes, causing distribution shifts between training and test data. The decomposition is achieved by orthogonalizing the two gradients (w.r.t. intermediate features) of losses for predicting category and context labels. Furthermore, we perform gradient-based augmentation on context-related features to improve the robustness of the learned representations. Experimental results show that DecAug outperforms other state-of-the-art methods on various OoD datasets, which is among the very few methods that can deal with different types of OoD generalization challenges.",ディープラーニングは、独立した同一分布（IID）データを処理する強力な能力を示していますが、テストデータが別の分布（トレーニングデータ）から取得される、分布外（OoD）の一般化に悩まされることがよくあります。幅広いアプリケーション向けの一般的なOoD一般化フレームワークの設計は、主に現実の世界で起こりうる相関シフトと多様性シフトのために困難です。以前のアプローチのほとんどは、ドメイン間のシフトや相関の外挿など、1つの特定の分布シフトしか解決できません。これに対処するために、OoD一般化のための新しい分解された特徴表現とセマンティック拡張アプローチであるDecAugを提案します。 DecAugは、カテゴリ関連およびコンテキスト関連の機能を解きほぐします。カテゴリ関連の機能にはターゲットオブジェクトの原因情報が含まれ、コンテキスト関連の機能には属性、スタイル、背景、またはシーンが記述されているため、トレーニングデータとテストデータの間で分布が変化します。分解は、カテゴリとコンテキストのラベルを予測するために、損失の2つの勾配（中間の特徴）を直交化することによって実現されます。さらに、学習した表現の堅牢性を向上させるために、コンテキスト関連の機能に対して勾配ベースの拡張を実行します。実験結果は、DecAugがさまざまなOoDデータセットで他の最先端の方法よりも優れていることを示しています。これは、さまざまなタイプのOoD一般化の課題に対処できる数少ない方法の1つです。,https://d3i71xaburhd42.cloudfront.net/6ea5701aa2ec72cdcddea6b1695e8c2192328261/1-Figure1-1.png
Improving Fairness and Privacy in Selection Problems,"['Mohammad Mahdi Khalili', 'Xueru Zhang', 'Mahed Abroshan', 'Somayeh Sojoudi']",https://arxiv.org/abs/2012.03812,"Supervised learning models have been increasingly used for making decisions about individuals in applications such as hiring, lending, and college admission. These models may inherit pre-existing biases from training datasets and discriminate against protected attributes (e.g., race or gender). In addition to unfairness, privacy concerns also arise when the use of models reveals sensitive personal information. Among various privacy notions, differential privacy has become popular in recent years. In this work, we study the possibility of using a differentially private exponential mechanism as a post-processing step to improve both fairness and privacy of supervised learning models. Unlike many existing works, we consider a scenario where a supervised model is used to select a limited number of applicants as the number of available positions is limited. This assumption is well-suited for various scenarios, such as job application and college admission. We use ``equal opportunity'' as the fairness notion and show that the exponential mechanisms can make the decision-making process perfectly fair. Moreover, the experiments on real-world datasets show that the exponential mechanism can improve both privacy and fairness, with a slight decrease in accuracy compared to the model without post-processing.",教師あり学習モデルは、採用、貸付、大学入学などのアプリケーションで個人に関する意思決定を行うためにますます使用されています。これらのモデルは、トレーニングデータセットから既存のバイアスを継承し、保護された属性（人種や性別など）を区別する場合があります。不公平に加えて、モデルの使用により機密性の高い個人情報が明らかになると、プライバシーの懸念も生じます。さまざまなプライバシーの概念の中で、差分プライバシーは近年人気が高まっています。この作業では、教師あり学習モデルの公平性とプライバシーの両方を改善するための後処理ステップとして、差分プライベート指数メカニズムを使用する可能性を研究します。多くの既存の作品とは異なり、利用可能なポジションの数が限られているため、教師ありモデルを使用して限られた数の応募者を選択するシナリオを検討します。この仮定は、求職や大学入学などのさまざまなシナリオに適しています。公平性の概念として機会均等を使用し、指数関数的メカニズムが意思決定プロセスを完全に公平にすることができることを示します。さらに、実際のデータセットでの実験は、指数メカニズムがプライバシーと公平性の両方を改善できることを示していますが、後処理なしのモデルと比較して精度がわずかに低下しています。,https://d3i71xaburhd42.cloudfront.net/90e70eb36e3ad7192ee958efb925b404408b94a4/7-Figure2-1.png
An Efficient Transformer Decoder with Compressed Sub-Layers,"['Yanyang Li', 'Ye Lin', 'Tong Xiao', 'Jingbo Zhu']",https://arxiv.org/abs/2101.00542,"The large attention-based encoder-decoder network (Transformer) has become prevailing recently due to its effectiveness. But the high computation complexity of its decoder raises the inefficiency issue. By examining the mathematic formulation of the decoder, we show that under some mild conditions, the architecture could be simplified by compressing its sub-layers, the basic building block of Transformer, and achieves a higher parallelism. We thereby propose Compressed Attention Network, whose decoder layer consists of only one sub-layer instead of three. Extensive experiments on 14 WMT machine translation tasks show that our model is 1.42× faster with performance on par with a strong baseline. This strong baseline is already 2× faster than the widely used standard baseline without loss in performance.",大規模な注意ベースのエンコーダ-デコーダネットワーク（Transformer）は、その有効性のために最近普及しています。しかし、そのデコーダーの計算の複雑さが高いと、非効率の問題が発生します。デコーダーの数学的定式化を検討することにより、いくつかの穏やかな条件下で、トランスフォーマーの基本的な構成要素であるサブレイヤーを圧縮することでアーキテクチャーを簡素化でき、より高い並列処理を実現できることを示します。これにより、デコーダ層が3つではなく1つのサブ層のみで構成されるCompressed AttentionNetworkを提案します。 14のWMT機械翻訳タスクに関する広範な実験により、モデルは1.42速く、強力なベースラインと同等のパフォーマンスが得られることが示されています。この強力なベースラインは、パフォーマンスを低下させることなく、広く使用されている標準ベースラインよりもすでに2高速です。,https://d3i71xaburhd42.cloudfront.net/4118ab82e4bd40c9c5b700a659e3383c986b6002/2-Figure1-1.png
Learning Task-Distribution Reward Shaping with Meta-Learning,"['Haosheng Zou', 'Tongzheng Ren', 'Dong Yan', 'Hang Su', 'Jun Zhu']",,,,
Consensus Graph Representation Learning for Better Grounded Image Captioning,"['Wenqiao Zhang', 'Haochen Shi', 'Siliang Tang', 'Jun Xiao', 'Qiang Yu', 'Yueting Zhuang']",,,,
Amata: An Annealing Mechanism for Adversarial Training Acceleration,"['Nanyang Ye', 'Qianxiao Li', 'Xiao-Yun Zhou', 'Zhanxing Zhu']",https://arxiv.org/abs/2012.08112,"Despite the empirical success in various domains, it has been revealed that deep neural networks are vulnerable to maliciously perturbed input data that much degrade their performance. This is known as adversarial attacks. To counter adversarial attacks, adversarial training formulated as a form of robust optimization has been demonstrated to be effective. However, conducting adversarial training brings much computational overhead compared with standard training. In order to reduce the computational cost, we propose an annealing mechanism, Amata, to reduce the overhead associated with adversarial training. The proposed Amata is provably convergent, well-motivated from the lens of optimal control theory and can be combined with existing acceleration methods to further enhance performance. It is demonstrated that on standard datasets, Amata can achieve similar or better robustness with around 1/3 to 1/2 the computational time compared with traditional methods. In addition, Amata can be incorporated into other adversarial training acceleration algorithms (e.g. YOPO, Free, Fast, and ATTA), which leads to further reduction in computational time on large-scale problems.",さまざまなドメインでの経験的な成功にもかかわらず、ディープニューラルネットワークは、パフォーマンスを大幅に低下させる悪意を持って摂動された入力データに対して脆弱であることが明らかになっています。これは敵対攻撃として知られています。敵対的攻撃に対抗するために、堅牢な最適化の形式として策定された敵対的トレーニングが効果的であることが実証されています。ただし、敵対的な訓練を実施すると、標準的な訓練と比較して多くの計算オーバーヘッドが発生します。計算コストを削減するために、アニーリングメカニズムであるAmataを提案し、敵対的なトレーニングに関連するオーバーヘッドを削減します。提案されたアマタは、最適制御理論のレンズから十分に動機付けられており、既存の加速方法と組み合わせてパフォーマンスをさらに向上させることができます。標準のデータセットでは、Amataは従来の方法と比較して約1/3から1/2の計算時間で同等以上の堅牢性を達成できることが実証されています。さらに、Amataは、他の敵対的なトレーニング加速アルゴリズム（YOPO、Free、Fast、ATTAなど）に組み込むことができるため、大規模な問題の計算時間をさらに短縮できます。,https://d3i71xaburhd42.cloudfront.net/3bfeba213c3e3bb161a7630ff16c23858c9a34b7/4-Figure1-1.png
PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object Detection,"['Yanan Zhang', 'Di Huang', 'Yunhong Wang']",,,,
A Theoretical Analysis of the Repetition Problem in Text Generation,"['Zihao Fu', 'Wai Lam', 'Anthony Man-Cho So', 'Bei Shi']",,,,
Hierarchical Coherence Modeling for Document Quality Assessment,"['Dongliang Liao', 'Jin Xu', 'Gongfu Li', 'Yiru Wang']",,,,
Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion,"['Jinpeng Wang', 'Yuting Gao', 'Ke Li', 'Jianguo Hu', 'Xinyang Jiang', 'Xiaowei Guo', 'Rongrong Ji', 'Xing Sun']",https://arxiv.org/abs/2009.05757,"One significant factor we expect the video representation learning to capture, especially in contrast with the image representation learning, is the object motion. However, we found that in the current mainstream video datasets, some action categories are highly related with the scene where the action happens, making the model tend to degrade to a solution where only the scene information is encoded. For example, a trained model may predict a video as playing football simply because it sees the field, neglecting that the subject is dancing as a cheerleader on the field. This is against our original intention towards the video representation learning and may bring scene bias on different dataset that can not be ignored. In order to tackle this problem, we propose to decouple the scene and the motion (DSM) with two simple operations, so that the model attention towards the motion information is better paid. Specifically, we construct a positive clip and a negative clip for each video. Compared to the original video, the positive/negative is motion-untouched/broken but scene-broken/untouched by Spatial Local Disturbance and Temporal Local Disturbance. Our objective is to pull the positive closer while pushing the negative farther to the original clip in the latent space. In this way, the impact of the scene is weakened while the temporal sensitivity of the network is further enhanced. We conduct experiments on two tasks with various backbones and different pre-training datasets, and find that our method surpass the SOTA methods with a remarkable 8.1% and 8.8% improvement towards action recognition task on the UCF101 and HMDB51 datasets respectively using the same backbone.",特に画像表現学習とは対照的に、ビデオ表現学習がキャプチャすることを期待する重要な要素の1つは、オブジェクトの動きです。ただし、現在の主流のビデオデータセットでは、一部のアクションカテゴリがアクションが発生するシーンと高度に関連しているため、モデルはシーン情報のみがエンコードされるソリューションに劣化する傾向があることがわかりました。たとえば、訓練を受けたモデルは、対象がフィールドでチアリーダーとして踊っていることを無視して、フィールドを見ているという理由だけでビデオをフットボールをしていると予測する場合があります。これは、ビデオ表現学習に対する当初の意図に反しており、無視できないさまざまなデータセットにシーンバイアスをもたらす可能性があります。この問題に取り組むために、2つの簡単な操作でシーンとモーション（DSM）を分離し、モーション情報に対するモデルの注意をよりよく払うことを提案します。具体的には、ビデオごとにポジティブクリップとネガティブクリップを作成します。元のビデオと比較すると、ポジティブ/ネガティブはモーションに触れられていない/壊れていますが、シーンが壊れている/触れられていないのは、空間的局所障害と時間的局所的障害です。私たちの目的は、潜在空間の元のクリップにネガを押し付けながら、ポジティブを近づけることです。このようにして、シーンの影響が弱まり、ネットワークの時間的感度がさらに向上します。さまざまなバックボーンとさまざまな事前トレーニングデータセットを使用して2つのタスクで実験を行ったところ、私たちの方法は、驚くべき8.1でSOTA方法を上回っています。,https://d3i71xaburhd42.cloudfront.net/7270be2fab5fcdb59c325c0fbc8370351956aa22/1-Figure1-1.png
Preserving Condorcet Winners under Strategic Manipulation,"['Sirin Botan', 'Ulle Endriss']",,"Condorcet extensions have long held a prominent place in social choice theory. A Condorcet extension will return the Condorcet winner as the unique winner whenever such an alternative exists. However, the definition of a Condorcet extension does not take into account possible manipulation by the voters. A profile where all agents vote truthfully may have a Condorcet winner, but this alternative may not end up in the set of winners if agents are acting strategically. Focusing on the class of tournament solutions, we show that many natural social choice functions in this class, such as the well-known Copeland and Slater rules, cannot guarantee the preservation of Condorcet winners when agents behave strategically. Our main result in this respect is an impossibility theorem that establishes that no tournament solution satisfying a very weak decisiveness requirement can provide such a guarantee. On the bright side, we identify several indecisive but otherwise attractive tournament solutions that do guarantee the preservation of Condorcet winners under strategic manipulation.",コンドルセ拡張は、社会選択理論において長い間重要な位置を占めてきました。コンドルセ拡張機能は、そのような代替案が存在する場合は常に、コンドルセ勝者を一意の勝者として返します。ただし、コンドルセ拡張の定義では、有権者による操作の可能性は考慮されていません。すべてのエージェントが正直に投票するプロファイルにはコンドルセの勝者がいる可能性がありますが、エージェントが戦略的に行動している場合、この代替案は勝者のセットに含まれない可能性があります。トーナメントソリューションのクラスに焦点を当てると、よく知られているコープランドルールやスレータールールなど、このクラスの多くの自然な社会的選択関数は、エージェントが戦略的に行動するときにコンドルセ勝者の維持を保証できないことを示します。この点での私たちの主な結果は、非常に弱い決定性要件を満たすトーナメントソリューションはそのような保証を提供できないことを確立する不可能性定理です。明るい面として、戦略的な操作の下でコンドルセの勝者を維持することを保証する、決定的ではないが魅力的なトーナメントソリューションをいくつか特定します。,https://d3i71xaburhd42.cloudfront.net/efd278ed3ecea58aa5f35bddcf0d55296d77d545/5-Figure1-1.png
Multinomial Logit Contextual Bandits: Provable Optimality and Practicality,"['Min-hwan Oh', 'Garud Iyengar']",,,,
Visual Comfort Aware-Reinforcement Learning for Depth Adjustment of Stereoscopic 3D Images,"['Hak Gu Kim', 'Minho Park', 'Sangmin Lee', 'Seongyeop Kim', 'Yong Man Ro']",,,,
Safe Search for Stackelberg Equilibria in Extensive-Form Games,"['Chun Kai Ling', 'Noam Brown']",https://arxiv.org/abs/2102.01775,"Stackelberg equilibrium is a solution concept in two-player games where the leader has commitment rights over the follower. In recent years, it has become a cornerstone of many security applications, including airport patrolling and wildlife poaching prevention. Even though many of these settings are sequential in nature, existing techniques pre-compute the entire solution ahead of time. In this paper, we present a theoretically sound and empirically effective way to apply search, which leverages extra online computation to improve a solution, to the computation of Stackelberg equilibria in general-sum games. Instead of the leader attempting to solve the full game upfront, an approximate “blueprint” solution is first computed offline and is then improved online for the particular subgames encountered in actual play. We prove that our search technique is guaranteed to perform no worse than the pre-computed blueprint strategy, and empirically demonstrate that it enables approximately solving significantly larger games compared to purely offline methods. We also show that our search operation may be cast as a smaller Stackelberg problem, making our method complementary to existing algorithms based on strategy generation.",Stackelberg平衡は、リーダーがフォロワーに対するコミットメント権を持っている2人用ゲームのソリューションコンセプトです。近年、空港のパトロールや野生生物の密猟防止など、多くのセキュリティアプリケーションの基礎となっています。これらの設定の多くは本質的にシーケンシャルですが、既存の手法ではソリューション全体を事前に事前に計算します。この論文では、追加のオンライン計算を活用してソリューションを改善する検索を、一般和ゲームのStackelberg平衡の計算に適用するための、理論的に健全で経験的に効果的な方法を示します。リーダーがゲーム全体を前もって解決しようとする代わりに、おおよその青写真ソリューションが最初にオフラインで計算され、次に実際のプレイで遭遇する特定のサブゲームのためにオンラインで改善されます。私たちの検索手法は、事前に計算された青写真戦略よりも悪くないことが保証されていることを証明し、純粋にオフラインの方法と比較して大幅に大きなゲームをほぼ解決できることを経験的に示しています。また、検索操作がより小さなStackelberg問題としてキャストされ、戦略生成に基づく既存のアルゴリズムを補完する方法になる可能性があることも示します。,https://d3i71xaburhd42.cloudfront.net/0c3c71c63153063afb08ecb67e9682b1b13e83fa/3-Figure1-1.png
Dual Distribution Alignment Network for Generalizable Person Re-Identification,"['Peixian Chen', 'Pingyang Dai', 'Jianzhuang Liu', 'Feng Zheng', 'Mingliang Xu', 'Qi Tian', 'Rongrong Ji']",https://arxiv.org/abs/2007.13249,"Domain generalization (DG) serves as a promising solution to handle person Re-Identification (Re-ID), which trains the model using labels from the source domain alone, and then directly adopts the trained model to the target domain without model updating. However, existing DG approaches are usually disturbed by serious domain variations due to significant dataset variations. Subsequently, DG highly relies on designing domain-invariant features, which is however not well exploited, since most existing approaches directly mix multiple datasets to train DG based models without considering the local dataset similarities, i.e., examples that are very similar but from different domains. In this paper, we present a Dual Distribution Alignment Network (DDAN), which handles this challenge by mapping images into a domain-invariant feature space by selectively aligning distributions of multiple source domains. Such an alignment is conducted by dual-level constraints, i.e., the domain-wise adversarial feature learning and the identity-wise similarity enhancement. We evaluate our DDAN on a large-scale Domain Generalization Re-ID (DG Re-ID) benchmark. Quantitative results demonstrate that the proposed DDAN can well align the distributions of various source domains, and significantly outperforms all existing domain generalization approaches.",ドメイン一般化（DG）は、個人の再識別（Re-ID）を処理するための有望なソリューションとして機能します。これは、ソースドメインからのラベルのみを使用してモデルをトレーニングし、モデルを更新せずに、トレーニングされたモデルをターゲットドメインに直接採用します。ただし、既存のDGアプローチは通常、データセットの大幅な変動による深刻なドメインの変動によって妨げられます。その後、DGはドメイン不変機能の設計に大きく依存しますが、ほとんどの既存のアプローチは、ローカルデータセットの類似性、つまり非常に類似しているが異なるドメインからの例を考慮せずに、複数のデータセットを直接混合してDGベースのモデルをトレーニングするため、十分に活用されていません。 。この論文では、複数のソースドメインの分布を選択的に整列させることにより、画像をドメイン不変の特徴空間にマッピングすることにより、この課題を処理するDual Distribution Alignment Network（DDAN）を紹介します。このような調整は、デュアルレベルの制約、つまり、ドメインごとの敵対的特徴学習とアイデンティティごとの類似性の強化によって実行されます。大規模なドメイン一般化Re-ID（DG Re-ID）ベンチマークでDDANを評価します。定量的な結果は、提案されたDDANがさまざまなソースドメインの分布を適切に調整でき、既存のすべてのドメイン一般化アプローチを大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/ec0f586a489a5c6ce83e8f39487b541d1bb8b19e/2-Figure1-1.png
Uncovering Latent Biases in Text: Method and Application to Peer Review,"['Emaad Manzoor', 'Nihar Shah']",https://arxiv.org/abs/2010.15300,"Quantifying systematic disparities in numerical quantities such as employment rates and wages between population subgroups provides compelling evidence for the existence of societal biases. However, biases in the text written for members of different subgroups (such as in recommendation letters for male and non-male candidates), though widely reported anecdotally, remain challenging to quantify. In this work, we introduce a novel framework to quantify bias in text caused by the visibility of subgroup membership indicators. We develop a nonparametric estimation and inference procedure to estimate this bias. We then formalize an identification strategy to causally link the estimated bias to the visibility of subgroup membership indicators, provided observations from time periods both before and after an identity-hiding policy change. We identify an application wherein ""ground truth"" bias can be inferred to evaluate our framework, instead of relying on synthetic or secondary data. Specifically, we apply our framework to quantify biases in the text of peer reviews from a reputed machine learning conference before and after the conference adopted a double-blind reviewing policy. We show evidence of biases in the review ratings that serves as ""ground truth"", and show that our proposed framework accurately detects these biases from the review text without having access to the review ratings.",人口サブグループ間の雇用率や賃金などの数値の体系的な格差を定量化することは、社会的バイアスの存在についての説得力のある証拠を提供します。ただし、さまざまなサブグループのメンバー向けに書かれたテキストのバイアス（男性および男性以外の候補者の推薦状など）は、逸話的に広く報告されていますが、定量化するのは依然として困難です。この作業では、サブグループメンバーシップインジケーターの可視性によって引き起こされるテキストのバイアスを定量化するための新しいフレームワークを紹介します。このバイアスを推定するために、ノンパラメトリック推定および推論手順を開発します。次に、識別戦略を形式化して、推定バイアスをサブグループメンバーシップ指標の可視性に因果的にリンクし、ID隠蔽ポリシーの変更の前後の期間からの観察結果を提供します。合成データや二次データに依存する代わりに、フレームワークを評価するために「グラウンドトゥルース」バイアスを推測できるアプリケーションを特定します。具体的には、フレームワークを適用して、会議が二重盲検レビューポリシーを採用する前後の、評判の高い機械学習会議からのピアレビューのテキストのバイアスを定量化します。 「グラウンドトゥルース」として機能するレビュー評価のバイアスの証拠を示し、提案されたフレームワークがレビュー評価にアクセスすることなくレビューテキストからこれらのバイアスを正確に検出することを示します。,https://d3i71xaburhd42.cloudfront.net/cc19de8d0782917098029ed20261cbe0b0c62bf5/7-Figure1-1.png
Towards a Better Understanding of VR Sickness: Physical Symptom Prediction for VR Contents,"['Hak Gu Kim', 'Sangmin Lee', 'Seongyeop Kim', 'Heoun-taek Lim', 'Yong Man Ro']",,,,
MIMOSA: Multi-Constraint Molecule Sampling for Molecule Optimization,"['Tianfan Fu', 'Cao Xiao', 'Xinhao Li', 'Lucas Glass', 'Jimeng Sun']",https://arxiv.org/abs/2010.02318,"Molecule optimization is a fundamental task for accelerating drug discovery, with the goal of generating new valid molecules that maximize multiple drug properties while maintaining similarity to the input molecule. Existing generative models and reinforcement learning approaches made initial success, but still face difficulties in simultaneously optimizing multiple drug properties. To address such challenges, we propose the MultI-constraint MOlecule SAmpling (MIMOSA) approach, a sampling framework to use input molecule as an initial guess and sample molecules from the target distribution. MIMOSA first pretrains two property agnostic graph neural networks (GNNs) for molecule topology and substructure-type prediction, where a substructure can be either atom or single ring. For each iteration, MIMOSA uses the GNNs' prediction and employs three basic substructure operations (add, replace, delete) to generate new molecules and associated weights. The weights can encode multiple constraints including similarity and drug property constraints, upon which we select promising molecules for next iteration. MIMOSA enables flexible encoding of multiple property- and similarity-constraints and can efficiently generate new molecules that satisfy various property constraints and achieved up to 49.6% relative improvement over the best baseline in terms of success rate.",分子の最適化は、入力分子との類似性を維持しながら複数の薬物特性を最大化する新しい有効な分子を生成することを目的として、創薬を加速するための基本的なタスクです。既存の生成モデルと強化学習アプローチは最初の成功を収めましたが、それでも複数の薬物特性を同時に最適化することは困難です。このような課題に対処するために、MultI-constraint MOlecule SAmpling（MIMOSA）アプローチを提案します。これは、入力分子を初期推定として使用し、ターゲット分布から分子をサンプリングするサンプリングフレームワークです。 MIMOSAはまず、分子トポロジーと下部構造タイプの予測のために、2つのプロパティにとらわれないグラフニューラルネットワーク（GNN）を事前トレーニングします。ここで、下部構造は原子または単一リングのいずれかです。 MIMOSAは、反復ごとにGNN予測を使用し、3つの基本的な下部構造操作（追加、置換、削除）を使用して、新しい分子と関連する重みを生成します。重みは、類似性や薬物特性の制約を含む複数の制約をエンコードできます。その上で、次の反復のために有望な分子を選択します。 MIMOSAは、複数のプロパティおよび類似性制約の柔軟なエンコードを可能にし、さまざまなプロパティ制約を満たし、最大49.6を達成する新しい分子を効率的に生成できます。,https://d3i71xaburhd42.cloudfront.net/10ddb6d742f6b736485be02925ecbd788a33a423/6-Figure1-1.png
"What's the Best Place for an AI Conference, Vancouver or _______: Why Completing Comparative Questions Is Difficult","['Avishai Zagoury', 'Einat Minkov', 'Idan Szpektor', 'William W Cohen']",,,,
Convergence Analysis of No-Regret Bidding Algorithms in Repeated Auctions,"['Zhe Feng', 'Guru Guruganesh', 'Christopher Liaw', 'Aranyak Mehta', 'Abhishek Sethi']",https://arxiv.org/abs/2009.06136,"The connection between games and no-regret algorithms has been widely studied in the literature. A fundamental result is that when all players play no-regret strategies, this produces a sequence of actions whose time-average is a coarse-correlated equilibrium of the game. However, much less is known about equilibrium selection in the case that multiple equilibria exist. 
In this work, we study the convergence of no-regret bidding algorithms in auctions. Besides being of theoretical interest, bidding dynamics in auctions is an important question from a practical viewpoint as well. We study repeated game between bidders in which a single item is sold at each time step and the bidder's value is drawn from an unknown distribution. We show that if the bidders use any mean-based learning rule then the bidders converge with high probability to the truthful pure Nash Equilibrium in a second price auction, in VCG auction in the multi-slot setting and to the Bayesian Nash equilibrium in a first price auction. We note mean-based algorithms cover a wide variety of known no-regret algorithms such as Exp3, UCB, $\epsilon$-Greedy etc. Also, we analyze the convergence of the individual iterates produced by such learning algorithms, as opposed to the time-average of the sequence. Our experiments corroborate our theoretical findings and also find a similar convergence when we use other strategies such as Deep Q-Learning.",ゲームと後悔のないアルゴリズムの関係は、文献で広く研究されています。基本的な結果は、すべてのプレーヤーが後悔のない戦略を実行すると、時間平均がゲームの粗い相関均衡である一連のアクションが生成されることです。ただし、複数の平衡が存在する場合の平衡選択についてはほとんど知られていません。この作業では、オークションにおける後悔のない入札アルゴリズムの収束を研究します。理論的に興味深いだけでなく、オークションでの入札のダイナミクスは、実用的な観点からも重要な問題です。各タイムステップで単一のアイテムが販売され、入札者の値が未知の分布から引き出される、入札者間の繰り返しゲームを調査します。入札者が平均ベースの学習ルールを使用する場合、入札者は2回目の価格オークションでの真実の純粋なナッシュ均衡、マルチスロット設定でのVCGオークション、および最初のベイジアンナッシュ均衡に高い確率で収束することを示します。価格オークション。平均ベースのアルゴリズムは、Exp3、UCB、-Greedyなど、さまざまな既知の後悔のないアルゴリズムをカバーしていることに注意してください。また、の時間平均とは対照的に、このような学習アルゴリズムによって生成された個々の反復の収束を分析します。シーケンス。私たちの実験は私たちの理論的発見を裏付けており、DeepQ-Learningなどの他の戦略を使用した場合にも同様の収束が見られます。,https://d3i71xaburhd42.cloudfront.net/5a3e6c92d902ea33ea73373e9b900fabc03f1452/10-Figure1-1.png
Interpretable NLG for Task-Oriented Dialogue Systems with Heterogeneous Rendering Machines,"['Yangming Li', 'Kaisheng Yao']",https://arxiv.org/abs/2012.14645,"End-to-end neural networks have achieved promising performances in natural language generation (NLG). However, they are treated as black boxes and lack interpretability. To address this problem, we propose a novel framework, heterogeneous rendering machines (HRM), that interprets how neural generators render an input dialogue act (DA) into an utterance. HRM consists of a renderer set and a mode switcher. The renderer set contains multiple decoders that vary in both structure and functionality. For every generation step, the mode switcher selects an appropriate decoder from the renderer set to generate an item (a word or a phrase). To verify the effectiveness of our method, we have conducted extensive experiments on 5 benchmark datasets. In terms of automatic metrics (e.g., BLEU), our model is competitive with the current state-of-the-art method. The qualitative analysis shows that our model can interpret the rendering process of neural generators well. Human evaluation also confirms the interpretability of our proposed approach.",エンドツーエンドのニューラルネットワークは、自然言語生成（NLG）で有望なパフォーマンスを実現しています。ただし、それらはブラックボックスとして扱われ、解釈可能性に欠けます。この問題に対処するために、ニューラルジェネレータが入力ダイアログ動作（DA）を発話にレンダリングする方法を解釈する新しいフレームワークである異種レンダリングマシン（HRM）を提案します。 HRMは、レンダラーセットとモードスイッチャーで構成されています。レンダラーセットには、構造と機能の両方が異なる複数のデコーダーが含まれています。モードスイッチャーは、生成ステップごとに、レンダラーセットから適切なデコーダーを選択して、アイテム（単語またはフレーズ）を生成します。私たちの方法の有効性を検証するために、5つのベンチマークデータセットで広範な実験を実施しました。自動メトリック（BLEUなど）に関して、私たちのモデルは現在の最先端の方法と競合しています。定性分析は、私たちのモデルが神経発生器のレンダリングプロセスをうまく解釈できることを示しています。人間による評価も、提案されたアプローチの解釈可能性を確認します。,https://d3i71xaburhd42.cloudfront.net/618fee552cfad4d72b296856f16bdedb61e5e812/1-Figure1-1.png
"Fairness, Semi-Supervised Learning, and More: A General Framework for Clustering with Stochastic Pairwise Constraints","['Brian Brubach', 'Darshan Chakrabarti', 'John P Dickerson', 'Aravind Srinivasan', 'Leonidas Tsepenekas']",,,,
Integrating Static and Dynamic Data for Improved Prediction of Cognitive Declines Using Augmented Genotype-Phenotype Representations,"['Hoon Seo', 'Lodewijk Brand', 'Hua Wang', 'Feiping Nie']",,,,
Temporal Latent Autoencoder: A Method for Probabilistic Multivariate Time Series Forecasting,"['Nam Nguyen', 'Brian Quanz']",https://arxiv.org/abs/2101.10460,"Probabilistic forecasting of high dimensional multivariate time series is a notoriously challenging task, both in terms of computational burden and distribution modeling. Most previous work either makes simple distribution assumptions or abandons modeling cross-series correlations. A promising line of work exploits scalable matrix factorization for latent-space forecasting, but is limited to linear embeddings, unable to model distributions, and not trainable end-to-end when using deep learning forecasting. We introduce a novel temporal latent auto-encoder method which enables nonlinear factorization of multivariate time series, learned end-to-end with a temporal deep learning latent space forecast model. By imposing a probabilistic latent space model, complex distributions of the input series are modeled via the decoder. Extensive experiments demonstrate that our model achieves state-of-theart performance on many popular multivariate datasets, with gains sometimes as high as 50% for several standard metrics.",高次元の多変量時系列の確率的予測は、計算負荷と分布モデリングの両方の観点から、悪名高い挑戦的なタスクです。以前のほとんどの作業では、単純な分布の仮定を行うか、系列間の相関のモデリングを放棄しています。有望な一連の作業は、潜在空間予測にスケーラブルな行列因数分解を利用しますが、線形埋め込みに限定され、分布をモデル化できず、深層学習予測を使用する場合はエンドツーエンドでトレーニングできません。多変量時系列の非線形因数分解を可能にする新しい時間的潜在オートエンコーダ法を紹介し、時間的深層学習潜在空間予測モデルでエンドツーエンドで学習します。確率的潜在空間モデルを課すことにより、入力系列の複雑な分布がデコーダーを介してモデル化されます。広範な実験により、私たちのモデルが多くの人気のある多変量データセットで最先端のパフォーマンスを達成し、時には50ものゲインが得られることが実証されています,https://d3i71xaburhd42.cloudfront.net/da90d057c5a4379ae3b27f3e9d2bb7b37288a654/5-Figure1-1.png
STELAR: Spatio-Temporal Tensor Factorization with Latent Epidemiological Regularization,"['Nikos Kargas', 'Cheng Qian', 'Nicholas Sidiropoulos', 'Cao Xiao', 'Lucas Glass', 'Jimeng Sun']",,,,
MolGrow: A Graph Normalizing Flow for Hierarchical Molecular Generation,"['Maksim Kuznetsov', 'Daniil Polykovskiy']",,,,
The Tractability of SHAP-Score-Based Explanations for Classification over Deterministic and Decomposable Boolean Circuits,"['Marcelo Arenas', 'Pablo Barceló', 'Leopoldo Bertossi', 'Mikaël Monet']",,,,
Constructing a Fair Classifier with Generated Fair Data,"['Taeuk Jang', 'Feng Zheng', 'Xiaoqian Wang']",,,,
Hypothesis Disparity Regularized Mutual information Maximization,"['Qicheng Lao', 'Xiang Jiang', 'Mohammad Havaei']",https://arxiv.org/abs/2012.08072,"We propose a hypothesis disparity regularized mutual information maximization~(HDMI) approach to tackle unsupervised hypothesis transfer -- as an effort towards unifying hypothesis transfer learning (HTL) and unsupervised domain adaptation (UDA) -- where the knowledge from a source domain is transferred solely through hypotheses and adapted to the target domain in an unsupervised manner. In contrast to the prevalent HTL and UDA approaches that typically use a single hypothesis, HDMI employs multiple hypotheses to leverage the underlying distributions of the source and target hypotheses. To better utilize the crucial relationship among different hypotheses -- as opposed to unconstrained optimization of each hypothesis independently -- while adapting to the unlabeled target domain through mutual information maximization, HDMI incorporates a hypothesis disparity regularization that coordinates the target hypotheses jointly learn better target representations while preserving more transferable source knowledge with better-calibrated prediction uncertainty. HDMI achieves state-of-the-art adaptation performance on benchmark datasets for UDA in the context of HTL, without the need to access the source data during the adaptation.",ソースドメインからの知識が仮説のみを介して転送され、適応される教師なしドメイン適応（HTL）と教師なしドメイン適応（UDA）を統合するための取り組みとして、教師なし仮説転送に取り組むための仮説視差正則化相互情報最大化（HDMI）アプローチを提案します。教師なしの方法でターゲットドメインに。通常、単一の仮説を使用する一般的なHTLおよびUDAアプローチとは対照的に、HDMIは複数の仮説を使用して、ソースおよびターゲットの仮説の基礎となる分布を活用します。相互情報量の最大化を通じてラベルのないターゲットドメインに適応しながら、各仮説の制約なしの最適化とは対照的に、異なる仮説間の重要な関係をより有効に活用するために、HDMIには、より転送可能性を維持しながら、ターゲット仮説を共同で学習する仮説視差正規化が組み込まれています。より適切に調整された予測の不確実性を伴うソース知識。 HDMIは、適応中にソースデータにアクセスする必要なしに、HTLのコンテキストでUDAのベンチマークデータセットで最先端の適応パフォーマンスを実現します。,https://d3i71xaburhd42.cloudfront.net/721c1e4b889b09ec2dc5c52a80340fec52a02f89/2-Figure1-1.png
Finding and Certifying (Near-)Optimal Strategies in Black-Box Extensive-Form Games,"['Brian H Zhang', 'Tuomas Sandholm']",https://arxiv.org/abs/2009.07384,"Often---for example in war games, strategy video games, and financial simulations---the game is given to us only as a black-box simulator in which we can play it. In these settings, since the game may have unknown nature action distributions (from which we can only obtain samples) and/or be too large to expand fully, it can be difficult to compute strategies with guarantees on exploitability. Recent work \cite{Zhang20:Small} resulted in a notion of certificate for extensive-form games that allows exploitability guarantees while not expanding the full game tree. However, that work assumed that the black box could sample or expand arbitrary nodes of the game tree at any time, and that a series of exact game solves (via, for example, linear programming) can be conducted to compute the certificate. Each of those two assumptions severely restricts the practical applicability of that method. In this work, we relax both of the assumptions. We show that high-probability certificates can be obtained with a black box that can do nothing more than play through games, using only a regret minimizer as a subroutine. As a bonus, we obtain an equilibrium-finding algorithm with $\tilde O(\sqrt{T})$ regret bound in the extensive-form game setting that does not rely on a sampling strategy with lower-bounded reach probabilities (which MCCFR assumes). We demonstrate experimentally that, in the black-box setting, our methods are able to provide nontrivial exploitability guarantees while expanding only a small fraction of the game tree.",多くの場合、たとえば、戦争ゲーム、戦略ビデオゲーム、および財務シミュレーションでは、ゲームは、プレイできるブラックボックスシミュレーターとしてのみ提供されます。これらの設定では、ゲームの性質が不明なアクション分布（サンプルしか取得できない）や大きすぎて完全に拡張できない可能性があるため、悪用可能性を保証する戦略を計算するのは難しい場合があります。最近の作業により、ゲームツリー全体を拡張せずに悪用可能性を保証できる展開型ゲームの証明書の概念が生まれました。ただし、その作業では、ブラックボックスがいつでもゲームツリーの任意のノードをサンプリングまたは拡張でき、一連の正確なゲーム解決（線形計画法など）を実行して証明書を計算できることを前提としています。これらの2つの仮定はそれぞれ、その方法の実際の適用性を厳しく制限します。この作業では、両方の仮定を緩和します。後悔の最小化子のみをサブルーチンとして使用して、ゲームをプレイする以外に何もできないブラックボックスで高確率の証明書を取得できることを示します。ボーナスとして、$ \ tilde O（\ sqrt {T}）$後悔が、下限リーチ確率（MCCFR想定）。ブラックボックス設定では、ゲームツリーのごく一部のみを拡張しながら、私たちのメソッドが重要な悪用可能性の保証を提供できることを実験的に示します。,https://d3i71xaburhd42.cloudfront.net/54e50032cf9f9550e03ae720d215a9ecbe4ee479/6-Figure1-1.png
Scheduling of Time-Varying Workloads Using Reinforcement Learning,"['Shanka Subhra Mondal', 'Nikhil Sheoran', 'Subrata Mitra']",,,,
Self-Correcting Q-Learning,"['Rong Zhu', 'Mattia Rigotti']",https://arxiv.org/abs/2012.01100,"The Q-learning algorithm is known to be affected by the maximization bias, i.e. the systematic overestimation of action values, an important issue that has recently received renewed attention. Double Q-learning has been proposed as an efficient algorithm to mitigate this bias. However, this comes at the price of an underestimation of action values, in addition to increased memory requirements and a slower convergence. In this paper, we introduce a new way to address the maximization bias in the form of a ""self-correcting algorithm"" for approximating the maximum of an expected value. Our method balances the overestimation of the single estimator used in conventional Q-learning and the underestimation of the double estimator used in Double Q-learning. Applying this strategy to Q-learning results in Self-correcting Q-learning. We show theoretically that this new algorithm enjoys the same convergence guarantees as Q-learning while being more accurate. Empirically, it performs better than Double Q-learning in domains with rewards of high variance, and it even attains faster convergence than Q-learning in domains with rewards of zero or low variance. These advantages transfer to a Deep Q Network implementation that we call Self-correcting DQN and which outperforms regular DQN and Double DQN on several tasks in the Atari 2600 domain.",Q学習アルゴリズムは、最大化バイアス、つまりアクション値の体系的な過大評価の影響を受けることが知られており、最近新たな注目を集めている重要な問題です。このバイアスを軽減するための効率的なアルゴリズムとして、ダブルQ学習が提案されています。ただし、これには、メモリ要件の増加と収束の遅延に加えて、アクション値の過小評価が伴います。この論文では、期待値の最大値を近似するための「自己修正アルゴリズム」の形で最大化バイアスに対処する新しい方法を紹介します。私たちの方法は、従来のQ学習で使用される単一推定量の過大評価と二重Q学習で使用される二重推定量の過小評価のバランスを取ります。この戦略をQ学習に適用すると、自己修正型Q学習が実現します。この新しいアルゴリズムは、より正確でありながら、Q学習と同じ収束保証を享受することを理論的に示しています。経験的には、分散の高いドメインでのダブルQ学習よりもパフォーマンスが高く、分散がゼロまたは低いドメインでのQ学習よりも高速な収束を実現します。これらの利点は、自己修正DQNと呼ばれるDeep Qネットワークの実装に移行します。これは、Atari2600ドメインのいくつかのタスクで通常のDQNおよびダブルDQNよりも優れています。,https://d3i71xaburhd42.cloudfront.net/cf73d19bdb6d78929678faac4badfb6b5341b6f3/4-Figure1-1.png
Open-Set Recognition with Gaussian Mixture Variational Autoencoders,"['Alexander Cao', 'Yuan Luo', 'Diego Klabjan']",https://arxiv.org/abs/2006.02003,"In inference, open-set classification is to either classify a sample into a known class from training or reject it as an unknown class. Existing deep open-set classifiers train explicit closed-set classifiers, in some cases disjointly utilizing reconstruction, which we find dilutes the latent representation's ability to distinguish unknown classes. In contrast, we train our model to cooperatively learn reconstruction and perform class-based clustering in the latent space. With this, our Gaussian mixture variational autoencoder (GMVAE) achieves more accurate and robust open-set classification results, with an average F1 improvement of 29.5%, through extensive experiments aided by analytical results.",推論では、開集合分類は、サンプルをトレーニングから既知のクラスに分類するか、未知のクラスとして拒否することです。既存の深い開集合分類器は、明示的な閉集合分類器をトレーニングし、場合によっては再構成をばらばらに利用します。これにより、未知のクラスを区別する潜在的な表現能力が希薄になります。対照的に、モデルをトレーニングして、再構成を協調的に学習し、潜在空間でクラスベースのクラスタリングを実行します。これにより、ガウス混合変分オートエンコーダー（GMVAE）は、平均F1の改善が29.5で、より正確で堅牢な開集合分類結果を実現します。,https://d3i71xaburhd42.cloudfront.net/dc304d97a36168a0c888e9668fa29937fcb2e009/7-Figure1-1.png
A Student-Teacher Architecture for Dialog Domain Adaptation under the Meta-Learning Setting,"['Kun Qian', 'Wei Wei', 'Zhou Yu']",,,,
Sample-Specific Output Constraints for Neural Networks,"['Mathis Brosowsky', 'Florian Keck', 'Olaf Dünkel', 'Marius Zöllner']",https://arxiv.org/abs/2003.10258,"Neural networks reach state-of-the-art performance in a variety of learning tasks. However, a lack of understanding the decision making process yields to an appearance as black box. We address this and propose ConstraintNet, a neural network with the capability to constrain the output space in each forward pass via an additional input. The prediction of ConstraintNet is proven within the specified domain. This enables ConstraintNet to exclude unintended or even hazardous outputs explicitly whereas the final prediction is still learned from data. We focus on constraints in form of convex polytopes and show the generalization to further classes of constraints. ConstraintNet can be constructed easily by modifying existing neural network architectures. We highlight that ConstraintNet is end-to-end trainable with no overhead in the forward and backward pass. For illustration purposes, we model ConstraintNet by modifying a CNN and construct constraints for facial landmark prediction tasks. Furthermore, we demonstrate the application to a follow object controller for vehicles as a safety-critical application. We submitted an approach and system for the generation of safety-critical outputs of an entity based on ConstraintNet at the German Patent and Trademark Office with the official registration mark DE10 2019 119 739.",ニューラルネットワークは、さまざまな学習タスクで最先端のパフォーマンスに到達します。ただし、意思決定プロセスを理解していないと、ブラックボックスのように見えます。これに対処し、追加の入力を介して各フォワードパスの出力スペースを制約する機能を備えたニューラルネットワークであるConstraintNetを提案します。 ConstraintNetの予測は、指定されたドメイン内で証明されます。これにより、ConstraintNetは意図しない出力や危険な出力を明示的に除外できますが、最終的な予測はデータから学習されます。凸ポリトープの形の制約に焦点を当て、制約のさらなるクラスへの一般化を示します。 ConstraintNetは、既存のニューラルネットワークアーキテクチャを変更することで簡単に構築できます。 ConstraintNetはエンドツーエンドでトレーニング可能であり、フォワードパスとバックワードパスにオーバーヘッドがないことを強調します。説明のために、CNNを変更してConstraintNetをモデル化し、顔のランドマーク予測タスクの制約を作成します。さらに、セーフティクリティカルなアプリケーションとして、車両のフォローオブジェクトコントローラーへのアプリケーションを示します。ドイツ特許商標庁で、ConstraintNetに基づくエンティティのセーフティクリティカルな出力を生成するためのアプローチとシステムを、公式登録マークDE10 2019 119739で提出しました。,https://d3i71xaburhd42.cloudfront.net/ab9ea01d28a330c1cbc96763c7273066a51eadab/3-Figure1-1.png
Preference Elicitation as Average-Case Sorting,"['Dominik Peters', 'Ariel D Procaccia']",,"Many decision making systems require users to indicate their preferences via a ranking. It is common to elicit such rankings through pairwise comparison queries. By using sorting algorithms, this can be achieved by asking at most O(m logm) adaptive comparison queries. However, in many cases we have some advance (probabilistic) information about the user’s preferences, for instance if we have a learnt model of the user’s preferences or if we expect the user’s preferences to be correlated with those of previous users. For these cases, we design elicitation algorithms that ask fewer questions in expectation, by building on results for average-case sorting. If the user’s preference are drawn from a Mallows phi model, O(m) queries are enough; for a mixture of k Mallows models, log k +O(m) queries are enough; for Plackett–Luce models, the answer varies with the alternative weights. Our results match information-theoretic lower bounds. We also provide empirical evidence for the benefits of our approach.",多くの意思決定システムでは、ユーザーがランキングを介して自分の好みを示す必要があります。ペアワイズ比較クエリを介してそのようなランキングを引き出すことは一般的です。ソートアルゴリズムを使用することにより、これは最大でO（m logm）の適応比較クエリを実行することで実現できます。ただし、多くの場合、ユーザーの好みに関する事前の（確率的な）情報があります。たとえば、ユーザーの好みの学習モデルがある場合や、ユーザーの好みが以前のユーザーの好みと相関していると予想される場合などです。これらのケースでは、平均的なケースの並べ替えの結果に基づいて、期待される質問が少ない誘発アルゴリズムを設計します。ユーザーの好みがMallowsphiモデルから引き出されている場合、O（m）クエリで十分です。 k個のMallowsモデルが混在している場合、log k + O（m）クエリで十分です。 PlackettLuceモデルの場合、答えは代替の重みによって異なります。私たちの結果は、情報理論の下限と一致しています。また、私たちのアプローチの利点についての経験的証拠も提供します。,https://d3i71xaburhd42.cloudfront.net/d6fc4fff91f3b84f2742529de6a5383471968102/4-Figure1-1.png
Generate Your Counterfactuals: Towards Controlled Counterfactual Generation for Text,"['Nishtha Madan', 'Inkit Padhi', 'Naveen Panwar', 'Diptikalyan Saha']",,,,
Optimal Kidney Exchange with Immunosuppressants,"['Haris Aziz', 'Agnes Cseh', 'John P Dickerson', 'Duncan C McElfresh']",,,,
Online Learning in Variable Feature Spaces under Incomplete Supervision,"['Yi He', 'Xu Yuan', 'Sheng Chen', 'Xindong Wu']",,,,
ChronoR: Rotation Based Temporal Knowledge Graph Embedding,"['Ali Sadeghian', 'Mohammadreza Armandpour', 'Anthony Colas', 'Daisy Zhe Wang']",,,,
Diverse Knowledge Distillation for End-to-End Person Search,"['Xinyu Zhang', 'Xinlong Wang', 'Jia-Wang Bian', 'Chunhua Shen', 'Mingyu You']",https://arxiv.org/abs/2012.11187,"Person search aims to localize and identify a specific person from a gallery of images. Recent methods can be categorized into two groups, i.e., two-step and end-to-end approaches. The former views person search as two independent tasks and achieves dominant results using separately trained person detection and re-identification (Re-ID) models. The latter performs person search in an end-to-end fashion. Although the end-to-end approaches yield higher inference efficiency, they largely lag behind those two-step counterparts in terms of accuracy. In this paper, we argue that the gap between the two kinds of methods is mainly caused by the Re-ID subnetworks of end-to-end methods. To this end, we propose a simple yet strong end-to-end network with diverse knowledge distillation to break the bottleneck. We also design a spatialinvariant augmentation to assist model to be invariant to inaccurate detection results. Experimental results on the CUHKSYSU and PRW datasets demonstrate the superiority of our method against existing approaches—it achieves on par accuracy with state-of-the-art two-step methods while maintaining high efficiency due to the single joint model. Code is available at: https://git.io/DKD-PersonSearch",人物検索は、画像のギャラリーから特定の人物を特定して特定することを目的としています。最近の方法は、2つのグループ、つまり2ステップとエンドツーエンドのアプローチに分類できます。前者は、人の検索を2つの独立したタスクと見なし、個別にトレーニングされた人の検出と再識別（Re-ID）モデルを使用して主要な結果を達成します。後者は、エンドツーエンドの方法で人の検索を実行します。エンドツーエンドのアプローチはより高い推論効率をもたらしますが、精度の点でこれらの2段階のアプローチに大きく遅れをとっています。この論文では、2種類のメソッド間のギャップは、主にエンドツーエンドメソッドのRe-IDサブネットワークによって引き起こされると主張します。この目的のために、ボトルネックを解消するための多様な知識の蒸留を備えた、シンプルでありながら強力なエンドツーエンドネットワークを提案します。また、不正確な検出結果に対してモデルが不変になるように、空間不変の拡張を設計します。 CUHKSYSUおよびPRWデータセットの実験結果は、シングルジョイントモデルによる高効率を維持しながら、最先端の2ステップメソッドと同等の精度で達成される既存のアプローチに対するメソッドの優位性を示しています。コードはhttps://git.io/DKD-PersonSearchで入手できます。,https://d3i71xaburhd42.cloudfront.net/f46d48e2afc0ec4c397db66557e80f42e765809a/1-Figure1-1.png
SWIFT: Scalable Wasserstein Factorization for Sparse Nonnegative Tensors,"['Ardavan Afshar', 'Kejing Yin', 'Sherry Yan', 'Cheng Qian', 'Joyce Ho', 'Haesun Park', 'Jimeng Sun']",https://arxiv.org/abs/2010.04081,"Existing tensor factorization methods assume that the input tensor follows some specific distribution (i.e. Poisson, Bernoulli and Gaussian), and solve the factorization by minimizing some empirical loss functions defined based on the corresponding distribution. However, it suffers from several drawbacks: 1) In reality, the underlying distributions are complicated and unknown, making it infeasible to be approximated by a simple distribution. 2) The correlation across dimensions of the input tensor is not well utilized, leading to sub-optimal performance. Although heuristics were proposed to incorporate such correlation as side information under Gaussian distribution, they can not easily be generalized to other distributions. Thus, a more principled way of utilizing the correlation in tensor factorization models is still an open challenge. Without assuming any explicit distribution, we formulate the tensor factorization as an optimal transport problem with Wasserstein distance, which can handle non-negative inputs. We introduce SWIFT, which minimizes the Wasserstein distance that measures the distance between the input tensor and that of the reconstruction. In particular, we define the N-th order tensor Wasserstein loss for the widely used tensor CP factorization, and derive the optimization algorithm that minimizes it. By leveraging sparsity structure and different equivalent formulations for optimizing computational efficiency, SWIFT is as scalable as other well-known CP algorithms. Using the factor matrices as features, SWIFT achieves up to 9.65% and 11.31% relative improvement over baselines for downstream prediction tasks. Under the noisy conditions, SWIFT achieves up to 15% and 17% relative improvements over the best competitors for the prediction tasks.",既存のテンソル分解法は、入力テンソルが特定の分布（つまり、ポアソン、ベルヌーイ、ガウス）に従うことを前提とし、対応する分布に基づいて定義されたいくつかの経験的損失関数を最小化することによって因数分解を解決します。ただし、いくつかの欠点があります。1）実際には、基礎となる分布は複雑で不明であるため、単純な分布で近似することは不可能です。 2）入力テンソルの次元間の相関が十分に活用されていないため、パフォーマンスが最適ではありません。ヒューリスティックは、ガウス分布の下でサイド情報などの相関を組み込むために提案されましたが、他の分布に簡単に一般化することはできません。したがって、テンソル分解モデルで相関を利用するより原理的な方法は、未解決の課題です。明示的な分布を仮定せずに、テンソル分解を、非負の入力を処理できるワッサースタイン距離を使用した最適な輸送問題として定式化します。入力テンソルと再構成の距離を測定するワッサースタイン距離を最小化するSWIFTを紹介します。特に、広く使用されているテンソルCP因数分解のN次テンソルワッサースタイン損失を定義し、それを最小化する最適化アルゴリズムを導出します。計算効率を最適化するためにスパース構造とさまざまな同等の定式化を活用することにより、SWIFTは他のよく知られたCPアルゴリズムと同じくらいスケーラブルです。因子行列を特徴として使用して、SWIFTは最大9.65を達成します,https://d3i71xaburhd42.cloudfront.net/5e575e44c3c0fec4abb3ed7d1824e85db6245a60/8-Figure1-1.png
Continuous-Time Attention for Sequential Learning,"['Yi-Hsiang Chen', 'Jen-Tzung Chien']",,,,
Accurate and Robust Feature Importance Estimation under Distribution Shifts,"['Jayaraman J. Thiagarajan', 'Vivek Narayanaswamy', 'Rushil Anirudh', 'Peer-Timo Bremer', 'Andreas Spanias']",https://arxiv.org/abs/2009.14454,"With increasing reliance on the outcomes of black-box models in critical applications, post-hoc explainability tools that do not require access to the model internals are often used to enable humans understand and trust these models. In particular, we focus on the class of methods that can reveal the influence of input features on the predicted outputs. Despite their wide-spread adoption, existing methods are known to suffer from one or more of the following challenges: computational complexities, large uncertainties and most importantly, inability to handle real-world domain shifts. In this paper, we propose PRoFILE, a novel feature importance estimation method that addresses all these challenges. Through the use of a loss estimator jointly trained with the predictive model and a causal objective, PRoFILE can accurately estimate the feature importance scores even under complex distribution shifts, without any additional re-training. To this end, we also develop learning strategies for training the loss estimator, namely contrastive and dropout calibration, and find that it can effectively detect distribution shifts. Using empirical studies on several benchmark image and non-image data, we show significant improvements over state-of-the-art approaches, both in terms of fidelity and robustness.",重要なアプリケーションでブラックボックスモデルの結果への依存度が高まるにつれ、モデルの内部へのアクセスを必要としない事後説明ツールが、人間がこれらのモデルを理解して信頼できるようにするためによく使用されます。特に、予測された出力に対する入力機能の影響を明らかにできるメソッドのクラスに焦点を当てます。広く採用されているにもかかわらず、既存の方法は、計算の複雑さ、大きな不確実性、そして最も重要なことに、実際のドメインシフトを処理できないという1つ以上の課題に悩まされていることが知られています。この論文では、これらすべての課題に対処する新しい特徴重要度推定法であるPRoFILEを提案します。 PRoFILEは、予測モデルおよび因果目的と共同でトレーニングされた損失推定量を使用することにより、追加の再トレーニングなしで、複雑な分布シフトの下でも特徴重要度スコアを正確に推定できます。この目的のために、損失推定量をトレーニングするための学習戦略、つまりコントラストとドロップアウトのキャリブレーションも開発し、それが分布シフトを効果的に検出できることを発見しました。いくつかのベンチマーク画像および非画像データに関する実証的研究を使用して、忠実度と堅牢性の両方の点で、最先端のアプローチよりも大幅に改善されていることを示しています。,https://d3i71xaburhd42.cloudfront.net/ecc6260cc1efc878c70bf5753d67e1a11b42627a/3-Figure1-1.png
Deep Fusion Clustering Network,"['Wenxuan Tu', 'Sihang Zhou', 'Xinwang Liu', 'Xifeng Guo', 'Zhiping Cai', 'En Zhu', 'Jieren Cheng']",https://arxiv.org/abs/2012.09600,"Deep clustering is a fundamental yet challenging task for data analysis. Recently we witness a strong tendency of combining autoencoder and graph neural networks to exploit structure information for clustering performance enhancement. However, we observe that existing literature 1) lacks a dynamic fusion mechanism to selectively integrate and refine the information of graph structure and node attributes for consensus representation learning; 2) fails to extract information from both sides for robust target distribution (i.e., ""groundtruth"" soft labels) generation. To tackle the above issues, we propose a Deep Fusion Clustering Network (DFCN). Specifically, in our network, an interdependency learning-based Structure and Attribute Information Fusion (SAIF) module is proposed to explicitly merge the representations learned by an autoencoder and a graph autoencoder for consensus representation learning. Also, a reliable target distribution generation measure and a triplet self-supervision strategy, which facilitate cross-modality information exploitation, are designed for network training. Extensive experiments on six benchmark datasets have demonstrated that the proposed DFCN consistently outperforms the state-of-the-art deep clustering methods.",ディープクラスタリングは、データ分析にとって基本的でありながら困難なタスクです。最近、オートエンコーダとグラフニューラルネットワークを組み合わせて、クラスタリングのパフォーマンスを向上させるために構造情報を活用する傾向が強くなっています。ただし、既存の文献1）は、コンセンサス表現学習のためにグラフ構造とノード属性の情報を選択的に統合および改良するための動的融合メカニズムを欠いていることを確認します。 2）堅牢なターゲット配布（つまり、「グラウンドトゥルース」ソフトラベル）を生成するために、両側から情報を抽出できません。上記の問題に取り組むために、Deep Fusion Clustering Network（DFCN）を提案します。具体的には、私たちのネットワークでは、コンセンサス表現学習のために、オートエンコーダーとグラフオートエンコーダーによって学習された表現を明示的にマージするために、相互依存性学習ベースの構造と属性情報融合（SAIF）モジュールが提案されています。また、クロスモダリティ情報の活用を容易にする信頼性の高いターゲット分布生成手段とトリプレット自己監視戦略は、ネットワークトレーニング用に設計されています。 6つのベンチマークデータセットでの広範な実験により、提案されたDFCNは常に最先端のディープクラスタリング手法よりも優れていることが実証されています。,https://d3i71xaburhd42.cloudfront.net/21a5c402b9ca4374b20c737f4b0cce3fe38472e0/1-Figure1-1.png
SSN3D: Self-Separated Network to Align Parts for 3D Convolution in Video Person Re-Identification,"['Xiaoke Jiang', 'Yu Qiao', 'Junjie Yan', 'Qichen Li', 'Wanrong Zheng', 'Dapeng Chen']",,,,
Deep Portfolio Optimization via Distributional Prediction of Residual Factors,"['Kentaro Imajo', 'Kentaro Minami', 'Katsuya Ito', 'Kei Nakagawa']",https://arxiv.org/abs/2012.07245,"Recent developments in deep learning techniques have motivated intensive research in machine learning-aided stock trading strategies. However, since the financial market has a highly non-stationary nature hindering the application of typical data-hungry machine learning methods, leveraging financial inductive biases is important to ensure better sample efficiency and robustness. In this study, we propose a novel method of constructing a portfolio based on predicting the distribution of a financial quantity called residual factors, which is known to be generally useful for hedging the risk exposure to common market factors. The key technical ingredients are twofold. First, we introduce a computationally efficient extraction method for the residual information, which can be easily combined with various prediction algorithms. Second, we propose a novel neural network architecture that allows us to incorporate widely acknowledged financial inductive biases such as amplitude invariance and time-scale invariance. We demonstrate the efficacy of our method on U.S. and Japanese stock market data. Through ablation experiments, we also verify that each individual technique contributes to improving the performance of trading strategies. We anticipate our techniques may have wide applications in various financial problems.",深層学習技術の最近の開発は、機械学習を利用した株取引戦略の集中的な研究を動機付けています。ただし、金融市場は非常に非定常的な性質を持っているため、一般的なデータを大量に消費する機械学習手法の適用を妨げているため、サンプルの効率と堅牢性を向上させるには、金融誘導バイアスを活用することが重要です。本研究では、一般的な市場要因へのリスクエクスポージャーをヘッジするために一般的に有用であることが知られている残余要因と呼ばれる財務量の分布を予測することに基づいてポートフォリオを構築する新しい方法を提案します。重要な技術的要素は2つあります。まず、さまざまな予測アルゴリズムと簡単に組み合わせることができる、残差情報の計算効率の高い抽出方法を紹介します。次に、振幅不変性や時間スケール不変性など、広く認められている金融誘導バイアスを組み込むことができる新しいニューラルネットワークアーキテクチャを提案します。米国と日本の株式市場データで、この方法の有効性を示します。アブレーション実験を通じて、個々の手法が取引戦略のパフォーマンスの向上に貢献していることも確認します。私たちの技術は、さまざまな財政問題に幅広い用途があると予想しています。,https://d3i71xaburhd42.cloudfront.net/98898ce8f3a1addb1d2e1e126781b4b765a0e4ca/3-Figure1-1.png
Conceptualized and Contextualized Gaussian Embedding,"['Chen Qian', 'Fuli Feng', 'Lijie Wen', 'Tat-Seng Chua']",,,,
Regularizing Attention Networks for Anomaly Detection in Visual Question Answering,"['Doyup Lee', 'Yeongjae Cheon', 'Wook-Shin Han']",https://arxiv.org/abs/2009.10054,"For stability and reliability of real-world applications, the robustness of DNNs in unimodal tasks has been evaluated. However, few studies consider abnormal situations that a visual question answering (VQA) model might encounter at test time after deployment in the real-world. In this study, we evaluate the robustness of state-of-the-art VQA models to five different anomalies, including worst-case scenarios, the most frequent scenarios, and the current limitation of VQA models. Different from the results in unimodal tasks, the maximum confidence of answers in VQA models cannot detect anomalous inputs, and post-training of the outputs, such as outlier exposure, is ineffective for VQA models. Thus, we propose an attention-based method, which uses confidence of reasoning between input images and questions and shows much more promising results than the previous methods in unimodal tasks. In addition, we show that a maximum entropy regularization of attention networks can significantly improve the attention-based anomaly detection of the VQA models. Thanks to the simplicity, attention-based anomaly detection and the regularization are model-agnostic methods, which can be used for various cross-modal attentions in the state-of-the-art VQA models. The results imply that cross-modal attention in VQA is important to improve not only VQA accuracy, but also the robustness to various anomalies.",実際のアプリケーションの安定性と信頼性のために、ユニモーダルタスクにおけるDNNの堅牢性が評価されています。ただし、実際の展開後のテスト時に視覚的な質問応答（VQA）モデルで発生する可能性のある異常な状況を考慮している研究はほとんどありません。この研究では、最悪のシナリオ、最も頻繁なシナリオ、VQAモデルの現在の制限など、5つの異なる異常に対する最先端のVQAモデルの堅牢性を評価します。単峰性タスクの結果とは異なり、VQAモデルの回答の最大の信頼度では異常な入力を検出できず、外れ値の露出などの出力のトレーニング後はVQAモデルでは効果がありません。したがって、入力画像と質問の間の推論の信頼性を使用し、単峰性タスクで以前の方法よりもはるかに有望な結果を示す注意ベースの方法を提案します。さらに、注意ネットワークの最大エントロピー正則化により、VQAモデルの注意ベースの異常検出を大幅に改善できることを示します。シンプルさのおかげで、注意ベースの異常検出と正則化はモデルにとらわれない方法であり、最先端のVQAモデルのさまざまなクロスモーダル注意に使用できます。この結果は、VQAのクロスモーダル注意が、VQAの精度だけでなく、さまざまな異常に対する堅牢性も向上させるために重要であることを示しています。,
Scalable and Safe Multi-Agent Motion Planning with Nonlinear Dynamics and Bounded Disturbances,"['Jingkai Chen', 'Jiaoyang Li', 'Chuchu Fan', 'Brian C Williams']",https://arxiv.org/abs/2012.09052,"We present a scalable and effective multi-agent safe motion planner that enables a group of agents to move to their desired locations while avoiding collisions with obstacles and other agents, with the presence of rich obstacles, high-dimensional, nonlinear, nonholonomic dynamics, actuation limits, and disturbances. We address this problem by finding a piecewise linear path for each agent such that the actual trajectories following these paths are guaranteed to satisfy the reach-and-avoid requirement. We show that the spatial tracking error of the actual trajectories of the controlled agents can be pre-computed for any qualified path that considers the minimum duration of each path segment due to actuation limits. Using these bounds, we find a collision-free path for each agent by solving Mixed Integer-Linear Programs and coordinate agents by using the priority-based search. We demonstrate our method by benchmarking in 2D and 3D scenarios with ground vehicles and quadrotors, respectively, and show improvements over the solving time and the solution quality compared to two state-of-the-art multi-agent motion planners.",豊富な障害物、高次元、非線形、非ホロノミックダイナミクス、作動の存在下で、障害物や他のエージェントとの衝突を回避しながら、エージェントのグループが目的の場所に移動できるようにする、スケーラブルで効果的なマルチエージェントセーフモーションプランナーを紹介します制限、および妨害。これらのパスをたどる実際の軌道が到達と回避の要件を満たすことが保証されるように、各エージェントの区分的線形パスを見つけることによって、この問題に対処します。制御されたエージェントの実際の軌道の空間追跡エラーは、作動制限による各パスセグメントの最小期間を考慮した適格なパスに対して事前に計算できることを示します。これらの境界を使用して、混合整数線形計画法を解くことにより各エージェントの衝突のないパスを見つけ、優先度ベースの検索を使用してエージェントを調整します。地上車両とクワッドローターをそれぞれ使用して2Dおよび3Dシナリオでベンチマークを行うことにより、この方法を示し、2つの最先端のマルチエージェントモーションプランナーと比較して、解決時間とソリューション品質の改善を示します。,https://d3i71xaburhd42.cloudfront.net/62a90d3f5f2a607faa182f5aa51cb83954191ce9/2-Figure1-1.png
Adversarial Robustness through Disentangled Representations,"['Shuo Yang', 'Tianyu Guo', 'Yunhe Wang', 'Chang Xu']",,,,
Improving Model Robustness by Adaptively Correcting Perturbation Levels with Active Queries,"['Kun-Peng Ning', 'Lue Tao', 'Songcan Chen', 'Sheng-Jun Huang']",,,,
Query-Memory Re-Aggregation for Weakly-Supervised Video Object Segmentation,"['Fanchao Lin', 'Hongtao Xie', 'Yan Li', 'Yongdong Zhang']",,,,
Heterogeneous Graph Structure Learning for Graph Neural Networks,"['Jianan Zhao', 'Xiao Wang', 'Chuan Shi', 'Binbin Hu', 'Guojie Song', 'Yanfang Ye']",,,,
Generative Partial Visual-Tactile Fused Object Clustering,"['Tao Zhang', 'Yang Cong', 'Gan Sun', 'Jiahua Dong', 'Yuyang Liu', 'Zhengming Ding']",https://arxiv.org/abs/2012.14070,"Visual-tactile fused sensing for object clustering has achieved significant progresses recently, since the involvement of tactile modality can effectively improve clustering performance. However, the missing data (i.e., partial data) issues always happen due to occlusion and noises during the data collecting process. This issue is not well solved by most existing partial multi-view clustering methods for the heterogeneous modality challenge. Naively employing these methods would inevitably induce a negative effect and further hurt the performance. To solve the mentioned challenges, we propose a Generative Partial Visual-Tactile Fused (i.e., GPVTF) framework for object clustering. More specifically, we first do partial visual and tactile features extraction from the partial visual and tactile data, respectively, and encode the extracted features in modality-specific feature subspaces. A conditional cross-modal clustering generative adversarial network is then developed to synthesize one modality conditioning on the other modality, which can compensate missing samples and align the visual and tactile modalities naturally by adversarial learning. To the end, two pseudo-label based KL-divergence losses are employed to update the corresponding modality-specific encoders. Extensive comparative experiments on three public visual-tactile datasets prove the effectiveness of our method. Introduction Benefitting from the great progresses in visual-tactile fused sensing (Liu and Sun 2018; Luo et al. 2018; Lee, Bollegala, and Luo 2019), researchers (Zhang et al. 2020) attempt to focus on visual-tactile fused clustering (VTFC), which aims to group similar objects together in an unsupervised manner. An interesting example is that when robots employ visual and tactile information to explore unknown environment (e.g., many objects cluttered in an unstructured scene), recognizing the objects in this scene by collecting and annotating a lot of samples is time-consuming and expensive (Zhao, Wang, and Huang 2021; Wei et al. 2019; Zhao et al. 2020; *The corresponding author is Prof. Yang Cong and this work is supported by the National Key Research and Development Program of China (2019YFB1310300) and National Nature Science Foundation of China under Grant (61722311, U1613214, 61821005). Modality 1: Partial Visual Data Modality 2: Partial Tactile Data Visual Subspace Tactile Subspace Missing Data",オブジェクトクラスタリングの視覚触覚融合センシングは、触覚モダリティの関与がクラスタリングパフォーマンスを効果的に改善できるため、最近大きな進歩を遂げました。ただし、欠測データ（つまり、部分データ）の問題は、データ収集プロセス中のオクルージョンとノイズが原因で常に発生します。この問題は、異種モダリティの課題に対するほとんどの既存の部分マルチビュークラスタリング手法では十分に解決されていません。これらの方法を単純に採用すると、必然的に悪影響が生じ、パフォーマンスがさらに低下します。上記の課題を解決するために、オブジェクトクラスタリング用のGenerative Partial Visual-Tactile Fused（つまり、GPVTF）フレームワークを提案します。より具体的には、最初に部分的な視覚的および触覚的データからそれぞれ部分的な視覚的および触覚的特徴抽出を行い、抽出された特徴をモダリティ固有の特徴部分空間にエンコードします。次に、条件付きクロスモーダルクラスタリング生成的敵対的ネットワークを開発して、一方のモダリティ条件付けをもう一方のモダリティに合成します。これにより、欠落しているサンプルを補正し、敵対的学習によって視覚的および触覚的モダリティを自然に調整できます。最後に、2つの疑似ラベルベースのKL発散損失を使用して、対応するモダリティ固有のエンコーダーを更新します。 3つの公開視覚触覚データセットでの広範な比較実験は、私たちの方法の有効性を証明しています。はじめに視覚触覚融合センシングの大きな進歩（Liu and Sun 2018; Luoetal。2018; Lee、Bollegala、and Luo 2019）の恩恵を受けて、研究者（Zhang etal。2020）は視覚触覚融合クラスタリングに焦点を当てようとしています（VTFC）は、監視されていない方法で類似したオブジェクトをグループ化することを目的としています。興味深い例は、ロボットが視覚的および触覚的な情報を使用して未知の環境（たとえば、構造化されていないシーンに散らばっている多くのオブジェクト）を探索する場合、多くのサンプルを収集して注釈を付けることによってこのシーンのオブジェクトを認識することは、時間と費用がかかることです（Zhao 、Wang、およびHuang 2021; Weietal。2019; Zhaoetal。2020; *対応する著者はYangCong教授であり、この研究は中国の国家主要研究開発プログラム（2019YFB1310300）および国家自然科学によってサポートされています。助成金の下での中国の財団（61722311、U1613214、61821005）。モダリティ1：部分的な視覚データモダリティ2：部分的な触覚データ視覚サブスペース触覚サブスペース欠落データ,https://d3i71xaburhd42.cloudfront.net/a3cf5f6e38261c51f5a6b0c24e6c70e04d848cac/1-Figure1-1.png
Large Batch Optimization for Deep Learning Using New Complete Layer-Wise Adaptive Rate Scaling,"['Zhouyuan Huo', 'Bin Gu', 'Heng Huang']",,,,
Integrated Optimization of Bipartite Matching and Its Stochastic Behavior: New Formulation and Approximation Algorithm via Min-Cost Flow Optimization,"['Yuya Hikima', 'Yasunori Akagi', 'Hideaki Kim', 'Masahiro Kohjima', 'Takeshi Kurashima', 'Hiroyuki Toda']",,,,
Multi-View information-Bottleneck Representation Learning,"['Zhibin Wan', 'Changqing Zhang', 'Pengfei Zhu', 'Qinghua Hu']",,,,
A Trace-Restricted Kronecker-Factored Approximation to Natural Gradient,"['Kaixin Gao', 'Xiaolei Liu', 'Zhenghai Huang', 'Min Wang', 'Zidong Wang', 'Dachuan Xu', 'Fan Yu']",,,,
"Writing Polishment with Simile: Task, Dataset and a Neural Approach","['Jiayi Zhang', 'Zhi Cui', 'Xiaoqiang Xia', 'Yalong Guo', 'Yanran Li', 'Chen Wei', 'Jianwei Cui']",https://arxiv.org/abs/2012.08117,"A simile is a figure of speech that directly makes a comparison, showing similarities between two different things, e.g. ""Reading papers can be dull sometimes,like watching grass grow"". Human writers often interpolate appropriate similes into proper locations of the plain text to vivify their writings. However, none of existing work has explored neural simile interpolation, including both locating and generation. In this paper, we propose a new task of Writing Polishment with Simile (WPS) to investigate whether machines are able to polish texts with similes as we human do. Accordingly, we design a two-staged Locate&Gen model based on transformer architecture. Our model firstly locates where the simile interpolation should happen, and then generates a location-specific simile. We also release a large-scale Chinese Simile (CS) dataset containing 5 million similes with context. The experimental results demonstrate the feasibility of WPS task and shed light on the future research directions towards better automatic text polishment.",直喩は、直接比較する比喩であり、2つの異なるものの類似点を示します。たとえば、「草が生えるのを見るように、紙を読むのが鈍くなることがあります」。人間の作家はしばしば、彼らの文章を生き生きとさせるために、適切な直喩を平文の適切な場所に補間します。ただし、既存の作業のいずれも、位置特定と生成の両方を含む、神経直喩補間を調査していません。この論文では、機械が私たち人間のように直喩でテキストを磨くことができるかどうかを調査するために、直喩で磨きを書く（WPS）という新しいタスクを提案します。したがって、トランスアーキテクチャに基づいて2段階のLocate＆Genモデルを設計します。私たちのモデルは、最初に直喩の補間が行われるべき場所を特定し、次に場所固有の直喩を生成します。また、コンテキスト付きの500万の直喩を含む大規模な中国の直喩（CS）データセットをリリースします。実験結果は、WPSタスクの実現可能性を示し、より良い自動テキスト研磨に向けた将来の研究の方向性に光を当てます。,https://d3i71xaburhd42.cloudfront.net/1a9c195c97036aeb98cab02081d656ed480198b2/4-Figure1-1.png
Show Me How To Revise: Improving Lexically Constrained Sentence Generation with XLNet,"['Xingwei He', 'Victor O.K. Li']",,,,
District-Fair Participatory Budgeting,"['D Ellis Hershkowitz', 'Anson Kahng', 'Dominik Peters', 'Ariel D Procaccia']",https://arxiv.org/abs/2102.06115,"Participatory budgeting is a method used by city governments to select public projects to fund based on residents’ votes. Many cities use participatory budgeting at a district level. Typically, a budget is divided among districts proportionally to their population, and each district holds an election over local projects and then uses its budget to fund the projects most preferred by its voters. However, district-level participatory budgeting can yield poor social welfare because it does not necessarily fund projects supported across multiple districts. On the other hand, decision making that only takes global social welfare into account can be unfair to districts: A social-welfare-maximizing solution might not fund any of the projects preferred by a district, despite the fact that its constituents pay taxes to the city. Thus, we study how to fairly maximize social welfare in a participatory budgeting setting with a single city-wide election. We propose a notion of fairness that guarantees each district at least as much welfare as it would have received in a district-level election. We show that, although optimizing social welfare subject to this notion of fairness is NP-hard, we can efficiently construct a lottery over welfare-optimal outcomes that is fair in expectation. Moreover, we show that, when we are allowed to slightly relax fairness, we can efficiently compute a fair solution that is welfare-maximizing, but which may overspend the budget.",参加型予算は、住民の投票に基づいて資金を提供する公共プロジェクトを選択するために市政府が使用する方法です。多くの都市は、地区レベルで参加型予算を使用しています。通常、予算は人口に比例して地区間で分割され、各地区は地元のプロジェクトに対して選挙を行い、その予算を使用して有権者が最も好むプロジェクトに資金を提供します。ただし、地区レベルの参加型予算は、必ずしも複数の地区で支援されるプロジェクトに資金を提供するわけではないため、社会福祉が不十分になる可能性があります。一方、グローバルな社会福祉のみを考慮した意思決定は、地区にとって不公平になる可能性があります。社会福祉を最大化するソリューションは、その構成員が税金を支払うという事実にもかかわらず、地区が好むプロジェクトに資金を提供しない可能性があります。市。したがって、私たちは、市全体の1回の選挙で、参加型予算の設定で社会福祉を公正に最大化する方法を研究します。私たちは、各地区が少なくとも地区レベルの選挙で受けたであろう福祉と同じくらいの福祉を保証する公平性の概念を提案します。この公平性の概念に従って社会福祉を最適化することはNP困難ですが、期待どおりに公平な福祉最適な結果についての宝くじを効率的に構築できることを示します。さらに、公平性をわずかに緩和することが許されると、福祉を最大化するが予算を超過する可能性のある公正な解決策を効率的に計算できることを示します。,
Train a One-Million-Way Instance Classifier for Unsupervised Visual Representation Learning,"['Yu Liu', 'Lianghua Huang', 'Pan Pan', 'Bin Wang', 'Yinghui Xu', 'Rong Jin']",https://arxiv.org/abs/2102.04848,"This paper presents a simple unsupervised visual representation learning method with a pretext task of discriminating all images in a dataset using a parametric, instance-level classifier. The overall framework is a replica of a supervised classification model, where semantic classes (e.g., dog, bird, and ship) are replaced by instance IDs. However, scaling up the classification task from thousands of semantic labels to millions of instance labels brings specific challenges including 1) the large-scale softmax computation; 2) the slow convergence due to the infrequent visiting of instance samples; and 3) the massive number of negative classes that can be noisy. This work presents several novel techniques to handle these difficulties. First, we introduce a hybrid parallel training framework to make large-scale training feasible. Second, we present a raw-feature initialization mechanism for classification weights, which we assume offers a contrastive prior for instance discrimination and can clearly speed up converge in our experiments. Finally, we propose to smooth the labels of a few hardest classes to avoid optimizing over very similar negative pairs. While being conceptually simple, our framework achieves competitive or superior performance compared to state-of-the-art unsupervised approaches, i.e., SimCLR, MoCoV2, and PIC under ImageNet linear evaluation protocol and on several downstream visual tasks, verifying that full instance classification is a strong pretraining technique for many semantic visual tasks. Unsupervised visual representation learning has recently shown encouraging progress (He et al. 2020; Chen et al. 2020a). Methods using instance discrimination as a pretext task (Tian, Krishnan, and Isola 2019; He et al. 2020; Chen et al. 2020a) have demonstrated competitive or even superior performance compared to supervised counterparts under ImageNet (Deng et al. 2009) linear evaluation protocol and on many downstream visual tasks. This shows the potential of unsupervised representation learning methods since they can utilize almost unlimited data without manual labels. To solve the instance discrimination task, usually a dualbranch structure is used, where two transformed views of a same image are encouraged to get close, while transformed views from different images are expected to get far apart (He et al. 2020; Chen et al. 2020a,c). These methods often rely on specialized designs such as memory bank (Wu et al. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Encoder Phase 1: Unsupervised pretraining Phase 2: Supervised transferring Pool + MLP N instance classes Pool + FC C semantic classes x ~ N instances (a) Outline of our representation learning framework. (b) Correlation between instance and semantic classification. Figure 1: (a) An overview of our unsupervised visual representation learning framework. Without manual labels, we simply train an instance-level classifier that tries to distinguish all images in a dataset to learn discriminative representations that can be well transferred to supervised tasks. (b) The relationship between instance (unsupervised) and semantic (supervised) classification accuracies. We observe a strong positive correlation between them in our experiments. 2018a), momentum encoder (He et al. 2020; Chen et al. 2020c), large batch size (Chen et al. 2020a,b), or shuffled batch normalization (BN) (He et al. 2020; Chen et al. 2020c) to compensate for the lack of negative samples or handle the information leakage issue (i.e., samples on a same GPU tend to get closer due to shared BN statistics). Unlike dual-branch approaches, one-branch scheme (e.g., parametric instance-level classification) usually avoids the information leakage issue, and can potentially explore a larger set of negative samples. ExemplarCNN (Dosovitskiy et al. 2014) and PIC (Cao et al. 2020) are of this category. Nevertheless, due to the high GPU computation and memory ar X iv :2 10 2. 04 84 8v 1 [ cs .C V ] 9 F eb 2 02 1",このホワイトペーパーでは、パラメトリックなインスタンスレベルの分類器を使用して、データセット内のすべての画像を識別するという口実タスクを使用した、単純な教師なし視覚表現学習方法を紹介します。全体的なフレームワークは、教師あり分類モデルのレプリカであり、セマンティッククラス（犬、鳥、船など）がインスタンスIDに置き換えられます。ただし、分類タスクを数千のセマンティックラベルから数百万のインスタンスラベルにスケールアップすると、次のような特定の課題が発生します。1）大規模なソフトマックス計算。 2）インスタンスサンプルへのアクセス頻度が低いため、収束が遅い。 3）ノイズが発生する可能性のある膨大な数のネガティブクラス。この作品は、これらの困難を処理するためのいくつかの新しい技術を提示します。まず、大規模なトレーニングを実現するためのハイブリッド並列トレーニングフレームワークを紹介します。次に、分類の重みの生の特徴の初期化メカニズムを示します。これは、たとえば識別の対照的な事前情報を提供し、実験での収束を明らかにスピードアップできると想定しています。最後に、非常に類似した負のペアに対する最適化を回避するために、いくつかの最も難しいクラスのラベルを平滑化することを提案します。概念的にシンプルでありながら、私たちのフレームワークは、ImageNet線形評価プロトコルおよびいくつかのダウンストリームビジュアルタスクの下で、最先端の教師なしアプローチ、つまりSimCLR、MoCoV2、およびPICと比較して、競争力のあるまたは優れたパフォーマンスを実現し、完全なインスタンス分類が多くのセマンティックビジュアルタスクのための強力な事前トレーニング手法。教師なし視覚表現学習は、最近、有望な進歩を示しています（Heetal。2020; Chen et al.2020a）。インスタンスの識別を口実タスクとして使用する方法（Tian、Krishnan、およびIsola 2019; Heetal。2020; Chen etal。2020a）は、ImageNet（Deng etal。2009）線形の下で監視された対応物と比較して競争力のあるまたはさらに優れたパフォーマンスを示しました評価プロトコルおよび多くのダウンストリームビジュアルタスク。これは、手動ラベルなしでほぼ​​無制限のデータを利用できるため、教師なし表現学習方法の可能性を示しています。インスタンス識別タスクを解決するために、通常、デュアルブランチ構造が使用されます。この構造では、同じ画像の2つの変換されたビューが近づくように促され、異なる画像からの変換されたビューは遠く離れると予想されます（Heetal。2020; Chen et al .2020a、c）。これらの方法は、メモリバンクなどの特殊な設計に依存することがよくあります（Wuetal。Copyright2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。Allrights reserved。エンコーダフェーズ1：監視なしの事前トレーニングフェーズ2：監視付き転送プール+ MLPNインスタンスクラスプール+ FCCセマンティッククラスxNインスタンス（a）表現学習フレームワークの概要（b）インスタンスとセマンティック分類の相関関係図1：（a）監視されていない視覚表現学習フレームワークの概要。手動ラベルを使用せずに、データセット内のすべての画像を区別しようとするインスタンスレベルの分類子をトレーニングして、監視対象タスクに適切に転送できる識別表現を学習します。（b）インスタンス（監視なし）とセマンティック（監視対象）分類の関係精度。実験では、それらの間に強い正の相関関係が見られます。2018a）、運動量エンコーダー（Heetal。2020; Chen etal。2020c）、大bキャッチサイズ（Chen etal。 2020a、b）、またはシャッフルされたバッチ正規化（BN）（Heetal。2020; Chen etal。2020c）は、負のサンプルの不足を補ったり、情報漏えいの問題を処理したりします（つまり、同じGPU上のサンプルは共有BN統計により、より近くなります）。デュアルブランチアプローチとは異なり、ワンブランチスキーム（パラメトリックインスタンスレベルの分類など）は通常、情報漏えいの問題を回避し、より多くのネガティブサンプルのセットを探索できる可能性があります。 ExemplarCNN（Dosovitskiy etal。2014）およびPIC（Cao etal。2020）はこのカテゴリに属します。それにもかかわらず、GPU計算とメモリが高いため、ar X iv：2 10 2. 04 84 8v 1 [cs .CV] 9 F eb 2 02 1,https://d3i71xaburhd42.cloudfront.net/ae815a8510a7bf888d0ec10c6b50c6f4472bfc57/1-Figure1-1.png
Transformer-Style Relational Reasoning with Dynamic Memory Updating for Temporal Network Modeling,"['Dongkuan Xu', 'Junjie Liang', 'Wei Cheng', 'Hua Wei', 'Haifeng Chen', 'Xiang Zhang']",,,,
Lexically Constrained Neural Machine Translation with Explicit Alignment Guidance,"['Guanhua Chen', 'Yun Chen', 'Victor O.K. Li']",,,,
Capturing Delayed Feedback in Conversion Rate Prediction via Elapsed-Time Sampling,"['Jia-Qi Yang', 'Xiang Li', 'Shuguang Han', 'Tao Zhuang', 'De-Chuan Zhan', 'Xiaoyi Zeng', 'Bin Tong']",,,,
Appearance-Motion Memory Consistency Network for Video Anomaly Detection,"['Ruichu Cai', 'Hao Zhang', 'Wen Liu', 'Shenghua Gao', 'Zhifeng Hao']",,,,
Training Spiking Neural Networks with Accumulated Spiking Flow,"['Hao Wu', 'Yueyi Zhang', 'Wenming Weng', 'Yongting Zhang', 'Zhiwei Xiong', 'Zheng-Jun Zha', 'Xiaoyan Sun', 'Feng Wu']",,,,
Multi-Task Recurrent Modular Networks,"['Dongkuan Xu', 'Wei Cheng', 'Xin Dong', 'Bo Zong', 'Wenchao Yu', 'Jingchao Ni', 'Dongjin Song', 'Xuchao Zhang', 'Haifeng Chen', 'Xiang Zhang']",,,,
Relation-Aware Neighborhood Matching Model for Entity Alignment,"['Yao Zhu', 'Hongzhi Liu', 'Zhonghai Wu', 'Yingpeng Du']",,,,
Finding Sparse Structure for Domain Specific Neural Machine Translation,"['Jianze Liang', 'Chengqi Zhao', 'Mingxuan Wang', 'Xipeng Qiu', 'Lei Li']",https://arxiv.org/abs/2012.10586,"Fine-tuning is a major approach for domain adaptation in Neural Machine Translation (NMT). However, unconstrained fine-tuning requires very careful hyper-parameter tuning otherwise it is easy to fall into over-fitting on the target domain and degradation on the general domain. To mitigate it, we propose PRUNE-TUNE, a novel domain adaptation method via gradual pruning. It learns tiny domain-specific subnetworks for tuning. During adaptation to a new domain, we only tune its corresponding subnetwork. PRUNE-TUNE alleviates the over-fitting and the degradation problem without model modification. Additionally, with no overlapping between domain-specific subnetworks, PRUNE-TUNE is also capable of sequential multi-domain learning. Empirical experiment results show that PRUNE-TUNE outperforms several strong competitors in the target domain test set without the quality degradation of the general domain in both single and multiple domain settings. 1",微調整は、ニューラル機械翻訳（NMT）におけるドメイン適応の主要なアプローチです。ただし、制約のない微調整には、非常に注意深いハイパーパラメータ調整が必要です。そうしないと、ターゲットドメインでの過剰適合や、一般ドメインでの劣化に陥りやすくなります。それを軽減するために、段階的な剪定による新しいドメイン適応方法であるPRUNE-TUNEを提案します。チューニングのための小さなドメイン固有のサブネットワークを学習します。新しいドメインへの適応中は、対応するサブネットワークのみを調整します。 PRUNE-TUNEは、モデルを変更することなく、過剰適合と劣化の問題を軽減します。さらに、ドメイン固有のサブネットワーク間で重複がないため、PRUNE-TUNEは順次マルチドメイン学習も可能です。経験的な実験結果は、PRUNE-TUNEが、単一ドメイン設定と複数ドメイン設定の両方で一般ドメインの品質を低下させることなく、ターゲットドメインテストセットでいくつかの強力な競合他社をしのぐことを示しています。 1,https://d3i71xaburhd42.cloudfront.net/1204920363b8f157506554cdeb08644d2ccaa3fd/2-Figure1-1.png
Distilling Localization for Self-Supervised Representation Learning,"['Nanxuan Zhao', 'Zhirong Wu', 'Rynson W.H. Lau', 'Stephen Lin']",https://arxiv.org/abs/2004.06638,"For high-level visual recognition, self-supervised learning defines and makes use of proxy tasks such as colorization and visual tracking to learn a semantic representation useful for distinguishing objects. In this paper, through visualizing and diagnosing classification errors, we observe that current self-supervised models are ineffective at localizing the foreground object, limiting their ability to extract discriminative high-level features. To address this problem, we propose a data-driven approach for learning invariance to backgrounds. It first estimates foreground saliency in images and then creates augmentations by copy-and-pasting the foreground onto a variety of backgrounds. The learning follows an instance discrimination approach which encourages the features of augmentations from the same image to be similar. In this way, the representation is trained to disregard background content and focus on the foreground. We study a variety of saliency estimation methods, and find that most methods lead to improvements for self-supervised learning. With this approach, strong performance is achieved for self-supervised learning on ImageNet classification, and also for transfer learning to object detection on PASCAL VOC 2007.",高レベルの視覚認識の場合、自己教師あり学習は、色付けや視覚追跡などのプロキシタスクを定義および利用して、オブジェクトを区別するのに役立つ意味表現を学習します。この論文では、分類エラーを視覚化および診断することにより、現在の自己教師ありモデルが前景オブジェクトのローカライズに効果がなく、識別可能な高レベルの特徴を抽出する能力が制限されていることを確認します。この問題に対処するために、背景に対する不変性を学習するためのデータ駆動型アプローチを提案します。最初に画像の前景の顕著性を推定し、次に前景をさまざまな背景にコピーして貼り付けることで拡張を作成します。学習は、同じ画像からの拡張の機能が類似することを奨励するインスタンス識別アプローチに従います。このようにして、表現は背景コンテンツを無視し、前景に焦点を合わせるようにトレーニングされます。さまざまな顕著性推定方法を研究し、ほとんどの方法が自己教師あり学習の改善につながることを発見しました。このアプローチにより、ImageNet分類での自己教師あり学習、およびPASCAL VOC2007でのオブジェクト検出への転移学習で強力なパフォーマンスが達成されます。,https://d3i71xaburhd42.cloudfront.net/f9e9ddec468c1c240a1a8c192e74d485d97205bd/2-Figure1-1.png
Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot Recognition,"['Siteng Huang', 'Min Zhang', 'Yachen Kang', 'Donglin Wang']",https://arxiv.org/abs/2009.04724,"The purpose of few-shot recognition is to recognize novel categories with a limited number of labeled examples in each class. To encourage learning from a supplementary view, recent approaches have introduced auxiliary semantic modalities into effective metric-learning frameworks that aim to learn a feature similarity between training samples (support set) and test samples (query set). However, these approaches only augment the representations of samples with available semantics while ignoring the query set, which loses the potential for the improvement and may lead to a shift between the modalities combination and the pure-visual representation. In this paper, we devise an attributes-guided attention module (AGAM) to utilize human-annotated attributes and learn more discriminative features. This plug-and-play module enables visual contents and corresponding attributes to collectively focus on important channels and regions for support set. And the feature selection is also achieved for query set with only visual information while the attributes are not available. Therefore, representations from both sets are improved in a fine-grained manner. Moreover, an attention alignment mechanism is proposed to distill knowledge from the guidance of attributes to the pure-visual branch for samples without attributes. Extensive experiments and analysis show that our proposed module can significantly improve simple metric-based approaches to achieve state-of-the-art performance on different datasets and settings.",数ショット認識の目的は、各クラスでラベル付けされた例の数が限られている新しいカテゴリを認識することです。補足的な観点からの学習を促進するために、最近のアプローチでは、トレーニングサンプル（サポートセット）とテストサンプル（クエリセット）の間の機能の類似性を学習することを目的とした効果的なメトリック学習フレームワークに補助的なセマンティックモダリティが導入されています。ただし、これらのアプローチは、クエリセットを無視して、使用可能なセマンティクスでサンプルの表現を拡張するだけであり、改善の可能性を失い、モダリティの組み合わせと純粋な視覚的表現の間のシフトにつながる可能性があります。この論文では、人間が注釈を付けた属性を利用し、より識別力のある機能を学習するために、属性誘導注意モジュール（AGAM）を考案します。このプラグアンドプレイモジュールを使用すると、ビジュアルコンテンツと対応する属性を、サポートセットの重要なチャネルと地域にまとめて集中させることができます。また、機能の選択は、属性が使用できないときに視覚情報のみを使用するクエリセットに対しても実行されます。したがって、両方のセットからの表現がきめ細かく改善されます。さらに、属性のガイダンスから属性のないサンプルの純粋な視覚的ブランチに知識を抽出するために、注意調整メカニズムが提案されています。広範な実験と分析により、提案されたモジュールは、さまざまなデータセットと設定で最先端のパフォーマンスを実現するための単純なメトリックベースのアプローチを大幅に改善できることが示されています。,https://d3i71xaburhd42.cloudfront.net/e14410b12732e5903b6bd1fe714e653e9b2c2936/1-Figure1-1.png
One for More: Selecting Generalizable Samples for Generalizable ReID Model,"['Enwei Zhang', 'Xinyang Jiang', 'Hao Cheng', 'Ancong Wu', 'Fufu Yu', 'Ke Li', 'Xiaowei Guo', 'Feng Zheng', 'Wei-Shi Zheng', 'Xing Sun']",https://arxiv.org/abs/2012.05475,"Current training objectives of existing person Re-IDentification (ReID) models only ensure that the loss of the model decreases on selected training batch, with no regards to the performance on samples outside the batch. It will inevitably cause the model to over-fit the data in the dominant position (e.g., head data in imbalanced class, easy samples or noisy samples). %We call the sample that updates the model towards generalizing on more data a generalizable sample. The latest resampling methods address the issue by designing specific criterion to select specific samples that trains the model generalize more on certain type of data (e.g., hard samples, tail data), which is not adaptive to the inconsistent real world ReID data distributions. Therefore, instead of simply presuming on what samples are generalizable, this paper proposes a one-for-more training objective that directly takes the generalization ability of selected samples as a loss function and learn a sampler to automatically select generalizable samples. More importantly, our proposed one-for-more based sampler can be seamlessly integrated into the ReID training framework which is able to simultaneously train ReID models and the sampler in an end-to-end fashion. The experimental results show that our method can effectively improve the ReID model training and boost the performance of ReID models.",既存の人の再識別（ReID）モデルの現在のトレーニング目標は、バッチ外のサンプルのパフォーマンスに関係なく、選択したトレーニングバッチでモデルの損失が減少することを保証するだけです。それは必然的に、モデルが支配的な位置のデータに過剰に適合する原因になります（たとえば、不均衡なクラスのヘッドデータ、簡単なサンプル、またはノイズの多いサンプル）。,https://d3i71xaburhd42.cloudfront.net/d3af32e0c614e7d141997c900fd3e7f9dc147eed/1-Figure1-1.png
Deep Semantic Dictionary Learning for Multi-Label Image Classification,"['Fengtao Zhou', 'Sheng Huang', 'Yun Xing']",https://arxiv.org/abs/2012.12509,"Compared with single-label image classification, multi-label image classification is more practical and challenging. Some recent studies attempted to leverage the semantic information of categories for improving multi-label image classification performance. However, these semantic-based methods only take semantic information as type of complements for visual representation without further exploitation. In this paper, we present a innovative path towards the solution of the multi-label image classification which considers it as a dictionary learning task. A novel end-to-end model named Deep Semantic Dictionary Learning (DSDL) is designed. In DSDL, an auto-encoder is applied to generate the semantic dictionary from class-level semantics and then such dictionary is utilized for representing the visual features extracted by Convolutional Neural Network (CNN) with label embeddings. The DSDL provides a simple but elegant way to exploit and reconcile the label, semantic and visual spaces simultaneously via conducting the dictionary learning among them. Moreover, inspired by iterative optimization of traditional dictionary learning, we further devise a novel training strategy named Alternately Parameters Update Strategy (APUS) for optimizing DSDL, which alteratively optimizes the representation coefficients and the semantic dictionary in forward and backward propagation. Extensive experimental results on three popular benchmarks demonstrate that our method achieves promising performances in comparison with the state-of-the-arts. Our codes and models are available at https://github.com/ZFT-CQU/DSDL.",シングルラベル画像分類と比較して、マルチラベル画像分類はより実用的で困難です。最近のいくつかの研究では、マルチラベル画像分類のパフォーマンスを向上させるために、カテゴリのセマンティック情報を活用しようとしました。ただし、これらのセマンティックベースのメソッドは、セマンティック情報を視覚的表現の補完のタイプとしてのみ取得し、さらに活用することはありません。この論文では、それを辞書学習タスクと見なすマルチラベル画像分類の解決に向けた革新的な道筋を提示します。 Deep Semantic Dictionary Learning（DSDL）という名前の新しいエンドツーエンドモデルが設計されています。 DSDLでは、オートエンコーダーを適用してクラスレベルのセマンティクスからセマンティック辞書を生成し、そのような辞書を使用して、畳み込みニューラルネットワーク（CNN）によって抽出された視覚的特徴をラベル埋め込みで表現します。 DSDLは、それらの間で辞書学習を実行することにより、ラベル、セマンティック、およびビジュアルスペースを同時に活用および調整するためのシンプルでエレガントな方法を提供します。さらに、従来の辞書学習の反復最適化に触発されて、DSDLを最適化するためのAlternative Parameters Update Strategy（APUS）という名前の新しいトレーニング戦略をさらに考案します。これは、順方向および逆方向の伝播で表現係数とセマンティック辞書を交互に最適化します。 3つの人気のあるベンチマークでの広範な実験結果は、私たちの方法が最先端技術と比較して有望なパフォーマンスを達成することを示しています。コードとモデルはhttps://github.com/ZFT-CQU/DSDLで入手できます。,https://d3i71xaburhd42.cloudfront.net/a3c07082b420c9d8b4864124b68ae7b256a0ae91/1-Figure1-1.png
Meta-Learning Effective Exploration Strategies for Contextual Bandits,"['Amr Sharaf', 'Hal Daume']",,,,
Unsupervised 3D Learning for Shape Analysis via Multiresolution Instance Discrimination,"['Peng-Shuai Wang', 'Yuqi Yang', 'Qianfang Zou', 'Zhirong Wu', 'Yang Liu', 'Xin Tong']",https://arxiv.org/abs/2008.01068,"Although unsupervised feature learning has demonstrated its advantages to reducing the workload of data labeling and network design in many fields, existing unsupervised 3D learning methods still cannot offer a generic network for various shape analysis tasks with competitive performance to supervised methods. In this paper, we propose an unsupervised method for learning a generic and efficient shape encoding network for different shape analysis tasks. The key idea of our method is to jointly encode and learn shape and point features from unlabeled 3D point clouds. For this purpose, we adapt HR-Net to octree-based convolutional neural networks for jointly encoding shape and point features with fused multiresolution subnetworks and design a simple-yet-efficient \emph{Multiresolution Instance Discrimination} (MID) loss for jointly learning the shape and point features. Our network takes a 3D point cloud as input and output both shape and point features. After training, the network is concatenated with simple task-specific back-end layers and fine-tuned for different shape analysis tasks. We evaluate the efficacy and generality of our method and validate our network and loss design with a set of shape analysis tasks, including shape classification, semantic shape segmentation, as well as shape registration tasks. With simple back-ends, our network demonstrates the best performance among all unsupervised methods and achieves competitive performance to supervised methods, especially in tasks with a small labeled dataset. For fine-grained shape segmentation, our method even surpasses existing supervised methods by a large margin.",教師なし特徴学習は、多くの分野でデータのラベル付けとネットワーク設計の作業負荷を軽減する利点を示していますが、既存の教師なし3D学習方法では、教師あり方法と競合するパフォーマンスを備えたさまざまな形状分析タスク用の汎用ネットワークを提供できません。この論文では、さまざまな形状分析タスクのための一般的で効率的な形状エンコーディングネットワークを学習するための教師なし方法を提案します。私たちの方法の重要なアイデアは、ラベルのない3D点群から形状と点の特徴を共同でエンコードして学習することです。この目的のために、HR-Netを八分木ベースの畳み込みニューラルネットワークに適合させて、融合された多重解像度サブネットワークで形状と点の特徴を共同でエンコードし、形状と点の特徴を共同で学習するためのシンプルでありながら効率的な多重解像度インスタンス識別（MID）損失を設計します。私たちのネットワークは、形状とポイントの両方の特徴を入力および出力するために3Dポイントクラウドを採用しています。トレーニング後、ネットワークは単純なタスク固有のバックエンドレイヤーと連結され、さまざまな形状分析タスク用に微調整されます。メソッドの有効性と一般性を評価し、形状分類、セマンティック形状セグメンテーション、形状登録タスクなどの一連の形状分析タスクを使用して、ネットワークと損失の設計を検証します。シンプルなバックエンドを使用して、私たちのネットワークは、すべての教師なしメソッドの中で最高のパフォーマンスを示し、特に小さなラベル付きデータセットを使用するタスクで、教師ありメソッドに対して競争力のあるパフォーマンスを実現します。きめ細かい形状セグメンテーションの場合、私たちの方法は、既存の教師あり方法を大幅に上回っています。,https://d3i71xaburhd42.cloudfront.net/b91c9c9beeaa0760e383fe702e6df10c51eb0a4c/1-Figure1-1.png
Provable Benefits of Overparameterization in Model Compression: From Double Descent to Pruning Neural Networks,"['Xiangyu Chang', 'Yingcong Li', 'Samet Oymak', 'Christos Thrampoulidis']",,,,
Learning Semantic Context from Normal Samples for Unsupervised Anomaly Detection,"['Xudong Yan', 'Huaidong Zhang', 'Xuemiao Xu', 'Xiaowei Hu', 'Pheng-Ann Heng']",,,,
Diagnose Like a Pathologist: Weakly-Supervised Pathologist-Tree Network for Slide-Level Immunohistochemical Scoring,"['Zhen Chen', 'Jun Zhang', 'Shuanlong Che', 'Junzhou Huang', 'Xiao Han', 'Yixuan Yuan']",,,,
Bayes DistNet - A Robust Neural Network for Algorithm Runtime Distribution Predictions,"['Jake Tuero', 'Michael Buro']",https://arxiv.org/abs/2012.07197,"Randomized algorithms are used in many state-of-the-art solvers for constraint satisfaction problems (CSP) and Boolean satisfiability (SAT) problems. For many of these problems, there is no single solver which will dominate others. Having access to the underlying runtime distributions (RTD) of these solvers can allow for better use of algorithm selection, algorithm portfolios, and restart strategies. Previous state-of-the-art methods directly try to predict a fixed parametric distribution that the input instance follows. In this paper, we extend RTD prediction models into the Bayesian setting for the first time. This new model achieves robust predictive performance in the low observation setting, as well as handling censored observations. This technique also allows for richer representations which cannot be achieved by the classical models which restrict their output representations. Our model outperforms the previous state-of-the-art model in settings in which data is scarce, and can make use of censored data such as lower bound time estimates, where that type of data would otherwise be discarded. It can also quantify its uncertainty in its predictions, allowing for algorithm portfolio models to make better informed decisions about which algorithm to run on a particular instance.",ランダム化アルゴリズムは、制約充足問題（CSP）およびブール充足可能性（SAT）問題の多くの最先端のソルバーで使用されます。これらの問題の多くでは、他の問題を支配する単一のソルバーはありません。これらのソルバーの基礎となるランタイム分布（RTD）にアクセスできると、アルゴリズムの選択、アルゴリズムポートフォリオ、および再起動戦略をより適切に使用できます。以前の最先端の方法は、入力インスタンスが従う固定パラメトリック分布を直接予測しようとします。この論文では、RTD予測モデルを初めてベイズ設定に拡張します。この新しいモデルは、打ち切られた観測を処理するだけでなく、低い観測設定で堅牢な予測パフォーマンスを実現します。この手法では、出力表現を制限する従来のモデルでは実現できない、より豊かな表現も可能になります。私たちのモデルは、データが不足している設定で以前の最先端モデルよりも優れており、そのタイプのデータが破棄される下限時間の見積もりなどの打ち切りデータを利用できます。また、予測の不確実性を定量化できるため、アルゴリズムポートフォリオモデルは、特定のインスタンスで実行するアルゴリズムについて、十分な情報に基づいた決定を下すことができます。,https://d3i71xaburhd42.cloudfront.net/07f4a05faca7e8b7879d7e46820db538434a7e35/6-Figure1-1.png
PASSLEAF: A Pool-Based Semi-Supervised Learning Framework for Uncertain Knowledge Graph Embedding,"['Zhu-Mu Chen', 'Mi-Yen Yeh', 'Tei-Wei Kuo']",,,,
Disentangled Representation Learning in Heterogeneous Information Network for Large-Scale Android Malware Detection in the COVID-19 Era and Beyond,"['Shifu Hou', 'Yujie Fan', 'Mingxuan Ju', 'Yanfang Ye', 'Wenqiang Wan', 'Kui Wang', 'Yinming Mei', 'Qi Xiong', 'Fudong Shao']",,,,
LightXML: Transformer with Dynamic Negative Sampling for High-Performance Extreme Multi-Label Text Classification,"['Ting Jiang', 'Deqing Wang', 'Leilei Sun', 'Huayi Yang', 'Zhengyang Zhao', 'Fuzhen Zhuang']",https://arxiv.org/abs/2101.03305,"Extreme Multi-label text Classification (XMC) is a task of finding the most relevant labels from a large label set. Nowadays deep learning-based methods have shown significant success in XMC. However, the existing methods (e.g., AttentionXML and X-Transformer etc) still suffer from 1) combining several models to train and predict for one dataset, and 2) sampling negative labels statically during the process of training label ranking model, which reduces both the efficiency and accuracy of the model. To address the above problems, we proposed LightXML, which adopts endto-end training and dynamic negative labels sampling. In LightXML, we use generative cooperative networks to recall and rank labels, in which label recalling part generates negative and positive labels, and label ranking part distinguishes positive labels from these labels. Through these networks, negative labels are sampled dynamically during label ranking part training by feeding with the same text representation. Extensive experiments show that LightXML outperforms state-of-the-art methods in five extreme multi-label datasets with much smaller model size and lower computational complexity. In particular, on the Amazon dataset with 670K labels, LightXML can reduce the model size up to 72% compared to AttentionXML. Our code is available at http://github.com/kongds/LightXML.",極端なマルチラベルテキスト分類（XMC）は、大きなラベルセットから最も関連性の高いラベルを見つけるタスクです。今日、ディープラーニングベースの方法はXMCで大きな成功を収めています。ただし、既存の方法（AttentionXMLやX-Transformerなど）は、1）複数のモデルを組み合わせて1つのデータセットをトレーニングおよび予測すること、および2）ラベルランキングモデルのトレーニングプロセス中にネガティブラベルを静的にサンプリングすることで、両方が減少するという問題があります。モデルの効率と精度。上記の問題に対処するために、エンドツーエンドのトレーニングと動的なネガティブラベルサンプリングを採用するLightXMLを提案しました。 LightXMLでは、生成協調ネットワークを使用してラベルをリコールおよびランク付けします。ラベルリコール部分はネガティブラベルとポジティブラベルを生成し、ラベルランク付け部分はポジティブラベルとこれらのラベルを区別します。これらのネットワークを介して、同じテキスト表現をフィードすることにより、ラベルランキングパーツトレーニング中にネガティブラベルが動的にサンプリングされます。広範な実験により、LightXMLは、モデルサイズがはるかに小さく、計算の複雑さが低い5つの極端なマルチラベルデータセットで最先端の方法よりも優れていることが示されています。特に、670KラベルのAmazonデータセットでは、LightXMLはモデルサイズを最大72まで縮小できます。,https://d3i71xaburhd42.cloudfront.net/a0cd055650dc69d671b52b7f979d3f1bbfacda4b/3-Figure1-1.png
MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records,"['Zhen Xu', 'David So', 'Andrew M Dai']",https://arxiv.org/abs/2102.02340,"One important challenge of applying deep learning to electronic health records (EHR) is the complexity of their multimodal structure. EHR usually contains a mixture of structured (codes) and unstructured (free-text) data with sparse and irregular longitudinal features – all of which doctors utilize when making decisions. In the deep learning regime, determining how different modality representations should be fused together is a difficult problem, which is often addressed by handcrafted modeling and intuition. In this work, we extend state-of-the-art neural architecture search (NAS) methods and propose MUltimodal Fusion Architecture SeArch (MUFASA) to simultaneously search across multimodal fusion strategies and modality-specific architectures for the first time. We demonstrate empirically that our MUFASA method outperforms established unimodal NAS on public EHR data with comparable computation costs. In addition, MUFASA produces architectures that outperform Transformer and Evolved Transformer. Compared with these baselines on CCS diagnosis code prediction, our discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate the ability to generalize to other EHR tasks. Studying our top architecture in depth, we provide empirical evidence that MUFASA’s improvements are derived from its ability to both customize modeling for each data modality and find effective fusion strategies.",電子健康記録（EHR）にディープラーニングを適用する際の重要な課題の1つは、マルチモーダル構造の複雑さです。 EHRには通常、構造化（コード）データと非構造化（フリーテキスト）データが混在しており、医師が意思決定を行う際に利用する、まばらで不規則な縦方向の特徴があります。ディープラーニング体制では、さまざまなモダリティ表現をどのように融合させるかを決定することは難しい問題であり、多くの場合、手作りのモデリングと直感によって対処されます。この作業では、最先端のニューラルアーキテクチャ検索（NAS）メソッドを拡張し、マルチモーダルフュージョン戦略とモダリティ固有のアーキテクチャを初めて同時に検索するMUltimodal Fusion Architecture SeArch（MUFASA）を提案します。私たちのMUFASAメソッドは、同等の計算コストで、公開EHRデータで確立されたユニモーダルNASよりも優れていることを経験的に示しています。さらに、MUFASAは、TransformerおよびEvolvedTransformerよりも優れたアーキテクチャを提供します。 CCS診断コード予測に関するこれらのベースラインと比較して、発見されたモデルはトップ5の想起を0.88から0.91に改善し、他のEHRタスクに一般化する能力を示しています。最上位のアーキテクチャを詳細に調査することで、MUFASAの改善は、各データモダリティのモデリングをカスタマイズし、効果的な融合戦略を見つける能力に由来するという経験的証拠を提供します。,https://d3i71xaburhd42.cloudfront.net/8aa8b3f5cf04fb4188d02a52a8b08b12ee847bd4/1-Figure1-1.png
VisualMRC: Machine Reading Comprehension on Document Images,"['Ryota Tanaka', 'Kyosuke Nishida', 'Sen Yoshida']",https://arxiv.org/abs/2101.11272,"Recent studies on machine reading comprehension have focused on text-level understanding but have not yet reached the level of human understanding of the visual layout and content of real-world documents. In this study, we introduce a new visual machine reading comprehension dataset, named VisualMRC, wherein given a question and a document image, a machine reads and comprehends texts in the image to answer the question in natural language. Compared with existing visual question answering (VQA) datasets that contain texts in images, VisualMRC focuses more on developing natural language understanding and generation abilities. It contains 30,000+ pairs of a question and an abstractive answer for 10,000+ document images sourced from multiple domains of webpages. We also introduce a new model that extends existing sequence-to-sequence models, pre-trained with largescale text corpora, to take into account the visual layout and content of documents. Experiments with VisualMRC show that this model outperformed the base sequence-to-sequence models and a state-of-the-art VQA model. However, its performance is still below that of humans on most automatic evaluation metrics. The dataset will facilitate research aimed at connecting vision and language understanding.","機械の読解に関する最近の研究は、テキストレベルの理解に焦点を合わせていますが、実際の文書の視覚的なレイアウトと内容についての人間の理解のレベルにはまだ達していません。この研究では、VisualMRCという名前の新しいビジュアルマシン読解データセットを紹介します。このデータセットでは、質問とドキュメントイメージが与えられると、マシンが画像内のテキストを読み取って理解し、自然言語で質問に答えます。画像にテキストを含む既存の視覚的質問応答（VQA）データセットと比較して、VisualMRCは自然言語理解と生成能力の開発に重点を置いています。これには、Webページの複数のドメインから供給された10,000以上のドキュメント画像に対する30,000以上の質問と抽象的な回答のペアが含まれています。また、ドキュメントの視覚的なレイアウトとコンテンツを考慮に入れるために、大規模なテキストコーパスで事前トレーニングされた既存のシーケンス間モデルを拡張する新しいモデルを紹介します。 VisualMRCを使用した実験では、このモデルが基本のシーケンス間モデルおよび最先端のVQAモデルよりも優れていることが示されています。ただし、そのパフォーマンスは、ほとんどの自動評価メトリックで依然として人間のパフォーマンスを下回っています。データセットは、視覚と言語理解を結びつけることを目的とした研究を促進します。",https://d3i71xaburhd42.cloudfront.net/af0d83579747249b80c9a3970f2da5a23dcdd4fe/1-Figure1-1.png
HiGAN: Handwriting Imitation Conditioned on Arbitrary-Length Texts and Disentangled Styles,"['Ji Gan', 'Weiqiang Wang']",,,,
Latent Independent Excitation for Generalizable Sensor-Based Cross-Person Activity Recognition,"['Hangwei Qian', 'Sinno Pan', 'Chunyan Miao']",,,,
Algebra of Modular Systems: Containment and Equivalence,"['Andrei Bulatov', 'Eugenia Ternovska']",,,,
Multi-SpectroGAN: High-Diversity and High-Fidelity Spectrogram Generation with Adversarial Style Combination for Speech Synthesis,"['Sang-Hoon Lee', 'Hyun-Wook Yoon', 'Hyeong-Rae Noh', 'Ji-Hoon Kim', 'Seong-Whan Lee']",https://arxiv.org/abs/2012.07267,"While generative adversarial networks (GANs) based neural text-to-speech (TTS) systems have shown significant improvement in neural speech synthesis, there is no TTS system to learn to synthesize speech from text sequences with only adversarial feedback. Because adversarial feedback alone is not sufficient to train the generator, current models still require the reconstruction loss compared with the ground-truth and the generated mel-spectrogram directly. In this paper, we present Multi-SpectroGAN (MSG), which can train the multi-speaker model with only the adversarial feedback by conditioning a self-supervised hidden representation of the generator to a conditional discriminator. This leads to better guidance for generator training. Moreover, we also propose adversarial style combination (ASC) for better generalization in the unseen speaking style and transcript, which can learn latent representations of the combined style embedding from multiple mel-spectrograms. Trained with ASC and feature matching, the MSG synthesizes a high-diversity mel-spectrogram by controlling and mixing the individual speaking styles (e.g., duration, pitch, and energy). The result shows that the MSG synthesizes a high-fidelity mel-spectrogram, which has almost the same naturalness MOS score as the ground-truth mel-spectrogram.",生成的敵対的ネットワーク（GAN）ベースのニューラルテキスト読み上げ（TTS）システムは、ニューラル音声合成の大幅な改善を示していますが、敵対的フィードバックのみでテキストシーケンスから音声を合成することを学習するTTSシステムはありません。敵対的なフィードバックだけではジェネレーターをトレーニングするのに十分ではないため、現在のモデルでは、グラウンドトゥルースおよび生成されたメルスペクトログラムと比較して、再構成損失が必要です。この論文では、Multi-SpectroGAN（MSG）を紹介します。これは、ジェネレータの自己監視非表示表現を条件付き弁別器に条件付けすることにより、敵対的なフィードバックのみでマルチスピーカーモデルをトレーニングできます。これは、発電機トレーニングのより良いガイダンスにつながります。さらに、複数のメルスペクトログラムから埋め込まれた組み合わせスタイルの潜在的表現を学習できる、目に見えない話し方のスタイルとトランスクリプトの一般化を改善するために、敵対スタイルの組み合わせ（ASC）も提案します。 ASCと機能マッチングでトレーニングされたMSGは、個々の話し方（持続時間、ピッチ、エネルギーなど）を制御および混合することにより、多様性の高いメルスペクトログラムを合成します。結果は、MSGが忠実度の高いメルスペクトログラムを合成することを示しています。これは、グラウンドトゥルースメルスペクトログラムとほぼ同じ自然性MOSスコアを持っています。,https://d3i71xaburhd42.cloudfront.net/2989bdc41227742becd0490ac05fdad2bdfec1f4/2-Figure1-1.png
Rethinking Object Detection in Retail Stores,"['Cai YuanQiang', 'Longyin Wen', 'Libo Zhang', 'Dawei Du', 'Weiqiang Wang']",,,,
KG-BART: Knowledge Graph-Augmented Bart for Generative Commonsense Reasoning,"['Ye Liu', 'Yao Wan', 'Lifang He', 'Hao Peng', 'Philip S Yu']",https://arxiv.org/abs/2009.12677,"Generative commonsense reasoning which aims to empower machines to generate sentences with the capacity of reasoning over a set of concepts is a critical bottleneck for text generation. Even the state-of-the-art pre-trained language generation models struggle at this task and often produce implausible and anomalous sentences. One reason is that they rarely consider incorporating the knowledge graph which can provide rich relational information among the commonsense concepts. To promote the ability of commonsense reasoning for text generation, we propose a novel knowledge graphaugmented pre-trained language generation model KG-BART, which encompasses the complex relations of concepts through the knowledge graph and produces more logical and natural sentences as output. Moreover, KG-BART can leverage the graph attention to aggregate the rich concept semantics that enhances the model generalization on unseen concept sets. Experiments on benchmark CommonGen dataset verify the effectiveness of our proposed approach by comparing with several strong pre-trained language generation models, particularly KG-BART outperforms BART by 15.98%, 17.49%, in terms of BLEU-3, 4. Moreover, we also show that the generated context by our model can work as background scenarios to benefit downstream commonsense QA tasks.",一連の概念を推論する能力を備えた文を生成するためにマシンを強化することを目的とした生成的常識推論は、テキスト生成の重大なボトルネックです。最先端の事前訓練された言語生成モデルでさえ、このタスクに苦労し、しばしば信じがたい異常な文を生成します。その理由の1つは、常識的な概念の中で豊富な関係情報を提供できるナレッジグラフを組み込むことをほとんど検討していないことです。テキスト生成の常識的推論の能力を促進するために、知識グラフを通じて概念の複雑な関係を包含し、出力としてより論理的で自然な文を生成する、新しい知識グラフ拡張事前トレーニング言語生成モデルKG-BARTを提案します。さらに、KG-BARTはグラフの注意を活用して、目に見えない概念セットのモデルの一般化を強化する豊富な概念のセマンティクスを集約できます。ベンチマークCommonGenデータセットでの実験は、いくつかの強力な事前トレーニング済み言語生成モデルと比較することにより、提案されたアプローチの有効性を検証します。特にKG-BARTはBARTより15.98優れています。,https://d3i71xaburhd42.cloudfront.net/baa8f524c82735f174b8d1ab512ac5750146d67e/1-Figure1-1.png
EMLight: Lighting Estimation via Spherical Distribution Approximation,"['Fangneng Zhan', 'Changgong Zhang', 'Yingchen Yu', 'Yuan Chang', 'Shijian Lu', 'Feiying Ma', 'Xuansong Xie']",https://arxiv.org/abs/2012.11116,"Illumination estimation from a single image is critical in 3D rendering and it has been investigated extensively in the computer vision and computer graphic research community. On the other hand, existing works estimate illumination by either regressing light parameters or generating illumination maps that are often hard to optimize or tend to produce inaccurate predictions. We propose Earth Mover’s Light (EMLight), an illumination estimation framework that leverages a regression network and a neural projector for accurate illumination estimation. We decompose the illumination map into spherical light distribution, light intensity and the ambient term, and define the illumination estimation as a parameter regression task for the three illumination components. Motivated by the Earth Mover’s distance, we design a novel spherical mover’s loss that guides to regress light distribution parameters accurately by taking advantage of the subtleties of spherical distribution. Under the guidance of the predicted spherical distribution, light intensity and ambient term, the neural projector synthesizes panoramic illumination maps with realistic light frequency. Extensive experiments show that EMLight achieves accurate illumination estimation and the generated relighting in 3D object embedding exhibits superior plausibility and fidelity as compared with state-of-the-art methods.",単一の画像からの照明推定は3Dレンダリングで重要であり、コンピュータービジョンおよびコンピューターグラフィックスの研究コミュニティで広く調査されています。一方、既存の研究では、光パラメータを回帰するか、最適化が難しいか、不正確な予測を生成する傾向がある照明マップを生成することによって、照明を推定します。正確な照明推定のために回帰ネットワークとニューラルプロジェクターを活用する照明推定フレームワークであるEarthMovers Light（EMLight）を提案します。照明マップを球面配光、光強度、周囲項に分解し、照明推定を3つの照明コンポーネントのパラメーター回帰タスクとして定義します。 Earth Moverの距離に動機付けられて、球形分布の微妙さを利用することにより、光分布パラメーターを正確に回帰するようにガイドする新しい球形ムーバー損失を設計します。予測された球面分布、光強度、および周囲項のガイダンスの下で、ニューラルプロジェクターは現実的な光周波数でパノラマ照明マップを合成します。広範な実験により、EMLightは正確な照明推定を実現し、3Dオブジェクト埋め込みで生成された再照明は、最先端の方法と比較して優れた妥当性と忠実度を示すことが示されています。,https://d3i71xaburhd42.cloudfront.net/9e4e4c56554f5e8e6c43c0475fb72a03f5f2844a/1-Figure1-1.png
Sequential End-to-End Network for Efficient Person Search,"['Zhengjia Li', 'Duoqian Miao']",,,,
Gene Regulatory Network Inference Using 3D Convolutional Neural Network,"['Yue Fan', 'Xiuli Ma']",,,,
A General Class of Transfer Learning Regression without Implementation Cost,"['Shunya Minami', 'Song Liu', 'Stephen Wu', 'Kenji Fukumizu', 'Ryo Yoshida']",,,,
SeCo: Exploring Sequence Supervision for Unsupervised Representation Learning,"['Ting Yao', 'Yiheng Zhang', 'Zhaofan Qiu', 'Yingwei Pan', 'Tao Mei']",,,,
Does Head Label Help for Long-Tailed Multi-Label Text Classification,"['Lin Xiao', 'Xiangliang Zhang', 'Chi Huang', 'Mingyang Song', 'Liping Jing']",,,,
Aggregated Multi-GANs for Controlled 3D Human Motion Prediction,"['Zhenguang Liu', 'Kedi Lyu', 'Shuang Wu', 'Haipeng Chen', 'Yanbin Hao', 'Shouling Ji']",,,,
Label Confusion Learning to Enhance Text Classification Models,"['Biyang Guo', 'Songqiao Han', 'Xiao Han', 'Hailiang Huang', 'Ting Lu']",,,,
CPCGAN: A Controllable 3D Point Cloud Generative Adversarial Network with Semantic Label Generating,"['Ximing Yang', 'Yuan Wu', 'Kaiyi Zhang', 'Cheng Jin']",,,,
Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification,"['Siyuan Cheng', 'Yingqi Liu', 'Shiqing Ma', 'Xiangyu Zhang']",,,,
Interpreting Deep Neural Networks with Relative Sectional Propagation by Analyzing Comparative Gradients and Hostile Activations,"['Woo Jeoung Nam', 'Jaesik Choi', 'Seong-Whan Lee']",,,,
Efficient Folded Attention for Medical Image Reconstruction and Segmentation,"['Hang Zhang', 'Jinwei Zhang', 'Rongguang Wang', 'Qihao Zhang', 'Pascal Spincemaille', 'Thanh D. Nguyen', 'Yi Wang']",,,,
Uncertainty-Matching Graph Neural Networks to Defend against Poisoning Attacks,"['Uday Shankar Shanthamallu', 'Jayaraman J. Thiagarajan', 'Andreas Spanias']",https://arxiv.org/abs/2009.14455,"Graph Neural Networks (GNNs), a generalization of neural networks to graph-structured data, are often implemented using message passes between entities of a graph. While GNNs are effective for node classification, link prediction and graph classification, they are vulnerable to adversarial attacks, i.e., a small perturbation to the structure can lead to a non-trivial performance degradation. In this work, we propose Uncertainty Matching GNN (UM-GNN), that is aimed at improving the robustness of GNN models, particularly against poisoning attacks to the graph structure, by leveraging epistemic uncertainties from the message passing framework. More specifically, we propose to build a surrogate predictor that does not directly access the graph structure, but systematically extracts reliable knowledge from a standard GNN through a novel uncertainty-matching strategy. Interestingly, this uncoupling makes UM-GNN immune to evasion attacks by design, and achieves significantly improved robustness against poisoning attacks. Using empirical studies with standard benchmarks and a suite of global and target attacks, we demonstrate the effectiveness of UM-GNN, when compared to existing baselines including the state-of-the-art robust GCN.",グラフ構造化データへのニューラルネットワークの一般化であるグラフニューラルネットワーク（GNN）は、多くの場合、グラフのエンティティ間のメッセージパスを使用して実装されます。 GNNはノード分類、リンク予測、グラフ分類に効果的ですが、敵対的な攻撃に対して脆弱です。つまり、構造への小さな摂動は、重要なパフォーマンスの低下につながる可能性があります。この作業では、メッセージパッシングフレームワークからの認識論的不確実性を活用することにより、特にグラフ構造へのポイズニング攻撃に対するGNNモデルの堅牢性を向上させることを目的とした不確実性マッチングGNN（UM-GNN）を提案します。より具体的には、グラフ構造に直接アクセスしないが、新しい不確実性マッチング戦略を通じて標準GNNから信頼できる知識を体系的に抽出する代理予測子を構築することを提案します。興味深いことに、この分離により、UM-GNNは設計上回避攻撃の影響を受けなくなり、中毒攻撃に対する堅牢性が大幅に向上します。標準ベンチマークと一連のグローバルおよびターゲット攻撃を使用した実証研究を使用して、最先端の堅牢なGCNを含む既存のベースラインと比較した場合のUM-GNNの有効性を示します。,https://d3i71xaburhd42.cloudfront.net/400389ca8b23ff77fa9ee96717fe6447df7469af/3-Figure1-1.png
DEAR: Deep Reinforcement Learning for Online Advertising Impression in Recommender Systems,"['Xiangyu Zhao', 'Changsheng Gu', 'Haoshenglun Zhang', 'Xiwang Yang', 'Xiaobing Liu', 'Jiliang Tang ', 'Hui Liu']",,,,
"Read, Retrospect, Select: An MRC Framework to Short Text Entity Linking","['Yingjie Gu', 'Xiaoye Qu', 'Zhefeng Wang', 'Baoxing Huai', 'Nicholas Jing Yuan', 'Xiaolin Gui']",https://arxiv.org/abs/2101.02394,"Entity linking (EL) for the rapidly growing short text (e.g. search queries and news titles) is critical to industrial applications. Most existing approaches relying on adequate context for long text EL are not effective for the concise and sparse short text. In this paper, we propose a novel framework called Multi-turn Multiple-choice Machine reading comprehension (M3) to solve the short text EL from a new perspective: a query is generated for each ambiguous mention exploiting its surrounding context, and an option selection module is employed to identify the golden entity from candidates using the query. In this way, M3 framework sufficiently interacts limited context with candidate entities during the encoding process, as well as implicitly considers the dissimilarities inside the candidate bunch in the selection stage. In addition, we design a two-stage verifier incorporated into M3 to address the commonly existed unlinkable problem in short text. To further consider the topical coherence and interdependence among referred entities, M3 leverages a multi-turn fashion to deal with mentions in a sequence manner by retrospecting historical cues. Evaluation shows that our M3 framework achieves the state-of-the-art performance on five Chinese and English datasets for the real-world short text EL.",急速に成長している短いテキスト（検索クエリやニュースタイトルなど）のエンティティリンキング（EL）は、産業用アプリケーションにとって重要です。長いテキストELの適切なコンテキストに依存するほとんどの既存のアプローチは、簡潔でまばらな短いテキストには効果的ではありません。この論文では、新しい視点から短いテキストELを解決するために、マルチターン多肢選択式機械読解（M3）と呼ばれる新しいフレームワークを提案します。クエリは、周囲のコンテキストを利用してあいまいな言及ごとに生成され、オプションが選択されます。モジュールは、クエリを使用して候補からゴールデンエンティティを識別するために使用されます。このようにして、M3フレームワークは、エンコードプロセス中に限定されたコンテキストを候補エンティティと十分に相互作用し、選択段階で候補バンチ内の非類似性を暗黙的に考慮します。さらに、M3に組み込まれた2段階のベリファイアを設計して、短いテキストで一般的に存在するリンクできない問題に対処します。参照されたエンティティ間のトピックの一貫性と相互依存性をさらに検討するために、M3はマルチターン方式を活用して、過去の手がかりを振り返ることにより、言及を順番に処理します。評価の結果、M3フレームワークは、実際のショートテキストELの5つの中国語と英語のデータセットで最先端のパフォーマンスを実現していることがわかりました。,https://d3i71xaburhd42.cloudfront.net/14c121c8975628653cb635a628aa0d38795437ee/1-Figure1-1.png
Text-Guided Graph Neural Networks for Referring 3D Instance Segmentation,"['Pin-Hao Huang', 'Han-Hung Lee', 'Hwann-Tzong Chen', 'Tyng-Luh Liu']",,,,
Learning Disentangled Representation for Fair Facial Attribute Classification via Fairness-Aware information Alignment,"['Sungho Park', 'Sunhee Hwang', 'Dohyung Kim', 'Hyeran Byun']",,,,
AI-Assisted Scientific Data Collection with Iterative Human Feedback,"['Travis Mandel', 'James Boyd', 'Sebastian J Carter', 'Randall H Tanaka', 'Taishi Nammoto']",,,,
KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation Classification,"['Chengyu Wang', 'Minghui Qiu', 'Jun Huang', 'Xiaofeng He']",https://arxiv.org/abs/2002.10903,"Lexical relations describe how concepts are semantically related, in the form of relation triples. The accurate prediction of lexical relations between concepts is challenging, due to the sparsity of patterns indicating the existence of such relations. We propose the Knowledge-Enriched Meta-Learning (KEML) framework to address the task of lexical relation classification. In KEML, the LKB-BERT (Lexical Knowledge Base-BERT) model is presented to learn concept representations from massive text corpora, with rich lexical knowledge injected by distant supervision. A probabilistic distribution of auxiliary tasks is defined to increase the model's ability to recognize different types of lexical relations. We further combine a meta-learning process over the auxiliary task distribution and supervised learning to train the neural lexical relation classifier. Experiments over multiple datasets show that KEML outperforms state-of-the-art methods.",語彙関係は、概念が意味的にどのように関連しているかを、関係トリプルの形式で記述します。概念間の語彙関係の正確な予測は、そのような関係の存在を示すパターンの希薄さのために困難です。語彙関係分類のタスクに対処するために、知識強化メタ学習（KEML）フレームワークを提案します。 KEMLでは、LKB-BERT（Lexical Knowledge Base-BERT）モデルが提示され、遠方の監督によって注入された豊富な語彙知識を使用して、大規模なテキストコーパスから概念表現を学習します。補助タスクの確率分布は、さまざまなタイプの語彙関係を認識するモデルの能力を高めるために定義されています。さらに、補助タスク分散と教師あり学習のメタ学習プロセスを組み合わせて、神経語彙関係分類器をトレーニングします。複数のデータセットでの実験は、KEMLが最先端の方法よりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/7a6d464c3d53095799408ac906c93d2614d4a554/3-Figure1-1.png
Simultaneous 2nd Price Item Auctions with No-Underbidding,"['Michal Feldman', 'Galia Shabtai']",https://arxiv.org/abs/2003.11857,"We study the price of anarchy (PoA) of simultaneous 2nd price auctions (S2PA) under a natural condition of {\em no underbidding}. No underbidding means that an agent's bid on every item is at least its marginal value given the outcome. In a 2nd price auction, underbidding on an item is weakly dominated by bidding the item's marginal value. Indeed, the no underbidding assumption is justified both theoretically and empirically. 
We establish bounds on the PoA of S2PA under no underbidding for different valuation classes, in both full-information and incomplete information settings. To derive our results, we introduce a new parameterized property of auctions, namely $(\gamma,\delta)$-revenue guaranteed, and show that every auction that is $(\gamma,\delta)$-revenue guaranteed has PoA at least $\gamma/(1+\delta)$. An auction that is both $(\lambda,\mu)$-smooth and $(\gamma,\delta)$-revenue guaranteed has PoA at least $(\gamma+\lambda)/(1+\delta+\mu)$. Via extension theorems, these bounds extend to coarse correlated equilibria in full information settings, and to Bayesian PoA (BPoA) in settings with incomplete information. 
We show that S2PA with submodular valuations and no underbidding is $(1,1)$-revenue guaranteed, implying that the PoA is at least $\frac{1}{2}$. Together with the known $(1,1)$-smoothness (under the standard no overbididng assumption), it gives PoA of $2/3$ and this is tight. 
For valuations beyond submodular valuations we employ a stronger condition of {\em set no underbidding}, which extends the no underbidding condition to sets of items. We show that S2PA with set no underbidding is $(1,1)$-revenue guaranteed for arbitrary valuations, implying a PoA of at least $1/2$. Together with no overbidding we get a lower bound of $\frac{2}{3}$ on the Bayesian PoA for XOS valuations, and on the PoA for subadditive valuations.",我々は、低入札のない自然条件の下での同時第2価格オークション（S2PA）の無秩序の代償（PoA）を研究します。入札不足がないということは、エージェントがすべてのアイテムに入札するということは、結果を考えると少なくともその限界値であることを意味します。 2回目の価格オークションでは、アイテムの入札不足は、アイテムの限界値を入札することによって弱く支配されます。確かに、入札不足の仮定は理論的にも経験的にも正当化されます。完全な情報と不完全な情報の両方の設定で、さまざまな評価クラスの入札を下回ることなく、S2PAのPoAの範囲を確立します。結果を導き出すために、オークションの新しいパラメータ化されたプロパティ、つまり（、）-収益が保証されていることを紹介し、（、）-収益が保証されているすべてのオークションが少なくとも/（1 +）のPoAを持っていることを示します。 （、）-スムーズと（、）-収益の両方が保証されているオークションでは、少なくとも（+）/（1 + +）のPoAが保証されます。拡張定理を介して、これらの境界は、完全な情報設定では粗い相関均衡に拡張され、不完全な情報を持つ設定ではベイズPoA（BPoA）に拡張されます。劣モジュラ評価でアンダービッドのないS2PAが（1、1）であることが示されます。これは、PoAが少なくとも$ \ frac {1} {2} $であることを意味する収益が保証されています。既知の（1、1）-滑らかさ（標準の過剰入札なしの仮定の下で）と合わせて、PoAは2/3になり、これはタイトです。劣モジュラ評価を超える評価については、アンダービッドなしのより強力な条件を採用します。これにより、アンダービッドなしの条件がアイテムのセットに拡張されます。アンダービッドが設定されていないS2PAが（1、1）であることを示します。これは、任意の評価に対して収益が保証され、少なくとも1/2のPoAを意味します。過剰入札がないことと合わせて、XOS評価のベイジアンPoAと劣加法評価のPoAで$ \ frac {2} {3} $の下限が得られます。,https://d3i71xaburhd42.cloudfront.net/210631482791c5a4ebe8ec8772c0003637206fe9/3-Table1-1.png
Discriminative Region Suppression for Weakly-Supervised Semantic Segmentation,"['Beomyoung Kim', 'Sangeun Han', 'Junmo Kim']",,,,
Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation,"['Runzhe Zhan', 'Xuebo Liu', 'Derek F. Wong', 'Lidia S. Chao']",,,,
TRQ: Ternary Neural Networks with Residual Quantization,"['Yue Li', 'Wenrui Ding', 'Chunlei Liu', 'Baochang Zhang', 'Guodong Guo']",,,,
TextGAIL: Generative Adversarial Imitation Learning for Text Generation,"['Qingyang Wu', 'Lei Li', 'Zhou Yu']",,,,
Alternative Baselines for Low-Shot 3D Medical Image Segmentation---An Atlas Perspective,"['Shuxin Wang', 'Shilei Cao', 'Dong Wei', 'Cong Xie', 'Kai Ma', 'Liansheng Wang', 'Deyu Meng', 'Yefeng Zheng']",,,,
Fast Multi-View Discrete Clustering with Anchor Graphs,"['Qianyao Qiang', 'Bin Zhang', 'Fei Wang', 'Feiping Nie']",,,,
Aspect-Level Sentiment-Controllable Review Generation with Mutual Learning Framework,"['Huimin Chen', 'Yankai Lin', 'Fanchao Qi', 'Jinyi Hu', 'Peng Li', 'Jie Zhou', 'Maosong Sun']",,,,
Knowledge-Driven Distractor Generation for Cloze-Style Multiple Choice Questions,"['Siyu Ren', 'Kenny Zhu']",https://arxiv.org/abs/2004.09853,"In this paper, we propose a novel configurable framework to automatically generate distractive choices for open-domain cloze-style multiple-choice questions, which incorporates a general-purpose knowledge base to effectively create a small distractor candidate set, and a feature-rich learning-to-rank model to select distractors that are both plausible and reliable. Experimental results on datasets across four domains show that our framework yields distractors that are more plausible and reliable than previous methods. This dataset can also be used as a benchmark for distractor generation in the future.",この論文では、オープンドメインのクローズスタイルの多肢選択問題の気を散らす選択肢を自動的に生成するための新しい構成可能なフレームワークを提案します。これには、小さな気晴らしの候補セットを効果的に作成するための汎用知識ベースと、機能豊富な学習が組み込まれています。 -もっともらしく信頼できるディストラクタを選択するためのランク付けモデル。 4つのドメインにわたるデータセットの実験結果は、私たちのフレームワークが以前の方法よりももっともらしく信頼性の高いディストラクタを生み出すことを示しています。このデータセットは、将来のディストラクタ生成のベンチマークとしても使用できます。,https://d3i71xaburhd42.cloudfront.net/9eca67402c76411d847ab27546d646e884ff213a/1-Figure1-1.png
Future-Guided Incremental Transformer for Simultaneous Translation,"['Shaolei Zhang', 'Yang Feng', 'Liangyou Li']",https://arxiv.org/abs/2012.12465,"Simultaneous translation (ST) starts translations synchronously while reading source sentences, and is used in many online scenarios. The previous wait-k policy is concise and achieved good results in ST. However, wait-k policy faces two weaknesses: low training speed caused by the recalculation of hidden states and lack of future source information to guide training. For the low training speed, we propose an incremental Transformer with an average embedding layer (AEL) to accelerate the speed of calculation of the hidden states during training. For future-guided training, we propose a conventional Transformer as the teacher of the incremental Transformer, and try to invisibly embed some future information in the model through knowledge distillation. We conducted experiments on Chinese-English and GermanEnglish simultaneous translation tasks and compared with the wait-k policy to evaluate the proposed method. Our method can effectively increase the training speed by about 28 times on average at different k and implicitly embed some predictive abilities in the model, achieving better translation quality than wait-k baseline.",同時翻訳（ST）は、ソースセンテンスの読み取り中に同期的に翻訳を開始し、多くのオンラインシナリオで使用されます。以前のwait-kポリシーは簡潔であり、STで良好な結果を達成しました。ただし、wait-kポリシーには、2つの弱点があります。それは、隠れた状態の再計算によって引き起こされるトレーニング速度の低下と、トレーニングをガイドするための将来のソース情報の欠如です。トレーニング速度が遅い場合は、トレーニング中の隠れ状態の計算速度を加速するために、平均埋め込み層（AEL）を備えたインクリメンタルトランスフォーマーを提案します。将来に向けたトレーニングでは、インクリメンタルトランスフォーマーの教師として従来のトランスフォーマーを提案し、知識の蒸留を通じてモデルに将来の情報を目に見えない形で埋め込むようにします。中国語-英語とドイツ語-英語の同時翻訳タスクで実験を行い、wait-kポリシーと比較して提案された方法を評価しました。私たちの方法は、異なるkで平均約28倍のトレーニング速度を効果的に向上させ、モデルにいくつかの予測能力を暗黙的に埋め込み、wait-kベースラインよりも優れた翻訳品質を実現します。,https://d3i71xaburhd42.cloudfront.net/cc5afa8f1d35ec8fb3179bf760552da496d2838f/2-Figure1-1.png
REFINE: Prediction Fusion Network for Panoptic Segmentation,"['Jiawei Ren', 'Cunjun Yu', 'Zhongang Cai', 'Mingyuan Zhang', 'Chongsong Chen', 'Haiyu Zhao', 'Shuai Yi', 'Hongsheng Li']",,,,
Simple and Effective Stochastic Neural Networks,"['Tianyuan Yu', 'Yongxin Yang', 'Da Li', 'Timothy Hospedales', 'Tao Xiang']",,,,
Learning to Augment for Data-Scarce Domain BERT Knowledge Distillation,"['Lingyun Feng', 'Minghui Qiu', 'Yaliang Li', 'Ying Shen', 'Hai-Tao Zheng']",https://arxiv.org/abs/2101.08106,"Despite pre-trained language models such as BERT have achieved appealing performance in a wide range of natural language processing tasks, they are computationally expensive to be deployed in real-time applications. A typical method is to adopt knowledge distillation to compress these large pre-trained models (teacher models) to small student models. However, for a target domain with scarce training data, the teacher can hardly pass useful knowledge to the student, which yields performance degradation for the student models. To tackle this problem, we propose a method to learn to augment for data-scarce domain BERT knowledge distillation, by learning a cross-domain manipulation scheme that automatically augments the target with the help of resource-rich source domains. Specifically, the proposed method generates samples acquired from a stationary distribution near the target data and adopts a reinforced selector to automatically refine the augmentation strategy according to the performance of the student. Extensive experiments demonstrate that the proposed method significantly outperforms state-of-the-art baselines on four different tasks, and for the data-scarce domains, the compressed student models even perform better than the original large teacher model, with much fewer parameters (only ∼13.3%) when only a few labeled examples available.",BERTなどの事前トレーニング済みの言語モデルは、さまざまな自然言語処理タスクで魅力的なパフォーマンスを実現していますが、リアルタイムアプリケーションに展開するには計算コストがかかります。典型的な方法は、知識蒸留を採用して、これらの大規模な事前トレーニング済みモデル（教師モデル）を小規模な学生モデルに圧縮することです。ただし、トレーニングデータが不足しているターゲットドメインの場合、教師は有用な知識を生徒に渡すことがほとんどできないため、生徒モデルのパフォーマンスが低下します。この問題に取り組むために、リソースが豊富なソースドメインの助けを借りてターゲットを自動的に拡張するクロスドメイン操作スキームを学習することにより、データが不足しているドメインのBERT知識蒸留を拡張する方法を提案します。具体的には、提案手法は、ターゲットデータの近くの定常分布から取得したサンプルを生成し、強化されたセレクターを採用して、学生のパフォーマンスに応じて拡張戦略を自動的に改良します。広範な実験により、提案された方法は4つの異なるタスクで最先端のベースラインを大幅に上回り、データが不足しているドメインでは、圧縮された学生モデルは元の大規模な教師モデルよりもパフォーマンスが高く、パラメータがはるかに少ないことが示されています（ 13.3,https://d3i71xaburhd42.cloudfront.net/057ebc6610d3f9f85297fd8386702fdc24cb3949/3-Figure1-1.png
DeepwriteSYN: On-Line Handwriting Synthesis via Deep Short-Term Representations,"['Ruben Tolosana', 'Paula Delgado-Santos', 'Andres Perez-Uribe', 'Ruben Vera-Rodriguez', 'Julian Fierrez', 'Aythami Morales']",https://arxiv.org/abs/2009.06308,"This study proposes DeepWriteSYN, a novel on-line handwriting synthesis approach via deep short-term representations. It comprises two modules: i) an optional and interchangeable temporal segmentation, which divides the handwriting into short-time segments consisting of individual or multiple concatenated strokes; and ii) the on-line synthesis of those short-time handwriting segments, which is based on a sequence-to-sequence Variational Autoencoder (VAE). The main advantages of the proposed approach are that the synthesis is carried out in short-time segments (that can run from a character fraction to full characters) and that the VAE can be trained on a configurable handwriting dataset. These two properties give a lot of flexibility to our synthesiser, e.g., as shown in our experiments, DeepWriteSYN can generate realistic handwriting variations of a given handwritten structure corresponding to the natural variation within a given population or a given subject. These two cases are developed experimentally for individual digits and handwriting signatures, respectively, achieving in both cases remarkable results. 
Also, we provide experimental results for the task of on-line signature verification showing the high potential of DeepWriteSYN to improve significantly one-shot learning scenarios. To the best of our knowledge, this is the first synthesis approach capable of generating realistic on-line handwriting in the short term (including handwritten signatures) via deep learning. This can be very useful as a module toward long-term realistic handwriting generation either completely synthetic or as natural variation of given handwriting samples.",この研究では、DeepWriteSYNを提案します。これは、深い短期表現による新しいオンライン手書き合成アプローチです。これは、次の2つのモジュールで構成されます。i）オプションの交換可能な時間セグメンテーション。手書きを個別または複数の連結ストロークで構成される短時間セグメントに分割します。 ii）シーケンス間変分オートエンコーダ（VAE）に基づく、これらの短時間の手書きセグメントのオンライン合成。提案されたアプローチの主な利点は、合成が短時間のセグメント（文字の端数から完全な文字まで実行できる）で実行されることと、VAEを構成可能な手書きデータセットでトレーニングできることです。これらの2つのプロパティは、シンセサイザーに多くの柔軟性を与えます。たとえば、実験で示したように、DeepWriteSYNは、特定の母集団または特定の対象内の自然な変化に対応する、特定の手書き構造の現実的な手書き変化を生成できます。これらの2つのケースは、それぞれ個々の数字と手書きの署名に対して実験的に開発されており、どちらの場合も驚くべき結果を達成しています。また、DeepWriteSYNがワンショット学習シナリオを大幅に改善する可能性が高いことを示す、オンライン署名検証のタスクの実験結果を提供します。私たちの知る限り、これは、ディープラーニングを介して短期間に現実的なオンライン手書き（手書きの署名を含む）を生成できる最初の合成アプローチです。これは、完全に合成された、または特定の手書きサンプルの自然なバリエーションとして、長期的に現実的な手書きを生成するためのモジュールとして非常に役立ちます。,https://d3i71xaburhd42.cloudfront.net/fff21f40ec8be759d7e0154eb33f7e9a18e15dfc/2-Figure1-1.png
Bigram and Unigram Based Text Attack via Adaptive Monotonic Heuristic Search,"['Xinghao Yang', 'Weifeng Liu', 'James Bailey', 'Dacheng Tao', 'Wei Liu']",,,,
Unsupervised Model Adaptation for Continual Semantic Segmentation,"['Serban Stan', 'Mohammad Rostami']",,,,
Supervised Training of Dense Object Nets Using Optimal Descriptors for Industrial Robotic Applications,"['Andras Kupcsik', 'Markus Spies', 'Alexander Klein', 'Marco Todescato', 'Nicolai Waniek', 'Philipp Schillinger', 'Mathias Buerger']",,,,
Reaching Individually Stable Coalition Structures in Hedonic Games,"['Felix Brandt', 'Martin Bullinger', 'Anaëlle Wilczynski']",,"The formal study of coalition formation in multiagent systems is typically realized using so-called hedonic games, which originate from economic theory. The main focus of this branch of research has been on the existence and the computational complexity of deciding the existence of coalition structures that satisfy various stability criteria. The actual process of forming coalitions based on individual behavior has received very little attention. In this paper, we study the convergence of simple dynamics leading to stable partitions in a variety of classes of hedonic games, including anonymous, dichotomous, fractional, and hedonic diversity games. The dynamics we consider is based on individual stability: an agent will join another coalition if she is better off and no member of the welcoming coalition is worse off. We identify conditions for convergence, provide elaborate counterexamples of existence of individually stable partitions, and study the computational complexity of problems related to the coalition formation dynamics. In particular, we settle open problems suggested by Bogomolnaia and Jackson (2002), Brandl, Brandt, and Strobel (2015), and Boehmer and Elkind (2020).",マルチエージェントシステムにおける連合形成の正式な研究は、通常、経済理論に由来するいわゆるヘドニックゲームを使用して実現されます。この研究分野の主な焦点は、さまざまな安定性基準を満たす連合構造の存在とその存在を決定する計算の複雑さにあります。個人の行動に基づいて連合を形成する実際のプロセスは、ほとんど注目されていません。この論文では、匿名、二分、分数、および快楽的多様性ゲームを含む、快楽的ゲームのさまざまなクラスで安定したパーティションにつながる単純なダイナミクスの収束を研究します。私たちが考えるダイナミクスは、個人の安定性に基づいています。エージェントは、彼女がより良い状態にあり、歓迎する連合のメンバーがより悪い状態にある場合、別の連合に参加します。収束の条件を特定し、個別に安定したパーティションの存在の詳細な反例を提供し、連合形成のダイナミクスに関連する問題の計算の複雑さを研究します。特に、Bogomolnaia and Jackson（2002）、Brandl、Brandt、およびStrobel（2015）、およびBoehmer and Elkind（2020）によって提案された未解決の問題を解決します。,https://d3i71xaburhd42.cloudfront.net/0b0405370edb654fbc3dfe786e7a65465c9c0ec8/6-Figure1-1.png
Progressive Multi-Task Learning with Controlled information Flow for Joint Entity and Relation Extraction,"['Kai Sun', 'Richong Zhang', 'Samuel A. Mensah', 'Yongyi Mao', 'Xudong Liu']",,,,
On the Complexity of Sum-of-Products Problems over Semirings,"['Thomas Eiter', 'Rafael Kiesel']",,,,
Unsupervised Domain Adaptation for Person Re-Identification via Heterogeneous Graph Alignment,"['Minying Zhang', 'Kai Liu', 'Yidong Li', 'Shihui Guo', 'Hongtao Duan', 'Yimin Long', 'Yi Jin']",,,,
Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent DAGs,"['Marcel Wienöbst', 'Max Bannach', 'Maciej Liskiewicz']",https://arxiv.org/abs/2012.09679,"Counting and uniform sampling of directed acyclic graphs (DAGs) from a Markov equivalence class are fundamental tasks in graphical causal analysis. In this paper, we show that these tasks can be performed in polynomial time, solving a long-standing open problem in this area. Our algorithms are effective and easily implementable. Experimental results show that the algorithms significantly outperform state-of-the-art methods.",マルコフ同値類からの有向非巡回グラフ（DAG）のカウントと均一サンプリングは、グラフィカルな因果分析の基本的なタスクです。この論文では、これらのタスクを多項式時間で実行できることを示し、この分野での長年の未解決の問題を解決します。当社のアルゴリズムは効果的で簡単に実装できます。実験結果は、アルゴリズムが最先端の方法を大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/6b80dea61e74a65b9ab0b0590932a3dc175f1755/4-Figure1-1.png
Adaptive Pattern-Parameter Matching for Robust Pedestrian Detection,"['Mengyin Liu', 'Chao Zhu', 'Jun Wang', 'Xu-Cheng Yin']",,,,
Persuading Voters in District-Based Elections,"['Matteo Castiglioni', 'Nicola Gatti']",https://arxiv.org/abs/2012.05002,"We focus on the scenario in which an agent can exploit his information advantage to manipulate the outcome of an election. In particular, we study district-based elections with two candidates, in which the winner of the election is the candidate that wins in the majority of the districts. District-based elections are adopted worldwide (e.g., UK and USA) and are a natural extension of widely studied voting mechanisms (e.g., k-voting and plurality voting). We resort to the Bayesian persuasion framework, where the manipulator (sender) strategically discloses information to the voters (receivers) that update their beliefs rationally. We study both private signaling, in which the sender can use a private communication channel per receiver, and public signaling, in which the sender can use a single communication channel for all the receivers. Furthermore, for the first time, we introduce semi-public signaling in which the sender can use a single communication channel per district. We show that there is a sharp distinction between private and (semi-)public signaling. In particular, optimal private signaling schemes can provide an arbitrarily better probability of victory than (semi-)public ones and can be computed efficiently, while optimal (semi-)public signaling schemes cannot be approximated to within any factor in polynomial time unless P=NP. However, we show that reasonable relaxations allow the design of multi-criteria PTASs for optimal (semi-)public signaling schemes. In doing so, we introduce a novel property, namely comparative stability, and we design a bi-criteria PTAS for public signaling in general Bayesian persuasion problems beyond elections when the sender's utility function is state-dependent.",エージェントが情報の利点を利用して選挙の結果を操作できるシナリオに焦点を当てます。特に、選挙の勝者が大多数の地区で勝つ候補者である2人の候補者による地区ベースの選挙を研究します。地区ベースの選挙は世界中で採用されており（たとえば、英国と米国）、広く研究されている投票メカニズム（たとえば、k投票と複数投票）の自然な延長です。私たちはベイズ説得フレームワークに頼ります。そこでは、マニピュレーター（送信者）が、信念を合理的に更新する情報を有権者（受信者）に戦略的に開示します。送信者が受信者ごとにプライベート通信チャネルを使用できるプライベートシグナリングと、送信者がすべての受信者に対して単一の通信チャネルを使用できるパブリックシグナリングの両方を調査します。さらに、送信者が地区ごとに1つの通信チャネルを使用できるセミパブリックシグナリングを初めて導入しました。プライベートシグナリングと（セミ）パブリックシグナリングの間には明確な違いがあることを示します。特に、最適なプライベートシグナリングスキームは、（セミ）パブリックシグナリングスキームよりも任意に優れた勝利確率を提供し、効率的に計算できますが、最適な（セミ）パブリックシグナリングスキームは、P =でない限り、多項式時間のどの要素内でも近似できません。 NP。ただし、合理的な緩和により、最適な（半）パブリックシグナリングスキームのための多基準PTASの設計が可能になることを示します。そうすることで、新しい特性、つまり比較安定性を導入し、送信者の効用関数が状態に依存する場合の選挙以外の一般的なベイズ説得問題におけるパブリックシグナリングの2基準PTASを設計します。,https://d3i71xaburhd42.cloudfront.net/097638237894cbf9a56675f746a2eb207aeba883/3-Figure1-1.png
An Unsupervised Sampling Approach for Image-Sentence Matching Using Document-Level Structural information,"['Zejun Li', 'Zhongyu Wei', 'Zhihao Fan', 'Haijun Shan', 'Xuanjing Huang']",,,,
A Multi-Step-Ahead Markov Conditional Forward Model with Cube Perturbations for Extreme Weather Forecasting,"['Chia-Yuan Chang', 'Cheng-Wei Lu', 'Chuan-Ju Wang']",,,,
Unsupervised Learning of Deterministic Dialogue Structure with Edge-Enhanced Graph Auto-Encoder,"['Yajing Sun', 'Yong Shan', 'Chengguang Tang', 'Yue Hu', 'Yinpei Dai', 'Jing Yu', 'Jian Sun', 'Fei Huang', 'Luo Si']",,,,
Backdoor Decomposable Monotone Circuits and Propagation Complete Encodings,"['Petr Kučera', 'Petr Savický']",https://arxiv.org/abs/1811.09435,"We describe a compilation language of backdoor decomposable monotone circuits (BDMCs) which generalizes several concepts appearing in the literature, e.g. DNNFs and backdoor trees. A $\mathcal{C}$-BDMC sentence is a monotone circuit which satisfies decomposability property (such as in DNNF) in which the inputs (or leaves) are associated with CNF encodings from a given base class $\mathcal{C}$. We consider different base classes which consist of encodings with various propagation strength. In particular, we consider encodings which implement consistency checker (CC) or domain consistency (DC) by unit propagation, unit refutation complete (URC) and propagation complete (PC) encodings. We show that a representation of a boolean function with a $\mathcal{C}$-BDMC can be transformed in polynomial time into an encoding from $\mathcal{C}$ for any of the classes of CNF encodings mentioned above.",DNNFやバックドアツリーなど、文献に登場するいくつかの概念を一般化したバックドア分解可能モノトーン回路（BDMC）のコンパイル言語について説明します。 C-BDMCセンテンスは、入力（またはリーフ）が特定の基本クラスCからのCNFエンコーディングに関連付けられている分解可能性プロパティ（DNNFなど）を満たす単調回路です。さまざまなエンコーディングで構成されるさまざまな基本クラスを検討します。伝播強度。特に、ユニット伝播、ユニット反論完了（URC）、および伝播完了（PC）エンコーディングによって整合性チェッカー（CC）またはドメイン整合性（DC）を実装するエンコーディングを検討します。 C-BDMCを使用したブール関数の表現は、上記のCNFエンコーディングのクラスのいずれかについて、多項式時間でCからのエンコーディングに変換できることを示します。,https://d3i71xaburhd42.cloudfront.net/fbfeaf92f5e1b2b323a70a8a83d575ce6c56642d/10-Table1-1.png
Deep Spiking Neural Network with Neural Oscillation and Spike-Phase information,"['Yi Chen', 'Hong Qu', 'Malu Zhang', 'Yuchen Wang']",,,,
A Scalable Reasoning and Learning Approach for Neural-Symbolic Stream Fusion,"['Danh Le Phuoc', 'Thomas Eiter', 'Tuan Anh Le']",,,,
Complexity and Algorithms for Exploiting Quantal Opponents in Large Two-Player Games,"['David Milec', 'Jakub Cerny', 'Viliam Lisy', 'Bo An']",https://arxiv.org/abs/2009.14521,"Solution concepts of traditional game theory assume entirely rational players; therefore, their ability to exploit subrational opponents is limited. One type of subrationality that describes human behavior well is the quantal response. While there exist algorithms for computing solutions against quantal opponents, they either do not scale or may provide strategies that are even worse than the entirely-rational Nash strategies. This paper aims to analyze and propose scalable algorithms for computing effective and robust strategies against a quantal opponent in normal-form and extensive-form games. Our contributions are: (1) we define two different solution concepts related to exploiting quantal opponents and analyze their properties; (2) we prove that computing these solutions is computationally hard; (3) therefore, we evaluate several heuristic approximations based on scalable counterfactual regret minimization (CFR); and (4) we identify a CFR variant that exploits the bounded opponents better than the previously used variants while being less exploitable by the worst-case perfectly-rational opponent.",従来のゲーム理論のソリューションコンセプトは、完全に合理的なプレーヤーを想定しています。したがって、非合理的な敵を悪用する能力は制限されています。人間の行動をよく説明するサブ合理性の1つのタイプは、量子応答です。量子的な敵に対してソリューションを計算するためのアルゴリズムは存在しますが、それらはスケーリングしないか、完全に合理的なナッシュ戦略よりもさらに悪い戦略を提供する可能性があります。このペーパーは、通常形式および拡張形式のゲームで、量子対戦相手に対して効果的で堅牢な戦略を計算するためのスケーラブルなアルゴリズムを分析および提案することを目的としています。私たちの貢献は次のとおりです。（1）量子的敵の搾取に関連する2つの異なるソリューションの概念を定義し、それらの特性を分析します。 （2）これらのソリューションの計算が計算上難しいことを証明します。 （3）したがって、スケーラブルな反事実的後悔最小化（CFR）に基づいていくつかのヒューリスティック近似を評価します。 （4）最悪の場合の完全に合理的な対戦相手による悪用が少ない一方で、以前に使用されたバリアントよりも制限された対戦相手をうまく悪用するCFRバリアントを特定します。,https://d3i71xaburhd42.cloudfront.net/94d552ab3bb7de7189cd010d92c5a722d51c87ca/4-Figure1-1.png
Gated Linear Networks,"['Joel Veness', 'Tor Lattimore', 'David Budden', 'Avishkar Bhoopchand', 'Christopher Mattern', 'Agnieszka Grabska-Barwinska', 'Eren Sezener', 'Jianan Wang', 'Peter Toth', 'Simon Schmitt', 'Marcus Hutter']",,,,
MASKER: Masked Keyword Regularization for Reliable Text Classification,"['Seung Jun Moon', 'Sangwoo Mo', 'Kimin Lee', 'Jaeho Lee', 'Jinwoo Shin']",https://arxiv.org/abs/2012.09392,"Pre-trained language models have achieved state-of-the-art accuracies on various text classification tasks, e.g., sentiment analysis, natural language inference, and semantic textual similarity. However, the reliability of the fine-tuned text classifiers is an often underlooked performance criterion. For instance, one may desire a model that can detect out-of-distribution (OOD) samples (drawn far from training distribution) or be robust against domain shifts. We claim that one central obstacle to the reliability is the over-reliance of the model on a limited number of keywords, instead of looking at the whole context. In particular, we find that (a) OOD samples often contain in-distribution keywords, while (b) cross-domain samples may not always contain keywords; over-relying on the keywords can be problematic for both cases. In light of this observation, we propose a simple yet effective fine-tuning method, coined masked keyword regularization (MASKER), that facilitates context-based prediction. MASKER regularizes the model to reconstruct the keywords from the rest of the words and make low-confidence predictions without enough context. When applied to various pre-trained language models (e.g., BERT, RoBERTa, and ALBERT), we demonstrate that MASKER improves OOD detection and cross-domain generalization without degrading classification accuracy. Code is available at this https URL.",事前にトレーニングされた言語モデルは、感情分析、自然言語推論、意味論的テキスト類似性など、さまざまなテキスト分類タスクで最先端の精度を実現しています。ただし、微調整されたテキスト分類子の信頼性は、見過ごされがちなパフォーマンス基準です。たとえば、分布外（OOD）サンプル（トレーニング分布から遠く離れて抽出された）を検出できるモデル、またはドメインシフトに対してロバストなモデルが必要な場合があります。信頼性に対する1つの中心的な障害は、コンテキスト全体を見るのではなく、限られた数のキーワードにモデルが過度に依存していることであると主張します。特に、（a）OODサンプルには多くの場合、配布中のキーワードが含まれていますが、（b）クロスドメインサンプルには必ずしもキーワードが含まれているとは限りません。キーワードに過度に依存することは、どちらの場合も問題になる可能性があります。この観察に照らして、コンテキストベースの予測を容易にする、シンプルでありながら効果的な微調整方法である、造語マスクキーワード正則化（MASKER）を提案します。 MASKERはモデルを正規化して、残りの単語からキーワードを再構築し、十分なコンテキストなしで信頼性の低い予測を行います。事前にトレーニングされたさまざまな言語モデル（BERT、RoBERTa、ALBERTなど）に適用すると、MASKERが分類精度を低下させることなくOOD検出とクロスドメインの一般化を改善することを示します。コードはこのhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/bdfe6051558414589f8b8b2e0fea596833e845bb/1-Figure1-1.png
A Free Lunch for Unsupervised Domain Adaptive Object Detection without Source Data,"['Xianfeng Li', 'Weijie Chen', 'Di Xie', 'Shicai Yang', 'Peng Yuan', 'Shiliang Pu', 'Yueting Zhuang']",https://arxiv.org/abs/2012.05400,"Unsupervised domain adaptation (UDA) assumes that source and target domain data are freely available and usually trained together to reduce the domain gap. However, considering the data privacy and the inefficiency of data transmission, it is impractical in real scenarios. Hence, it draws our eyes to optimize the network in the target domain without accessing labeled source data. To explore this direction in object detection, for the first time, we propose a source data-free domain adaptive object detection (SFOD) framework via modeling it into a problem of learning with noisy labels. Generally, a straightforward method is to leverage the pre-trained network from the source domain to generate the pseudo labels for target domain optimization. However, it is difficult to evaluate the quality of pseudo labels since no labels are available in target domain. In this paper, self-entropy descent (SED) is a metric proposed to search an appropriate confidence threshold for reliable pseudo label generation without using any handcrafted labels. Nonetheless, completely clean labels are still unattainable. After a thorough experimental analysis, false negatives are found to dominate in the generated noisy labels. Undoubtedly, false negatives mining is helpful for performance improvement, and we ease it to false negatives simulation through data augmentation like Mosaic. Extensive experiments conducted in four representative adaptation tasks have demonstrated that the proposed framework can easily achieve state-of-the-art performance. From another view, it also reminds the UDA community that the labeled source data are not fully exploited in the existing methods.",教師なしドメイン適応（UDA）は、ソースドメインデータとターゲットドメインデータが自由に利用可能であり、通常はドメインギャップを減らすために一緒にトレーニングされることを前提としています。ただし、データのプライバシーとデータ送信の非効率性を考慮すると、実際のシナリオでは実用的ではありません。したがって、ラベル付けされたソースデータにアクセスせずに、ターゲットドメインのネットワークを最適化することに目を向けます。オブジェクト検出におけるこの方向性を探求するために、ノイズの多いラベルを使用した学習の問題にモデル化することにより、ソースデータフリードメイン適応オブジェクト検出（SFOD）フレームワークを初めて提案します。一般に、簡単な方法は、ソースドメインから事前にトレーニングされたネットワークを活用して、ターゲットドメインの最適化のための疑似ラベルを生成することです。ただし、ターゲットドメインで使用できるラベルがないため、疑似ラベルの品質を評価することは困難です。この論文では、自己エントロピー降下（SED）は、手作りのラベルを使用せずに、信頼性の高い疑似ラベル生成のための適切な信頼しきい値を検索するために提案されたメトリックです。それにもかかわらず、完全にきれいなラベルはまだ達成できません。徹底的な実験的分析の結果、生成されたノイズの多いラベルでは偽陰性が優勢であることがわかりました。間違いなく、フォールスネガティブマイニングはパフォーマンスの向上に役立ち、Mosaicのようなデータ拡張を通じてフォールスネガティブシミュレーションを容易にします。 4つの代表的な適応タスクで実施された広範な実験により、提案されたフレームワークが最先端のパフォーマンスを簡単に達成できることが実証されました。別の見方をすれば、ラベル付けされたソースデータが既存の方法では十分に活用されていないこともUDAコミュニティに思い出させます。,https://d3i71xaburhd42.cloudfront.net/8bd4264cc4e4644e9ff5beff466cceb4a3325e90/1-Figure1-1.png
Riemannian Embedding Banks for Common Spatial Patterns with EEG-Based SPD Neural Networks,"['Yoon-Je Suh', 'Byung Hyung Kim']",,,,
Evolutionary Approach for Autoaugment Using the Thermodynamical Genetic Algorithm,"['Akira Terauchi', 'Naoki Mori']",,,,
High Fidelity GAN Inversion via Prior Multi-Subspace Feature Composition,"['Guanyue Li', 'Qianfen Jiao', 'Sheng Qian', 'Si Wu', 'Hau San Wong']",,,,
Cost-Aware Graph Generation: A Deep Bayesian Optimization Approach,"['Jiaxu Cui', 'Bo Yang', 'Bingyi Sun', 'Jiming Liu']",,,,
FLAME: Differentially Private Federated Learning in the Shuffle Model,"['Ruixuan Liu', 'Yang Cao', 'Hong Chen', 'Ruoyang Guo', 'Masatoshi Yoshikawa']",https://arxiv.org/abs/2009.08063,"Differentially private federated learning has been intensively studied. The current works are mainly based on the \textit{curator model} or \textit{local model} of differential privacy. However, both of them have pros and cons. The curator model allows greater accuracy but requires a trusted analyzer. In the local model where users randomize local data before sending them to the analyzer, a trusted analyzer is not required, but the accuracy is limited. In this work, by leveraging the \textit{privacy amplification} effect in the recently proposed shuffle model of differential privacy, we achieve the best of two worlds, i.e., accuracy in the curator model and strong privacy without relying on any trusted party. We first propose an FL framework in the shuffle model and a simple protocol (SS-Simple) extended from existing work. We find that SS-Simple only provides an insufficient privacy amplification effect in FL since the dimension of the model parameter is quite large. To solve this challenge, we propose an enhanced protocol (SS-Double) to increase the privacy amplification effect by subsampling. Furthermore, for boosting the utility when the model size is greater than the user population, we propose an advanced protocol (SS-Topk) with gradient sparsification techniques. We also provide theoretical analysis and numerical evaluations of the privacy amplification of the proposed protocols. Experiments on real-world datasets validate that SS-Topk improves the testing accuracy by 60.7\% than the local model based FL. We highlight the observation that SS-Topk even can improve by 33.94\% accuracy than the curator model based FL without any trusted party. Compared with non-private FL, our protocol SS-Topk only lose 1.48\% accuracy under $(4.696, 10^{-5})$-DP.",差分プライベート連合学習は集中的に研究されてきました。現在の作品は、主に差分プライバシーのキュレーターモデルまたはローカルモデルに基づいています。ただし、どちらにも長所と短所があります。キュレーターモデルでは精度が向上しますが、信頼できるアナライザーが必要です。ユーザーがローカルデータをアナライザーに送信する前にランダム化するローカルモデルでは、信頼できるアナライザーは必要ありませんが、精度には制限があります。この作業では、最近提案された差分プライバシーのシャッフルモデルのプライバシー増幅効果を活用することで、信頼できる当事者に依存することなく、キュレーターモデルの精度と強力なプライバシーという2つの世界の長所を実現します。まず、シャッフルモデルのFLフレームワークと、既存の作業から拡張された単純なプロトコル（SS-Simple）を提案します。モデルパラメータの次元が非常に大きいため、SS-SimpleはFLで不十分なプライバシー増幅効果しか提供しないことがわかります。この課題を解決するために、サブサンプリングによってプライバシー増幅効果を高める拡張プロトコル（SS-Double）を提案します。さらに、モデルサイズがユーザー母集団よりも大きい場合に効用を高めるために、勾配スパース化手法を使用した高度なプロトコル（SS-Topk）を提案します。また、提案されたプロトコルのプライバシー増幅の理論的分析と数値評価も提供します。実際のデータセットでの実験により、SS-TopkがローカルモデルベースのFLよりも60.7％テスト精度を向上させることが検証されています。 SS-Topkは、信頼できる当事者がいなくても、キュレーターモデルベースのFLよりも33.94％の精度で向上できるという観察結果を強調します。非プライベートFLと比較して、私たちのプロトコルSS-Topkは、（4.696、10 ^（5））-DPで1.48％の精度しか失いません。,https://d3i71xaburhd42.cloudfront.net/50781751a97cbf7ccddb0a4860d04fc550d01f7c/2-Figure1-1.png
"Locate Globally, Segment Locally: A Progressive Architecture with Knowledge Review Network for Salient Object Detection","['Binwei Xu', 'Haoran Liang', 'Ronghua Liang', 'Peng Chen']",,,,
Curriculum-Meta Learning for Order-Robust Continual Relation Extraction,"['Tongtong Wu', 'Xuekai Li', 'Yuan-Fang Li ', 'Reza Haffari', 'Guilin Qi', 'Yujin Zhu', 'Guoqiang Xu']",https://arxiv.org/abs/2101.01926,"Continual relation extraction is an important task that focuses on extracting new facts incrementally from unstructured text. Given the sequential arrival order of the relations, this task is prone to two serious challenges, namely catastrophic forgetting and order-sensitivity. We propose a novel curriculum-meta learning method to tackle the above two challenges in continual relation extraction. We combine meta learning and curriculum learning to quickly adapt model parameters to a new task and to reduce interference of previously seen tasks on the current task. We design a novel relation representation learning method through the distribution of domain and range types of relations. Such representations are utilized to quantify the difficulty of tasks for the construction of curricula. Moreover, we also present novel difficulty-based metrics to quantitatively measure the extent of order-sensitivity of a given model, suggesting new ways to evaluate model robustness. Our comprehensive experiments on three benchmark datasets show that our proposed method outperforms the state-of-the-art techniques. The code is available at the anonymous GitHub repository https://github.com/wutong8023/AAAI-CML.",継続的な関係の抽出は、非構造化テキストから新しい事実を段階的に抽出することに焦点を当てた重要なタスクです。関係が順番に到着することを考えると、このタスクは2つの深刻な課題、つまり壊滅的な忘却と順序の敏感さの傾向があります。継続的な関係抽出における上記の2つの課題に取り組むための新しいカリキュラム-メタ学習法を提案します。メタ学習とカリキュラム学習を組み合わせて、モデルパラメータを新しいタスクにすばやく適応させ、以前に見たタスクが現在のタスクに干渉するのを減らします。ドメインおよび範囲タイプの関係の分布を通じて、新しい関係表現学習方法を設計します。このような表現は、カリキュラム構築のためのタスクの難しさを定量化するために利用されます。さらに、特定のモデルの順序感度の程度を定量的に測定するための新しい難易度ベースのメトリックも提示し、モデルの堅牢性を評価する新しい方法を提案します。 3つのベンチマークデータセットに対する包括的な実験は、提案された方法が最先端の技術よりも優れていることを示しています。このコードは、匿名のGitHubリポジトリhttps://github.com/wutong8023/AAAI-CMLで入手できます。,https://d3i71xaburhd42.cloudfront.net/2885953a1efbf9c7a5fbbb113e4e8de577a5ad1e/10-Figure1-1.png
Write-a-Speaker: Text-Based Emotional and Rhythmic Talking-Head Generation,"['Lincheng Li', 'Suzhen Wang', 'Zhimeng Zhang', 'Yu Ding', 'Yixing Zheng', 'Xin Yu', 'Changjie Fan']",,,,
DPM: A Novel Training Method for Physics-Informed Neural Networks in Extrapolation,"['Jungeun Kim', 'Kookjin Lee', 'Dongeun Lee', 'Sheo Yon Jin', 'Noseong Park']",,,,
An LP-Based Approach for Goal Recognition as Planning,"['Luísa R. A. Santos', 'Felipe Meneguzzi', 'Ramon Fraga Pereira', 'André Grahl Pereira']",,,,
Double Oracle Algorithm for Computing Equilibria in Continuous Games,"['Lukáš Adam', 'Rostislav Horčík', 'Tomáš Kasl', 'Tomáš Kroupa']",https://arxiv.org/abs/2009.12185,"Many efficient algorithms have been designed to recover Nash equilibria of various classes of finite games. Special classes of continuous games with infinite strategy spaces, such as polynomial games, can be solved by semidefinite programming. In general, however, continuous games are not directly amenable to computational procedures. In this contribution, we develop an iterative strategy generation technique for finding a Nash equilibrium in a whole class of continuous two-person zero-sum games with compact strategy sets. The procedure, which is called the double oracle algorithm, has been successfully applied to large finite games in the past. We prove the convergence of the double oracle algorithm to a Nash equilibrium. Moreover, the algorithm is guaranteed to recover an approximate equilibrium in finitely-many steps. Our numerical experiments show that it outperforms fictitious play on several examples of games appearing in the literature. In particular, we provide a detailed analysis of experiments with a version of the continuous Colonel Blotto game.",さまざまなクラスの有限ゲームのナッシュ均衡を回復するために、多くの効率的なアルゴリズムが設計されています。多項式ゲームなど、無限の戦略空間を持つ連続ゲームの特別なクラスは、半正定値計画法によって解決できます。ただし、一般的に、連続ゲームは計算手順に直接従うことはできません。この寄稿では、コンパクトな戦略セットを使用して、連続する2人のゼロサムゲームのクラス全体でナッシュ均衡を見つけるための反復戦略生成手法を開発します。ダブルオラクルアルゴリズムと呼ばれるこの手順は、過去に大規模な有限ゲームにうまく適用されてきました。ダブルオラクルアルゴリズムのナッシュ均衡への収束を証明します。さらに、アルゴリズムは、有限の数のステップで近似平衡を回復することが保証されています。私たちの数値実験は、それが文献に登場するゲームのいくつかの例で架空のプレイよりも優れていることを示しています。特に、連続大佐ブロットゲームのバージョンを使用した実験の詳細な分析を提供します。,https://d3i71xaburhd42.cloudfront.net/0a3f967b10838b19cbcf595d27b14ef711f89df1/4-Figure1-1.png
Static-Dynamic interaction Networks for Offline Signature Verification,"['Huan Li', 'Ping Wei', 'Ping Hu']",,,,
Progression Heuristics for Planning with Probabilistic LTL Constraints,"['Ian Mallett', 'Sylvie Thiebaux', 'Felipe Trevizan']",,,,
Multi-View Representation Learning with Manifold Smoothness,"['Shu Li', 'Wei Wang', 'Wen-Tao Li', 'Pan Chen']",,,,
Equitable Scheduling on a Single Machine,"['Klaus Heeger', 'Dan Hermelin', 'George Mertzios', 'Hendrik Molter', 'Rolf Niedermeier', 'Dvir Shabtay']",https://arxiv.org/abs/2010.04643,"We introduce a natural but seemingly yet unstudied generalization of the problem of scheduling jobs on a single machine so as to minimize the number of tardy jobs. Our generalization lies in simultaneously considering several instances of the problem at once. In particular, we have $n$ clients over a period of $m$ days, where each client has a single job with its own processing time and deadline per day. Our goal is to provide a schedule for each of the $m$ days, so that each client is guaranteed to have their job meet its deadline in at least $k \le m$ days. This corresponds to an equitable schedule where each client is guaranteed a minimal level of service throughout the period of $m$ days. We provide a thorough analysis of the computational complexity of three main variants of this problem, identifying both efficient algorithms and worst-case intractability results.",遅延ジョブの数を最小限に抑えるために、単一のマシンでジョブをスケジュールする問題の自然であるが、まだ研究されていない一般化を紹介します。私たちの一般化は、問題のいくつかのインスタンスを同時に考慮することにあります。特に、m日間でn個のクライアントがあり、各クライアントには、独自の処理時間と1日あたりの期限を持つ単一のジョブがあります。私たちの目標は、m日のそれぞれのスケジュールを提供することです。これにより、各クライアントは、少なくともkm日で仕事が期限に間に合うことが保証されます。これは、各クライアントがm日間にわたって最小レベルのサービスを保証される公平なスケジュールに対応します。この問題の3つの主要なバリアントの計算の複雑さを徹底的に分析し、効率的なアルゴリズムと最悪の場合の難易度の結果の両方を特定します。,
The Complexity of Object Association in Multiple Object Tracking,"['Robert Ganian', 'Thekla Hamm', 'Sebastian Ordyniak']",,,,
Deep Style Transfer for Line Drawings,"['Xueting Liu', 'Wenliang Wu', 'Huisi Wu', 'Zhenkun Wen']",,,,
KAN: Knowledge-Aware Attention Network for Fake News Detection,"['Yaqian Dun', 'Kefei Tu', 'Chen Chen', 'Chunyan Hou', 'Xiaojie Yuan']",,,,
Deep Radial-Basis Value Functions for Continuous Control,"['Kavosh Asadi', 'Neev Parikh', 'Ron Parr', 'George Konidaris', 'Michael L. Littman']",,"A core operation in reinforcement learning (RL) is finding an action that is optimal with respect to a learned value function. This operation is often challenging when the learned value function takes continuous actions as input. We introduce deep radial-basis value functions (RBVFs): value functions learned using a deep network with a radial-basis function (RBF) output layer. We show that the maximum action-value with respect to a deep RBVF can be approximated easily and accurately. Moreover, deep RBVFs can represent any true value function owing to their support for universal function approximation. We extend the standard DQN algorithm to continuous control by endowing the agent with a deep RBVF. We show that the resultant agent, called RBF-DQN, significantly outperforms value-function-only baselines, and is competitive with state-of-the-art actor-critic algorithms.",強化学習（RL）の中核となる操作は、学習値関数に関して最適なアクションを見つけることです。学習値関数が入力として連続アクションを実行する場合、この操作はしばしば困難です。ディープラジアルベース値関数（RBVF）を紹介します。ラジアルベース関数（RBF）出力層を備えたディープネットワークを使用して学習した値関数です。深いRBVFに関する最大アクション値を簡単かつ正確に近似できることを示します。さらに、ディープRBVFは、ユニバーサル関数近似をサポートしているため、任意の真の値関数を表すことができます。エージェントに深いRBVFを与えることにより、標準のDQNアルゴリズムを継続的な制御に拡張します。 RBF-DQNと呼ばれる結果のエージェントは、値関数のみのベースラインを大幅に上回り、最先端のアクター批評アルゴリズムと競合することを示します。,https://d3i71xaburhd42.cloudfront.net/09a9cae0503a3a354b420e5bcecdd432283435cc/3-Figure1-1.png
Communicative Message Passing for Inductive Relation Reasoning,"['Sijie Mai', 'Shuangjia Zheng', 'Yuedong Yang', 'Haifeng Hu']",https://arxiv.org/abs/2012.08911,"Relation prediction for knowledge graphs aims at predicting missing relationships between entities. Despite the importance of inductive relation prediction, most previous works are limited to a transductive setting and cannot process previously unseen entities. The recent proposed subgraph-based relation reasoning models provided alternatives to predict links from the subgraph structure surrounding a candidate triplet inductively. However, we observe that these methods often neglect the directed nature of the extracted subgraph and weaken the role of relation information in the subgraph modeling. As a result, they fail to effectively handle the asymmetric/anti-symmetric triplets and produce insufficient embeddings for the target triplets. To this end, we introduce a \textbf{C}\textbf{o}mmunicative \textbf{M}essage \textbf{P}assing neural network for \textbf{I}nductive re\textbf{L}ation r\textbf{E}asoning, \textbf{CoMPILE}, that reasons over local directed subgraph structures and has a vigorous inductive bias to process entity-independent semantic relations. In contrast to existing models, CoMPILE strengthens the message interactions between edges and entitles through a communicative kernel and enables a sufficient flow of relation information. Moreover, we demonstrate that CoMPILE can naturally handle asymmetric/anti-symmetric relations without the need for explosively increasing the number of model parameters by extracting the directed enclosing subgraphs. Extensive experiments show substantial performance gains in comparison to state-of-the-art methods on commonly used benchmark datasets with variant inductive settings.",知識グラフの関係予測は、エンティティ間の欠落している関係を予測することを目的としています。帰納的関係予測の重要性にもかかわらず、以前のほとんどの作品はトランスダクティブな設定に限定されており、以前は見られなかったエンティティを処理することはできません。最近提案されたサブグラフベースの関係推論モデルは、候補トリプレットを誘導的に囲むサブグラフ構造からリンクを予測するための代替手段を提供しました。ただし、これらの方法では、抽出されたサブグラフの方向性が無視され、サブグラフモデリングにおける関係情報の役割が弱くなることがよくあります。その結果、非対称/反対称トリプレットを効果的に処理できず、ターゲットトリプレットの埋め込みが不十分になります。この目的のために、帰納的関係推論のためのコミュニケーションメッセージパッシングニューラルネットワーク、COMPILEを紹介します。これは、ローカルの有向サブグラフ構造を理由とし、エンティティに依存しない意味関係を処理するための強力な帰納的バイアスを持っています。既存のモデルとは対照的に、CoMPILEは、通信カーネルを介してエッジとエンタイトルメント間のメッセージの相互作用を強化し、関係情報の十分なフローを可能にします。さらに、CoMPILEは、有向の囲みサブグラフを抽出することにより、モデルパラメータの数を爆発的に増やす必要なしに、非対称/反対称関係を自然に処理できることを示します。広範な実験では、さまざまな誘導設定を使用して一般的に使用されるベンチマークデータセットで、最先端の方法と比較して大幅なパフォーマンスの向上が示されています。,https://d3i71xaburhd42.cloudfront.net/f17cfbaf28a4fadfa817972ec678e6600e14df68/2-Figure1-1.png
TSQA: Tabular Scenario Based Question Answering,"['Xiao Li', 'Yawei Sun', 'Gong Cheng']",https://arxiv.org/abs/2101.11429,"Scenario-based question answering (SQA) has attracted an increasing research interest. Compared with the well-studied machine reading comprehension (MRC), SQA is a more challenging task: a scenario may contain not only a textual passage to read but also structured data like tables, i.e., tabular scenario based question answering (TSQA). AI applications of TSQA such as answering multiple-choice questions in high-school exams require synthesizing data in multiple cells and combining tables with texts and domain knowledge to infer answers. To support the study of this task, we construct GeoTSQA. This dataset contains 1k real questions contextualized by tabular scenarios in the geography domain. To solve the task, we extend state-of-the-art MRC methods with TTGen, a novel table-to-text generator. It generates sentences from variously synthesized tabular data and feeds the downstream MRC method with the most useful sentences. Its sentence ranking model fuses the information in the scenario, question, and domain knowledge. Our approach outperforms a variety of strong baseline methods on GeoTSQA.",シナリオベースの質問応答（SQA）は、ますます多くの研究の関心を集めています。よく研究されている機械読解（MRC）と比較すると、SQAはより困難なタスクです。シナリオには、読むためのテキストパッセージだけでなく、表のような構造化データ、つまり表形式のシナリオベースの質問応答（TSQA）も含まれる場合があります。高校の試験で多肢選択式の質問に答えるなど、TSQAのAIアプリケーションでは、複数のセルでデータを合成し、表とテキストおよびドメイン知識を組み合わせて答えを推測する必要があります。このタスクの研究をサポートするために、GeoTSQAを構築します。このデータセットには、地理ドメインの表形式のシナリオによってコンテキスト化された1kの実際の質問が含まれています。このタスクを解決するために、新しいテーブルからテキストへのジェネレーターであるTTGenを使用して最先端のMRCメソッドを拡張します。さまざまに合成された表形式のデータから文を生成し、下流のMRCメソッドに最も有用な文を提供します。そのセンテンスランキングモデルは、シナリオ、質問、およびドメイン知識の情報を融合します。私たちのアプローチは、GeoTSQAのさまざまな強力なベースライン手法よりも優れています。,https://d3i71xaburhd42.cloudfront.net/084c5afc5b16b0c50c53390f550a13f4ed4c7d3c/2-Figure1-1.png
Deep Just-in-Time Inconsistency Detection between Comments and Source Code,"['Sheena L Panthaplackel', 'Junyi Jessy Li', 'Milos Gligoric', 'Raymond Mooney']",https://arxiv.org/abs/2010.01625,"Natural language comments convey key aspects of source code such as implementation, usage, and pre- and post-conditions. Failure to update comments accordingly when the corresponding code is modified introduces inconsistencies, which is known to lead to confusion and software bugs. In this paper, we aim to detect whether a comment becomes inconsistent as a result of changes to the corresponding body of code, in order to catch potential inconsistencies just-in-time, i.e., before they are committed to a version control system. To achieve this, we develop a deep-learning approach that learns to correlate a comment with code changes. By evaluating on a large corpus of comment/code pairs spanning various comment types, we show that our model outperforms multiple baselines by significant margins. For extrinsic evaluation, we show the usefulness of our approach by combining it with a comment update model to build a more comprehensive automatic comment maintenance system which can both detect and resolve inconsistent comments based on code changes.",自然言語コメントは、実装、使用法、事前条件と事後条件など、ソースコードの重要な側面を伝えます。対応するコードが変更されたときにそれに応じてコメントを更新しないと、不整合が発生し、混乱やソフトウェアのバグにつながることが知られています。このホワイトペーパーでは、対応するコード本体の変更の結果としてコメントが不整合になるかどうかを検出し、潜在的な不整合をジャストインタイムで、つまりバージョン管理システムにコミットする前にキャッチすることを目的としています。これを実現するために、コメントとコードの変更を関連付けることを学習するディープラーニングアプローチを開発します。さまざまなコメントタイプにまたがるコメント/コードペアの大規模なコーパスを評価することにより、モデルが複数のベースラインを大幅に上回っていることを示します。外部評価については、コメント更新モデルと組み合わせて、コードの変更に基づいて一貫性のないコメントを検出および解決できる、より包括的な自動コメント保守システムを構築することにより、このアプローチの有用性を示します。,https://d3i71xaburhd42.cloudfront.net/03b6e258168796f96f1c40d32411bd699b6de922/2-Figure1-1.png
Transfer Graph Neural Networks for Pandemic Forecasting,"['Georgios Panagopoulos', 'Giannis Nikolentzos', 'Michalis Vazirgiannis']",https://arxiv.org/abs/2009.08388,"The recent outbreak of COVID-19 has affected millions of individuals around the world and has posed a significant challenge to global healthcare. From the early days of the pandemic, it became clear that it is highly contagious and that human mobility contributes significantly to its spread. In this paper, we study the impact of population movement on the spread of COVID-19, and we capitalize on recent advances in the field of representation learning on graphs to capture the underlying dynamics. Specifically, we create a graph where nodes correspond to a country's regions and the edge weights denote human mobility from one region to another. Then, we employ graph neural networks to predict the number of future cases, encoding the underlying diffusion patterns that govern the spread into our learning model. Furthermore, to account for the limited amount of training data, we capitalize on the pandemic's asynchronous outbreaks across countries and use a model-agnostic meta-learning based method to transfer knowledge from one country's model to another's. We compare the proposed approach against simple baselines and more traditional forecasting techniques in 3 European countries. Experimental results demonstrate the superiority of our method, highlighting the usefulness of GNNs in epidemiological prediction. Transfer learning provides the best model, highlighting its potential to improve the accuracy of the predictions in case of secondary waves, if data from past/parallel outbreaks is utilized.",最近のCOVID-19の発生は、世界中の何百万もの個人に影響を及ぼし、世界の医療に重大な課題をもたらしました。パンデミックの初期から、それは非常に伝染性であり、人間の移動性がその広がりに大きく貢献していることが明らかになりました。この論文では、人口移動がCOVID-19の蔓延に与える影響を研究し、グラフでの表現学習の分野における最近の進歩を利用して、根底にあるダイナミクスを捉えます。具体的には、ノードが国の地域に対応し、エッジの重みが1つの地域から別の地域への人間の移動性を示すグラフを作成します。次に、グラフニューラルネットワークを使用して将来のケースの数を予測し、学習モデルへの広がりを支配する基礎となる拡散パターンをエンコードします。さらに、限られた量のトレーニングデータを説明するために、国全体でのパンデミックの非同期発生を利用し、モデルにとらわれないメタ学習ベースの方法を使用して、ある国のモデルから別の国のモデルに知識を転送します。提案されたアプローチを、ヨーロッパの3か国における単純なベースラインおよびより伝統的な予測手法と比較します。実験結果は、疫学的予測におけるGNNの有用性を強調し、私たちの方法の優位性を示しています。転移学習は最良のモデルを提供し、過去/並行した発生からのデータが利用される場合、二次波の場合の予測の精度を改善する可能性を強調します。,
HMS: A Hierarchical Solver with Dependency-Enhanced Understanding for Math Word Problem,"['Xin Lin', 'Zhenya Huang', 'Hongke Zhao', 'Enhong Chen', 'Qi Liu', 'Hao Wang', 'Shijin Wang']",,,,
A Novice-Reviewer Experiment to Address Scarcity of Qualified Reviewers in Large Conferences,"['Ivan Stelmakh', 'Nihar Shah', 'Aarti Singh', 'Hal Daume']",https://arxiv.org/abs/2011.15050,"Conference peer review constitutes a human-computation process whose importance cannot be overstated: not only it identifies the best submissions for acceptance, but, ultimately, it impacts the future of the whole research area by promoting some ideas and restraining others. A surge in the number of submissions received by leading AI conferences has challenged the sustainability of the review process by increasing the burden on the pool of qualified reviewers which is growing at a much slower rate. In this work, we consider the problem of reviewer recruiting with a focus on the scarcity of qualified reviewers in large conferences. Specifically, we design a procedure for (i) recruiting reviewers from the population not typically covered by major conferences and (ii) guiding them through the reviewing pipeline. In conjunction with ICML 2020 -- a large, top-tier machine learning conference -- we recruit a small set of reviewers through our procedure and compare their performance with the general population of ICML reviewers. Our experiment reveals that a combination of the recruiting and guiding mechanisms allows for a principled enhancement of the reviewer pool and results in reviews of superior quality compared to the conventional pool of reviews as evaluated by senior members of the program committee (meta-reviewers).",コンファレンスピアレビューは、その重要性を誇張することのできない人間の計算プロセスを構成します。それは、受け入れに最適な提出物を特定するだけでなく、最終的には、いくつかのアイデアを促進し、他のアイデアを抑制することによって、研究領域全体の将来に影響を与えます。主要なAI会議が受け取る提出物の数の急増は、はるかに遅い速度で成長している資格のあるレビューアのプールへの負担を増やすことによって、レビュープロセスの持続可能性に挑戦しています。この作業では、大規模な会議での資格のあるレビュー担当者の不足に焦点を当てて、レビュー担当者の募集の問題を検討します。具体的には、（i）通常は主要な会議でカバーされない母集団からレビュー担当者を募集し、（ii）レビューパイプラインを通じてレビュー担当者をガイドするための手順を設計します。 ICML 2020に関連して、大規模な一流の機械学習会議で、手順を通じて少数のレビュー担当者を募集し、そのパフォーマンスをICMLレビュー担当者の一般的な母集団と比較します。私たちの実験では、採用メカニズムとガイドメカニズムの組み合わせにより、レビュー担当者プールの原則的な強化が可能になり、プログラム委員会の上級メンバー（メタレビュー担当者）によって評価された従来のレビュープールと比較して優れた品質のレビューが得られることが明らかになりました。,https://d3i71xaburhd42.cloudfront.net/f136a0fdc2065485c83396ae41d431395de51af4/7-Figure1-1.png
Overcoming Catastrophic Forgetting in Graph Neural Networks with Experience Replay,"['Fan Zhou', 'Chengtai Cao']",https://arxiv.org/abs/2003.09908,"Graph Neural Networks (GNNs) have recently received significant research attention due to their superior performance on a variety of graph-related learning tasks. Most of the current works focus on either static or dynamic graph settings, addressing a single particular task, e.g., node/graph classification, link prediction. In this work, we investigate the question: can GNNs be applied to continuously learning a sequence of tasks? Towards that, we explore the Continual Graph Learning (CGL) paradigm and present the Experience Replay based framework ER-GNN for CGL to alleviate the catastrophic forgetting problem in existing GNNs. ER-GNN stores knowledge from previous tasks as experiences and replays them when learning new tasks to mitigate the catastrophic forgetting issue. We propose three experience node selection strategies: mean of feature, coverage maximization, and influence maximization, to guide the process of selecting experience nodes. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our ER-GNN and shed light on the incremental graph (non-Euclidean) structure learning.",グラフニューラルネットワーク（GNN）は、さまざまなグラフ関連の学習タスクで優れたパフォーマンスを発揮するため、最近大きな研究の注目を集めています。現在の作業のほとんどは、静的または動的なグラフ設定に焦点を当てており、ノード/グラフの分類、リンク予測など、単一の特定のタスクに対応しています。この作業では、質問を調査します。GNNは、一連のタスクを継続的に学習するために適用できますか？そのために、Continual Graph Learning（CGL）パラダイムを調査し、CGL用のExperience ReplayベースのフレームワークER-GNNを提示して、既存のGNNの壊滅的な忘却の問題を軽減します。 ER-GNNは、以前のタスクからの知識を経験として保存し、新しいタスクを学習するときにそれらを再生して、壊滅的な忘却の問題を軽減します。エクスペリエンスノードを選択するプロセスをガイドするために、3つのエクスペリエンスノード選択戦略を提案します。機能の平均、カバレッジの最大化、および影響の最大化です。 3つのベンチマークデータセットでの広範な実験は、ER-GNNの有効性を示し、インクリメンタルグラフ（非ユークリッド）構造学習に光を当てます。,
Signaling in Bayesian Network Congestion Games: The Subtle Power of Symmetry,"['Matteo Castiglioni', 'Andrea Celli', 'Alberto Marchesi', 'Nicola Gatti']",https://arxiv.org/abs/2002.05190,"Network congestion games are a well-understood model of multi-agent strategic interactions. Despite their ubiquitous applications, it is not clear whether it is possible to design information structures to ameliorate the overall experience of the network users. We focus on Bayesian games with atomic players, where network vagaries are modeled via a (random) state of nature which determines the costs incurred by the players. A third-party entity---the sender---can observe the realized state of the network and exploit this additional information to send a signal to each player. A natural question is the following: is it possible for an informed sender to reduce the overall social cost via the strategic provision of information to players who update their beliefs rationally? The paper focuses on the problem of computing optimal ex ante persuasive signaling schemes, showing that symmetry is a crucial property for its solution. Indeed, we show that an optimal ex ante persuasive signaling scheme can be computed in polynomial time when players are symmetric and have affine cost functions. Moreover, the problem becomes NP-hard when players are asymmetric, even in non-Bayesian settings.",ネットワーク輻輳ゲームは、マルチエージェントの戦略的相互作用のよく理解されているモデルです。それらのユビキタスなアプリケーションにもかかわらず、ネットワークユーザーの全体的なエクスペリエンスを改善するための情報構造を設計することが可能かどうかは明らかではありません。アトミックプレーヤーを使用したベイジアンゲームに焦点を当てます。このゲームでは、ネットワークの変動は、プレーヤーが負担するコストを決定する（ランダムな）自然状態を介してモデル化されます。送信者がネットワークの実現状態を監視し、この追加情報を利用して各プレーヤーに信号を送信できるサードパーティエンティティ。当然の質問は次のとおりです。情報に基づいた送信者が、信念を合理的に更新するプレーヤーに情報を戦略的に提供することで、全体的な社会的コストを削減することは可能ですか。この論文は、最適な事前の説得力のある信号方式を計算する問題に焦点を当てており、対称性がその解決策にとって重要な特性であることを示しています。確かに、プレーヤーが対称であり、アフィンコスト関数を持っている場合、最適な事前の説得力のあるシグナリングスキームが多項式時間で計算できることを示します。さらに、ベイジアン以外の設定でも、プレーヤーが非対称の場合、問題はNP困難になります。,https://d3i71xaburhd42.cloudfront.net/85f10fc6261e2ed11728101ec2f8f7bc26b650d3/3-Figure1-1.png
Optimal Decision Trees for Nonlinear Metrics,"['Emir Demirović', 'Peter Stuckey']",https://arxiv.org/abs/2009.06921,"Nonlinear metrics, such as the F1-score, Matthews correlation coefficient, and Fowlkes-Mallows index, are often used to evaluate the performance of machine learning models, in particular, when facing imbalanced datasets that contain more samples of one class than the other. Recent optimal decision tree algorithms have shown remarkable progress in producing trees that are optimal with respect to linear criteria, such as accuracy, but unfortunately nonlinear metrics remain a challenge. To address this gap, we propose a novel algorithm based on bi-objective optimisation, which treats misclassifications of each binary class as a separate objective. We show that, for a large class of metrics, the optimal tree lies on the Pareto frontier. Consequently, we obtain the optimal tree by using our method to generate the set of all nondominated trees. To the best of our knowledge, this is the first method to compute provably optimal decision trees for nonlinear metrics. Our approach leads to a trade-off when compared to optimising linear metrics: the resulting trees may be more desirable according to the given nonlinear metric at the expense of higher runtimes. Nevertheless, the experiments illustrate that runtimes are reasonable for majority of the tested datasets.",F1スコア、Matthews相関係数、Fowlkes-Mallowsインデックスなどの非線形メトリックは、特に、あるクラスのサンプルが他のクラスよりも多い不均衡なデータセットに直面した場合に、機械学習モデルのパフォーマンスを評価するためによく使用されます。最近の最適決定木アルゴリズムは、精度などの線形基準に関して最適なツリーの作成において目覚ましい進歩を示していますが、残念ながら非線形メトリックは依然として課題です。このギャップに対処するために、多目的最適化に基づく新しいアルゴリズムを提案します。これは、各バイナリクラスの誤分類を個別の目的として扱います。メトリックの大規模なクラスの場合、最適なツリーはパレートフロンティアにあることを示します。したがって、私たちの方法を使用して、すべての非優勢ツリーのセットを生成することにより、最適なツリーを取得します。私たちの知る限り、これは非線形メトリックの証明可能な最適決定木を計算する最初の方法です。私たちのアプローチは、線形メトリックの最適化と比較した場合、トレードオフにつながります。結果として得られるツリーは、実行時間が長くなる代わりに、特定の非線形メトリックに従ってより望ましい場合があります。それにもかかわらず、実験は、ランタイムがテストされたデータセットの大部分にとって妥当であることを示しています。,https://d3i71xaburhd42.cloudfront.net/c1e48bbf0a8a02e548a97cd79d853879228a0592/5-Figure1-1.png
REM-Net: Recursive Erasure Memory Network for Commonsense Evidence Refinement,"['Yinya Huang', 'Meng Fang', 'Xunlin Zhan', 'Qingxing Cao', 'Xiaodan Liang']",,,,
Semantic Consistency Networks for 3D Object Detection,"['Wenwen Wei', 'Ping Wei', 'Nanning Zheng']",,,,
Personalized Adaptive Meta Learning for Cold-Start User Preference Prediction,"['Runsheng Yu', 'Yu Gong', 'Xu He', 'Yu Zhu', 'Qingwen Liu', 'Wenwu Ou', 'Bo An']",https://arxiv.org/abs/2012.11842,"A common challenge in personalized user preference prediction is the cold-start problem. Due to the lack of user-item interactions, directly learning from the new users’ log data causes serious over-fitting problem. Recently, many existing studies regard the cold-start personalized preference prediction as a few-shot learning problem, where each user is the task and recommended items are the classes, and the gradient-based meta learning method (MAML) is leveraged to address this challenge. However, in real-world application, the users are not uniformly distributed (i.e., different users may have different browsing history, recommended items, and user profiles. We define the major users as the users in the groups with large numbers of users sharing similar user information, and other users are the minor users), existing MAML approaches tend to fit the major users and ignore the minor users. To address this cold-start task-overfitting problem, we propose a novel personalized adaptive meta learning approach to consider both the major and the minor users with three key contributions: 1) We are the first to present a personalized adaptive learning rate meta-learning approach to improve the performance of MAML by focusing on both the major and minor users. 2) To provide better personalized learning rates for each user, we introduce a similarity-based method to find similar users as a reference and a tree-based method to store users’ features for fast search. 3) To reduce the memory usage, we design a memory agnostic regularizer to further reduce the space complexity to constant while maintain the performance. Experiments on MovieLens, BookCrossing, and real-world production datasets reveal that our method outperforms the state-of-the-art methods dramatically for both the minor and major users.",パーソナライズされたユーザーの好みの予測における一般的な課題は、コールドスタートの問題です。ユーザーとアイテムの相互作用がないため、新しいユーザーのログデータから直接学習すると、深刻な過剰適合の問題が発生します。最近、多くの既存の研究では、コールドスタートのパーソナライズされた選好予測を数ショットの学習問題と見なしています。各ユーザーがタスクであり、推奨項目がクラスであり、勾配ベースのメタ学習法（MAML）を利用してこれに対処します。チャレンジ。ただし、実際のアプリケーションでは、ユーザーは均一に分散されていません（つまり、ユーザーごとに閲覧履歴、推奨アイテム、ユーザープロファイルが異なる場合があります。主要なユーザーは、多数のユーザーが同じようなものを共有しているグループ内のユーザーとして定義されます。ユーザー情報、および他のユーザーはマイナーユーザーです）、既存のMAMLアプローチはメジャーユーザーに適合し、マイナーユーザーを無視する傾向があります。このコールドスタートタスクの過剰適合問題に対処するために、メジャーユーザーとマイナーユーザーの両方を考慮した新しいパーソナライズされた適応メタ学習アプローチを提案します。1）パーソナライズされた適応学習率メタ学習を初めて提示します。メジャーユーザーとマイナーユーザーの両方に焦点を当てることにより、MAMLのパフォーマンスを向上させるアプローチ。 2）各ユーザーにより良いパーソナライズされた学習率を提供するために、参照として類似ユーザーを見つける類似性ベースの方法と、高速検索のためにユーザー機能を保存するツリーベースの方法を導入します。 3）メモリ使用量を削減するために、メモリに依存しない正則化を設計して、パフォーマンスを維持しながらスペースの複雑さを一定にさらに削減します。 MovieLens、BookCrossing、および実際の制作データセットでの実験により、私たちの方法は、マイナーユーザーとメジャーユーザーの両方にとって、最先端の方法よりも劇的に優れていることが明らかになりました。,https://d3i71xaburhd42.cloudfront.net/449e9f36d28c24a240f463b26abfda2dcf33ce17/1-Figure1-1.png
Towards Enabling Learnware to Handle Unseen Jobs,"['Yu-Jie Zhang', 'Yu-Hu Yan', 'Peng Zhao', 'Zhi-Hua Zhou']",,,,
Region-Aware Global Context Modeling for Automatic Nerve Segmentation from Ultrasound Images,"['Huisi Wu', 'Jiasheng Liu', 'Wei Wang', 'Zhenkun Wen', 'Jing Qin']",,,,
Fully-Connected Tensor Network Decomposition and Its Application to Higher-Order Tensor Completion,"['Yu-Bang Zheng', 'Ting-Zhu Huang', 'Xi-Le Zhao', 'Qibin Zhao', 'Tai-Xiang Jiang']",,,,
Catch Me If I Can: Detecting Strategic Behaviour in Peer Assessment,"['Ivan Stelmakh', 'Nihar Shah', 'Aarti Singh']",https://arxiv.org/abs/2010.04041,"We consider the issue of strategic behaviour in various peer-assessment tasks, including peer grading of exams or homeworks and peer review in hiring or promotions. When a peer-assessment task is competitive (e.g., when students are graded on a curve), agents may be incentivized to misreport evaluations in order to improve their own final standing. Our focus is on designing methods for detection of such manipulations. Specifically, we consider a setting in which agents evaluate a subset of their peers and output rankings that are later aggregated to form a final ordering. In this paper, we investigate a statistical framework for this problem and design a principled test for detecting strategic behaviour. We prove that our test has strong false alarm guarantees and evaluate its detection ability in practical settings. For this, we design and execute an experiment that elicits strategic behaviour from subjects and release a dataset of patterns of strategic behaviour that may be of independent interest. We then use the collected data to conduct a series of real and semi-synthetic evaluations that demonstrate a strong detection power of our test.",私たちは、試験や宿題のピアグレーディングや採用や昇進のピアレビューなど、さまざまなピアアセスメントタスクにおける戦略的行動の問題を検討します。ピアアセスメントタスクが競争的である場合（たとえば、学生がカーブで採点される場合）、エージェントは、自身の最終的な地位を向上させるために、評価を誤って報告するように動機付けられる場合があります。私たちの焦点は、そのような操作を検出するための方法を設計することにあります。具体的には、エージェントがピアのサブセットを評価し、後で集計されて最終的な順序を形成するランキングを出力する設定を検討します。この論文では、この問題の統計的フレームワークを調査し、戦略的行動を検出するための原理的なテストを設計します。私たちのテストには強力な誤警報が保証されていることを証明し、実際の設定でその検出能力を評価します。このために、被験者から戦略的行動を引き出す実験を設計および実行し、独立した関心を持つ可能性のある戦略的行動のパターンのデータセットをリリースします。次に、収集したデータを使用して、テストの強力な検出力を実証する一連の実際の評価と半合成の評価を実行します。,https://d3i71xaburhd42.cloudfront.net/b0894f5c914cd90cc3b3e16b15bec11efe317b14/5-Figure1-1.png
Decision-Guided Weighted Automata Extraction from Recurrent Neural Networks,"['Xiyue Zhang', 'Xiaoning Du', 'Xiaofei Xie', 'Lei Ma', 'Yang Liu', 'Meng Sun']",,,,
Bayesian Optimized Monte Carlo Planning,"['John Mern', 'Anil Yildiz', 'Zachary Sunberg', 'Tapan Mukerji', 'Mykel Kochenderfer']",https://arxiv.org/abs/2010.03597,"Online solvers for partially observable Markov decision processes have difficulty scaling to problems with large action spaces. Monte Carlo tree search with progressive widening attempts to improve scaling by sampling from the action space to construct a policy search tree. The performance of progressive widening search is dependent upon the action sampling policy, often requiring problem-specific samplers. In this work, we present a general method for efficient action sampling based on Bayesian optimization. The proposed method uses a Gaussian process to model a belief over the action-value function and selects the action that will maximize the expected improvement in the optimal action value. We implement the proposed approach in a new online tree search algorithm called Bayesian Optimized Monte Carlo Planning (BOMCP). Several experiments show that BOMCP is better able to scale to large action space POMDPs than existing state-of-the-art tree search solvers.",部分的に観測可能なマルコフ決定過程のオンラインソルバーは、大きなアクションスペースの問題にスケーリングするのが困難です。プログレッシブ拡張を使用したモンテカルロ木探索は、アクションスペースからサンプリングしてポリシー検索ツリーを構築することにより、スケーリングを改善しようとします。プログレッシブ拡大検索のパフォーマンスは、アクションサンプリングポリシーに依存し、多くの場合、問題固有のサンプラーが必要です。この作業では、ベイズ最適化に基づく効率的なアクションサンプリングの一般的な方法を示します。提案された方法は、ガウス過程を使用して、アクション値関数に対する信念をモデル化し、最適なアクション値の期待される改善を最大化するアクションを選択します。提案されたアプローチを、ベイジアン最適化モンテカルロ計画（BOMCP）と呼ばれる新しいオンラインツリー検索アルゴリズムに実装します。いくつかの実験は、BOMCPが既存の最先端のツリー検索ソルバーよりも大きなアクションスペースPOMDPにうまくスケーリングできることを示しています。,https://d3i71xaburhd42.cloudfront.net/108184c22782466c04890a1bff254a7791e93d2d/5-Figure1-1.png
Precise Yet Efficient Semantic Calibration and Refinement in ConvNets for Real-Time Polyp Segmentation from Colonoscopy Videos,"['Huisi Wu', 'Jiafu Zhong', 'Wei Wang', 'Zhenkun Wen', 'Jing Qin']",,,,
Deep Low-Contrast Image Enhancement Using Structure Tensor Representation,"['Hyungjoo Jung', 'Hyunsung Jang', 'Namkoo Ha', 'Kwanghoon Sohn']",,,,
Towards Effective Context for Meta-Reinforcement Learning: An Approach Based on Contrastive Learning,"['Haotian Fu', 'Hongyao Tang', 'Jianye Hao', 'Chen Chen', 'Xidong Feng', 'Dong Li', 'Wulong Liu']",https://arxiv.org/abs/2009.13891,"Context, the embedding of previous collected trajectories, is a powerful construct for Meta-Reinforcement Learning (Meta-RL) algorithms. By conditioning on an effective context, Meta-RL policies can easily generalize to new tasks within a few adaptation steps. We argue that improving the quality of context involves answering two questions: 1. How to train a compact and sufficient encoder that can embed the task-specific information contained in prior trajectories? 2. How to collect informative trajectories of which the corresponding context reflects the specification of tasks? To this end, we propose a novel Meta-RL framework called CCM (Contrastive learning augmented Context-based Meta-RL). We first focus on the contrastive nature behind different tasks and leverage it to train a compact and sufficient context encoder. Further, we train a separate exploration policy and theoretically derive a new information-gain-based objective which aims to collect informative trajectories in a few steps. Empirically, we evaluate our approaches on common benchmarks as well as several complex sparse-reward environments. The experimental results show that CCM outperforms state-of-the-art algorithms by addressing previously mentioned problems respectively.",以前に収集された軌跡の埋め込みであるコンテキストは、メタ強化学習（Meta-RL）アルゴリズムの強力な構成要素です。効果的なコンテキストを条件付けることにより、Meta-RLポリシーは、いくつかの適応ステップ内で新しいタスクに簡単に一般化できます。コンテキストの品質を向上させるには、次の2つの質問に答えることが必要であると主張します。1。以前の軌跡に含まれるタスク固有の情報を埋め込むことができるコンパクトで十分なエンコーダーをトレーニングするにはどうすればよいですか。 2.対応するコンテキストがタスクの仕様を反映している有益な軌跡を収集する方法は？この目的のために、CCM（対照学習拡張コンテキストベースのメタRL）と呼ばれる新しいメタRLフレームワークを提案します。まず、さまざまなタスクの背後にある対照的な性質に焦点を当て、それを活用してコンパクトで十分なコンテキストエンコーダーをトレーニングします。さらに、個別の探索ポリシーをトレーニングし、いくつかのステップで有益な軌道を収集することを目的とした、情報獲得に基づく新しい目標を理論的に導き出します。経験的に、私たちは一般的なベンチマークといくつかの複雑なまばらな報酬環境で私たちのアプローチを評価します。実験結果は、CCMが前述の問題にそれぞれ対処することにより、最先端のアルゴリズムよりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/8e679513c341684926c85951dffff04f3256d2a2/2-Figure1-1.png
How Do We Move: Modeling Human Movement with System Dynamics,"['Hua Wei', 'Dongkuan Xu', 'Junjie Liang', 'Zhenhui (Jessie) Li']",,,,
Improved POMDP Tree Search Planning with Prioritized Action Branching,"['John Mern', 'Anil Yildiz', 'Lawrence Bush', 'Tapan Mukerji', 'Mykel Kochenderfer']",https://arxiv.org/abs/2010.03599,Online solvers for partially observable Markov decision processes have difficulty scaling to problems with large action spaces. This paper proposes a method called PA-POMCPOW to sample a subset of the action space that provides varying mixtures of exploitation and exploration for inclusion in a search tree. The proposed method first evaluates the action space according to a score function that is a linear combination of expected reward and expected information gain. The actions with the highest score are then added to the search tree during tree expansion. Experiments show that PA-POMCPOW is able to outperform existing state-of-the-art solvers on problems with large discrete action spaces.,部分的に観測可能なマルコフ決定過程のオンラインソルバーは、大きなアクションスペースの問題にスケーリングするのが困難です。このホワイトペーパーでは、PA-POMCPOWと呼ばれる方法を提案して、検索ツリーに含めるための活用と探索のさまざまな組み合わせを提供するアクションスペースのサブセットをサンプリングします。提案された方法は、最初に、期待される報酬と期待される情報獲得の線形結合であるスコア関数に従ってアクション空間を評価します。スコアが最も高いアクションは、ツリーの展開中に検索ツリーに追加されます。実験によると、PA-POMCPOWは、大きな離散アクションスペースの問題について、既存の最先端のソルバーよりも優れたパフォーマンスを発揮します。,https://d3i71xaburhd42.cloudfront.net/ad2dc7542376eed6e04ac3d35ae100e7bdbff6d4/1-Figure1-1.png
Parameterized Algorithms for MILPS with Small Treedepth,"['Cornelius Brand', 'Martin Koutecky', 'Sebastian Ordyniak']",https://arxiv.org/abs/1912.03501,"Solving (mixed) integer linear programs, (M)ILPs for short, is a fundamental optimization task. While hard in general, recent years have brought about vast progress for solving structurally restricted, (non-mixed) ILPs: $n$-fold, tree-fold, 2-stage stochastic and multi-stage stochastic programs admit efficient algorithms, and all of these special cases are subsumed by the class of ILPs of small treedepth. 
In this paper, we extend this line of work to the mixed case, by showing an algorithm solving MILP in time $f(a,d) \textrm{poly}(n)$, where $a$ is the largest coefficient of the constraint matrix, $d$ is its treedepth, and $n$ is the number of variables. 
This is enabled by proving bounds on the denominators of the vertices of bounded-treedepth (non-integer) linear programs. We do so by carefully analyzing the inverses of invertible submatrices of the constraint matrix. This allows us to afford scaling up the mixed program to the integer grid, and applying the known methods for integer programs. 
We trace the limiting boundary of our approach, showing that naturally related classes of linear programs have vertices of unbounded fractionality. Finally, we show that restricting the structure of only the integral variables in the constraint matrix does not yield tractable special cases.",（混合）整数線形計画法（略して（M）ILP）を解くことは、基本的な最適化タスクです。一般的には難しいですが、近年、構造的に制限された（混合されていない）ILPの解決に大きな進歩がもたらされました。n-fold、tree-fold、2ステージ確率およびマルチステージ確率プログラムは、効率的なアルゴリズムを認めています。特殊なケースは、ツリーの深さが小さいILPのクラスに含まれます。この論文では、時間f（a、d）poly（n）でMILPを解くアルゴリズムを示すことにより、この作業ラインを混合ケースに拡張します。ここで、aは制約行列の最大係数、dはそのツリー深度です。 nは変数の数です。これは、有界ツリー深度（非整数）線形計画法の頂点の分母の境界を証明することによって可能になります。これを行うには、制約行列の可逆部分行列の逆行列を注意深く分析します。これにより、混合プログラムを整数グリッドにスケールアップし、既知の方法を整数プログラムに適用することができます。私たちのアプローチの限界境界をたどり、自然に関連する線形計画法のクラスが無制限の分数の頂点を持っていることを示します。最後に、制約行列の積分変数のみの構造を制限しても、扱いやすい特殊なケースが得られないことを示します。,
Joint Semantic-Geometric Learning for Polygonal Building Segmentation,"['Weijia Li', 'Wenqian Zhao', 'Huaping Zhong', 'Conghui He', 'Dahua Lin']",,,,
The Parameterized Complexity of Clustering Incomplete Data,"['Eduard Eiben', 'Robert Ganian', 'Iyad Kanj', 'Sebastian Ordyniak', 'Stefan Szeider']",,,,
Document-Level Relation Extraction with Reconstruction,"['Wang Xu', 'Kehai Chen', 'Tiejun Zhao']",https://arxiv.org/abs/2012.11384,"In document-level relation extraction (DocRE), graph structure is generally used to encode relation information in the input document to classify the relation category between each entity pair, and has greatly advanced the DocRE task over the past several years. However, the learned graph representation universally models relation information between all entity pairs regardless of whether there are relationships between these entity pairs. Thus, those entity pairs without relationships disperse the attention of the encoder-classifier DocRE for ones with relationships, which may further hind the improvement of DocRE. To alleviate this issue, we propose a novel encoder-classifierreconstructor model for DocRE. The reconstructor manages to reconstruct the ground-truth path dependencies from the graph representation, to ensure that the proposed DocRE model pays more attention to encode entity pairs with relationships in the training. Furthermore, the reconstructor is regarded as a relationship indicator to assist relation classification in the inference, which can further improve the performance of DocRE model. Experimental results on a large-scale DocRE dataset show that the proposed model can significantly improve the accuracy of relation extraction on a strong heterogeneous graph-based baseline. The code is publicly available at https://github.com/xwjim/DocRE-Rec.",ドキュメントレベルの関係抽出（DocRE）では、グラフ構造は通常、入力ドキュメントの関係情報をエンコードして各エンティティペア間の関係カテゴリを分類するために使用され、過去数年間でDocREタスクを大幅に進歩させました。ただし、学習されたグラフ表現は、これらのエンティティペア間に関係があるかどうかに関係なく、すべてのエンティティペア間の関係情報を普遍的にモデル化します。したがって、関係のないエンティティペアは、関係のあるエンティティペアに対するエンコーダ-分類子DocREの注意を分散させ、DocREの改善をさらに妨げる可能性があります。この問題を軽減するために、DocRE用の新しいエンコーダー分類子再構成モデ​​ルを提案します。再構築者は、グラフ表現からグラウンドトゥルースパスの依存関係を再構築し、提案されたDocREモデルがトレーニング内の関係を持つエンティティペアをエンコードすることにさらに注意を払うようにします。さらに、リコンストラクターは、推論における関係の分類を支援する関係インジケーターと見なされます。これにより、DocREモデルのパフォーマンスをさらに向上させることができます。大規模なDocREデータセットでの実験結果は、提案されたモデルが強力な異種グラフベースのベースラインでの関係抽出の精度を大幅に向上させることができることを示しています。コードはhttps://github.com/xwjim/DocRE-Recで公開されています。,https://d3i71xaburhd42.cloudfront.net/1e15de9245be9bf8f11c1270f46fb0195caf240d/2-Figure1-1.png
Simple is Not Easy: A Simple Strong Baseline for TextVQA and TextCaps,"['Qi Zhu', 'Chenyu Gao', 'Peng Wang', 'Qi Wu']",https://arxiv.org/abs/2012.05153,"Texts appearing in daily scenes that can be recognized by OCR (Optical Character Recognition) tools contain significant information, such as street name, product brand and prices. Two tasks -- text-based visual question answering and text-based image captioning, with a text extension from existing vision-language applications, are catching on rapidly. To address these problems, many sophisticated multi-modality encoding frameworks (such as heterogeneous graph structure) are being used. In this paper, we argue that a simple attention mechanism can do the same or even better job without any bells and whistles. Under this mechanism, we simply split OCR token features into separate visual- and linguistic-attention branches, and send them to a popular Transformer decoder to generate answers or captions. Surprisingly, we find this simple baseline model is rather strong -- it consistently outperforms state-of-the-art (SOTA) models on two popular benchmarks, TextVQA and all three tasks of ST-VQA, although these SOTA models use far more complex encoding mechanisms. Transferring it to text-based image captioning, we also surpass the TextCaps Challenge 2020 winner. We wish this work to set the new baseline for this two OCR text related applications and to inspire new thinking of multi-modality encoder design. Code is available at https://github.com/ZephyrZhuQi/ssbaseline",OCR（光学式文字認識）ツールで認識できる日常のシーンに表示されるテキストには、通りの名前、製品のブランド、価格などの重要な情報が含まれています。テキストベースの視覚的な質問応答とテキストベースの画像キャプションの2つのタスクは、既存の視覚言語アプリケーションからのテキスト拡張機能を使用して、急速に普及しています。これらの問題に対処するために、多くの洗練されたマルチモダリティエンコーディングフレームワーク（異種グラフ構造など）が使用されています。この論文では、単純な注意メカニズムが、ベルやホイッスルなしで同じまたはさらに優れた仕事をすることができると主張します。このメカニズムでは、OCRトークン機能を個別の視覚的および言語的注意ブランチに分割し、それらを人気のあるTransformerデコーダーに送信して、回答またはキャプションを生成します。驚いたことに、この単純なベースラインモデルはかなり強力であり、2つの人気のあるベンチマークであるTextVQAとST-VQAの3つのタスクすべてで、常に最先端の（SOTA）モデルを上回っていますが、これらのSOTAモデルははるかに複雑なエンコードメカニズムを使用しています。 。それをテキストベースの画像キャプションに転送すると、TextCaps Challenge2020の優勝者も上回ります。この作業が、この2つのOCRテキスト関連アプリケーションの新しいベースラインを設定し、マルチモダリティエンコーダ設計の新しい考え方を刺激することを願っています。コードはhttps://github.com/ZephyrZhuQi/ssbaselineで入手できます。,https://d3i71xaburhd42.cloudfront.net/952edddbb3438072312756762be1bfde287e1497/1-Figure1-1.png
Symbolic Search for Oversubscription Planning,"['David Speck', 'Michael Katz']",,,,
Automated Model Design and Benchmarking of Deep Learning Models for COVID-19 Detection with Chest CT Scans,"['Xin He', 'Shihao Wang', 'Shaohuai Shi', 'Xiaowen Chu', 'Jiangping Tang', 'Xin Liu', 'Chenggang Yan', 'Jiyong Zhang', 'Guiguang Ding']",,,,
Anytime Heuristic and Monte Carlo Methods for Large-Scale Simultaneous Coalition Structure Generation and Assignment,"['Fredrik Präntare', 'Fredrik Heintz', 'Herman Appelgren']",,,,
Understanding Catastrophic Overfitting in Single-Step Adversarial Training,"['Hoki Kim', 'Woojin Lee', 'Jaewook Lee']",https://arxiv.org/abs/2010.01799,"Adversarial examples are perturbed inputs that are designed to deceive machine-learning classifiers by adding adversarial perturbations to the original data. Although fast adversarial training have demonstrated both robustness and efficiency, the problem of ""catastrophic overfitting"" has been observed. It is a phenomenon that, during single-step adversarial training, the robust accuracy against projected gradient descent (PGD) suddenly decreases to 0% after few epochs, whereas the robustness against fast gradient sign method (FGSM) increases to 100%. In this paper, we address three main topics. (i) We demonstrate that catastrophic overfitting occurs in single-step adversarial training because it trains adversarial images with maximum perturbation only, not all adversarial examples in the adversarial direction, which leads to a distorted decision boundary and a highly curved loss surface. (ii) We experimentally prove this phenomenon by proposing a simple method using checkpoints. This method not only prevents catastrophic overfitting, but also overrides the belief that single-step adversarial training is hard to prevent multi-step attacks. (iii) We compare the performance of the proposed method to that obtained in recent works and demonstrate that it provides sufficient robustness to different attacks even after hundreds of training epochs in less time. All code for reproducing the experiments in this paper are at this https URL.",敵対的な例は、元のデータに敵対的な摂動を追加することによって機械学習分類器を欺くように設計された摂動入力です。迅速な敵対的訓練は堅牢性と効率性の両方を示していますが、「壊滅的な過剰適合」の問題が観察されています。これは、シングルステップの敵対的トレーニング中に、投影勾配降下（PGD）に対するロバストな精度が突然0に低下する現象です。,https://d3i71xaburhd42.cloudfront.net/c0cd5cfb9c3b1b2fe2380b8102dfea9cea598777/2-Figure1-1.png
Trembling-Hand Perfection and Correlation in Sequential Games,"['Alberto Marchesi', 'Nicola Gatti']",https://arxiv.org/abs/2012.06528,"We initiate the study of trembling-hand perfection in sequential (i.e., extensive-form) games with correlation. We introduce the extensive-form perfect correlated equilibrium (EFPCE) as a refinement of the classical extensive-form correlated equilibrium (EFCE) that amends its weaknesses off the equilibrium path. This is achieved by accounting for the possibility that players may make mistakes while following recommendations independently at each information set of the game. After providing an axiomatic definition of EFPCE, we show that one always exists since any perfect (Nash) equilibrium constitutes an EFPCE, and that it is a refinement of EFCE, as any EFPCE is also an EFCE. Then, we prove that, surprisingly, computing an EFPCE is not harder than finding an EFCE, since the problem can be solved in polynomial time for general n-player extensive-form games (also with chance). This is achieved by formulating the problem as that of finding a limit solution (as $\epsilon \rightarrow 0$) to a suitably defined trembling LP parametrized by $\epsilon$, featuring exponentially many variables and polynomially many constraints. To this end, we show how a recently developed polynomial-time algorithm for trembling LPs can be adapted to deal with problems having an exponential number of variables. This calls for the solution of a sequence of (non-trembling) LPs with exponentially many variables and polynomially many constraints, which is possible in polynomial time by applying an ellipsoid against hope approach.",相関のあるシーケンシャル（つまり、展開型）ゲームの摂動完全均衡の研究を開始します。均衡経路からの弱点を修正する古典的な展開型相関均衡（EFCE）の改良版として、展開型完全相関均衡（EFPCE）を紹介します。これは、ゲームの各情報セットで個別に推奨事項に従いながら、プレーヤーがミスを犯す可能性を考慮することによって達成されます。 EFPCEの公理的定義を提供した後、完全（ナッシュ）均衡がEFPCEを構成するため、常に存在すること、およびEFPCEもEFCEであるため、EFCEの改良版であることを示します。次に、驚くべきことに、EFPCEの計算はEFCEを見つけることよりも難しくないことを証明します。これは、一般的なnプレーヤーの展開型ゲームの多項式時間で問題を解決できるためです（これも偶然です）。これは、指数関数的に多くの変数と多項式的に多くの制約を特徴とする、によってパラメータ化された適切に定義された震えるLPの限界解（0として）を見つける問題として問題を定式化することによって達成されます。この目的のために、LPを震わせるために最近開発された多項式時間アルゴリズムを、指数関数的な数の変数を持つ問題に対処するためにどのように適合させることができるかを示します。これは、指数関数的に多くの変数と多項式的に多くの制約を持つ一連の（震えない）LPの解決を必要とします。これは、希望に対する楕円体アプローチを適用することにより、多項式時間で可能です。,https://d3i71xaburhd42.cloudfront.net/c8994263e4961526b6aeb8e42ef03e4b79534638/3-Figure1-1.png
Toward Robust Long Range Policy Transfer,"['Wei-Cheng Tseng', 'Jin-Siang Lin', 'Yao-Min Feng', 'Min Sun']",,,,
High Dimensional Level Set Estimation with Bayesian Neural Network,"['Huong Ha', 'Sunil Gupta', 'Santu Rana', 'Svetha Venkatesh']",https://arxiv.org/abs/2012.09973,"Level Set Estimation (LSE) is an important problem with applications in various fields such as material design, biotechnology, machine operational testing, etc. Existing techniques suffer from the scalability issue, that is, these methods do not work well with high dimensional inputs. This paper proposes novel methods to solve the high dimensional LSE problems using Bayesian Neural Networks. In particular, we consider two types of LSE problems: (1) explicit LSE problem where the threshold level is a fixed user-specified value, and, (2) implicit LSE problem where the threshold level is defined as a percentage of the (unknown) maximum of the objective function. For each problem, we derive the corresponding theoretic information based acquisition function to sample the data points so as to maximally increase the level set accuracy. Furthermore, we also analyse the theoretical time complexity of our proposed acquisition functions, and suggest a practical methodology to efficiently tune the network hyper-parameters to achieve high model accuracy. Numerical experiments on both synthetic and real-world datasets show that our proposed method can achieve better results compared to existing state-of-the-art approaches.",レベルセット推定（LSE）は、マテリアルデザイン、バイオテクノロジー、機械の動作テストなどのさまざまな分野のアプリケーションで重要な問題です。既存の手法にはスケーラビリティの問題があります。つまり、これらの方法は高次元の入力ではうまく機能しません。この論文は、ベイズニューラルネットワークを使用して高次元LSE問題を解決するための新しい方法を提案します。特に、2種類のLSE問題を検討します。（1）しきい値レベルがユーザー指定の固定値である明示的なLSE問題、および（2）しきい値レベルが（不明）のパーセンテージとして定義される暗黙的なLSE問題です。 ）目的関数の最大値。問題ごとに、対応する理論的な情報ベースの取得関数を導出して、データポイントをサンプリングし、レベルセットの精度を最大限に高めます。さらに、提案された取得関数の理論的な時間計算量を分析し、ネットワークのハイパーパラメータを効率的に調整して高いモデル精度を実現するための実用的な方法論を提案します。合成データセットと実世界のデータセットの両方での数値実験は、提案された方法が既存の最先端のアプローチと比較してより良い結果を達成できることを示しています。,https://d3i71xaburhd42.cloudfront.net/f7225998cd2c14958701c9c87f5324b88b6237b9/6-Figure1-1.png
Graph Neural Network-Based Anomaly Detection in Multivariate Time Series,"['Ailin Deng', 'Bryan Hooi']",,"Given high-dimensional time series data (e.g., sensor data), how can we detect anomalous events, such as system faults and attacks? More challengingly, how can we do this in a way that captures complex inter-sensor relationships, and detects and explains anomalies which deviate from these relationships? Recently, deep learning approaches have enabled improvements in anomaly detection in high-dimensional datasets; however, existing methods do not explicitly learn the structure of existing relationships between variables, or use them to predict the expected behavior of time series. Our approach combines a structure learning approach with graph neural networks, additionally using attention weights to provide explainability for the detected anomalies. Experiments on two real-world sensor datasets with ground truth anomalies show that our method detects anomalies more accurately than baseline approaches, accurately captures correlations between sensors, and allows users to deduce the root cause of a detected anomaly.",高次元の時系列データ（センサーデータなど）が与えられた場合、システム障害や攻撃などの異常なイベントをどのように検出できますか？さらに難しいことに、複雑なセンサー間の関係をキャプチャし、これらの関係から逸脱する異常を検出して説明する方法でこれを行うにはどうすればよいでしょうか。最近、深層学習アプローチにより、高次元データセットの異常検出を改善できるようになりました。ただし、既存のメソッドは、変数間の既存の関係の構造を明示的に学習したり、時系列の予想される動作を予測するためにそれらを使用したりしません。私たちのアプローチは、構造学習アプローチとグラフニューラルネットワークを組み合わせ、さらに注意の重みを使用して、検出された異常の説明可能性を提供します。グラウンドトゥルース異常を伴う2つの実世界のセンサーデータセットでの実験は、私たちの方法がベースラインアプローチよりも正確に異常を検出し、センサー間の相関を正確にキャプチャし、ユーザーが検出された異常の根本原因を推測できることを示しています。,https://d3i71xaburhd42.cloudfront.net/21d2742e38f7167354dafcf7f565d3894b31d008/3-Figure1-1.png
Answering Complex Queries in Knowledge Graphs with Bidirectional Sequence Encoders,"['Bhushan Kotnis', 'Carolin Lawrence', 'Mathias Niepert']",https://arxiv.org/abs/2004.02596,"Representation learning for knowledge graphs (KGs) has focused on the problem of answering simple link prediction queries. In this work we address the more ambitious challenge of predicting the answers of conjunctive queries with multiple missing entities. We propose Bi-Directional Query Embedding (BIQE), a method that embeds conjunctive queries with models based on bi-directional attention mechanisms. Contrary to prior work, bidirectional self-attention can capture interactions among all the elements of a query graph. We introduce a new dataset for predicting the answer of conjunctive query and conduct experiments that show BIQE significantly outperforming state of the art baselines.",知識グラフ（KG）の表現学習は、単純なリンク予測クエリに答える問題に焦点を合わせてきました。この作業では、複数のエンティティが欠落している結合クエリの回答を予測するという、より野心的な課題に対処します。双方向注意メカニズムに基づくモデルに結合クエリを埋め込む方法である双方向クエリ埋め込み（BIQE）を提案します。以前の作業とは異なり、双方向の自己注意は、クエリグラフのすべての要素間の相互作用をキャプチャできます。結合クエリの回答を予測するための新しいデータセットを導入し、BIQEが最先端のベースラインを大幅に上回っていることを示す実験を実施します。,https://d3i71xaburhd42.cloudfront.net/cd1dffa09c8163b3544a3f19d061ec76749a1e72/2-Figure1-1.png
Neural Relational Inference with Efficient Message Passing Mechanisms,"['Siyuan Chen', 'Jiahai Wang', 'Guoqing Li']",https://arxiv.org/abs/2101.09486,"Many complex processes can be viewed as dynamical systems of interacting agents. In many cases, only the state sequences of individual agents are observed, while the interacting relations and the dynamical rules are unknown. The neural relational inference (NRI) model adopts graph neural networks that pass messages over a latent graph to jointly learn the relations and the dynamics based on the observed data. However, NRI infers the relations independently and suffers from error accumulation in multi-step prediction at dynamics learning procedure. Besides, relation reconstruction without prior knowledge becomes more difficult in more complex systems. This paper introduces efficient message passing mechanisms to the graph neural networks with structural prior knowledge to address these problems. A relation interaction mechanism is proposed to capture the coexistence of all relations, and a spatio-temporal message passing mechanism is proposed to use historical information to alleviate error accumulation. Additionally, the structural prior knowledge, symmetry as a special case, is introduced for better relation prediction in more complex systems. The experimental results on simulated physics systems show that the proposed method outperforms existing state-of-the-art methods. Introduction Many complex processes in natural and social areas including multi-agent systems (Yang et al. 2018; Li et al. 2020), swarm systems (Oliveira et al. 2020), physical systems (Ha and Jeong 2020; Bapst et al. 2020) and social systems (Almaatouq et al. 2020; Zhang et al. 2020) can be viewed as dynamical systems of interacting agents. Revealing the underlying interactions and dynamics can help us understand, predict, and control the behavior of these systems. However, in many cases, only the state sequences of individual agents are observed, while the interacting relations and the dynamical rules are unknown. A lot of works (Hoshen 2017; van Steenkiste et al. 2018; Watters et al. 2017) use implicit interaction models to learn the dynamics. These models can be regarded as graph neural networks (GNNs) over a fully-connected graph, and the implicit interactions are modeled via message passing operations (Watters et al. 2017) or attention mechanisms (Hoshen *Corresponding author Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. infer",多くの複雑なプロセスは、相互作用するエージェントの動的システムと見なすことができます。多くの場合、個々のエージェントの状態シーケンスのみが観察され、相互作用関係と動的ルールは不明です。ニューラルリレーショナル推論（NRI）モデルは、潜在的なグラフを介してメッセージを渡すグラフニューラルネットワークを採用し、観測されたデータに基づいて関係とダイナミクスを共同で学習します。ただし、NRIは独立して関係を推測し、ダイナミクス学習手順での多段階予測でエラーが蓄積するという問題があります。さらに、事前の知識がない関係の再構築は、より複雑なシステムではより困難になります。この論文では、これらの問題に対処するための構造的な事前知識を備えたグラフニューラルネットワークに効率的なメッセージパッシングメカニズムを紹介します。すべての関係の共存をキャプチャするために関係相互作用メカニズムが提案され、エラーの蓄積を軽減するために履歴情報を使用するために時空間メッセージパッシングメカニズムが提案されます。さらに、より複雑なシステムでの関係予測を改善するために、構造的な事前知識、特殊なケースとしての対称性が導入されています。シミュレートされた物理システムに関する実験結果は、提案された方法が既存の最先端の方法よりも優れていることを示しています。はじめにマルチエージェントシステム（Yangetal。2018; Li etal。2020）、群れシステム（Oliveira etal。2020）、物理システム（Ha and Jeong 2020; Bapst et al。）を含む自然および社会領域における多くの複雑なプロセス。 2020）および社会システム（Almaatouqetal。2020; Zhang etal。2020）は、相互作用するエージェントの動的システムと見なすことができます。根底にある相互作用とダイナミクスを明らかにすることは、これらのシステムの動作を理解、予測、および制御するのに役立ちます。ただし、多くの場合、個々のエージェントの状態シーケンスのみが観察され、相互作用関係と動的ルールは不明です。多くの作品（Hoshen 2017; van Steenkisteetal。2018; Watters etal。2017）は、ダイナミクスを学習するために暗黙の相互作用モデルを使用しています。これらのモデルは、完全に接続されたグラフ上のグラフニューラルネットワーク（GNN）と見なすことができ、暗黙の相互作用は、メッセージパッシング操作（Watters etal。2017）または注意メカニズム（Hoshen *対応著者Copyright2021、Association for the人工知能学会（www.aaai.org）。無断複写・転載を禁じます。,https://d3i71xaburhd42.cloudfront.net/36d1934e8f6e5b16696aa22968d4a78790e6bf4d/1-Figure1-1.png
Toward Understanding the Influence of Individual Clients in Federated Learning,"['Yihao Xue', 'Chaoyue Niu', 'Zhenzhe Zheng', 'Shaojie Tang', 'Chengfei Lyu', 'Fan Wu', 'Guihai Chen']",https://arxiv.org/abs/2012.10936,"Federated learning allows mobile clients to jointly train a global model without sending their private data to a central server. Despite that extensive works have studied the performance guarantee of the global model, it is still unclear how each individual client influences the collaborative training process. In this work, we defined a novel notion, called Fed-Influence, to quantify this influence in terms of model parameter, and proposed an effective and efficient estimation algorithm. In particular, our design satisfies several desirable properties: (1) it requires neither retraining nor retracing, adding only linear computational overhead to clients and the server; (2) it strictly maintains the tenet of federated learning, without revealing any client’s local data; and (3) it works well on both convex and non-convex loss functions and does not require the final model to be optimal. Empirical results on a synthetic dataset and the FEMNIST dataset show that our estimation method can approximate Fed-Influence with small bias. Further, we demonstrated an application of client-level model debugging.",統合学習により、モバイルクライアントは、プライベートデータを中央サーバーに送信することなく、グローバルモデルを共同でトレーニングできます。グローバルモデルのパフォーマンス保証を研究した広範な作業にもかかわらず、個々のクライアントが共同トレーニングプロセスにどのように影響するかはまだ不明です。この作業では、モデルパラメータの観点からこの影響を定量化するために、Fed-Influenceと呼ばれる新しい概念を定義し、効果的かつ効率的な推定アルゴリズムを提案しました。特に、私たちの設計はいくつかの望ましい特性を満たしています。（1）再トレーニングも再トレースも必要とせず、クライアントとサーバーに線形の計算オーバーヘッドのみを追加します。 （2）クライアントのローカルデータを公開することなく、フェデレーション学習の信条を厳密に維持します。 （3）凸損失関数と非凸損失関数の両方でうまく機能し、最終モデルが最適である必要はありません。合成データセットとFEMNISTデータセットの経験的結果は、私たちの推定方法が小さなバイアスでFed-Influenceを近似できることを示しています。さらに、クライアントレベルのモデルデバッグのアプリケーションを示しました。,https://d3i71xaburhd42.cloudfront.net/f95f6f467735abd90c1f5f574d90eb00fa80acbc/4-Figure1-1.png
Edge-Competing Pathological Liver Vessel Segmentation with Limited Labels,"['Zunlei Feng', 'Zhonghua Wang', 'Xinchao Wang', 'Xiuming Zhang', 'Lechao Cheng', 'Jie Lei', 'Yuexuan Wang', 'Mingli Song']",,,,
A Simple Framework for Cognitive Planning,"['Jorge Fernandez', 'Dominique Longin', 'Emiliano Lorini', 'Frédéric Maris']",,,,
Symbolic Search for Optimal Total-Order HTN Planning,"['Gregor Behnke', 'David Speck']",,,,
How Linguistically Fair Are Multilingual Pre-Trained Language Models?,"['Monojit Choudhury', 'Amit Deshpande']",,,,
Objective-Based Hierarchical Clustering of Deep Embedding Vectors,"['Dmitrii Avdiukhin', 'Stanislav Naumov', 'Grigory Yaroslavtsev']",,,,
Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation,"['Shaoxiong Feng', 'Xuancheng Ren', 'Kan Li', 'Xu Sun']",,,,
Deep Graph Spectral Evolution Networks for Graph Topological Evolution,"['Negar Etemadyrad', 'Qingzhe Li', 'Liang Zhao']",,"Characterizing the underlying mechanism of graph topological evolution from a source graph to a target graph has attracted fast increasing attention in the deep graph learning domain. However, it is very challenging to build expressive and efficient models that can handle global and local evolution patterns between source and target graphs. On the other hand, graph topological evolution has been investigated in the graph signal processing domain historically, but it involves intensive labors to manually determine suitable prescribed spectral models and prohibitive difficulty to fit their potential combinations and compositions. To address these challenges, this paper proposes the deep Graph Spectral Evolution Network (GSEN) for modeling the graph topology evolution problem by the composition of newly-developed generalized graph kernels. GSEN can effectively fit a wide range of existing graph kernels and their combinations and compositions with the theoretical guarantee and experimental verification. GSEN has outstanding efficiency in terms of time complexity (O(n)) and parameter complexity (O(1)), where n is the number of nodes of the graph. Extensive experiments on multiple synthetic and real-world datasets demonstrate outstanding performance.",ソースグラフからターゲットグラフへのグラフトポロジ進化の根本的なメカニズムを特徴づけることは、ディープグラフ学習ドメインで急速に注目を集めています。ただし、ソースグラフとターゲットグラフの間のグローバルおよびローカルの進化パターンを処理できる、表現力豊かで効率的なモデルを構築することは非常に困難です。一方、グラフのトポロジー進化は、歴史的にグラフ信号処理領域で調査されてきましたが、適切な規定のスペクトルモデルを手動で決定するための多大な労力と、それらの潜在的な組み合わせや構成に合わせるのが非常に困難です。これらの課題に対処するために、この論文では、新しく開発された一般化されたグラフカーネルの構成によってグラフトポロジ進化問題をモデル化するためのディープグラフスペクトル進化ネットワーク（GSEN）を提案します。 GSENは、理論的保証と実験的検証により、既存のさまざまなグラフカーネルとその組み合わせおよび構成を効果的に適合させることができます。 GSENは、時間計算量（O（n））とパラメーター計算量（O（1））の点で優れた効率を示します。ここで、nはグラフのノード数です。複数の合成データセットと実世界のデータセットでの広範な実験は、卓越したパフォーマンスを示しています。,https://d3i71xaburhd42.cloudfront.net/bb4b5ae14d4c22771136ed4630c9c47b055950b2/5-Figure1-1.png
Reinforcement Learning with Trajectory Feedback,"['Yonathan Efroni', 'Nadav Merlis', 'Shie Mannor']",https://arxiv.org/abs/2008.06036,"The computational model of reinforcement learning is based upon the ability to query a score of every visited state-action pair, i.e., to observe a per state-action reward signal. However, in practice, it is often the case such a score is not readily available to the algorithm designer. In this work, we relax this assumption and require a weaker form of feedback, which we refer to as \emph{trajectory feedback}. Instead of observing the reward from every visited state-action pair, we assume we only receive a score that represents the quality of the whole trajectory observed by the agent. We study natural extensions of reinforcement learning algorithms to this setting, based on least-squares estimation of the unknown reward, for both the known and unknown transition model cases, and study the performance of these algorithms by analyzing the regret. For cases where the transition model is unknown, we offer a hybrid optimistic-Thompson Sampling approach that results in a computationally efficient algorithm.",強化学習の計算モデルは、訪問したすべての状態とアクションのペアのスコアを照会する機能、つまり、状態アクションごとの報酬信号を観察する機能に基づいています。ただし、実際には、そのようなスコアをアルゴリズム設計者がすぐに利用できない場合がよくあります。この作業では、この仮定を緩和し、より弱い形式のフィードバックを必要とします。これを軌道フィードバックと呼びます。訪問したすべての状態とアクションのペアからの報酬を観察する代わりに、エージェントによって観察された軌道全体の品質を表すスコアのみを受け取ると想定します。既知および未知の遷移モデルの場合の両方について、未知の報酬の最小二乗推定に基づいて、この設定に対する強化学習アルゴリズムの自然な拡張を研究し、後悔を分析することによってこれらのアルゴリズムのパフォーマンスを研究します。遷移モデルが不明な場合は、計算効率の高いアルゴリズムを実現する、楽観的でトンプソンのハイブリッドサンプリングアプローチを提供します。,
Knowledge-Guided Object Discovery with Acquired Deep Impressions,"['Jinyang Yuan', 'Bin Li', 'Xiangyang Xue']",,,,
Tracking interaction States for Multi-Turn Text-to-SQL Semantic Parsing,"['Runze Wang', 'Zhen-Hua Ling', 'Jingbo Zhou', 'Yu Hu']",https://arxiv.org/abs/2012.04995,"The task of multi-turn text-to-SQL semantic parsing aims to translate natural language utterances in an interaction into SQL queries in order to answer them using a database which normally contains multiple table schemas. Previous studies on this task usually utilized contextual information to enrich utterance representations and to further influence the decoding process. While they ignored to describe and track the interaction states which are determined by history SQL queries and are related with the intent of current utterance. In this paper, two kinds of interaction states are defined based on schema items and SQL keywords separately. A relational graph neural network and a non-linear layer are designed to update the representations of these two states respectively. The dynamic schema-state and SQL-state representations are then utilized to decode the SQL query corresponding to current utterance. Experimental results on the challenging CoSQL dataset demonstrate the effectiveness of our proposed method, which achieves better performance than other published methods on the task leaderboard.",テキストからSQLへのマルチターンセマンティック解析のタスクは、通常は複数のテーブルスキーマを含むデータベースを使用して応答するために、インタラクション内の自然言語の発話をSQLクエリに変換することを目的としています。このタスクに関する以前の研究では、通常、コンテキスト情報を利用して発話表現を充実させ、デコードプロセスにさらに影響を与えていました。彼らは、履歴SQLクエリによって決定され、現在の発話の意図に関連する相互作用状態を記述および追跡することを無視しました。この論文では、スキーマ項目とSQLキーワードに基づいて、2種類の相互作用状態を個別に定義します。リレーショナルグラフニューラルネットワークと非線形層は、これら2つの状態の表現をそれぞれ更新するように設計されています。次に、動的スキーマ状態表現とSQL状態表現を利用して、現在の発話に対応するSQLクエリをデコードします。挑戦的なCoSQLデータセットの実験結果は、タスクリーダーボードで公開されている他の方法よりも優れたパフォーマンスを実現する、提案された方法の有効性を示しています。,https://d3i71xaburhd42.cloudfront.net/849a987959193eed1d0ca9303d2ee9c7359b011a/1-Figure1-1.png
Commonsense Knowledge Aware Concept Selection for Diverse and Informative Visual Storytelling,"['Hong Chen', 'Yifei Huang', 'Hiroya Takamura', 'Hideki Nakayama']",,,,
Collaborative Group Learning,"['Shaoxiong Feng', 'Hongshen Chen', 'Xuancheng Ren', 'Zhuoye Ding', 'Kan Li', 'Xu Sun']",https://arxiv.org/abs/2009.07712,"Collaborative learning has successfully applied knowledge transfer to guiding a pool of small student networks towards robust local minima. However, previous approaches typically struggle with drastically aggravated student homogenization and rapidly growing computational complexity when the number of students rises. In this paper, we propose Collaborative Group Learning, an efficient framework that aims to maximize student population without sacrificing generalization performance and computational efficiency. First, each student is established by randomly routing on a modular neural network, which is not only parameter-efficient but also facilitates flexible knowledge communication between students due to random levels of representation sharing and branching. Second, to resist homogenization and further reduce the computational cost, students first compose diverse feature sets by exploiting the inductive bias from sub-sets of training data, and then aggregate and distill supplementary knowledge by choosing a random sub-group of students at each time step. Empirical evaluations on both image and text tasks indicate that our method significantly outperforms various state-of-the-art collaborative approaches whilst enhancing computational efficiency.",共同学習は、知識の伝達を適用して、小規模な学生ネットワークのプールを堅牢な極小値に導くことに成功しました。ただし、以前のアプローチでは、通常、学生の均質化が大幅に悪化し、学生の数が増えると計算の複雑さが急速に増大することに苦労しています。この論文では、一般化のパフォーマンスと計算効率を犠牲にすることなく、学生の人口を最大化することを目的とした効率的なフレームワークであるコラボレーティブグループラーニングを提案します。まず、各学生は、モジュール式ニューラルネットワーク上でランダムにルーティングすることによって確立されます。これは、パラメータ効率が高いだけでなく、表現の共有と分岐のランダムなレベルにより、学生間の柔軟な知識コミュニケーションを促進します。第二に、均質化に抵抗し、計算コストをさらに削減するために、学生は最初にトレーニングデータのサブセットからの誘導バイアスを利用して多様な機能セットを作成し、次に学生のランダムなサブグループを毎回選択して補足知識を集約および抽出しますステップ。画像とテキストの両方のタスクに関する経験的評価は、私たちの方法が、計算効率を高めながら、さまざまな最先端のコラボレーションアプローチを大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/d11afc012bcbb35b0d28713be3f4a08f082e619d/2-Figure1-1.png
Ideography Leads Us to the Field of Cognition: A Radical-Guided Associative Model for Chinese Text Classification,"['Hanqing Tao', 'Shiwei Tong', 'Kun Zhang', 'Tong Xu', 'Qi Liu', 'Enhong Chen', 'Min Hou']",,,,
GaussianPath: A Bayesian Multi-Hop Reasoning Framework for Knowledge Graph Reasoning,"['Guojia Wan', 'Bo Du']",,,,
A Bottom-Up DAG Structure Extraction Model for Math Word Problems,"['Yixuan Cao', 'Feng Hong', 'Hongwei Li', 'Ping Luo']",,,,
Bridging the Domain Gap: Improve Informal Language Translation via Counterfactual Domain Adaptation,"['Ke Wang', 'Guandan Chen', 'Zhongqiang Huang', 'Xiaojun Wan', 'Fei Huang']",,,,
ShapeNet: A Shapelet-Neural Network Approach for Multivariate Time Series Classification,"['Guozhong Li', 'Byron Choi', 'Jianliang Xu', 'Sourav S Bhowmick', 'Kwok-Pan Chun', 'Grace Lai-Hung Wong']",,,,
ASHF-Net: Adaptive Sampling and Hierarchical Folding Network for Robust Point Cloud Completion,"['Daoming Zong', 'Shiliang Sun', 'Jing Zhao']",,,,
Multimodal Fusion via Teacher-Student Network for Indoor Action Recognition,"['Bruce X.B. Yu', 'Yan Liu', 'Keith Chan']",,,,
Decaug: Augmenting HOI Detection via Decomposition,"['Hao-Shu Fang', 'Yichen Xie', 'Dian Shao', 'Yong-Lu Li', 'Cewu Lu']",,,,
Encoding Human Domain Knowledge to Warm Start Reinforcement Learning,"['Andrew Silva', 'Matthew Gombolay']",,,,
Certifying Top-Down Decision-DNNF Compilers,"['Florent Capelli', 'Jean-Marie Lagniez', 'Pierre Marquis']",,,,
Approximate Multiplication of Sparse Matrices with Limited Space,"['Yuanyu Wan', 'Lijun Zhang']",,,,
Towards Faithfulness in Open Domain Table-to-Text Generation from an Entity-Centric View,"['Tianyu Liu', 'Xin Zheng', 'Baobao Chang', 'Zhifang Sui']",,,,
Parameterized Complexity of Small Decision Tree Learning,"['Sebastian Ordyniak', 'Stefan Szeider']",,,,
Attention-Based Multi-Level Fusion Network for Light Field Depth Estimation,"['Jiaxin Chen', 'Shuo Zhang', 'Youfang Lin']",,,,
Time Series Anomaly Detection with Multiresolution Ensemble Decoding,"['Lifeng Shen', 'Zhongzhong Yu', 'Qianli Ma', 'James Tin-Yau Kwok']",,,,
Projection-Free Online Learning in Dynamic Environments,"['Yuanyu Wan', 'Bo Xue', 'Lijun Zhang']",,,,
Majority Opinion Diffusion in Social Networks: An Adversarial Approach,['Ahad N. Zehmakan'],https://arxiv.org/abs/2012.03143,"We introduce and study a novel majority-based opinion diffusion model. Consider a graph $G$, which represents a social network. Assume that initially a subset of nodes, called seed nodes or early adopters, are colored either black or white, which correspond to positive or negative opinion regarding a consumer product or a technological innovation. Then, in each round an uncolored node, which is adjacent to at least one colored node, chooses the most frequent color among its neighbors. 
Consider a marketing campaign which advertises a product of poor quality and its ultimate goal is that more than half of the population believe in the quality of the product at the end of the opinion diffusion process. We focus on three types of attackers which can select the seed nodes in a deterministic or random fashion and manipulate almost half of them to adopt a positive opinion toward the product (that is, to choose black color). We say that an attacker succeeds if a majority of nodes are black at the end of the process. Our main purpose is to characterize classes of graphs where an attacker cannot succeed. In particular, we prove that if the maximum degree of the underlying graph is not too large or if it has strong expansion properties, then it is fairly resilient to such attacks. 
Furthermore, we prove tight bounds on the stabilization time of the process (that is, the number of rounds it needs to end) in both settings of choosing the seed nodes deterministically and randomly. We also provide several hardness results for some optimization problems regarding stabilization time and choice of seed nodes.",新しい多数派ベースの意見拡散モデルを紹介し、研究します。ソーシャルネットワークを表すグラフGについて考えてみます。最初に、シードノードまたはアーリーアダプターと呼ばれるノードのサブセットが黒または白のいずれかに色付けされていると仮定します。これは、消費者製品または技術革新に関する肯定的または否定的な意見に対応します。次に、各ラウンドで、少なくとも1つの色付きノードに隣接する色なしノードが、隣接ノードの中から最も頻度の高い色を選択します。質の悪い製品を宣伝するマーケティングキャンペーンを考えてみましょう。その最終的な目標は、人口の半数以上が意見の拡散プロセスの最後に製品の品質を信じることです。決定論的またはランダムな方法でシードノードを選択し、それらのほぼ半分を操作して製品に対して肯定的な意見を採用する（つまり、黒色を選択する）ことができる3種類の攻撃者に焦点を当てます。プロセスの最後にノードの大部分が黒である場合、攻撃者は成功すると言います。私たちの主な目的は、攻撃者が成功できないグラフのクラスを特徴づけることです。特に、基礎となるグラフの最大次数が大きすぎない場合、またはグラフが強力な拡張特性を持っている場合、そのような攻撃に対してかなり回復力があることを証明します。さらに、シードノードを決定論的かつランダムに選択する両方の設定で、プロセスの安定化時間（つまり、終了する必要のあるラウンド数）に厳しい限界があることを証明します。また、安定化時間とシードノードの選択に関するいくつかの最適化問題について、いくつかの硬度結果を提供します。,
MARTA: Leveraging Human Rationales for Explainable Text Classification,"['Ines Arous', 'Ljiljana Dolamic', 'Akansha Bhardwaj', 'Jie Yang', 'Giuseppe Cuccu', 'Philippe Cudre-Mauroux']",,"Explainability is a key requirement for text classification in many application domains ranging from sentiment analysis to medical diagnosis or legal reviews. Existing methods often rely on “attention” mechanisms for explaining classification results by estimating the relative importance of input units. However, recent studies have shown that such mechanisms tend to mis-identify irrelevant input units in their explanation. In this work, we propose a hybrid human-AI approach that incorporates human rationales into attention-based text classification models to improve the explainablility of classification results. Specifically, we ask workers to provide rationales for their annotation by selecting relevant pieces of text. We introduce MARTA, a Bayesian framework that jointly learns an attention-based model and the reliability of workers while injecting human rationales into model training. We derive a principled optimization algorithm based on variational inference with efficient updating rules for learning MARTA parameters. Extensive validation on real-world datasets shows that our framework significantly improves the state of the art both in terms of classification explainability and accuracy.",説明性は、感情分析から医学的診断または法的レビューに至るまで、多くのアプリケーションドメインにおけるテキスト分類の重要な要件です。既存の方法は、入力ユニットの相対的な重要性を推定することによって分類結果を説明するための注意メカニズムに依存することがよくあります。ただし、最近の研究では、そのようなメカニズムは、説明の中で無関係な入力ユニットを誤認する傾向があることが示されています。この作業では、分類結果の説明可能性を向上させるために、注意ベースのテキスト分類モデルに人間の論理的根拠を組み込んだハイブリッド人間AIアプローチを提案します。具体的には、関連するテキストを選択して、注釈の根拠を提供するようにワーカーに依頼します。モデルトレーニングに人間の論理的根拠を注入しながら、注意ベースのモデルと労働者の信頼性を共同で学習するベイズフレームワークであるMARTAを紹介します。 MARTAパラメータを学習するための効率的な更新ルールを使用した変分推論に基づいて、原理的な最適化アルゴリズムを導出します。実世界のデータセットに対する広範な検証は、私たちのフレームワークが分類の説明可能性と精度の両方の点で最先端技術を大幅に改善することを示しています。,https://d3i71xaburhd42.cloudfront.net/0e6338c992b6b72da05cb783f4d422ebf0462451/3-Figure1-1.png
Constraint Logic Programming for Real-World Test Laboratory Scheduling,"['Tobias Geibinger', 'Florian Mischek', 'Nysret Musliu']",,,,
Projection-Free Online Learning over Strongly Convex Sets,"['Yuanyu Wan', 'Lijun Zhang']",https://arxiv.org/abs/2010.08177,"To efficiently solve online problems with complicated constraints, projection-free algorithms including online frank-wolfe (OFW) and its variants have received significant interest recently. However, in the general case, existing projection-free algorithms only achieved the regret bound of $O(T^{3/4})$, which is worse than the regret of projection-based algorithms, where $T$ is the number of decision rounds. In this paper, we study the special case of online learning over strongly convex sets, for which we first prove that OFW enjoys a better regret bound of $O(T^{2/3})$ for general convex losses. The key idea is to refine the decaying step-size in the original OFW by a simple line search rule. Furthermore, for strongly convex losses, we propose a strongly convex variant of OFW by redefining the surrogate loss function in OFW. We show that it achieves a regret bound of $O(T^{2/3})$ over general convex sets and a better regret bound of $O(\sqrt{T})$ over strongly convex sets.",複雑な制約のあるオンライン問題を効率的に解決するために、オンラインフランクウルフ（OFW）とその変種を含む射影のないアルゴリズムが最近大きな関心を集めています。ただし、一般的なケースでは、既存の射影のないアルゴリズムはO（T ^（3/4））の後悔の限界しか達成しませんでした。これは、射影ベースのアルゴリズムの後悔よりも悪いです。ここで、Tは決定ラウンドの数です。この論文では、強い凸集合を介したオンライン学習の特殊なケースを研究します。そのため、OFWが一般的な凸損失に対してO（T ^（2/3））のより良い後悔限界を享受していることを最初に証明します。重要なアイデアは、単純なライン探索ルールによって元のOFWの減衰ステップサイズを改良することです。さらに、強く凸状の損失については、OFWの代理損失関数を再定義することにより、OFWの強く凸状の変形を提案します。一般的な凸集合に対してO（T ^（2/3））の後悔限界を達成し、強く凸集合に対して$ O（\ sqrt {T}）$のより良い後悔限界を達成することを示します。,
Faster Stackelberg Planning via Symbolic Search and Information Sharing,"['Alvaro Torralba', 'Patrick Speicher', 'Robert Künnemann', 'Marcel Steinmetz', 'Joerg Hoffmann']",,,,
GraphMSE: Efficient Meta-Path Selection in Semantically Aligned Feature Space for Graph Neural Networks,"['Yi Li', 'Yilun Jin', 'Guojie Song', 'Zihao Zhu', 'Chuan Shi', 'Yiming Wang']",,,,
ECG ODE-GAN: Learning Ordinary Differential Equations of ECG Dynamics via Generative Adversarial Learning,"['Tomer Golany', 'Kira Radinsky', 'Daniel Freedman']",,,,
"Infinite-Dimensional Fisher Markets: Equilibrium, Duality and Optimization","['Yuan Gao', 'Christian Kroer']",,"This paper considers a linear Fisher market with $n$ buyers and a continuum of items. In order to compute market equilibria, we introduce (infinite-dimensional) convex programs over Banach spaces, thereby generalizing the Eisenberg-Gale convex program and its dual. Regarding the new convex programs, we establish existence of optimal solutions, the existence of KKT-type conditions, as well as strong duality. All these properties are established via non-standard arguments, which circumvent the limitations of duality theory in optimization over infinite-dimensional vector spaces. Furthermore, we show that there exists a pure equilibrium allocation, i.e., a division of the item space. Similar to the finite-dimensional case, a market equilibrium under the infinite-dimensional Fisher market is Pareto optimal, envy-free and proportional. We also show how to obtain the (a.e. unique) equilibrium price vector and a pure equilibrium allocation from the (unique) $n$-dimensional equilibrium bang-per-buck vector. When the item space is the unit interval $[0,1]$ and buyers have piecewise linear utilities, we show that $\epsilon$-approximate equilibrium prices can be computed in time polynomial in the market size and $\log \frac{1}{\epsilon}$. This is achieved by solving a finite-dimensional convex program using the ellipsoid method. To this end, we give nontrivial and efficient subgradient and separation oracles. For general buyer valuations, we propose computing market equilibrium using stochastic dual averaging, which finds an approximate equilibrium price vector with high probability.",このペーパーでは、n人のバイヤーと一連のアイテムがある線形フィッシャー市場について考察します。市場均衡を計算するために、バナッハ空間上に（無限次元の）凸計画を導入し、それによってアイゼンバーグ-ゲール凸計画とその双対を一般化します。新しい凸プログラムに関しては、最適解の存在、KKT型条件の存在、および強双対性を確立します。これらのプロパティはすべて、無限次元のベクトル空間での最適化における双対理論の制限を回避する非標準の引数を介して確立されます。さらに、純粋な均衡配分、つまりアイテム空間の分割が存在することを示します。有限次元の場合と同様に、無限次元のフィッシャー市場の下での市場均衡は、パレート最適で、羨望のない、比例的です。また、（固有の）n次元均衡バングパーバックベクトルから（固有の）均衡価格ベクトルと純粋な均衡配分を取得する方法も示します。アイテムスペースが単位間隔[0、1]であり、バイヤーが区分的線形ユーティリティを使用している場合、-近似均衡価格は市場規模と$ \ log \ frac {1} {\ epsilon}の時間多項式で計算できることを示します。 $。これは、楕円体法を使用して有限次元の凸計画を解くことによって実現されます。この目的のために、私たちは重要で効率的な劣勾配および分離オラクルを提供します。一般的なバイヤーの評価については、確率的二重平均を使用して市場均衡を計算することを提案します。これにより、高い確率で近似均衡価格ベクトルが見つかります。,https://d3i71xaburhd42.cloudfront.net/8de20a5ecb5a4cafde283dfe4b112ab0f3a02a8f/7-Figure1-1.png
Noninvasive Self-Attention for Side Information Fusion in Sequential Recommendation,"['Chang Liu', 'Xiaoguang Li', 'Guohao Cai', 'Zhenhua Dong', 'Lifeng Shang', 'Hong Zhu']",,,,
Augmented Experiment in Material Engineering Using Machine Learning,"['Aomar Osmani', 'Massinissa Hamidi', 'Salah Bouhouche']",,,,
Joint-Label Learning by Dual Augmentation for Time Series Classification,"['Qianli Ma', 'Zhenjing Zheng', 'Jiawei Zheng', 'Sen Li', 'Wanqing Zhuang', 'Garrison Cottrell']",,,,
Improving Maximum k-plex Solver via Second-Order Reduction and Graph Color Bounding,"['Yi Zhou', 'Shan Hu', 'Mingyu Xiao', 'Zhang-Hua Fu']",,,,
Human-Level Interpretable Learning for Aspect-Based Sentiment Analysis,"['Rohan K Yadav', 'Lei Jiao', 'Ole-Christoffer Granmo', 'Morten Goodwin']",,,,
GLIB: Efficient Exploration for Relational Model-Based Reinforcement Learning via Goal-Literal Babbling,"['Rohan Chitnis', 'Tom Silver', 'Joshua Tenenbaum', 'Leslie Kaelbling', 'Tomas Lozano-Perez']",https://arxiv.org/abs/2001.08299,"We address the problem of efficient exploration for transition model learning in the relational model-based reinforcement learning setting without extrinsic goals or rewards. Inspired by human curiosity, we propose goal-literal babbling (GLIB), a simple and general method for exploration in such problems. GLIB samples relational conjunctive goals that can be understood as specific, targeted effects that the agent would like to achieve in the world, and plans to achieve these goals using the transition model being learned. We provide theoretical guarantees showing that exploration with GLIB will converge almost surely to the ground truth model. Experimentally, we find GLIB to strongly outperform existing methods in prediction and planning on a range of tasks, encompassing standard PDDL and PPDDL planning benchmarks and a robotic manipulation task in the PyBullet physics simulator. Video: this https URL",外部の目標や報酬のないリレーショナルモデルベースの強化学習設定での遷移モデル学習の効率的な探索の問題に対処します。人間の好奇心に触発されて、私たちはそのような問題を探求するための簡単で一般的な方法であるゴールリテラルバブリング（GLIB）を提案します。 GLIBは、エージェントが世界で達成したい特定のターゲット効果として理解できる関係接続詞の目標をサンプリングし、学習中の遷移モデルを使用してこれらの目標を達成することを計画します。 GLIBを使用した探索がほぼ確実にグラウンドトゥルースモデルに収束することを示す理論的保証を提供します。実験的に、GLIBは、標準のPDDLおよびPPDDL計画ベンチマークとPyBullet物理シミュレーターのロボット操作タスクを含む、さまざまなタスクの予測と計画において既存の方法を大幅に上回っています。ビデオ：このhttps URL,
Multi-Scale Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition,"['Zhan Chen', 'Sicheng Li', 'Bing Yang', 'Qinghan Li', 'Hong Liu']",,,,
Learning to Stop: Dynamic Simulation Monte-Carlo Tree Search,"['Li Cheng Lan', 'Cho-Jui Hsieh', 'Ti-Rong Wu', 'I-Chen Wu']",https://arxiv.org/abs/2012.07910,"Monte Carlo tree search (MCTS) has achieved state-of-the-art results in many domains such as Go and Atari games when combining with deep neural networks (DNNs). When more simulations are executed, MCTS can achieve higher performance but also requires enormous amounts of CPU and GPU resources. However, not all states require a long searching time to identify the best action that the agent can find. For example, in 19x19 Go and NoGo, we found that for more than half of the states, the best action predicted by DNN remains unchanged even after searching 2 minutes. This implies that a significant amount of resources can be saved if we are able to stop the searching earlier when we are confident with the current searching result. In this paper, we propose to achieve this goal by predicting the uncertainty of the current searching status and use the result to decide whether we should stop searching. With our algorithm, called Dynamic Simulation MCTS (DS-MCTS), we can speed up a NoGo agent trained by AlphaZero 2.5 times faster while maintaining a similar winning rate. Also, under the same average simulation count, our method can achieve a 61% winning rate against the original program.",モンテカルロ木探索（MCTS）は、ディープニューラルネットワーク（DNN）と組み合わせると、GoやAtariゲームなどの多くのドメインで最先端の結果を達成しています。より多くのシミュレーションが実行されると、MCTSはより高いパフォーマンスを達成できますが、膨大な量のCPUおよびGPUリソ​​ースも必要とします。ただし、すべての状態で、エージェントが見つけることができる最適なアクションを特定するために長い検索時間が必要なわけではありません。たとえば、19x19 GoとNoGoでは、州の半分以上で、2分検索した後でもDNNによって予測された最良のアクションが変わらないことがわかりました。これは、現在の検索結果に自信があるときに検索を早期に停止できれば、かなりの量のリソースを節約できることを意味します。本論文では、現在の検索状況の不確実性を予測し、その結果を使用して検索を停止するかどうかを決定することにより、この目標を達成することを提案します。 Dynamic Simulation MCTS（DS-MCTS）と呼ばれるアルゴリズムを使用すると、同様の勝率を維持しながら、AlphaZeroによってトレーニングされたNoGoエージェントを2.5倍高速化できます。また、同じ平均シミュレーション数の下で、私たちの方法は61を達成することができます,https://d3i71xaburhd42.cloudfront.net/ad038ba73ba8a2b7d855624c7e107e711dd63790/1-Figure1-1.png
A Graph Reasoning Network for Multi-Turn Response Selection via Customized Pre-Training,"['Yongkang Liu', 'Shi Feng', 'Daling Wang', 'Kaisong Song', 'Ren Feiliang', 'Yifei Zhang']",https://arxiv.org/abs/2012.11099,"We investigate response selection for multi-turn conversation in retrieval-based chatbots. Existing studies pay more attention to the matching between utterances and responses by calculating the matching score based on learned features, leading to insufficient model reasoning ability. In this paper, we propose a graphreasoning network (GRN) to address the problem. GRN first conducts pre-training based on ALBERT using next utterance prediction and utterance order prediction tasks specifically devised for response selection. These two customized pre-training tasks can endow our model with the ability of capturing semantical and chronological dependency between utterances. We then fine-tune the model on an integrated network with sequence reasoning and graph reasoning structures. The sequence reasoning module conducts inference based on the highly summarized context vector of utterance-response pairs from the global perspective. The graph reasoning module conducts the reasoning on the utterance-level graph neural network from the local perspective. Experiments on two conversational reasoning datasets show that our model can dramatically outperform the strong baseline methods and can achieve performance which is close to human-level.",検索ベースのチャットボットにおけるマルチターン会話の応答選択を調査します。既存の研究では、学習した特徴に基づいてマッチングスコアを計算することにより、発話と応答のマッチングにさらに注意を払っているため、モデルの推論能力が不十分になっています。本論文では、問題に対処するためにグラフ推論ネットワーク（GRN）を提案します。 GRNはまず、応答選択のために特別に考案された次の発話予測および発話順序予測タスクを使用して、ALBERTに基づく事前トレーニングを実行します。これらの2つのカスタマイズされた事前トレーニングタスクは、発話間の意味的および時系列の依存関係をキャプチャする機能をモデルに与えることができます。次に、シーケンス推論とグラフ推論の構造を使用して、統合ネットワーク上でモデルを微調整します。シーケンス推論モジュールは、グローバルな観点から、発話と応答のペアの高度に要約されたコンテキストベクトルに基づいて推論を実行します。グラフ推論モジュールは、ローカルの観点から発話レベルのグラフニューラルネットワークで推論を実行します。 2つの会話型推論データセットでの実験は、私たちのモデルが強力なベースライン手法を劇的に上回り、人間レベルに近いパフォーマンスを達成できることを示しています。,https://d3i71xaburhd42.cloudfront.net/9698cff93ec15e4c92b1fccb2332673ef4074899/1-Figure1-1.png
Increasing Iterate Averaging for Solving Saddle-Point Problems,"['Yuan Gao', 'Christian Kroer', 'Donald Goldfarb']",,"Many problems in machine learning and game theory can be formulated as saddle-point problems, for which various first-order methods have been developed and proven efficient in practice. Under the general convex-concave assumption, most first-order methods only guarantee ergodic convergence, that is, convergence of the uniform averages of the iterates. However, numerically, the iterates themselves can sometimes converge much faster than the uniform averages. This observation motivates increasing averaging schemes that put more weight on later iterates, in contrast to the usual uniform averaging. We show that such increasing averaging schemes, applied to various first-order methods, are able to preserve the convergence of the averaged iterates with no additional assumptions or computational overhead. Extensive numerical experiments on various equilibrium computation and image denoising problems demonstrate the effectiveness of the increasing averaging schemes. In particular, the increasing averages consistently outperform the uniform averages in all test problems by orders of magnitude. When solving matrix games and extensive-form games, increasing averages consistently outperform the last iterate as well. For matrix games, a first-order method equipped with increasing averaging outperforms the highly competitive CFR$^+$ algorithm.",機械学習とゲーム理論の多くの問題は鞍点問題として定式化でき、さまざまな一次手法が開発され、実際に効率的であることが証明されています。一般的な凸凹の仮定の下では、ほとんどの1次法は、エルゴード収束、つまり反復の均一平均の収束のみを保証します。ただし、数値的には、反復自体が均一な平均​​よりもはるかに速く収束する場合があります。この観察は、通常の均一な平均​​化とは対照的に、後の反復により多くの重みを置く平均化スキームの増加を動機付けます。さまざまな一次法に適用されるこのような増加する平均化スキームは、追加の仮定や計算のオーバーヘッドなしに、平均化された反復の収束を維持できることを示します。さまざまな平衡計算と画像ノイズ除去の問題に関する広範な数値実験は、増加する平均化スキームの有効性を示しています。特に、増加する平均は、すべてのテスト問題で均一な平均​​を桁違いに上回っています。マトリックスゲームや展開型ゲームを解く場合、平均を増やすと、最後の反復よりも一貫してパフォーマンスが向上します。マトリックスゲームの場合、平均化を増加させる一次法は、競争の激しいCFR +アルゴリズムよりも優れています。,
Provably Good Solutions to the Knapsack Problem via Neural Networks of Bounded Size,"['Christoph Hertrich', 'Martin Skutella']",https://arxiv.org/abs/2005.14105,"In view of the undisputed success of neural networks and due to the remarkable recent improvements in their ability to solve a huge variety of practical problems, the development of a satisfying and rigorous mathematical understanding of their performance is one of the main challenges in the field of learning theory. Against this background, we study the expressive power of neural networks through the example of the classical NP-hard Knapsack Problem. 
Our main contribution is a class of recurrent neural networks (RNNs) with rectified linear units that are iteratively applied to each item of a Knapsack instance and thereby compute optimal or provably good solution values. In order to find optimum Knapsack solutions, an RNN of depth four and width depending quadratically on the profit of an optimum Knapsack solution is sufficient. We also prove the following tradeoff between the size of an RNN and the quality of the computed Knapsack solution: For Knapsack instances consisting of $n$ items, an RNN of depth five and width $w$ computes a solution of value at least $1-\mathcal{O}(n^2/\sqrt{w})$ times the optimum solution value. Our results build upon a dynamic programming formulation of the Knapsack Problem as well as a careful rounding of profit values that is also at the core of the well-known fully polynomial-time approximation scheme for the Knapsack Problem. Finally, we point out that similar results can be achieved for other optimization problems that can be solved by dynamic programming, such as, e.g., various Shortest Path Problems and the Longest Common Subsequence Problem.",ニューラルネットワークの明白な成功を考慮し、そして多種多様な実用的な問題を解決する能力の目覚ましい最近の改善により、それらの性能の満足のいく厳密な数学的理解の開発は、次の分野における主要な課題の1つです。学習理論。このような背景から、古典的なNP困難ナップサック問題の例を通してニューラルネットワークの表現力を研究します。私たちの主な貢献は、Knapsackインスタンスの各アイテムに繰り返し適用され、それによって最適または証明可能な優れたソリューション値を計算する、正規化線形ユニットを備えたリカレントニューラルネットワーク（RNN）のクラスです。最適なナップザックソリューションを見つけるには、最適なナップザックソリューションの利益に二次関数的に依存する深さ4と幅のRNNで十分です。また、RNNのサイズと計算されたナップザックソリューションの品質の間の次のトレードオフを証明します。n個のアイテムで構成されるナップザックインスタンスの場合、深さ5、幅wのRNNは、少なくとも$ 1- \ mathcal {Oの値のソリューションを計算します。 }（n ^ 2 / \ sqrt {w}）$に最適解の値を掛けます。私たちの結果は、ナップサック問題の動的計画法の定式化と、ナップサック問題のよく知られた完全多項式時間近似スキームの中核でもある利益値の注意深い丸めに基づいています。最後に、動的計画法によって解決できる他の最適化問題、たとえば、さまざまな最短経路問題や最長共通部分列問題についても、同様の結果が得られることを指摘します。,https://d3i71xaburhd42.cloudfront.net/05e95fdf43e627fb1827ee3e21c35f0ebf0b3ba2/5-Figure1-1.png
Provably Secure Federated Learning against Malicious Clients,"['Xiaoyu Cao', 'Jinyuan Jia', 'Neil Zhenqiang Gong']",,,,
WCSAC: Worst-Case Soft Actor Critic for Safety-Constrained Reinforcement Learning,"['Qisong Yang', 'Thiago D. Simão', 'Simon H Tindemans', 'Matthijs T. J. Spaan']",,,,
A Recipe for Global Convergence Guarantee in Deep Neural Networks,"['Kenji Kawaguchi', 'Qingyun Sun']",,,,
Mind-the-Gap! Unsupervised Domain Adaptation for Text-Video Retrieval,"['Qingchao Chen', 'Yang Liu', 'Samuel Albanie']",,,,
Modeling the Momentum Spillover Effect for Stock Prediction via Attribute-Driven Graph Attention Networks,"['Rui Cheng', 'Qing Li']",,,,
Queue-Learning: A Reinforcement Learning Approach for Providing Quality of Service,"['Majid Raeis', 'Ali Tizghadam', 'Alberto Leon-Garcia']",https://arxiv.org/abs/2101.04627,"End-to-end delay is a critical attribute of quality of service (QoS) in application domains such as cloud computing and computer networks. This metric is particularly important in tandem service systems, where the end-to-end service is provided through a chain of services. Service-rate control is a common mechanism for providing QoS guarantees in service systems. In this paper, we introduce a reinforcement learningbased (RL-based) service-rate controller that provides probabilistic upper-bounds on the end-to-end delay of the system, while preventing the overuse of service resources. In order to have a general framework, we use queueing theory to model the service systems. However, we adopt an RL-based approach to avoid the limitations of queueing-theoretic methods. In particular, we use Deep Deterministic Policy Gradient (DDPG) to learn the service rates (action) as a function of the queue lengths (state) in tandem service systems. In contrast to existing RL-based methods that quantify their performance by the achieved overall reward, which could be hard to interpret or even misleading, our proposed controller provides explicit probabilistic guarantees on the end-to-end delay of the system. The evaluations are presented for a tandem queueing system with non-exponential inter-arrival and service times, the results of which validate our controller’s capability in meeting QoS constraints.",エンドツーエンドの遅延は、クラウドコンピューティングやコンピューターネットワークなどのアプリケーションドメインにおけるサービス品質（QoS）の重要な属性です。このメトリックは、エンドツーエンドのサービスが一連のサービスを通じて提供されるタンデムサービスシステムで特に重要です。サービスレート制御は、サービスシステムでQoS保証を提供するための一般的なメカニズムです。このホワイトペーパーでは、サービスリソースの過剰使用を防ぎながら、システムのエンドツーエンドの遅延に確率的な上限を提供する強化学習ベース（RLベース）のサービスレートコントローラーを紹介します。一般的なフレームワークを作成するために、キューイング理論を使用してサービスシステムをモデル化します。ただし、待ち行列理論的な方法の制限を回避するために、RLベースのアプローチを採用しています。特に、Deep Deterministic Policy Gradient（DDPG）を使用して、タンデムサービスシステムのキューの長さ（状態）の関数としてサービスレート（アクション）を学習します。解釈が困難または誤解を招く可能性がある、達成された全体的な報酬によってパフォーマンスを定量化する既存のRLベースの方法とは対照的に、提案されたコントローラーは、システムのエンドツーエンドの遅延に対して明示的な確率的保証を提供します。評価は、非指数関数的な到着間隔とサービス時間を持つタンデムキューイングシステムに対して提示され、その結果は、QoS制約を満たすためのコントローラーの機能を検証します。,https://d3i71xaburhd42.cloudfront.net/fd15384646a386521ee4824c35011bc17e6fa987/2-Figure1-1.png
Learning Compositional Sparse Gaussian Processes with a Shrinkage Prior,"['Anh Tong', 'Toan M Tran', 'Kim Juhyeong', 'Hung Bui', 'Jaesik Choi']",https://arxiv.org/abs/2012.11339,"Choosing a proper set of kernel functions is an important problem in learning Gaussian Process (GP) models since each kernel structure has different model complexity and data fitness. Recently, automatic kernel composition methods provide not only accurate prediction but also attractive interpretability through search-based methods. However, existing methods suffer from slow kernel composition learning. To tackle large-scaled data, we propose a new sparse approximate posterior for GPs, MultiSVGP, constructed from groups of inducing points associated with individual additive kernels in compositional kernels. We demonstrate that this approximation provides a better fit to learn compositional kernels given empirical observations. We also theoretically justification on error bound when compared to the traditional sparse GP. In contrast to the search-based approach, we present a novel probabilistic algorithm to learn a kernel composition by handling the sparsity in the kernel selection with Horseshoe prior. We demonstrate that our model can capture characteristics of time series with significant reductions in computational time and have competitive regression performance on real-world data sets.",カーネル構造ごとにモデルの複雑さとデータの適合性が異なるため、カーネル関数の適切なセットを選択することは、ガウス過程（GP）モデルを学習する上で重要な問題です。最近、自動カーネル構成方法は、正確な予測だけでなく、検索ベースの方法による魅力的な解釈可能性も提供します。ただし、既存の方法では、カーネル構成の学習が遅くなります。大規模なデータに取り組むために、構成カーネル内の個々の加法カーネルに関連付けられた誘導点のグループから構築された、GPの新しいスパース近似事後確率MultiSVGPを提案します。この近似は、経験的な観察を前提として、構成カーネルを学習するためのより良い適合を提供することを示しています。また、従来のスパースGPと比較した場合、エラー限界を理論的に正当化します。検索ベースのアプローチとは対照的に、Horseshoe事前確率を使用してカーネル選択のスパース性を処理することにより、カーネル構成を学習するための新しい確率的アルゴリズムを提示します。私たちのモデルは、計算時間を大幅に短縮して時系列の特性をキャプチャし、実際のデータセットで競合する回帰パフォーマンスを発揮できることを示しています。,https://d3i71xaburhd42.cloudfront.net/4522d04e6dff6e05e83e4c595dffd8176711da4d/3-Figure1-1.png
Deep Event Stereo Leveraged by Event-to-Image Translation,"['Soikat Hasan Ahmed', 'Hae Woong Jang', 'S M Nadim Uddin', 'Yong Ju Jung']",,,,
A Joint Training Dual-MRC Framework for Aspect Based Sentiment Analysis,"['Yue Mao', 'Yi Shen', 'Chao Yu', 'LongJun Cai']",https://arxiv.org/abs/2101.00816,"Aspect based sentiment analysis (ABSA) involves three fundamental subtasks: aspect term extraction, opinion term extraction, and aspect-level sentiment classification. Early works only focused on solving one of these subtasks individually. Some recent work focused on solving a combination of two subtasks, e.g., extracting aspect terms along with sentiment polarities or extracting the aspect and opinion terms pair-wisely. More recently, the triple extraction task has been proposed, i.e., extracting the (aspect term, opinion term, sentiment polarity) triples from a sentence. However, previous approaches fail to solve all subtasks in a unified end-to-end framework. In this paper, we propose a complete solution for ABSA. We construct two machine reading comprehension (MRC) problems and solve all subtasks by joint training two BERT-MRC models with parameters sharing. We conduct experiments on these subtasks, and results on several benchmark datasets demonstrate the effectiveness of our proposed framework, which significantly outperforms existing state-ofthe-art methods. Introduction Aspect based sentiment analysis (ABSA)1 is an important research area in natural language processing. Consider the example in Figure 1, in the sentence “The ambience was nice, but the service was not so great.”, the aspect terms (AT) are “ambience/service” and the opinion terms (OT) are “nice/not so great”. Traditionally, there exist three fundamental subtasks: aspect term extraction, opinion term extraction, and aspect-level sentiment classification. Recent research works aim to do a combination of two subtasks and have achieved great progress. For example, they extract (AT, OT) pairs, or extract ATs with corresponding sentiment polarities (SP). More recently, some work that aims to do all related subtasks in ABSA with a unified framework has raised increasing interests. For convenience, we assume the following abbreviations of ABSA subtasks as illustrated in Figure 1:",アスペクトベースの感情分析（ABSA）には、アスペクト用語の抽出、意見用語の抽出、およびアスペクトレベルの感情分類という3つの基本的なサブタスクが含まれます。初期の作品は、これらのサブタスクの1つを個別に解決することにのみ焦点を当てていました。最近のいくつかの研究は、2つのサブタスクの組み合わせを解決することに焦点を当てています。たとえば、感情の極性とともにアスペクト用語を抽出するか、アスペクトと意見の用語をペアで抽出します。最近では、トリプル抽出タスクが提案されています。つまり、文から（アスペクト用語、意見用語、感情極性）トリプルを抽出します。ただし、以前のアプローチでは、統合されたエンドツーエンドのフレームワークですべてのサブタスクを解決できません。この論文では、ABSAの完全なソリューションを提案します。 2つの機械読解（MRC）問題を構築し、パラメーターを共有する2つのBERT-MRCモデルを共同トレーニングすることですべてのサブタスクを解決します。これらのサブタスクで実験を行い、いくつかのベンチマークデータセットの結果は、提案されたフレームワークの有効性を示しています。これは、既存の最先端の方法を大幅に上回っています。はじめにアスペクトベースの感情分析（ABSA）1は、自然言語処理における重要な研究分野です。図1の例を考えてみましょう。文の中で、雰囲気は素晴らしかったが、サービスはそれほど素晴らしかった。アスペクト用語（AT）は雰囲気/サービスであり、意見用語（OT）は素晴らしかった/それほど素晴らしかった。従来、3つの基本的なサブタスクが存在します。アスペクト用語の抽出、意見用語の抽出、およびアスペクトレベルの感情分類です。最近の研究は、2つのサブタスクの組み合わせを目的としており、大きな進歩を遂げています。たとえば、（AT、OT）ペアを抽出したり、対応する感情極性（SP）を持つATを抽出したりします。最近では、ABSAの関連するすべてのサブタスクを統一されたフレームワークで実行することを目的としたいくつかの作業により、関心が高まっています。便宜上、図1に示すように、ABSAサブタスクの次の略語を想定しています。,https://d3i71xaburhd42.cloudfront.net/0e021f936adf979f86812d67f32b090acb07d706/1-Figure1-1.png
Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers,"['Shijie Geng', 'Peng Gao', 'Moitreya Chatterjee', 'Chiori Hori', 'Jonathan LeRoux', 'Yongfeng Zhang', 'Hongsheng Li', 'Anoop Cherian']",,,,
Planning with Learned Object Importance in Large Problem Instances Using Graph Neural Networks,"['Tom Silver', 'Rohan Chitnis', 'Aidan Curtis', 'Joshua Tenenbaum', 'Tomas Lozano-Perez', 'Leslie Kaelbling']",https://arxiv.org/abs/2009.05613,"Real-world planning problems often involve hundreds or even thousands of objects, straining the limits of modern planners. In this work, we address this challenge by learning to predict a small set of objects that, taken together, would be sufficient for finding a plan. We propose a graph neural network architecture for predicting object importance in a single pass, thereby incurring little overhead while substantially reducing the number of objects that must be considered by the planner. Our approach treats the planner and transition model as black boxes, and can be used with any off-the-shelf planner. Empirically, across classical planning, probabilistic planning, and robotic task and motion planning, we find that our method results in planning that is significantly faster than several baselines, including other partial grounding strategies and lifted planners. We conclude that learning to predict a sufficient set of objects for a planning problem is a simple, powerful, and general mechanism for planning in large instances. Video: this https URL",実際の計画の問題には、数百または数千ものオブジェクトが関係していることが多く、現代の計画担当者の限界に負担をかけています。この作業では、計画を見つけるのに十分なオブジェクトの小さなセットを予測することを学習することで、この課題に対処します。シングルパスでオブジェクトの重要性を予測するためのグラフニューラルネットワークアーキテクチャを提案します。これにより、オーバーヘッドがほとんど発生せず、プランナーが考慮する必要のあるオブジェクトの数が大幅に削減されます。私たちのアプローチは、プランナーと遷移モデルをブラックボックスとして扱い、既成のプランナーで使用できます。経験的に、古典的な計画、確率的計画、およびロボットのタスクとモーションの計画全体で、私たちの方法は、他の部分的な接地戦略やリフトプランナーを含むいくつかのベースラインよりも大幅に高速な計画をもたらすことがわかりました。計画問題の十分なオブジェクトのセットを予測することを学ぶことは、大規模なインスタンスで計画するための単純で強力な一般的なメカニズムであると結論付けます。ビデオ：このhttps URL,https://d3i71xaburhd42.cloudfront.net/b1f122c06a9a87678d92dbf5a4a843c2a7843e26/1-Figure1-1.png
Knowledge-Enhanced Top-K Recommendation in Poincaré Ball,"['Chen Ma', 'Liheng Ma', 'Yingxue Zhang', 'Haolun Wu', 'Xue Liu', 'Mark Coates']",https://arxiv.org/abs/2101.04852,"Personalized recommender systems are increasingly important as more content and services become available and users struggle to identify what might interest them. Thanks to the ability for providing rich information, knowledge graphs (KGs) are being incorporated to enhance the recommendation performance and interpretability. To effectively make use of the knowledge graph, we propose a recommendation model in the hyperbolic space, which facilitates the learning of the hierarchical structure of knowledge graphs. Furthermore, a hyperbolic attention network is employed to determine the relative importances of neighboring entities of a certain item. In addition, we propose an adaptive and finegrained regularization mechanism to adaptively regularize items and their neighboring representations. Via a comparison using three real-world datasets with stateof-the-art methods, we show that the proposed model outperforms the best existing models by 2-16% in terms of NDCG@K on Top-K recommendation.",より多くのコンテンツとサービスが利用可能になり、ユーザーが興味のあるものを特定するのに苦労するにつれて、パーソナライズされたレコメンダーシステムはますます重要になっています。豊富な情報を提供する機能のおかげで、推奨のパフォーマンスと解釈可能性を強化するために知識グラフ（KG）が組み込まれています。知識グラフを有効に活用するために、知識グラフの階層構造の学習を容易にする双曲空間での推奨モデルを提案します。さらに、双曲線注意ネットワークは、特定のアイテムの隣接するエンティティの相対的な重要性を決定するために使用されます。さらに、アイテムとその隣接表現を適応的に正則化するための、適応的できめ細かい正則化メカニズムを提案します。最先端の方法で3つの実世界のデータセットを使用した比較により、提案されたモデルが既存の最良のモデルを2〜16で上回っていることを示します。,https://d3i71xaburhd42.cloudfront.net/ac00f701ea57ba2f588895c31a098928d080f1aa/4-Figure1-1.png
On Fair Division under Heterogeneous Matroid Constraints,"['Amitay Dror', 'Michal Feldman', 'Erel Segal-Halevi']",https://arxiv.org/abs/2010.07280,"We study fair allocation of indivisible goods among additive agents with feasibility constraints. In these settings, every agent is restricted to get a bundle among a specified set of feasible bundles. Such scenarios have been of great interest to the AI community due to their applicability to real-world problems. Following some impossibility results, we restrict attention to matroid feasibility constraints that capture natural scenarios, such as the allocation of shifts to medical doctors or conference papers to referees. 
We focus on the common fairness notion of envy-freeness up to one good (EF1). Previous algorithms for finding EF1 allocations are either restricted to agents with identical feasibility constraints, or allow free disposal of items. A major open problem is the existence of EF1 complete allocations among heterogeneous agents, where the heterogeneity is both in the agents' feasibility constraints and in their valuations. In this work, we make progress on this problem by providing positive and negative results for different matroid and valuation types. Among other results, we devise polynomial-time algorithms for finding EF1 allocations in the following settings: (i) n agents with heterogeneous partition matroids and heterogeneous binary valuations, (ii) 2 agents with heterogeneous partition matroids and heterogeneous valuations, and (iii) at most 3 agents with identical arbitrary matroids and heterogeneous binary valuations.",実現可能性の制約がある添加剤間での不可分な商品の公平な配分を研究します。これらの設定では、すべてのエージェントは、指定された実行可能なバンドルのセットからバンドルを取得するように制限されています。このようなシナリオは、実際の問題に適用できるため、AIコミュニティにとって非常に興味深いものです。いくつかの不可能な結果に続いて、医師へのシフトの割り当てや審判への会議論文など、自然なシナリオを捉えるマトロイドの実現可能性の制約への注意を制限します。私たちは、1つの善（EF1）までの羨望のないという一般的な公平性の概念に焦点を当てています。 EF1割り当てを見つけるための以前のアルゴリズムは、同一の実現可能性制約を持つエージェントに制限されているか、アイテムの無料廃棄を許可しています。主要な未解決の問題は、異種エージェント間にEF1の完全な割り当てが存在することです。この場合、異種はエージェントの実現可能性の制約とその評価の両方にあります。この作業では、さまざまなマトロイドと評価タイプに対して正と負の結果を提供することにより、この問題を進展させます。他の結果の中で、次の設定でEF1割り当てを見つけるための多項式時間アルゴリズムを考案します：（i）異種分割マトロイドと異種バイナリ評価を持つn個のエージェント、（ii）異種分割マトロイドと異種評価を持つ2個のエージェント、および（iii）同一の任意のマトロイドと異種のバイナリ評価を持つ最大3つのエージェント。,https://d3i71xaburhd42.cloudfront.net/eb5aff784fe1a7670f51437118c76e64ee1e1a92/32-Figure1-1.png
ROSITA: Refined BERT Compression with Integrated Techniques,"['Yuanxin Liu', 'Zheng Lin', 'Fengcheng Yuan']",,,,
Raven's Progressive Matrices Completion with Latent Gaussian Process Priors,"['Fan Shi', 'Bin Li', 'Xiangyang Xue']",,,,
Satisfiability and Algorithms for Non-Uniform Random k-SAT,"['Andrei Bulatov', 'Oleksii Omelchenko']",,,,
Achieving Proportionality up to the Maximin Item with Indivisible Goods,"['Artem Baklanov', 'Pranav Garimidi', 'Vasilis Gkatzelis', 'Daniel R Schoepflin']",https://arxiv.org/abs/2009.09508,"We study the problem of fairly allocating indivisible goods and focus on the classic fairness notion of proportionality. The indivisibility of the goods is long known to pose highly non-trivial obstacles to achieving fairness, and a very vibrant line of research has aimed to circumvent them using appropriate notions of approximate fairness. Recent work has established that even approximate versions of proportionality (PROPx) may be impossible to achieve even for small instances, while the best known achievable approximations (PROP1) are much weaker. We introduce the notion of proportionality up to the maximin item (PROPm) and show how to reach an allocation satisfying this notion for any instance involving up to five agents with additive valuations. PROPm provides a well motivated middle-ground between PROP1 and PROPx, while also capturing some elements of the well-studied maximin share (MMS) benchmark: another relaxation of proportionality that has attracted a lot of attention.",私たちは、分割できない商品を公平に配分する問題を研究し、比例の古典的な公平性の概念に焦点を当てます。商品の不可分性は、公平性を達成する上で非常に重要な障害となることが長い間知られており、非常に活気のある一連の研究は、おおよその公平性の適切な概念を使用してそれらを回避することを目的としています。最近の研究では、比例の近似バージョン（PROPx）でさえ、小さなインスタンスでも達成できない可能性がありますが、最もよく知られている達成可能な近似（PROP1）ははるかに弱いことがわかっています。マキシミン項目（PROPm）までの比例の概念を紹介し、加法評価のある最大5つのエージェントが関与するインスタンスに対してこの概念を満たす割り当てに到達する方法を示します。 PROPmは、PROP1とPROPxの間のやる気のある中間点を提供すると同時に、十分に研究されたマキシミンシェア（MMS）ベンチマークのいくつかの要素をキャプチャします。これは、多くの注目を集めている比例のもう1つの緩和です。,
Tripartite Collaborative Filtering with Observability and Selection for Debiasing Rating Estimation on Missing-Not-at-Random Data,"['Qi Zhang', 'Longbing Cao', 'Chongyang Shi', 'Liang Hu']",,,,
Variational Fair Clustering,"['Imtiaz Masud Ziko', 'Jing Yuan', 'Eric Granger', 'Ismail Ben Ayed']",,,,
Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-Based Dialogues,"['Ruijian Xu', 'Chongyang Tao', 'Daxin Jiang', 'Xueliang Zhao', 'Dongyan Zhao', 'Rui Yan']",,,,
AnchorFace: An Anchor-Based Facial Landmark Detector across Large Poses,"['Zixuan Xu', 'Banghuai Li', 'Ye Yuan', 'Miao Geng']",,,,
Right for Better Reasons: Training Differentiable Models by Constraining their Influence Function,"['Xiaoting Shao', 'Arseny Skryagin', 'Patrick Schramowski', 'Wolfgang Stammer', 'Kristian Kersting']",,,,
Nutri-Bullets: Summarizing Health Studies by Composing Segments,"['Darsh J Shah', 'Lili Yu', 'Tao Lei', 'Dr.Regina Barzilay']",,,,
CrossNER: Evaluating Cross-Domain Named Entity Recognition,"['Zihan Liu', 'Yan Xu', 'Tiezheng Yu', 'Wenliang Dai', 'Ziwei Ji', 'Samuel Cahyawijaya', 'Andrea Madotto', 'Pascale Fung']",https://arxiv.org/abs/2012.04373,"Cross-domain named entity recognition (NER) models are able to cope with the scarcity issue of NER samples in target domains. However, most of the existing NER benchmarks lack domain-specialized entity types or do not focus on a certain domain, leading to a less effective cross-domain evaluation. To address these obstacles, we introduce a cross-domain NER dataset (CrossNER), a fully-labeled collection of NER data spanning over five diverse domains with specialized entity categories for different domains. Additionally, we also provide a domain-related corpus since using it to continue pre-training language models (domain-adaptive pre-training) is effective for the domain adaptation. We then conduct comprehensive experiments to explore the effectiveness of leveraging different levels of the domain corpus and pre-training strategies to do domain-adaptive pre-training for the cross-domain task. Results show that focusing on the fractional corpus containing domain-specialized entities and utilizing a more challenging pre-training strategy in domain-adaptive pre-training are beneficial for the NER domain adaptation, and our proposed method can consistently outperform existing cross-domain NER baselines. Nevertheless, experiments also illustrate the challenge of this cross-domain NER task. We hope that our dataset and baselines will catalyze research in the NER domain adaptation area. The code and data are available at this https URL.",クロスドメイン固有表現抽出（NER）モデルは、ターゲットドメインのNERサンプルの不足の問題に対処できます。ただし、既存のNERベンチマークのほとんどは、ドメインに特化したエンティティタイプがないか、特定のドメインに焦点を当てていないため、クロスドメイン評価の効果が低くなります。これらの障害に対処するために、クロスドメインNERデータセット（CrossNER）を導入します。これは、異なるドメインに特化したエンティティカテゴリを持つ5つの異なるドメインにまたがる完全にラベル付けされたNERデータのコレクションです。さらに、事前トレーニング言語モデル（ドメイン適応事前トレーニング）を継続するためにそれを使用することはドメイン適応に効果的であるため、ドメイン関連コーパスも提供します。次に、包括的な実験を実施して、さまざまなレベルのドメインコーパスと事前トレーニング戦略を活用して、クロスドメインタスクのドメイン適応型事前トレーニングを実行することの有効性を調査します。結果は、ドメインに特化したエンティティを含む分数コーパスに焦点を当て、ドメイン適応型事前トレーニングでより挑戦的な事前トレーニング戦略を利用することがNERドメイン適応に有益であり、提案された方法が既存のクロスドメインNERベースラインを一貫して上回ることができることを示しています。それにもかかわらず、実験は、このクロスドメインNERタスクの課題も示しています。私たちのデータセットとベースラインがNERドメイン適応領域の研究を促進することを願っています。コードとデータは、このhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/5cb87cd3b1feb8f39e565b1d054d37a3cf38b66c/3-Figure1-1.png
Programmatic Strategies for Real-Time Strategy Games,"['Julian Mariño', 'Rubens Moraes', 'Tassiana Oliveira', 'Claudio Toledo', 'Levi H. S. Lelis']",,,,
Multi-Scale Games: Representing and Solving Games on Networks with Group Structure,"['Kun Jin', 'Yevgeniy Vorobeychik', 'Mingyan Liu']",https://arxiv.org/abs/2101.08314,"Network games provide a natural machinery to compactly represent strategic interactions among agents whose payoffs exhibit sparsity in their dependence on the actions of others. Besides encoding interaction sparsity, however, real networks often exhibit a multi-scale structure, in which agents can be grouped into communities, those communities further grouped, and so on, and where interactions among such groups may also exhibit sparsity. We present a general model of multi-scale network games that encodes such multi-level structure. We then develop several algorithmic approaches that leverage this multi-scale structure, and derive sufficient conditions for convergence of these to a Nash equilibrium. Our numerical experiments demonstrate that the proposed approaches enable orders of magnitude improvements in scalability when computing Nash equilibria in such games. For example, we can solve previously intractable instances involving up to 1 million agents in under 15 minutes.",ネットワークゲームは、他の人の行動への依存において見返りが希薄であるエージェント間の戦略的相互作用をコンパクトに表すための自然な機構を提供します。ただし、実際のネットワークは、相互作用のスパース性をエンコードするだけでなく、エージェントをコミュニティにグループ化したり、コミュニティをさらにグループ化したりすることができ、そのようなグループ間の相互作用もスパース性を示す可能性があるマルチスケール構造を示すことがよくあります。このようなマルチレベル構造をエンコードするマルチスケールネットワークゲームの一般的なモデルを提示します。次に、このマルチスケール構造を活用するいくつかのアルゴリズムアプローチを開発し、これらをナッシュ均衡に収束させるための十分条件を導き出します。私たちの数値実験は、提案されたアプローチが、そのようなゲームでナッシュ均衡を計算するときにスケーラビリティの桁違いの改善を可能にすることを示しています。たとえば、15分以内に最大100万人のエージェントが関与する以前は困難だったインスタンスを解決できます。,https://d3i71xaburhd42.cloudfront.net/1bb82e8e8163eab88a366886fc99b94232e35944/1-Figure1-1.png
Improved Knowledge Modeling and Its Use for Signaling in Multi-Agent Planning with Partial Observability,"['Shashank Shekhar', 'Ronen Brafman', 'Guy Shani']",,,,
*-CFQ: Analyzing the Scalability of Machine Learning on a Compositional Task,"['Dmitry Tsarkov', 'Tibor Tihon', 'Nathan Scales', 'Nikola Momchev', 'Danila Sinopalnikov', 'Nathanael Schärli']",https://arxiv.org/abs/2012.08266,"We present *-CFQ (""star-CFQ""): a suite of large-scale datasets of varying scope based on the CFQ semantic parsing benchmark, designed for principled investigation of the scalability of machine learning systems in a realistic compositional task setting. Using this suite, we conduct a series of experiments investigating the ability of Transformers to benefit from increased training size under conditions of fixed computational cost. We show that compositional generalization remains a challenge at all training sizes, and we show that increasing the scope of natural language leads to consistently higher error rates, which are only partially offset by increased training data. We further show that while additional training data from a related domain improves the accuracy in data-starved situations, this improvement is limited and diminishes as the distance from the related domain to the target domain increases.",* -CFQ（ &quot;star-CFQ&quot;）：CFQセマンティック解析ベンチマークに基づくさまざまなスコープの大規模データセットのスイートで、現実的な構成タスク設定における機械学習システムのスケーラビリティの原理的な調査用に設計されています。このスイートを使用して、固定の計算コストの条件下でトレーニングサイズの増加から利益を得るトランスフォーマーの能力を調査する一連の実験を実施します。構成の一般化がすべてのトレーニングサイズで課題のままであることを示し、自然言語の範囲を拡大すると、一貫して高いエラー率につながることを示しますが、トレーニングデータの増加によって部分的に相殺されるだけです。さらに、関連ドメインからの追加のトレーニングデータにより、データが不足している状況での精度が向上しますが、この向上は限定的であり、関連ドメインからターゲットドメインまでの距離が長くなるにつれて低下することを示します。,https://d3i71xaburhd42.cloudfront.net/d3edc20ed4a07195f3663abc0ead4220266fd75b/3-Figure1-1.png
Responsibility Attribution in Parameterized Markovian Models,"['Christel Baier', 'Florian Funke', 'Rupak Majumdar']",,,,
Relational Classification of Biological Cells in Microscopy Images,"['Ping Liu', 'Mustafa Bilgic']",,,,
Fully Exploiting Cascade Graphs for Real-Time Forwarding Prediction,"['Xiangyun Tang', 'Dongliang Liao', 'Weijie Huang', 'Liehuang Zhu', 'Meng Shen', 'Jin Xu']",,,,
Complete Closed Time Intervals-Related Patterns Mining,"['Omer David Harel', 'Robert Moskovitch']",,,,
Deep Conservation: A Latent-Dynamics Model for Exact Satisfaction of Physical Conservation Laws,"['Kookjin Lee', 'Kevin Carlberg']",https://arxiv.org/abs/1909.09754,"This work proposes an approach for latent dynamics learning that exactly enforces physical conservation laws. The method comprises two steps. First, we compute a low-dimensional embedding of the high-dimensional dynamical-system state using deep convolutional autoencoders. This defines a low-dimensional nonlinear manifold on which the state is subsequently enforced to evolve. Second, we define a latent dynamics model that associates with a constrained optimization problem. Specifically, the objective function is defined as the sum of squares of conservation-law violations over control volumes in a finite-volume discretization of the problem; nonlinear equality constraints explicitly enforce conservation over prescribed subdomains of the problem. The resulting dynamics model-which can be considered as a projection-based reduced-order model-ensures that the time-evolution of the latent state exactly satisfies conservation laws over the prescribed subdomains. In contrast to existing methods for latent dynamics learning, this is the only method that both employs a nonlinear embedding and computes dynamics for the latent state that guarantee the satisfaction of prescribed physical properties. Numerical experiments on a benchmark advection problem illustrate the method's ability to significantly reduce the dimensionality while enforcing physical conservation.",この作品は、物理的保存則を正確に施行する潜在ダイナミクス学習のアプローチを提案します。この方法は２つのステップからなる。最初に、深い畳み込みオートエンコーダーを使用して、高次元の動的システム状態の低次元の埋め込みを計算します。これは、状態がその後進化するように強制される低次元の非線形マニホールドを定義します。次に、制約付き最適化問題に関連する潜在的なダイナミクスモデルを定義します。具体的には、目的関数は、問題の有限体積離散化におけるコントロールボリュームに対する保存則違反の二乗和として定義されます。非線形等式制約は、問題の規定されたサブドメインに対して明示的に保存を強制します。結果として得られるダイナミクスモデル（射影ベースの低次元モデルと見なすことができます）は、潜在状態の時間発展が、指定されたサブドメインの保存則を正確に満たすことを保証します。潜在ダイナミクス学習の既存の方法とは対照的に、これは、非線形埋め込みを採用し、規定の物理的特性の満足を保証する潜在状態のダイナミクスを計算する唯一の方法です。ベンチマーク移流問題に関する数値実験は、物理的保存を実施しながら次元を大幅に削減する方法の能力を示しています。,https://d3i71xaburhd42.cloudfront.net/02327b889e75a9d86d4351cfea7c17e730d8efa4/7-Figure1-1.png
Theoretically Principled Deep Rl Acceleration via Nearest Neighbor Function Approximation,"['Junhong Shen', 'Lin Yang']",,,,
Condorcet Relaxation in Spatial Voting,"['Omrit Filtser', 'Arnold Filtser']",,,,
Generating Natural Language Attacks in a Hard Label Black Box Setting,"['Rishabh Maheshwary', 'Saket Maheshwary', 'Vikram Pudi']",https://arxiv.org/abs/2012.14956,"We study an important and challenging task of attacking natural language processing models in a hard label black box setting. We propose a decision-based attack strategy that crafts high quality adversarial examples on text classification and entailment tasks. Our proposed attack strategy leverages population-based optimization algorithm to craft plausible and semantically similar adversarial examples by observing only the top label predicted by the target model. At each iteration, the optimization procedure allow word replacements that maximizes the overall semantic similarity between the original and the adversarial text. Further, our approach does not rely on using substitute models or any kind of training data. We demonstrate the efficacy of our proposed approach through extensive experimentation and ablation studies on five state-of-the-art target models across seven benchmark datasets. In comparison to attacks proposed in prior literature, we are able to achieve a higher success rate with lower word perturbation percentage that too in a highly restricted setting.",ハードラベルのブラックボックス設定で自然言語処理モデルを攻撃するという重要でやりがいのあるタスクを研究します。テキスト分類と含意タスクに関する高品質の敵対的な例を作成する意思決定ベースの攻撃戦略を提案します。私たちが提案する攻撃戦略は、人口ベースの最適化アルゴリズムを活用して、ターゲットモデルによって予測されたトップラベルのみを観察することにより、もっともらしい、意味的に類似した敵対的な例を作成します。各反復で、最適化手順により、元のテキストと敵対的なテキストの間の全体的な意味的類似性を最大化する単語の置換が可能になります。さらに、私たちのアプローチは、代替モデルやあらゆる種類のトレーニングデータの使用に依存していません。 7つのベンチマークデータセットにわたる5つの最先端のターゲットモデルに関する広範な実験とアブレーション研究を通じて、提案されたアプローチの有効性を示します。以前の文献で提案された攻撃と比較して、非常に制限された設定でも、単語の摂動率を低くして、より高い成功率を達成することができます。,https://d3i71xaburhd42.cloudfront.net/d1e7b5f08061c2e549313151075ac755b6c81755/3-Figure1-1.png
Improving Sample Efficiency in Model-Free Reinforcement Learning from Images,"['Denis Yarats', 'Amy Zhang', 'Ilya Kostrikov', 'Brandon Amos', 'Joelle Pineau', 'Rob Fergus']",https://arxiv.org/abs/1910.01741,"Training an agent to solve control tasks directly from high-dimensional images with model-free reinforcement learning (RL) has proven difficult. A promising approach is to learn a latent representation together with the control policy. However, fitting a high-capacity encoder using a scarce reward signal is sample inefficient and leads to poor performance. Prior work has shown that auxiliary losses, such as image reconstruction, can aid efficient representation learning. However, incorporating reconstruction loss into an off-policy learning algorithm often leads to training instability. We explore the underlying reasons and identify variational autoencoders, used by previous investigations, as the cause of the divergence. Following these findings, we propose effective techniques to improve training stability. This results in a simple approach capable of matching state-of-the-art model-free and model-based algorithms on MuJoCo control tasks. Furthermore, our approach demonstrates robustness to observational noise, surpassing existing approaches in this setting. Code, results, and videos are anonymously available at this https URL.",モデルフリー強化学習（RL）を使用して、高次元画像から直接制御タスクを解決するようにエージェントをトレーニングすることは困難であることが証明されています。有望なアプローチは、制御ポリシーとともに潜在表現を学習することです。ただし、希少な報酬信号を使用して大容量エンコーダを取り付けると、サンプルの効率が低下し、パフォーマンスが低下します。以前の研究では、画像再構成などの補助損失が効率的な表現学習に役立つことが示されています。ただし、再構築の損失をポリシー外の学習アルゴリズムに組み込むと、トレーニングが不安定になることがよくあります。根本的な理由を調査し、以前の調査で使用された変分オートエンコーダーを発散の原因として特定します。これらの発見に続いて、トレーニングの安定性を改善するための効果的な手法を提案します。これにより、MuJoCo制御タスクで最先端のモデルフリーアルゴリズムとモデルベースアルゴリズムを一致させることができるシンプルなアプローチが実現します。さらに、私たちのアプローチは、この設定での既存のアプローチを超えて、観測ノイズに対するロバスト性を示しています。コード、結果、およびビデオは、このhttpsURLで匿名で入手できます。,https://d3i71xaburhd42.cloudfront.net/88dd6594c9ddd4c4bb7f9b407b162e283907f4f3/2-Figure1-1.png
Neural Architecture Search as Sparse Supernet,"['Yan Wu', 'Aoming Liu', 'Zhiwu Huang', 'Siwei Zhang', 'Luc Van Gool']",https://arxiv.org/abs/2007.16112,"This paper aims at enlarging the problem of Neural Architecture Search from Single-Path and Multi-Path Search to automated Mixed-Path Search. In particular, we model the new problem as a sparse supernet with a new continuous architecture representation using a mixture of sparsity constraints, i.e., Sparse Group Lasso. The sparse supernet is expected to automatically achieve sparsely-mixed paths upon a compact set of nodes. To optimize the proposed sparse supernet, we exploit a hierarchical accelerated proximal gradient algorithm within a bi-level optimization framework. Extensive experiments on CIFAR-10, CIFAR-100, Tiny ImageNet and ImageNet demonstrate that the proposed methodology is capable of searching for compact, general and powerful neural architectures.",この論文は、ニューラルアーキテクチャ検索の問題をシングルパスおよびマルチパス検索から自動化された混合パス検索に拡大することを目的としています。特に、新しい問題を、スパース性制約の混合、つまりスパースグループラッソを使用した新しい連続アーキテクチャ表現を備えたスパーススーパーネットとしてモデル化します。スパーススーパーネットは、ノードのコンパクトなセットでスパース混合パスを自動的に実現することが期待されています。提案されたスパーススーパーネットを最適化するために、2レベルの最適化フレームワーク内で階層的加速近接勾配アルゴリズムを活用します。 CIFAR-10、CIFAR-100、Tiny ImageNet、およびImageNetでの広範な実験は、提案された方法論がコンパクトで一般的かつ強力なニューラルアーキテクチャを検索できることを示しています。,https://d3i71xaburhd42.cloudfront.net/0c5627fb5bc540e4f93a725cd6c8e23152887aff/2-Figure1-1.png
Modeling the Probabilistic Distribution of Unlabeled Data for One-Shot Medical Image Segmentation,"['Yuhang Ding', 'Xin Yu', 'Yi Yang']",https://arxiv.org/abs/2102.02033,"Existing image segmentation networks mainly leverage largescale labeled datasets to attain high accuracy. However, labeling medical images is very expensive since it requires sophisticated expert knowledge. Thus, it is more desirable to employ only a few labeled data in pursuing high segmentation performance. In this paper, we develop a data augmentation method for one-shot brain magnetic resonance imaging (MRI) image segmentation which exploits only one labeled MRI image (named atlas) and a few unlabeled images. In particular, we propose to learn the probability distributions of deformations (including shapes and intensities) of different unlabeled MRI images with respect to the atlas via 3D variational autoencoders (VAEs). In this manner, our method is able to exploit the learned distributions of image deformations to generate new authentic brain MRI images, and the number of generated samples will be sufficient to train a deep segmentation network. Furthermore, we introduce a new standard segmentation benchmark to evaluate the generalization performance of a segmentation network through a cross-dataset setting (collected from different sources). Extensive experiments demonstrate that our method outperforms the state-of-theart one-shot medical segmentation methods. Our code has been released at https://github.com/dyh127/Modeling-theProbabilistic-Distribution-of-Unlabeled-Data.",既存の画像セグメンテーションネットワークは、主に大規模なラベル付きデータセットを活用して高精度を実現します。ただし、医用画像のラベル付けには高度な専門知識が必要なため、非常に費用がかかります。したがって、高いセグメンテーションパフォーマンスを追求するには、少数のラベル付きデータのみを使用することがより望ましい。この論文では、1つのラベル付きMRI画像（アトラスという名前）といくつかのラベルなし画像のみを利用するワンショット脳磁気共鳴画像（MRI）画像セグメンテーションのデータ拡張方法を開発します。特に、3D変分オートエンコーダー（VAE）を介して、アトラスに関するさまざまなラベルなしMRI画像の変形（形状と強度を含む）の確率分布を学習することを提案します。このようにして、私たちの方法は、画像変形の学習された分布を利用して、新しい本物の脳MRI画像を生成することができ、生成されたサンプルの数は、深いセグメンテーションネットワークをトレーニングするのに十分です。さらに、新しい標準セグメンテーションベンチマークを導入して、クロスデータセット設定（さまざまなソースから収集）を通じてセグメンテーションネットワークの一般化パフォーマンスを評価します。広範な実験は、私たちの方法が最先端のワンショット医療セグメンテーション方法よりも優れていることを示しています。私たちのコードはhttps://github.com/dyh127/Modeling-theProbabilistic-Distribution-of-Unlabeled-Dataでリリースされています。,https://d3i71xaburhd42.cloudfront.net/d94db8bf218a9ed41d9df8cab81edf5f68162e8c/1-Figure1-1.png
Local Differential Privacy for Bayesian Optimization,"['Xingyu Zhou', 'Jian Tan']",https://arxiv.org/abs/2010.06709,"Motivated by the increasing concern about privacy in nowadays data-intensive online learning systems, we consider a black-box optimization in the nonparametric Gaussian process setting with local differential privacy (LDP) guarantee. Specifically, the rewards from each user are further corrupted to protect privacy and the learner only has access to the corrupted rewards to minimize the regret. We first derive the regret lower bounds for any LDP mechanism and any learning algorithm. Then, we present three almost optimal algorithms based on the GP-UCB framework and Laplace DP mechanism. In this process, we also propose a new Bayesian optimization (BO) method (called MoMA-GP-UCB) based on median-of-means techniques and kernel approximations, which complements previous BO algorithms for heavy-tailed payoffs with a reduced complexity. Further, empirical comparisons of different algorithms on both synthetic and real-world datasets highlight the superior performance of MoMA-GP-UCB in both private and non-private scenarios.",今日のデータ集約型オンライン学習システムにおけるプライバシーへの関心の高まりに動機付けられて、ローカル差分プライバシー（LDP）保証を備えたノンパラメトリックガウス過程設定でのブラックボックス最適化を検討します。具体的には、プライバシーを保護するために各ユーザーからの報酬がさらに破損し、学習者は破損した報酬にのみアクセスして後悔を最小限に抑えることができます。まず、LDPメカニズムと学習アルゴリズムに対する後悔の下限を導き出します。次に、GP-UCBフレームワークとラプラスDPメカニズムに基づく3つのほぼ最適なアルゴリズムを示します。このプロセスでは、平均値の中央値手法とカーネル近似に基づく新しいベイズ最適化（BO）法（MoMA-GP-UCBと呼ばれる）も提案します。これは、複雑さを軽減した裾の重いペイオフの以前のBOアルゴリズムを補完します。さらに、合成データセットと実世界のデータセットの両方でのさまざまなアルゴリズムの経験的比較により、プライベートシナリオと非プライベートシナリオの両方でMoMA-GP-UCBの優れたパフォーマンスが強調されています。,https://d3i71xaburhd42.cloudfront.net/6fcf884343bfac0d4680133b51c558c6a4e0bf35/7-Figure1-1.png
Communication-Efficient Projection-Free Algorithm for Nonconvex Constrained Learning Models,"['Wenhan Xian', 'Feihu Huang', 'Heng Huang']",,,,
Cutting to the Core of Pseudo-Boolean Optimization: Combining Core-Guided Search with Cutting Planes Reasoning,"['Jo Devriendt', 'Stephan Gocht', 'Emir Demirović', 'Peter Stuckey', 'Jakob Nordström']",,,,
Scalable Graph Networks for Particle Simulations,"['Karolis Martinkus', 'Aurelien Lucchi', 'Nathanaël Perraudin']",https://arxiv.org/abs/2010.06948,"Learning system dynamics directly from observations is a promising direction in machine learning due to its potential to significantly enhance our ability to understand physical systems. However, the dynamics of many real-world systems are challenging to learn due to the presence of nonlinear potentials and a number of interactions that scales quadratically with the number of particles $N$, as in the case of the N-body problem. In this work, we introduce an approach that transforms a fully-connected interaction graph into a hierarchical one which reduces the number of edges to $O(N)$. This results in linear time and space complexity while the pre-computation of the hierarchical graph requires $O(N\log (N))$ time and $O(N)$ space. Using our approach, we are able to train models on much larger particle counts, even on a single GPU. We evaluate how the phase space position accuracy and energy conservation depend on the number of simulated particles. Our approach retains high accuracy and efficiency even on large-scale gravitational N-body simulations which are impossible to run on a single machine if a fully-connected graph is used. Similar results are also observed when simulating Coulomb interactions. Furthermore, we make several important observations regarding the performance of this new hierarchical model, including: i) its accuracy tends to improve with the number of particles in the simulation and ii) its generalisation to unseen particle counts is also much better than for models that use all $O(N^2)$ interactions.",観測から直接システムダイナミクスを学習することは、物理システムを理解する能力を大幅に向上させる可能性があるため、機械学習の有望な方向性です。ただし、多くの実世界のシステムのダイナミクスは、非線形ポテンシャルの存在と、N体問題の場合のように、粒子数Nに比例してスケーリングする相互作用の数のために学習が困難です。この作業では、完全に接続された相互作用グラフを、エッジの数をO（N）に減らす階層グラフに変換するアプローチを紹介します。これにより、線形の時間と空間の複雑さが生じますが、階層グラフの事前計算にはO（Nlog（N））時間とO（N）空間が必要です。私たちのアプローチを使用すると、単一のGPUでも、はるかに多くの粒子数でモデルをトレーニングできます。位相空間の位置精度とエネルギー節約がシミュレートされた粒子の数にどのように依存するかを評価します。私たちのアプローチは、完全に接続されたグラフを使用した場合、単一のマシンでは実行できない大規模な重力N体シミュレーションでも高い精度と効率を維持します。クーロン相互作用をシミュレートする場合にも、同様の結果が観察されます。さらに、この新しい階層モデルのパフォーマンスに関して、次のようないくつかの重要な観察を行います。i）シミュレーションの粒子数とともに精度が向上する傾向があり、ii）目に見えない粒子数への一般化もモデルよりもはるかに優れています。すべてのO（N2）相互作用を使用します。,
Efficient On-Chip Learning for Optical Neural Networks through Power-Aware Sparse Zeroth-Order Optimization,"['Jiaqi Gu', 'Chenghao Feng', 'Zheng Zhao', 'Zhoufeng Ying', 'Ray T Chen', 'David Z Pan']",https://arxiv.org/abs/2012.11148,"Optical neural networks (ONNs) have demonstrated recordbreaking potential in high-performance neuromorphic computing due to its ultra-high execution speed and low energy consumption. However, current learning protocols fail to provide scalable and efficient solutions to photonic circuit optimization in practical applications. In this work, we propose a novel on-chip learning framework to release the full potential of ONNs for power-efficient in situ training. Instead of deploying implementation-costly back-propagation, we directly optimize the device configurations with computation budgets and power constraints. We are the first to model the ONN on-chip learning as a resource-constrained stochastic noisy zeroth-order optimization problem, and propose a novel mixed-training strategy with two-level sparsity and power-aware dynamic pruning to offer a scalable on-chip training solution in practical ONN deployment. Compared with previous methods, we are the first to optimize over 2,500 optical components on chip. We can achieve much better optimization stability, 3.7×7.6× higher efficiency, and save >90% power under practical device variations and thermal crosstalk. Introduction As Moore’s Law slows down, it becomes challenging for traditional electronics to further satisfy the escalating computational demands of machine learning tasks given clock frequency limitation and power density constraints. Recently, the emerging optical neural network (ONN) has attracted increasing attention due to its ultra-high execution speed and order-of-magnitude higher energy efficiency compared to electronics. In resource-constrained applications, ONNs become a promising alternative to accelerate machine learning workloads (Shen et al. 2017; Ramey et al. 2020; Ying et al. 2020a; Feng et al. 2020a; Ying et al. 2020b). Computationally-intensive operations in neural networks, e.g., matrix multiplication, can be finished within the light propagation delay in one shot (Shen et al. 2017; Zhao et al. 2019b; Gu et al. 2020c,d; Feng et al. 2020c; Miscuglio and Sorger 2020; Liu et al. 2019; Zokaee et al. 2020; Zhao et al. 2019a). With optical interconnects to reduce communication and memory transaction cost, a fully-optical neural engine provides a fundamental solution to break through the NN Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. performance bound. Shen, et al. (Shen et al. 2017) demonstrated an integrated fully-optical neural chip to implement a multi-layer perceptron based on singular value decomposition (SVD) (Reck et al. 1994; Ribeiro et al. 2016). The weight matrices are mapped onto cascaded Mach-Zehnder interferometer (MZI) meshes to realize ultra-fast neural computing with over 100 GHz photo-detection rate and near-zero energy consumption (Shen et al. 2017; Vivien et al. 2012). However, training methodologies for integrated ONNs still lack a scalable and efficient solution so far. The mainstream approach offloads the training and simulation process to electrical computers using classical back-propagation (BP) (Shen et al. 2017; Zhao et al. 2019b), which is inefficient in circuit simulation and inaccurate in device noise modeling. Hence, there exist great potentials to offload the learning process on photonic circuits. Back-propagation is technically challenging to be implemented on a chip given the expensive hardware overhead and time-consuming gradient computation. A brute-force phase tuning algorithm is proposed and adopted in (Shen et al. 2017; Zhou et al. 2019) to perform ONN on-chip training via sequential device tuning, which is intractable as circuits scale up. To mitigate the inefficiency issue of the above brute-force algorithm, an in situ adjoint variable method (AVM) (Hughes et al. 2018) is applied to directly compute the gradient w.r.t. MZI phases via inverse design. However, it is challenging to be scaled to larger systems as the fully-observable circuits is a technically impractical assumption. Evolutionary algorithms, e.g., genetic algorithm (GA) and particle swarm optimization (PSO), are introduced to train ONNs by population evolution (Zhang et al. 2019). A stochastic zeroth-order optimization framework FLOPS (Gu et al. 2020a) has been proposed to improve the ONN learning efficiency by 3-5 times via random-sampling-based zerothorder gradient estimation. However, previous works have the following disadvantages: 1) nontrivial Gaussian sampling cost, 2) divergence issues due to high variance, 3) high energy consumption, and 4) hardware-unfriendly weight update step size. In this work, we propose a novel mixed-training framework that enables scalable on-chip optimization with more stable convergence, higher training efficiency, and much lower power consumption under non-ideal environment. Compared with previous state-of-the-art (SOTA) methods, our mixed-training framework has the following advantages. ar X iv :2 01 2. 11 14 8v 1 [ cs .E T ] 2 1 D ec 2 02 0","光ニューラルネットワーク（ONN）は、その超高速実行速度と低エネルギー消費により、高性能ニューロモーフィックコンピューティングで記​​録的な可能性を示しています。ただし、現在の学習プロトコルは、実際のアプリケーションでフォトニック回路の最適化にスケーラブルで効率的なソリューションを提供することができません。この作業では、電力効率の高い現場トレーニングのためのONNの可能性を最大限に引き出すための新しいオンチップ学習フレームワークを提案します。実装コストのかかるバックプロパゲーションを導入する代わりに、計算バジェットと電力制約を使用してデバイス構成を直接最適化します。 ONNオンチップ学習を、リソースに制約のある確率的ノイズの多い0次最適化問題としてモデル化した最初の企業であり、スケーラブルなオンチップを提供するために、2レベルのスパース性と電力を意識した動的プルーニングを備えた新しい混合トレーニング戦略を提案します。実際のONN展開におけるチップトレーニングソリューション。以前の方法と比較して、2,500を超える光学部品をチップ上で最適化した最初の方法です。はるかに優れた最適化の安定性、3.77.6高い効率を達成し、90を超える節約を実現できます",https://d3i71xaburhd42.cloudfront.net/3bca749276f83a256b5451dade8ab5e666b4547b/2-Figure1-1.png
Learning Cycle-Consistent Cooperative Networks via Alternating MCMC Teaching for Unsupervised Cross-Domain Translation,"['Jianwen Xie', 'Zilong Zheng', 'Xiaolin Fang', 'Song-Chun Zhu', 'Ying Nian Wu']",,"This paper studies unsupervised cross-domain translation problem by proposing a generative framework that represents each domain via a cooperative network that consists of a pair of energy-based model and latent variable model. The use of cooperative network enables maximum likelihood estimation of the domain distribution by MCMC teaching, where the energy-based model seeks to fit the data distribution of domain and distills its knowledge to the latent variable model via MCMC. Specifically, in the MCMC teaching, the latent variable model parameterized by an encoder-decoder maps an individual example from source domain to the target domain, while the energy-based model further refines the initial result by MCMC such that the final translated results match to the examples in the target domain in terms of some statistical properties represented by the learned energy function. The proposed framework simultaneously learns and aligns two cooperative networks, accounting for two opposite directions of mappings between two domains, by alternating MCMC teaching for the purpose of building up cross-domain correspondence. Experiments show that the proposed framework can be useful for unsupervised image-to-image translation and unpaired image sequence translation.",この論文は、エネルギーベースのモデルと潜在変数モデルのペアからなる協調ネットワークを介して各ドメインを表す生成フレームワークを提案することにより、教師なしクロスドメイン変換問題を研究します。協調ネットワークの使用により、MCMCティーチングによるドメイン分布の最尤推定が可能になります。この場合、エネルギーベースのモデルはドメインのデータ分布に適合し、MCMCを介してその知識を潜在変数モデルに抽出します。具体的には、MCMCの教えでは、エンコーダーデコーダーによってパラメーター化された潜在変数モデルが個々の例をソースドメインからターゲットドメインにマッピングし、エネルギーベースのモデルがMCMCによる初期結果をさらに洗練して、最終的な変換結果が学習されたエネルギー関数によって表されるいくつかの統計的特性に関するターゲットドメインの例。提案されたフレームワークは、クロスドメイン対応を構築する目的でMCMCティーチングを交互に行うことにより、2つのドメイン間のマッピングの2つの反対方向を考慮して、2つの協調ネットワークを同時に学習および調整します。実験は、提案されたフレームワークが教師なし画像から画像への変換および対になっていない画像シーケンス変換に役立つ可能性があることを示しています。,https://d3i71xaburhd42.cloudfront.net/e8266aa7606217305c25720c839d9742f60360ac/4-Figure1-1.png
Knowledge-Base Degrees of Inconsistency: Complexity and Counting,"['Johannes K Fichte', 'Markus Hecher', 'Arne Meier']",,,,
An Analysis of Approval-Based Committee Rules for 2D-Euclidean Elections,"['Michał T Godziszewski', 'Paweł Batko', 'Piotr Skowron', 'Piotr Faliszewski']",,,,
Mercer Features for Efficient Combinatorial Bayesian Optimization,"['Aryan Deshwal', 'Syrine Belakaria', 'Janardhan Rao Doppa']",https://arxiv.org/abs/2012.07762,"Bayesian optimization (BO) is an efficient framework for solving black-box optimization problems with expensive function evaluations. This paper addresses the BO problem setting for combinatorial spaces (e.g., sequences and graphs) that occurs naturally in science and engineering applications. A prototypical example is molecular optimization guided by expensive experiments. The key challenge is to balance the complexity of statistical models and tractability of search to select combinatorial structures for evaluation. In this paper, we propose an efficient approach referred as Mercer Features for Combinatorial Bayesian Optimization (MerCBO). The key idea behind MerCBO is to provide explicit feature maps for diffusion kernels over discrete objects by exploiting the structure of their combinatorial graph representation. These Mercer features combined with Thompson sampling as the acquisition function allows us to employ tractable solvers to find next structures for evaluation. Experiments on diverse real-world benchmarks demonstrate that MerCBO performs similarly or better than prior methods. The source code is available at https://github.com/aryandeshwal/MerCBO.",ベイズ最適化（BO）は、高価な関数評価を伴うブラックボックス最適化問題を解決するための効率的なフレームワークです。このホワイトペーパーでは、科学および工学アプリケーションで自然に発生する組み合わせ空間（シーケンスやグラフなど）のBO問題設定について説明します。典型的な例は、高価な実験によって導かれる分子の最適化です。重要な課題は、統計モデルの複雑さと検索の扱いやすさのバランスを取り、評価用の組み合わせ構造を選択することです。この論文では、組み合わせベイズ最適化のためのマーサー機能（MerCBO）と呼ばれる効率的なアプローチを提案します。 MerCBOの背後にある重要なアイデアは、組み合わせグラフ表現の構造を活用することにより、離散オブジェクト上の拡散カーネルの明示的な特徴マップを提供することです。これらのマーサーの機能を取得機能としてのトンプソンサンプリングと組み合わせると、扱いやすいソルバーを使用して、評価用の次の構造を見つけることができます。さまざまな実世界のベンチマークでの実験は、MerCBOが以前の方法と同等またはそれよりも優れていることを示しています。ソースコードはhttps://github.com/aryandeshwal/MerCBOで入手できます。,https://d3i71xaburhd42.cloudfront.net/0fe589d100806afdaaff574e76616242ad9f13da/6-Figure1-1.png
A Market-Inspired Bidding Scheme for Peer Review Paper Assignment,"['Reshef Meir', 'Jerome Lang', 'Julien Lesca', 'Nicholas Mattei', 'Natan Kaminsky']",,,,
Explaining a Black-Box by Using a Deep Variational information Bottleneck Approach,"['Seojin Bang', 'Pengtao Xie', 'Heewook Lee', 'Wei Wu', 'Eric Xing']",,,,
Out-of-Town Recommendation with Travel Intention Modeling,"['Haoran Xin', 'Xinjiang Lu', 'Tong Xu', 'Hao Liu', 'Jingjing Gu', 'Dejing Dou', 'Hui Xiong']",https://arxiv.org/abs/2101.12555,"Out-of-town recommendation is designed for those users who leave their home-town areas and visit the areas they have never been to before. It is challenging to recommend Pointof-Interests (POIs) for out-of-town users since the out-oftown check-in behavior is determined by not only the user’s home-town preference but also the user’s travel intention. Besides, the user’s travel intentions are complex and dynamic, which leads to big difficulties in understanding such intentions precisely. In this paper, we propose a TRAvelINtention-aware Out-of-town Recommendation framework, named TRAINOR. The proposed TRAINOR framework distinguishes itself from existing out-of-town recommenders in three aspects. First, graph neural networks are explored to represent users’ home-town check-in preference and geographical constraints in out-of-town check-in behaviors. Second, a user-specific travel intention is formulated as an aggregation combining home-town preference and generic travel intention together, where the generic travel intention is regarded as a mixture of inherent intentions that can be learned by Neural Topic Model (NTM). Third, a non-linear mapping function as well as a matrix factorization method are employed to transfer users’ home-town preference and estimate out-of-town POI’s representation, respectively. Extensive experiments on real-world data sets validate the effectiveness of the TRAINOR framework. Moreover, the learned travel intention can deliver meaningful explanations for understanding a user’s travel purposes. Introduction Point-of-Interest (POI) recommendation is an important task in location-based services (LBS), which tends to act as a more pivotal part in people’s daily life. Recently, since the POI check-in data having accumulated rapidly over time, a more refined recommendation problem, out-of-town recommendation, is coming into focus. To be specific, out-of-town recommendations are designed for those users who travel from their home-town areas to out-of-town areas they have seldom been to before. Out-of-town recommendation problem suffers from the cold-start issue a lot due to the insufficiency of out-of-town *Corresponding author. This work was done when Haoran Xin was an intern at the Baidu Research. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. check-ins (Ference, Ye, and Lee 2013). Traditional POI recommender systems (POI RSs) fail to make appropriate recommendations to tackle such severe cold start issues. The reasons are: 1) Individual’s home-town preferences cannot be used for out-of-town recommendations directly due to the gap between home-town preferences and out-of-town behaviors (i.e. interest drifts); and 2) The travel intention, which tends to affect the out-of-town check-in behaviors, is often ignored in these POI RSs. In the literature, some research efforts have been made to attack the out-of-town recommendation problem. For instance, (Pham, Li, and Cong 2017) recommends out-oftown region of POIs instead of individual POIs by exploiting the proximity of human mobility. (Ference, Ye, and Lee 2013) proposes a recommender for out-of-town users by taking into account user preference, social influence and geographical proximity. Besides, some researchers have also paid attentions to interest drifts when addressing the outof-town recommendation problem (Yin et al. 2014, 2016; Wang et al. 2017). However, none of these approaches comprehensively integrate users’ preferences, interest drifts and complex travel intentions as a whole. To this end, in this paper, we propose a TRAvel-INtentionaware Out-of-town Recommendation framework, named TRAINOR. Specifically, we first devise a user’s preference representation module based on Gated Graph Neural Network (G-GNN) to explore the underlying structural information encoded in user’s home-town check-ins. After being aggregated via an attention network, the user’s home-town preference is further transferred into out-of-town preference through a non-linear mapping function, i.e. multi-layer perceptron (MLP). In this way, the interest drifts from hometown to out-of-town can be captured directly. Besides, we devise a travel intention discovery module by developing a Neural Topic Model (NTM) followed by user-specific travel intention aggregation. In particular, we assume that each out-of-town check-in activity can be drawn from a latent topic mixture which can be further generated by Gaussian Softmax construction, then we adopt variational inference to uncover users’ generic travel intention without extra supervision. Moreover, the aforementioned user’s home-town preference is integrated into the disclosed generic travel intention to generate user-specific travel intention via another attention network. In addition, we represent user’s out-ofar X iv :2 10 1. 12 55 5v 1 [ cs .I R ] 2 9 Ja n 20 21 Check-in graph G-GNN Home-town check-ins Attention",郊外の推奨事項は、故郷のエリアを離れて、これまでに行ったことのないエリアを訪れるユーザー向けに設計されています。郊外のチェックイン行動は、ユーザーの故郷の好みだけでなく、ユーザーの旅行の意図によっても決定されるため、郊外のユーザーにPointof-Interests（POI）を推奨することは困難です。その上、ユーザーの旅行の意図は複雑で動的であるため、そのような意図を正確に理解することは非常に困難です。この論文では、TRAINORという名前のTRAvelINtention対応の郊外推奨フレームワークを提案します。提案されたTRAINORフレームワークは、3つの点で既存の郊外の推奨者とは異なります。最初に、グラフニューラルネットワークを調査して、ユーザーの故郷のチェックインの好みと、町外のチェックイン行動における地理的制約を表します。第2に、ユーザー固有の旅行意図は、故郷の好みと一般的な旅行意図を組み合わせた集合体として定式化されます。ここで、一般的な旅行意図は、ニューラルトピックモデル（NTM）によって学習できる固有の意図の混合と見なされます。第三に、非線形マッピング関数と行列因数分解法を使用して、ユーザーの故郷の好みを転送し、町外のPOI表現をそれぞれ推定します。実世界のデータセットに関する広範な実験により、TRAINORフレームワークの有効性が検証されます。さらに、学習した旅行の意図は、ユーザーの旅行目的を理解するための有意義な説明を提供することができます。はじめにPOI（Point-of-Interest）の推奨は、位置情報サービス（LBS）の重要なタスクであり、人々の日常生活においてより重要な部分として機能する傾向があります。最近、POIチェックインデータが時間の経過とともに急速に蓄積されているため、より洗練された推奨問題である郊外の推奨に焦点が当てられています。具体的には、郊外の推奨事項は、故郷の地域から、これまでほとんど行ったことのない郊外の地域に旅行するユーザー向けに設計されています。市外推奨問題は、市外の不十分さのためにコールドスタートの問題に多く苦しんでいます。*対応する著者。この作業は、HaoranXinがBaiduResearchのインターンであったときに行われました。 Copyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。全著作権所有。チェックイン（Ference、Ye、およびLee 2013）。従来のPOIレコメンダーシステム（POI RS）は、このような深刻なコールドスタートの問題に対処するための適切な推奨を行うことができません。理由は次のとおりです。1）個人の故郷の好みは、故郷の好みと町外の行動とのギャップ（つまり、関心のドリフト）のために、町外の推奨に直接使用することはできません。 2）これらのPOI RSでは、町外のチェックイン行動に影響を与える傾向のある旅行の意図が無視されることがよくあります。文献では、町外の推奨問題を攻撃するためにいくつかの研究努力がなされてきました。たとえば、（Pham、Li、およびCong 2017）は、人間の移動性の近接性を利用して、個々のPOIではなくPOIの郊外地域を推奨しています。 （Ference、Ye、and Lee 2013）は、ユーザーの好み、社会的影響、地理的な近さを考慮して、郊外のユーザーに推奨を提案しています。その上、一部の研究者は、町外の推奨問題に取り組む際に関心のドリフトにも注意を払っています（Yin et al。2014、2016; Wang et al.2017）。ただし、これらのアプローチはいずれも、ユーザーの好み、関心のドリフト、複雑な旅行の意図を全体として包括的に統合するものではありません。この目的のために、この論文では、TRAINORという名前のTRAvel-INtentionaware Out-of-townRecommendationフレームワークを提案します。具体的には、まず、Gated Graph Neural Network（G-GNN）に基づくユーザー設定表現モジュールを考案して、ユーザーの故郷のチェックインでエンコードされた基礎となる構造情報を調査します。アテンションネットワークを介して集約された後、ユーザーの故郷の好みは、非線形マッピング機能、つまり多層パーセプトロン（MLP）を介して町外の好みにさらに転送されます。このようにして、故郷から郊外への関心の流れを直接捉えることができます。さらに、Neural Topic Model（NTM）を開発し、続いてユーザー固有の旅行意図を集約することにより、旅行意図発見モジュールを考案します。特に、各郊外のチェックインアクティビティは、Gaussian Softmax構築によってさらに生成できる潜在的なトピックの混合から引き出すことができると想定し、変分推論を採用して、特別な監督なしでユーザーの一般的な旅行意図を明らかにします。さらに、前述のユーザーの故郷の好みは、開示された一般的な旅行意図に統合され、別の注意ネットワークを介してユーザー固有の旅行意図を生成する。さらに、外部のユーザーを表しますX iv：2 10 1. 12 55 5v 1 [cs .IR] 2 9 Ja n 2021チェックイングラフG-GNN故郷のチェックイン注意,https://d3i71xaburhd42.cloudfront.net/eb10b623a76dae8d69bc5f551cd02e51218dba5e/2-Figure1-1.png
A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with Constraints,"['Krishna C Kalagarla', 'Rahul Jain', 'Pierluigi Nuzzo']",https://arxiv.org/abs/2009.11348,"Constrained Markov Decision Processes (CMDPs) formalize sequential decision-making problems whose objective is to minimize a cost function while satisfying constraints on various cost functions. In this paper, we consider the setting of episodic fixed-horizon CMDPs. We propose an online algorithm which leverages the linear programming formulation of finite-horizon CMDP for repeated optimistic planning to provide a probably approximately correct (PAC) guarantee on the number of episodes needed to ensure an $\epsilon$-optimal policy, i.e., with resulting objective value within $\epsilon$ of the optimal value and satisfying the constraints within $\epsilon$-tolerance, with probability at least $1-\delta$. The number of episodes needed is shown to be of the order $\tilde{\mathcal{O}}\big(\frac{|S||A|C^{2}H^{2}}{\epsilon^{2}}\log\frac{1}{\delta}\big)$, where $C$ is the upper bound on the number of possible successor states for a state-action pair. Therefore, if $C \ll |S|$, the number of episodes needed have a linear dependence on the state and action space sizes $|S|$ and $|A|$, respectively, and quadratic dependence on the time horizon $H$.",制約付きマルコフ決定過程（CMDP）は、さまざまなコスト関数の制約を満たしながらコスト関数を最小化することを目的とした、順次の意思決定問題を形式化します。この論文では、エピソード的な固定ホライズンCMDPの設定について考察します。有限ホライズンCMDPの線形計画法を活用して楽観的な計画を繰り返すオンラインアルゴリズムを提案し、最適なポリシーを確保するために必要なエピソードの数について、おそらくほぼ正しい（PAC）保証を提供します。最適値を求め、-tolerance内の制約を満たし、確率は少なくとも1です。必要なエピソードの数は、$ \ tilde {\ mathcal {O}} \ big（\ frac {| S || A | C ^ {2} H ^ {2}} {\ epsilon ^ { 2}} \ log \ frac {1} {\ delta} \ big）$、ここでCは、状態とアクションのペアで可能な後続状態の数の上限です。したがって、C | S |の場合、必要なエピソードの数は、状態とアクション空間のサイズ| S |に線形依存します。それぞれ| A |、および時間範囲Hへの2次依存性。,
Learning Energy-Based Model with Variational Auto-Encoder as Amortized Sampler,"['Jianwen Xie', 'Zilong Zheng', 'Ping Li']",https://arxiv.org/abs/2012.14936,"Due to the intractable partition function, training energybased models (EBMs) by maximum likelihood requires Markov chain Monte Carlo (MCMC) sampling to approximate the gradient of the Kullback–Leibler divergence between data and model distributions. However, it is non-trivial to sample from an EBM because of the difficulty of mixing between modes. In this paper, we propose to learn a variational auto-encoder (VAE) to initialize the finite-step MCMC, such as Langevin dynamics that is derived from the energy function, for efficient amortized sampling of the EBM. With these amortized MCMC samples, the EBM can be trained by maximum likelihood, which follows an “analysis by synthesis” scheme; while the variational auto-encoder learns from these MCMC samples via variational Bayes. We call this joint training algorithm the variational MCMC teaching, in which the VAE chases the EBM toward data distribution. We interpret the learning algorithm as a dynamic alternating projection in the context of information geometry. Our proposed models can generate samples comparable to GANs and EBMs. Additionally, we demonstrate that our models can learn effective probabilistic distribution toward supervised conditional learning experiments.",扱いにくい分配関数のため、最尤法によるエネルギーベースモデル（EBM）のトレーニングでは、データとモデル分布の間のカルバックライブラー発散の勾配を近似するためにマルコフ連鎖モンテカルロ（MCMC）サンプリングが必要です。ただし、モード間の混合が難しいため、EBMからサンプリングすることは簡単ではありません。この論文では、EBMの効率的な償却サンプリングのために、エネルギー関数から導出されるランジュバン動力学などの有限ステップMCMCを初期化する変分オートエンコーダ（VAE）を学習することを提案します。これらの償却されたMCMCサンプルを使用すると、EBMは最尤法でトレーニングできます。これは、合成スキームによる分析に従います。一方、変分オートエンコーダは、変分ベイズを介してこれらのMCMCサンプルから学習します。この共同トレーニングアルゴリズムを、VAEがデータ分散に向けてEBMを追跡する変分MCMCティーチングと呼びます。学習アルゴリズムは、情報幾何学のコンテキストで動的な交互投影として解釈されます。私たちが提案するモデルは、GANやEBMに匹敵するサンプルを生成できます。さらに、モデルが教師あり条件学習実験に向けて効果的な確率分布を学習できることを示します。,https://d3i71xaburhd42.cloudfront.net/34910ca00ff02baaa65e5f46253c5cb8c8743588/5-Figure1-1.png
High-Confidence Off-Policy (or Counterfactual) Variance Estimation,"['Yash Chandak', 'Shiv Shankar', 'Philip Thomas']",https://arxiv.org/abs/2101.09847,"Many sequential decision-making systems leverage data collected using prior policies to propose a new policy. For critical applications, it is important that high-confidence guarantees on the new policy’s behavior are provided before deployment, to ensure that the policy will behave as desired. Prior works have studied high-confidence off-policy estimation of the expected return, however, high-confidence off-policy estimation of the variance of returns can be equally critical for high-risk applications. In this paper we tackle the previously open problem of estimating and bounding, with high confidence, the variance of returns from off-policy data. Introduction Reinforcement learning (RL) has emerged as a promising method for solving sequential decision-making problems (Sutton and Barto 2018). Deploying RL to real-world applications, however, requires additional consideration of reliability, which has been relatively understudied. Specifically, it is often desirable to provide high-confidence guarantees on the behavior of a given policy, before deployment, to ensure that the policy will behave as desired. Prior works in RL have studied the problem of providing high-confidence guarantees on the expected return of an evaluation policy, π, using only data collected from a currently deployed policy called the behavior policy, β (Thomas, Theocharous, and Ghavamzadeh 2015; Hanna, Stone, and Niekum 2017; Kuzborskij et al. 2020). Analogously, researchers have also studied the problem of counter-factually estimating and bounding the average treatment effect, with high confidence, using data from past treatments (Bottou et al. 2013). While these methods present important contributions towards developing practical algorithms, real-world problems may require additional consideration of the variance of returns (effect) under any new policy (treatment) before it can be deployed responsibly. For applications that have high stakes in the terms of financial cost or public well-being, only providing guarantees on the mean outcome might not be sufficient. Analysis of variance (ANOVA) has therefore become a de-facto standard for many industrial and medical applications (Tabachnick and Fidell 2007). Similarly, analysis of variance can Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Figure 1: Illustrative example of the distributions of returns from a behavior policy β, and evaluation policy π, along with the importance weighted returns ρ, discussed later. Given trajectories from the behavior policy β, we aim to estimate and bound the variance, σ(π), of returns under an evaluation policy π, with high confidence. Note that the distribution of importance-weighted returns ρ has the mean value μ(π), but might have variance not equal to σ(π). inform numerous real-world applications of RL. For example, (a) analysing the variance of outcomes in a robotics application (Kuindersma, Grupen, and Barto 2013), (b) ensuring that the variance of outcomes for a medical treatment is not high, (c) characterizing the variance of customer experiences for a recommendation system (Teevan et al. 2009), or (d) limiting the variability of the performance of an autonomous driving system (Montgomery 2007). More generally, variance estimation can be used to account for risk in decision-making by designing objectives that maximize the mean of returns but minimize the variance of returns (Sato, Kimura, and Kobayashi 2001; Di Castro, Tamar, and Mannor 2012; La and Ghavamzadeh 2013). Variance estimates have also been shown to be useful for automatically adapting hyper-parameters, like the exploration rate (Sakaguchi and Takano 2004) or λ for eligibility-traces (White and White 2016), and might also inform other methods that depend on the entire distribution of returns (Bellemare, Dabney, and Munos 2017; Dabney et al. 2017). Despite the wide applicability of variance analysis, estimating and bounding the variance of returns with high confidence, using only off-policy data, has remained an understudied problem. In this paper, we first formalize the problem statement; an illustration of which is provided in Figure 1. We show that the typical use of importance sampling (IS) in RL only corrects for the mean, and so ar X iv :2 10 1. 09 84 7v 1 [ cs .L G ] 2 5 Ja n 20 21 it does not directly provide unbiased off-policy estimates of variance. We then present an off-policy estimator of the variance of returns that uses IS twice, together with a simple double-sampling technique. To reduce the variance of the estimator, we extend the per-decision IS technique (Precup 2000) to off-policy variance estimation. Building upon this estimator, we provide confidence intervals for the variance using (a) concentration inequalities, and (b) statistical bootstrapping. Advantages: The proposed variance estimator has several advantages: (a) it is a model-free estimator and can thus be used irrespective of the environment complexity, (b) it requires only off-policy data and can therefore be used before actual policy deployment, (c) it is unbiased and consistent. For high-confidence guarantees, (d) we provide both upper and lower confidence intervals for the variance that have guaranteed coverage (that is, they hold with any desired confidence level and without requiring false assumptions), and (e) we also provide bootstrap confidence intervals, which are approximate but often more practical. Limitations: The proposed off-policy estimator of the variance relies upon IS and thus inherits its limitations. Namely, (a) it requires knowledge of the action probabilities from the behavior policy β, (b) it requires that the support of the trajectories under the evaluation policy π is a subset of the support under the behavior policy β, and (c) the variance of the estimator scales exponentially with the length of the trajectory (Guo, Thomas, and Brunskill 2017; Liu et al. 2018). Background and Problem Statement A Markov decision process (MDP) is a tuple (S,A,P,R, γ, d0), where S is the set of states, A is the set of actions, P is the transition function, R is the reward function, γ ∈ [0, 1) is the discount factor, and d0 is the starting state distribution.1 A policy π is a distribution over the actions conditioned on the state, i.e., π(a|s) represents the probability of taking action a in state s. We assume that the MDP has finite horizon T , after which any action leads to an absorbing state S(∞). In general, we will use subscripts with parentheses for the timestep and subscript without parentheses to indicate the episode number. Let Ri(j) ∈ [Rmin, Rmax] represent the reward observed at timestep j of the episode i. Let the random variable Gi := ∑T j=0 γ Ri(j) be the return for episode i. Let c := (1 − γ )/(1 − γ) so that the minimum and the maximum returns possible are Gmin := cRmin and Gmax := cRmax, respectively. Let μ(π) := Eπ[G] be the expected return, and σ(π) := Vπ[G] be the variance of returns, where the subscript π denotes that the trajectories are generated using policy π. We formulate the problem in terms of MDPs, but it can analogously be formulated in terms of structural causal models. (Pearl 2009). For simplicity, we consider finite states and actions, but our results extend to POMDPs (by replacing states with observations) and to continuous states and actions (by appropriately replacing summations with integrals), and to infinite horizons (T := ∞). LetH (i):(j) be the set of all possible trajectories for a policy π, from timestep i to timestep j. LetH denote a complete trajectory: (S(0), A(0),Pr(A(0)|S(0)), R(0), S(1), ..., S(∞)), where T is the horizon length, and S(0) is sampled from d0. Let D be a set of n trajectories {Hi}i=1 generated using behavior policies {βi}i=1, respectively. Let ρi(0, T ) := ∏T j=0 π(Ai(j)|Si(j)) βi(Ai(j)|Si(j)) denote the product of importance ratios from timestep 0 to T . For brevity, when the range of timesteps is not necessary, we write ρi := ρi(0, T ). Similarly, when referring to ρi for an arbitrary i ∈ {1, . . . , n}, we often write ρ. With this notation, we now formalize the offpolicy variance estimation (OVE) and the high-confidence off-policy variance estimation (HCOVE) problems. OVE Problem: Given a set of trajectories D and an evaluation policy π, we aim to find an estimator σ̂ n that is both an unbiased and consistent estimator of σ(π), i.e., E[σ̂ n] = σ(π), σ̂ n a.s. −→ σ(π). HCOVE Problem: Given a set of trajectories D, an evaluation policy π, and a confidence level 1− δ, we aim to find a confidence interval C := [vlb, vub], such that Pr ( σ(π) ∈ C ) ≥ 1− δ. Remark 1. It is worth emphasizing that the OVE problem is about estimating the variance of returns, and not the variance of the estimator of the mean of returns. These problems would not be possible to solve if the trajectories in D are not informative about the trajectories that are possible under π. For example, if D has no trajectory that could be observed if policy π were to be executed, then D provides little or no information about the possible outcomes under π. To avoid this case, we make the following common assumption (Precup 2000), which is satisfied if (βi(a|s) = 0) =⇒ (π(a|s) = 0) for all s ∈ S, a ∈ A, and i ∈ {1, . . . , n}. Assumption 1. The setD contains independent trajectories generated using behavior policies {βi}i=1, such that ∀i, H (0):(T ) ⊆ H βi (0):(T ). The methods that we derive, and IS methods in general, do not require complete knowledge of {βi}i=1 (which might be parameterized using deep neural networks and might be hard to store). Only the probabilities, βi(a|s), for states s and actions a present in D are required. For simplicity, we restrict our notation to a single behavior policy β, such that ∀i, βi = β. Naïve Methods In the on-policy setting, computing an estimate of μ(π) or σ(π) is trivial—sample n trajectories using π and compute the sample mean or variance of the observed returns, {Gi}",多くの順次意思決定システムは、以前のポリシーを使用して収集されたデータを活用して、新しいポリシーを提案します。重要なアプリケーションの場合、ポリシーが希望どおりに動作することを保証するために、展開前に新しいポリシーの動作に関する信頼性の高い保証を提供することが重要です。以前の研究では、期待収益の信頼性の高いポリシー外推定が研究されてきましたが、リスクの高いアプリケーションでは、収益の分散の信頼性の高いポリシー外推定も同様に重要になる可能性があります。この論文では、これまで未解決だった、ポリシー外のデータからのリターンの分散を高い信頼性で推定および制限するという問題に取り組みます。はじめに強化学習（RL）は、一連の意思決定の問題を解決するための有望な方法として登場しました（Sutton and Barto2018）。ただし、RLを実際のアプリケーションに展開するには、信頼性についてさらに考慮する必要があり、これは比較的十分に研究されていません。具体的には、ポリシーが希望どおりに動作することを保証するために、展開前に、特定のポリシーの動作に対して信頼性の高い保証を提供することが望ましい場合がよくあります。 RLでの以前の研究では、行動ポリシーと呼ばれる現在展開されているポリシーから収集されたデータのみを使用して、評価ポリシーの期待収益に高い信頼性の保証を提供する問題を研究しました（Thomas、Theocharous、およびGhavamzadeh 2015; Hanna、Stone 、およびNiekum 2017; Kuzborskij et al.2020）。同様に、研究者は、過去の治療からのデータを使用して、高い信頼性で平均治療効果を反事実的に推定し、制限する問題も研究しました（Bottou et al.2013）。これらの方法は実用的なアルゴリズムの開発に重要な貢献をしますが、実際の問題では、責任を持って展開する前に、新しいポリシー（処理）の下でのリターンの分散（効果）をさらに考慮する必要があります。経済的コストや公共の福祉の面で高い利害関係を持つアプリケーションの場合、平均的な結果を保証するだけでは不十分な場合があります。したがって、分散分析（ANOVA）は、多くの産業および医療アプリケーションの事実上の標準になっています（Tabachnick and Fidell2007）。同様に、分散分析はCopyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）で行うことができます。全著作権所有。図1：行動ポリシー、評価ポリシーからのリターンの分布の実例と、後で説明する重要度加重リターン。行動方針からの軌跡を前提として、評価方針の下でのリターンの分散（）を高い信頼性で推定し、制限することを目指しています。重要度加重リターンの分布には平均値（）がありますが、分散が（）に等しくない場合があることに注意してください。 RLの多くの実際のアプリケーションに通知します。たとえば、（a）ロボット工学アプリケーション（Kuindersma、Grupen、およびBarto 2013）の結果の分散を分析し、（b）医療の結果の分散が高くないことを確認し、（c）顧客の分散を特徴付けます。レコメンデーションシステムの経験（Teevan etal。2009）、または（d）自律運転システムのパフォーマンスの変動を制限する（Montgomery 2007）。より一般的には、分散推定を使用して、リターンの平均を最大化するがリターンの分散を最小化する目標を設計することにより、意思決定におけるリスクを説明できます（Sato、Kimura、and Kobayashi 2001; Di Castro、Tamar、and Mannor 2012; LaおよびGhavamzadeh2013）。分散推定は、探索率（Sakaguchi and Takano 2004）や適格性トレース（White and White 2016）などのハイパーパラメーターを自動的に適応させるのにも役立つことが示され、分布全体に依存する他の方法にも情報を提供する可能性があります。収益の割合（Bellemare、Dabney、およびMunos 2017; Dabney et al.2017）。分散分析の幅広い適用性にもかかわらず、ポリシー外のデータのみを使用して、高い信頼性でリターンの分散を推定および制限することは、十分に研究されていない問題のままです。このホワイトペーパーでは、最初に問題ステートメントを形式化します。その図を図1に示します。RLでの重要度サンプリング（IS）の一般的な使用は平均のみを修正するため、X iv：2 10 1. 09 84 7v 1 [cs .LG] 2 5 Ja n 2021それは分散の偏りのないポリシー外推定を直接提供しません。次に、ISを2回使用するリターンの分散のポリシー外推定量を、単純なダブルサンプリング手法とともに提示します。推定量の分散を減らすために、決定ごとのIS手法（Precup 2000）をポリシー外の分散推定に拡張します。この推定量に基づいて、（a）濃度の不等式、および（b）統計的ブートストラップを使用して分散の信頼区間を提供します。利点：提案された分散推定量にはいくつかの利点があります。（a）モデルフリーの推定量であるため、環境の複雑さに関係なく使用できます。（b）ポリシー外のデータのみが必要であるため、実際のポリシー展開の前に使用できます。 、（c）偏りがなく一貫性がある。信頼度の高い保証については、（d）カバレッジが保証されている分散の信頼区間の上限と下限の両方を提供します（つまり、任意の信頼水準で、誤った仮定を必要とせずに保持します）。信頼区間。概算ですが、多くの場合、より実用的です。制限：提案された分散のポリシー外推定量はISに依存しているため、その制限を継承します。つまり、（a）行動ポリシーからの行動確率の知識が必要であり、（b）評価ポリシーの下での軌道のサポートが行動ポリシーの下でのサポートのサブセットである必要があり、（c）の分散推定量は、軌道の長さに応じて指数関数的にスケーリングします（Guo、Thomas、およびBrunskill 2017; Liu et al.2018）。背景と問題の説明マルコフ決定過程（MDP）はタプル（S、A、P、R 、、 d0）です。ここで、Sは状態のセット、Aはアクションのセット、Pは遷移関数、Rは報酬関数[0、1）は割引係数であり、d0は開始状態の分布です。1ポリシーは、状態を条件とするアクションの分布です。つまり、（a | s）はアクションを実行する確率を表します。状態sで。 MDPには有限の地平線Tがあると仮定します。その後、任意のアクションが吸収状態S（）につながります。一般に、タイムステップには括弧付きの添え字を使用し、エピソード番号を示すには括弧なしの添え字を使用します。 Ri（j）[Rmin、Rmax]がエピソードiのタイムステップjで観測された報酬を表すとします。確率変数Gi：= T j = 0 Ri（j）をエピソードiのリターンとします。可能な最小および最大のリターンがそれぞれGmin：= cRminおよびGmax：= cRmaxになるように、c：=（1）/（1）とします。 （）：= E [G]を期待収益、（）：= V [G]を収益の分散とします。ここで、下付き文字は、軌道がポリシーを使用して生成されることを示します。問題はMDPの観点から定式化されますが、構造的因果モデルの観点からも同様に定式化できます。 （Pearl 2009）。簡単にするために、有限の状態とアクションを検討しますが、結果はPOMDP（状態を観測値に置き換えることによる）、連続状態とアクション（合計を積分に適切に置き換えることによる）、および無限の範囲（T：=）に拡張されます。 LetH（i）:( j）は、タイムステップiからタイムステップjまでのポリシーのすべての可能な軌道のセットです。 LetHは完全な軌道を示します：（S（0）、A（0）、Pr（A（0）| S（0））、R（0）、S（1）、...、S（））、ここでTは地平線の長さであり、S（0）はd0からサンプリングされます。 Dを、それぞれ動作ポリシーii = 1を使用して生成されたn個の軌道Hii = 1のセットとします。 i（0、T）：= T j = 0（Ai（j）| Si（j））i（Ai（j）| Si（j））は、タイムステップ0からTまでの重要度比の積を表します。簡潔にするために、タイムステップの範囲が必要ない場合は、i：= i（0、T）と記述します。同様に、任意のi 1、。についてiを参照する場合。 。 。 、n、私たちはよく書きます。この表記法を使用して、オフポリシー分散推定（OVE）および高信頼性オフポリシー分散推定（HCOVE）の問題を形式化します。 OVE問題：一連の軌道Dと評価ポリシーが与えられた場合、（）の不偏で一貫性のある推定量である推定量nを見つけることを目指します。つまり、E [n] =（）、n as（）です。 HCOVE問題：一連の軌道D、評価ポリシー、および信頼水準1が与えられた場合、Pr（（）C）1となるような信頼区間C：= [vlb、vub]を見つけることを目指します。備考1.OVEの問題は、収益の平均の推定量の分散ではなく、収益の分散の推定に関するものであることを強調する価値があります。 Dの軌道が、の下で可能な軌道について情報を提供しない場合、これらの問題を解決することはできません。たとえば、ポリシーが実行された場合に観察できる軌道がDにない場合、Dは、の下で考えられる結果に関する情報をほとんどまたはまったく提供しません。このケースを回避するために、次の一般的な仮定（Precup 2000）を作成します。これは、すべてのs S、a A、およびiに対して（i（a | s）= 0）=（（a | s）= 0）の場合に満たされます。 1、。 。 。 、n。仮定1.setDには、動作ポリシーii = 1を使用して生成された、i​​、H（0）:( T）H i（0）:( T）のような独立した軌道が含まれています。私たちが導出するメソッド、および一般的なISメソッドは、ii = 1の完全な知識を必要としません（ディープニューラルネットワークを使用してパラメーター化され、保存が難しい場合があります）。 Dに存在する状態sとアクションの確率i（a | s）のみが必要です。簡単にするために、i、i =のように、表記を単一の動作ポリシーに制限します。ナイーブな方法オンポリシー設定では、（）または（）の推定値の計算は、観測されたリターンのサンプル平均または分散Giを使用して計算する、n個の軌道のサンプルです。,https://d3i71xaburhd42.cloudfront.net/0d0725bed339ae51ed7867a7300e8ebe1a3e667d/1-Figure1-1.png
Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes,"['Xinyuan Zhang', 'Ruiyi Zhang', 'Manzil Zaheer', 'Amr Ahmed']",,,,
Self-Progressing Robust Training,"['Minhao Cheng', 'Pin-Yu Chen', 'Sijia Liu', 'Shiyu Chang', 'Cho-Jui Hsieh', 'Payel Das']",https://arxiv.org/abs/2012.11769,"Enhancing model robustness under new and even adversarial environments is a crucial milestone toward building trustworthy machine learning systems. Current robust training methods such as adversarial training explicitly uses an “attack” (e.g., `∞-norm bounded perturbation) to generate adversarial examples during model training for improving adversarial robustness. In this paper, we take a different perspective and propose a new framework called SPROUT, self-progressing robust training. During model training, SPROUT progressively adjusts training label distribution via our proposed parametrized label smoothing technique, making training free of attack generation and more scalable. We also motivate SPROUT using a general formulation based on vicinity risk minimization, which includes many robust training methods as special cases. Compared with state-of-the-art adversarial training methods (PGD-`∞ and TRADES) under `∞-norm bounded attacks and various invariance tests, SPROUT consistently attains superior performance and is more scalable to large neural networks. Our results shed new light on scalable, effective and attack-independent robust training methods.",新しい環境や敵対的な環境でモデルの堅牢性を強化することは、信頼できる機械学習システムを構築するための重要なマイルストーンです。敵対的訓練などの現在のロバストな訓練方法は、攻撃（例えば、ノルム有界摂動）を明示的に使用して、敵対的ロバスト性を改善するためのモデル訓練中に敵対的例を生成する。このホワイトペーパーでは、別の視点から、自己進行型の堅牢なトレーニングであるSPROUTと呼ばれる新しいフレームワークを提案します。モデルトレーニング中、SPROUTは、提案されたパラメーター化されたラベル平滑化手法を介してトレーニングラベルの分布を段階的に調整し、トレーニングを攻撃の生成なしでよりスケーラブルにします。また、特殊なケースとして多くの堅牢なトレーニング方法を含む、近傍リスクの最小化に基づく一般的な定式化を使用して、SPROUTを動機付けます。ノルム制限攻撃およびさまざまな不変性テストの下での最先端の敵対的トレーニング方法（PGDおよびTRADES）と比較して、SPROUTは一貫して優れたパフォーマンスを達成し、大規模なニューラルネットワークに対してよりスケーラブルです。私たちの結果は、スケーラブルで効果的で攻撃に依存しない堅牢なトレーニング方法に新たな光を当てました。,https://d3i71xaburhd42.cloudfront.net/73aa94064c4c2e592ddad579c51960c5838828b8/2-Figure1-1.png
Preferred Explanations for Ontology-Mediated Queries under Existential Rules,"['Ismail Ilkan Ceylan', 'Thomas Lukasiewicz', 'Enrico Malizia', 'Cristian Molinaro', 'Andrius Vaicenavicius']",,,,
Learning Contextual Representations for Semantic Parsing with Generation-Augmented Pre-Training,"['Peng Shi', 'Patrick Ng', 'Zhiguo Wang', 'Henghui Zhu', 'Alexander Hanbo Li', 'Jun Wang', 'Cicero Nogueira dos Santos', 'Bing Xiang']",https://arxiv.org/abs/2012.10309,"Most recently, there has been significant interest in learning contextual representations for various NLP tasks, by leveraging large scale text corpora to train large neural language models with self-supervised learning objectives, such as Masked Language Model (MLM). However, based on a pilot study, we observe three issues of existing general-purpose language models when they are applied to text-to-SQL semantic parsers: fail to detect column mentions in the utterances, fail to infer column mentions from cell values, and fail to compose complex SQL queries. To mitigate these issues, we present a model pre-training framework, GenerationAugmented Pre-training (GAP), that jointly learns representations of natural language utterances and table schemas by leveraging generation models to generate pre-train data. GAP MODEL is trained on 2M utterance-schema pairs and 30K utterance-schema-SQL triples, whose utterances are produced by generative models. Based on experimental results, neural semantic parsers that leverage GAP MODEL as a representation encoder obtain new state-of-the-art results on both SPIDER and CRITERIA-TO-SQL benchmarks.",最近では、大規模なテキストコーパスを活用して、マスク言語モデル（MLM）などの自己教師あり学習目的で大規模な神経言語モデルをトレーニングすることにより、さまざまなNLPタスクのコンテキスト表現を学習することに大きな関心が寄せられています。ただし、パイロットスタディに基づいて、既存の汎用言語モデルをテキストからSQLへのセマンティックパーサーに適用すると、3つの問題が観察されます。発話内の列の言及を検出できない、セルの値から列の言及を推測できない、複雑なSQLクエリの作成に失敗します。これらの問題を軽減するために、生成モデルを活用して事前トレーニングデータを生成することにより、自然言語の発話とテーブルスキーマの表現を共同で学習する、モデル事前トレーニングフレームワークであるGenerationAugmented Pre-training（GAP）を紹介します。 GAP MODELは、2Mの発話スキーマペアと30Kの発話スキーマSQLトリプルでトレーニングされており、その発話は生成モデルによって生成されます。実験結果に基づいて、表現エンコーダーとしてGAP MODELを活用するニューラルセマンティックパーサーは、SPIDERとCRITERIA-TO-SQLの両方のベンチマークで新しい最先端の結果を取得します。,https://d3i71xaburhd42.cloudfront.net/c75a2ee17056d2b8c14ac25f9f328a09eb4cf040/3-Figure1-1.png
Market-Based Explanations of Collective Decisions,"['Dominik Peters', 'Grzegorz Pierczyński', 'Nisarg Shah', 'Piotr Skowron']",,"We consider approval-based committee elections, in which a size-k subset of available candidates must be selected given approval sets for each voter, indicating the candidates approved by the voter. A number of axioms capturing ideas of fairness and proportionality have been proposed for this framework. We argue that even the strongest of them, such as priceability and the core, only rule out certain undesirable committees, but fail to ensure that the selected committee is fair in all cases. We propose two new solution concepts, stable priceability and balanced stable priceability, and show that they select arguably fair committees. Our solution concepts come with a non-trivial-to-construct but easy-tounderstand market-based explanation for why the chosen committee is fair. We show that stable priceability is closely related to the notion of Lindahl equilibrium from economics.",承認ベースの委員会選挙を検討します。この選挙では、投票者ごとに承認セットを指定して、利用可能な候補者のサイズkのサブセットを選択し、投票者によって承認された候補者を示します。このフレームワークのために、公平性と比例性のアイデアを捉えた多くの公理が提案されています。価格やコアなどの最強の委員会でさえ、特定の望ましくない委員会を除外するだけであり、選択された委員会がすべての場合に公正であることを保証できないと私たちは主張します。安定した価格設定とバランスの取れた安定した価格設定という2つの新しいソリューションの概念を提案し、それらがほぼ間違いなく公正な委員会を選択することを示します。私たちのソリューションの概念には、選択された委員会が公正である理由について、構築するのは簡単ではありませんが、市場ベースの理解が容易な説明が付属しています。安定した価格性は、経済学からのリンダール均衡の概念と密接に関連していることを示します。,https://d3i71xaburhd42.cloudfront.net/0d5e09422963dc8db76b6c2424cd8786c1602f95/31-Table1-1.png
Decentralised Learning from Independent Multi-Domain Labels for Person Re-Identification,"['Guile Wu', 'Shaogang Gong']",https://arxiv.org/abs/2006.04150,"Deep learning has been successful for many computer vision tasks due to the availability of shared and centralised large-scale training data. However, increasing awareness of privacy concerns poses new challenges to deep learning, especially for human subject related recognition such as person re-identification (Re-ID). In this work, we solve the Re-ID problem by decentralised learning from non-shared private training data distributed at multiple user sites of independent multi-domain label spaces. We propose a novel paradigm called Federated Person Re-Identification (FedReID) to construct a generalisable global model (a central server) by simultaneously learning with multiple privacy-preserved local models (local clients). Specifically, each local client receives global model updates from the server and trains a local model using its local data independent from all the other clients. Then, the central server aggregates transferrable local model updates to construct a generalisable global feature embedding model without accessing local data so to preserve local privacy. This client-server collaborative learning process is iteratively performed under privacy control, enabling FedReID to realise decentralised learning without sharing distributed data nor collecting any centralised data. Extensive experiments on ten Re-ID benchmarks show that FedReID achieves compelling generalisation performance beyond any locally trained models without using shared training data, whilst inherently protects the privacy of each local client. This is uniquely advantageous over contemporary Re-ID methods.",共有および一元化された大規模なトレーニングデータが利用できるため、ディープラーニングは多くのコンピュータービジョンタスクで成功しています。ただし、プライバシーの懸念に対する意識の高まりは、特に個人の再識別（Re-ID）などの被験者に関連する認識の場合、ディープラーニングに新たな課題をもたらします。この作業では、独立したマルチドメインラベルスペースの複数のユーザーサイトに分散された非共有プライベートトレーニングデータからの分散学習によって、Re-ID問題を解決します。複数のプライバシー保護されたローカルモデル（ローカルクライアント）と同時に学習することにより、一般化可能なグローバルモデル（中央サーバー）を構築するために、Federated Person Re-Identification（FedReID）と呼ばれる新しいパラダイムを提案します。具体的には、各ローカルクライアントはサーバーからグローバルモデルの更新を受信し、他のすべてのクライアントから独立したローカルデータを使用してローカルモデルをトレーニングします。次に、中央サーバーは転送可能なローカルモデルの更新を集約して、ローカルデータにアクセスせずに一般化可能なグローバル機能埋め込みモデルを構築し、ローカルのプライバシーを保護します。このクライアント/サーバー共同学習プロセスは、プライバシー管理の下で繰り返し実行されるため、FedReIDは、分散データを共有したり、集中データを収集したりすることなく、分散学習を実現できます。 10個のRe-IDベンチマークでの広範な実験により、FedReIDは、共有トレーニングデータを使用せずに、ローカルでトレーニングされたモデルを超える魅力的な一般化パフォーマンスを実現すると同時に、各ローカルクライアントのプライバシーを本質的に保護することが示されています。これは、現在のRe-ID方式よりも独自に有利です。,https://d3i71xaburhd42.cloudfront.net/978342e84a67231456a2ca4a23a7829cfd2090fb/1-Figure1-1.png
Saturated Post-Hoc Optimization for Classical Planning,"['Jendrik Seipp', 'Thomas Keller', 'Malte Helmert']",,,,
Quantum Cognitively Motivated Decision Fusion for Video Sentiment Analysis,"['Dimitris Gkoumas', 'Qiuchi Li', 'Shahram Dehdashti', 'Massimo Melucci', 'Yijun Yu', 'Dawei Song']",https://arxiv.org/abs/2101.04406,"Video sentiment analysis as a decision-making process is inherently complex, involving the fusion of decisions from multiple modalities and the so-caused cognitive biases. Inspired by recent advances in quantum cognition, we show that the sentiment judgment from one modality could be incompatible with the judgment from another, i.e., the order matters and they cannot be jointly measured to produce a final decision. Thus the cognitive process exhibits “quantum-like” biases that cannot be captured by classical probability theories. Accordingly, we propose a fundamentally new, quantum cognitively motivated fusion strategy for predicting sentiment judgments. In particular, we formulate utterances as quantum superposition states of positive and negative sentiment judgments, and uni-modal classifiers as mutually incompatible observables, on a complex-valued Hilbert space with positive-operator valued measures. Experiments on two benchmarking datasets illustrate that our model significantly outperforms various existing decision level and a range of state-of-the-art content-level fusion approaches. The results also show that the concept of incompatibility allows effective handling of all combination patterns, including those extreme cases that are wrongly predicted by all uni-modal classifiers.",意思決定プロセスとしてのビデオ感情分析は本質的に複雑であり、複数のモダリティからの決定とその原因となる認知バイアスの融合が含まれます。量子認知の最近の進歩に触発されて、あるモダリティからの感情判断が別のモダリティからの判断と両立しない可能性があることを示します。つまり、順序が重要であり、それらを一緒に測定して最終決定を下すことはできません。したがって、認知プロセスは、古典的な確率論では捉えることができない量子のようなバイアスを示します。したがって、感情判断を予測するための根本的に新しい、量子認知的に動機付けられた融合戦略を提案します。特に、正と負の感情判断の量子重ね合わせ状態として発話を定式化し、正の演算子値の測定値を持つ複素数値のヒルベルト空間で、相互に互換性のない観測量として単峰性分類器を定式化します。 2つのベンチマークデータセットでの実験は、私たちのモデルがさまざまな既存の意思決定レベルおよび最先端のコンテンツレベルの融合アプローチの範囲を大幅に上回っていることを示しています。結果は、非互換性の概念により、すべてのユニモーダル分類器によって誤って予測された極端なケースを含む、すべての組み合わせパターンの効果的な処理が可能になることも示しています。,https://d3i71xaburhd42.cloudfront.net/f240d27142f26eb1faaac0e726070be53a51c27c/4-Figure1-1.png
Exacerbating Algorithmic Bias through Fairness Attacks,"['Ninareh Mehrabi', 'Muhammad Naveed', 'Fred Morstatter', 'Aram Galstyan']",https://arxiv.org/abs/2012.08723,"Algorithmic fairness has attracted significant attention in recent years, with many quantitative measures suggested for characterizing the fairness of different machine learning algorithms. Despite this interest, the robustness of those fairness measures with respect to an intentional adversarial attack has not been properly addressed. Indeed, most adversarial machine learning has focused on the impact of malicious attacks on the accuracy of the system, without any regard to the system's fairness. We propose new types of data poisoning attacks where an adversary intentionally targets the fairness of a system. Specifically, we propose two families of attacks that target fairness measures. In the anchoring attack, we skew the decision boundary by placing poisoned points near specific target points to bias the outcome. In the influence attack on fairness, we aim to maximize the covariance between the sensitive attributes and the decision outcome and affect the fairness of the model. We conduct extensive experiments that indicate the effectiveness of our proposed attacks.",アルゴリズムの公平性は近年大きな注目を集めており、さまざまな機械学習アルゴリズムの公平性を特徴づけるために多くの定量的測定が提案されています。この関心にもかかわらず、意図的な敵対的攻撃に関するこれらの公平性対策の堅牢性は適切に対処されていません。実際、ほとんどの敵対的機械学習は、システムの公平性に関係なく、システムの精度に対する悪意のある攻撃の影響に焦点を合わせてきました。攻撃者が意図的にシステムの公平性を狙う、新しいタイプのデータポイズニング攻撃を提案します。具体的には、公平性対策を狙った2つの攻撃ファミリーを提案します。アンカリング攻撃では、特定のターゲットポイントの近くにポイズニングポイントを配置して結果にバイアスをかけることにより、決定境界を歪めます。公平性への影響攻撃では、敏感な属性と決定結果の間の共分散を最大化し、モデルの公平性に影響を与えることを目指します。提案された攻撃の有効性を示す広範な実験を実施します。,https://d3i71xaburhd42.cloudfront.net/f29bb1e3f5e98a6887c2414a2036858a076a5915/3-Figure1-1.png
On the Adequacy of Untuned Warmup for Adaptive Optimization,"['Jerry Ma', 'Denis Yarats']",https://arxiv.org/abs/1910.04209,"Adaptive optimization algorithms such as Adam (Kingma & Ba, 2014) are widely used in deep learning. The stability of such algorithms is often improved with a warmup schedule for the learning rate. Motivated by the difficulty of choosing and tuning warmup schedules, Liu et al. (2019) propose automatic variance rectification of Adam's adaptive learning rate, claiming that this rectified approach (""RAdam"") surpasses the vanilla Adam algorithm and reduces the need for expensive tuning of Adam with warmup. In this work, we point out various shortcomings of this analysis. We then provide an alternative explanation for the necessity of warmup based on the magnitude of the update term, which is of greater relevance to training stability. Finally, we provide some ""rule-of-thumb"" warmup schedules, and we demonstrate that simple untuned warmup of Adam performs more-or-less identically to RAdam in typical practical settings. We conclude by suggesting that practitioners stick to linear warmup with Adam, with a sensible default being linear warmup over $2 / (1 - \beta_2)$ training iterations.",Adam（Kingma＆Ba、2014）などの適応最適化アルゴリズムは、深層学習で広く使用されています。このようなアルゴリズムの安定性は、学習率のウォームアップスケジュールによって改善されることがよくあります。ウォームアップスケジュールの選択と調整の難しさに動機付けられて、Liu etal。 （2019）この修正されたアプローチ（「RAdam」）がバニラアダムアルゴリズムを上回り、ウォームアップによるアダムの高価な調整の必要性を減らすと主張して、アダムス適応学習率の自動分散修正を提案します。この作業では、この分析のさまざまな欠点を指摘します。次に、更新期間の大きさに基づいてウォームアップの必要性について別の説明を提供します。これは、トレーニングの安定性との関連性が高くなります。最後に、いくつかの「経験則」ウォームアップスケジュールを提供し、Adamの単純な調整されていないウォームアップが、一般的な実際の設定でRAdamとほぼ同じように実行されることを示します。開業医がアダムとの線形ウォームアップに固執することを提案することによって結論を下します。賢明なデフォルトは、2 /（1 2）トレーニングの反復にわたる線形ウォームアップです。,
Resilient Multi-Agent Reinforcement Learning with Adversarial Value Decomposition,"['Thomy Phan', 'Lenz Belzner', 'Thomas Gabor', 'Andreas Sedlmeier', 'Fabian Ritz', 'Claudia Linnhoff-Popien']",,,,
Improving Adversarial Robustness via Probabilistically Compact Loss with Logit Constraints,"['Xin Li', 'Xiangrui Li', 'Deng Pan', 'Dongxiao Zhu']",,,,
"Automated Storytelling via Causal, Commonsense Plot Ordering","['Prithviraj V Ammanabrolu', 'Wesley Cheung', 'William D Broniec', 'Mark Riedl']",https://arxiv.org/abs/2009.00829,"Automated story plot generation is the task of generating a coherent sequence of plot events. Causal relations between plot events are believed to increase the perception of story and plot coherence. In this work, we introduce the concept of soft causal relations as causal relations inferred from commonsense reasoning. We demonstrate C2PO, an approach to narrative generation that operationalizes this concept through Causal, Commonsense Plot Ordering. Using human-participant protocols, we evaluate our system against baseline systems with different commonsense reasoning reasoning and inductive biases to determine the role of soft causal relations in perceived story quality. Through these studies we also probe the interplay of how changes in commonsense norms across storytelling genres affect perceptions of story quality.",自動化されたストーリープロットの生成は、プロットイベントの一貫したシーケンスを生成するタスクです。プロットイベント間の因果関係は、ストーリーの認識とプロットの一貫性を高めると考えられています。この作品では、常識的な推論から推論される因果関係として、ソフトな因果関係の概念を紹介します。 C2POは、因果的で常識的なプロットの順序付けを通じてこの概念を運用化するナラティブ生成へのアプローチを示しています。人間参加プロトコルを使用して、知覚されるストーリーの質におけるソフトな因果関係の役割を決定するために、さまざまな常識的な推論の推論と誘導バイアスを備えたベースラインシステムに対してシステムを評価します。これらの研究を通じて、ストーリーテリングのジャンル全体での常識的な規範の変化がストーリーの質の認識にどのように影響するかについての相互作用についても調査します。,https://d3i71xaburhd42.cloudfront.net/536e00c02d9596c926fb362f2ba4114b0b045ed8/3-Figure1-1.png
ESCAPED: Efficient Secure and Private Dot Product Framework for Kernel-Based Machine Learning Algorithms with Applications in Healthcare,"['Ali Burak Ünal', 'Mete Akgün', 'Nico Pfeifer']",https://arxiv.org/abs/2012.02688,"To train sophisticated machine learning models one usually needs many training samples. Especially in healthcare settings these samples can be very expensive, meaning that one institution alone usually does not have enough on its own. Merging privacy-sensitive data from different sources is usually restricted by data security and data protection measures. This can lead to approaches that reduce data quality by putting noise onto the variables (e.g., in $\epsilon$-differential privacy) or omitting certain values (e.g., for $k$-anonymity). Other measures based on cryptographic methods can lead to very time-consuming computations, which is especially problematic for larger multi-omics data. We address this problem by introducing ESCAPED, which stands for Efficient SeCure And PrivatE Dot product framework, enabling the computation of the dot product of vectors from multiple sources on a third-party, which later trains kernel-based machine learning algorithms, while neither sacrificing privacy nor adding noise. We evaluated our framework on drug resistance prediction for HIV-infected people and multi-omics dimensionality reduction and clustering problems in precision medicine. In terms of execution time, our framework significantly outperforms the best-fitting existing approaches without sacrificing the performance of the algorithm. Even though we only show the benefit for kernel-based algorithms, our framework can open up new research opportunities for further machine learning models that require the dot product of vectors from multiple sources.",高度な機械学習モデルをトレーニングするには、通常、多くのトレーニングサンプルが必要です。特に医療現場では、これらのサンプルは非常に高価になる可能性があります。つまり、通常、1つの施設だけでは十分ではありません。さまざまなソースからのプライバシーに配慮したデータのマージは、通常、データセキュリティとデータ保護対策によって制限されます。これは、変数にノイズを入れたり（たとえば、差分プライバシー）、特定の値を省略したり（たとえば、k-匿名性の場合）、データ品質を低下させるアプローチにつながる可能性があります。暗号化方式に基づく他の手段は、非常に時間のかかる計算につながる可能性があり、これは、より大きなマルチオミクスデータにとって特に問題となる。 Efficient SeCure And PrivatE Dot製品フレームワークの略であるESCAPEDを導入することでこの問題に対処し、サードパーティの複数のソースからのベクトルのドット積の計算を可能にします。これにより、後でカーネルベースの機械学習アルゴリズムをトレーニングします。プライバシーもノイズの追加も。私たちは、HIV感染者の薬剤耐性予測と、精密医療におけるマルチオミクスの次元削減とクラスタリングの問題に関するフレームワークを評価しました。実行時間に関して、私たちのフレームワークは、アルゴリズムのパフォーマンスを犠牲にすることなく、最適な既存のアプローチを大幅に上回っています。カーネルベースのアルゴリズムの利点のみを示していますが、私たちのフレームワークは、複数のソースからのベクトルの内積を必要とするさらなる機械学習モデルの新しい研究機会を開くことができます。,https://d3i71xaburhd42.cloudfront.net/8cddbe7e863a387ade384c0bb5b9e8f5d9f29326/10-Figure1-1.png
Deep Probabilistic Canonical Correlation Analysis,"['Mahdi Karami', 'Dale Schuurmans']",,,,
An Enhanced Advising Model in Teacher-Student Framework Using State Categorization,"['Daksh Anand', 'Vaibhav Gupta', 'Praveen Paruchuri', 'Balaraman Ravindran']",,,,
Automated Mechanism Design for Classification with Partial Verification,"['Hanrui Zhang', 'Yu Cheng', 'Vincent Conitzer']",,"We study the problem of automated mechanism design with partial verification, where each type can (mis)report only a restricted set of types (rather than any other type), induced by the principal’s limited verification power. We prove hardness results when the revelation principle does not necessarily hold, as well as when types have even minimally different preferences. In light of these hardness results, we focus on truthful mechanisms in the setting where all types share the same preference over outcomes, which is motivated by applications in, e.g., strategic classification. We present a number of algorithmic and structural results, including an efficient algorithm for finding optimal deterministic truthful mechanisms, which also implies a faster algorithm for finding optimal randomized truthful mechanisms via a characterization based on convexity. We then consider a more general setting, where the principal’s cost is a function of the combination of outcomes assigned to each type. In particular, we focus on the case where the cost function is submodular, and give generalizations of essentially all our results in the classical setting where the cost function is additive. Our results provide a relatively complete picture for automated mechanism design with partial verification.",部分検証を使用した自動メカニズム設計の問題を調査します。各タイプは、プリンシパルの制限された検証能力によって引き起こされた、制限されたタイプのセット（他のタイプではなく）のみを（誤って）報告できます。顕示原理が必ずしも当てはまらない場合や、タイプの好みが最小限でも異なる場合に、硬度の結果を証明します。これらの硬さの結果に照らして、すべてのタイプが結果に対して同じ優先順位を共有する設定での真実のメカニズムに焦点を当てます。これは、戦略的分類などのアプリケーションによって動機付けられます。最適な決定論的真実メカニズムを見つけるための効率的なアルゴリズムを含む、多くのアルゴリズム的および構造的結果を提示します。これは、凸性に基づく特性評価を介して最適なランダム化された真実メカニズムを見つけるためのより高速なアルゴリズムも意味します。次に、プリンシパルコストが各タイプに割り当てられた結果の組み合わせの関数である、より一般的な設定を検討します。特に、コスト関数が劣モジュラである場合に焦点を当て、コスト関数が加法的である古典的な設定で本質的にすべての結果の一般化を示します。私たちの結果は、部分的な検証を伴う自動化されたメカニズム設計の比較的完全な全体像を提供します。,https://d3i71xaburhd42.cloudfront.net/a6ada139344a996f398e1c7441e524b6a875be9c/18-Figure1-1.png
A Unified Taylor Framework for Revisiting Attribution Methods,"['Huiqi Deng', 'Na Zou', 'Mengnan Du', 'Weifu Chen', 'Guocan Feng', 'Xia Hu']",https://arxiv.org/abs/2008.09695,"Attribution methods have been developed to understand the decision making process of machine learning models, especially deep neural networks, by assigning importance scores to individual features. Existing attribution methods often built upon empirical intuitions and heuristics. There still lacks a unified framework that can provide deeper understandings of their rationales, theoretical fidelity, and limitations. To bridge the gap, we present a Taylor attribution framework to theoretically characterize the fidelity of explanations. The key idea is to decompose model behaviors into first-order, high-order independent, and high-order interactive terms, which makes clearer attribution of high-order effects and complex feature interactions. Three desired properties are proposed for Taylor attributions, i.e., low model approximation error, accurate assignment of independent and interactive effects. Moreover, several popular attribution methods are mathematically reformulated under the unified Taylor attribution framework. Our theoretical investigations indicate that these attribution methods implicitly reflect high-order terms involving complex feature interdependencies. Among these methods, Integrated Gradient is the only one satisfying the proposed three desired properties. New attribution methods are proposed based on Integrated Gradient by utilizing the Taylor framework. Experimental results show that the proposed method outperforms the existing ones in model interpretations.",個々の特徴に重要度スコアを割り当てることにより、機械学習モデル、特にディープニューラルネットワークの意思決定プロセスを理解するために、帰属方法が開発されました。多くの場合、既存の帰属方法は、経験的な直感とヒューリスティックに基づいて構築されています。それらの理論的根拠、理論的忠実度、および制限についてのより深い理解を提供できる統一されたフレームワークはまだありません。ギャップを埋めるために、説明の忠実度を理論的に特徴づけるテイラー帰属フレームワークを提示します。重要なアイデアは、モデルの動作を1次、高次の独立、および高次の対話型の用語に分解することです。これにより、高次の効果と複雑な機能の相互作用の帰属が明確になります。テイラーの帰属には、3つの望ましい特性が提案されています。つまり、モデルの近似誤差が小さいこと、独立したインタラクティブな効果の正確な割り当てです。さらに、いくつかの一般的な帰属方法は、統一されたテイラー帰属フレームワークの下で数学的に再定式化されています。私たちの理論的調査は、これらの帰属方法が複雑な機能の相互依存性を含む高次の用語を暗黙的に反映していることを示しています。これらの方法の中で、統合グラジエントは、提案された3つの望ましい特性を満たす唯一の方法です。テイラーフレームワークを利用して、統合勾配に基づいた新しい帰属方法が提案されています。実験結果は、提案された方法がモデル解釈において既存の方法よりも優れていることを示している。,https://d3i71xaburhd42.cloudfront.net/40ea10d2112d19a3da61d0f1b21f87cb18156049/3-Figure1-1.png
Learning Accurate and Interpretable Decision Rule Sets from Neural Networks,"['Litao Qiao', 'Weijia Wang', 'Bill Lin']",,,,
How RL Agents Behave When Their Actions Are Modified,"['Eric D Langlois', 'Tom Everitt']",,,,
Almost Linear Time Density Level Set Estimation via DBSCAN,"['Hossein Esfandiari', 'Vahab Mirrokni', 'Peilin Zhong']",,,,
Are Adversarial Examples Created Equal? A Learnable Weighted Minimax Risk for Robustness under Non-Uniform Attacks,"['Huimin Zeng', 'Chen Zhu', 'Tom Goldstein', 'Furong Huang']",https://arxiv.org/abs/2010.12989,"Adversarial Training is proved to be an efficient method to defend against adversarial examples, being one of the few defenses that withstand strong attacks. However, traditional defense mechanisms assume a uniform attack over the examples according to the underlying data distribution, which is apparently unrealistic as the attacker could choose to focus on more vulnerable examples. We present a weighted minimax risk optimization that defends against non-uniform attacks, achieving robustness against adversarial examples under perturbed test data distributions. Our modified risk considers importance weights of different adversarial examples and focuses adaptively on harder examples that are wrongly classified or at higher risk of being classified incorrectly. The designed risk allows the training process to learn a strong defense through optimizing the importance weights. The experiments show that our model significantly improves state-of-the-art adversarial accuracy under non-uniform attacks without a significant drop under uniform attacks.",敵対訓練は、敵対的な例から防御するための効率的な方法であることが証明されており、強力な攻撃に耐える数少ない防御の1つです。ただし、従来の防御メカニズムは、基盤となるデータ分布に従って例に対して均一な攻撃を想定しています。これは、攻撃者がより脆弱な例に焦点を当てることを選択できるため、明らかに非現実的です。不均一な攻撃から防御する加重ミニマックスリスク最適化を提示し、摂動されたテストデータ分布の下で敵対的な例に対する堅牢性を実現します。私たちの修正されたリスクは、さまざまな敵対的な例の重要度の重みを考慮し、誤って分類された、または誤って分類されるリスクが高い、より難しい例に適応的に焦点を合わせます。設計されたリスクにより、トレーニングプロセスは、重要度の重みを最適化することで強力な防御を学習できます。実験は、私たちのモデルが、均一な攻撃の下で大幅に低下することなく、不均一な攻撃の下で最先端の敵対的精度を大幅に改善することを示しています。,https://d3i71xaburhd42.cloudfront.net/eef656a1683e9ea18a40a3a858b085101a088d8d/2-Figure1-1.png
Relation-Aware Graph Attention Model with Adaptive Self-Adversarial Training,"['Xiao Qin', 'Nasrullah Sheikh', 'Berthold Reinwald', 'Lingfei Wu']",,,,
Learning by Fixing: Solving Math Word Problems with Weak Supervision,"['Yining Hong', 'Qing Li', 'Daniel Ciao', 'Siyuan Huang', 'Song-Chun Zhu']",https://arxiv.org/abs/2012.10582,"Previous neural solvers of math word problems (MWPs) are learned with full supervision and fail to generate diverse solutions. In this paper, we address this issue by introducing a weakly-supervised paradigm for learning MWPs. Our method only requires the annotations of the final answers and can generate various solutions for a single problem. To boost weaklysupervised learning, we propose a novel learning-by-fixing (LBF) framework, which corrects the misperceptions of the neural network via symbolic reasoning. Specifically, for an incorrect solution tree generated by the neural network, the fixing mechanism propagates the error from the root node to the leaf nodes and infers the most probable fix that can be executed to get the desired answer. To generate more diverse solutions, tree regularization is applied to guide the efficient shrinkage and exploration of the solution space, and a memory buffer is designed to track and save the discovered various fixes for each problem. Experimental results on the Math23K dataset show the proposed LBF framework significantly outperforms reinforcement learning baselines in weakly-supervised learning. Furthermore, it achieves comparable top-1 and much better top-3/5 answer accuracies than fully-supervised methods, demonstrating its strength in producing diverse solutions. Introduction Solving math word problems (MWPs) poses unique challenges for understanding natural-language problems and performing arithmetic reasoning over quantities with commonsense knowledge. As shown in Figure 1, a typical MWP consists of a short narrative describing a situation in the world and asking a question about an unknown quantity. To solve the MWP in Figure 1, a machine needs to extract key quantities from the text, such as “100 kilometers” and “2 hours”, and understand the relationships between them. General mathematical knowledge like “distance = velocity × time” is then used to calculate the solution. Researchers have recently focused on solving MWPs using neural-symbolic models (Ling et al. 2017; Wang, Liu, and Shi 2017; Huang et al. 2018; Wang et al. 2018; Xie and Sun 2019). These models usually consist of a neural perception module (i.e., Seq2Seq or Seq2Tree) that maps the problem text into a solution expression or tree, and a symbolic module Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Problem: A truck travels 100 kilometers in 2 hours. At this speed, if it travels for another 3.5 hours, how many kilometers will it complete for the entire journey? Answer: 275 Solution1: 100/2 ×(2 + 3.5) Solution2: 100 + 100/2×3.5 Total Distance",数学の文章題（MWP）の以前のニューラルソルバーは、完全な監督の下で学習され、多様なソリューションを生成できません。このホワイトペーパーでは、MWPを学習するための弱教師ありパラダイムを導入することでこの問題に対処します。私たちの方法は、最終的な答えの注釈のみを必要とし、単一の問題に対してさまざまな解決策を生成できます。弱く監視された学習を後押しするために、シンボリック推論を介してニューラルネットワークの誤解を修正する新しい固定学習（LBF）フレームワークを提案します。具体的には、ニューラルネットワークによって生成された誤ったソリューションツリーの場合、修正メカニズムはエラーをルートノードからリーフノードに伝播し、目的の答えを得るために実行できる最も可能性の高い修正を推測します。より多様なソリューションを生成するために、ツリーの正則化を適用してソリューションスペースの効率的な縮小と探索をガイドし、メモリバッファーを設計して、問題ごとに検出されたさまざまな修正を追跡および保存します。 Math23Kデータセットの実験結果は、提案されたLBFフレームワークが、弱教師あり学習の強化学習ベースラインを大幅に上回っていることを示しています。さらに、完全に監視された方法よりも同等のトップ1およびはるかに優れたトップ3/5の回答精度を達成し、多様なソリューションを生成する上での強みを示しています。はじめに数学の文章題（MWP）を解決することは、自然言語の問題を理解し、常識的な知識を持つ量に対して算術推論を実行するための固有の課題をもたらします。図1に示すように、典型的なMWPは、世界の状況を説明し、未知の量について質問する短い説明で構成されています。図1のMWPを解決するには、マシンはテキストから100 kmや2時間などの重要な量を抽出し、それらの間の関係を理解する必要があります。次に、距離=速度時間などの一般的な数学的知識を使用して解を計算します。研究者は最近、神経記号モデルを使用してMWPを解決することに焦点を当てています（Ling et al.2017; Wang、Liu、and Shi 2017; Huang et al.2018; Wang et al.2018; Xie and Sun 2019）。これらのモデルは通常、問題のテキストを解の式またはツリーにマッピングする神経知覚モジュール（つまり、Seq2SeqまたはSeq2Tree）と、シンボリックモジュールCopyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）で構成されます。全著作権所有。問題：トラックが2時間で100キロメートル移動します。この速度でさらに3.5時間移動すると、移動全体で何キロメートル完了しますか？回答：275ソリューション1：100/2（2 + 3.5）ソリューション2：100 + 100 /23.5合計距離,https://d3i71xaburhd42.cloudfront.net/6514b9e969d1dc5feca7a60289470b5f1c024de7/1-Figure1-1.png
Accelerating Continuous Normalizing Flow with Trajectory Polynomial Regularization,"['Han-Hsien Huang', 'Mi-Yen Yeh']",https://arxiv.org/abs/2012.04228,"In this paper, we propose an approach to effectively accelerating the computation of continuous normalizing flow (CNF), which has been proven to be a powerful tool for the tasks such as variational inference and density estimation. The training time cost of CNF can be extremely high because the required number of function evaluations (NFE) for solving corresponding ordinary differential equations (ODE) is very large. We think that the high NFE results from large truncation errors of solving ODEs. To address the problem, we propose to add a regularization. The regularization penalizes the difference between the trajectory of the ODE and its fitted polynomial regression. The trajectory of ODE will approximate a polynomial function, and thus the truncation error will be smaller. Furthermore, we provide two proofs and claim that the additional regularization does not harm training quality. Experimental results show that our proposed method can result in 42.3% to 71.3% reduction of NFE on the task of density estimation, and 19.3% to 32.1% reduction of NFE on variational auto-encoder, while the testing losses are not affected at all.",本論文では、変分推論や密度推定などのタスクのための強力なツールであることが証明されている連続正規化フロー（CNF）の計算を効果的に加速するアプローチを提案します。対応する常微分方程式（ODE）を解くために必要な関数評価（NFE）の数が非常に多いため、CNFのトレーニング時間コストは非常に高くなる可能性があります。高いNFEは、ODEを解く際の大きな切り捨て誤差に起因すると考えられます。この問題に対処するために、正則化を追加することを提案します。正則化は、ODEの軌道とその近似多項式回帰の違いにペナルティを課します。 ODEの軌道は多項式関数に近似するため、打ち切り誤差は小さくなります。さらに、2つの証明を提供し、追加の正則化がトレーニングの品質に悪影響を与えないと主張します。実験結果は、提案した方法が42.3になる可能性があることを示しています。,https://d3i71xaburhd42.cloudfront.net/7b1b9757c0357a4e1f164fdeed82048e425ca903/4-Figure1-1.png
Personalized Cross-Silo Federated Learning on Non-IID Data,"['Yutao Huang', 'Lingyang Chu', 'Zirui Zhou', 'Lanjun Wang', 'Jiangchuan Liu', 'Jian Pei', 'Yong Zhang']",https://arxiv.org/abs/2007.03797,"Non-IID data present a tough challenge for federated learning. In this paper, we explore a novel idea of facilitating pairwise collaborations between clients with similar data. We propose FedAMP, a new method employing federated attentive message passing to facilitate similar clients to collaborate more. We establish the convergence of FedAMP for both convex and non-convex models, and propose a heuristic method to further improve the performance of FedAMP when clients adopt deep neural networks as personalized models. Our extensive experiments on benchmark data sets demonstrate the superior performance of the proposed methods.",非IIDデータは、連合学習にとって難しい課題です。このホワイトペーパーでは、同様のデータを持つクライアント間のペアワイズコラボレーションを促進するという斬新なアイデアを探ります。 FedAMPを提案します。これは、フェデレーションされた注意深いメッセージパッシングを使用して、同様のクライアントがより多くのコラボレーションを容易にする新しい方法です。凸型モデルと非凸型モデルの両方に対してFedAMPの収束を確立し、クライアントがパーソナライズされたモデルとしてディープニューラルネットワークを採用する場合にFedAMPのパフォーマンスをさらに向上させるヒューリスティック手法を提案します。ベンチマークデータセットに関する広範な実験は、提案された方法の優れたパフォーマンスを示しています。,
Fair and Efficient Online Allocations with Normalized Valuations,"['Xizhi Tan', 'Vasilis Gkatzelis', 'Alexandros Psomas']",,,,
Group Fairness by Probabilistic Modeling with Latent Fair Decisions,"['YooJung Choi', 'Meihua Dang', 'Guy Van den Broeck']",https://arxiv.org/abs/2009.09031,"Machine learning systems are increasingly being used to make impactful decisions such as loan applications and criminal justice risk assessments, and as such, ensuring fairness of these systems is critical. This is often challenging as the labels in the data are biased. This paper studies learning fair probability distributions from biased data by explicitly modeling a latent variable that represents a hidden, unbiased label. In particular, we aim to achieve demographic parity by enforcing certain independencies in the learned model. We also show that group fairness guarantees are meaningful only if the distribution used to provide those guarantees indeed captures the real-world data. In order to closely model the data distribution, we employ probabilistic circuits, an expressive and tractable probabilistic model, and propose an algorithm to learn them from incomplete data. We evaluate our approach on a synthetic dataset in which observed labels indeed come from fair labels but with added bias, and demonstrate that the fair labels are successfully retrieved. Moreover, we show on real-world datasets that our approach not only is a better model than existing methods of how the data was generated but also achieves competitive accuracy.",機械学習システムは、ローンの申し込みや刑事司法のリスク評価などの影響力のある意思決定にますます使用されているため、これらのシステムの公平性を確保することが重要です。データ内のラベルに偏りがあるため、これはしばしば困難です。この論文は、隠れた偏りのないラベルを表す潜在変数を明示的にモデル化することにより、偏ったデータから公正な確率分布を学習することを研究しています。特に、学習したモデルに特定の独立性を適用することにより、人口統計上の同等性を達成することを目指しています。また、グループの公平性の保証は、それらの保証を提供するために使用される分布が実際に実際のデータをキャプチャする場合にのみ意味があることも示します。データ分布を厳密にモデル化するために、表現的で扱いやすい確率モデルである確率回路を採用し、不完全なデータからそれらを学習するアルゴリズムを提案します。観測されたラベルが実際に公正なラベルからのものであるがバイアスが追加されている合成データセットでアプローチを評価し、公正なラベルが正常に取得されることを示します。さらに、実際のデータセットで、私たちのアプローチがデータの生成方法の既存の方法よりも優れたモデルであるだけでなく、競争力のある精度を達成していることを示します。,https://d3i71xaburhd42.cloudfront.net/6cb09bd0897182958eea764190daf8a80ab7e47d/3-Figure1-1.png
Improved Worst-Case Regret Bounds for Randomized Least-Squares Value Iteration,"['Priyank Agrawal', 'Jinglin Chen', 'Nan Jiang']",https://arxiv.org/abs/2010.12163,"This paper studies regret minimization with randomized value functions in reinforcement learning. In tabular finite-horizon Markov Decision Processes, we introduce a clipping variant of one classical Thompson Sampling (TS)-like algorithm, randomized least-squares value iteration (RLSVI). We analyze the algorithm using a novel intertwined regret decomposition. Our $\tilde{\mathrm{O}}(H^2S\sqrt{AT})$ high-probability worst-case regret bound improves the previous sharpest worst-case regret bounds for RLSVI and matches the existing state-of-the-art worst-case TS-based regret bounds.",この論文は、強化学習におけるランダム化された値関数による後悔の最小化を研究します。表形式の有限ホライズンマルコフ決定過程では、1つの古典的なトンプソンサンプリング（TS）のようなアルゴリズム、ランダム化最小二乗値反復（RLSVI）のクリッピングバリアントを紹介します。新規の絡み合った後悔分解を使用してアルゴリズムを分析します。 $ \ tilde {\ mathrm {O}}（H ^ 2S \ sqrt {AT}）$の高確率の最悪の場合の後悔の限界は、RLSVIの以前の最も鋭い最悪の場合の後悔の限界を改善し、既存の状態と一致します。 -アート最悪の場合のTSベースの後悔の限界。,
Incentive-Aware PAC Learning,"['Hanrui Zhang', 'Vincent Conitzer']",,"We study PAC learning in the presence of strategic manipulation, where data points may modify their features in certain predefined ways in order to receive a better outcome. We show that the vanilla ERM principle fails to achieve any nontrivial guarantee in this context. Instead, we propose an incentive-aware version of the ERM principle which has asymptotically optimal sample complexity. We then focus our attention on incentive-compatible classifiers, which provably prevent any kind of strategic manipulation. We give a sample complexity bound that is, curiously, independent of the hypothesis class, for the ERM principle restricted to incentive-compatible classifiers. This suggests that incentive compatibility alone can act as an effective means of regularization. We further show that it is without loss of generality to consider only incentive-compatible classifiers when opportunities for strategic manipulation satisfy a transitivity condition. As a consequence, in such cases, our hypothesis-classindependent sample complexity bound applies even without incentive compatibility. Our results set the foundations of incentive-aware PAC learning.",戦略的操作の存在下でPAC学習を研究します。この場合、データポイントは、より良い結果を受け取るために、特定の事前定義された方法で機能を変更できます。バニラERMの原則は、このコンテキストで重要な保証を達成できないことを示します。代わりに、漸近的に最適なサンプルの複雑さを持つERM原理のインセンティブ対応バージョンを提案します。次に、インセンティブと互換性のある分類子に注目します。これにより、あらゆる種類の戦略的操作が確実に防止されます。インセンティブ互換の分類器に制限されたERM原理について、不思議なことに、仮説クラスに依存しないサンプルの複雑さの限界を示します。これは、インセンティブの互換性だけが正則化の効果的な手段として機能できることを示唆しています。さらに、戦略的操作の機会が推移性条件を満たす場合に、インセンティブと互換性のある分類子のみを考慮することは一般性を失うことはないことを示します。結果として、そのような場合、インセンティブの互換性がなくても、仮説クラスに依存しないサンプルの複雑さの限界が適用されます。私たちの結果は、インセンティブを意識したPAC学習の基礎を築きました。,
Learning Intuitive Physics with Multimodal Generative Models,"['Sahand Rezaei-Shoshtari', 'Francois R Hogan', 'Michael Jenkin', 'David Meger', 'Gregory Dudek']",,,,
Holistic Multi-View Building Analysis in the Wild with Projection Pooling,"['Zbigniew Bogdan Wojna', 'Krzysztof Maziarz', 'Lukasz Jocz', 'Robert Paluba', 'Robert Kozikowski', 'Iason Kokkinos']",,,,
Asking the Right Questions: Learning Interpretable Action Models through Query Answering,"['Pulkit Verma', 'Shashank Rao Marpally', 'Siddharth Srivastava']",,,,
Model-Sharing Games: Analyzing Federated Learning under Voluntary Participation,"['Kathleen Donahue', 'Jon Kleinberg']",,,,
Variational Disentanglement for Rare Event Modeling,"['Zidi Xiu', 'Chenyang Tao', 'Michael Gao', 'Connor Davis', 'Benjamin Goldstein', 'Ricardo Henao']",https://arxiv.org/abs/2009.08541,"Combining the increasing availability and abundance of healthcare data and the current advances in machine learning methods have created renewed opportunities to improve clinical decision support systems. However, in healthcare risk prediction applications, the proportion of cases with the condition (label) of interest is often very low relative to the available sample size. Though very prevalent in healthcare, such imbalanced classification settings are also common and challenging in many other scenarios. So motivated, we propose a variational disentanglement approach to semi-parametrically learn from rare events in heavily imbalanced classification problems. Specifically, we leverage the imposed extreme-distribution behavior on a latent space to extract information from low-prevalence events, and develop a robust prediction arm that joins the merits of the generalized additive model and isotonic neural nets. Results on synthetic studies and diverse real-world datasets, including mortality prediction on a COVID-19 cohort, demonstrate that the proposed approach outperforms existing alternatives.",医療データの可用性と豊富さの増加と機械学習手法の現在の進歩を組み合わせることで、臨床意思決定支援システムを改善する新たな機会が生まれました。ただし、医療リスク予測アプリケーションでは、対象の状態（ラベル）を持つケースの割合は、利用可能なサンプルサイズに比べて非常に低いことがよくあります。ヘルスケアでは非常に普及していますが、このような不均衡な分類設定は、他の多くのシナリオでも一般的で困難です。非常にやる気があり、非常に不均衡な分類問題のまれなイベントからセミパラメトリックに学習するための変分解きほぐしアプローチを提案します。具体的には、潜在空間に課せられた極値分布の動作を活用して、低有病率のイベントから情報を抽出し、一般化された加法モデルと等張ニューラルネットのメリットを結合する堅牢な予測アームを開発します。 COVID-19コホートでの死亡率予測を含む、総合的な研究と多様な実世界のデータセットに関する結果は、提案されたアプローチが既存の代替案よりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/a821fd83751217fa7251435aeb279a90142bb1b9/4-Figure1-1.png
Data-Free Knowledge Distillation with Soft Targeted Transfer Set Synthesis,['Zi Wang'],,,,
Fast and Scalable Adversarial Training of Kernel SVM via Doubly Stochastic Gradients,"['Huimin Wu', 'Zhengmian Hu', 'Bin Gu']",,,,
Domain Adaptation in Reinforcement Learning via Latent Unified State Representation,"['Jinwei Xing', 'Takashi Nagata', 'Kexin Chen', 'Xinyun Zou', 'Emre Neftci', 'Jeffrey Prof. Krichmar']",https://arxiv.org/abs/2102.05714,"Despite the recent success of deep reinforcement learning (RL), domain adaptation remains an open problem. Although the generalization ability of RL agents is critical for the realworld applicability of Deep RL, zero-shot policy transfer is still a challenging problem since even minor visual changes could make the trained agent completely fail in the new task. To address this issue, we propose a two-stage RL agent that first learns a latent unified state representation (LUSR) which is consistent across multiple domains in the first stage, and then do RL training in one source domain based on LUSR in the second stage. The cross-domain consistency of LUSR allows the policy acquired from the source domain to generalize to other target domains without extra training. We first demonstrate our approach in variants of CarRacing games with customized manipulations, and then verify it in CARLA, an autonomous driving simulator with more complex and realistic visual observations. Our results show that this approach can achieve state-of-the-art domain adaptation performance in related RL tasks and outperforms prior approaches based on latent-representation based RL and image-to-image",深層強化学習（RL）の最近の成功にもかかわらず、ドメイン適応は未解決の問題のままです。 RLエージェントの一般化機能は、Deep RLの実際の適用性にとって重要ですが、わずかな視覚的変更でもトレーニング済みのエージェントが新しいタスクで完全に失敗する可能性があるため、ゼロショットポリシー転送は依然として困難な問題です。この問題に対処するために、最初の段階で複数のドメイン間で一貫性のある潜在的な統一状態表現（LUSR）を最初に学習し、次に2番目の段階でLUSRに基づいて1つのソースドメインでRLトレーニングを行う2段階のRLエージェントを提案します。ステージ。 LUSRのクロスドメイン整合性により、ソースドメインから取得したポリシーを、追加のトレーニングなしで他のターゲットドメインに一般化できます。まず、カスタマイズされた操作を使用したCarRacingゲームのバリエーションでアプローチを示し、次に、より複雑で現実的な視覚的観察を備えた自動運転シミュレーターであるCARLAで検証します。私たちの結果は、このアプローチが関連するRLタスクで最先端のドメイン適応パフォーマンスを達成でき、潜在表現ベースのRLと画像間に基づく以前のアプローチよりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/29a771c76eb0d4eea2a6cdd56076333588be9e7e/3-Figure1-1.png
"Order Regularization on Ordinal Loss for Head Pose, Age and Gaze Estimation","['Hui Zhang', 'Tianchu Guo', 'Jae-Joon Han', 'ByungIn Yoo', 'Yongchao Liu', 'Youngjun Kwak']",,,,
Testing Independence between Linear Combinations for Causal Discovery,"['Hao Zhang', 'Kun Zhang', 'Shuigeng Zhou', 'Jihong Guan', 'Ji Zhang']",,,,
Efficient Querying for Cooperative Probabilistic Commitments,"['Qi Zhang', 'Edmund Durfee', 'Satinder Singh']",https://arxiv.org/abs/2012.07195,"Multiagent systems can use commitments as the core of a general coordination infrastructure, supporting both cooperative and non-cooperative interactions. Agents whose objectives are aligned, and where one agent can help another achieve greater reward by sacrificing some of its own reward, should choose a cooperative commitment to maximize their joint reward. We present a solution to the problem of how cooperative agents can efficiently find an (approximately) optimal commitment by querying about carefully-selected commitment choices. We prove structural properties of the agents' values as functions of the parameters of the commitment specification, and develop a greedy method for composing a query with provable approximation bounds, which we empirically show can find nearly optimal commitments in a fraction of the time methods that lack our insights require.",マルチエージェントシステムは、コミットメントを一般的な調整インフラストラクチャのコアとして使用し、協調的および非協調的な相互作用の両方をサポートできます。目的が一致していて、あるエージェントが自分の報酬の一部を犠牲にすることで別のエージェントがより大きな報酬を達成するのを助けることができるエージェントは、共同の報酬を最大化するために協力的なコミットメントを選択する必要があります。慎重に選択されたコミットメントの選択肢についてクエリを実行することにより、協調エージェントが（ほぼ）最適なコミットメントを効率的に見つける方法の問題に対する解決策を提示します。コミットメント仕様のパラメーターの関数としてエージェント値の構造特性を証明し、証明可能な近似範囲を使用してクエリを作成するための欲張り法を開発します。私たちの洞察が必要です。,https://d3i71xaburhd42.cloudfront.net/d463e84df408027719b643e954cd08f85239685c/6-Figure1-1.png
Bidirectional RNN Based Few Shot Learning for 3D Medical Image Segmentation,"['Soopil Kim', 'Sion An', 'Philip Chikontwe', 'Sanghyun Park']",https://arxiv.org/abs/2011.09608,"Segmentation of organs of interest in 3D medical images is necessary for accurate diagnosis and longitudinal studies. Though recent advances using deep learning have shown success for many segmentation tasks, large datasets are required for high performance and the annotation process is both time consuming and labor intensive. In this paper, we propose a 3D few shot segmentation framework for accurate organ segmentation using limited training samples of the target organ annotation. To achieve this, a U-Net like network is designed to predict segmentation by learning the relationship between 2D slices of support data and a query image, including a bidirectional gated recurrent unit (GRU) that learns consistency of encoded features between adjacent slices. Also, we introduce a transfer learning method to adapt the characteristics of the target image and organ by updating the model before testing with arbitrary support and query data sampled from the support data. We evaluate our proposed model using three 3D CT datasets with annotations of different organs. Our model yielded significantly improved performance over state-of-the-art few shot segmentation models and was comparable to a fully supervised model trained with more target training data.",正確な診断と縦断的研究には、3D医用画像で関心のある臓器のセグメンテーションが必要です。ディープラーニングを使用した最近の進歩により、多くのセグメンテーションタスクで成功が示されていますが、高性能には大規模なデータセットが必要であり、注釈プロセスは時間と労力の両方を伴います。この論文では、ターゲット臓器アノテーションの限られたトレーニングサンプルを使用して正確な臓器セグメンテーションのための3D数ショットセグメンテーションフレームワークを提案します。これを実現するために、U-Netのようなネットワークは、サポートデータの2Dスライスとクエリ画像の関係を学習することでセグメンテーションを予測するように設計されています。これには、隣接するスライス間のエンコードされた特徴の一貫性を学習する双方向ゲート付き回帰ユニット（GRU）が含まれます。また、任意のサポートでテストする前にモデルを更新し、サポートデータからサンプリングしたクエリデータを使用して、ターゲット画像と臓器の特性を適応させる転移学習法を紹介します。異なる臓器の注釈付きの3つの3DCTデータセットを使用して、提案されたモデルを評価します。私たちのモデルは、最先端の数ショットセグメンテーションモデルよりも大幅に改善されたパフォーマンスをもたらし、より多くのターゲットトレーニングデータでトレーニングされた完全に監視されたモデルに匹敵しました。,https://d3i71xaburhd42.cloudfront.net/149018b4faf1aa1f3250b6821a51cc1a9c2c7a53/3-Figure1-1.png
Task Cooperation for Semi-Supervised Few-Shot Learning,"['Han-Jia Ye', 'Xin-Chun Li', 'De-Chuan Zhan']",,,,
Learning To Sit: Synthesizing Human-Chair Interactions via Hierarchical Control,"['Yu-Wei Chao', 'Jimei Yang', 'Weifeng Chen', 'Jia Deng']",https://arxiv.org/abs/1908.07423,"Recent progress on physics-based character animation has shown impressive breakthroughs on human motion synthesis, through the imitation of motion capture data via deep reinforcement learning. However, results have mostly been demonstrated on imitating a single distinct motion pattern, and do not generalize to interactive tasks that require flexible motion patterns due to varying human-object spatial configurations. In this paper, we focus on one class of interactive task---sitting onto a chair. We propose a hierarchical reinforcement learning framework which relies on a collection of subtask controllers trained to imitate simple, reusable mocap motions, and a meta controller trained to execute the subtasks properly to complete the main task. We experimentally demonstrate the strength of our approach over different single level and hierarchical baselines. We also show that our approach can be applied to motion prediction given an image input. A video highlight can be found at this https URL.",物理ベースのキャラクターアニメーションの最近の進歩は、深層強化学習によるモーションキャプチャデータの模倣を通じて、人間のモーション合成に目覚ましい進歩をもたらしました。ただし、結果は主に単一の異なるモーションパターンを模倣することで実証されており、人間とオブジェクトの空間構成が異なるために柔軟なモーションパターンを必要とするインタラクティブなタスクに一般化されていません。このホワイトペーパーでは、椅子に座っているインタラクティブなタスクの1つのクラスに焦点を当てます。シンプルで再利用可能なモーションキャプチャモーションを模倣するようにトレーニングされたサブタスクコントローラーのコレクションと、サブタスクを適切に実行してメインタスクを完了するようにトレーニングされたメタコントローラーに依存する階層型強化学習フレームワークを提案します。さまざまな単一レベルおよび階層ベースラインでのアプローチの強さを実験的に示します。また、画像入力が与えられた場合の動き予測に私たちのアプローチを適用できることも示します。ビデオのハイライトは、このhttpsURLにあります。,https://d3i71xaburhd42.cloudfront.net/ed580995e4a51424d8f1a20f5b64200fe227c2cd/1-Figure1-1.png
Online Optimal Control with Affine Constraints,"['Yingying Li', 'Subhro Das', 'Na Li']",https://arxiv.org/abs/2010.04891,"This paper considers online optimal control with affine constraints on the states and actions under linear dynamics with random disturbances. We consider convex stage cost functions that change adversarially. Besides, we consider time-invariant and known system dynamics and constraints. To solve this problem, we propose Online Gradient Descent with Buffer Zone (OGD-BZ). Theoretically, we show that OGD-BZ can guarantee the system to satisfy all the constraints despite any realization of the disturbances under proper parameters. Further, we investigate the policy regret of OGD-BZ, which compares OGD-BZ's performance with the performance of the optimal linear policy in hindsight. We show that OGD-BZ can achieve $\tilde O(\sqrt T)$ policy regret under proper parameters, where $\tilde O(\cdot)$ absorbs logarithmic terms of $T$.",この論文では、ランダムな外乱を伴う線形ダイナミクスの下での状態とアクションに対するアフィン制約を伴うオンライン最適制御について考察します。逆に変化する凸ステージコスト関数を検討します。さらに、時不変で既知のシステムダイナミクスと制約を考慮します。この問題を解決するために、バッファゾーンを使用したオンライン最急降下法（OGD-BZ）を提案します。理論的には、OGD-BZは、適切なパラメーターの下で外乱が発生した場合でも、システムがすべての制約を満たすことを保証できることを示しています。さらに、OGD-BZのパフォーマンスを後知恵で最適な線形ポリシーのパフォーマンスと比較するOGD-BZのポリシー後悔を調査します。 OGD-BZが適切なパラメータの下で$ \ tilde O（\ sqrt T）$ポリシー後悔を達成できることを示します。ここで、O（）はTの対数項を吸収します。,https://d3i71xaburhd42.cloudfront.net/d31c2992b8a56625dd3684c6728cda224cad40d1/12-Figure1-1.png
"Uncertainty-Aware Policy Optimization: A Robust, Adaptive Trust Region Approach","['James Queeney', 'Ioannis Paschalidis', 'Christos G. Cassandras']",https://arxiv.org/abs/2012.10791,"In order for reinforcement learning techniques to be useful in real-world decision making processes, they must be able to produce robust performance from limited data. Deep policy optimization methods have achieved impressive results on complex tasks, but their real-world adoption remains limited because they often require significant amounts of data to succeed. When combined with small sample sizes, these methods can result in unstable learning due to their reliance on high-dimensional sample-based estimates. In this work, we develop techniques to control the uncertainty introduced by these estimates. We leverage these techniques to propose a deep policy optimization approach designed to produce stable performance even when data is scarce. The resulting algorithm, Uncertainty-Aware Trust Region Policy Optimization, generates robust policy updates that adapt to the level of uncertainty present throughout the learning process.",強化学習手法が実際の意思決定プロセスで役立つためには、限られたデータから堅牢なパフォーマンスを生み出すことができなければなりません。深いポリシー最適化手法は、複雑なタスクで印象的な結果を達成しましたが、成功するには大量のデータが必要になることが多いため、実際の採用は限られています。これらの方法を小さなサンプルサイズと組み合わせると、高次元のサンプルベースの推定に依存するため、学習が不安定になる可能性があります。この作業では、これらの推定値によってもたらされる不確実性を制御するための手法を開発します。これらの手法を活用して、データが不足している場合でも安定したパフォーマンスを実現するように設計された、詳細なポリシー最適化アプローチを提案します。結果として得られるアルゴリズムである不確実性を意識した信頼領域ポリシーの最適化は、学習プロセス全体に存在する不確実性のレベルに適応する堅牢なポリシー更新を生成します。,https://d3i71xaburhd42.cloudfront.net/b29ef3794829d56ce139a8d02aa88c307d045ed3/2-Figure1-1.png
Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences,"['Andis Draguns', 'Emīls Ozoliņš', 'Agris Šostaks', 'Matīss Apinis', 'Karlis Freivalds']",https://arxiv.org/abs/2004.04662,"Attention is a commonly used mechanism in sequence processing, but it is of O(n^2) complexity which prevents its application to long sequences. The recently introduced Neural Shuffle-Exchange network offers a computation-efficient alternative, enabling the modelling of long-range dependencies in O(n log n) time. The model, however, is quite complex, involving a sophisticated gating mechanism derived from Gated Recurrent Unit. In this paper, we present a simple and lightweight variant of the Shuffle-Exchange network, which is based on a residual network employing GELU and Layer Normalization. The proposed architecture not only scales to longer sequences but also converges faster and provides better accuracy. It surpasses Shuffle-Exchange network on the LAMBADA language modelling task and achieves state-of-the-art performance on the MusicNet dataset for music transcription while using significantly fewer parameters. We show how to combine Shuffle-Exchange network with convolutional layers establishing it as a useful building block in long sequence processing applications.",注意はシーケンス処理で一般的に使用されるメカニズムですが、O（n ^ 2）の複雑さのため、長いシーケンスへの適用が妨げられます。最近導入されたニューラルシャッフル-Exchangeネットワークは、計算効率の高い代替手段を提供し、O（n log n）時間での長距離依存関係のモデリングを可能にします。ただし、モデルは非常に複雑で、ゲート付き回帰ユニットから派生した高度なゲートメカニズムが含まれます。このホワイトペーパーでは、GELUとレイヤー正規化を採用した残余ネットワークに基づくShuffle-Exchangeネットワークのシンプルで軽量なバリアントを紹介します。提案されたアーキテクチャは、より長いシーケンスにスケーリングするだけでなく、より速く収束し、より良い精度を提供します。 LAMBADA言語モデリングタスクでShuffle-Exchangeネットワークを上回り、使用するパラメーターを大幅に減らしながら、音楽トランスクリプション用のMusicNetデータセットで最先端のパフォーマンスを実現します。 Shuffle-Exchangeネットワークを畳み込み層と組み合わせて、長いシーケンス処理アプリケーションで有用なビルディングブロックとして確立する方法を示します。,https://d3i71xaburhd42.cloudfront.net/dec1a49f4368fe7ef13cc55211c4e2379a6322ee/2-Figure1-1.png
Multidimensional Uncertainty-Aware Evidential Neural Networks,"['Yibo Hu', 'Yuzhe Ou', 'Xujiang Zhao', 'Jin-Hee Cho', 'Feng Chen']",,,,
Robust Contextual Bandits via Bootstrapping,"['Qiao Tang', 'Hong Xie', 'Yunni Xia', 'Jia Lee', 'Qingsheng Zhu']",,,,
Reinforced Imitative Graph Representation Learning for Mobile User Profiling: An Adversarial Training Perspective,"['Dongjie Wang', 'Pengyang Wang', 'Kunpeng Liu', 'Yuanchun Zhou', 'Charles E Hughes', 'Yanjie Fu']",,,,
Winning Lottery Tickets in Deep Generative Models,"['Neha Mukund Kalibhat', 'Yogesh Balaji', 'Soheil Feizi']",,,,
Learning Flexibly Distributional Representation for Low-Quality 3D Face Recognition,"['Zihui Zhang', 'Cuican Yu', 'Shuang Xu', 'HUIBIN LI']",,,,
Learning to Recommend from Sparse Data via Generative User Feedback,['Wenlin Wang'],https://arxiv.org/abs/1910.12735,"Traditional collaborative filtering (CF) based recommender systems tend to perform poorly when the user-item interactions/ratings are highly scarce. To address this, we propose a learning framework that improves collaborative filtering with a synthetic feedback loop (CF-SFL) to simulate the user feedback. The proposed framework consists of a""recommender""and a""virtual user"". The""recommender""is formulated as a CF model, recommending items according to observed user preference. The""virtual user""estimates rewards from the recommended items and generates a \emph{feedback} in addition to the observed user preference. The""recommender""connected with the""virtual user""constructs a closed loop, that recommends users with items and imitates the \emph{unobserved} feedback of the users to the recommended items. The synthetic feedback is used to augment the observed user preference and improve recommendation results. Theoretically, such model design can be interpreted as inverse reinforcement learning, which can be learned effectively via rollout (simulation). Experimental results show that the proposed framework is able to enrich the learning of user preference and boost the performance of existing collaborative filtering methods on multiple datasets.",従来の協調フィルタリング（CF）ベースのレコメンダーシステムは、ユーザーとアイテムの相互作用/評価が非常に少ない場合、パフォーマンスが低下する傾向があります。これに対処するために、ユーザーフィードバックをシミュレートするための合成フィードバックループ（CF-SFL）を使用した協調フィルタリングを改善する学習フレームワークを提案します。提案されたフレームワークは、「推奨者」と「仮想ユーザー」で構成されています。 「レコメンダー」はCFモデルとして策定され、観察されたユーザーの好みに応じてアイテムを推奨します。 「仮想ユーザー」は、推奨されるアイテムから報酬を見積もり、観察されたユーザーの好みに加えてフィードバックを生成します。 「仮想ユーザー」に接続された「推奨者」は、閉ループを構築します。これは、アイテムを持つユーザーを推奨し、推奨されたアイテムに対するユーザーの観察されないフィードバックを模倣します。合成フィードバックは、観察されたユーザーの好みを補強し、推奨結果を改善するために使用されます。理論的には、このようなモデル設計は逆強化学習として解釈でき、ロールアウト（シミュレーション）を介して効果的に学習できます。実験結果は、提案されたフレームワークがユーザーの好みの学習を充実させ、複数のデータセットに対する既存の協調フィルタリング方法のパフォーマンスを向上させることができることを示しています。,
Deep Recurrent Belief Propagation Network for POMDPs,"['Yuhui Wang', 'Xiaoyang Tan']",,,,
Strategy and Benchmark for Converting Deep Q-Networks to Event-Driven Spiking Neural Networks,"['Weihao Tan', 'Devdhar Patel', 'Robert Kozma']",https://arxiv.org/abs/2009.14456,"Spiking neural networks (SNNs) have great potential for energy-efficient implementation of Deep Neural Networks (DNNs) on dedicated neuromorphic hardware. Recent studies demonstrated competitive performance of SNNs compared with DNNs on image classification tasks, including CIFAR-10 and ImageNet data. The present work focuses on using SNNs in combination with deep reinforcement learning in ATARI games, which involves additional complexity as compared to image classification. We review the theory of converting DNNs to SNNs and extending the conversion to Deep Q-Networks (DQNs). We propose a robust representation of the firing rate to reduce the error during the conversion process. In addition, we introduce a new metric to evaluate the conversion process by comparing the decisions made by the DQN and SNN, respectively. We also analyze how the simulation time and parameter normalization influence the performance of converted SNNs. We achieve competitive scores on 17 top-performing Atari games. To the best of our knowledge, our work is the first to achieve state-of-the-art performance on multiple Atari games with SNNs. Our work serves as a benchmark for the conversion of DQNs to SNNs and paves the way for further research on solving reinforcement learning tasks with SNNs.",スパイキングニューラルネットワーク（SNN）は、専用のニューロモーフィックハードウェア上にディープニューラルネットワーク（DNN）をエネルギー効率よく実装する大きな可能性を秘めています。最近の研究では、CIFAR-10やImageNetデータなどの画像分類タスクでDNNと比較してSNNの競争力のあるパフォーマンスが実証されました。現在の作業は、画像分類と比較して追加の複雑さを伴うATARIゲームでの深層強化学習と組み合わせたSNNの使用に焦点を当てています。 DNNをSNNに変換し、変換をDeep Q-Networks（DQN）に拡張する理論を確認します。変換プロセス中のエラーを減らすために、発火率のロバストな表現を提案します。さらに、DQNとSNNがそれぞれ行った決定を比較することにより、変換プロセスを評価するための新しいメトリックを導入します。また、シミュレーション時間とパラメーターの正規化が変換されたSNNのパフォーマンスにどのように影響するかを分析します。 17のトップパフォーマンスのAtariゲームで競争力のあるスコアを達成しています。私たちの知る限り、私たちの仕事は、SNNを使用した複数のAtariゲームで最先端のパフォーマンスを実現した最初の作品です。私たちの仕事は、DQNをSNNに変換するためのベンチマークとして機能し、SNNを使用した強化学習タスクの解決に関するさらなる研究への道を開きます。,https://d3i71xaburhd42.cloudfront.net/6a106a837c87c73d1fac65b095a27e13d17b4476/6-Figure1-1.png
Synchronous Dynamical Systems on Directed Acyclic Graphs: Complexity and Algorithms,"['Daniel J Rosenkrantz', 'Madhav Marathe', 'S S Ravi', 'Richard Stearns']",,,,
Topology-Aware Correlations between Relations for Inductive Link Prediction in Knowledge Graphs,"['Jiajun Chen', 'Huarui He', 'Feng Wu', 'Jie Wang']",,,,
Automated Symbolic Law Discovery: A Computer Vision Approach,"['Hengrui Xing', 'Ansaf Salleb Aouissi', 'Nakul Verma']",,,,
Interactive Speech and Noise Modeling for Speech Enhancement,"['Chengyu Zheng', 'Xiulian Peng', 'Yuan Zhang', 'Sriram Srinivasan', 'Yan Lu']",https://arxiv.org/abs/2012.09408,"Speech enhancement is challenging because of the diversity of background noise types. Most of the existing methods are focused on modelling the speech rather than the noise. In this paper, we propose a novel idea to model speech and noise simultaneously in a two-branch convolutional neural network, namely SN-Net. In SN-Net, the two branches predict speech and noise, respectively. Instead of information fusion only at the final output layer, interaction modules are introduced at several intermediate feature domains between the two branches to benefit each other. Such an interaction can leverage features learned from one branch to counteract the undesired part and restore the missing component of the other and thus enhance their discrimination capabilities. We also design a feature extraction module, namely residual-convolution-and-attention (RA), to capture the correlations along temporal and frequency dimensions for both the speech and the noises. Evaluations on public datasets show that the interaction module plays a key role in simultaneous modeling and the SN-Net outperforms the state-of-the-art by a large margin on various evaluation metrics. The proposed SN-Net also shows superior performance for speaker separation.",バックグラウンドノイズの種類が多様であるため、音声強調は困難です。既存の方法のほとんどは、ノイズではなく音声のモデリングに焦点を合わせています。本論文では、2分岐畳み込みニューラルネットワーク、すなわちSN-Netで音声とノイズを同時にモデル化するための新しいアイデアを提案します。 SN-Netでは、2つのブランチがそれぞれ音声とノイズを予測します。最終出力層でのみ情報を融合する代わりに、相互作用モジュールが2つのブランチ間のいくつかの中間機能ドメインに導入され、相互に利益をもたらします。このような相互作用は、一方のブランチから学習した機能を活用して、不要な部分を打ち消し、もう一方の欠落しているコンポーネントを復元して、それらの識別機能を強化できます。また、音声とノイズの両方の時間次元と周波数次元に沿った相関をキャプチャするために、特徴抽出モジュール、つまり残差畳み込みと注意（RA）を設計します。公開データセットの評価は、インタラクションモジュールが同時モデリングで重要な役割を果たし、SN-Netがさまざまな評価指標で最先端技術を大幅に上回っていることを示しています。提案されたSN-Netは、スピーカーの分離に関しても優れたパフォーマンスを示します。,https://d3i71xaburhd42.cloudfront.net/d918e6b84101e7a3071f5196e45e79cc68d5dee8/1-Figure1-1.png
DART: Adaptive Accept Reject Algorithm for Non-Linear Combinatorial Bandits,"['Mridul Agarwal', 'Vaneet Aggarwal', 'Abhishek Kumar Umrawal', 'Chris Quinn']",,,,
IA-GM: A Deep Bidirectional Learning Method for Graph Matching,"['Kaixuan Zhao', 'Shikui Tu', 'Lei Xu']",,,,
Research Reproducibility as a Survival Analysis,['Edward Raff'],https://arxiv.org/abs/2012.09932,"There has been increasing concern within the machine learning community that we are in a reproducibility crisis. As many have begun to work on this problem, all work we are aware of treat the issue of reproducibility as an intrinsic binary property: a paper is or is not reproducible. Instead, we consider modeling the reproducibility of a paper as a survival analysis problem. We argue that this perspective represents a more accurate model of the underlying meta-science question of reproducible research, and we show how a survival analysis allows us to draw new insights that better explain prior longitudinal data. The data and code can be found at https://github.com/EdwardRaff/Research-ReproducibilitySurvival-Analysis",機械学習コミュニティでは、再現性の危機に直面しているという懸念が高まっています。多くの人がこの問題に取り組み始めているので、私たちが知っているすべての作業は、再現性の問題を固有のバイナリプロパティとして扱います。紙は再現可能かどうかです。代わりに、生存分析の問題として、紙の再現性をモデル化することを検討します。この視点は、再現性のある研究の根底にあるメタサイエンスの質問のより正確なモデルを表していると主張し、生存分析によって、以前の縦断的データをよりよく説明する新しい洞察を引き出す方法を示します。データとコードはhttps://github.com/EdwardRaff/Research-ReproducibilitySurvival-Analysisにあります。,https://d3i71xaburhd42.cloudfront.net/9d8b7b2c4e7a006cbaf4418804318647b6a4fe99/2-Figure1-1.png
Inverse Reinforcement Learning from Like-Minded Teachers,"['Ritesh Noothigattu', 'Tom Yan', 'Ariel D Procaccia']",,"We study the problem of learning a policy in a Markov decision process based on observations of the actions taken by multiple teachers. We assume that the teachers are like-minded in that their reward functions — while different from each other — are random perturbations of an underlying reward function. Under this assumption, we show that inverse reinforcement learning algorithms that satisfy a certain property — that of matching feature expectations — recover policies that are approximately optimal with respect to the underlying reward function, and that no algorithm can do better in the worst case. We support this conclusion with experiments involving a classic inverse reinforcement learning algorithm that matches feature expectations.",複数の教師がとった行動の観察に基づいて、マルコフ決定過程でポリシーを学習する問題を研究します。教師は、報酬関数が互いに異なる一方で、基礎となる報酬関数のランダムな摂動であるという点で同じ考えを持っていると想定しています。この仮定の下で、特徴の期待に一致する特定の特性を満たす逆強化学習アルゴリズムが、基礎となる報酬関数に関してほぼ最適なポリシーを回復し、最悪の場合にこれ以上うまくいくアルゴリズムはないことを示します。機能の期待に一致する古典的な逆強化学習アルゴリズムを含む実験で、この結論を支持します。,https://d3i71xaburhd42.cloudfront.net/0da646add1af224d36eb16a63687317db97ec982/6-Figure1-1.png
Neighborhood Consensus Networks for Unsupervised Multi-View Outlier Detection,"['Li Cheng', 'Yijie Wang', 'Xinwang Liu']",,,,
FontRL: Chinese Font Synthesis via Deep Reinforcement Learning,"['Yitian Liu', 'Zhouhui Lian']",,,,
Enhancing Audio-Visual Association with Self-Supervised Curriculum Learning,"['Jingran Zhang', 'Xing Xu', 'Fumin Shen', 'Huimin Lu', 'Xin Liu', 'Heng Tao Shen']",,,,
Coordination between Individual Agents in Multi-Agent Reinforcement Learning,"['Yang Zhang', 'Qingyu Yang', 'Dou An', 'Chengwei Zhang']",,,,
CHEF: Cross-Modal Hierarchical Embeddings for Food Domain Retrieval,"['Hai X Pham', 'Ricardo Guerrero ', 'Vladimir Pavlovic', 'Jiatong Li']",https://arxiv.org/abs/2102.02547,"Despite the abundance of multi-modal data, such as imagetext pairs, there has been little effort in understanding the individual entities and their different roles in the construction of these data instances. In this work, we endeavour to discover the entities and their corresponding importance in cooking recipes automatically as a visual-linguistic association problem. More specifically, we introduce a novel crossmodal learning framework to jointly model the latent representations of images and text in the food image-recipe association and retrieval tasks. This model allows one to discover complex functional and hierarchical relationships between images and text, and among textual parts of a recipe including title, ingredients and cooking instructions. Our experiments show that by making use of efficient tree-structured Long Short-Term Memory as the text encoder in our computational cross-modal retrieval framework, we are not only able to identify the main ingredients and cooking actions in the recipe descriptions without explicit supervision, but we can also learn more meaningful feature representations of food recipes, appropriate for challenging cross-modal retrieval and recipe adaption tasks. Introduction Computer vision and natural language processing have witnessed outstanding improvements in recent years. Computational food analysis (CFA) broadly refers to methods that attempt automating food understanding, and as such, it has recently received increased attention, in part due to its importance in health and general wellbeing (Min et al. 2019). For instance, CFA can play an important role in assessing and learning the functional similarity and interaction of ingredients, cooking methods and meal preferences, while aiding in computational meal preparation and planning (Teng, Lin, and Adamic 2012; Helmy et al. 2015). However, despite recent efforts CFA still poses specific and difficult challenges due to the highly heterogeneous and complex nature of the cooking transformation process. Further to this, a particular modality may offer only a partial “view”of the item, for example, a cooking recipe often describe elements that can easily be occluded in the visual depiction of a cooked dish, and/or come in a variety of colors, forms and textures (e.g., Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. ingredients such as tomatoes can be green, yellow or red and can also be presented as a sauce, chunks or whole). Recent approaches that aim at learning the translation between visual and textual representations of food items do so by learning the semantics of objects in a shared latent space (Salvador et al. 2017; Chen et al. 2018; Carvalho et al. 2018; Wang et al. 2019; Marı́n et al. 2019). Here, representations (also called embeddings) derived from multi-modal evidence sources (e.g., images, text, video, flavours, etc.) that belong to the same item are matched. In effect, this type of approach aims to find a common grounding language that describes items independent of their observed modality, therefore, allowing cross-modal retrieval. Recently, recurrent neural network (RNN) architectures such as Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber 1997) units and Gated Recurrent Units (GRU) (Cho et al. 2014) have (re-)emerged as two popular and effective models that are able to capture some long-term dependencies in sequential data. Previous works on cross-modal image-torecipe (test) retrieval in the food domain treat textual elements (e.g., words) as a linear sequence in a RNN (Salvador et al. 2017; Chen et al. 2018; Carvalho et al. 2018; Wang et al. 2019; Marı́n et al. 2019). However, natural language exhibits syntactic properties that would naturally combine words into phrases in a not necessarily sequential fashion (Tai, Socher, and Manning 2015). Chain structured RNNs (such as LSTMs) struggle to capture this type of relationship. Tree-LSTM offers a generalization of LSTMs to treestructured network topologies (Tai, Socher, and Manning 2015; Zhu, Sobihani, and Guo 2015), further to this, recent advancements in Tree-LSTMs allow online learning of the sequence structure (Choi, Min Yoo, and Lee 2017). In this work, we argue that these recent advancements in Tree-LSTM structure learning are specially well suited to discover the underlying syntactic structure specific to food cooking recipes, exclusively through the signal provided by its pairing with its visual representation (food dish image). Motivation One of the more general goals of the work proposed here is to have a system that is able to “understand” food. This is a very broad and challenging task that requires an understanding of not only the visual aspect of a meal, but also understanding what are its basic constituents and how they are ar X iv :2 10 2. 02 54 7v 1 [ cs .C V ] 4 F eb 2 02 1 processed and transformed into the final dish. Recipes offer an instruction manual as to how to prepare a dish; they specify the building blocks (ingredients), how to process them (instructions) and a succinct summary of the dish in the form of a title. Additionally, an image of a food also provides a type of dish summary in visual form, e.g., it is often possible to see main ingredients and deduce principal cooking techniques from them. As our main task is to delve deeper in the understanding of food, we would naturally focus on as many representations as possible, however, in this work we will focus primarily on recipes and images. Some key questions that people regularly ask themselves regarding food are: what it is and how it is made. In the proposed framework we aim at learning distinct textual entities that underline a particular dish in an unsupervised way. The proposed framework, driven solely by information arising by paired data (images and recipes), is able to understand concepts such as what is the main ingredient in this dish, thus answering the “what it is”. This information can be valuable to recommendation systems, which would benefit from understanding what is the main ingredient in a recipe. For example, a person querying for apple recipes is unlikely to be interested in recipes where apples are only a minor ingredient. In order to facilitate this, it is important to also understand the key actions that are required to create a dish. Food preparation actions describe types of dishes, which can impact the likelihood of an ingredient being either major or minor. For example, assuming “apple” is in the list of ingredients of a dish, while showing the action “bake” as prominent, it is more likely that apples are main ingredient as opposed to a recipe that where the action “grill” is the most prominent. Furthermore, the ability to deeply understand food, through simple pairing of images and recipes, enables the possibility of better “ingredient swap recipe retrieval”, where the goal is to find the dishes similar to the one described except for the main ingredient, which is replaced. To address some of the aforementioned challenges, we propose a novel cross-modal retrieval computational framework that can effectively learn translations between images of food dishes and their corresponding preparation recipes’ textual descriptions. Special emphasis is given to the functional and hierarchical relationship between text and images through the use of Tree-LSTMs. We show that using TreeLSTMs offers not only a better representation of sentences in the context of cross-modal retrieval, but also allow us to discover important aspects of the data, that are normally lost in sequential RNNs. In summary our contributions are: (1) a hierarchical crossmodal retrieval framework that allows the discovery of important syntactic concepts, such as ingredient importance, keywords and/or action words, exclusively through visualtext pairings, while also providing (2) extensive experiments that demonstrate state-of-the-art performance in the imageto-recipe retrieval task as well as various recipe modifications enabled by Tree-LSTM. Source code of our proposed method is available at https://github.com/haixpham/CHEF. Cross-Modal Association Model Cross-modal learning is an active research topic in computer science. In general terms, it describes a system that given a view or modality (e.g., image) of an instance, it retrieves the same instance but as viewed in another modality (e.g., text). These type models are usually trained using a direct correspondence between pairs of instances in different modalities. In the case of food recipe retrieval, these modalities are usually food images and their associated text descriptions (title, ingredients, recipe, etc.). In order to extract feature representations from both images and recipes (text), we base our architecture on a simplified version of the cross-modal association model presented by Salvador et al. (Salvador et al. 2017). Different to their model, we additionally make use of titles and replace the pre-embedding of instructions with an online instruction embedding module. Such model is trained to match recipes (a concatenation of the encoding of title, ingredients and instructions) and their corresponding images in a joint latent space. Our general cross-modal framework is shown in Fig. 1. During training, the model’s objective is formulated as the minimization of the distance between an anchor recipe r and matching image v, while also maximizing (up to a margin ) the distance between the anchor recipe r and a non-matching image v−, that is, it minimizes the margin triplet loss of (r+,v+,v−). Using two separate neural networks, one for text encoding Fp and another for image encoding Fq, each item of the triplet is embedded in a latent space with coordinates (p, q, q−). Formally, with the text encoder p = Fp(r) and image encoder q = Fq(v), the training is a minimization of the following objective function, V (Fp,Fq) = Ep̂(r+,v+),p̂(v−) min ([ d [ p, q ] − ",イメージテキストペアなどのマルチモーダルデータが豊富にあるにもかかわらず、これらのデータインスタンスの構築における個々のエンティティとそれらのさまざまな役割を理解するための努力はほとんどありませんでした。この作業では、視覚的言語的関連の問題として、レシピを調理する際のエンティティとそれに対応する重要性を自動的に発見するように努めます。より具体的には、食品の画像とレシピの関連付けおよび検索タスクにおける画像とテキストの潜在的な表現を共同でモデル化するための新しいクロスモーダル学習フレームワークを紹介します。このモデルにより、画像とテキストの間、およびタイトル、材料、調理手順などのレシピのテキスト部分の間で、複雑な機能的および階層的な関係を発見できます。私たちの実験は、計算クロスモーダル検索フレームワークのテキストエンコーダーとして効率的なツリー構造の長短期記憶を利用することにより、明示的な監督なしにレシピの説明で主要な成分と調理動作を特定できるだけではないことを示しています、しかし、クロスモーダル検索やレシピ適応タスクに挑戦するのに適した、食品レシピのより意味のある特徴表現を学ぶこともできます。はじめにコンピュータビジョンと自然言語処理は、近年、目覚ましい進歩を遂げています。計算食品分析（CFA）は、食品の理解を自動化しようとする方法を広く指します。そのため、健康と一般的な幸福における重要性もあり、最近注目を集めています（Min et al.2019）。たとえば、CFAは、計算による食事の準備と計画を支援しながら、食材、調理方法、食事の好みの機能的な類似性と相互作用を評価および学習する上で重要な役割を果たすことができます（Teng、Lin、およびAdamic 2012; Helmy et al.2015） 。しかし、最近の努力にもかかわらず、CFAは、調理変換プロセスの非常に不均一で複雑な性質のために、依然として特定の困難な課題を提起しています。これに加えて、特定のモダリティはアイテムの部分的なビューのみを提供する場合があります。たとえば、調理レシピは、調理された料理の視覚的描写で簡単に遮られる要素、および/またはさまざまな色や形で提供される要素を説明することがよくあります。およびテクスチャ（例：Copyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。Allrightsreserved。トマトなどの材料は、緑、黄、または赤にすることができ、ソース、チャンク、または全体として提示することもできます。 ）。食品の視覚的表現とテキスト表現の間の翻訳を学習することを目的とした最近のアプローチは、共有潜在空間内のオブジェクトのセマンティクスを学習することによってそれを行います（Salvador et al.2017; Chen et al.2018; Carvalho et al.2018; Wang et al.2018; al.2019; Marn et al.2019）。ここでは、同じアイテムに属するマルチモーダル証拠ソース（画像、テキスト、ビデオ、フレーバーなど）から派生した表現（埋め込みとも呼ばれます）が照合されます。事実上、このタイプのアプローチは、観察されたモダリティとは無関係にアイテムを記述する共通の接地言語を見つけることを目的としているため、クロスモーダル検索が可能になります。最近、長短期記憶（LSTM）（Hochreiter and Schmidhuber 1997）ユニットやゲート付き回帰ユニット（GRU）（Cho etal。2014）などのリカレントニューラルネットワーク（RNN）アーキテクチャが、2つの人気のあるものとして（再）出現しました。シーケンシャルデータの長期的な依存関係をキャプチャできる効果的なモデル。食品ドメインでのクロスモーダル画像-レシピ（テスト）検索に関する以前の研究では、テキスト要素（単語など）をRNNの線形シーケンスとして扱います（Salvador et al.2017; Chen et al.2018; Carvalho et al.2018 ; Wang et al.2019; Marn et al.2019）。ただし、自然言語は、必ずしも連続した方法で単語をフレーズに自然に組み合わせる構文特性を示します（Tai、Socher、およびManning2015）。チェーン構造のRNN（LSTMなど）は、このタイプの関係をキャプチャするのに苦労しています。 Tree-LSTMは、ツリー構造のネットワークトポロジ（Tai、Socher、およびManning 2015、Zhu、Sobihani、およびGuo 2015）へのLSTMの一般化を提供します。さらに、Tree-LSTMの最近の進歩により、シーケンス構造のオンライン学習が可能になります（Choi、 Min Yoo、およびLee 2017）。この作業では、Tree-LSTM構造学習におけるこれらの最近の進歩は、視覚的表現（料理の画像）とのペアリングによって提供される信号のみを介して、料理レシピに固有の基本的な構文構造を発見するのに特に適していると主張します。動機ここで提案されている作業のより一般的な目標の1つは、食べ物を理解できるシステムを持つことです。これは非常に広範でやりがいのある作業であり、食事の視覚的側面だけでなく、その基本的な構成要素とその構成要素を理解する必要がありますX iv：2 10 2. 02 54 7v 1 [cs .CV ] 4 F eb 2 02 1処理され、最終的な皿に変換されます。レシピは、料理の作り方に関する取扱説明書を提供します。それらは、構成要素（材料）、それらを処理する方法（指示）、およびタイトルの形で料理の簡潔な要約を指定します。さらに、食品の画像は、視覚的な形で料理の要約のタイプも提供します。たとえば、主な材料を確認し、それらから主要な調理技術を推測することがしばしば可能です。私たちの主な仕事は食べ物の理解を深めることであるため、当然、できるだけ多くの表現に焦点を当てますが、この作業では、主にレシピと画像に焦点を当てます。人々が食べ物に関して定期的に自問するいくつかの重要な質問は、それが何であるか、そしてそれがどのように作られるかです。提案されたフレームワークでは、教師なしの方法で特定の料理に下線を引く別個のテキストエンティティを学習することを目的としています。提案されたフレームワークは、ペアのデータ（画像とレシピ）によって生じる情報のみによって駆動され、この料理の主成分が何であるかなどの概念を理解し、それが何であるかを答えることができます。この情報は、レシピの主成分が何であるかを理解することで恩恵を受けるレコメンデーションシステムにとって価値があります。たとえば、リンゴのレシピを照会する人は、リンゴがほんのわずかな成分であるレシピに興味を持っている可能性は低いです。これを容易にするために、料理を作成するために必要な主要なアクションを理解することも重要です。食品加工アクションは、食材がメジャーまたはマイナーになる可能性に影響を与える可能性のある料理の種類を表します。たとえば、リンゴが料理の材料のリストに含まれていると仮定すると、アクションベークが目立つように表示されますが、アクショングリルが最も目立つレシピとは対照的に、リンゴが主な材料である可能性が高くなります。さらに、画像とレシピを簡単に組み合わせることで、食べ物を深く理解できるため、材料交換レシピの検索が向上する可能性があります。目的は、主な材料が置き換えられることを除いて、説明したものと同様の料理を見つけることです。前述の課題のいくつかに対処するために、食品料理の画像とそれに対応する調理レシピのテキストによる説明との間の翻訳を効果的に学習できる、新しいクロスモーダル検索計算フレームワークを提案します。 Tree-LSTMを使用することにより、テキストと画像の間の機能的および階層的な関係に特に重点が置かれます。 TreeLSTMを使用すると、クロスモーダル検索のコンテキストで文をより適切に表現できるだけでなく、通常はシーケンシャルRNNで失われるデータの重要な側面を発見できることを示します。要約すると、私たちの貢献は次のとおりです。（1）成分の重要性、キーワード、アクションワードなどの重要な構文概念の発見を、ビジュアルテキストのペアリングのみを通じて可能にする階層的なクロスモーダル検索フレームワーク。画像からレシピへの検索タスクにおける最先端のパフォーマンスと、Tree-LSTMによって可能になるさまざまなレシピの変更。提案された方法のソースコードは、https：//github.com/haixpham/CHEFで入手できます。クロスモーダルアソシエーションモデルクロスモーダル学習は、コンピュータサイエンスの活発な研究トピックです。一般的には、インスタンスのビューまたはモダリティ（画像など）を指定すると、同じインスタンスを取得しますが、別のモダリティ（テキストなど）で表示されるシステムを表します。これらのタイプモデルは通常、異なるモダリティのインスタンスのペア間の直接対応を使用してトレーニングされます。食品レシピ検索の場合、これらのモダリティは通常、食品画像とそれに関連するテキストの説明（タイトル、材料、レシピなど）です。画像とレシピ（テキスト）の両方から特徴表現を抽出するために、サルバドールらによって提示されたクロスモーダル関連モデルの簡略化されたバージョンに基づいてアーキテクチャを構築します。 （Salvador et al.2017）。モデルとは異なり、タイトルを追加で使用し、命令の事前埋め込みをオンライン命令埋め込みモジュールに置き換えます。このようなモデルは、レシピ（タイトル、材料、指示のエンコードの連結）と、共同潜在空間内の対応する画像に一致するようにトレーニングされています。一般的なクロスモーダルフレームワークを図1に示します。トレーニング中、モデルの目的は、アンカーレシピrと一致する画像vの間の距離を最小化すると同時に、（マージンまで）最大化することとして定式化されます。アンカーレシピrと一致しない画像v、つまり、（r +、v +、v）のマージントリプレット損失を最小限に抑えます。 1つはテキストエンコーディングFp用、もう1つは画像エンコーディングFq用の2つの別々のニューラルネットワークを使用して、トリプレットの各アイテムは座標（p、q、q）を持つ潜在空間に埋め込まれます。正式には、テキストエンコーダーp = Fp（r）および画像エンコーダーq = Fq（v）の場合、トレーニングは次の目的関数の最小化です。V（Fp、Fq）= Ep（r +、v +）、p（v ）min（[d [p、q],https://d3i71xaburhd42.cloudfront.net/582ff0395d97f3e90003811346c940559cec9a51/3-Figure1-1.png
Towards Robust Visual information Extraction in Real World: New Dataset and Novel Solution,"['Jiapeng Wang', 'Chongyu Liu', 'Lianwen Jin', 'Guozhi Tang', 'Jiaxin Zhang', 'Shuaitao Zhang', 'Qianying Wang', 'Yaqiang Wu', 'Mingxiang Cai']",,,,
Classification with Few Tests through Self-Selection,"['Hanrui Zhang', 'Yu Cheng', 'Vincent Conitzer']",,,,
Semantic MapNet: Building Allocentric Semanticmaps and Representations from Egocentric Views,"['Vincent Cartillier', 'Zhile Ren', 'Neha Jain', 'Stefan Lee', 'Irfan Essa', 'Dhruv Batra']",,,,
Extreme k-Center Clustering,"['MohammadHossein Bateni', 'Hossein Esfandiari', 'Manuela Fischer', 'Vahab Mirrokni']",,,,
Fair and Efficient Allocations under Subadditive Valuations,"['Bhaskar R Chaudhury', 'Jugal Garg', 'Ruta Mehta']",https://arxiv.org/abs/2005.06511,"We study the problem of allocating a set of indivisible goods among agents with subadditive valuations in a fair and efficient manner. Envy-Freeness up to any good (EFX) is the most compelling notion of fairness in the context of indivisible goods. Although the existence of EFX is not known beyond the simple case of two agents with subadditive valuations, some good approximations of EFX are known to exist, namely $\tfrac{1}{2}$-EFX allocation and EFX allocations with bounded charity. 
Nash welfare (the geometric mean of agents' valuations) is one of the most commonly used measures of efficiency. In case of additive valuations, an allocation that maximizes Nash welfare also satisfies fairness properties like Envy-Free up to one good (EF1). Although there is substantial work on approximating Nash welfare when agents have additive valuations, very little is known when agents have subadditive valuations. In this paper, we design a polynomial-time algorithm that outputs an allocation that satisfies either of the two approximations of EFX as well as achieves an $\mathcal{O}(n)$ approximation to the Nash welfare. Our result also improves the current best-known approximation of $\mathcal{O}(n \log n)$ and $\mathcal{O}(m)$ to Nash welfare when agents have submodular and subadditive valuations, respectively. 
Furthermore, our technique also gives an $\mathcal{O}(n)$ approximation to a family of welfare measures, $p$-mean of valuations for $p\in (-\infty, 1]$, thereby also matching asymptotically the current best known approximation ratio for special cases like $p =-\infty$ while also retaining the fairness properties.",劣加法性の評価を持つエージェント間で分割不可能な商品のセットを公正かつ効率的な方法で割り当てる問題を研究します。羨望-あらゆる商品までの自由（EFX）は、不可分な商品の文脈における公平性の最も説得力のある概念です。 EFXの存在は、劣加法性評価を持つ2つのエージェントの単純なケースを超えては知られていませんが、EFXのいくつかの適切な近似、つまり$ \ tfrac {1} {2} $-EFX割り当てと制限付きチャリティーによるEFX割り当てが存在することが知られています。ナッシュ福祉（エージェント評価の幾何平均）は、最も一般的に使用される効率の尺度の1つです。加法評価の場合、ナッシュの福祉を最大化する割り当ては、最大1つの商品（EF1）までのEnvy-Freeのような公平性の特性も満たします。エージェントが劣加法性の評価を持っている場合、ナッシュの福祉を概算することについてはかなりの研究がありますが、エージェントが劣加法性の評価を持っている場合はほとんど知られていません。この論文では、EFXの2つの近似のいずれかを満たすだけでなく、ナッシュ福祉のO（n）近似を達成する割り当てを出力する、多項式時間アルゴリズムを設計します。私たちの結果はまた、エージェントが劣モジュラ評価と劣加法評価をそれぞれ持っている場合、ナッシュ福祉に対するO（nlog n）とO（m）の現在最もよく知られている近似を改善します。さらに、私たちの手法は、福祉指標のファミリーにO（n）近似、p（、1]の評価のp平均を与えます。これにより、p =のような特殊なケースの現在の最もよく知られている近似比も、保持しながら漸近的に一致します。公平性のプロパティ。,
Fair and Efficient Allocations under Lexicographic Preferences,"['Hadi Hosseini', 'Sujoy Sikdar', 'Rohit Vaish', 'Lirong Xia']",https://arxiv.org/abs/2012.07680,"Envy-freeness up to any good (EFX) provides a strong and intuitive guarantee of fairness in the allocation of indivisible goods. But whether such allocations always exist or whether they can be efficiently computed remains an important open question. We study the existence and computation of EFX in conjunction with various other economic properties under lexicographic preferences--a well-studied preference model in artificial intelligence and economics. In sharp contrast to the known results for additive valuations, we not only prove the existence of EFX and Pareto optimal allocations, but in fact provide an algorithmic characterization of these two properties. We also characterize the mechanisms that are, in addition, strategyproof, non-bossy, and neutral. When the efficiency notion is strengthened to rank-maximality, we obtain non-existence and computational hardness results, and show that tractability can be restored when EFX is relaxed to another well-studied fairness notion called maximin share guarantee (MMS).",あらゆる商品までの羨望のない状態（EFX）は、分割できない商品の割り当てにおける公平性の強力で直感的な保証を提供します。しかし、そのような割り当てが常に存在するかどうか、またはそれらを効率的に計算できるかどうかは、重要な未解決の問題のままです。 EFXの存在と計算を、辞書式の選好の下で他のさまざまな経済的特性と組み合わせて研究します。人工知能と経済学でよく研究されている選好モデルです。加法評価の既知の結果とは対照的に、EFXとパレートの最適な割り当ての存在を証明するだけでなく、実際にはこれら2つのプロパティのアルゴリズムによる特性評価を提供します。さらに、戦略的で、上品でなく、中立であるメカニズムを特徴づけます。効率の概念がランク最大に強化されると、存在しない計算難度の結果が得られ、EFXがマキシミンシェア保証（MMS）と呼ばれる別のよく研究された公平性の概念に緩和されたときに扱いやすさが回復できることを示します。,https://d3i71xaburhd42.cloudfront.net/765d39b6a6c937a7ad4ec6a74376faa3e864616a/2-Figure1-1.png
Deductive Learning for Weakly-Supervised 3D Human Pose Estimation via Uncalibrated Cameras,"['Xipeng Chen', 'Pengxu Wei', 'Liang Lin']",,,,
Tracking Disease Outbreaks from Sparse Data with Bayesian Inference,"['Bryan Wilder', 'Michael Mina', 'Milind Tambe']",,,,
Transfer Learning for Efficient Iterative Safety Validation,"['Anthony Corso', 'Mykel Kochenderfer']",,,,
ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning,"['Zhewei Yao', 'Amir Gholami', 'Sheng Shen', 'Mustafa Mustafa', 'Kurt Keutzer', 'Michael Mahoney']",,,,
RNA Secondary Structure Representation Network for RNA-Proteins Binding Prediction,"['Liu Ziyi', 'Fulin Luo', 'Bo Du']",,,,
Making the Relation Matters: Relation of Relation Learning Network for Sentence Semantic Matching,"['Kun Zhang', 'Le Wu', 'Guangyi Lv', 'Meng Wang', 'Enhong Chen', 'Shulan Ruan']",,,,
Dual Adversarial Graph Neural Networks for Multi-Label Cross-Modal Retrieval,"['Shengsheng Qian', 'Dizhan Xue', 'Huaiwen Zhang', 'Quan Fang', 'Changsheng Xu']",,,,
ERNIE-ViL: Knowledge Enhanced Vision-Language Representations through Scene Graphs,"['Fei Yu', 'Jiji Tang', 'Weichong Yin', 'Yu Sun', 'Hao Tian', 'Hua Wu', 'Haifeng Wang']",https://arxiv.org/abs/2006.16934,"We propose a knowledge-enhanced approach, ERNIE-ViL, to learn joint representations of vision and language. ERNIE-ViL tries to construct the detailed semantic connections (objects, attributes of objects and relationships between objects in visual scenes) across vision and language, which are essential to vision-language cross-modal tasks. Incorporating knowledge from scene graphs, ERNIE-ViL constructs Scene Graph Prediction tasks, i.e., Object Prediction, Attribute Prediction and Relationship Prediction in the pre-training phase. More specifically, these prediction tasks are implemented by predicting nodes of different types in the scene graph parsed from the sentence. Thus, ERNIE-ViL can model the joint representation characterizing the alignments of the detailed semantics across vision and language. Pre-trained on two large image-text alignment datasets (Conceptual Captions and SBU), ERNIE-ViL learns better and more robust joint representations. It achieves state-of-the-art performance on 5 vision-language downstream tasks after fine-tuning ERNIE-ViL. Furthermore, it ranked the 1st place on the VCR leader-board with an absolute improvement of 3.7%.",視覚と言語の共同表現を学ぶために、知識強化アプローチ、ERNIE-ViLを提案します。 ERNIE-ViLは、視覚と言語のクロスモーダルタスクに不可欠な、視覚と言語にわたる詳細なセマンティック接続（オブジェクト、オブジェクトの属性、および視覚シーン内のオブジェクト間の関係）を構築しようとします。 ERNIE-ViLは、シーングラフからの知識を取り入れて、シーングラフ予測タスク、つまり、事前トレーニングフェーズでのオブジェクト予測、属性予測、および関係予測を構築します。より具体的には、これらの予測タスクは、文から解析されたシーングラフ内のさまざまなタイプのノードを予測することによって実装されます。したがって、ERNIE-ViLは、視覚と言語にわたる詳細なセマンティクスのアラインメントを特徴付ける共同表現をモデル化できます。 2つの大きな画像とテキストの配置データセット（概念キャプションとSBU）で事前トレーニングされた、ERNIE-ViLは、より優れた、より堅牢なジョイント表現を学習します。 ERNIE-ViLを微調整した後、5つのビジョン言語のダウンストリームタスクで最先端のパフォーマンスを実現します。さらに、それは3.7の絶対的な改善でVCRリーダーボードで1位にランクされました,https://d3i71xaburhd42.cloudfront.net/bc996a4dbf9d4234eacdd0b930a94de1d158e256/2-Figure1-1.png
Constrained Risk-Averse Markov Decision Processes,"['Mohamadreza Ahmadi', 'Ugo Rosolia', 'Michel Ingham', 'Richard M Murray', 'Aaron Ames']",https://arxiv.org/abs/2012.02423,"We consider the problem of designing policies for Markov decision processes (MDPs) with dynamic coherent risk objectives and constraints. We begin by formulating the problem in a Lagrangian framework. Under the assumption that the risk objectives and constraints can be represented by a Markov risk transition mapping, we propose an optimization-based method to synthesize Markovian policies that lower-bound the constrained risk-averse problem. We demonstrate that the formulated optimization problems are in the form of difference convex programs (DCPs) and can be solved by the disciplined convex-concave programming (DCCP) framework. We show that these results generalize linear programs for constrained MDPs with total discounted expected costs and constraints. Finally, we illustrate the effectiveness of the proposed method with numerical experiments on a rover navigation problem involving conditional-value-at-risk (CVaR) and entropic-value-at-risk (EVaR) coherent risk measures.",動的コヒーレントリスクの目的と制約を使用して、マルコフ決定過程（MDP）のポリシーを設計する問題を検討します。まず、ラグランジュのフレームワークで問題を定式化します。リスクの目的と制約をマルコフリスク遷移マッピングで表すことができるという仮定の下で、制約されたリスク回避問題を下限とするマルコフポリシーを合成するための最適化ベースの方法を提案します。公式化された最適化問題が差分凸プログラム（DCP）の形式であり、規律ある凸凹プログラミング（DCCP）フレームワークによって解決できることを示します。これらの結果は、予想されるコストと制約の合計が割引された制約付きMDPの線形計画法を一般化することを示しています。最後に、条件付きバリューアットリスク（CVaR）とエントロピーバリューアットリスク（EVaR）のコヒーレントリスク尺度を含むローバーナビゲーション問題に関する数値実験を使用して、提案された方法の有効性を示します。,https://d3i71xaburhd42.cloudfront.net/7b313679816e3ce1c7153f27c8ab60e1b4b993b0/1-Figure1-1.png
Learning Interpretable Models for Couple Networks under Domain Constraints,"['Hongyuan You', 'Sikun Lin', 'Ambuj Singh']",,,,
A Hybrid Probabilistic Approach for Table Understanding,"['Kexuan Sun', 'Harsha Rayudu', 'Jay Pujara']",,"Tables of data are used to record vast amounts of socioeconomic, scientific, and governmental information. Although humans create tables using underlying organizational principles, unfortunately AI systems struggle to understand the contents of these tables. This paper introduces an end-to-end system for table understanding, the process of capturing the relational structure of data in tables. We introduce models that identify cell types, group these cells into blocks of data that serve a similar functional role, and predict the relationships between these blocks. We introduce a hybrid, neuro-symbolic approach, combining embedded representations learned from thousands of tables with probabilistic constraints that capture regularities in how humans organize tables. Our neurosymbolic model is better able to capture positional invariants of headers and enforce homogeneity of data types. One limitation in this research area is the lack of rich datasets for evaluating end-to-end table understanding, so we introduce a new benchmark dataset comprised of 431 diverse tables from data.gov. The evaluation results show that our system achieves the state-of-the-art performance on cell type classification, block identification, and relationship prediction, improving over prior efforts by up to 7% of macro F1 score.",データの表は、膨大な量の社会経済的、科学的、および政府の情報を記録するために使用されます。人間は基本的な組織の原則を使用してテーブルを作成しますが、残念ながらAIシステムはこれらのテーブルの内容を理解するのに苦労しています。このホワイトペーパーでは、テーブルを理解するためのエンドツーエンドのシステム、つまりテーブル内のデータのリレーショナル構造をキャプチャするプロセスを紹介します。セルタイプを識別し、これらのセルを同様の機能的役割を果たすデータのブロックにグループ化し、これらのブロック間の関係を予測するモデルを紹介します。何千ものテーブルから学習した埋め込み表現と、人間がテーブルを編成する方法の規則性をキャプチャする確率的制約を組み合わせた、ハイブリッドのニューロシンボリックアプローチを紹介します。私たちの神経シンボリックモデルは、ヘッダーの位置不変量をより適切にキャプチャし、データ型の均一性を強化することができます。この研究分野の1つの制限は、エンドツーエンドのテーブル理解を評価するための豊富なデータセットがないことです。そのため、data.govからの431の多様なテーブルで構成される新しいベンチマークデータセットを導入します。評価結果は、私たちのシステムが細胞タイプの分類、ブロックの識別、および関係の予測に関して最先端のパフォーマンスを達成し、以前の取り組みよりも最大7つ向上していることを示しています,https://d3i71xaburhd42.cloudfront.net/4d6ae639850441b259ec261497f7a55838f9132a/2-Figure1-1.png
Deep Wasserstein Graph Discriminant Learning for Graph Classification,"['Tong Zhang', 'Yun Wang', 'Zhen Cui', 'Chuanwei Zhou', 'Baoliang Cui', 'Haikuan Huang', 'Jian Yang']",,,,
UNIpoint: Universally Approximating Point Processes Intensities,"['Alexander Soen', 'Lexing Xie', 'Alexander Mathews', 'Daniel Grixti-Cheng']",https://arxiv.org/abs/2007.14082,"Point processes are a useful mathematical tool for describing events over time, and there are many recent approaches for representing and learning them. One notable open question is how to precisely describe the flexibility of the various models, and whether there exists a general model that can represent all point processes. Our work bridges this gap. Focusing on the widely used event intensity function representation of point processes, we provide a proof that a class of learnable functions can universally approximate any valid intensity function. The proof connects the well known Stone-Weierstrass Theorem for function approximation, the uniform density of non-negative continuous functions using a transfer functions, the formulation of the parameters of a piece-wise continuous functions as a dynamical system, and recurrent neural networks for capturing the dynamics. Using these insights, we design and implement UNIPoint, a novel neural point process model, using recurrent neural networks to parameterise sums of basis function upon each event. Evaluations on synthetic and real world datasets show that this simpler representation performs better than Hawkes process variants and more complex neural network-based approaches. We expect this result will provide a basis for practically selecting and tuning models, as well as furthering theoretical work on fine-grained characterisation of representational complexity versus expressiveness.",点過程は、時間の経過に伴うイベントを記述するための便利な数学的ツールであり、それらを表現および学習するための最近のアプローチは数多くあります。注目すべき未解決の質問の1つは、さまざまなモデルの柔軟性を正確に説明する方法と、すべての点過程を表すことができる一般的なモデルが存在するかどうかです。私たちの仕事はこのギャップを埋めます。点過程の広く使用されているイベント強度関数表現に焦点を当て、学習可能な関数のクラスが任意の有効な強度関数を普遍的に近似できるという証拠を提供します。この証明は、関数近似のよく知られたStone-Weierstrassの定理、伝達関数を使用した非負の連続関数の均一密度、動的システムとしての区分的連続関数のパラメーターの定式化、およびリカレントニューラルネットワークを接続します。ダイナミクスをキャプチャします。これらの洞察を使用して、リカレントニューラルネットワークを使用して各イベントの基底関数の合計をパラメーター化する、新しいニューラルポイントプロセスモデルであるUNIPointを設計および実装します。合成データセットと実世界データセットの評価は、この単純な表現がホークスプロセスバリアントやより複雑なニューラルネットワークベースのアプローチよりも優れていることを示しています。この結果は、モデルを実際に選択および調整するための基礎を提供するだけでなく、表現の複雑さ対表現力のきめ細かい特性評価に関する理論的研究を促進することを期待しています。,
Boundary Proposal Network for Two-Stage Natural Language Video Localization,"['Shaoning Xiao', 'Long Chen', 'Songyang Zhang', 'Wei Ji', 'Jian Shao', 'Lu Ye', 'Jun Xiao']",,,,
A Bidirectional Multi-Paragraph Reading Model for Zero-Shot Entity Linking,"['Hongyin Tang', 'Xingwu Sun', 'Beihong Jin', 'Fuzheng Zhang']",,,,
Discovering New Intents with Deep Aligned Clustering,"['Hanlei Zhang', 'Hua Xu', 'Ting-En Lin', 'Lv Rui']",https://arxiv.org/abs/2012.08987,"Discovering new intents is a crucial task in a dialogue system. Most existing methods are limited in transferring the prior knowledge from known intents to new intents. These methods also have difficulties in providing high-quality supervised signals to learn clustering-friendly features for grouping unlabeled intents. In this work, we propose an effective method (Deep Aligned Clustering) to discover new intents with the aid of limited known intent data. Firstly, we leverage a few labeled known intent samples as prior knowledge to pre-train the model. Then, we perform k-means to produce cluster assignments as pseudo-labels. Moreover, we propose an alignment strategy to tackle the label inconsistency during clustering assignments. Finally, we learn the intent representations under the supervision of the aligned pseudo-labels. With an unknown number of new intents, we predict the number of intent categories by eliminating low-confidence intent-wise clusters. Extensive experiments on two benchmark datasets show that our method is more robust and achieves substantial improvements over the state-of-the-art methods.(Code available at this https URL)",新しい意図を発見することは、対話システムにおける重要なタスクです。ほとんどの既存の方法は、既知のインテントから新しいインテントに事前知識を転送することに制限があります。これらの方法では、ラベルのないインテントをグループ化するためのクラスタリングに適した機能を学習するために、高品質の教師あり信号を提供することも困難です。この作業では、限られた既知のインテントデータを使用して、新しいインテントを発見するための効果的な方法（Deep Aligned Clustering）を提案します。まず、モデルを事前トレーニングするための事前知識として、いくつかのラベル付きの既知の意図サンプルを活用します。次に、k-meansを実行して、クラスター割り当てを疑似ラベルとして生成します。さらに、クラスタリング割り当て中のラベルの不整合に対処するためのアライメント戦略を提案します。最後に、整列された疑似ラベルの監視下でインテント表現を学習します。新しいインテントの数が不明な場合、信頼性の低いインテントワイズクラスターを排除することにより、インテントカテゴリの数を予測します。 2つのベンチマークデータセットでの広範な実験は、私たちの方法がより堅牢であり、最先端の方法よりも大幅に改善されていることを示しています（コードはこのhttps URLで入手可能）,https://d3i71xaburhd42.cloudfront.net/e8e2e75bf2d83053576aa644c394536bd0fd8f12/1-Figure1-1.png
Continual Learning by Using Information of Each Class Holistically,"['Wenpeng Hu', 'Qi Qin', 'Mengyu Wang', 'Jinwen Ma', 'Bing Liu']",,,,
A Supervised Multi-Head Self-Attention Network for Nested Named Entity Recognition,"['Yongxiu Xu', 'Heyan Huang', 'Chong Feng', 'Yue Hu']",,,,
StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke Encoding,"['Jinshan Zeng', 'Qi Chen', 'Yunxin Liu', 'Mingwen Wang', 'Yuan Yao']",https://arxiv.org/abs/2012.08687,"The generation of stylish Chinese fonts is an important problem involved in many applications. Most of existing generation methods are based on the deep generative models, particularly, the generative adversarial networks (GAN) based models. However, these deep generative models may suffer from the mode collapse issue, which significantly degrades the diversity and quality of generated results. In this paper, we introduce a one-bit stroke encoding to capture the key mode information of Chinese characters and then incorporate it into CycleGAN, a popular deep generative model for Chinese font generation. As a result we propose an efficient method called StrokeGAN, mainly motivated by the observation that the stroke encoding contains amount of mode information of Chinese characters. In order to reconstruct the one-bit stroke encoding of the associated generated characters, we introduce a stroke-encoding reconstruction loss imposed on the discriminator. Equipped with such one-bit stroke encoding and stroke-encoding reconstruction loss, the mode collapse issue of CycleGAN can be significantly alleviated, with an improved preservation of strokes and diversity of generated characters. The effectiveness of StrokeGAN is demonstrated by a series of generation tasks over nine datasets with different fonts. The numerical results demonstrate that StrokeGAN generally outperforms the state-of-the-art methods in terms of content and recognition accuracies, as well as certain stroke error, and also generates more realistic characters.",スタイリッシュな中国語フォントの生成は、多くのアプリケーションに関係する重要な問題です。既存の生成方法のほとんどは、深い生成モデル、特に生成的敵対的ネットワーク（GAN）ベースのモデルに基づいています。ただし、これらの深い生成モデルは、生成される結果の多様性と品質を大幅に低下させるモード崩壊の問題に悩まされる可能性があります。この論文では、漢字のキーモード情報をキャプチャし、それを中国語フォント生成の人気のある深層生成モデルであるCycleGANに組み込むための1ビットストロークエンコーディングを紹介します。その結果、主にストロークエンコーディングに漢字のモード情報が大量に含まれているという観察に動機付けられたStrokeGANと呼ばれる効率的な方法を提案します。関連する生成された文字の1ビットストロークエンコーディングを再構築するために、ディスクリミネータに課せられるストロークエンコーディング再構築損失を導入します。このような1ビットのストロークエンコーディングとストロークエンコーディングの再構築損失を備えているため、CycleGANのモード崩壊の問題は大幅に軽減され、ストロークの保存と生成される文字の多様性が向上します。 StrokeGANの有効性は、フォントが異なる9つのデータセットに対する一連の生成タスクによって示されます。数値結果は、StrokeGANが、コンテンツと認識の精度、および特定のストロークエラーの点で、一般に最先端の方法を上回り、よりリアルな文字を生成することを示しています。,https://d3i71xaburhd42.cloudfront.net/b98caf7802c9136f1fcb4094519d2cddddf845c8/2-Figure1-1.png
Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting,"['Mengzhang Li', 'Zhanxing Zhu']",,,,
A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving,"['Maxwell Crouse', 'Ibrahim Abdelaziz', 'Bassem Makni', 'Spencer Whitehead', 'Cristina Cornelio', 'Pavan Kapanipathi', 'Kavitha Srinivas', 'Veronika Thost', 'Michael Witbrock', 'Achille Fokoue']",https://arxiv.org/abs/1911.02065,"Automated theorem provers have traditionally relied on manually tuned heuristics to guide how they perform proof search. Deep reinforcement learning has been proposed as a way to obviate the need for such heuristics, however, its deployment in automated theorem proving remains a challenge. In this paper we introduce TRAIL, a system that applies deep reinforcement learning to saturation-based theorem proving. TRAIL leverages (a) a novel neural representation of the state of a theorem prover and (b) a novel characterization of the inference selection process in terms of an attention-based action policy. We show through systematic analysis that these mechanisms allow TRAIL to significantly outperform previous reinforcement-learning-based theorem provers on two benchmark datasets for first-order logic automated theorem proving (proving around 15% more theorems).",自動定理証明者は、従来、手動で調整されたヒューリスティックに依存して、証明検索の実行方法をガイドしてきました。このようなヒューリスティックの必要性を排除する方法として、深層強化学習が提案されていますが、自動定理証明での展開は依然として課題です。この論文では、飽和に基づく定理証明に深層強化学習を適用するシステムであるTRAILを紹介します。 TRAILは、（a）定理証明者の状態の新しい神経表現と（b）注意ベースのアクションポリシーの観点からの推論選択プロセスの新しい特性を活用します。体系的な分析を通じて、これらのメカニズムにより、TRAILが一階述語論理自動定理証明の2つのベンチマークデータセットで以前の強化学習ベースの定理証明器を大幅に上回ることができることを示します（約15を証明）,
Counterfactual Fairness with Disentangled Causal Effect Variational Autoencoder,"['Hyemi Kim', 'Seungjae Shin', 'JoonHo Jang', 'Kyungwoo Song', 'Weonyoung Joo', 'Wanmo Kang', 'Il-Chul Moon']",https://arxiv.org/abs/2011.11878,"The problem of fair classification can be mollified if we develop a method to remove the embedded sensitive information from the classification features. This line of separating the sensitive information is developed through the causal inference, and the causal inference enables the counterfactual generations to contrast the what-if case of the opposite sensitive attribute. Along with this separation with the causality, a frequent assumption in the deep latent causal model defines a single latent variable to absorb the entire exogenous uncertainty of the causal graph. However, we claim that such structure cannot distinguish the 1) information caused by the intervention (i.e., sensitive variable) and 2) information correlated with the intervention from the data. Therefore, this paper proposes Disentangled Causal Effect Variational Autoencoder (DCEVAE) to resolve this limitation by disentangling the exogenous uncertainty into two latent variables: either 1) independent to interventions or 2) correlated to interventions without causality. Particularly, our disentangling approach preserves the latent variable correlated to interventions in generating counterfactual examples. We show that our method estimates the total effect and the counterfactual effect without a complete causal graph. By adding a fairness regularization, DCEVAE generates a counterfactual fair dataset while losing less original information. Also, DCEVAE generates natural counterfactual images by only flipping sensitive information. Additionally, we theoretically show the differences in the covariance structures of DCEVAE and prior works from the perspective of the latent disentanglement.",埋め込まれた機密情報を分類機能から削除する方法を開発すれば、公正な分類の問題を緩和することができます。機密情報を分離するこの線は、因果推論によって開発され、因果推論により、反事実世代は、反対の機密属性の仮定の場合を対比することができます。因果関係とのこの分離に加えて、深い潜在因果モデルで頻繁に想定されるのは、因果グラフの外因​​性の不確実性全体を吸収する単一の潜在変数を定義することです。ただし、そのような構造では、1）介入によって引き起こされた情報（つまり、機密変数）と2）介入に関連する情報をデータから区別できないと主張します。したがって、この論文は、外因性の不確実性を2つの潜在変数に解きほぐすことによってこの制限を解決するための解きほぐされた因果効果変分オートエンコーダー（DCEVAE）を提案します：1）介入に依存しないか2）因果関係のない介入に相関します。特に、私たちのもつれを解くアプローチは、反事実的な例を生成する際の介入に相関する潜在変数を保持します。私たちの方法が完全な因果グラフなしで総効果と反事実効果を推定することを示します。公平性の正則化を追加することにより、DCEVAEは、元の情報を失うことなく、反事実的な公平なデータセットを生成します。また、DCEVAEは、機密情報を反転するだけで、自然な反事実画像を生成します。さらに、潜在的な解きほぐしの観点から、DCEVAEと以前の研究の共分散構造の違いを理論的に示します。,https://d3i71xaburhd42.cloudfront.net/a7bb20f6d5d07c2043712f9b17aa1150aedec362/1-Figure1-1.png
PULNS: Positive-Unlabeled Learning with Effective Negative Sample Selector,"['Chuan Luo', 'Pu Zhao', 'Chen Chen', 'Bo Qiao', 'Chao Du', 'Hongyu Zhang', 'Wei Wu', 'Shaowei Cai', 'Bing He', 'Saravanakumar Rajmohan', 'Qingwei Lin']",,,,
Visual Relation Detection Using Hybrid Analogical Learning,"['Kezhen Chen', 'Ken Forbus']",,,,
Leveraging Table Content for Zero-Shot Text-to-SQL with Meta-Learning,"['Yongrui Chen', 'Xinnan Guo', 'Chaojie Wang', 'Jian Qiu', 'Guilin Qi', 'Meng Wang', 'Huiying Li']",,,,
Unsupervised Domain Adaptation for Semantic Segmentation by Content Transfer,"['Suhyeon Lee', 'Junhyuk Hyun', 'Hongje Seong', 'Euntai Kim']",https://arxiv.org/abs/2012.12545,"In this paper, we tackle the unsupervised domain adaptation (UDA) for semantic segmentation, which aims to segment the unlabeled real data using labeled synthetic data. The main problem of UDA for semantic segmentation relies on reducing the domain gap between the real image and synthetic image. To solve this problem, we focused on separating information in an image into content and style. Here, only the content has cues for semantic segmentation, and the style makes the domain gap. Thus, precise separation of content and style in an image leads to effect as supervision of real data even when learning with synthetic data. To make the best of this effect, we propose a zero-style loss. Even though we perfectly extract content for semantic segmentation in the real domain, another main challenge, the class imbalance problem, still exists in UDA for semantic segmentation. We address this problem by transferring the contents of tail classes from synthetic to real domain. Experimental results show that the proposed method achieves the state-of-the-art performance in semantic segmentation on the major two UDA settings.",この論文では、ラベル付き合成データを使用してラベルなし実データをセグメント化することを目的とした、セマンティックセグメンテーションの教師なしドメイン適応（UDA）に取り組みます。セマンティックセグメンテーションのためのUDAの主な問題は、実画像と合成画像の間のドメインギャップを減らすことに依存しています。この問題を解決するために、画像内の情報をコンテンツとスタイルに分離することに重点を置きました。ここでは、コンテンツのみがセマンティックセグメンテーションの手がかりを持っており、スタイルによってドメインギャップが生じます。したがって、画像内のコンテンツとスタイルを正確に分離することは、合成データで学習する場合でも、実際のデータの監視としての効果につながります。この効果を最大限に活用するために、ゼロスタイルの損失を提案します。実際のドメインでセマンティックセグメンテーションのコンテンツを完全に抽出しますが、もう1つの主要な課題であるクラスの不均衡の問題は、セマンティックセグメンテーションのUDAにまだ存在します。テールクラスのコンテンツを合成ドメインから実ドメインに転送することで、この問題に対処します。実験結果は、提案された方法が主要な2つのUDA設定でセマンティックセグメンテーションで最先端のパフォーマンスを達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/11de73205f632acb422de5cadae7ed4571595bf5/3-Figure1-1.png
The Maximin Support Method: An Extension of the D’Hondt Method to Approval-Based Multiwinner Elections,"['Luis Sanchez-Fernandez', 'Norberto Fernández García', 'Jesús Fisteus', 'Markus Brill']",,"We propose the maximin support method, a novel extension of the D'Hondt apportionment method to approval-based multiwinner elections. The maximin support method is based on maximizing the support of the least supported elected candidate. It can be computed efficiently and satisfies (adjusted versions of) the main properties of the original D'Hondt method: house monotonicity, population monotonicity, and proportional representation. We also establish a close relationship between the maximin support method and Phragm\'{e}n's voting rules.",承認ベースの複数の勝者の選挙へのDHondt配分方法の新しい拡張であるマキシミンサポート方法を提案します。マキシミンサポート方法は、サポートが最も少ない選出候補者のサポートを最大化することに基づいています。これは効率的に計算でき、元のDHondtメソッドの主なプロパティ（家の単調性、母集団の単調性、比例代表）を満たします（の調整済みバージョン）。また、マキシミンサポート方法とPhragmens投票ルールの間に密接な関係を確立します。,https://d3i71xaburhd42.cloudfront.net/f7f83205efea8c56b0671329618d02ba342bf600/5-Table1-1.png
Neural Analogical Matching,"['Maxwell Crouse', 'Constantine Nakos', 'Ibrahim Abdelaziz', 'Ken Forbus']",https://arxiv.org/abs/2004.03573,"Analogy is core to human cognition. It allows us to solve problems based on prior experience, it governs the way we conceptualize new information, and it even influences our visual perception. The importance of analogy to humans has made it an active area of research in the broader field of artificial intelligence, resulting in data-efficient models that learn and reason in human-like ways. While analogy and deep learning have generally been studied independently of one another, the integration of the two lines of research seems like a promising step towards more robust and efficient learning techniques. As part of the first steps towards such an integration, we introduce the Analogical Matching Network: a neural architecture that learns to produce analogies between structured, symbolic representations that are largely consistent with the principles of Structure-Mapping Theory.",類推は人間の認知の中核です。それは私たちが以前の経験に基づいて問題を解決することを可能にし、私たちが新しい情報を概念化する方法を支配し、そしてそれは私たちの視覚にさえ影響を与えます。人間との類似性の重要性により、人工知能の幅広い分野で活発な研究分野になり、人間のように学習して推論するデータ効率の高いモデルが生まれました。類推と深層学習は一般に互いに独立して研究されてきましたが、2つの研究ラインの統合は、より堅牢で効率的な学習手法に向けた有望なステップのようです。このような統合に向けた最初のステップの一部として、Analogical Matching Networkを紹介します。これは、構造マッピング理論の原則とほぼ一致する構造化された記号表現間の類似性を生成することを学習するニューラルアーキテクチャです。,https://d3i71xaburhd42.cloudfront.net/8ab65c510bd042fa30b3c71cb2edf7aafdd318eb/3-Figure1-1.png
Unanswerable Question Correction in Question Answering over Personal Knowledge Base,"['An-Zi Yen', 'Hen-Hsen Huang', 'Hsin-Hsi Chen']",,,,
Hierarchical Negative Binomial Factorization for Recommender Systems on Implicit Feedback,"['Li-Yen Kuo', 'Ming-Syan Chen']",,,,
GLISTER: Generalization Based Data Subset Selection for Efficient and Robust Learning,"['Krishnateja Killamsetty', 'Durga S', 'Ganesh Ramakrishnan', 'Rishabh Iyer']",https://arxiv.org/abs/2012.10630,"Large scale machine learning and deep models are extremely data-hungry. Unfortunately, obtaining large amounts of labeled data is expensive, and training state-of-the-art models (with hyperparameter tuning) requires significant computing resources and time. Secondly, real-world data is noisy and imbalanced. As a result, several recent papers try to make the training process more efficient and robust. However, most existing work either focuses on robustness or efficiency, but not both. In this work, we introduce GLISTER, a GeneraLIzation based data Subset selecTion for Efficient and Robust learning framework. We formulate GLISTER as a mixed discretecontinuous bi-level optimization problem to select a subset of the training data, which maximizes the log-likelihood on a held-out validation set. We then analyze GLISTER for simple classifiers such as gaussian and multinomial naive-bayes, k-nearest neighbor classifier, and linear regression and show connections to submodularity. Next, we propose an iterative online algorithm GLISTER-ONLINE, which performs data selection iteratively along with the parameter updates and can be applied to any loss-based learning algorithm. We then show that for a rich class of loss functions including cross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete data selection is an instance of (weakly) submodular optimization, and we analyze conditions for which GLISTER-ONLINE reduces the validation loss and converges. Finally, we propose GLISTER-ACTIVE, an extension to batch active learning, and we empirically demonstrate the performance of GLISTER on a wide range of tasks including, (a) data selection to reduce training time, (b) robust learning under label noise and imbalance settings, and (c) batch-active learning with several deep and shallow models. We show that our framework improves upon state of the art both in efficiency and accuracy (in cases (a) and (c)) and is more efficient compared to other state-ofthe-art robust learning algorithms in case (b). The code for GLISTERis at:https://github.com/dssresearch/GLISTER. Introduction With the quest to achieve human-like performance for machine learning and deep learning systems, the cost of training and deploying machine learning models has been significantly increasing. The wasted computational and engineering energy becomes evident in deep learning algorithms, wherein extensive hyper-parameter tuning and network architecture Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. search need to be done. This results in staggering compute costs and running times1. As a result, efficient and robust machine learning is a very relevant and substantial research problem. In this paper, we shall focus on three goals: Goal 1: Train machine learning and deep learning models on effective subsets of data, thereby significantly reducing training time and compute while not sacrificing accuracy. Goal 2: To (iteratively) select effective subsets of labeled data to reduce the labeling cost. Goal 3: Select data subsets to remove noisy labels and class imbalance, which is increasingly common in operational machine learning settings. Background and Related Work A number of papers have studied data efficient training and robust training of machine learning and deep learning models. However, the area of data efficient training of models that are also robust is relatively under-explored. Below, we summarize papers based on efficiency and robustness. Reducing Training Time and Compute (Data Selection): A number of recent papers have used submodular functions as proxy functions (Wei, Iyer, and Bilmes 2014; Wei et al. 2014b; Kirchhoff and Bilmes 2014; Kaushal et al. 2019). These approaches have been used in several domains including speech recognition (Wei et al. 2014a,b; Liu et al. 2015), machine translation (Kirchhoff and Bilmes 2014), computer vision (Kaushal et al. 2019), and NLP (Bairi et al. 2015). Another common approach uses coresets. Coresets are weighted subsets of the data, which approximate certain desirable characteristics of the full data (e.g., the loss function) (Feldman 2020). Coreset algorithms have been used for several problems including k-means clustering (Har-Peled and Mazumdar 2004), SVMs (Clarkson 2010) and Bayesian inference (Campbell and Broderick 2018). Coreset algorithms require specialized (and often very different algorithms) depending on the model and problem at hand and have had limited success in deep learning. A very recent coreset algorithm called CRAIG (Mirzasoleiman, Bilmes, and Leskovec 2020), which tries to select representative subsets of the training data that closely approximate the full gradient, has shown promise for several machine learning models. The resulting https://medium.com/syncedreview/the-staggering-cost-oftraining-sota-ai-models-e329e80fa82 ar X iv :2 01 2. 10 63 0v 3 [ cs .L G ] 1 5 Ja n 20 21 subset selection problem becomes an instance of the facility location problem (which is submodular). Another data selection framework, which is very relevant to this work, poses the data selection problem as that of selecting a subset of the training data such that the resulting model (trained on the subset) perform well on the full dataset (Wei, Iyer, and Bilmes 2015). (Wei, Iyer, and Bilmes 2015) showed that the resulting problem is a submodular optimization problem for the Nearest Neighbor (NN) and Naive Bayes (NB) classifiers. The authors empirically showed that these functions worked well for other classifiers, such as logistic regression and deep models (Kaushal et al. 2019; Wei, Iyer, and Bilmes 2015). Reducing Labeling Cost (Active Learning): Traditionally, active learning techniques like uncertainty sampling (US) and query by committee (QBC) have shown great promise in several domains of machine learning (Settles 2009). However, with the emergence of batch active learning (Wei, Iyer, and Bilmes 2015; Sener and Savarese 2018), simple US and QBC approaches do not capture diversity in the batch. Among the approaches to diversified active learning, one of the first approaches was Filtered Active Submodular Selection (FASS) (Wei, Iyer, and Bilmes 2015) that combines the uncertainty sampling method with a submodular data subset selection framework to label a subset of data points to train a classifier. Another related approach (Sener and Savarese 2018) defines active learning as a core-set selection problem and has demonstrated that the model learned over the k-centers of the dataset is competitive to the one trained over the entire data. Very recently, an algorithm called BADGE (Ash et al. 2020) sampled groups of points that have a diverse and higher magnitude of hypothesized gradients to incorporate both predictive uncertainty and sample diversity into every selected batch. Robust Learning: A number of approaches have been proposed to address robust learning in the context of noise, distribution shift and class imbalance. Several methods rely on reweighting training examples either by knowledge distillation from auxilliary models (Han et al. 2018; Jiang et al. 2018; Malach and Shalev-Shwartz 2017) or by using a clean held out validation set (Ren et al. 2018; Zhang and Sabuncu 2018). In particular, our approach bears similarity to the learning to reweight framework (Ren et al. 2018) wherein the authors try to reweight the training examples using a validation set, and solve the problem using a online meta-learning based approach. Submodular Functions: Since several of the data selection techniques use the notion of submodularity, we briefly introduce submodular functions and optimization. Let V = {1, 2, · · · , n} denote a ground set of items (for example, in our case, the set of training data points). Set functions are functions f : 2 → R that operate on subsets of V . A set function f is called a submodular function (Fujishige 2005) if it satisfies the diminishing returns property: for subsets S ⊆ T ⊆ V, f(j|S) , f(S ∪ j) − f(S) ≥ f(j|T ). Several natural combinatorial functions such as facility location, set cover, concave over modular, etc., are submodular functions (Iyer 2015; Iyer et al. 2020). Submodularity is also very appealing because a simple greedy algorithm achieves a 1−1/e constant factor approximation guarantee (Nemhauser, Wolsey, and Fisher 1978) for the problem of maximizing a submodular function subject to a cardinality constraint (which most data selection approaches involve). Moreover, several variants of the greedy algorithm have been proposed which further scale up submodular maximization to almost linear time complexity (Minoux 1978; Mirzasoleiman et al. 2014, 2013). Our Contribution Most prior work discussed above, either study robustness or efficiency, but not both. For example, the data selection approaches such as (Wei, Iyer, and Bilmes 2015; Mirzasoleiman, Bilmes, and Leskovec 2020; Shinohara 2014) and others focus on approximating either gradients or performance on the training sets, and hence would not be suitable for scenarios such as label noise and imbalance. On the other hand, the approaches like (Ren et al. 2018; Jiang et al. 2018) and others, focus on robustness but are not necessarily efficient. For example, the approach of (Ren et al. 2018) requires 3x the standard (deep) training cost, to obtain a robust model. GLISTER is the first framework, to the best of our knowledge, which focuses on both efficiency and robustness. Our work is closely related to the approaches of (Wei, Iyer, and Bilmes 2015) and (Ren et al. 2018). We build upon the work of (Wei, Iyer, and Bilmes 2015), by first generalizing their framework beyond simple classifiers (like nearest neighbor and naive bayes), but with general loss functions. We do this by proposing an iterative algorithm GLISTER-ONLINE which does data selection via a meta-learning based approach along with parameter updates. Furthermore, we pose the problem a","大規模な機械学習と詳細なモデルは、非常にデータを大量に消費します。残念ながら、大量のラベル付きデータを取得するにはコストがかかり、最先端のモデル（ハイパーパラメータ調整を使用）のトレーニングには、かなりのコンピューティングリソースと時間が必要です。第二に、実際のデータはノイズが多く、不均衡です。その結果、最近のいくつかの論文では、トレーニングプロセスをより効率的かつ堅牢にしようとしています。ただし、ほとんどの既存の作業は、堅牢性または効率性のいずれかに焦点を当てていますが、両方には焦点を当てていません。この作業では、効率的で堅牢な学習フレームワークのためのGeneraLIzationベースのデータサブセット選択であるGLISTERを紹介します。 GLISTERを混合離散連続2レベル最適化問題として定式化し、トレーニングデータのサブセットを選択します。これにより、保持された検証セットの対数尤度が最大化されます。次に、GLISTERを分析して、ガウスおよび多項ナイーブベイズ、k最近傍分類器、線形回帰などの単純な分類器を探し、劣モジュラ性への接続を示します。次に、反復オンラインアルゴリズムGLISTER-ONLINEを提案します。これは、パラメーターの更新とともにデータ選択を反復的に実行し、損失ベースの学習アルゴリズムに適用できます。次に、クロスエントロピー、ヒンジ損失、二乗損失、ロジスティック損失などの豊富なクラスの損失関数の場合、内部離散データ選択が（弱く）劣モジュラ最適化のインスタンスであることを示し、その条件を分析します。 GLISTER-ONLINEは、検証の損失を減らし、収束します。最後に、バッチアクティブラーニングの拡張機能であるGLISTER-ACTIVEを提案し、（a）トレーニング時間を短縮するためのデータ選択、（b）ラベルノイズ下での堅牢な学習など、さまざまなタスクでのGLISTERのパフォーマンスを実証的に示します。不均衡な設定、および（c）いくつかの深いモデルと浅いモデルを使用したバッチアクティブラーニング。私たちのフレームワークは、効率と精度の両方で最先端技術を改善し（ケース（a）と（c））、ケース（b）の他の最先端の堅牢な学習アルゴリズムと比較してより効率的であることを示します。 GLISTERのコードはhttps://github.com/dssresearch/GLISTERにあります。はじめに機械学習および深層学習システムで人間のようなパフォーマンスを実現するために、機械学習モデルのトレーニングとデプロイのコストが大幅に増加しています。無駄な計算およびエンジニアリングエネルギーは、ディープラーニングアルゴリズムで明らかになります。ディープラーニングアルゴリズムでは、広範なハイパーパラメータチューニングとネットワークアーキテクチャCopyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。全著作権所有。検索を行う必要があります。その結果、計算コストと実行時間が驚異的になります1。その結果、効率的で堅牢な機械学習は、非常に関連性が高く、実質的な研究課題です。このホワイトペーパーでは、次の3つの目標に焦点を当てます。目標1：データの効果的なサブセットで機械学習モデルと深層学習モデルをトレーニングし、精度を犠牲にすることなくトレーニング時間と計算を大幅に削減します。目標2：ラベル付けされたデータの効果的なサブセットを（繰り返し）選択して、ラベル付けのコストを削減する。目標3：データサブセットを選択して、ノイズの多いラベルとクラスの不均衡を取り除きます。これは、運用中の機械学習設定でますます一般的になっています。背景と関連作業多くの論文が、機械学習と深層学習モデルのデータ効率の高いトレーニングと堅牢なトレーニングを研究しています。ただし、堅牢なモデルのデータ効率の高いトレーニングの領域は、比較的十分に検討されていません。以下に、効率性と堅牢性に基づいて論文を要約します。トレーニング時間と計算の削減（データ選択）：最近の多くの論文では、劣モジュラ関数をプロキシ関数として使用しています（Wei、Iyer、およびBilmes 2014; Weietal。2014b; Kirchhoff and Bilmes 2014; Kaushal et al.2019）。これらのアプローチは、音声認識（Wei etal。2014a、b; Liu etal。2015）、機械翻訳（Kirchhoff and Bilmes 2014）、コンピュータービジョン（Kaushal etal。2019）、NLP（Bairi）などのいくつかの分野で使用されています。 et al.2015）。別の一般的なアプローチでは、コアセットを使用します。コアセットはデータの重み付けされたサブセットであり、完全なデータの特定の望ましい特性（損失関数など）を近似します（Feldman2020）。コアセットアルゴリズムは、k-meansクラスタリング（Har-Peled and Mazumdar 2004）、SVM（Clarkson 2010）、ベイズ推定（Campbell and Broderick 2018）などのいくつかの問題に使用されています。コアセットアルゴリズムは、モデルと目前の問題に応じて特殊な（そして多くの場合非常に異なるアルゴリズム）必要があり、深層学習での成功は限られています。 CRAIG（Mirzasoleiman、Bilmes、およびLeskovec 2020）と呼ばれるごく最近のコアセットアルゴリズムは、完全な勾配に厳密に近似するトレーニングデータの代表的なサブセットを選択しようとし、いくつかの機械学習モデルの可能性を示しています。結果のhttps://medium.com/syncedreview/the-staggering-cost-oftraining-sota-ai-models-e329e80fa82ar X iv：2 01 2. 10 63 0v 3 [cs .LG] 1 5 Ja n 20 21サブセット選択問題は、施設の場所の問題（劣モジュラ）のインスタンスになります。この作業に非常に関連する別のデータ選択フレームワークは、トレーニングデータのサブセットを選択する問題としてデータ選択の問題を提起し、結果のモデル（サブセットでトレーニングされた）が完全なデータセット（Wei、Iyer、およびBilmes2015）。 （Wei、Iyer、およびBilmes 2015）は、結果として生じる問題が、最近傍（NN）および単純ベイズ（NB）分類器の劣モジュラ最適化問題であることを示しました。著者は、これらの関数がロジスティック回帰やディープモデルなどの他の分類器でうまく機能することを経験的に示しました（Kaushaletal。2019; Wei、Iyer、and Bilmes 2015）。ラベリングコストの削減（アクティブラーニング）：従来、不確実性サンプリング（US）や委員会によるクエリ（QBC）などのアクティブラーニング手法は、機械学習のいくつかの領域で大きな期待を示してきました（Settles2009）。ただし、バッチアクティブラーニングの出現により（Wei、Iyer、およびBilmes 2015; Sener and Savarese 2018）、単純な米国およびQBCのアプローチではバッチの多様性を捉えることができません。多様化された能動学習へのアプローチの中で、最初のアプローチの1つは、不確実性サンプリング法と劣モジュラデータサブセット選択フレームワークを組み合わせてデータポイントのサブセットにラベルを付けるフィルタードアクティブ劣モジュラ選択（FASS）（Wei、Iyer、およびBilmes 2015）でした。分類器をトレーニングします。別の関連するアプローチ（Sener and Savarese 2018）は、アクティブラーニングをコアセット選択問題として定義し、データセットのk中心で学習されたモデルが、データ全体でトレーニングされたモデルと競合することを示しています。ごく最近、BADGE（Ash etal。2020）と呼ばれるアルゴリズムが、選択されたすべてのバッチに予測の不確実性とサンプルの多様性の両方を組み込むために、仮定された勾配の多様でより高い大きさを持つポイントのグループをサンプリングしました。ロバスト学習：ノイズ、分布シフト、クラスの不均衡のコンテキストでロバストな学習に対処するために、いくつかのアプローチが提案されています。いくつかの方法は、補助モデルからの知識蒸留（Han et al.2018; Jiang et al.2018; Malach and Shalev-Shwartz 2017）またはクリーンな保持検証セットの使用（Ren et al.2018; Zhang and Sabuncu 2018）。特に、私たちのアプローチは、著者が検証セットを使用してトレーニング例を再重み付けし、オンラインメタ学習ベースのアプローチを使用して問題を解決しようとするフレームワークを再重み付けする学習（Ren et al.2018）と類似しています。劣モジュラ関数：いくつかのデータ選択手法は劣モジュラ性の概念を使用しているため、劣モジュラ関数と最適化について簡単に紹介します。 V = 1、2、、nがアイテムのグラウンドセット（たとえば、この場合はトレーニングデータポイントのセット）を表すとします。集合関数は、Vのサブセットを操作する関数f：2Rです。集合関数fは、収穫逓減特性を満たす場合、劣モジュラ関数（Fujishige 2005）と呼ばれます。サブセットSTVの場合、f（j | S）、f（S j）f（S）f（j | T）。施設の場所、集合被覆、モジュラー上の凹面など、いくつかの自然な組み合わせ関数は劣モジュラ関数です（Iyer 2015; Iyer et al.2020）。単純な欲張りアルゴリズムがカーディナリティ制約（ほとんどのデータ選択アプローチに含まれる）の対象となる劣モジュラ関数を最大化する問題に対して11 / e定数因子近似保証（Nemhauser、Wolsey、およびFisher 1978）を達成するため、劣モジュラ性も非常に魅力的です。さらに、劣モジュラ最大化をほぼ線形の時間計算量にさらにスケールアップする欲張りアルゴリズムのいくつかの変形が提案されています（Minoux 1978; Mirzasoleiman etal。2014,2013）。私たちの貢献上記で説明したほとんどの以前の作業は、堅牢性または効率のいずれかを研究していますが、両方を研究しているわけではありません。たとえば、（Wei、Iyer、およびBilmes 2015、Mirzasoleiman、Bilmes、およびLeskovec 2020、Shinohara 2014）などのデータ選択アプローチは、トレーニングセットの勾配またはパフォーマンスの近似に焦点を合わせているため、ラベルノイズや不均衡などのシナリオ。一方、（Renetal。2018; Jiang etal。2018）などのアプローチは、堅牢性に重点を置いていますが、必ずしも効率的ではありません。たとえば、（Ren etal。2018）のアプローチでは、堅牢なモデルを取得するために、標準の（深い）トレーニングコストの3倍が必要です。 GLISTERは、私たちの知る限りでは、効率と堅牢性の両方に焦点を当てた最初のフレームワークです。私たちの仕事は、（Wei、Iyer、およびBilmes 2015）および（Ren et al.2018）のアプローチと密接に関連しています。 （Wei、Iyer、およびBilmes 2015）の作業に基づいて、最初に単純な分類器（最近傍や単純ベイズなど）を超えてフレームワークを一般化しますが、一般的な損失関数を使用します。これを行うには、メタ学習ベースのアプローチとパラメーターの更新を介してデータ選択を行う反復アルゴリズムGLISTER-ONLINEを提案します。さらに、問題を提起します",https://d3i71xaburhd42.cloudfront.net/b8487d528fd7ffd66abdc645a412c32e2a669c6c/3-Figure1-1.png
Improved Penalty Method via Doubly Stochastic Gradients for Bilevel Hyperparameter Optimization,"['Wanli Shi', 'Bin Gu']",,,,
Improving Continuous-Time Conflict Based Search,"['Anton Andreychuk', 'Konstantin Yakovlev', 'Eli Boyarski', 'Roni Stern']",https://arxiv.org/abs/2101.09723,"Conflict-Based Search (CBS) is a powerful algorithmic framework for optimally solving classical multi-agent path finding (MAPF) problems, where time is discretized into the time steps. Continuous-time CBS (CCBS) is a recently proposed version of CBS that guarantees optimal solutions without the need to discretize time. However, the scalability of CCBS is limited because it does not include any known improvements of CBS. In this paper, we begin to close this gap and explore how to adapt successful CBS improvements, namely, prioritizing conflicts (PC), disjoint splitting (DS), and high-level heuristics, to the continuous time setting of CCBS. These adaptions are not trivial, and require careful handling of different types of constraints, applying a generalized version of the Safe interval path planning (SIPP) algorithm, and extending the notion of cardinal conflicts. We evaluate the effect of the suggested enhancements by running experiments both on general graphs and 2-neighborhood grids. CCBS with these improvements significantly outperforms vanilla CCBS, solving problems with almost twice as many agents in some cases and pushing the limits of multiagent path finding in continuous-time domains.",競合ベースの検索（CBS）は、時間が時間ステップに離散化される古典的なマルチエージェントパスファインディング（MAPF）の問題を最適に解決するための強力なアルゴリズムフレームワークです。連続時間CBS（CCBS）は、最近提案されたバージョンのCBSであり、時間を離散化することなく最適なソリューションを保証します。ただし、CCBSのスケーラビリティには、CBSの既知の改善が含まれていないため、制限があります。このホワイトペーパーでは、このギャップを埋め、CBSの改善を成功させる方法、つまり、競合（PC）、非結合分割（DS）、および高レベルのヒューリスティックをCCBSの連続時間設定に適応させる方法を探ります。これらの適応は簡単ではなく、さまざまなタイプの制約を注意深く処理し、セーフインターバルパスプランニング（SIPP）アルゴリズムの一般化バージョンを適用し、基本的な競合の概念を拡張する必要があります。一般的なグラフと2近隣グリッドの両方で実験を実行することにより、提案された拡張機能の効果を評価します。これらの改善されたCCBSは、バニラCCBSを大幅に上回り、場合によってはほぼ2倍のエージェントの問題を解決し、連続時間ドメインでのマルチエージェントパス検索の限界を押し上げます。,https://d3i71xaburhd42.cloudfront.net/cb784a32fb351797c65625ff21e1b034d2073d5c/3-Figure1-1.png
Wasserstein Distributionally Robust Inverse Multiobjective Optimization,"['Chaosheng Dong', 'Bo Zeng']",https://arxiv.org/abs/2009.14552,"Inverse multiobjective optimization provides a general framework for the unsupervised learning task of inferring parameters of a multiobjective decision making problem (DMP), based on a set of observed decisions from the human expert. However, the performance of this framework relies critically on the availability of an accurate DMP, sufficient decisions of high quality, and a parameter space that contains enough information about the DMP. To hedge against the uncertainties in the hypothetical DMP, the data, and the parameter space, we investigate in this paper the distributionally robust approach for inverse multiobjective optimization. Specifically, we leverage the Wasserstein metric to construct a ball centered at the empirical distribution of these decisions. We then formulate a Wasserstein distributionally robust inverse multiobjective optimization problem (WRO-IMOP) that minimizes a worst-case expected loss function, where the worst case is taken over all distributions in the Wasserstein ball. We show that the excess risk of the WRO-IMOP estimator has a sub-linear convergence rate. Furthermore, we propose the semi-infinite reformulations of the WRO-IMOP and develop a cutting-plane algorithm that converges to an approximate solution in finite iterations. Finally, we demonstrate the effectiveness of our method on both a synthetic multiobjective quadratic program and a real world portfolio optimization problem.",逆多目的最適化は、人間の専門家から観察された一連の決定に基づいて、多目的意思決定問題（DMP）のパラメーターを推測する教師なし学習タスクの一般的なフレームワークを提供します。ただし、このフレームワークのパフォーマンスは、正確なDMPの可用性、高品質の十分な決定、およびDMPに関する十分な情報を含むパラメーター空間に大きく依存しています。仮想のDMP、データ、およびパラメーター空間の不確実性をヘッジするために、この論文では、逆多目的最適化のための分布的にロバストなアプローチを調査します。具体的には、ワッサースタインメトリックを活用して、これらの決定の経験的分布を中心としたボールを構築します。次に、最悪の場合の予想損失関数を最小化する、ワッサースタインの分布的にロバストな逆多目的最適化問題（WRO-IMOP）を定式化します。ここで、最悪の場合は、ワッサースタインボールのすべての分布に適用されます。 WRO-IMOP推定量の過剰リスクには、劣線形収束率があることを示します。さらに、WRO-IMOPの半無限再定式化を提案し、有限反復で近似解に収束する切断面アルゴリズムを開発します。最後に、合成多目的二次計画法と実際のポートフォリオ最適化問題の両方に対する私たちの方法の有効性を示します。,https://d3i71xaburhd42.cloudfront.net/eef710d6b72b22914a1dbd7ac4048fa8af8a047f/10-Figure1-1.png
Active Bayesian Assessment of Black-Box Classifiers,"['Disi Ji', 'Robert L Logan', 'Padhraic Smyth', 'Mark Steyvers']",,,,
"SCRUPLES: A Corpus of Community Ethical Judgments on 32,000 Real-Life Anecdotes","['Nicholas Lourie', 'Ronan Le Bras', 'Yejin Choi']",https://arxiv.org/abs/2008.09094,"As AI systems become an increasing part of people's everyday lives, it becomes ever more important that they understand people's ethical norms. Motivated by descriptive ethics, a field of study that focuses on people's descriptive judgments rather than theoretical prescriptions on morality, we investigate a novel, data-driven approach to machine ethics. 
We introduce Scruples, the first large-scale dataset with 625,000 ethical judgments over 32,000 real-life anecdotes. Each anecdote recounts a complex ethical situation, often posing moral dilemmas, paired with a distribution of judgments contributed by the community members. Our dataset presents a major challenge to state-of-the-art neural language models, leaving significant room for improvement. However, when presented with simplified moral situations, the results are considerably more promising, suggesting that neural models can effectively learn simpler ethical building blocks. 
A key take-away of our empirical analysis is that norms are not always clean-cut; many situations are naturally divisive. We present a new method to estimate the best possible performance on such tasks with inherently diverse label distributions, and explore likelihood functions that separate intrinsic from model uncertainty.","AIシステムが人々の日常生活の一部になるにつれて、AIシステムが人々の倫理的規範を理解することがますます重要になっています。道徳に関する理論的処方箋ではなく、人々の記述的判断に焦点を当てた研究分野である記述的倫理に動機付けられて、機械倫理への新しいデータ駆動型アプローチを調査します。 Scruplesを紹介します。これは、32,000の実際の逸話を超える625,000の倫理的判断を備えた最初の大規模データセットです。それぞれの逸話は、複雑な倫理的状況を語り、しばしば道徳的なジレンマを引き起こし、コミュニティのメンバーによって提供された判断の分布と対になっています。私たちのデータセットは、最先端の神経言語モデルに大きな課題を提示しており、大幅な改善の余地があります。ただし、単純化された道徳的状況が提示された場合、結果はかなり有望であり、神経モデルがより単純な倫理的構成要素を効果的に学習できることを示唆しています。私たちの経験的分析の重要なポイントは、規範が常にクリーンカットされているとは限らないということです。多くの状況は自然に分裂します。本質的に多様なラベル分布を持つそのようなタスクで可能な限り最高のパフォーマンスを推定するための新しい方法を提示し、モデルの不確実性から本質的なものを分離する尤度関数を探索します。",https://d3i71xaburhd42.cloudfront.net/ba3c0aa5c9057140e08872e908efe48791af3083/3-Figure2-1.png
UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark,"['Nicholas Lourie', 'Ronan Le Bras', 'Chandra Bhagavatula', 'Yejin Choi']",,,,
Graph-Based Tri-Attention Network for Answer Ranking in CQA,"['Wei Zhang', 'Zeyuan Chen', 'Chao Dong', 'Wen Wang', 'Hongyuan Zha', 'Jianyong Wang']",,,,
Treewidth-Aware Complexity in ASP: Not All Positive Cycles Are Equally Hard,"['Markus Hecher', 'Jorge Fandinno']",https://arxiv.org/abs/2007.04620,"It is well-know that deciding consistency for normal answer set programs (ASP) is NP-complete, thus, as hard as the satisfaction problem for classical propositional logic (SAT). The best algorithms to solve these problems take exponential time in the worst case. The exponential time hypothesis (ETH) implies that this result is tight for SAT, that is, SAT cannot be solved in subexponential time. This immediately establishes that the result is also tight for the consistency problem for ASP. However, accounting for the treewidth of the problem, the consistency problem for ASP is slightly harder than SAT: while SAT can be solved by an algorithm that runs in exponential time in the treewidth k, it was recently shown that ASP requires exponential time in k \cdot log(k). This extra cost is due checking that there are no self-supported true atoms due to positive cycles in the program. In this paper, we refine the above result and show that the consistency problem for ASP can be solved in exponential time in k \cdot log({\lambda}) where {\lambda} is the minimum between the treewidth and the size of the largest strongly-connected component in the positive dependency graph of the program. We provide a dynamic programming algorithm that solves the problem and a treewidth-aware reduction from ASP to SAT that adhere to the above limit.",通常の回答セットプログラム（ASP）の一貫性を決定することは、NP完全であるため、古典的な命題論理（SAT）の満足度の問題と同じくらい難しいことはよく知られています。これらの問題を解決するための最良のアルゴリズムは、最悪の場合、指数関数的な時間を要します。指数時間仮説（ETH）は、この結果がSATに対して厳密であることを意味します。つまり、SATは指数以下の時間で解くことができません。これにより、ASPの整合性の問題に対しても結果がタイトであることがすぐにわかります。ただし、問題のツリー幅を考慮すると、ASPの整合性の問題はSATよりも少し難しいです。SA​​Tはツリー幅kで指数時間で実行されるアルゴリズムで解決できますが、ASPにはkで指数時間を必要とすることが最近示されました。 log（k）。この余分なコストは、プログラムの正のサイクルのために自立した真の原子がないことを確認するためです。この論文では、上記の結果を改良し、ASPの整合性の問題がk log（）の指数時間で解決できることを示します。ここで、は木幅と正の依存関係グラフの最大の強連結成分のサイズの間の最小値です。プログラムの。問題を解決する動的計画法アルゴリズムと、上記の制限に準拠したASPからSATへのツリー幅を意識した削減を提供します。,https://d3i71xaburhd42.cloudfront.net/16c2e88c28874cb372e946c7c749fe577f275eaa/4-Figure1-1.png
Reinforcement Learning Based Multi-Agent Resilient Control: From Deep Neural Networks to an Adaptive Law,"['Jian Hou', 'Fangyuan Wang', 'Lili Wang', 'Zhiyong Chen']",,,,
Patch-Wise Attention Network for Monocular Depth Estimation,"['Sihaeng Lee', 'Janghyeon Lee', 'Byungju Kim', 'Eojindl Yi', 'Junmo Kim']",,,,
Hierarchically and Cooperatively Learning Traffic Signal Control,"['Bingyu Xu', 'Yaowei Wang', 'Zhaozhi Wang', 'Huizhu Jia', 'Zongqing Lu']",,,,
Computing an Efficient Exploration Basis for Learning with Univariate Polynomial Features,"['Chaitanya Amballa', 'Manu Kumar Gupta', 'Sanjay P. P. Bhat']",,,,
To Choose or To Fuse? Scale Selection for Crowd Counting,"['Qingyu Song', 'Changan Wang', 'Yabiao Wang', 'Ying Tai', 'Chengjie Wang', 'Jilin Li', 'Jian Wu', 'Jiayi Ma']",,,,
Embodied Visual Active Learning for Semantic Segmentation,"['David Nilsson', 'Aleksis Pirinen', 'Erik Gärtner', 'Cristian Sminchisescu']",https://arxiv.org/abs/2012.09503,"We study the task of embodied visual active learning, where an agent is set to explore a 3d environment with the goal to acquire visual scene understanding by actively selecting views for which to request annotation. While accurate on some benchmarks, today's deep visual recognition pipelines tend to not generalize well in certain real-world scenarios, or for unusual viewpoints. Robotic perception, in turn, requires the capability to refine the recognition capabilities for the conditions where the mobile system operates, including cluttered indoor environments or poor illumination. This motivates the proposed task, where an agent is placed in a novel environment with the objective of improving its visual recognition capability. To study embodied visual active learning, we develop a battery of agents - both learnt and pre-specified - and with different levels of knowledge of the environment. The agents are equipped with a semantic segmentation network and seek to acquire informative views, move and explore in order to propagate annotations in the neighbourhood of those views, then refine the underlying segmentation network by online retraining. The trainable method uses deep reinforcement learning with a reward function that balances two competing objectives: task performance, represented as visual recognition accuracy, which requires exploring the environment, and the necessary amount of annotated data requested during active exploration. We extensively evaluate the proposed models using the photorealistic Matterport3D simulator and show that a fully learnt method outperforms comparable pre-specified counterparts, even when requesting fewer annotations.",注釈を要求するビューを積極的に選択することで視覚的なシーンの理解を獲得することを目的として、エージェントが3D環境を探索するように設定された具体化された視覚的アクティブラーニングのタスクを研究します。一部のベンチマークでは正確ですが、今日の深い視覚認識パイプラインは、特定の現実世界のシナリオや異常な視点では一般化されない傾向があります。次に、ロボットによる知覚には、雑然とした屋内環境や不十分な照明など、モバイルシステムが動作する条件の認識機能を改善する機能が必要です。これは、エージェントがその視覚認識能力を向上させる目的で新しい環境に配置されるという提案されたタスクを動機付けます。具現化された視覚的能動学習を研究するために、私たちは、学習されたものと事前に指定されたものの両方で、環境に関するさまざまなレベルの知識を持つ一連のエージェントを開発します。エージェントはセマンティックセグメンテーションネットワークを備えており、有益なビューを取得し、それらのビューの近くに注釈を伝播するために移動および探索し、オンライン再トレーニングによって基礎となるセグメンテーションネットワークを改良しようとします。訓練可能な方法は、2つの競合する目的のバランスをとる報酬関数を使用した深層強化学習を使用します。環境の探索を必要とする視覚認識の精度として表されるタスクのパフォーマンスと、アクティブな探索中に要求される必要な量の注釈付きデータです。フォトリアリスティックなMatterport3Dシミュレーターを使用して提案されたモデルを広範囲に評価し、完全に学習された方法が、要求する注釈が少ない場合でも、同等の事前指定された方法よりも優れていることを示します。,https://d3i71xaburhd42.cloudfront.net/f6c397dc04c3e30ed2d6dc8299884db50d70f0b6/2-Figure1-1.png
Temporal Pyramid Network for Pedestrian Trajectory Prediction with Multi-Supervision,"['Rongqin Liang', 'Yuanman Li', 'Xia Li', 'Yi Tang', 'Jiantao Zhou', 'Wenbin Zou']",https://arxiv.org/abs/2012.01884,"Predicting human motion behavior in a crowd is important for many applications, ranging from the natural navigation of autonomous vehicles to intelligent security systems of video surveillance. All the previous works model and predict the trajectory with a single resolution, which is rather inefficient and difficult to simultaneously exploit the long-range information (e.g., the destination of the trajectory), and the short-range information (e.g., the walking direction and speed at a certain time) of the motion behavior. In this paper, we propose a temporal pyramid network for pedestrian trajectory prediction through a squeeze modulation and a dilation modulation. Our hierarchical framework builds a feature pyramid with increasingly richer temporal information from top to bottom, which can better capture the motion behavior at various tempos. Furthermore, we propose a coarse-to-fine fusion strategy with multi-supervision. By progressively merging the top coarse features of global context to the bottom fine features of rich local context, our method can fully exploit both the long-range and short-range information of the trajectory. Experimental results on several benchmarks demonstrate the superiority of our method. Our code and models will be available upon acceptance.",自動運転車の自然なナビゲーションからビデオ監視のインテリジェントセキュリティシステムに至るまで、群衆の中での人間の動きの行動を予測することは、多くのアプリケーションにとって重要です。これまでのすべての作品は、単一の解像度で軌道をモデル化して予測します。これは、長距離情報（軌道の目的地など）と短距離情報（歩行方向など）を同時に活用するのはかなり非効率的で困難です。モーション動作の特定の時間での速度）。本論文では、スクイーズ変調と膨張変調による歩行者軌道予測のための時間ピラミッドネットワークを提案した。私たちの階層的フレームワークは、上から下へとますます豊富な時間情報を備えた機能ピラミッドを構築します。これにより、さまざまなテンポでのモーション動作をより適切にキャプチャできます。さらに、マルチ監視による粗い融合戦略を提案します。グローバルコンテキストの上部の粗い特徴をリッチなローカルコンテキストの下部の細かい特徴に徐々にマージすることにより、私たちの方法は、軌道の長距離情報と短距離情報の両方を完全に活用できます。いくつかのベンチマークでの実験結果は、私たちの方法の優位性を示しています。私たちのコードとモデルは、承認され次第利用可能になります。,https://d3i71xaburhd42.cloudfront.net/6c240231b06495b8386db604b3db685dd467d502/2-Figure1-1.png
Linearly Replaceable Filters for Deep Network Channel Pruning,"['Donggyu Joo', 'Eojindl Yi', 'Sung Hyun Baek', 'Junmo Kim']",,,,
Knowledge Refinery: Learning from Decoupled Label,"['Qianggang Ding', 'Sifan Wu', 'Tao Dai', 'Hao Sun', 'Jiadong Guo', 'Zhang-Hua Fu', 'Shutao Xia']",,,,
Interpretable Actions: Controlling Experts with Understandable Commands,"['Shumeet Baluja', 'David Marwood', 'Michele Covell']",,,,
Shuffling Recurrent Neural Networks,"['Michael Rotman', 'Lior Wolf']",https://arxiv.org/abs/2007.07324,"We propose a novel recurrent neural network model, where the hidden state $h_t$ is obtained by permuting the vector elements of the previous hidden state $h_{t-1}$ and adding the output of a learned function $b(x_t)$ of the input $x_t$ at time $t$. In our model, the prediction is given by a second learned function, which is applied to the hidden state $s(h_t)$. The method is easy to implement, extremely efficient, and does not suffer from vanishing nor exploding gradients. In an extensive set of experiments, the method shows competitive results, in comparison to the leading literature baselines.",前の隠れ状態h（t 1）のベクトル要素を並べ替え、学習した関数b（x（t））の出力を追加することによって隠れ状態h（t）が得られる、新しいリカレントニューラルネットワークモデルを提案します。時間tでの入力x（t）。私たちのモデルでは、予測は、隠れた状態s（h（t））に適用される2番目の学習関数によって与えられます。この方法は、実装が簡単で、非常に効率的であり、勾配の消失や爆発の影響を受けません。広範な一連の実験で、このメソッドは、主要な文献のベースラインと比較して、競争力のある結果を示しています。,https://d3i71xaburhd42.cloudfront.net/1e31c3e42b4d0ba9ed1a13c0d8df962b72b0df7c/3-Figure1-1.png
Simpson's Bias in NLP Training,"['Fei Yuan', 'Longtu Zhang', 'Huang Bojun', 'Yaobo Liang']",,,,
Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information,"['Qiu Ran', 'Yankai Lin', 'Peng Li', 'Jie Zhou']",https://arxiv.org/abs/1911.02215,"Non-autoregressive neural machine translation (NAT) generates each target word in parallel and has achieved promising inference acceleration. However, existing NAT models still have a big gap in translation quality compared to autoregressive neural machine translation models due to the enormous decoding space. To address this problem, we propose a novel NAT framework named ReorderNAT which explicitly models the reordering information in the decoding procedure. We further introduce deterministic and non-deterministic decoding strategies that utilize reordering information to narrow the decoding search space in our proposed ReorderNAT. Experimental results on various widely-used datasets show that our proposed model achieves better performance compared to existing NAT models, and even achieves comparable translation quality as autoregressive translation models with a significant speedup.",非自己回帰ニューラル機械翻訳（NAT）は、各ターゲット単語を並行して生成し、有望な推論加速を実現しました。ただし、既存のNATモデルは、膨大なデコードスペースがあるため、自己回帰ニューラル機械翻訳モデルと比較して、翻訳品質に大きなギャップがあります。この問題に対処するために、デコード手順で並べ替え情報を明示的にモデル化するReorderNATという名前の新しいNATフレームワークを提案します。さらに、提案されたReorderNATのデコード検索スペースを狭めるために、並べ替え情報を利用する決定論的および非決定論的デコード戦略を紹介します。広く使用されているさまざまなデータセットでの実験結果は、提案されたモデルが既存のNATモデルと比較して優れたパフォーマンスを実現し、大幅な高速化を備えた自己回帰翻訳モデルと同等の翻訳品質を実現することを示しています。,https://d3i71xaburhd42.cloudfront.net/0174a1619b23fd74e6295be4d6231a45c0858f08/2-Figure1-1.png
Scheduled Sampling in Vision-Language Pretraining with Decoupled Encoder-Decoder Network,"['Yehao Li', 'Yingwei Pan', 'Ting Yao', 'Jingwen Chen', 'Tao Mei']",https://arxiv.org/abs/2101.11562,"Despite having impressive vision-language (VL) pretraining with BERT-based encoder for VL understanding, the pretraining of a universal encoder-decoder for both VL understanding and generation remains challenging. The difficulty originates from the inherently different peculiarities of the two disciplines, e.g., VL understanding tasks capitalize on the unrestricted message passing across modalities, while generation tasks only employ visual-to-textual message passing. In this paper, we start with a two-stream decoupled design of encoder-decoder structure, in which two decoupled cross-modal encoder and decoder are involved to separately perform each type of proxy tasks, for simultaneous VL understanding and generation pretraining. Moreover, for VL pretraining, the dominant way is to replace some input visual/word tokens with mask tokens and enforce the multimodal encoder/decoder to reconstruct the original tokens, but no mask token is involved when fine-tuning on downstream tasks. As an alternative, we propose a primary scheduled sampling strategy that elegantly mitigates such discrepancy via pretraining encoder-decoder in a two-pass manner. Extensive experiments demonstrate the compelling generalizability of our pretrained encoder-decoder by fine-tuning on four VL understanding and generation downstream tasks. Source code is available at https://github.com/YehLi/TDEN.",VLを理解するためのBERTベースのエンコーダーを使用した印象的な視覚言語（VL）の事前トレーニングがあるにもかかわらず、VLの理解と生成の両方のためのユニバーサルエンコーダー-デコーダーの事前トレーニングは依然として困難です。難しさは、2つの分野の本質的に異なる特性に起因します。たとえば、VL理解タスクは、モダリティ間での無制限のメッセージパッシングを利用しますが、生成タスクは、ビジュアルからテキストへのメッセージパッシングのみを使用します。このホワイトペーパーでは、エンコーダ-デコーダ構造の2ストリーム分離設計から始めます。この設計では、VLの理解と生成の事前トレーニングを同時に行うために、2つの分離クロスモーダルエンコーダとデコーダが各タイプのプロキシタスクを個別に実行します。さらに、VL事前トレーニングの場合、主な方法は、一部の入力ビジュアル/単語トークンをマスクトークンに置き換え、マルチモーダルエンコーダー/デコーダーを適用して元のトークンを再構築することですが、ダウンストリームタスクの微調整にはマスクトークンは含まれません。別の方法として、2パス方式でエンコーダー-デコーダーを事前トレーニングすることにより、このような不一致をエレガントに軽減する主要なスケジュールされたサンプリング戦略を提案します。広範な実験により、4つのVLの理解とダウンストリームタスクの生成を微調整することにより、事前にトレーニングされたエンコーダ-デコーダの説得力のある一般化が実証されています。ソースコードはhttps://github.com/YehLi/TDENで入手できます。,https://d3i71xaburhd42.cloudfront.net/04dee7bfed6af7e18cf8dcfc639de105120a3f6e/2-Figure1-1.png
Capturing Uncertainty in Unsupervised GPS Trajectory Segmentation Using Bayesian Deep Learning,"['Christos Markos', 'James Yu', 'Richard Yi Da Xu']",,,,
Synchronous Interactive Decoding for Multilingual Neural Machine Translation,"['Hao He', 'Qian Wang', 'Zhipeng Yu', 'Yang Zhao', 'Jiajun Zhang', 'Chengqing Zong']",,,,
Unchain the Search Space with Hierarchical Differentiable Architecture Search,"['Guanting Liu', 'Yujie Zhong', 'Sheng Guo', 'Matthew R. Scott', 'Weilin Huang']",https://arxiv.org/abs/2101.04028,"Differentiable architecture search (DAS) has made great progress in searching for high-performance architectures with reduced computational cost. However, DAS-based methods mainly focus on searching for a repeatable cell structure, which is then stacked sequentially in multiple stages to form the networks. This configuration significantly reduces the search space, and ignores the importance of connections between the cells. To overcome this limitation, in this paper, we propose a Hierarchical Differentiable Architecture Search (H-DAS) that performs architecture search both at the cell level and at the stage level. Specifically, the cell-level search space is relaxed so that the networks can learn stage-specific cell structures. For the stage-level search, we systematically study the architectures of stages, including the number of cells in each stage and the connections between the cells. Based on insightful observations, we design several search rules and losses, and mange to search for better stage-level architectures. Such hierarchical search space greatly improves the performance of the networks without introducing expensive search cost. Extensive experiments on CIFAR10 and ImageNet demonstrate the effectiveness of the proposed HDAS. Moreover, the searched stage-level architectures can be combined with the cell structures searched by existing DAS methods to further boost the performance. Code is available at: https://github.com/MalongTech/research-HDAS",微分可能アーキテクチャ検索（DAS）は、計算コストを削減した高性能アーキテクチャの検索において大きな進歩を遂げました。ただし、DASベースの方法は、主に繰り返し可能なセル構造の検索に重点を置いており、セル構造は複数の段階で順番に積み重ねられてネットワークを形成します。この構成では、検索スペースが大幅に削減され、セル間の接続の重要性が無視されます。この制限を克服するために、この論文では、セルレベルとステージレベルの両方でアーキテクチャ検索を実行する階層微分可能アーキテクチャ検索（H-DAS）を提案します。具体的には、セルレベルの検索スペースが緩和され、ネットワークがステージ固有のセル構造を学習できるようになります。ステージレベルの検索では、各ステージのセル数やセル間の接続など、ステージのアーキテクチャを体系的に調査します。洞察に満ちた観察に基づいて、いくつかの検索ルールと損失を設計し、より優れたステージレベルのアーキテクチャを検索するように管理します。このような階層的な検索スペースは、高価な検索コストを導入することなく、ネットワークのパフォーマンスを大幅に向上させます。 CIFAR10とImageNetでの広範な実験は、提案されたHDASの有効性を示しています。さらに、検索されたステージレベルのアーキテクチャを既存のDASメソッドで検索されたセル構造と組み合わせて、パフォーマンスをさらに向上させることができます。コードはhttps://github.com/MalongTech/research-HDASで入手できます。,https://d3i71xaburhd42.cloudfront.net/b0cb2cf5aba4d07fe152e9eaa3e1008fbb099a0a/1-Figure1-1.png
MERL: Multimodal Event Representation Learning in Heterogeneous Embedding Spaces,"['Linhai Zhang', 'Deyu Zhou', 'Yulan He', 'Zeng Yang']",,,,
Learning Term Embeddings for Lexical Taxonomies,"['Jingping Liu', 'Menghui Wang', 'Chao Wang', 'Jiaqing Liang', 'Lihan Chen', 'Haiyun Jiang', 'Yanghua Xiao', 'Yunwen Chen']",,,,
HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions,"['Shaobo Li', 'Xiaoguang Li', 'Lifeng Shang', 'Xin Jiang', 'Qun Liu', 'Chengjie Sun', 'Zhenzhou Ji', 'Bingquan Liu']",https://arxiv.org/abs/2012.15534,"Collecting supporting evidence from large corpora of text (e.g., Wikipedia) is of great challenge for open-domain Question Answering (QA). Especially, for multi-hop open-domain QA, scattered evidence pieces are required to be gathered together to support the answer extraction. In this paper, we propose a new retrieval target, hop, to collect the hidden reasoning evidence from Wikipedia for complex question answering. Specifically, the hop in this paper is defined as the combination of a hyperlink and the corresponding outbound link document. The hyperlink is encoded as the mention embedding which models the structured knowledge of how the outbound link entity is mentioned in the textual context, and the corresponding outbound link document is encoded as the document embedding representing the unstructured knowledge within it. Accordingly, we build HopRetriever which retrieves hops over Wikipedia to answer complex questions. Experiments on the HotpotQA dataset demonstrate that HopRetriever outperforms previously published evidence retrieval methods by large margins. Moreover, our approach also yields quantifiable interpretations of the evidence collection process.",大量のテキスト（ウィキペディアなど）から裏付けとなる証拠を収集することは、オープンドメインの質問応答（QA）にとって大きな課題です。特に、マルチホップオープンドメインQAの場合、回答の抽出をサポートするために、散在する証拠を収集する必要があります。この論文では、複雑な質問応答のためにウィキペディアから隠された推論の証拠を収集するための新しい検索ターゲット、ホップを提案します。具体的には、このペーパーのホップは、ハイパーリンクと対応するアウトバウンドリンクドキュメントの組み合わせとして定義されます。ハイパーリンクは、アウトバウンドリンクエンティティがテキストコンテキストでどのように言及されるかについての構造化された知識をモデル化する言及埋め込みとしてエンコードされ、対応するアウトバウンドリンクドキュメントは、その中の非構造化知識を表すドキュメント埋め込みとしてエンコードされます。したがって、複雑な質問に答えるためにウィキペディア上のホップを取得するHopRetrieverを構築します。 HotpotQAデータセットでの実験は、HopRetrieverが以前に公開された証拠検索方法を大幅に上回っていることを示しています。さらに、私たちのアプローチは、証拠収集プロセスの定量化可能な解釈ももたらします。,https://d3i71xaburhd42.cloudfront.net/64435711f6542aa6b53e95c6e084a0ccd2ec1c16/1-Figure1-1.png
Learning Game-Theoretic Models of Multiagent Trajectories Using Implicit Layers,"['Philipp Geiger', 'Christoph-Nikolas Straehle']",https://arxiv.org/abs/2008.07303,"For prediction of interacting agents' trajectories, we propose an end-to-end trainable architecture that hybridizes neural nets with game-theoretic reasoning, has interpretable intermediate representations, and transfers to downstream decision making. It uses a net that reveals preferences from the agents' past joint trajectory, and a differentiable implicit layer that maps these preferences to local Nash equilibria, forming the modes of the predicted future trajectory. Additionally, it learns an equilibrium refinement concept. For tractability, we introduce a new class of continuous potential games and an equilibrium-separating partition of the action space. We provide theoretical results for explicit gradients and soundness. In experiments, we evaluate our approach on two real-world data sets, where we predict highway driver merging trajectories, and on a simple decision-making transfer task.",相互作用するエージェントの軌道を予測するために、ニューラルネットをゲーム理論的推論とハイブリッド化し、解釈可能な中間表現を持ち、下流の意思決定に移行する、エンドツーエンドのトレーニング可能なアーキテクチャを提案します。これは、エージェントの過去の共同軌道からの選好を明らかにするネットと、これらの選好をローカルのナッシュ均衡にマッピングする微分可能な暗黙のレイヤーを使用して、予測される将来の軌道のモードを形成します。さらに、平衡精製の概念を学習します。扱いやすさのために、新しいクラスの連続潜在的ゲームとアクションスペースの平衡分離パーティションを導入します。明示的な勾配と健全性の理論的結果を提供します。実験では、高速道路のドライバーの合流軌道を予測する2つの実際のデータセットと、単純な意思決定転送タスクでアプローチを評価します。,
"THOR, Trace-Based Hardware-Driven Layer-Oriented Natural Gradient Descent Computation","['Mengyun Chen', 'Kaixin Gao', 'Xiaolei Liu', 'Zidong Wang', 'Ningxi Ni', 'Qian Zhang', 'Lei Chen', 'Chao Ding', 'Zhenghai Huang', 'Min Wang', 'Shuangling Wang', 'Fan Yu', 'Xinyuan Zhao', 'Dachuan Xu']",,,,
On the Optimal Efficiency of A* with Dominance Pruning,['Alvaro Torralba'],,,,
Learning Deep Generative Models for Queuing Systems,"['Cesar A Ojeda', 'Ramses Sanchez', 'Kostadin Cvejoski', 'Bodgan Georgiev', 'Christian Bauckhage', 'Jannis Schuecker']",,,,
Two-Stream Convolution Augmented Transformer for Human Activity Recognition,"['Bing Li', 'Wei Cui', 'Wei Wang', 'Le Zhang', 'Zhenghua Chen', 'Min Wu']",,,,
Toward Realistic Virtual Try-On through Landmark Guided Shape Matching,"['Guoqiang Liu', 'Dan Song', 'Ruofeng Tong', 'Min Tang']",,,,
News Content Completion with Location-Aware Image Selection,"['Zhengkun Zhang', 'Jun Wang', 'Adam Jatowt', 'Zhe Sun', 'Shao-Ping Lu', 'Zhenglu Yang']",,,,
SongMASS: Automatic Song Writing with Pre-Training and Alignment Constraint,"['Zhonghao Sheng', 'Kaitao Song', 'Xu Tan', 'Yi Ren', 'Wei Ye', 'Shikun Zhang', 'Tao Qin']",,,,
Entity Guided Question Generation with Contextual Structure and Sequence Information Capturing,"['Qingbao Huang', 'Mingyi Fu', 'Linzhang Mo', 'Yi Cai', 'Jingyun Xu', 'Pijian Li', 'Qing Li', 'Ho-fung Leung']",,,,
Generalized Relation Learning with Semantic Correlation Awareness for Link Prediction,"['Yao Zhang', 'Xu Zhang', 'Jun Wang', 'Hongru Liang', 'Wenqiang Lei', 'Zhe Sun', 'Adam Jatowt', 'Zhenglu Yang']",https://arxiv.org/abs/2012.11957,"Developing link prediction models to automatically complete knowledge graphs has recently been the focus of significant research interest. The current methods for the link prediction task have two natural problems: 1) the relation distributions in knowledge graphs are usually unbalanced, and 2) there are many unseen relations that occur in practical situations. These two problems limit the training effectiveness and practical applications of the existing link prediction models. We advocate a holistic understanding of KGs and we propose in this work a unified Generalized Relation Learning framework GRL to address the above two problems, which can be plugged into existing link prediction models. GRL conducts a generalized relation learning, which is aware of semantic correlations between relations that serve as a bridge to connect semantically similar relations. After training with GRL, the closeness of semantically similar relations in vector space and the discrimination of dissimilar relations are improved. We perform comprehensive experiments on six benchmarks to demonstrate the superior capability of GRL in the link prediction task. In particular, GRL is found to enhance the existing link prediction models making them insensitive to unbalanced relation distributions and capable of learning unseen",知識グラフを自動的に完成させるためのリンク予測モデルの開発は、最近、重要な研究関心の焦点となっています。リンク予測タスクの現在の方法には、2つの自然な問題があります。1）知識グラフの関係分布は通常不均衡であり、2）実際の状況で発生する多くの目に見えない関係があります。これらの2つの問題は、既存のリンク予測モデルのトレーニングの有効性と実際のアプリケーションを制限します。 KGの全体的な理解を提唱し、この作業では、既存のリンク予測モデルにプラグインできる上記の2つの問題に対処するための統合された一般化関係学習フレームワークGRLを提案します。 GRLは、一般化された関係学習を実行します。これは、意味的に類似した関係を接続するためのブリッジとして機能する関係間の意味相関を認識します。 GRLでトレーニングした後、ベクトル空間での意味的に類似した関係の近さと、異なる関係の識別が改善されます。リンク予測タスクにおけるGRLの優れた機能を実証するために、6つのベンチマークで包括的な実験を実行します。特に、GRLは、既存のリンク予測モデルを強化して、不均衡な関係分布に鈍感にし、目に見えない学習を可能にすることがわかっています。,https://d3i71xaburhd42.cloudfront.net/258d015243ba2f396f4094aa401ea38b6a423984/1-Figure1-1.png
A Deeper Look at the Hessian Eigenspectrum of Deep Neural Networks and Its Applications to Regularization,"['Adepu Ravi', 'Yash Khasbage', 'Rahul Vigneswaran K', 'Vineeth N Balasubramanian']",,,,
Towards Balanced Defect Prediction with Better information Propagation,"['Xianda Zheng', 'Yuan-Fang Li ', 'Huan Gao', 'Yuncheng Hua', 'Guilin Qi']",,,,
Effective Slot Filling via Weakly-Supervised Dual-Model Learning,"['Jue Wang', 'Ke Chen', 'Lidan Shou', 'Sai Wu', 'Gang Chen']",,,,
MetaAugment: Sample-Aware Data Augmentation Policy Learning,"['Fengwei Zhou', 'Jiawei Li', 'Chuanlong Xie', 'Fei Chen', 'Lanqing Hong', 'Rui Sun', 'Zhenguo Li']",https://arxiv.org/abs/2012.12076,"Automated data augmentation has shown superior performance in image recognition. Existing works search for datasetlevel augmentation policies without considering individual sample variations, which are likely to be sub-optimal. On the other hand, learning different policies for different samples naively could greatly increase the computing cost. In this paper, we learn a sample-aware data augmentation policy efficiently by formulating it as a sample reweighting problem. Specifically, an augmentation policy network takes a transformation and the corresponding augmented image as inputs, and outputs a weight to adjust the augmented image loss computed by a task network. At training stage, the task network minimizes the weighted losses of augmented training images, while the policy network minimizes the loss of the task network on a validation set via meta-learning. We theoretically prove the convergence of the training procedure and further derive the exact convergence rate. Superior performance is achieved on widely-used benchmarks including CIFAR-10/100, Omniglot, and ImageNet. Introduction Data augmentation is widely used to increase the diversity of training data in order to improve model generalization (Krizhevsky, Sutskever, and Hinton 2012; Srivastava, Greff, and Schmidhuber 2015; Han, Kim, and Kim 2017; DeVries and Taylor 2017; Zhang et al. 2017; Yun et al. 2019). Automated data augmentation that searches for data-driven augmentation policies improves the performance of deep models in image recognition compared with the manually designed ones. A data augmentation policy is a distribution of transformations, according to which training samples are augmented. Reinforcement learning (Cubuk et al. 2019a; Zhang et al. 2020), population-based training (Ho et al. 2019), and Bayesian optimization (Lim et al. 2019) have been employed to learn augmentation policies from target datasets. Despite the difference of search algorithms, these approaches search for policies at the dataset level, i.e., all samples in the dataset are augmented with the same policy. For an image recognition task, left translation may be suitable for the image where *Equal Contribution Corresponding Author Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. the target object is on the right, but may not be suitable for the image where the target object is on the left (see Figure 4). According to this observation, dataset-level polices may give rise to various noises such as noisy labels, misalignment, or image distortion, since different samples vary greatly in object scale, position, color, illumination, etc. To increase data diversity while avoiding noises, it is appealing to learn a sample-aware data augmentation policy, i.e., learning different distributions of transformations for different samples. However, it is time-consuming to evaluate a large number of distributions and non-trivial to determine the relation among the distributions. Augmenting training samples with the corresponding policies, we consider the augmented sample loss as a random variable and train a task network to minimize the expectation of the augmented sample loss. From this perspective, learning a sample-aware policy can be regarded as reweighting the augmented sample losses and the computing cost can be greatly reduced. In this paper, we propose an efficient method, called MetaAugment, to learn a sample-aware data augmentation policy by formulating it as a sample reweighting problem. An overview of the proposed method is illustrated in Figure 1. Given a transformation and the corresponding augmented image feature, extracted by a task network, an augmentation policy network outputs the weight of the augmented image loss. The task network is optimized by minimizing the weighted training loss, while the goal of the policy network is to improve the performance of the task network on a validation set via adjusting the weights of the losses. This is a bilevel optimization problem (Colson, Marcotte, and Savard 2007) which is hard to be optimized. We leverage the mechanism of meta-learning (Finn, Abbeel, and Levine 2017; Li et al. 2017; Ren et al. 2018; Wu et al. 2018; Liu, Simonyan, and Yang 2019; Shu et al. 2019) to solve this problem. The motivation is based on the ability of meta-learning to extract useful knowledge from related tasks. During training, classification for each batch of samples is treated as a task. The policy network acts as a meta-learner to adapt the task network with the augmented samples such that it can perform well on a batch of validation samples. Instead of learning an initialization for fast adaptation in downstream tasks, the policy network learns to augment while guiding the actual training process of the task network. We also propose a novel transformation sampler that samples transformations accordar X iv :2 01 2. 12 07 6v 1 [ cs .L G ] 2 2 D ec 2 02 0",自動化されたデータ拡張は、画像認識において優れたパフォーマンスを示しています。既存の作品は、最適ではない可能性が高い個々のサンプルのバリエーションを考慮せずに、データセットレベルの拡張ポリシーを検索します。一方、サンプルごとに異なるポリシーを素朴に学習すると、コンピューティングコストが大幅に増加する可能性があります。この論文では、サンプルを再重み付けする問題として定式化することにより、サンプルを意識したデータ拡張ポリシーを効率的に学習します。具体的には、拡張ポリシーネットワークは、変換と対応する拡張画像を入力として受け取り、重みを出力して、タスクネットワークによって計算された拡張画像の損失を調整します。トレーニング段階では、タスクネットワークは拡張トレーニング画像の加重損失を最小限に抑え、ポリシーネットワークはメタ学習を介した検証セットでのタスクネットワークの損失を最小限に抑えます。トレーニング手順の収束を理論的に証明し、さらに正確な収束率を導き出します。 CIFAR-10 / 100、Omniglot、ImageNetなど、広く使用されているベンチマークで優れたパフォーマンスが実現されます。はじめにデータ拡張は、モデルの一般化を改善するためにトレーニングデータの多様性を高めるために広く使用されています（Krizhevsky、Sutskever、およびHinton 2012、Srivastava、Greff、およびSchmidhuber 2015、Han、Kim、およびKim 2017、DeVriesおよびTaylor 2017、Zhang et al.2017; Yun et al.2019）。データ駆動型拡張ポリシーを検索する自動データ拡張は、手動で設計されたものと比較して、画像認識におけるディープモデルのパフォーマンスを向上させます。データ拡張ポリシーは、トレーニングサンプルが拡張される変換の分布です。強化学習（Cubuketal。2019a; Zhang etal。2020）、人口ベースのトレーニング（Ho etal。2019）、およびベイズ最適化（Lim etal。2019）は、ターゲットデータセットから拡張ポリシーを学習するために採用されています。検索アルゴリズムの違いにもかかわらず、これらのアプローチはデータセットレベルでポリシーを検索します。つまり、データセット内のすべてのサンプルが同じポリシーで拡張されます。画像認識タスクの場合、左翻訳は、* Equal Contribution Corresponding Author Copyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）の画像に適している場合があります。全著作権所有。ターゲットオブジェクトは右側にありますが、ターゲットオブジェクトが左側にある画像には適さない場合があります（図4を参照）。この観察によれば、データセットレベルのポリシーは、オブジェクトのスケール、位置、色、照明などがサンプルごとに大きく異なるため、ノイズの多いラベル、位置ずれ、画像の歪みなどのさまざまなノイズを発生させる可能性があります。ノイズを回避しながらデータの多様性を高めるため、サンプル対応のデータ拡張ポリシーを学習すること、つまり、サンプルごとに変換のさまざまな分布を学習することは魅力的です。ただし、多数の分布を評価するのは時間がかかり、分布間の関係を判断するのは簡単ではありません。対応するポリシーを使用してトレーニングサンプルを拡張し、拡張されたサンプル損失を確率変数と見なし、タスクネットワークをトレーニングして、拡張されたサンプル損失の期待値を最小限に抑えます。この観点から、サンプル対応ポリシーを学習することは、拡張されたサンプル損失を再重み付けすることと見なすことができ、計算コストを大幅に削減できます。この論文では、MetaAugmentと呼ばれる効率的な方法を提案し、サンプルの再重み付け問題として定式化することにより、サンプルを意識したデータ拡張ポリシーを学習します。提案された方法の概要を図1に示します。タスクネットワークによって抽出された変換と対応する拡張画像の特徴が与えられると、拡張ポリシーネットワークは拡張画像損失の重みを出力します。タスクネットワークは、重み付きトレーニング損失を最小化することによって最適化されますが、ポリシーネットワークの目標は、損失の重みを調整することにより、検証セットでのタスクネットワークのパフォーマンスを向上させることです。これは、最適化が難しい2レベルの最適化問題（Colson、Marcotte、およびSavard 2007）です。メタ学習のメカニズム（Finn、Abbeel、およびLevine 2017; Li et al.2017; Ren et al.2018; Wu et al.2018; Liu、Simonyan、and Yang 2019; Shu et al.2019）を活用してこの問題を解決します。動機は、関連するタスクから有用な知識を抽出するメタ学習の能力に基づいています。トレーニング中、サンプルの各バッチの分類はタスクとして扱われます。ポリシーネットワークはメタラーナーとして機能し、検証サンプルのバッチで適切に実行できるように、タスクネットワークを拡張サンプルに適合させます。ポリシーネットワークは、ダウンストリームタスクでの高速適応のための初期化を学習する代わりに、タスクネットワークの実際のトレーニングプロセスをガイドしながら拡張することを学習します。また、変換アコーダーX iv：2 01 2. 12 07 6v 1 [cs .LG] 2 2 D ec 2 020をサンプリングする新しい変換サンプラーを提案します。,https://d3i71xaburhd42.cloudfront.net/951f0cd7a4b43623cb4ad7a4a6215ae0113eb0ab/2-Figure1-1.png
Nested Named Entity Recognition with Partially-Observed TreeCRFs,"['Yao Fu', 'Chuanqi Tan', 'Mosha Chen', 'Songfang Huang', 'Fei Huang']",https://arxiv.org/abs/2012.08478,"Named entity recognition (NER) is a well-studied task in natural language processing. However, the widely-used sequence labeling framework is difficult to detect entities with nested structures. In this work, we view nested NER as constituency parsing with partially-observed trees and model it with partially-observed TreeCRFs. Specifically, we view all labeled entity spans as observed nodes in a constituency tree, and other spans as latent nodes. With the TreeCRF we achieve a uniform way to jointly model the observed and the latent nodes. To compute the probability of partial trees with partial marginalization, we propose a variant of the Inside algorithm, the \textsc{Masked Inside} algorithm, that supports different inference operations for different nodes (evaluation for the observed, marginalization for the latent, and rejection for nodes incompatible with the observed) with efficient parallelized implementation, thus significantly speeding up training and inference. Experiments show that our approach achieves the state-of-the-art (SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable performance to SOTA models on the GENIA dataset. Our approach is implemented at: \url{this https URL}.",固有表現抽出（NER）は、自然言語処理でよく研究されているタスクです。ただし、広く使用されているシーケンスラベリングフレームワークは、ネストされた構造を持つエンティティを検出するのが困難です。この作業では、ネストされたNERを、部分的に観察されたツリーで解析する構成要素と見なし、部分的に観察されたTreeCRFでモデル化します。具体的には、ラベル付けされたすべてのエンティティスパンを構成ツリー内の観測ノードとして表示し、他のスパンを潜在ノードとして表示します。 TreeCRFを使用すると、観測ノードと潜在ノードを共同でモデル化するための統一された方法を実現できます。部分的な周縁化を伴う部分的なツリーの確率を計算するために、Insideアルゴリズムの変形であるMASKED INSIDEアルゴリズムを提案します。これは、異なるノードの異なる推論操作（観測されたものの評価、潜在的なものの周縁化、および互換性のないノードの拒否）をサポートします。観察された）効率的な並列化された実装により、トレーニングと推論が大幅に高速化されます。実験は、私たちのアプローチがACE2004、ACE2005データセットの最先端（SOTA）F1スコアを達成し、GENIAデータセットのSOTAモデルと同等のパフォーマンスを示すことを示しています。私たちのアプローチは、このhttpsURLで実装されています。,https://d3i71xaburhd42.cloudfront.net/5dfcc1f19a22c3bc081f2ff4410eb1efc7061838/1-Figure1-1.png
RareBERT: Transformer Architecture for Rare Disease Patient Identification Using Administrative Claims,"['PKS Prakash', 'Srinivas Chilukuri', 'Nikhil Ranade', 'Shankar Viswanathan']",,,,
Network Satisfaction for Symmetric Relation Algebras with a Flexible Atom,"['Manuel Bodirsky', 'Simon Knäuer']",https://arxiv.org/abs/2008.11943,"Robin Hirsch posed in 1996 the Really Big Complexity Problem: classify the computational complexity of the network satisfaction problem for all finite relation algebras $\bf A$. We provide a complete classification for the case that $\bf A$ is symmetric and has a flexible atom; the problem is in this case NP-complete or in P. If a finite integral relation algebra has a flexible atom, then it has a normal representation $\mathfrak{B}$. We can then study the computational complexity of the network satisfaction problem of ${\bf A}$ using the universal-algebraic approach, via an analysis of the polymorphisms of $\mathfrak{B}$. We also use a Ramsey-type result of Nesetřil and Rodl and a complexity dichotomy result of Bulatov for conservative finite-domain constraint satisfaction problems.",ロビン・ハーシュは1996年に本当に大きな複雑さの問題を提起しました：すべての有限関係代数$ \ bf A $のネットワーク満足度問題の計算の複雑さを分類します。 $ \ bf A $が対称であり、アトムが柔軟である場合の完全な分類を提供します。この場合、問題はNP完全またはPにあります。有限積分関係代数に柔軟なアトムがある場合、それは正規表現Bになります。次に、$ {\ bfAのネットワーク充足問題の計算の複雑さを調べることができます。 } $は、Bの多形性の分析を介して、普遍代数アプローチを使用します。また、保守的な有限領域制約充足問題に対して、ネセトリルとロドルのラムジー型の結果とブラトフの複雑さの二分法の結果を使用します。,https://d3i71xaburhd42.cloudfront.net/5e87cc954f66df7e916b2ee352312d5f17d8e604/5-Figure1-1.png
Do Response Selection Models Really Know What’s Next? Utterance Manipulation Strategies for Multi-Turn Response Selection,"['Taesun Whang', 'Dongyub Lee', 'Dongsuk Oh', 'Chanhee Lee', 'Kijong Han', 'Dong-hun Lee', 'Saebyeok Lee']",https://arxiv.org/abs/2009.04703,"In this paper, we study the task of selecting optimal response given user and system utterance history in retrieval-based multi-turn dialog systems. Recently, pre-trained language models (e.g., BERT, RoBERTa, and ELECTRA) have shown significant improvements in various natural language processing tasks. This and similar response selection tasks can also be solved using such language models by formulating them as dialog-response binary classification tasks. Although existing works using this approach successfully obtained state-of-the-art results, we observe that language models trained in this manner tend to make predictions based on the relatedness of history and candidates, ignoring the sequential nature of multi-turn dialog systems. This suggests that the response selection task alone is insufficient in learning temporal dependencies between utterances. To this end, we propose utterance manipulation strategies (UMS) to address this problem. Specifically, UMS consist of several strategies (i.e., insertion, deletion, and search), which aid the response selection model towards maintaining dialog coherence. Further, UMS are self-supervised methods that do not require additional annotation and thus can be easily incorporated into existing approaches. Extensive evaluation across multiple languages and models shows that UMS are highly effective in teaching dialog consistency, which lead to models pushing the state-of-the-art with significant margins on multiple public benchmark datasets.",この論文では、検索ベースのマルチターンダイアログシステムで、ユーザーとシステムの発話履歴を考慮して最適な応答を選択するタスクを研究します。最近、事前にトレーニングされた言語モデル（BERT、RoBERTa、ELECTRAなど）は、さまざまな自然言語処理タスクで大幅な改善を示しています。これと同様の応答選択タスクは、ダイアログ応答バイナリ分類タスクとして定式化することにより、そのような言語モデルを使用して解決することもできます。このアプローチを使用した既存の作品は最先端の結果を得ることに成功しましたが、この方法でトレーニングされた言語モデルは、マルチターンダイアログシステムのシーケンシャルな性質を無視して、履歴と候補の関連性に基づいて予測を行う傾向があることがわかります。これは、応答選択タスクだけでは、発話間の時間的依存関係を学習するには不十分であることを示唆しています。この目的のために、この問題に対処するための発話操作戦略（UMS）を提案します。具体的には、UMSはいくつかの戦略（つまり、挿入、削除、検索）で構成されており、ダイアログの一貫性を維持するための応答選択モデルを支援します。さらに、UMSは、追加の注釈を必要としない自己監視方式であるため、既存のアプローチに簡単に組み込むことができます。複数の言語とモデルにわたる広範な評価は、UMSがダイアログの一貫性を教えるのに非常に効果的であることを示しています。これにより、モデルは複数の公開ベンチマークデータセットで大幅なマージンを持って最先端を推進します。,https://d3i71xaburhd42.cloudfront.net/9eda9bbb3317452646e23f8341e5a4e5c7e73c58/1-Figure1-1.png
Balanced Open Set Domain Adaptation via Centroid Alignment,"['Mengmeng Jing', 'Jingjing Li', 'Lei Zhu', 'Zhengming Ding', 'Ke Lu', 'Yang Yang']",,,,
Learning Monocular Depth in Dynamic Scenes via Instance-Aware Projection Consistency,"['Seokju Lee', 'Sunghoon Im', 'Stephen Lin', 'In So Kweon']",,,,
A Few Queries Go a Long Way: Information-Distortion Tradeoffs in Matching,"['Georgios Amanatidis', 'Georgios Birmpas', 'Aris Filos-Ratsikas', 'Alexandros Voudouris']",,,,
Demodalizing Face Recognition with Synthetic Samples,"['Zhonghua Zhai', 'Pengju Yang', 'Xiaofeng Zhang', 'Maji Huang', 'Haijing Cheng', 'Xuejun Yan', 'Chunmao Wang', 'Shiliang Pu']",,,,
Escaping Local Optima with Non-Elitist Evolutionary Algorithms,"['Duc-Cuong Dang', 'Anton Eremeev', 'Per Kristian Lehre']",,,,
Audio-Visual Localization by Synthetic Acoustic Image Generation,"['Valentina Sanguineti', 'Pietro Morerio', 'Alessio Del Bue', 'Vittorio Murino']",,,,
Differential Spectral Normalization (DSN) for PDE Discovery,"['Chi Chiu So', 'Tsz On Li', 'Chufang Wu', 'Siu Pang Yung']",,,,
Correlation-Aware Heuristic Search for Intelligent Virtual Machine Provisioning in Cloud Systems,"['Chuan Luo', 'Bo Qiao', 'Wenqian Xing', 'Xin Chen', 'Pu Zhao', 'Chao Du', 'Randolph Yao', 'Hongyu Zhang', 'Wei Wu', 'Shaowei Cai', 'Bing He', 'Saravanakumar Rajmohan', 'Qingwei Lin']",,,,
Slimmable Generative Adversarial Networks,"['Liang Hou', 'Zehuan Yuan', 'Lei Huang', 'Huawei Shen', 'Xueqi Cheng', 'Changhu Wang']",https://arxiv.org/abs/2012.05660,"Generative adversarial networks (GANs) have achieved remarkable progress in recent years, but the continuously growing scale of models make them challenging to deploy widely in practical applications. In particular, for real-time generation tasks, different devices require generators of different sizes due to varying computing power. In this paper, we introduce slimmable GANs (SlimGANs), which can flexibly switch the width of the generator to accommodate various quality-efficiency trade-offs at runtime. Specifically, we leverage multiple discriminators that share partial parameters to train the slimmable generator. To facilitate the consistency between generators of different widths, we present a stepwise inplace distillation technique that encourages narrow generators to learn from wide ones. As for class-conditional generation, we propose a sliceable conditional batch normalization that incorporates the label information into different widths. Our methods are validated, both quantitatively and qualitatively, by extensive experiments and a detailed ablation study.",生成的敵対的ネットワーク（GAN）は近年目覚ましい進歩を遂げていますが、モデルの規模が継続的に拡大しているため、実際のアプリケーションに広く展開することは困難です。特に、リアルタイムの生成タスクの場合、計算能力が異なるため、デバイスごとに異なるサイズのジェネレータが必要になります。このホワイトペーパーでは、実行時にさまざまな品質と効率のトレードオフに対応するために、ジェネレータの幅を柔軟に切り替えることができるスリム化可能なGAN（SlimGAN）を紹介します。具体的には、部分的なパラメーターを共有する複数の弁別器を活用して、スリム化可能なジェネレーターをトレーニングします。異なる幅の発電機間の一貫性を促進するために、狭い発電機が広い発電機から学ぶことを奨励する段階的なインプレース蒸留技術を提示します。クラス条件付き生成に関しては、ラベル情報をさまざまな幅に組み込むスライス可能な条件付きバッチ正規化を提案します。私たちの方法は、広範な実験と詳細なアブレーション研究によって、定量的および定性的に検証されています。,https://d3i71xaburhd42.cloudfront.net/ead9eae16aa288cc2d8a0b07cc4b86f4a16e3e96/3-Figure1-1.png
Towards Consumer Loan Fraud Detection: Graph Neural Networks with Role-Constrained Conditional Random Field,"['Bingbing Xu', 'Huawei Shen', 'Rong An', 'Bingjie Sun', 'Qi Cao', 'Xueqi Cheng']",,,,
Disposable Linear Bandits for Online Recommendations,"['Melda Korkut', 'Andrew Li']",,,,
Parameterized Complexity of Logic-Based Argumentation in Schaefer's Framework,"['Yasir Mahmood', 'Arne Meier', 'Johannes Schmidt']",,,,
Consistency and Finite Sample Behavior of Binary Class Probability Estimation,"['Alexander Mey', 'Marco Loog']",https://arxiv.org/abs/1908.11823,"In this work we investigate to which extent one can recover class probabilities within the empirical risk minimization (ERM) paradigm. The main aim of our paper is to extend existing results and emphasize the tight relations between empirical risk minimization and class probability estimation. Based on existing literature on excess risk bounds and proper scoring rules, we derive a class probability estimator based on empirical risk minimization. We then derive fairly general conditions under which this estimator will converge, in the L1-norm and in probability, to the true class probabilities. Our main contribution is to present a way to derive finite sample L1-convergence rates of this estimator for different surrogate loss functions. We also study in detail which commonly used loss functions are suitable for this estimation problem and finally discuss the setting of model-misspecification as well as a possible extension to asymmetric loss functions.",この作業では、経験的リスク最小化（ERM）パラダイム内でクラス確率をどの程度回復できるかを調査します。私たちの論文の主な目的は、既存の結果を拡張し、経験的リスクの最小化とクラス確率推定の間の緊密な関係を強調することです。超過リスク限界と適切なスコアリングルールに関する既存の文献に基づいて、経験的なリスク最小化に基づいてクラス確率推定量を導き出します。次に、この推定量がL1ノルムで、確率で真のクラス確率に収束するかなり一般的な条件を導き出します。私たちの主な貢献は、さまざまな代理損失関数に対するこの推定量の有限サンプルL1収束率を導出する方法を提示することです。また、一般的に使用されるどの損失関数がこの推定問題に適しているかを詳細に調査し、最後にモデルの仕様ミスの設定と非対称損失関数への拡張の可能性について説明します。,https://d3i71xaburhd42.cloudfront.net/2d5387d98173c089f87f48642b1cd0fe582a7209/5-Figure1-1.png
Restricted Domains of Dichotomous Preferences with Possibly Incomplete Information,"['Zoi Terzopoulou', 'Alexander Karpov', 'Svetlana Obraztsova']",,"Restricted domains have been extensively studied within computational social choice, initially for voters’ preferences that are total orders over the set of alternatives and subsequently for preferences that are dichotomous—i.e., that correspond to approved and disapproved alternatives. We contribute to the latter stream of work. We obtain forbidden subprofile characterisations for various important dichotomous domains, and we also study profiles with incomplete information about the voters’ preferences. Specifically, we design polynomial algorithms to determine whether such incomplete profiles admit completions within certain restricted domains. ACM Reference Format: Zoi Terzopoulou, Alexander Karpov, and Svetlana Obraztsova. 2020. Restricted Domains of Dichotomous Preferences with Possibly Incomplete Information. In Proc. of the 19th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2020), Auckland, New Zealand, May 9–13, 2020, IFAAMAS, 3 pages.",制限されたドメインは、計算による社会的選択の範囲内で広く研究されてきました。最初は、一連の選択肢に対する全順序である有権者の選好について、その後、二分された、つまり承認および不承認の選択肢に対応する選好についてです。私たちは後者の仕事の流れに貢献します。さまざまな重要な二分ドメインの禁止されたサブプロファイルの特性を取得し、有権者の好みに関する情報が不完全なプロファイルも調査します。具体的には、そのような不完全なプロファイルが特定の制限されたドメイン内での完了を許可するかどうかを判断するための多項式アルゴリズムを設計します。 ACM参照形式：Zoi Terzopoulou、Alexander Karpov、およびSvetlanaObrazztsova。 2020.情報が不完全である可能性のある二分された設定の制限されたドメイン。 Proc。自律エージェントとマルチエージェントシステムに関する第19回国際会議（AAMAS 2020）、ニュージーランド、オークランド、2020年5月913日、IFAAMAS、3ページ。,https://d3i71xaburhd42.cloudfront.net/89f24fbc114126ed3b3f26ab7a04116e0220f710/2-Figure2-1.png
Efficient Truthful Scheduling and Resource Allocation through Monitoring,"['Dimitris Fotakis', 'Piotr Krysta', 'Carmine Ventre']",,,,
"Counterfactual Explanations for Oblique Decision Trees: Exact, Efficient Algorithms","['Miguel A Carreira-Perpinan', 'Suryabhan Singh Hada']",,,,
Online Posted Pricing with Unknown Time-Discounted Valuations,"['Giulia Romano', 'Alberto Marchesi', 'Gianluca Tartaglia', 'Nicola Gatti']",https://arxiv.org/abs/2012.05774,"We study the problem of designing posted-price mechanisms in order to sell a single unit of a single item within a finite period of time. Motivated by real-world problems, such as, e.g., long-term rental of rooms and apartments, we assume that customers arrive online according to a Poisson process, and their valuations are drawn from an unknown distribution and discounted over time. We evaluate our mechanisms in terms of competitive ratio, measuring the worst-case ratio between their revenue and that of an optimal mechanism that knows the distribution of valuations. First, we focus on the identical valuation setting, where all the customers value the item for the same amount. In this setting, we provide a mechanism M_c that achieves the best possible competitive ratio, discussing its dependency on the parameters in the case of linear discount. Then, we switch to the random valuation setting. We show that, if we restrict the attention to distributions of valuations with a monotone hazard rate, then the competitive ratio of M_c is lower bounded by a strictly positive constant that does not depend on the distribution. Moreover, we provide another mechanism, called M_pc, which is defined by a piecewise constant pricing strategy and reaches performances comparable to those obtained with M_c. This mechanism is useful when the seller cannot change the posted price too often. Finally, we empirically evaluate the performances of our mechanisms in a number of experimental settings.",有限の期間内に単一のアイテムの単一のユニットを販売するために、ポスト価格メカニズムを設計する問題を研究します。部屋やアパートの長期賃貸などの現実の問題に動機付けられて、顧客はポアソン過程に従ってオンラインに到着し、その評価は未知の分布から引き出され、時間の経過とともに割引されると想定しています。メカニズムを競争力の観点から評価し、収益と評価の分布を知っている最適なメカニズムの収益との間の最悪の場合の比率を測定します。まず、すべての顧客が同じ金額でアイテムを評価する、同一の評価設定に焦点を当てます。この設定では、可能な限り最高の競争率を達成するメカニズムM_cを提供し、線形割引の場合のパラメーターへの依存性について説明します。次に、ランダム評価設定に切り替えます。単調なハザード率の評価の分布に注意を限定すると、M_cの競合率は、分布に依存しない厳密に正の定数によって下限が定められることを示します。さらに、区分的に一定の価格設定戦略によって定義され、M_cで得られるパフォーマンスに匹敵するパフォーマンスに到達するM_pcと呼ばれる別のメカニズムを提供します。このメカニズムは、売り手が転記価格を頻繁に変更できない場合に役立ちます。最後に、いくつかの実験設定でメカニズムのパフォーマンスを経験的に評価します。,https://d3i71xaburhd42.cloudfront.net/be8c1fa8bc4181b345cb56cc7cbbc32e289ca94b/6-Figure1-1.png
Joint Air Quality and Weather Prediction Based on Multi-Adversarial Spatiotemporal Networks,"['Jindong Han', 'Hao Liu', 'Hengshu Zhu', 'Hui Xiong', 'Dejing Dou']",https://arxiv.org/abs/2012.15037,"Accurate and timely air quality and weather predictions are of great importance to urban governance and human livelihood. Though many efforts have been made for air quality or weather prediction, most of them simply employ one another as feature input, which ignores the inner-connection between two predictive tasks. On the one hand, the accurate prediction of one task can help improve another task’s performance. On the other hand, geospatially distributed air quality and weather monitoring stations provide additional hints for city-wide spatiotemporal dependency modeling. Inspired by the above two insights, in this paper, we propose the Multi-adversarial spatiotemporal recurrent Graph Neural Networks (MasterGNN) for joint air quality and weather predictions. Specifically, we first propose a heterogeneous recurrent graph neural network to model the spatiotemporal autocorrelation among air quality and weather monitoring stations. Then, we develop a multi-adversarial graph learning framework to against observation noise propagation introduced by spatiotemporal modeling. Moreover, we present an adaptive training strategy by formulating multi-adversarial learning as a multi-task learning problem. Finally, extensive experiments on two real-world datasets show that MasterGNN achieves the best performance compared with seven baselines on both air quality and weather prediction tasks.",正確でタイムリーな大気質と天気予報は、都市の統治と人間の生活にとって非常に重要です。大気質や天気予報には多くの努力が払われてきましたが、それらのほとんどは、2つの予測タスク間の内部接続を無視して、機能入力として相互に使用するだけです。一方では、あるタスクを正確に予測することで、別のタスクのパフォーマンスを向上させることができます。一方、地理空間的に分散された大気質および気象監視ステーションは、都市全体の時空間依存性モデリングのための追加のヒントを提供します。上記の2つの洞察に触発されて、この論文では、共同の大気質と天気予報のためのマルチ敵対的時空間反復グラフニューラルネットワーク（MasterGNN）を提案します。具体的には、まず、大気質と気象監視ステーション間の時空間自己相関をモデル化するために、異種の反復グラフニューラルネットワークを提案します。次に、時空間モデリングによって導入された観測ノイズの伝播に対抗するために、複数の敵対的なグラフ学習フレームワークを開発します。さらに、マルチタスク学習問題としてマルチ敵対的学習を定式化することにより、適応トレーニング戦略を提示します。最後に、2つの実世界のデータセットでの広範な実験により、MasterGNNは、大気質と天気予報の両方のタスクで7つのベースラインと比較して最高のパフォーマンスを達成することが示されています。,https://d3i71xaburhd42.cloudfront.net/ed360bb72d67d7ae7aae80841137cb9cb34d6978/1-Figure1-1.png
Fitting the Search Space of Weight-Sharing NAS with Graph Convolutional Networks,"['Xin Chen', 'Lingxi Xie', 'Jun Wu', 'Longhui Wei', 'Yuhui Xu', 'Qi Tian']",https://arxiv.org/abs/2004.08423,"Neural architecture search has attracted wide attentions in both academia and industry. To accelerate it, researchers proposed weight-sharing methods which first train a super-network to reuse computation among different operators, from which exponentially many sub-networks can be sampled and efficiently evaluated. These methods enjoy great advantages in terms of computational costs, but the sampled sub-networks are not guaranteed to be estimated precisely unless an individual training process is taken. This paper owes such inaccuracy to the inevitable mismatch between assembled network layers, so that there is a random error term added to each estimation. We alleviate this issue by training a graph convolutional network to fit the performance of sampled sub-networks so that the impact of random errors becomes minimal. With this strategy, we achieve a higher rank correlation coefficient in the selected set of candidates, which consequently leads to better performance of the final architecture. In addition, our approach also enjoys the flexibility of being used under different hardware constraints, since the graph convolutional network has provided an efficient lookup table of the performance of architectures in the entire search space.",ニューラルアーキテクチャの検索は、学界と産業界の両方で幅広い注目を集めています。それを加速するために、研究者は、最初にスーパーネットワークをトレーニングして異なる演算子間で計算を再利用する重み共有方法を提案しました。この方法から、指数関数的に多くのサブネットワークをサンプリングして効率的に評価できます。これらの方法は、計算コストの点で大きな利点がありますが、個別のトレーニングプロセスを実行しない限り、サンプリングされたサブネットワークが正確に推定されるとは限りません。この論文は、組み立てられたネットワーク層間の不可避の不一致にそのような不正確さがあるため、各推定にランダム誤差項が追加されています。ランダムエラーの影響が最小限になるように、サンプリングされたサブネットワークのパフォーマンスに合うようにグラフ畳み込みネットワークをトレーニングすることで、この問題を軽減します。この戦略により、選択した候補のセットでより高いランク相関係数を達成し、その結果、最終的なアーキテクチャのパフォーマンスが向上します。さらに、グラフ畳み込みネットワークが検索空間全体のアーキテクチャのパフォーマンスの効率的なルックアップテーブルを提供しているため、このアプローチは、さまざまなハードウェア制約の下で使用できる柔軟性も備えています。,https://d3i71xaburhd42.cloudfront.net/dc04a0ba0f01448874c5e5d1ec4f133c431df45f/5-Figure1-1.png
Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness,"['Anh Tuan Bui', 'Trung Le', 'He Zhao', 'Paul Montague', 'Olivier DeVel', 'Tamas Abraham', 'Dinh Phung']",https://arxiv.org/abs/2009.09612,"Ensemble-based adversarial training is a principled approach to achieve robustness against adversarial attacks. An important technique of this approach is to control the transferability of adversarial examples among ensemble members. We propose in this work a simple yet effective strategy to collaborate among committee models of an ensemble model. This is achieved via the secure and insecure sets defined for each model member on a given sample, hence help us to quantify and regularize the transferability. Consequently, our proposed framework provides the flexibility to reduce the adversarial transferability as well as to promote the diversity of ensemble members, which are two crucial factors for better robustness in our ensemble approach. We conduct extensive and comprehensive experiments to demonstrate that our proposed method outperforms the state-of-the-art ensemble baselines, at the same time can detect a wide range of adversarial examples with a nearly perfect accuracy.",アンサンブルベースの敵対的トレーニングは、敵対的攻撃に対する堅牢性を実現するための原則的なアプローチです。このアプローチの重要な手法は、アンサンブルメンバー間での敵対的な例の転送可能性を制御することです。この作業では、アンサンブルモデルの委員会モデル間でコラボレーションするためのシンプルで効果的な戦略を提案します。これは、特定のサンプルの各モデルメンバーに対して定義された安全なセットと安全でないセットを介して実現されるため、転送可能性を定量化して正規化するのに役立ちます。その結果、提案されたフレームワークは、敵対的な移転可能性を減らし、アンサンブルメンバーの多様性を促進する柔軟性を提供します。これは、アンサンブルアプローチの堅牢性を高めるための2つの重要な要素です。提案された方法が最先端のアンサンブルベースラインを上回り、同時にほぼ完全な精度でさまざまな敵対的な例を検出できることを実証するために、広範囲にわたる包括的な実験を実施します。,https://d3i71xaburhd42.cloudfront.net/afcc1ebe56fdfb5d247cd4e7062b1d41bc5fd8ae/7-Figure1-1.png
Aligning Artificial Neural Networks and Ontologies Towards Explainable AI,"['Manuel de Sousa Ribeiro', 'João Leite']",,,,
Exploratory Machine Learning with Unknown Unknowns,"['Peng Zhao', 'Yu-Jie Zhang', 'Zhi-Hua Zhou']",,,,
Learning from History: Modeling Temporal Knowledge Graphs with Sequential Copy-Generation Networks,"['Cunchao Zhu', 'Muhao Chen', 'Changjun Fan', 'Guangquan Cheng', 'Yan Zhang']",https://arxiv.org/abs/2012.08492,"Large knowledge graphs often grow to store temporal facts that model the dynamic relations or interactions of entities along the timeline. Since such temporal knowledge graphs often suffer from incompleteness, it is important to develop time-aware representation learning models that help to infer the missing temporal facts. While the temporal facts are typically evolving, it is observed that many facts often show a repeated pattern along the timeline, such as economic crises and diplomatic activities. This observation indicates that a model could potentially learn much from the known facts appeared in history. To this end, we propose a new representation learning model for temporal knowledge graphs, namely CyGNet, based on a novel timeaware copy-generation mechanism. CyGNet is not only able to predict future facts from the whole entity vocabulary, but also capable of identifying facts with repetition and accordingly predicting such future facts with reference to the known facts in the past. We evaluate the proposed method on the knowledge graph completion task using five benchmark datasets. Extensive experiments demonstrate the effectiveness of CyGNet for predicting future facts with repetition as well as de novo fact prediction.",大規模な知識グラフは、タイムラインに沿ったエンティティの動的な関係または相互作用をモデル化する時間的事実を格納するために成長することがよくあります。このような時間知識グラフは不完全であることが多いため、欠落している時間的事実を推測するのに役立つ時間認識表現学習モデルを開発することが重要です。時間的事実は通常進化していますが、経済危機や外交活動など、多くの事実がタイムラインに沿って繰り返されるパターンを示すことがよくあります。この観察結果は、モデルが歴史に登場する既知の事実から多くを学ぶ可能性があることを示しています。この目的のために、我々は、新しい時間認識コピー生成メカニズムに基づいて、時間的知識グラフのための新しい表現学習モデル、すなわちCyGNetを提案する。 CyGNetは、エンティティの語彙全体から将来の事実を予測できるだけでなく、繰り返して事実を識別し、それに応じて過去の既知の事実を参照してそのような将来の事実を予測することもできます。 5つのベンチマークデータセットを使用して、知識グラフ完了タスクで提案された方法を評価します。広範な実験により、CyGNetが、繰り返しのある将来の事実を予測すること、およびdenovoの事実を予測することの有効性が実証されています。,https://d3i71xaburhd42.cloudfront.net/40cfa0263e7d39d4a61cfcb844a5093c8c283152/1-Figure1-1.png
Multi-Scale Graph Fusion for Co-Saliency Detection,"['Rongyao Hu', 'Zhenyun Deng', 'Xiaofeng Zhu']",,,,
PointINet: Point Cloud Frame Interpolation Network,"['Fan Lu', 'Guang Chen', 'Sanqing Qu', 'Zhijun Li', 'Yinlong Liu', 'Alois Knoll']",https://arxiv.org/abs/2012.10066,"LiDAR point cloud streams are usually sparse in time dimension, which is limited by hardware performance. Generally, the frame rates of mechanical LiDAR sensors are 10 to 20 Hz, which is much lower than other commonly used sensors like cameras. To overcome the temporal limitations of LiDAR sensors, a novel task named Point Cloud Frame Interpolation is studied in this paper. Given two consecutive point cloud frames, Point Cloud Frame Interpolation aims to generate intermediate frame(s) between them. To achieve that, we propose a novel framework, namely Point Cloud Frame Interpolation Network (PointINet). Based on the proposed method, the low frame rate point cloud streams can be upsampled to higher frame rates. We start by estimating bi-directional 3D scene flow between the two point clouds and then warp them to the given time step based on the 3D scene flow. To fuse the two warped frames and generate intermediate point cloud(s), we propose a novel learning-based points fusion module, which simultaneously takes two warped point clouds into consideration. We design both quantitative and qualitative experiments to evaluate the performance of the point cloud frame interpolation method and extensive experiments on two large scale outdoor LiDAR datasets demonstrate the effectiveness of the proposed PointINet. Our code is available at https://github.com/ispc-lab/PointINet.git.",LiDARポイントクラウドストリームは通常、時間次元がまばらであり、ハードウェアのパフォーマンスによって制限されます。一般に、機械式LiDARセンサーのフレームレートは10〜20 Hzであり、カメラなどの他の一般的に使用されるセンサーよりもはるかに低くなっています。 LiDARセンサーの時間的制限を克服するために、この論文では点群フレーム補間という名前の新しいタスクを研究します。 2つの連続するポイントクラウドフレームが与えられた場合、ポイントクラウドフレーム補間は、それらの間に中間フレームを生成することを目的としています。これを実現するために、新しいフレームワーク、つまりポイントクラウドフレーム補間ネットワーク（PointINet）を提案します。提案された方法に基づいて、低フレームレートの点群ストリームをより高いフレームレートにアップサンプリングすることができます。まず、2つの点群間の双方向の3Dシーンフローを推定し、3Dシーンフローに基づいて指定されたタイムステップにワープします。 2つのワープフレームを融合し、中間点群を生成するために、2つのワープポイントクラウドを同時に考慮に入れる、新しい学習ベースのポイント融合モジュールを提案します。点群フレーム補間法のパフォーマンスを評価するために、定量的および定性的な実験の両方を設計し、2つの大規模な屋外LiDARデータセットでの広範な実験により、提案されたPointINetの有効性が実証されます。私たちのコードはhttps://github.com/ispc-lab/PointINet.gitで入手できます。,https://d3i71xaburhd42.cloudfront.net/b7e6377d5d5d42c8b06a197465a281624dca8a4d/1-Figure1-1.png
Community-Aware Multi-Task Transportation Demand Prediction,"['Hao Liu', 'Qiyu Wu', 'Fuzhen Zhuang', 'Xinjiang Lu', 'Dejing Dou', 'Hui Xiong']",,,,
More the Merrier: Towards Multi-Emotion and Intensity Controllable Response Generation,"['Mauajama Firdaus', 'Hardik Chauhan', 'Asif Ekbal', 'Pushpak Bhattacharyya']",,,,
Computing Plan-Length Bounds Using Lengths of Longest Paths,"['Mohammad Abdulaziz', 'Dominik Berger']",https://arxiv.org/abs/2006.01011,"We devise a method to exactly compute the length of the longest simple path in factored state spaces, like state spaces encountered in classical planning. Although the complexity of this problem is NEXP-Hard, we show that our method can be used to compute practically useful upper-bounds on lengths of plans. We show that the computed upper-bounds are significantly (in many cases, orders of magnitude) better than bounds produced by previous bounding techniques and that they can be used to improve the SAT-based planning.",古典的な計画で遭遇する状態空間のように、因数分解された状態空間で最も長い単純なパスの長さを正確に計算する方法を考案します。この問題の複雑さはNEXP-Hardですが、私たちの方法を使用して、計画の長さの実際に役立つ上限を計算できることを示します。計算された上限は、以前の境界手法によって生成された境界よりも大幅に（多くの場合、桁違いに）優れており、SATベースの計画を改善するために使用できることを示しています。,https://d3i71xaburhd42.cloudfront.net/2c2f88d30d6e545ad736ab3766813af2418ceb92/2-Figure1-1.png
Pareto Optimization for Subset Selection with Dynamic Partition Matroid Constraints,"['Anh V Do', 'Frank Neumann']",,,,
DeepTrader: A Deep Reinforcement Learning Approach for Risk-Return Balanced Portfolio Management with Market Conditions Embedding,"['Zhicheng Wang', 'Biwei Huang', 'Shikui Tu', 'Kun Zhang', 'Lei Xu']",,,,
Going Deeper with Directly-Trained Larger Spiking Neural Networks,"['Hanle Zheng', 'Guoqi Li', 'Yujie Wu', 'Lei Deng', 'Yifan Hu']",https://arxiv.org/abs/2011.05280,"Spiking neural networks (SNNs) are promising in a bio-plausible coding for spatio-temporal information and event-driven signal processing, which is very suited for energy-efficient implementation in neuromorphic hardware. However, the unique working mode of SNNs makes them more difficult to train than traditional networks. Currently, there are two main routes to explore the training of deep SNNs with high performance. The first is to convert a pre-trained ANN model to its SNN version, which usually requires a long coding window for convergence and cannot exploit the spatio-temporal features during training for solving temporal tasks. The other is to directly train SNNs in the spatio-temporal domain. But due to the binary spike activity of the firing function and the problem of gradient vanishing or explosion, current methods are restricted to shallow architectures and thereby difficult in harnessing large-scale datasets (e.g. ImageNet). To this end, we propose a threshold-dependent batch normalization (tdBN) method based on the emerging spatio-temporal backpropagation, termed ""STBP-tdBN"", enabling direct training of a very deep SNN and the efficient implementation of its inference on neuromorphic hardware. With the proposed method and elaborated shortcut connection, we significantly extend directly-trained SNNs from a shallow structure ( < 10 layer) to a very deep structure (50 layers). Furthermore, we theoretically analyze the effectiveness of our method based on ""Block Dynamical Isometry"" theory. Finally, we report superior accuracy results including 93.15 % on CIFAR-10, 67.8 % on DVS-CIFAR10, and 67.05% on ImageNet with very few timesteps. To our best knowledge, it's the first time to explore the directly-trained deep SNNs with high performance on ImageNet.",スパイキングニューラルネットワーク（SNN）は、時空間情報とイベント駆動型信号処理の生物学的に妥当なコーディングで有望であり、ニューロモーフィックハードウェアでのエネルギー効率の高い実装に非常に適しています。ただし、SNNの独自の動作モードにより、従来のネットワークよりもトレーニングが困難になります。現在、高性能のディープSNNのトレーニングを探索するための2つの主要なルートがあります。 1つ目は、事前にトレーニングされたANNモデルをSNNバージョンに変換することです。これは通常、収束のために長いコーディングウィンドウを必要とし、時間的タスクを解決するためのトレーニング中に時空間機能を活用できません。もう1つは、時空間ドメインでSNNを直接トレーニングすることです。しかし、発火関数のバイナリスパイクアクティビティと勾配消失または爆発の問題により、現在の方法は浅いアーキテクチャに制限されており、大規模なデータセット（ImageNetなど）を利用することは困難です。この目的のために、「STBP-tdBN」と呼ばれる新たな時空間バックプロパゲーションに基づくしきい値依存バッチ正規化（tdBN）法を提案し、非常に深いSNNの直接トレーニングと、ニューロモーフィックハードウェアでの推論の効率的な実装を可能にします。 。提案された方法と精巧なショートカット接続を使用して、直接トレーニングされたSNNを浅い構造（&lt;10層）から非常に深い構造（50層）に大幅に拡張します。さらに、「ブロック動的等長写像」理論に基づいて、本手法の有効性を理論的に分析します。最後に、93.15を含む優れた精度の結果を報告します,https://d3i71xaburhd42.cloudfront.net/e5ac393af264eb99484973c565ce2e1f12c85e18/3-Figure1-1.png
Differentiable Inductive Logic Programming for Structured Examples,"['Hikaru Shindo', 'Masaaki Nishino', 'Akihiro Yamamoto']",,,,
Memory-Gated Recurrent Networks,"['Yaquan Zhang', 'Qi Wu', 'Nanbo Peng', 'Min Dai', 'Jing Zhang', 'Hu Wang']",https://arxiv.org/abs/2012.13121,"The essence of multivariate sequential learning is all about how to extract dependencies in data. These data sets, such as hourly medical records in intensive care units and multifrequency phonetic time series, often time exhibit not only strong serial dependencies in the individual components (the “marginal” memory) but also non-negligible memories in the cross-sectional dependencies (the “joint” memory). Because of the multivariate complexity in the evolution of the joint distribution that underlies the data generating process, we take a data-driven approach and construct a novel recurrent network architecture, termed Memory-Gated Recurrent Networks (mGRN), with gates explicitly regulating two distinct types of memories: the marginal memory and the joint memory. Through a combination of comprehensive simulation studies and empirical experiments on a range of public datasets, we show that our proposed mGRN architecture consistently outperforms state-of-the-art architectures targeting multivariate time series.",多変量シーケンシャル学習の本質は、データの依存関係を抽出する方法にあります。集中治療室の1時間ごとの医療記録や多周波音声時系列などのこれらのデータセットは、多くの場合、個々のコンポーネント（限界記憶）の強い連続依存性だけでなく、断面依存性（共同記憶）。データ生成プロセスの根底にある同時分布の進化における多変量の複雑さのために、データ駆動型アプローチを採用し、メモリゲートリカレントネットワーク（mGRN）と呼ばれる新しいリカレントネットワークアーキテクチャを構築します。ゲートは2つの異なる記憶の種類：限界記憶と共同記憶。包括的なシミュレーション研究とさまざまな公開データセットでの経験的実験を組み合わせることにより、提案されたmGRNアーキテクチャが、多変量時系列を対象とした最先端のアーキテクチャよりも一貫して優れていることを示します。,https://d3i71xaburhd42.cloudfront.net/0d8ff0e190ca20c7158675312fc71cd75c6b5270/3-Figure1-1.png
Contrastive Self-Supervised Learning for Graph Classification,"['Jiaqi Zeng', 'Pengtao Xie']",,,,
Reinforcement Learning with a Disentangled Universal Value Function for Item Recommendation,"['Kai Wang', 'Zhene Zou', 'Qilin Deng', 'Jianrong Tao', 'Runze Wu', 'Changjie Fan', 'Liang Chen', 'Peng Cui']",,,,
Certifying Parity Reasoning Efficiently Using Pseudo-Boolean Proofs,"['Stephan Gocht', 'Jakob Nordström']",,"The dramatic improvements in combinatorial optimization algorithms over the last decades have had a major impact in artificial intelligence, operations research, and beyond, but the output of current state-of-the-art solvers is often hard to verify and is sometimes wrong. For Boolean satisfiability (SAT) solvers proof logging has been introduced as a way to certify correctness, but the methods used seem hard to generalize to stronger paradigms. What is more, even for enhanced SAT techniques such as parity (XOR) reasoning, cardinality detection, and symmetry handling, it has remained beyond reach to design practically efficient proofs in the standard DRAT format. In this work, we show how to instead use pseudo-Boolean inequalities with extension variables to concisely justify XOR reasoning. Our experimental evaluation of a SAT solver integration shows a dramatic decrease in proof logging and verification time compared to existing DRAT methods. Since our method is a strict generalization of DRAT , and readily lends itself to expressing also 0-1 programming and even constraint programming problems, we hope this work points the way towards a unified approach for efficient machine-verifiable proofs for a rich class of combinatorial optimization paradigms.",過去数十年にわたる組み合わせ最適化アルゴリズムの劇的な改善は、人工知能、オペレーションズリサーチなどに大きな影響を与えましたが、現在の最先端のソルバーの出力は検証が難しいことが多く、間違っている場合もあります。ブール充足可能性（SAT）ソルバーの場合、正確性を証明する方法としてプルーフロギングが導入されましたが、使用される方法をより強力なパラダイムに一般化するのは難しいようです。さらに、パリティ（XOR）推論、カーディナリティ検出、対称性処理などの強化されたSAT手法でも、標準のDRAT形式で実用的に効率的な証明を設計することはできません。この作業では、代わりに拡張変数で疑似ブール不等式を使用して、XOR推論を簡潔に正当化する方法を示します。 SATソルバー統合の実験的評価では、既存のDRAT手法と比較して、プルーフロギングと検証時間が劇的に短縮されていることが示されています。私たちの方法はDRATの厳密な一般化であり、0-1プログラミング、さらには制約プログラミングの問題も表現するのに役立ちます。この作業が、豊富なクラスの組み合わせの効率的な機械検証可能な証明のための統一されたアプローチへの道を示すことを願っています。最適化パラダイム。,https://d3i71xaburhd42.cloudfront.net/d8bf3c1b99d2d3eeab9df88a92f0097eef3bb291/5-Figure1-1.png
Nyströmformer: A Nyströmform-Based Algorithm for Approximating Self-Attention,"['Yunyang Xiong', 'Zhanpeng Zeng', 'Rudrasis Chakraborty', 'Mingxing Tan', 'Glenn M Fung', 'Yin Li', 'Vikas Singh']",,,,
Theoretical Analyses of Multi-Objective Evolutionary Algorithms on Multi-Modal Objectives,"['Benjamin Doerr', 'Weijie Zheng']",https://arxiv.org/abs/2012.07231,"Previous theory work on multi-objective evolutionary algorithms considers mostly easy problems that are composed of unimodal objectives. This paper takes a first step towards a deeper understanding of how evolutionary algorithms solve multi-modal multi-objective problems. We propose the OneJumpZeroJump problem, a bi-objective problem whose single objectives are isomorphic to the classic jump functions benchmark. We prove that the simple evolutionary multi-objective optimizer (SEMO) cannot compute the full Pareto front. In contrast, for all problem sizes~$n$ and all jump sizes $k \in [4..\frac n2 - 1]$, the global SEMO (GSEMO) covers the Pareto front in $\Theta((n-2k)n^{k})$ iterations in expectation. To improve the performance, we combine the GSEMO with two approaches, a heavy-tailed mutation operator and a stagnation detection strategy, that showed advantages in single-objective multi-modal problems. Runtime improvements of asymptotic order at least $k^{\Omega(k)}$ are shown for both strategies. Our experiments verify the {substantial} runtime gains already for moderate problem sizes. Overall, these results show that the ideas recently developed for single-objective evolutionary algorithms can be effectively employed also in multi-objective optimization.",多目的進化的アルゴリズムに関する以前の理論研究では、単峰性の目的で構成されるほとんどの簡単な問題を考慮しています。この論文は、進化的アルゴリズムがマルチモーダル多目的問題をどのように解決するかをより深く理解するための第一歩を踏み出します。 OneJumpZeroJump問題を提案します。これは、単一の目的が従来のジャンプ関数ベンチマークと同型である2目的問題です。単純な進化的多目的最適化（SEMO）では完全なパレートフロントを計算できないことを証明します。対照的に、すべての問題サイズnおよびすべてのジャンプサイズ$ k \ in [4 .. \ frac n2-1] $の場合、グローバルSEMO（GSEMO）は（（n 2k）n ^（k））のパレートフロントをカバーします。期待の反復。パフォーマンスを向上させるために、GSEMOを、裾が重い突然変異演算子と停滞検出戦略の2つのアプローチと組み合わせます。これらのアプローチは、単一目的のマルチモーダル問題で利点を示しました。両方の戦略について、少なくともk ^（（k））の漸近次数の実行時の改善が示されています。私たちの実験では、中程度の問題サイズですでに大幅なランタイムの向上が確認されています。全体として、これらの結果は、単一目的の進化的アルゴリズムのために最近開発されたアイデアが、多目的最適化でも効果的に使用できることを示しています。,https://d3i71xaburhd42.cloudfront.net/a1eb57de19ebc25702ad5f1a663fd796cf67ed3d/7-Figure1-1.png
IQ -- Incremental Learning for Solving QSAT,"['Thomas L Lee', 'Viktor Tóth', 'Sean B Holden']",,,,
SDGNN: Learning Node Representation for Signed Directed Networks,"['Junjie Huang', 'Huawei Shen', 'Liang Hou', 'Xueqi Cheng']",https://arxiv.org/abs/2101.02390,"Network embedding is aimed at mapping nodes in a network into low-dimensional vector representations. Graph Neural Networks (GNNs) have received widespread attention and lead to state-of-the-art performance in learning node representations. However, most GNNs only work in unsigned networks, where only positive links exist. It is not trivial to transfer these models to signed directed networks, which are widely observed in the real world yet less studied. In this paper, we first review two fundamental sociological theories (i.e., status theory and balance theory) and conduct empirical studies on real-world datasets to analyze the social mechanism in signed directed networks. Guided by related sociological theories, we propose a novel Signed Directed Graph Neural Networks model named SDGNN to learn node embeddings for signed directed networks. The proposed model simultaneously reconstructs link signs, link directions, and signed directed triangles. We validate our model’s effectiveness on five real-world datasets, which are commonly used as the benchmark for signed network embeddings. Experiments demonstrate the proposed model outperforms existing models, including feature-based methods, network embedding methods, and several GNN methods.",ネットワーク埋め込みは、ネットワーク内のノードを低次元のベクトル表現にマッピングすることを目的としています。グラフニューラルネットワーク（GNN）は広く注目されており、ノード表現の学習において最先端のパフォーマンスを実現しています。ただし、ほとんどのGNNは、正のリンクのみが存在する署名されていないネットワークでのみ機能します。これらのモデルを署名された有向ネットワークに転送することは簡単ではありません。署名された有向ネットワークは、現実の世界で広く観察されていますが、あまり研究されていません。この論文では、最初に2つの基本的な社会学理論（すなわち、ステータス理論とバランス理論）をレビューし、署名された有向ネットワークの社会的メカニズムを分析するために、実世界のデータセットに関する実証的研究を行います。関連する社会学理論に基づいて、SDGNNという名前の新しい署名付き有向グラフニューラルネットワークモデルを提案し、署名付き有向ネットワークのノード埋め込みを学習します。提案されたモデルは、リンク記号、リンク方向、および署名された有向三角形を同時に再構築します。署名されたネットワーク埋め込みのベンチマークとして一般的に使用される5つの実際のデータセットでモデルの有効性を検証します。実験は、提案されたモデルが、機能ベースの方法、ネットワーク埋め込み方法、およびいくつかのGNN方法を含む既存のモデルよりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/5c98e15d451980576e01db4fee47543c86920671/3-Figure1-1.png
Relaxed Clustered Hawkes Process for Student Procrastination Modeling in MOOCs,"['Mengfan Yao', 'Siqian Zhao', 'Shaghayegh Sahebi', 'Reza Feyzi Behnagh']",,,,
Contract Scheduling with Predictions,"['Spyros Angelopoulos', 'Shahin Kamali']",,,,
Filling the Gap of Utterance-Aware and Speaker-Aware Representation for Multi-Turn Dialogue,"['Longxiang Liu', 'Zhuosheng Zhang', 'Hai Zhao', 'Xi Zhou', 'Xiang Zhou']",,,,
Semantic Grouping Network for Video Captioning,"['Hobin Ryu', 'Sunghun Kang', 'Haeyong Kang', 'Chang D. Yoo']",,,,
Learning Complex 3D Human Self-Contact,"['Mihai Fieraru', 'Mihai Zanfir', 'Elisabeta Oneata', 'Alin-Ionut Popa', 'Vlad Olaru', 'Cristian Sminchisescu']",,,,
Adversarial Training Reduces Information and Improves Transferability,"['Matteo Terzi', 'Alessandro Achille', 'Marco Maggipinto', 'Gian Antonio Susto']",,,,
Multi-Objective Submodular Maximization by Regret Ratio Minimization with Theoretical Guarantee,"['Chao Feng', 'Chao Qian']",,,,
Adversarial Defense by Diversified Simultaneous Training of Deep Ensembles,"['Bo Huang', 'Zhiwei Ke', 'Yi Wang', 'Wei Wang', 'Linlin Shen', 'Feng Liu']",,,,
Savable but Lost Lives when ICU Is Overloaded: A Model from 733 Patients in Epicenter,"['Wuhan', 'China Tingting Dan', 'Yang Li', 'Ziwei Zhu', 'Xijie Chen', 'Wuxiu Quan', 'Yu Hu', 'Guihua Tao', 'Lei Zhu', 'Jijin Zhu', 'Hongmin Cai', 'Hanchun Wen']",,,,
Distribution Adaptive INT8 Quantization for Training CNNs,"['Kang Zhao', 'Sida Huang', 'Pan Pan', 'Yinghan Li', 'Yingya Zhang', 'Zhenyu Gu', 'Yinghui Xu']",,,,
Online Search with Maximum Clearance,"['Spyros Angelopoulos', 'Malachi L Voss']",https://arxiv.org/abs/2011.14144,"We study the setting in which a mobile agent must locate a hidden target in a bounded or unbounded environment, with no information about the hider's position. In particular, we consider online search, in which the performance of the search strategy is evaluated by its worst case competitive ratio. We introduce a multi-criteria search problem in which the searcher has a budget on its allotted search time, and the objective is to design strategies that are competitively efficient, respect the budget, and maximize the total searched ground. We give analytically optimal strategies for the line and the star environments, and efficient heuristics for general networks.",モバイルエージェントが、ハイダーの位置に関する情報なしで、制限された環境または制限されていない環境で非表示のターゲットを見つけなければならない設定を調査します。特に、検索戦略のパフォーマンスが最悪の場合の競争率によって評価されるオンライン検索を検討します。探索者が割り当てられた探索時間に予算を持っている多基準探索問題を紹介します。その目的は、競争力のある効率的な戦略を設計し、予算を尊重し、検索対象の合計を最大化することです。ライン環境とスター環境に対して分析的に最適な戦略を提供し、一般的なネットワークに対して効率的なヒューリスティックを提供します。,https://d3i71xaburhd42.cloudfront.net/bfe12b505e0a0d07ed7e88241669c065d004e00c/11-Figure1-1.png
"Almost Envy-Freeness, Envy-Rank, and Nash Social Welfare Matchings","['Alireza Farhadi', 'MohammadTaghi Hajiaghai', 'Mohamad Latifian', 'Masoud Seddighin', 'Hadi Yami']",https://arxiv.org/abs/2007.07027,"Envy-free up to one good (EF1) and envy-free up to any good (EFX) are two well-known extensions of envy-freeness for the case of indivisible items. It is shown that EF1 can always be guaranteed for agents with subadditive valuations. In sharp contrast, it is unknown whether or not an EFX allocation always exists, even for four agents and additive valuations. In addition, the best approximation guarantee for EFX is $(\phi -1) \simeq 0.61$ by Amanitidis et al.. 
In order to find a middle ground to bridge this gap, in this paper we suggest another fairness criterion, namely envy-freeness up to a random good or EFR, which is weaker than EFX, yet stronger than EF1. For this notion, we provide a polynomial-time $0.73$-approximation allocation algorithm. For our algorithm, we introduce Nash Social Welfare Matching which makes a connection between Nash Social Welfare and envy freeness. We believe Nash Social Welfare Matching will find its applications in future work.",羨望のない最大1つの商品（EF1）と羨望のない最大1つの商品（EFX）は、分割できないアイテムの場合の羨望のない拡張の2つのよく知られた拡張機能です。 EF1は、劣加法性の評価を持つエージェントに対して常に保証できることが示されています。対照的に、4つのエージェントと加法評価であっても、EFX割り当てが常に存在するかどうかは不明です。さらに、EFXの最良の近似保証は（1）Amanitidis et al。による0.61です。このギャップを埋めるための中間点を見つけるために、この論文では、別の公平性基準、つまりランダムな善までの羨望のないことを提案します。またはEFR。これはEFXよりも弱いが、EF1よりは強い。この概念のために、多項式時間0.73近似割り当てアルゴリズムを提供します。私たちのアルゴリズムでは、ナッシュ社会福祉と羨望の自由を結びつけるナッシュ社会福祉マッチングを導入します。 Nash Social Welfare Matchingは、将来の作業でそのアプリケーションが見つかると信じています。,https://d3i71xaburhd42.cloudfront.net/e8d90f8fdc2ff9ff24faee07fb3bd718f688a28b/3-Figure1-1.png
User Driven Model Adjustment via Boolean Rule Explanations,"['Elizabeth Daly', 'Massimiliano Mattetti', 'Oznur Alkan', 'Rahul Nair']",,,,
Consistent-Separable Feature Representation for Semantic Segmentation,"['Xingjian He', 'Jing Liu', 'Jun Fu', 'Xinxin Zhu', 'Jinqiao Wang', 'Hanqing Lu']",,,,
Cross-Domain Grouping and Alignment for Domain Adaptive Semantic Segmentation,"['Minsu Kim', 'Sunghun Joung', 'Seungryong Kim', 'JungIn Park', 'Ig-Jae Kim', 'Kwanghoon Sohn']",https://arxiv.org/abs/2012.08226,"Existing techniques to adapt semantic segmentation networks across the source and target domains within deep convolutional neural networks (CNNs) deal with all the samples from the two domains in a global or category-aware manner. They do not consider an inter-class variation within the target domain itself or estimated category, providing the limitation to encode the domains having a multi-modal data distribution. To overcome this limitation, we introduce a learnable clustering module, and a novel domain adaptation framework called cross-domain grouping and alignment. To cluster the samples across domains with an aim to maximize the domain alignment without forgetting precise segmentation ability on the source domain, we present two loss functions, in particular, for encouraging semantic consistency and orthogonality among the clusters. We also present a loss so as to solve a class imbalance problem, which is the other limitation of the previous methods. Our experiments show that our method consistently boosts the adaptation performance in semantic segmentation, outperforming the state-of-the-arts on various domain adaptation settings.",ディープ畳み込みニューラルネットワーク（CNN）内のソースドメインとターゲットドメインにまたがるセマンティックセグメンテーションネットワークを適応させる既存の手法は、2つのドメインからのすべてのサンプルをグローバルまたはカテゴリ対応の方法で処理します。それらは、ターゲットドメイン自体または推定カテゴリ内のクラス間変動を考慮せず、マルチモーダルデータ分布を持つドメインをエンコードするための制限を提供します。この制限を克服するために、学習可能なクラスタリングモジュールと、クロスドメインのグループ化とアラインメントと呼ばれる新しいドメイン適応フレームワークを導入します。ソースドメインでの正確なセグメンテーション機能を忘れずにドメインの配置を最大化することを目的として、ドメイン間でサンプルをクラスター化するために、特にクラスター間のセマンティックの一貫性と直交性を促進するための2つの損失関数を示します。また、以前の方法のもう1つの制限である、クラスの不均衡の問題を解決するために損失を提示します。私たちの実験は、私たちの方法がセマンティックセグメンテーションの適応パフォーマンスを一貫して向上させ、さまざまなドメイン適応設定で最先端のパフォーマンスを上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/b636fb60037af31a1a67e9353e13332771515425/1-Figure1-1.png
Explanation Consistency Training: Facilitating Consistency-Based Semi-Supervised Learning with Interpretability,"['Tao Han', 'Wei-Wei Tu', 'Yu-Feng Li']",,,,
A Graph-Based Relevance Matching Model for Ad-Hoc Retrieval,"['Yufeng Zhang', 'Jinghao Zhang', 'Zeyu Cui', 'Shu Wu', 'Liang Wang']",https://arxiv.org/abs/2101.11873,"To retrieve more relevant, appropriate and useful documents given a query, finding clues about that query through the text is crucial. Recent deep learning models regard the task as a term-level matching problem, which seeks exact or similar query patterns in the document. However, we argue that they are inherently based on local interactions and do not generalise to ubiquitous, non-consecutive contextual relationships. In this work, we propose a novel relevance matching model based on graph neural networks to leverage the documentlevel word relationships for ad-hoc retrieval. In addition to the local interactions, we explicitly incorporate all contexts of a term through the graph-of-word text format. Matching patterns can be revealed accordingly to provide a more accurate relevance score. Our approach significantly outperforms strong baselines on two ad-hoc benchmarks. We also experimentally compare our model with BERT and show our advantages on long documents.",クエリを指定して、より関連性が高く、適切で有用なドキュメントを取得するには、テキストからそのクエリに関する手がかりを見つけることが重要です。最近の深層学習モデルでは、タスクを用語レベルのマッチング問題と見なしており、ドキュメント内で正確または類似のクエリパターンを探します。ただし、それらは本質的にローカルの相互作用に基づいており、ユビキタスで非連続的なコンテキスト関係に一般化されていないと主張します。この作業では、アドホック検索のためにドキュメントレベルの単語の関係を活用するために、グラフニューラルネットワークに基づく新しい関連性マッチングモデルを提案します。ローカルインタラクションに加えて、単語のグラフテキスト形式を介して用語のすべてのコンテキストを明示的に組み込みます。それに応じて一致パターンを明らかにし、より正確な関連性スコアを提供できます。私たちのアプローチは、2つのアドホックベンチマークの強力なベースラインを大幅に上回っています。また、モデルをBERTと実験的に比較し、長いドキュメントでの利点を示します。,https://d3i71xaburhd42.cloudfront.net/37023fc7bcd987e795a3842795a3e72863139f67/1-Figure1-1.png
Self-Domain Adaptation for Face Anti-Spoofing,"['Jing jing Wang', 'Jingyi Zhang', 'Bian Ying', 'Youyi Cai', 'Chunmao Wang', 'Shiliang Pu']",,,,
Adaptive Gradient Methods for Constrained Convex Optimization and Variational Inequalities,"['Alina Ene', 'Huy Nguyen', 'Adrian Vladu']",,,,
SAT-Based Decision Tree Learning for Large Data Sets,"['Andre Schidler', 'Stefan Szeider']",,,,
Story Ending Generation with Multi-Level Graph Convolutional Networks over Dependency Trees,"['Qingbao Huang', 'Linzhang Mo', 'Pijian Li', 'Yi Cai', 'Qingguang Liu', 'Jielong Wei', 'Qing Li', 'Ho-fung Leung']",,,,
Coupling Macro-Sector-Micro Financial Indicators for Learning Stock Representations with Less Uncertainty,"['Guifeng Wang', 'Longbing Cao', 'Hongke Zhao', 'Qi Liu', 'Enhong Chen']",,,,
Tempered Sigmoid Activations for Deep Learning with Differential Privacy,"['Nicolas Papernot', 'Abhradeep Thakurta', 'Shuang Song', 'Steve Chien', 'Ulfar Erlingsson']",https://arxiv.org/abs/2007.14191,"Because learning sometimes involves sensitive data, machine learning algorithms have been extended to offer privacy for training data. In practice, this has been mostly an afterthought, with privacy-preserving models obtained by re-running training with a different optimizer, but using the model architectures that already performed well in a non-privacy-preserving setting. This approach leads to less than ideal privacy/utility tradeoffs, as we show here. Instead, we propose that model architectures are chosen ab initio explicitly for privacy-preserving training. 
To provide guarantees under the gold standard of differential privacy, one must bound as strictly as possible how individual training points can possibly affect model updates. In this paper, we are the first to observe that the choice of activation function is central to bounding the sensitivity of privacy-preserving deep learning. We demonstrate analytically and experimentally how a general family of bounded activation functions, the tempered sigmoids, consistently outperform unbounded activation functions like ReLU. Using this paradigm, we achieve new state-of-the-art accuracy on MNIST, FashionMNIST, and CIFAR10 without any modification of the learning procedure fundamentals or differential privacy analysis.",学習には機密データが含まれることがあるため、機械学習アルゴリズムが拡張され、トレーニングデータのプライバシーが保護されています。実際には、これはほとんど後から考えられたものであり、別のオプティマイザーでトレーニングを再実行することによってプライバシーを保護するモデルが取得されますが、プライバシーを保護しない設定ですでに十分に機能しているモデルアーキテクチャを使用しています。ここに示すように、このアプローチでは、プライバシーとユーティリティのトレードオフが理想的とは言えません。代わりに、プライバシー保護トレーニングのために、モデルアーキテクチャを最初から明示的に選択することを提案します。差分プライバシーのゴールドスタンダードの下で保証を提供するには、個々のトレーニングポイントがモデルの更新にどのように影響する可能性があるかを可能な限り厳密に制限する必要があります。この論文では、活性化関数の選択がプライバシーを保護する深層学習の感度を制限するための中心であることに最初に気づきました。有界活性化関数の一般的なファミリーである強化シグモイドが、ReLUのような非有界活性化関数よりも一貫して優れていることを分析的および実験的に示します。このパラダイムを使用して、学習手順の基本や差分プライバシー分析を変更することなく、MNIST、FashionMNIST、およびCIFAR10で新しい最先端の精度を実現します。,https://d3i71xaburhd42.cloudfront.net/7290945147946bc5ac06ec010e07d027e306d6aa/4-Figure1-1.png
Cross-Oilfield Reservoir Classification via Multi-Scale Sensor Knowledge Transfer,"['Zhi Li', 'Zhefeng Wang', 'Zhicheng Wei', 'Xiangguang Zhou', 'Yijun Wang', 'Baoxing Huai', 'Qi Liu', 'Nicholas Jing Yuan', 'Renbin Gong', 'Enhong Chen']",,,,
Accelerating Neural Machine Translation with Partial Word Embedding Compression,"['Fan Zhang', 'Mei Tu', 'Jinyao Yan']",,,,
Symmetry Breaking for k-Robust Multi-Agent Path Finding,"['Zhe Chen', 'Daniel Harabor', 'Jiaoyang Li', 'Peter Stuckey']",,"During Multi-Agent Path Finding (MAPF) problems, agents can be delayed by unexpected events. To address such situations recent work describes k-Robust Conflict-Based Search (k-CBS): an algorithm that produces a coordinated and collision-free plan that is robust for up to k delays for any agent. In this work we introduce a variety of pairwise symmetry breaking constraints, specific to k-robust planning, that can efficiently find compatible and optimal paths for pairs of colliding agents. We give a thorough description of the new constraints and report large improvements to success rate in a range of domains including: (i) classic MAPF benchmarks, (ii) automated warehouse domains, and (iii) on maps from the 2019 Flatland Challenge, a recently introduced railway domain where k-robust planning can be fruitfully applied to",マルチエージェントパスファインディング（MAPF）の問題の際、予期しないイベントによってエージェントが遅延する可能性があります。このような状況に対処するために、最近の研究では、k-Robust Conflict-Based Search（k-CBS）について説明しています。これは、任意のエージェントの最大kの遅延に対して堅牢な、調整された衝突のない計画を生成するアルゴリズムです。この作業では、衝突するエージェントのペアの互換性のある最適なパスを効率的に見つけることができる、k-robust計画に固有のさまざまなペアワイズ対称性の破れの制約を紹介します。新しい制約について詳しく説明し、（i）従来のMAPFベンチマーク、（ii）自動化されたウェアハウスドメイン、（iii）2019 Flatland Challengeのマップなど、さまざまなドメインで成功率が大幅に向上したことを報告します。 k-robust計画を実りある形で適用できる最近導入された鉄道ドメイン,https://d3i71xaburhd42.cloudfront.net/cdcca6a68b10d2672099e16af035f90dd0792d12/2-Figure1-1.png
Frequency Consistent Adaptation for Real World Super Resolution,"['Xiaozhong Ji', 'Guangpin Tao', 'Yun Cao', 'Ying Tai', 'Tong Lu', 'Chengjie Wang', 'Jilin Li', 'Feiyue Huang']",https://arxiv.org/abs/2012.10102,"Recent deep-learning based Super-Resolution (SR) methods have achieved remarkable performance on images with known degradation. However, these methods always fail in real-world scene, since the Low-Resolution (LR) images after the ideal degradation (e.g., bicubic down-sampling) deviate from real source domain. The domain gap between the LR images and the real-world images can be observed clearly on frequency density, which inspires us to explictly narrow the undesired gap caused by incorrect degradation. From this point of view, we design a novel Frequency Consistent Adaptation (FCA) that ensures the frequency domain consistency when applying existing SR methods to the real scene. We estimate degradation kernels from unsupervised images and generate the corresponding LR images. To provide useful gradient information for kernel estimation, we propose Frequency Density Comparator (FDC) by distinguishing the frequency density of images on different scales. Based on the domain-consistent LR-HR pairs, we train easy-implemented Convolutional Neural Network (CNN) SR models. Extensive experiments show that the proposed FCA improves the performance of the SR model under real-world setting achieving state-of-the-art results with high fidelity and plausible perception, thus providing a novel effective framework for realworld SR application. Introduction Super-Resolution (SR) is a basic low-level visual problem (Freeman, Jones, and Pasztor 2002; Glasner, Bagon, and Irani 2009), which is defined as enlarging the resolution of a Low-Resolution (LR) image and restoring it to a High-Resolution (HR) image. In recent years, deep-learning methods have dominated the research in the SR field, and lots of novel structures (Dong et al. 2015; Tai et al. 2017; Chen et al. 2018; Tai, Yang, and Liu 2017; Lai et al. 2017; Kim, Kwon Lee, and Mu Lee 2016; Lim et al. 2017) are proposed to improve performance on standard benchmarks. However, known degradation used to train these models is not suitable to real-world scenarios. In fact, the SR model is sensitive to different degradation (Zhang, Zuo, and Zhang * indicates equal contribution. † Corresponding author. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. LR",最近の深層学習ベースの超解像（SR）手法は、劣化がわかっている画像で驚くべきパフォーマンスを達成しています。ただし、理想的な劣化（バイキュービックダウンサンプリングなど）後の低解像度（LR）画像は実際のソースドメインから逸脱するため、これらの方法は実際のシーンでは常に失敗します。 LR画像と実世界の画像の間のドメインギャップは、周波数密度で明確に観察できます。これにより、不正確な劣化によって引き起こされる望ましくないギャップを明示的に狭めることができます。この観点から、既存のSRメソッドを実際のシーンに適用するときに周波数領域の一貫性を保証する新しい周波数一貫性適応（FCA）を設計します。教師なし画像から劣化カーネルを推定し、対応するLR画像を生成します。カーネル推定に役立つ勾配情報を提供するために、さまざまなスケールで画像の周波数密度を区別することにより、周波数密度コンパレータ（FDC）を提案します。ドメイン整合性のあるLR-HRペアに基づいて、簡単に実装できる畳み込みニューラルネットワーク（CNN）SRモデルをトレーニングします。広範な実験により、提案されたFCAは、実世界の設定でSRモデルのパフォーマンスを向上させ、高い忠実度ともっともらしい知覚を備えた最先端の結果を達成し、実世界のSRアプリケーションに新しい効果的なフレームワークを提供することが示されています。はじめに超解像（SR）は、基本的な低レベルの視覚的問題（Freeman、Jones、およびPasztor 2002; Glasner、Bagon、およびIrani 2009）であり、低解像度（LR）画像の解像度を拡大することとして定義されています。高解像度（HR）イメージに復元します。近年、ディープラーニング手法がSR分野の研究を支配し、多くの新しい構造があります（Dong et al.2015; Tai et al.2017; Chen et al.2018; Tai、Yang、and Liu 2017; Lai etal。2017; Kim、Kwon Lee、およびMu Lee 2016; Lim etal。2017）は、標準ベンチマークでのパフォーマンスを改善するために提案されています。ただし、これらのモデルのトレーニングに使用される既知の劣化は、実際のシナリオには適していません。実際、SRモデルはさまざまな劣化に敏感です（Zhang、Zuo、およびZhang *は同等の貢献を示します。対応する著者。Copyright2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。Allrightsreserved。LR,https://d3i71xaburhd42.cloudfront.net/f3c954bdeae18ca362b9642965f51757e4d37aba/1-Figure1-1.png
Improving the Efficiency and Effectiveness for Bert-Based Entity Resolution,"['Bing Li', 'Yukai Miao', 'Yaoshu Wang', 'Yifang Sun', 'Wei Wang']",,,,
Automatic Curriculum Learning with Over-Repetition Penalty for Dialogue Policy Learning,"['Yangyang Zhao', 'Zhenyu Wang', 'Zhenhua Huang']",https://arxiv.org/abs/2012.14072,"Dialogue policy learning based on reinforcement learning is difficult to be applied to real users to train dialogue agents from scratch because of the high cost. User simulators, which choose random user goals for the dialogue agent to train on, have been considered as an affordable substitute for real users. However, this random sampling method ignores the law of human learning, making the learned dialogue policy inefficient and unstable. We propose a novel framework, Automatic Curriculum Learning-based Deep QNetwork (ACL-DQN), which replaces the traditional random sampling method with a teacher policy model to realize the dialogue policy for automatic curriculum learning. The teacher model arranges a meaningful ordered curriculum and automatically adjusts it by monitoring the learning progress of the dialogue agent and the over-repetition penalty without any requirement of prior knowledge. The learning progress of the dialogue agent reflects the relationship between the dialogue agent’s ability and the sampled goals’ difficulty for sample efficiency. The over-repetition penalty guarantees the sampled diversity. Experiments show that the ACL-DQN significantly improves the effectiveness and stability of dialogue tasks with a statistically significant margin. Furthermore, the framework can be further improved by equipping with different curriculum schedules, which demonstrates that the framework has strong generalizability.",強化学習に基づく対話ポリシー学習は、コストが高いため、対話エージェントをゼロからトレーニングするために実際のユーザーに適用することは困難です。ダイアログエージェントがトレーニングするランダムなユーザー目標を選択するユーザーシミュレーターは、実際のユーザーの手頃な代替品と見なされてきました。ただし、このランダムサンプリング方法は、人間の学習の法則を無視するため、学習した対話ポリシーが非効率的で不安定になります。自動カリキュラム学習の対話ポリシーを実現するために、従来のランダムサンプリング方法を教師ポリシーモデルに置き換える、新しいフレームワークである自動カリキュラム学習ベースのディープQNetwork（ACL-DQN）を提案します。教師モデルは、意味のある順序付けられたカリキュラムを配置し、事前の知識を必要とせずに、対話エージェントの学習の進行状況と繰り返しのペナルティを監視することによって自動的に調整します。対話エージェントの学習の進捗状況は、対話エージェントの能力とサンプル効率のサンプル目標の難易度との関係を反映しています。過剰な繰り返しのペナルティは、サンプリングされた多様性を保証します。実験は、ACL-DQNが統計的に有意なマージンで対話タスクの有効性と安定性を大幅に改善することを示しています。さらに、さまざまなカリキュラムスケジュールを装備することで、フレームワークをさらに改善することができます。これは、フレームワークが強力な一般化可能性を備えていることを示しています。,https://d3i71xaburhd42.cloudfront.net/6a60bf27a3d997d373f7536cb6a6c1abf3561e6a/2-Figure1-1.png
Relational Boosted Bandits,"['Ashutosh Dilipbhai Kakadiya', 'Sriraam Natarajan', 'Balaraman Ravindran']",https://arxiv.org/abs/2012.09220,"Contextual bandits algorithms have become essential in real-world user interaction problems in recent years. However, these algorithms rely on context as attribute value representation, which makes them unfeasible for real-world domains like social networks are inherently relational. We propose Relational Boosted Bandits(RB2), acontextual bandits algorithm for relational domains based on (relational) boosted trees. RB2 enables us to learn interpretable and explainable models due to the more descriptive nature of the relational representation. We empirically demonstrate the effectiveness and interpretability of RB2 on tasks such as link prediction, relational classification, and recommendations.",コンテキストバンディットアルゴリズムは、近年、実際のユーザーインタラクションの問題に不可欠になっています。ただし、これらのアルゴリズムは属性値の表現としてコンテキストに依存しているため、ソーシャルネットワークが本質的にリレーショナルであるなどの実際のドメインでは実行できません。 （リレーショナル）ブーストツリーに基づくリレーショナルドメインのコンテキストバンディットアルゴリズムであるRelational Boosted Bandits（RB2）を提案します。 RB2を使用すると、リレーショナル表現のより記述的な性質により、解釈可能で説明可能なモデルを学習できます。リンク予測、リレーショナル分類、推奨事項などのタスクにおけるRB2の有効性と解釈可能性を経験的に示します。,https://d3i71xaburhd42.cloudfront.net/36cfdf79c7140afaeff94f15849ae4774dc7f2c1/6-Figure1-1.png
A Systematic Evaluation of Object Detection Networks for Scientific Plots,"['Pritha Ganguly', 'Nitesh S Methani', 'Mitesh M. Khapra', 'Pratyush Kumar']",https://arxiv.org/abs/2007.02240,"Are existing object detection methods adequate for detecting text and visual elements in scientific plots which are arguably different than the objects found in natural images? To answer this question, we train and compare the accuracy of Fast/Faster R-CNN, SSD, YOLO and RetinaNet on the PlotQA dataset with over 220,000 scientific plots. At the standard IOU setting of 0.5, most networks perform well with mAP scores greater than 80% in detecting the relatively simple objects in plots. However, the performance drops drastically when evaluated at a stricter IOU of 0.9 with the best model giving a mAP of 35.70%. Note that such a stricter evaluation is essential when dealing with scientific plots where even minor localisation errors can lead to large errors in downstream numerical inferences. Given this poor performance, we propose minor modifications to existing models by combining ideas from different object detection networks. While this significantly improves the performance, there are still 2 main issues: (i) performance on text objects which are essential for reasoning is very poor, and (ii) inference time is unacceptably large considering the simplicity of plots. Based on these experiments and results, we identify the following considerations for improving object detection on plots: (a) small inference time, (b) higher precision on text objects, and (c) more accurate localisation with a custom loss function with non-negligible loss values at high IOU (> 0.8). We propose a network which meets all these considerations: It is 16x faster than the best performing competitor and significantly improves upon the accuracy of existing models with a mAP of 93.44%@0.9 IOU.",既存のオブジェクト検出方法は、自然画像に見られるオブジェクトとはほぼ間違いなく異なる科学的プロットのテキストや視覚要素を検出するのに適していますか？この質問に答えるために、PlotQAデータセットのFast / Faster R-CNN、SSD、YOLO、およびRetinaNetの精度をトレーニングし、22万を超える科学的プロットと比較します。 0.5の標準IOU設定では、ほとんどのネットワークは80を超えるmAPスコアで良好に機能します。,https://d3i71xaburhd42.cloudfront.net/2b3248ed0bb8531d70fba6afc98ec5730be336d3/3-Figure1-1.png
Complex Coordinate-Based Meta-Analysis with Probabilistic Programming,"['Valentin Lovene', 'Gaston E Zanitti', 'Demian Wassermann']",,,,
DramaQA: Character-Centered Video Story Understanding with Hierarchical QA,"['Seongho Choi', 'Kyoung-Woon On', 'Yu-Jung Heo', 'Ahjeong Seo', 'Youwon Jang', 'Minsu Lee', 'Byoung-Tak Zhang']",https://arxiv.org/abs/2005.03356,"Despite recent progress on computer vision and natural language processing, developing video understanding intelligence is still hard to achieve due to the intrinsic difficulty of story in video. Moreover, there is not a theoretical metric for evaluating the degree of video understanding. In this paper, we propose a novel video question answering (Video QA) task, DramaQA, for a comprehensive understanding of the video story. The DramaQA focused on two perspectives: 1) hierarchical QAs as an evaluation metric based on the cognitive developmental stages of human intelligence. 2) character-centered video annotations to model local coherence of the story. Our dataset is built upon the TV drama ""Another Miss Oh"" and it contains 16,191 QA pairs from 23,928 various length video clips, with each QA pair belonging to one of four difficulty levels. We provide 217,308 annotated images with rich character-centered annotations, including visual bounding boxes, behaviors, and emotions of main characters, and coreference resolved scripts. Additionally, we provide analyses of the dataset as well as Dual Matching Multistream model which effectively learns character-centered representations of video to answer questions about the video. We are planning to release our dataset and model publicly for research purposes and expect that our work will provide a new perspective on video story understanding research.","コンピュータビジョンと自然言語処理の最近の進歩にもかかわらず、ビデオのストーリーの本質的な難しさのために、ビデオ理解インテリジェンスの開発はまだ達成が困難です。さらに、ビデオの理解度を評価するための理論的な指標はありません。この論文では、ビデオストーリーを包括的に理解するために、新しいビデオ質問応答（Video QA）タスクであるDramaQAを提案します。 DramaQAは、2つの視点に焦点を当てました。1）人間の知性の認知発達段階に基づく評価指標としての階層的QA。 2）ストーリーのローカルコヒーレンスをモデル化するためのキャラクター中心のビデオ注釈。私たちのデータセットは、テレビドラマ「また！オ・ヘビ」に基づいて構築されており、23,928のさまざまな長さのビデオクリップからの16,191のQAペアが含まれ、各QAペアは4つの難易度レベルのいずれかに属します。 217,308の注釈付き画像に、主人公の視覚的な境界ボックス、動作、感情、共参照解決スクリプトなど、文字中心の豊富な注釈を提供します。さらに、データセットの分析と、ビデオの文字中心の表現を効果的に学習してビデオに関する質問に答えるデュアルマッチングマルチストリームモデルを提供します。私たちは、研究目的でデータセットとモデルを公開することを計画しており、私たちの仕事がビデオストーリー理解研究に関する新しい視点を提供することを期待しています。",https://d3i71xaburhd42.cloudfront.net/a4cc963ee840e66fab1eb72bff90e3a8b2a32890/4-Figure1-1.png
A Unified Multi-Scenario Attacking Network for Visual Object Tracking,"['Xuesong Chen', 'Canmiao Fu', 'Feng Zheng', 'Yong Zhao', 'Hongsheng Li', 'Ping Luo', 'Guo-Jun Qi']",,,,
Selfish Creation of Social Networks,"['Davide Bilò', 'Tobias Friedrich', 'Pascal Lenzner', 'Stefanie Lowski', 'Anna Melnichenko']",https://arxiv.org/abs/2012.06203,"Understanding real-world networks has been a core research endeavor throughout the last two decades. Network Creation Games are a promising approach for this from a game-theoretic perspective. In these games, selfish agents corresponding to nodes in a network strategically decide which links to form to optimize their centrality. Many versions have been introduced and analyzed, but none of them fits to modeling the evolution of social networks. In real-world social networks, connections are often established by recommendations from common acquaintances or by a chain of such recommendations. Thus establishing and maintaining a contact with a friend of a friend is easier than connecting to complete strangers. This explains the high clustering, i.e., the abundance of triangles, in real-world social networks. We propose and analyze a network creation model inspired by real-world social networks. Edges are formed in our model via bilateral consent of both endpoints and the cost for establishing and maintaining an edge is proportional to the distance of the endpoints before establishing the connection. We provide results for generic cost functions, which essentially only must be convex functions in the distance of the endpoints without the respective edge. For this broad class of cost functions, we provide many structural properties of equilibrium networks and prove (almost) tight bounds on the diameter, the Price of Anarchy and the Price of Stability. Moreover, as a proof-of-concept we show via experiments that the created equilibrium networks of our model indeed closely mimics real-world social networks. We observe degree distributions that seem to follow a power-law, high clustering, and low diameters. This can be seen as a promising first step towards game-theoretic network creation models that predict networks featuring all core real-world properties.",実世界のネットワークを理解することは、過去20年間の中心的な研究努力でした。ネットワーク作成ゲームは、ゲーム理論の観点から、これに対する有望なアプローチです。これらのゲームでは、ネットワーク内のノードに対応する利己的なエージェントが、中心性を最適化するために形成するリンクを戦略的に決定します。多くのバージョンが導入および分析されていますが、ソーシャルネットワークの進化のモデル化に適合するものはありません。現実のソーシャルネットワークでは、多くの場合、一般的な知人からの推奨事項またはそのような推奨事項のチェーンによって接続が確立されます。したがって、友達の友達との連絡を確立して維持することは、完全な見知らぬ人に接続するよりも簡単です。これは、現実世界のソーシャルネットワークにおける高度なクラスタリング、つまり三角形の豊富さを説明しています。実世界のソーシャルネットワークに触発されたネットワーク作成モデルを提案し、分析します。エッジは、両方のエンドポイントの二国間同意によってモデルに形成され、エッジを確立および維持するためのコストは、接続を確立する前のエンドポイントの距離に比例します。一般的なコスト関数の結果を提供します。これは、基本的に、それぞれのエッジのない端点の距離にある凸関数である必要があります。この幅広いクラスのコスト関数に対して、平衡ネットワークの多くの構造特性を提供し、直径、無秩序の代償、および安定性の価格に（ほぼ）厳しい限界があることを証明します。さらに、概念実証として、モデルの作成された平衡ネットワークが実際に実際のソーシャルネットワークを厳密に模倣していることを実験を通じて示します。べき乗則、高いクラスタリング、および低い直径に従うように見える次数分布を観察します。これは、すべてのコア実世界プロパティを特徴とするネットワークを予測するゲーム理論的なネットワーク作成モデルに向けた有望な第一歩と見なすことができます。,https://d3i71xaburhd42.cloudfront.net/f89f716e305635fdaa67fa2f75050cbe73313c1e/4-Figure1-1.png
Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting,"['Haoyi Zhou', 'Shanghang Zhang', 'Jieqi Peng', 'Shuai Zhang', 'Jianxin Li', 'Hui Xiong', 'Wancai Zhang']",,,,
PoA of Simple Auctions with Interdependent Values,"['Alon Eden', 'Michal Feldman', 'Inbal Talgam-Cohen', 'Ori Zviran']",,,,
Learning Prediction Intervals for Model Performance,"['Benjamin Elder', 'Matthew Arnold', 'Anupama Murthi', 'Jiri Navratil']",https://arxiv.org/abs/2012.08625,"Understanding model performance on unlabeled data is a fundamental challenge of developing, deploying, and maintaining AI systems. Model performance is typically evaluated using test sets or periodic manual quality assessments, both of which require laborious manual data labeling. Automated performance prediction techniques aim to mitigate this burden, but potential inaccuracy and a lack of trust in their predictions has prevented their widespread adoption. We address this core problem of performance prediction uncertainty with a method to compute prediction intervals for model performance. Our methodology uses transfer learning to train an uncertainty model to estimate the uncertainty of model performance predictions. We evaluate our approach across a wide range of drift conditions and show substantial improvement over competitive baselines. We believe this result makes prediction intervals, and performance prediction in general, significantly more practical for real-world use.",ラベルのないデータのモデルパフォーマンスを理解することは、AIシステムを開発、展開、維持する上での基本的な課題です。モデルのパフォーマンスは通常、テストセットまたは定期的な手動の品質評価を使用して評価されます。どちらも面倒な手動のデータラベル付けが必要です。自動化されたパフォーマンス予測手法は、この負担を軽減することを目的としていますが、潜在的な不正確さと予測への信頼の欠如により、それらの広範な採用が妨げられています。モデルパフォーマンスの予測区間を計算する方法を使用して、パフォーマンス予測の不確実性というこのコア問題に対処します。私たちの方法論では、伝達学習を使用して不確実性モデルをトレーニングし、モデルのパフォーマンス予測の不確実性を推定します。幅広いドリフト条件でアプローチを評価し、競合ベースラインを大幅に上回っています。この結果により、予測区間、および一般的なパフォーマンス予測が、実際の使用で大幅に実用化されると確信しています。,https://d3i71xaburhd42.cloudfront.net/69d439ffa9da071ed163736a9ce1e306404653e4/5-Figure1-1.png
A Multivariate Complexity Analysis of the Material Consumption Scheduling Problem,"['Matthias Bentert', 'Robert Bredereck', 'Péter Györgyi', 'Andrzej Kaczmarczyk', 'Rolf Niedermeier']",,,,
Generative Semi-Supervised Learning for Multivariate Time Series Imputation,"['Xiaoye Miao', 'Yangyang Wu', 'Jun Wang', 'Yunjun Gao', 'Xudong Mao', 'Jianwei Yin']",,,,
Learning Model-Based Privacy Protection under Budget Constraints,"['Junyuan Hong', 'Haotao Wang', 'Zhangyang Wang', 'Jiayu Zhou']",,,,
Towards Efficient Selection of Activity Trajectories Based on Diversity and Coverage,"['Chengcheng Yang', 'Lisi Chen', 'Hao Wang', 'Shuo Shang']",,,,
Revisiting Iterative Back-Translation from the Perspective of Compositional Generalization,"['Yinuo Guo', 'Hualei Zhu', 'Zeqi Lin', 'Bei Chen', 'Jian-Guang Lou', 'Dongmei Zhang']",https://arxiv.org/abs/2012.04276,"Human intelligence exhibits compositional generalization (i.e., the capacity to understand and produce unseen combinations of seen components), but current neural seq2seq models lack such ability. In this paper, we revisit iterative back-translation, a simple yet effective semi-supervised method, to investigate whether and how it can improve compositional generalization. In this work: (1) We first empirically show that iterative back-translation substantially improves the performance on compositional generalization benchmarks (CFQ and SCAN). (2) To understand why iterative back-translation is useful, we carefully examine the performance gains and find that iterative back-translation can increasingly correct errors in pseudo-parallel data. (3) To further encourage this mechanism, we propose curriculum iterative back-translation, which better improves the quality of pseudo-parallel data, thus further improving the performance.",人間の知性は、構成の一般化（つまり、目に見えるコンポーネントの目に見えない組み合わせを理解して生成する能力）を示しますが、現在のニューラルseq2seqモデルにはそのような能力がありません。この論文では、単純でありながら効果的な半教師あり方法である反復逆翻訳を再検討し、それが組成の一般化を改善できるかどうか、またどのように改善できるかを調査します。この作業では：（1）最初に、反復逆変換が構成一般化ベンチマーク（CFQおよびSCAN）のパフォーマンスを大幅に向上させることを経験的に示します。 （2）反復逆変換が有用である理由を理解するために、パフォーマンスの向上を注意深く調べ、反復逆変換が疑似パラレルデータのエラーをますます修正できることを発見しました。 （3）このメカニズムをさらに促進するために、カリキュラムの反復逆変換を提案します。これにより、疑似パラレルデータの品質が向上し、パフォーマンスがさらに向上します。,https://d3i71xaburhd42.cloudfront.net/df66fcd3fd4f0d55bd96528cddb0e2f08ddb3385/2-Figure1-1.png
C-Watcher: A Framework for Early Detection of High-Risk Neighborhoods Ahead of COVID-19 Outbreak,"['Congxi Xiao', 'Jingbo Zhou', 'Jizhou Huang', 'Haoyi Xiong', 'An Zhuo', 'Ji Liu', 'Dejing Dou']",https://arxiv.org/abs/2012.12169,"The novel coronavirus disease (COVID-19) has crushed daily routines and is still rampaging through the world. Existing solution for nonpharmaceutical interventions usually needs to timely and precisely select a subset of residential urban areas for containment or even quarantine, where the spatial distribution of confirmed cases has been considered as a key criterion for the subset selection. While such containment measure has successfully stopped or slowed down the spread of COVID-19 in some countries, it is criticized for being inefficient or ineffective, as the statistics of confirmed cases are usually time-delayed and coarse-grained. To tackle the issues, we propose C-Watcher, a novel data-driven framework that aims at screening every neighborhood in a target city and predicting infection risks, prior to the spread of COVID-19 from epicenters to the city. In terms of design, C-Watcher collects large-scale long-term human mobility data from Baidu Maps, then characterizes every residential neighborhood in the city using a set of features based on urban mobility patterns. Furthermore, to transfer the firsthand knowledge (witted in epicenters) to the target city before local outbreaks, we adopt a novel adversarial encoder framework to learn “city-invariant” representations from the mobility-related features for precise early detection of high-risk neighborhoods, even before any confirmed cases known, in the target city. We carried out extensive experiments on C-Watcher using the real-data records in the early stage of COVID-19 outbreaks, where the results demonstrate the efficiency and effectiveness of C-Watcher for early detection of high-risk neighborhoods from a large number of cities.",新しいコロナウイルス病（COVID-19）は日常生活を破壊し、今でも世界中で蔓延しています。非医薬品介入の既存の解決策は、通常、封じ込めまたは検疫のために住宅都市地域のサブセットをタイムリーかつ正確に選択する必要があり、確認された症例の空間分布がサブセット選択の重要な基準と見なされています。このような封じ込め措置は、一部の国でCOVID-19の蔓延を阻止または減速させることに成功しましたが、確認された症例の統計は通常時間遅延と粗粒度であるため、非効率的または非効率的であると批判されています。この問題に取り組むために、震源地から都市にCOVID-19が広がる前に、対象都市のすべての近隣をスクリーニングし、感染リスクを予測することを目的とした新しいデータ駆動型フレームワークであるC-Watcherを提案します。設計に関しては、C-WatcherはBaidu Mapsから大規模な長期の人間の移動性データを収集し、都市の移動性パターンに基づく一連の機能を使用して、都市のすべての住宅地を特徴付けます。さらに、地域で発生する前に直接の知識（震源地で知られている）をターゲット都市に転送するために、新しい敵対エンコーダフレームワークを採用して、モビリティ関連の機能から都市不変の表現を学習し、リスクの高い近隣地域を正確に早期に検出します。確認された症例が知られる前に、対象都市で。 COVID-19発生の初期段階で実データレコードを使用してC-Watcherで広範な実験を実施しました。その結果は、多数のリスクの高い近隣地域を早期に検出するためのC-Watcherの効率と有効性を示しています。都市。,https://d3i71xaburhd42.cloudfront.net/3e0ee08039f771f6e53cad8a02bff37ca26a4c6d/3-Figure1-1.png
CMAX++ : Leveraging Experience in Planning and Execution Using Inaccurate Models,"['Anirudh Vemula', 'J. Andrew Bagnell', 'Maxim Likhachev']",https://arxiv.org/abs/2009.09942,"Given access to accurate dynamical models, modern planning approaches are effective in computing feasible and optimal plans for repetitive robotic tasks. However, it is difficult to model the true dynamics of the real world before execution, especially for tasks requiring interactions with objects whose parameters are unknown. A recent planning approach, CMAX, tackles this problem by adapting the planner online during execution to bias the resulting plans away from inaccurately modeled regions. CMAX, while being provably guaranteed to reach the goal, requires strong assumptions on the accuracy of the model used for planning and fails to improve the quality of the solution over repetitions of the same task. In this paper we propose CMAX++, an approach that leverages real-world experience to improve the quality of resulting plans over successive repetitions of a robotic task. CMAX++ achieves this by integrating model-free learning using acquired experience with model-based planning using the potentially inaccurate model. We provide provable guarantees on the completeness and asymptotic convergence of CMAX++ to the optimal path cost as the number of repetitions increases. CMAX++ is also shown to outperform baselines in simulated robotic tasks including 3D mobile robot navigation where the track friction is incorrectly modeled, and a 7D pick-and-place task where the mass of the object is unknown leading to discrepancy between true and modeled dynamics.",正確な動的モデルへのアクセスを考えると、最新の計画アプローチは、反復的なロボットタスクの実行可能で最適な計画を計算するのに効果的です。ただし、特にパラメータが不明なオブジェクトとの相互作用を必要とするタスクの場合、実行前に実世界の真のダイナミクスをモデル化することは困難です。最近の計画アプローチであるCMAXは、実行中にプランナーをオンラインに適合させて、結果の計画を不正確にモデル化された領域から遠ざけることで、この問題に取り組んでいます。 CMAXは、目標を達成することが保証されていますが、計画に使用されるモデルの精度について強い仮定を必要とし、同じタスクを繰り返してもソリューションの品質を向上させることはできません。このホワイトペーパーでは、CMAX ++を提案します。これは、実際の経験を活用して、ロボットタスクを連続して繰り返すことで結果の計画の品質を向上させるアプローチです。 CMAX ++は、取得した経験を使用したモデルフリー学習と、潜在的に不正確なモデルを使用したモデルベースの計画を統合することでこれを実現します。繰り返し回数が増えるにつれて、CMAX ++が最適なパスコストに完全かつ漸近的に収束することを証明できる保証を提供します。 CMAX ++は、トラックの摩擦が誤ってモデル化されている3Dモバイルロボットナビゲーションや、オブジェクトの質量が不明で真のダイナミクスとモデル化されたダイナミクスの不一致につながる7Dピックアンドプレースタスクなど、シミュレートされたロボットタスクのベースラインを上回ることも示されています。,https://d3i71xaburhd42.cloudfront.net/eb5ac16a773644fa43d75a26ecb9d9819b53fd32/1-Figure1-1.png
Split-and-Bridge: Adaptable Class Incremental Learning within a Single Neural Network,"['Jong-Yeong Kim', 'Dong-Wan Choi']",,,,
Computing Quantal Stackelberg Equilibrium in Extensive-Form Games,"['Jakub Cerny', 'Viliam Lisy', 'Branislav Bošanský', 'Bo An']",,"Deployments of game-theoretic solution concepts in the real world have highlighted the necessity to consider human opponents’ boundedly rational behavior. If subrationality is not addressed, the system can face significant losses in terms of expected utility. While there exist algorithms for computing optimal strategies to commit to when facing subrational decision-makers in one-shot interactions, these algorithms cannot be generalized for solving sequential scenarios because of the inherent curse of strategy-space dimensionality in sequential games and because humans act subrationally in each decision point separately. We study optimal strategies to commit to against subrational opponents in sequential games for the first time and make the following key contributions: (1) we prove the problem is NP-hard in general; (2) to enable further analysis, we introduce a non-fractional reformulation of the direct non-concave representation of the equilibrium; (3) we identify conditions under which the problem can be approximated in polynomial time in the size of the representation; (4) we show how an MILP can approximate the reformulation with a guaranteed bounded error, and (5) we experimentally demonstrate that our algorithm provides higher quality results several orders of magnitude faster than a baseline method for general non-linear optimization.",現実の世界でのゲーム理論的ソリューションの概念の展開は、人間の対戦相手を限定合理的な行動と見なす必要性を浮き彫りにしました。サブ合理性に対処しないと、システムは期待効用の観点から重大な損失に直面する可能性があります。ワンショットインタラクションで準合理的な意思決定者に直面するときにコミットする最適な戦略を計算するためのアルゴリズムは存在しますが、これらのアルゴリズムは、逐次ゲームにおける戦略空間の次元の固有の呪いのため、および人間が準合理的に行動するため、逐次シナリオを解決するために一般化できません各決定ポイントで個別に。逐次手番ゲームでサブ合理的な対戦相手に対してコミットするための最適な戦略を初めて研究し、次の重要な貢献をします。（1）問題が一般にNP困難であることを証明します。 （2）さらなる分析を可能にするために、平衡の直接非凹表現の非分数再定式化を導入します。 （3）表現のサイズで問題を多項式時間で近似できる条件を特定します。 （4）MILPが保証された有界誤差で再定式化を近似する方法を示し、（5）アルゴリズムが一般的な非線形最適化のベースライン法よりも数桁速い高品質の結果を提供することを実験的に示します。,https://d3i71xaburhd42.cloudfront.net/a1600c90aa2255a7d3bf6a34348dae9b0fae4e8c/3-Figure1-1.png
Large Motion Video Super-Resolution with Dual Subnet and Multi-Stage Communicated Upsampling,"['Hongying Liu', 'Peng Zhao', 'Zhubo Ruan', 'Fanhua Shang', 'Yuanyuan Liu']",,,,
Symmetric Component Caching for Model Counting on Combinatorial Instances,"['Timothy van Bremen', 'Vincent Derkinderen', 'Shubham Sharma', 'Subhajit Roy', 'Kuldeep S Meel']",,"Given a propositional formula ψ, the model counting problem, also referred to as #SAT, seeks to compute the number of satisfying assignments (or models) of ψ. Modern search-based model counting algorithms are built on conflict-driven clause learning, combined with the caching of certain subformulas (called components) encountered during the search process. Despite significant progress in these algorithms over the years, state-of-the-art model counters often struggle to handle large but structured instances that typically arise in combinatorial settings. Motivated by the observation that these counters do not exploit the inherent symmetries exhibited in such instances, we revisit the component caching architecture employed in current counters and introduce a novel caching scheme that focuses on identifying symmetric components. We first prove the soundness of our approach, and then integrate it into the stateof-the-art model counter GANAK. Our extensive experiments on hard combinatorial instances demonstrate that the resulting counter, SYMGANAK, leads to improvements over GANAK both in terms of PAR-2 score and the number of instances",命題式が与えられると、＃SATとも呼ばれるモデルカウント問題は、の満足のいく割り当て（またはモデル）の数を計算しようとします。最新の検索ベースのモデルカウントアルゴリズムは、検索プロセス中に発生した特定のサブ式（コンポーネントと呼ばれる）のキャッシュと組み合わせて、競合駆動型の句学習に基づいて構築されています。何年にもわたってこれらのアルゴリズムが大幅に進歩したにもかかわらず、最先端のモデルカウンターは、通常、組み合わせの設定で発生する、大きくても構造化されたインスタンスの処理に苦労することがよくあります。これらのカウンターがそのような場合に示される固有の対称性を利用しないという観察に動機付けられて、現在のカウンターで採用されているコンポーネントキャッシングアーキテクチャを再検討し、対称コンポーネントの識別に焦点を当てた新しいキャッシングスキームを紹介します。まず、アプローチの健全性を証明し、それを最先端のモデルカウンターGANAKに統合します。ハードコンビナトリアルインスタンスに関する私たちの広範な実験は、結果として得られるカウンターSYMGANAKが、PAR-2スコアとインスタンス数の両方の点でGANAKよりも改善されることを示しています。,https://d3i71xaburhd42.cloudfront.net/473bc283b625f6d21c4905ed33a293cd2c135ec6/6-Figure1-1.png
Modeling Heterogeneous Relations across Multiple Modes for Potential Crowd Flow Prediction,"['Qiang Zhou', 'Jingjing Gu', 'Xinjiang Lu', 'Fuzhen Zhuang', 'Yanchao Zhao', 'Qiuhong Wang', 'Xiao Zhang']",https://arxiv.org/abs/2101.06954,"Potential crowd flow prediction for new planned transportation sites is a fundamental task for urban planners and administrators. Intuitively, the potential crowd flow of the new coming site can be implied by exploring the nearby sites. However, the transportation modes of nearby sites (e.g. bus stations, bicycle stations) might be different from the target site (e.g. subway station), which results in severe data scarcity issues. To this end, we propose a data driven approach, named MOHER, to predict the potential crowd flow in a certain mode for a new planned site. Specifically, we first identify the neighbor regions of the target site by examining the geographical proximity as well as the urban function similarity. Then, to aggregate these heterogeneous relations, we devise a cross-mode relational GCN, a novel relation-specific transformation model, which can learn not only the correlation but also the differences between different transportation modes. Afterward, we design an aggregator for inductive potential flow representation. Finally, an LTSM module is used for sequential flow prediction. Extensive experiments on real-world data sets demonstrate the superiority of the MOHER framework compared with the state-of-the-art algorithms.",新たに計画された交通機関の潜在的な群集の流れの予測は、都市計画者と管理者にとって基本的なタスクです。直感的には、近くのサイトを探索することで、新しいサイトの潜在的な群集の流れを暗示することができます。ただし、近くのサイト（バス停、駐輪場など）の交通手段が対象サイト（地下鉄駅など）と異なる場合があり、データ不足が深刻な問題になります。この目的のために、MOHERという名前のデータ駆動型アプローチを提案して、新しい計画サイトの特定のモードでの潜在的な群集の流れを予測します。具体的には、まず地理的な近接性と都市機能の類似性を調べることにより、ターゲットサイトの隣接地域を特定します。次に、これらの異種関係を集約するために、相関だけでなく、異なる輸送モード間の違いも学習できる、新しい関係固有の変換モデルであるクロスモード関係GCNを考案します。その後、誘導ポテンシャルフロー表現用のアグリゲーターを設計します。最後に、LTSMモジュールはシーケンシャルフロー予測に使用されます。実世界のデータセットでの広範な実験は、最先端のアルゴリズムと比較したMOHERフレームワークの優位性を示しています。,https://d3i71xaburhd42.cloudfront.net/ba7b80fd765b3326dbc5f8cb7692f5b40ee25a10/1-Figure1-1.png
Dependency Stochastic Boolean Satisfiability: A Logical Formalism for NEXPTIME Decision Problems with Uncertainty,"['Nian-Ze Lee', 'Jie-Hong R Jiang']",https://arxiv.org/abs/1911.04112,"Stochastic Boolean Satisfiability (SSAT) is a logical formalism to model decision problems with uncertainty, such as Partially Observable Markov Decision Process (POMDP) for verification of probabilistic systems. SSAT, however, is limited by its descriptive power within the PSPACE complexity class. More complex problems, such as the NEXPTIME-complete Decentralized POMDP (Dec-POMDP), cannot be succinctly encoded with SSAT. To provide a logical formalism of such problems, we generalize the Dependency Quantified Boolean Formula (DQBF), a representative problem in the NEXPTIME-complete class, to its stochastic variant, named Dependency SSAT (DSSAT), and show that DSSAT is also NEXPTIME-complete. We demonstrate the potential applications of DSSAT to circuit synthesis of probabilistic design and approximate design. Furthermore, to study the descriptive power of DSSAT, we establish a polynomial-time reduction from Dec-POMDP to DSSAT. With the theoretical foundations paved in this work, our results may encourage DSSAT solver development to enable potential broad applications.",確率的充足可能性（SSAT）は、確率システムの検証のための部分観測マルコフ決定過程（POMDP）など、不確実性を伴う決定問題をモデル化するための論理形式です。ただし、SSATは、PSPACE複雑度クラス内の記述力によって制限されます。 NEXPTIME-complete分散型POMDP（Dec-POMDP）などのより複雑な問題は、SSATで簡潔にエンコードすることはできません。このような問題の論理形式を提供するために、NEXPTIME-completeクラスの代表的な問題であるDependency Quantified Boolean Formula（DQBF）を、Dependency SSAT（DSSAT）という名前の確率的バリアントに一般化し、DSSATもNEXPTIME-であることを示します。コンプリート。確率的設計と近似設計の回路合成へのDSSATの潜在的なアプリケーションを示します。さらに、DSSATの記述力を研究するために、Dec-POMDPからDSSATへの多項式時間短縮を確立します。この作業で舗装された理論的基礎により、私たちの結果は、潜在的な幅広いアプリケーションを可能にするDSSATソルバーの開発を促進する可能性があります。,https://d3i71xaburhd42.cloudfront.net/7c38f2393017ca86974d93001d354ebe6fe0d012/8-Figure1-1.png
SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent Prediction,"['Jasmine Sekhon', 'Cody Fleming']",https://arxiv.org/abs/2102.00109,"Safe navigation of autonomous agents in human centric environments requires the ability to understand and predict motion of neighboring pedestrians. However, predicting pedestrian intent is a complex problem. Pedestrian motion is governed by complex social navigation norms, is dependent on neighbors’ trajectories, and is multimodal in nature. In this work, we propose SCAN, a Spatial Context Attentive Network that can jointly predict socially-acceptable multiple future trajectories for all pedestrians in a scene. SCAN encodes the influence of spatially close neighbors using a novel spatial attention mechanism in a manner that relies on fewer assumptions, is parameter efficient, and is more interpretable compared to state-of-the-art spatial attention approaches. Through experiments on several datasets we demonstrate that our approach can also quantitatively outperform state of the art trajectory prediction methods in terms of accuracy of predicted intent.",人間中心の環境で自律エージェントを安全にナビゲートするには、隣接する歩行者の動きを理解して予測する能力が必要です。ただし、歩行者の意図を予測することは複雑な問題です。歩行者の動きは、複雑な社会的ナビゲーション規範によって支配され、隣人の軌道に依存し、本質的にマルチモーダルです。この作業では、シーン内のすべての歩行者の社会的に受け入れられる複数の将来の軌道を共同で予測できる空間コンテキスト注意ネットワークであるSCANを提案します。 SCANは、新しい空間的注意メカニズムを使用して、空間的に近い隣人の影響を、より少ない仮定に依存し、パラメーター効率が高く、最先端の空間的注意アプローチと比較してより解釈しやすい方法でエンコードします。いくつかのデータセットでの実験を通じて、私たちのアプローチは、予測された意図の精度の点で、最先端の軌道予測方法よりも定量的に優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/c5cfe7ef60a1b91822c3fc32530c1db9b443f0b0/2-Figure1-1.png
Dynamic Memory Based Attention Network for Sequential Recommendation,"['Qiaoyu Tan', 'Jianwei Zhang', 'Ninghao Liu', 'Xiao Huang', 'Hongxia Yang', 'Jingren Zhou', 'Xia Hu']",,,,
SALNet: Semi-Supervised Few-Shot Text Classification with Attention-Based Lexicon Construction,"['Ju-Hyoung Lee', 'Sang-Ki Ko', 'Yo-Sub Han']",,,,
PHASE: Physically-Grounded Abstract Social Events for Machine Social Perception,"['Aviv Netanyahu', 'Tianmin Shu', 'Boris Katz', 'Andrei Barbu', 'Joshua Tenenbaum']",,,,
AdvantageNAS: Efficient Neural Architecture Search with Credit Assignment,"['Rei Sato', 'Jun Sakuma', 'Youhei Akimoto']",https://arxiv.org/abs/2012.06138,"Neural architecture search (NAS) is an approach for automatically designing a neural network architecture without human effort or expert knowledge. However, the high computational cost of NAS limits its use in commercial applications. Two recent NAS paradigms, namely one-shot and sparse propagation, which reduce the time and space complexities, respectively, provide clues for solving this problem. In this paper, we propose a novel search strategy for one-shot and sparse propagation NAS, namely AdvantageNAS, which further reduces the time complexity of NAS by reducing the number of search iterations. AdvantageNAS is a gradient-based approach that improves the search efficiency by introducing credit assignment in gradient estimation for architecture updates. Experiments on the NAS-Bench-201 and PTB dataset show that AdvantageNAS discovers an architecture with higher performance under a limited time budget compared to existing sparse propagation NAS. To further reveal the reliabilities of AdvantageNAS, we investigate it theoretically and find that it monotonically improves the expected loss and thus converges.",ニューラルアーキテクチャ検索（NAS）は、人間の努力や専門知識がなくてもニューラルネットワークアーキテクチャを自動的に設計するためのアプローチです。ただし、NASの計算コストが高いため、商用アプリケーションでの使用が制限されます。最近の2つのNASパラダイム、つまりワンショット伝搬とスパース伝搬は、それぞれ時間と空間の複雑さを軽減し、この問題を解決するための手がかりを提供します。この論文では、ワンショットでスパースな伝播NAS、つまりAdvantageNASの新しい検索戦略を提案します。これは、検索の反復回数を減らすことでNASの時間計算量をさらに削減します。 AdvantageNASは、アーキテクチャ更新の勾配推定にクレジット割り当てを導入することで検索効率を向上させる勾配ベースのアプローチです。 NAS-Bench-201およびPTBデータセットでの実験は、AdvantageNASが、既存のスパース伝搬NASと比較して、限られた時間予算の下でより高いパフォーマンスを備えたアーキテクチャを発見することを示しています。 AdvantageNASの信頼性をさらに明らかにするために、理論的に調査し、期待損失を単調に改善して収束することを確認しました。,https://d3i71xaburhd42.cloudfront.net/71b9f5f3f33f6f3f9eb78d01f2e8f9d3db8fc616/6-Figure1-1.png
The Smoothed Complexity of Computing Kemeny and Slater Rankings,"['Lirong Xia', 'Weiqiang Zheng']",https://arxiv.org/abs/2010.13020,"The computational complexity of winner determination under common voting rules is a classical and fundamental topic in the field of computational social choice. Previous work has established the NP-hardness of winner determination under some commonly-studied voting rules, especially the Kemeny rule and the Slater rule. In a recent blue-sky paper, Baumeister, Hogrebe, and Rothe (2020) questioned the relevance of the worst-case nature of NP-hardness in social choice and proposed to conduct smoothed complexity analysis (Spielman and Teng 2009) under Blaser and Manthey (2015)'s framework. 
In this paper, we develop the first smoothed complexity results for winner determination in voting. We illustrate the inappropriateness of Blaser and Manthey (2015)'s smoothed complexity framework in social choice contexts by proving a paradoxical result, which states that the exponential-time brute force search algorithm is smoothed poly-time according to their definition. We then prove the smoothed hardness of Kemeny and Slater using the classical smoothed complexity analysis, and prove a parameterized typical-case smoothed easiness result for Kemeny. Overall, our results show that smoothed complexity analysis in computational social choice is a challenging and fruitful topic.",一般的な投票ルールの下での勝者決定の計算の複雑さは、計算による社会的選択の分野における古典的かつ基本的なトピックです。以前の研究では、一般的に研究されているいくつかの投票規則、特にケメニー規則とスレーター規則の下で、勝者決定のNP困難性が確立されています。最近の青空の論文で、Baumeister、Hogrebe、およびRothe（2020）は、社会的選択におけるNP困難の最悪の場合の性質の関連性に疑問を呈し、Blaser and Mantheyの下で平滑化された複雑性分析（Spielman and Teng 2009）を実施することを提案しました。 （2015）のフレームワーク。この論文では、投票における勝者決定のための最初の平滑化された複雑さの結果を開発します。逆説的な結果を証明することにより、社会的選択の文脈におけるBlaser and Manthey（2015）の平滑化された複雑さのフレームワークの不適切さを説明します。これは、指数時間ブルートフォース検索アルゴリズムがその定義に従って多時間平滑化されることを示しています。次に、古典的な平滑化された複雑さの分析を使用して、KemenyとSlaterの平滑化された硬度を証明し、Kemenyのパラメーター化された典型的なケースの平滑化された容易さの結果を証明します。全体として、私たちの結果は、計算による社会的選択におけるスムーズな複雑さの分析が挑戦的で実り多いトピックであることを示しています。,https://d3i71xaburhd42.cloudfront.net/a35c6813578f8723d7e3200a87f35e23896bb21c/4-Figure1-1.png
Branch and Price for Bus Driver Scheduling with Complex Break Constraints,"['Lucas Kletzander', 'Nysret Musliu', 'Pascal Van Hentenryck']",,,,
Window Loss for Abnormal Finding Classification and Localization in X-Ray Image with Point-Base Annotation,"['Xinyu Zhang', 'Yirui Wang', 'Chi Tung Cheng', 'Le Lu', 'Adam P Harrison', 'Jing Xiao', 'ChienHung Liao', 'Shun Miao']",,,,
Measuring Dependence with Matrix-Based Entropy Functional,"['Shujian Yu', 'Francesco Alesiani', 'Xi Yu', 'Robert Jenssen', 'Jose Principe']",https://arxiv.org/abs/2101.10160,"Measuring the dependence of data plays a central role in statistics and machine learning. In this work, we summarize and generalize the main idea of existing information-theoretic dependence measures into a higher-level perspective by the Shearer’s inequality. Based on our generalization, we then propose two measures, namely the matrix-based normalized total correlation (T ∗ α) and the matrix-based normalized dual total correlation (D∗ α), to quantify the dependence of multiple variables in arbitrary dimensional space, without explicit estimation of the underlying data distributions. We show that our measures are differentiable and statistically more powerful than prevalent ones. We also show the impact of our measures in four different machine learning problems, namely the gene regulatory network inference, the robust machine learning under covariate shift and non-Gaussian noises, the subspace outlier detection, and the understanding of the learning dynamics of convolutional neural networks (CNNs), to demonstrate their utilities, advantages, as well as implications to those problems. Code of our dependence measure is available at: https://bit.ly/AAAI-dependence. Introduction Measuring the strength of dependence between random variables plays a central role in statistics and machine learning. For the linear dependence case, measures such as the Pearson’s ρ, the Spearman’s rank and the Kendall’s τ are computationally efficient and have been widely used. For the more general case where the two variables share a nonlinear relationship, one of the most well-known dependence measures is the mutual information and its modifications such as the maximal information coefficient (Reshef et al. 2011). However, real-world data often contains three or more variables which can exhibit higher-order dependencies. If bivariate based measures are used to identify multivariate dependence, wrong conclusions may drawn. For example, in the XOR gate, we have y = x ⊕ x with x, x being binary random processes with equal probability. Although x, x individually are independent to y, the full dependence is synergistically contained in the union of {x1,x2} and y. On the other hand, in various practical applications, the observational data or variables of interest lie on a highCopyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. dimensional space. Thus, it is desirable to extend the theory of scalar variable dependence to an arbitrary dimension. Despite that tremendous efforts have been made based on the seven postulates (on measure of dependence on pair of variables) proposed by Alfréd Rényi (Rényi 1959), the problem of measuring dependence (especially in a nonparametric manner) still remains challenging and unsatisfactory (Fernandes and Gloor 2010). This is not hard to understand. Note that, most of the existing measures are defined as some functions of a density. Thus, a prerequisite for them is to estimate the underlying data distributions, a notoriously difficult problem in high-dimensional space. Moreover, current measures primarily focus on two special scenarios: 1) the dependence associated with each dimension of a random vector (e.g., the multivariate maximal correlation (MAC) (Nguyen et al. 2014)); and 2) the dependence between two random vectors (e.g., the Hilbert Schmidt Independence Criterion (HSIC) (Gretton et al. 2005)). The former is called multivariate correlation analysis in machine learning, and the latter is commonly referred to as random vector association in statistics. Our main contributions are multi-fold: • We provide a unified view of existing informationtheoretic dependence measures and illustrate their inner connections. We also generalize the main idea of these measures into a higher-level perspective by the Shearer’s inequality (Chung et al. 1986). • Motivated by our generalization, we suggest two measures, namely the matrix-based normalized total correlation (T ∗ α) and the matrix-based normalized dual total correlation (D∗ α), to quantify the dependence of data by making use of the recently proposed matrix-based Rényi’s αentropy functional estimator (Sanchez Giraldo, Rao, and Principe 2014; Yu et al. 2019). • We show that T ∗ α and D ∗ α enjoy several appealing properties. First, they are not constrained by the number of variables and variable dimension. Second, they are statistically more powerful than most of the prevalent measures. Moreover, they are differentiable, which make them suitable to be used as loss functions to train neural networks. • We show that our measures offer a remarkable performance gain to benchmark methods in applications like gene regulatory network (GRN) inference and subspace ar X iv :2 10 1. 10 16 0v 1 [ cs .L G ] 2 5 Ja n 20 21 outlier detection. They also provide insights to challenging topics like the understanding of the dynamics of learning of Convolutional Neural Networks (CNNs). • Motivated by (Greenfeld and Shalit 2020) that training a neural network by encouraging the distribution of the prediction residuals e is statistically independent of the distribution of the input x, we show that our measure (as a loss) improves robust machine learning against the shift of the input distribution (a.k.a., the covariate shift (Sugiyama et al. 2008)) and non-Gaussian noises. We also establish the connection between our loss to the minimum error entropy (MEE) criterion (Erdogmus and Principe 2002), a learning principle that has been extensively investigated in signal processing and process control. Background Knowledge Problem Formulation We consider the problem of estimating the total amount of dependence of the dm-dimensional components of the random variable y = [y;y; · · · ;y] ∈ R, in which them-th component y ∈ Rm and d =∑Lm=1 dm. The estimation is based purely on N i.i.d. samples from y, i.e., {yi}i=1. Usually, we expect the derived statistic to be strictly between 0 and 1 for improved interpretability (Wang et al. 2017). Obviously, when L = 2, we are dealing with random vector association between y ∈ R1 and y ∈ R2 . Notable measures in this category include the HSIC, the Randomized Dependence Coefficient (RDC) (Lopez-Paz, Hennig, and Schölkopf 2013), the Cauchy-Schwarz quadratic mutual information (QMI CS) (Principe et al. 2000) and the recently developed mutual information neural estimator (MINE) (Belghazi et al. 2018). On the other hand, in case of di = 1 (i = 1, 2, · · · , L), the problem reduces to the multivariate correlation analysis on each dimension of y. Examples in this category are the multivariate Spearman’s ρ (Schmid and Schmidt 2007) and the MAC. Different from the above mentioned measures, we seek a general measure that is applicable to multiple variables in an arbitrary dimensional space (i.e., without constrains on L and di). But, at the same time, we also hope that our measure is interpretable and statistically more powerful than existing counterparts in quantifying either random vector association or multivariate correlation. A Unified View of Information-Theoretic Measures From an information-theoretic perspective, a dependence measure M that quantifies how much a random vector y = {y1;y2; · · · ;yL} ∈ R deviates from statistical independence in each component can take the form of:",データの依存関係を測定することは、統計と機械学習において中心的な役割を果たします。この作業では、既存の情報理論的依存性測定の主なアイデアを要約し、シアラーの不等式によるより高いレベルの視点に一般化します。次に、一般化に基づいて、明示的な推定なしで、任意の次元空間における複数の変数の依存性を定量化するために、マトリックスベースの正規化された全相関（T）とマトリックスベースの正規化された二重総相関（D）の2つの測定値を提案します。基礎となるデータ分布の。私たちの測定値は微分可能であり、一般的な測定値よりも統計的に強力であることを示しています。また、4つの異なる機械学習問題、つまり遺伝子調節ネットワークの推論、共変量シフトと非ガウスノイズの下での堅牢な機械学習、部分空間の異常検出、畳み込みニューラルの学習ダイナミクスの理解における測定の影響を示します。ネットワーク（CNN）、それらのユーティリティ、利点、およびそれらの問題への影響を示します。依存性測定のコードは、https：//bit.ly/AAAI-dependenceで入手できます。はじめに確率変数間の依存の強さを測定することは、統計と機械学習において中心的な役割を果たします。線形依存の場合、ピアソン、スピアマンの順位、ケンダルなどの尺度は計算効率が高く、広く使用されています。 2つの変数が非線形関係を共有するより一般的なケースの場合、最もよく知られている依存性の尺度の1つは、相互情報量と、最大情報係数などのその修正です（Reshef et al.2011）。ただし、実際のデータには、高次の依存関係を示す可能性のある3つ以上の変数が含まれていることがよくあります。二変量ベースの測定値を使用して多変量依存性を特定すると、誤った結論が導き出される可能性があります。たとえば、XORゲートでは、y = xxであり、xは等しい確率のバイナリランダムプロセスです。 x、xは個別にyに独立していますが、完全な依存関係は相乗的にx1、x2、yの和集合に含まれています。一方、さまざまな実用的なアプリケーションでは、観測データまたは関心のある変数は、highCopyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）にあります。全著作権所有。次元空間。したがって、スカラー変数依存性の理論を任意の次元に拡張することが望ましい。 Alfred Renyi（Renyi 1959）によって提案された7つの仮定（変数のペアへの依存性の測定）に基づいて多大な努力が払われてきたにもかかわらず、依存性の測定の問題（特にノンパラメトリックな方法）は依然として挑戦的で不十分です（Fernandes and Gloor 2010）。これは理解するのは難しいことではありません。既存のメジャーのほとんどは、密度のいくつかの関数として定義されていることに注意してください。したがって、それらの前提条件は、高次元空間で悪名高い難しい問題である、基礎となるデータ分布を推定することです。さらに、現在の対策は主に2つの特別なシナリオに焦点を当てています。1）ランダムベクトルの各次元に関連する依存関係（たとえば、多変量最大相関（MAC）（Nguyen et al.2014））。 2）2つのランダムベクトル間の依存性（たとえば、ヒルベルトシュミット独立基準（HSIC）（Gretton et al.2005））。前者は機械学習では多変量相関分析と呼ばれ、後者は一般に統計ではランダムベクトル関連付けと呼ばれます。私たちの主な貢献は複数あります。既存の情報理論的依存性測定の統一されたビューを提供し、それらの内部接続を示します。また、これらの対策の主な考え方を、シアラーの不等式によるより高いレベルの視点に一般化します（Chung et al.1986）。私たちの一般化に動機付けられて、最近提案されたマトリックスベースを利用することによってデータの依存性を定量化するために、マトリックスベースの正規化された全相関（T）とマトリックスベースの正規化された二重総相関（D）の2つの尺度を提案しますレニーエントロピー関数推定量（Sanchez Giraldo、Rao、およびPrincipe 2014; Yu et al.2019）。 TとDがいくつかの魅力的な特性を楽しんでいることを示します。まず、変数の数と変数の次元によって制約されません。第二に、それらは一般的な手段のほとんどよりも統計的に強力です。さらに、それらは微分可能であるため、ニューラルネットワークをトレーニングするための損失関数として使用するのに適しています。私たちの測定値は、遺伝子調節ネットワーク（GRN）推論や部分空間ar X iv：2 10 1. 10 16 0v 1 [cs .LG] 2 5 Ja n 2021外れ値検出などのアプリケーションのベンチマーク手法に顕著なパフォーマンスの向上をもたらすことを示しています。 。また、畳み込みニューラルネットワーク（CNN）の学習のダイナミクスの理解など、難しいトピックへの洞察も提供します。予測残差eの分布を奨励することによってニューラルネットワークをトレーニングすることは、入力xの分布から統計的に独立しているという（Greenfeld and Shalit 2020）に動機付けられて、私たちの測定値（損失として）がシフトに対するロバストな機械学習を改善することを示します入力分布（別名、共変量シフト（Sugiyama etal。2008））と非ガウスノイズの比較。また、損失と最小エラーエントロピー（MEE）基準（Erdogmus and Principe 2002）との関係を確立します。これは、信号処理とプロセス制御で広く調査されている学習原理です。背景知識問題の定式化確率変数y = [y; y;のdm次元成分の依存性の総量を推定する問題を検討します。 ; y] R、ここで、それらのコンポーネントyRmおよびd = Lm = 1dm。推定は、yからのN iidサンプル、つまりyii = 1に純粋に基づいています。通常、解釈可能性を向上させるために、導出された統計は厳密に0から1の間であると予想されます（Wang et al.2017）。明らかに、L = 2の場合、yR1とyR2の間のランダムなベクトルの関連付けを処理しています。このカテゴリの注目すべき指標には、HSIC、ランダム化依存係数（RDC）（Lopez-Paz、Hennig、およびScholkopf 2013）、コーシー-シュワルツ二次相互情報量（QMI CS）（Principe etal。2000）、および最近開発されたものが含まれます。相互情報量神経推定量（MINE）（Belghazi et al.2018）。一方、di = 1（i = 1、2、、L）の場合、問題はyの各次元での多変量相関分析に還元されます。このカテゴリの例は、多変量スピアマン（Schmid and Schmidt 2007）とMACです。上記の尺度とは異なり、任意の次元空間内の複数の変数に適用できる一般的な尺度を探します（つまり、Lとdiに制約はありません）。しかし同時に、ランダムなベクトルの関連付けまたは多変量相関の定量化において、私たちの測定値が解釈可能であり、既存の測定値よりも統計的に強力であることも期待しています。情報理論的尺度の統一されたビュー情報理論的観点から、ランダムベクトルy = y1; y2;の量を定量化する依存性尺度M。 ; yL Rは、各コンポーネントの統計的独立性から逸脱し、次の形式をとることができます。,https://d3i71xaburhd42.cloudfront.net/efa10c8d7e628341997ab07a5feb99b03db4dc17/4-Figure1-1.png
YOLObile: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design,"['Yuxuan Cai', 'Hongjia Li', 'Geng Yuan', 'Wei Niu', 'Yanyu Li', 'Xulong Tang', 'Bin Ren', 'Yanzhi Wang']",https://arxiv.org/abs/2009.05697,"The rapid development and wide utilization of object detection techniques have aroused attention on both accuracy and speed of object detectors. However, the current state-of-the-art object detection works are either accuracy-oriented using a large model but leading to high latency or speed-oriented using a lightweight model but sacrificing accuracy. In this work, we propose YOLObile framework, a real-time object detection on mobile devices via compression-compilation co-design. A novel block-punched pruning scheme is proposed for any kernel size. To improve computational efficiency on mobile devices, a GPU-CPU collaborative scheme is adopted along with advanced compiler-assisted optimizations. Experimental results indicate that our pruning scheme achieves 14$\times$ compression rate of YOLOv4 with 49.0 mAP. Under our YOLObile framework, we achieve 17 FPS inference speed using GPU on Samsung Galaxy S20. By incorporating our proposed GPU-CPU collaborative scheme, the inference speed is increased to 19.1 FPS, and outperforms the original YOLOv4 by 5$\times$ speedup.",物体検出技術の急速な発展と幅広い利用により、物体検出器の精度と速度の両方に注目が集まっています。ただし、現在の最先端のオブジェクト検出作業は、大きなモデルを使用して精度を重視しているが待ち時間が長くなるか、軽量モデルを使用して速度を重視しているが精度を犠牲にしている。この作業では、圧縮コンパイルの共同設計によるモバイルデバイスでのリアルタイムオブジェクト検出であるYOLObileフレームワークを提案します。新しいブロックパンチプルーニングスキームが、任意のカーネルサイズに対して提案されています。モバイルデバイスでの計算効率を向上させるために、GPU-CPUコラボレーションスキームが、高度なコンパイラ支援最適化とともに採用されています。実験結果は、私たちの剪定スキームが49.0mAPでYOLOv4の14圧縮率を達成することを示しています。 YOLObileフレームワークでは、Samsung GalaxyS20でGPUを使用して17FPSの推論速度を達成しています。提案されたGPU-CPUコラボレーションスキームを組み込むことにより、推論速度は19.1 FPSに増加し、元のYOLOv4を5スピードアップします。,https://d3i71xaburhd42.cloudfront.net/a0924b1d78ffcd2e670835ff70e4791a97ed8224/2-Figure1-1.png
Category Dictionary Guided Unsupervised Domain Adaptation for Object Detection,"['Shuai Li', 'Jianqiang Huang', 'Xian-Sheng Hua', 'Lei Zhang']",,"Unsupervised domain adaption (UDA) is a promising solution to enhance the generalization ability of a model from a source domain to a target domain without manually annotating labels for the target data. Recent works in cross-domain object detection mostly resort to adversarial feature adaptation to match the marginal distributions of two domains. However, perfect feature alignment is hard to achieve and what’s more is likely to cause negative transfer due to the high complexity of object detection. In this paper, we take a different approach to reduce the domain gap by a selftraining paradigm, which regards the pseudo-labels as ground truth to fully exploit the unlabeled target data. In order to generate more informative pseudo labels, we further propose a category dictionary guided (CDG) UDA model for crossdomain object detection, which learns category-specific dictionaries from the source domain to represent the candidate boxes in target domain. The representation residual can be used for not only pseudo label assignment but also quality (e.g., IoU) estimation of the candidate box. Compared with decision boundary based classifiers such as softmax, the proposed CDG scheme can select more informative and reliable pseudo-boxes. Experimental results on benchmark datasets show that the proposed CDG significantly exceeds the stateof-the-arts in cross-domain object detection.",教師なしドメイン適応（UDA）は、ターゲットデータのラベルに手動で注釈を付けることなく、ソースドメインからターゲットドメインへのモデルの一般化機能を強化するための有望なソリューションです。クロスドメインオブジェクト検出の最近の研究は、主に2つのドメインの周辺分布に一致するように敵対的な特徴の適応に頼っています。ただし、完全な特徴の位置合わせを実現することは困難であり、オブジェクト検出が非常に複雑であるため、それ以上に負の転送が発生する可能性があります。このホワイトペーパーでは、セルフトレーニングパラダイムによってドメインギャップを削減するための別のアプローチを採用しています。このパラダイムでは、疑似ラベルをグラウンドトゥルースと見なして、ラベルのないターゲットデータを完全に活用します。より有益な疑似ラベルを生成するために、クロスドメインオブジェクト検出用のカテゴリ辞書ガイド（CDG）UDAモデルをさらに提案します。これは、ソースドメインからカテゴリ固有の辞書を学習して、ターゲットドメインの候補ボックスを表します。表現残余は、疑似ラベル割り当てだけでなく、候補ボックスの品質（IoUなど）の推定にも使用できます。ソフトマックスなどの決定境界ベースの分類器と比較して、提案されたCDGスキームは、より有益で信頼性の高い疑似ボックスを選択できます。ベンチマークデータセットの実験結果は、提案されたCDGがクロスドメインオブジェクト検出の最先端を大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/5e412cedaa116ed4d1965dc4815ca56969be1be7/3-Figure1-1.png
Neural Utility Functions,"['Porter Jenkins', 'Ahmad Farag', 'Stockton Jenkins', 'Huaxiu Yao', 'Suhang Wang', 'Zhenhui Li']",,,,
Explaining Convolutional Neural Networks through Attribution-Based Input Sampling and Block-Wise Feature Aggregation,"['Sam Sattarzadeh', 'Mahesh Sudhakar', 'Anthony Lem', 'Shervin Mehryar', 'Konstantinos N Plataniotis', 'Jongseong Jang', 'Hyunwoo Kim', 'Yeonjeong Jeong', 'SangMin Lee', 'Kyunghoon Bae']",,,,
Towards Fully Automated Manga Translation,"['Ryota Hinami', 'Shonosuke Ishiwatari', 'Kazuhiko Yasuda', 'Yusuke Matsui']",https://arxiv.org/abs/2012.14271,"We tackle the problem of machine translation (MT) of manga, Japanese comics. Manga translation involves two important problems in MT: context-aware and multimodal translation. Since text and images are mixed up in an unstructured fashion in manga, obtaining context from the image is essential for its translation. However, it is still an open problem how to extract context from images and integrate into MT models. In addition, corpus and benchmarks to train and evaluate such models are currently unavailable. In this paper, we make the following four contributions that establish the foundation of manga translation research. First, we propose a multimodal context-aware translation framework. We are the first to incorporate context information obtained from manga images. It enables us to translate texts in speech bubbles that cannot be translated without using context information (e.g., texts in other speech bubbles, gender of speakers, etc.). Second, for training the model, we propose the approach to automatic corpus construction from pairs of original manga and their translations, by which a large parallel corpus can be constructed without any manual labeling. Third, we created a new benchmark to evaluate manga translation. Finally, on top of our proposed methods, we devised a first comprehensive system for fully automated manga translation.",マンガ、日本の漫画の機械翻訳（MT）の問題に取り組んでいます。マンガの翻訳には、MTにおける2つの重要な問題が含まれます。コンテキストアウェアとマルチモーダル翻訳です。マンガではテキストと画像が構造化されていない形で混ざり合っているため、画像からコンテキストを取得することが翻訳に不可欠です。ただし、画像からコンテキストを抽出してMTモデルに統合する方法は未解決の問題です。さらに、そのようなモデルをトレーニングおよび評価するためのコーパスとベンチマークは現在利用できません。本稿では、マンガのトランスレーショナルリサーチの基盤となる以下の4つの貢献を行います。まず、マルチモーダルなコンテキストアウェア翻訳フレームワークを提案します。マンガ画像から得られたコンテキスト情報を初めて取り入れました。これにより、コンテキスト情報を使用しないと翻訳できない吹き出しのテキスト（たとえば、他の吹き出しのテキスト、話者の性別など）を翻訳できます。次に、モデルをトレーニングするために、オリジナルのマンガとその翻訳のペアから自動コーパスを構築するアプローチを提案します。これにより、手動でラベルを付けることなく、大きなパラレルコーパスを構築できます。第三に、マンガの翻訳を評価するための新しいベンチマークを作成しました。最後に、提案された方法に加えて、完全に自動化されたマンガ翻訳のための最初の包括的なシステムを考案しました。,https://d3i71xaburhd42.cloudfront.net/a8302a61f49bbf1e702d417c4122dfbc729a4985/1-Figure1-1.png
Predictive Adversarial Learning from Positive and Unlabeled Data,"['Wenpeng Hu', 'Ran Le', 'Bing Liu', 'Feng Ji', 'Jinwen Ma', 'Dongyan Zhao', 'Rui Yan']",,,,
Cascade Size Distributions: Why They Matter and How To Compute Them Efficiently,"['Rebekka Burkholz', 'John Quackenbush']",https://arxiv.org/abs/1909.05416,"Cascade models are central to understanding, predicting, and controlling epidemic spreading and information propagation. Related optimization, including influence maximization, model parameter inference, or the development of vaccination strategies, relies heavily on sampling from a model. This is either inefficient or inaccurate. As alternative, we present an efficient message passing algorithm that computes the probability distribution of the cascade size for the Independent Cascade Model on weighted directed networks and generalizations. Our approach is exact on trees but can be applied to any network topology. It approximates locally treelike networks well, scales to large networks, and can lead to surprisingly good performance on more dense networks, as we also exemplify on real world data.",カスケードモデルは、エピデミックの蔓延と情報の伝播を理解、予測、および制御するための中心的な役割を果たします。影響の最大化、モデルパラメータの推論、ワクチン接種戦略の開発など、関連する最適化は、モデルからのサンプリングに大きく依存しています。これは非効率的または不正確です。別の方法として、重み付き有向ネットワークと一般化での独立カスケードモデルのカスケードサイズの確率分布を計算する効率的なメッセージパッシングアルゴリズムを紹介します。私たちのアプローチはツリーに正確ですが、どのネットワークトポロジにも適用できます。これは、ローカルのツリー状ネットワークによく近似し、大規模なネットワークに拡張でき、実際のデータでも例示しているように、より高密度のネットワークで驚くほど優れたパフォーマンスを実現できます。,https://d3i71xaburhd42.cloudfront.net/2e2d33a224f1569f071286e13dbf8c00a1291287/3-Figure1-1.png
Analogical Image Translation for Fog Generation,"['Rui Gong', 'Dengxin Dai', 'Yuhua Chen', 'Wen Li', 'Danda Pani Paudel', 'Luc Van Gool']",https://arxiv.org/abs/2006.15618,"Image-to-image translation is to map images from a given \emph{style} to another given \emph{style}. While exceptionally successful, current methods assume the availability of training images in both source and target domains, which does not always hold in practice. Inspired by humans' reasoning capability of analogy, we propose analogical image translation (AIT). Given images of two styles in the source domain: $\mathcal{A}$ and $\mathcal{A}^\prime$, along with images $\mathcal{B}$ of the first style in the target domain, learn a model to translate $\mathcal{B}$ to $\mathcal{B}^\prime$ in the target domain, such that $\mathcal{A}:\mathcal{A}^\prime ::\mathcal{B}:\mathcal{B}^\prime$. AIT is especially useful for translation scenarios in which training data of one style is hard to obtain but training data of the same two styles in another domain is available. For instance, in the case from normal conditions to extreme, rare conditions, obtaining real training images for the latter case is challenging but obtaining synthetic data for both cases is relatively easy. In this work, we are interested in adding adverse weather effects, more specifically fog effects, to images taken in clear weather. To circumvent the challenge of collecting real foggy images, AIT learns with synthetic clear-weather images, synthetic foggy images and real clear-weather images to add fog effects onto real clear-weather images without seeing any real foggy images during training. AIT achieves this zero-shot image translation capability by coupling a supervised training scheme in the synthetic domain, a cycle consistency strategy in the real domain, an adversarial training scheme between the two domains, and a novel network design. Experiments show the effectiveness of our method for zero-short image translation and its benefit for downstream tasks such as semantic foggy scene understanding.",画像から画像への変換は、特定のスタイルから別の特定のスタイルに画像をマッピングすることです。非常に成功していますが、現在の方法では、ソースドメインとターゲットドメインの両方でトレーニングイメージが利用可能であると想定していますが、実際には常にそうとは限りません。類推の能力を推論する人間に触発されて、我々は類推画像翻訳（AIT）を提案します。ソースドメインの2つのスタイルの画像AとA ^（）が、ターゲットドメインの最初のスタイルの画像Bとともに、ターゲットドメインのBをB ^（）に変換するモデルを学習します。A： A ^（）：： B：B ^（）。 AITは、あるスタイルのトレーニングデータを取得するのが難しいが、別のドメインの同じ2つのスタイルのトレーニングデータを利用できる翻訳シナリオで特に役立ちます。たとえば、通常の状態から極端でまれな状態までの場合、後者の場合の実際のトレーニング画像を取得することは困難ですが、両方の場合の合成データを取得することは比較的簡単です。この作品では、晴天時に撮影された画像に悪天候の影響、より具体的には霧の影響を追加することに関心があります。実際の霧の画像を収集するという課題を回避するために、AITは、合成の晴天画像、合成の霧の画像、および実際の晴天の画像を使用して学習し、トレーニング中に実際の霧の画像を見ることなく、実際の晴天の画像に霧の効果を追加します。 AITは、合成ドメインでの教師ありトレーニングスキーム、実ドメインでのサイクル整合性戦略、2つのドメイン間の敵対的トレーニングスキーム、および新しいネットワーク設計を組み合わせることにより、このゼロショット画像変換機能を実現します。実験は、ゼロショート画像変換のための私たちの方法の有効性と、意味的な霧のシーンの理解などのダウンストリームタスクに対するその利点を示しています。,https://d3i71xaburhd42.cloudfront.net/dc15dca53e34be8dabb3cd7690612faf3e7dde5a/2-Figure1-1.png
Computationally Tractable Riemannian Manifolds for Graph Embeddings,"['Calin C Cruceru', 'Gary Becigneul', 'Octavian Ganea']",https://arxiv.org/abs/2002.08665,"Representing graphs as sets of node embeddings in certain curved Riemannian manifolds has recently gained momentum in machine learning due to their desirable geometric inductive biases, e.g., hierarchical structures benefit from hyperbolic geometry. However, going beyond embedding spaces of constant sectional curvature, while potentially more representationally powerful, proves to be challenging as one can easily lose the appeal of computationally tractable tools such as geodesic distances or Riemannian gradients. Here, we explore computationally efficient matrix manifolds, showcasing how to learn and optimize graph embeddings in these Riemannian spaces. Empirically, we demonstrate consistent improvements over Euclidean geometry while often outperforming hyperbolic and elliptical embeddings based on various metrics that capture different graph properties. Our results serve as new evidence for the benefits of non-Euclidean embeddings in machine learning pipelines.",グラフを特定の湾曲したリーマン多様体のノード埋め込みのセットとして表すことは、その望ましい幾何学的誘導バイアスのために、最近機械学習で勢いを増しています。たとえば、階層構造は双曲幾何学の恩恵を受けています。ただし、一定の断面曲率の埋め込みスペースを超えると、表現力が向上する可能性がありますが、測地線距離やリーマン勾配などの計算上扱いやすいツールの魅力を簡単に失う可能性があるため、困難であることがわかります。ここでは、計算効率の高い行列多様体を探索し、これらのリーマン空間でのグラフ埋め込みを学習して最適化する方法を紹介します。経験的に、さまざまなグラフプロパティをキャプチャするさまざまなメトリックに基づいて、双曲線および楕円の埋め込みを上回ることが多い一方で、ユークリッド幾何学に対する一貫した改善を示しています。私たちの結果は、機械学習パイプラインへの非ユークリッド埋め込みの利点の新しい証拠として役立ちます。,https://d3i71xaburhd42.cloudfront.net/4fd4dd869b3d5e83ff3f666f50f85d7a05cc0493/1-Figure1-1.png
Characterizing the Evasion Attackability of Multi-Label Classifiers,"['Zhuo Yang', 'Yufei Han', 'Xiangliang Zhang']",https://arxiv.org/abs/2012.09427,"Evasion attack in multi-label learning systems is an interesting, widely witnessed, yet rarely explored research topic. Characterizing the crucial factors determining the attackability of the multi-label adversarial threat is the key to interpret the origin of the adversarial vulnerability and to understand how to mitigate it. Our study is inspired by the theory of adversarial risk bound. We associate the attackability of a targeted multi-label classifier with the regularity of the classifier and the training data distribution. Beyond the theoretical attackability analysis, we further propose an efficient empirical attackability estimator via greedy label space exploration. It provides provably computational efficiency and approximation accuracy. Substantial experimental results on real-world datasets validate the unveiled attackability factors and the effectiveness of the proposed empirical attackability indicator",マルチラベル学習システムでの回避攻撃は、興味深い、広く目撃されているが、めったに調査されていない研究トピックです。マルチラベルの敵対的脅威の攻撃可能性を決定する重要な要因を特徴づけることは、敵対的脆弱性の原因を解釈し、それを軽減する方法を理解するための鍵です。私たちの研究は、敵対的リスク限界の理論に触発されています。ターゲットとなるマルチラベル分類器の攻撃性を、分類器の規則性とトレーニングデータの分布に関連付けます。理論的な攻撃可能性分析を超えて、貪欲なラベル空間探索を介した効率的な経験的攻撃可能性推定量をさらに提案します。それは確かに計算効率と近似精度を提供します。実世界のデータセットでの実質的な実験結果は、明らかにされた攻撃可能性要因と提案された経験的攻撃可能性指標の有効性を検証します,https://d3i71xaburhd42.cloudfront.net/af6b7679f847bdae78e0c2e0a400ddee80dfbd47/6-Figure1-1.png
A Simple and Effective Self-Supervised Contrastive Learning Framework for Aspect Detection,"['Tian Shi', 'Liuqing Li', 'Ping Wang', 'Chandan K Reddy']",https://arxiv.org/abs/2009.09107,"Unsupervised aspect detection (UAD) aims at automatically extracting interpretable aspects and identifying aspect-specific segments (such as sentences) from online reviews. However, recent deep learning-based topic models, specifically aspect-based autoencoder, suffer from several problems, such as extracting noisy aspects and poorly mapping aspects discovered by models to the aspects of interest. To tackle these challenges, in this paper, we first propose a self-supervised contrastive learning framework and an attention-based model equipped with a novel smooth self-attention (SSA) module for the UAD task in order to learn better representations for aspects and review segments. Secondly, we introduce a high-resolution selective mapping (HRSMap) method to efficiently assign aspects discovered by the model to aspects of interest. We also propose using a knowledge distilling technique to further improve the aspect detection performance. Our methods outperform several recent unsupervised and weakly supervised approaches on publicly available benchmark user review datasets. Aspect interpretation results show that extracted aspects are meaningful, have good coverage, and can be easily mapped to aspects of interest. Ablation studies and attention weight visualization also demonstrate the effectiveness of SSA and the knowledge distilling method.",教師なしアスペクト検出（UAD）は、解釈可能なアスペクトを自動的に抽出し、オンラインレビューからアスペクト固有のセグメント（文など）を識別することを目的としています。ただし、最近の深層学習ベースのトピックモデル、特にアスペクトベースのオートエンコーダには、ノイズの多いアスペクトの抽出や、モデルによって発見されたアスペクトの関心のあるアスペクトへのマッピングが不十分であるなど、いくつかの問題があります。これらの課題に取り組むために、この論文では、まず、自己監視型の対照的な学習フレームワークと、UADタスク用の新しいスムーズな自己注意（SSA）モジュールを備えた注意ベースのモデルを提案し、セグメントを確認します。次に、高解像度の選択的マッピング（HRSMap）メソッドを導入して、モデルによって検出されたアスペクトを対象のアスペクトに効率的に割り当てます。また、知識蒸留技術を使用して、アスペクト検出パフォーマンスをさらに向上させることを提案します。私たちの方法は、公開されているベンチマークユーザーレビューデータセットに対する最近のいくつかの教師なしおよび弱教師ありアプローチよりも優れています。アスペクト解釈の結果は、抽出されたアスペクトが意味があり、カバレッジが良好で、関心のあるアスペクトに簡単にマッピングできることを示しています。アブレーション研究と注意の重みの視覚化も、SSAと知識蒸留法の有効性を示しています。,https://d3i71xaburhd42.cloudfront.net/eef25ed5ebd5fc0b176335d95de683fcb21073bd/3-Figure1-1.png
The Value-Improvement Path: Towards Better Representations for Reinforcement Learning,"['Will Dabney', 'Andre Barreto', 'Mark Rowland', 'Robert Dadashi', 'John Quan', 'Marc G. Bellemare', 'David Silver']",https://arxiv.org/abs/2006.02243,"In value-based reinforcement learning (RL), unlike in supervised learning, the agent faces not a single, stationary, approximation problem, but a sequence of value prediction problems. Each time the policy improves, the nature of the problem changes, shifting both the distribution of states and their values. In this paper we take a novel perspective, arguing that the value prediction problems faced by an RL agent should not be addressed in isolation, but rather as a single, holistic, prediction problem. An RL algorithm generates a sequence of policies that, at least approximately, improve towards the optimal policy. We explicitly characterize the associated sequence of value functions and call it the value-improvement path. Our main idea is to approximate the value-improvement path holistically, rather than to solely track the value function of the current policy. Specifically, we discuss the impact that this holistic view of RL has on representation learning. We demonstrate that a representation that spans the past value-improvement path will also provide an accurate value approximation for future policy improvements. We use this insight to better understand existing approaches to auxiliary tasks and to propose new ones. To test our hypothesis empirically, we augmented a standard deep RL agent with an auxiliary task of learning the value-improvement path. In a study of Atari 2600 games, the augmented agent achieved approximately double the mean and median performance of the baseline agent.",値ベースの強化学習（RL）では、教師あり学習とは異なり、エージェントは単一の定常的な近似問題ではなく、一連の値予測問題に直面します。ポリシーが改善されるたびに、問題の性質が変化し、状態の分布とその値の両方が変化します。このホワイトペーパーでは、RLエージェントが直面する価値予測の問題は、単独で対処するのではなく、単一の全体的な予測問題として対処する必要があると主張し、新しい視点を取り入れています。 RLアルゴリズムは、最適なポリシーに向けて少なくともおおよそ改善される一連のポリシーを生成します。関連する一連の値関数を明示的に特徴付け、それを値改善パスと呼びます。私たちの主なアイデアは、現在のポリシーの価値関数を単に追跡するのではなく、価値改善パスを全体的に概算することです。具体的には、RLのこの全体的なビューが表現学習に与える影響について説明します。過去の価値改善パスにまたがる表現が、将来のポリシー改善のための正確な価値近似も提供することを示します。この洞察を使用して、補助タスクへの既存のアプローチをよりよく理解し、新しいアプローチを提案します。仮説を経験的にテストするために、標準のディープRLエージェントに、価値向上パスを学習するという補助タスクを追加しました。 Atari 2600ゲームの研究では、拡張エージェントはベースラインエージェントの平均および中央値のパフォーマンスの約2倍を達成しました。,https://d3i71xaburhd42.cloudfront.net/c035d3bd325fd374f4f4a2c3a9b6aa8483d64c66/2-Figure1-1.png
CNN Profiler on Polar Coordinate Images for Tropical Cyclone Structure Analysis,"['Boyo Chen', 'Buo-Fu Chen', 'Chun Min Hsiao']",https://arxiv.org/abs/2010.15158,"Convolutional neural networks (CNN) have achieved great success in analyzing tropical cyclones (TC) with satellite images in several tasks, such as TC intensity estimation. In contrast, TC structure, which is conventionally described by a few parameters estimated subjectively by meteorology specialists, is still hard to be profiled objectively and routinely. This study applies CNN on satellite images to create the entire TC structure profiles, covering all the structural parameters. By utilizing the meteorological domain knowledge to construct TC wind profiles based on historical structure parameters, we provide valuable labels for training in our newly released benchmark dataset. With such a dataset, we hope to attract more attention to this crucial issue among data scientists. Meanwhile, a baseline is established with a specialized convolutional model operating on polar-coordinates. We discovered that it is more feasible and physically reasonable to extract structural information on polar-coordinates, instead of Cartesian coordinates, according to a TC's rotational and spiral natures. Experimental results on the released benchmark dataset verified the robustness of the proposed model and demonstrated the potential for applying deep learning techniques for this barely developed yet important topic.",畳み込みニューラルネットワーク（CNN）は、TC強度推定などのいくつかのタスクで、衛星画像を使用して熱帯低気圧（TC）を分析することに大きな成功を収めています。対照的に、気象学の専門家によって主観的に推定されたいくつかのパラメータによって従来から記述されているTC構造は、依然として客観的かつ日常的にプロファイルすることは困難です。この調査では、衛星画像にCNNを適用して、すべての構造パラメータをカバーするTC構造プロファイル全体を作成します。気象領域の知識を利用して、過去の構造パラメータに基づいてTC風プロファイルを構築することにより、新しくリリースされたベンチマークデータセットでトレーニングするための貴重なラベルを提供します。このようなデータセットを使用して、データサイエンティストの間でこの重大な問題にさらに注目を集めることを望んでいます。一方、ベースラインは、極座標で動作する特殊な畳み込みモデルを使用して確立されます。 TCの回転およびスパイラルの性質に従って、デカルト座標ではなく極座標で構造情報を抽出する方が実行可能で物理的に合理的であることがわかりました。リリースされたベンチマークデータセットの実験結果は、提案されたモデルの堅牢性を検証し、このほとんど開発されていないが重要なトピックにディープラーニング手法を適用する可能性を示しました。,https://d3i71xaburhd42.cloudfront.net/7928cdd65449f24e3b5b480ad233c027d7de2b56/2-Figure1-1.png
NeuralAC: Learning Cooperation and Competition Effects for Match Outcome Prediction,"['Yin Gu', 'Qi Liu', 'Kai Zhang', 'Zhenya Huang', 'Runze Wu', 'Jianrong Tao']",,,,
On the PTAS for Maximin Shares in an Indivisible Mixed Manna,"['Rucha Kulkarni', 'Ruta Mehta', 'Setareh Taki']",,,,
Efficient Bayesian Network Structure Learning via Parameterized Local Search on Topological Orderings,"['Niels Grüttemeier', 'Christian Komusiewicz', 'Nils Morawietz']",,,,
Classification by Attention: Scene Graph Classification with Prior Knowledge,"['Sahand Sharifzadeh', 'Sina Moayed Baharlou', 'Volker Tresp']",https://arxiv.org/abs/2011.10084,"A main challenge in scene graph classification is that the appearance of objects and relations can be significantly different from one image to another. Previous works have addressed this by relational reasoning over all objects in an image, or incorporating prior knowledge into classification. Unlike previous works, we do not consider separate models for the perception and prior knowledge. Instead, we take a multi-task learning approach, where the classification is implemented as an attention layer. This allows for the prior knowledge to emerge and propagate within the perception model. By enforcing the model to also represent the prior, we achieve a strong inductive bias. We show that our model can accurately generate commonsense knowledge and that the iterative injection of this knowledge to scene representations leads to a significantly higher classification performance. Additionally, our model can be fine-tuned on external knowledge given as triples. When combined with self-supervised learning, this leads to accurate predictions with 1% of annotated images only.",シーングラフ分類の主な課題は、オブジェクトの外観と関係が画像ごとに大幅に異なる可能性があることです。以前の作品は、画像内のすべてのオブジェクトに対する関係推論、または事前知識を分類に組み込むことによってこれに対処しました。以前の作品とは異なり、知覚と事前知識の別々のモデルは考慮していません。代わりに、分類が注意層として実装されるマルチタスク学習アプローチを採用しています。これにより、事前の知識が出現し、知覚モデル内で伝播することができます。モデルに事前の表現も適用することにより、強い誘導バイアスを実現します。モデルが常識的な知識を正確に生成できること、およびこの知識をシーン表現に繰り返し注入すると、分類パフォーマンスが大幅に向上することを示します。さらに、私たちのモデルは、トリプルとして与えられた外部の知識に基づいて微調整することができます。自己教師あり学習と組み合わせると、1で正確な予測が可能になります。,https://d3i71xaburhd42.cloudfront.net/a5661066faa0f28a61f238e860fb14a9057acf6b/1-Figure1-1.png
Plug-and-Play Domain Adaptation for Cross-Subject EEG-Based Emotion Recognition,"['Liming Zhao', 'Xu Yan', 'Bao-Liang Lu']",,,,
Gene Regulatory Network Inference as Relaxed Graph Matching,"['Deborah Weighill', 'Marouen Ben Guebila', 'Camila Lopes-Ramos', 'Kimberly Glass', 'John Quackenbush', 'John H Platig', 'Rebekka Burkholz']",,"Gene regulatory network inference is instrumental to the discovery of genetic mechanisms driving diverse diseases, including cancer. Here, we present a theoretical framework for PANDA, an established method for gene regulatory network inference. PANDA is based on iterative message passing updates that resemble the gradient descent of an optimization problem, OTTER, which can be interpreted as relaxed inexact graph matching between a gene-gene co-expression and a protein-protein interaction matrix. The solutions of OTTER can be derived explicitly and inspire an alternative spectral algorithm, for which we can provide network recovery guarantees. We compare different solution approaches of OTTER to other inference methods using three biological data sets, which we make publicly available to offer a new application venue for relaxed graph matching in gene regulatory network inference. We find that using modern gradient descent methods with superior convergence properties solving OTTER outperforms state-of-the-art gene regulatory network inference methods in predicting binding of transcription factors to regulatory regions.",遺伝子調節ネットワークの推論は、癌を含む多様な疾患を引き起こす遺伝的メカニズムの発見に役立ちます。ここでは、遺伝子調節ネットワーク推論のための確立された方法であるパンダの理論的枠組みを提示します。 PANDAは、最適化問題OTTERの最急降下法に似た反復メッセージパッシング更新に基づいています。これは、遺伝子-遺伝子共発現とタンパク質間相互作用行列の間の緩和された不正確なグラフマッチングとして解釈できます。 OTTERのソリューションは明示的に導き出すことができ、ネットワーク回復の保証を提供できる代替のスペクトルアルゴリズムを刺激します。 OTTERのさまざまなソリューションアプローチを、3つの生物学的データセットを使用して他の推論方法と比較します。これらのデータセットは、遺伝子調節ネットワーク推論におけるリラックスしたグラフマッチングの新しいアプリケーション会場を提供するために公開されています。 OTTERを解く優れた収束特性を備えた最新の勾配降下法を使用すると、転写因子の調節領域への結合を予測する際に、最先端の遺伝子調節ネットワーク推論法よりも優れていることがわかります。,
Power in Liquid Democracy,"['Yuzhe Zhang', 'Grossi Davide']",,,,
Norm-Based Generalisation Bounds for Deep Multi-Class Convolutional Neural Networks,"['Antoine Ledent', 'Waleed Mustafa', 'Yunwen Lei', 'Marius Kloft']",https://arxiv.org/abs/1905.12430,"We show generalisation error bounds for deep learning with two main improvements over the state of the art. (1) Our bounds have no explicit dependence on the number of classes except for logarithmic factors. This holds even when formulating the bounds in terms of the $L^2$-norm of the weight matrices, where previous bounds exhibit at least a square-root dependence on the number of classes. (2) We adapt the classic Rademacher analysis of DNNs to incorporate weight sharing---a task of fundamental theoretical importance which was previously attempted only under very restrictive assumptions. In our results, each convolutional filter contributes only once to the bound, regardless of how many times it is applied. Further improvements exploiting pooling and sparse connections are provided. The presented bounds scale as the norms of the parameter matrices, rather than the number of parameters. In particular, contrary to bounds based on parameter counting, they are asymptotically tight (up to log factors) when the weights approach initialisation, making them suitable as a basic ingredient in bounds sensitive to the optimisation procedure. We also show how to adapt the recent technique of loss function augmentation to our situation to replace spectral norms by empirical analogues whilst maintaining the advantages of our approach.",最先端技術に対する2つの主な改善点を使用して、ディープラーニングの汎化誤差範囲を示します。 （1）私たちの境界は、対数因子を除いて、クラスの数に明示的に依存していません。これは、重み行列のL2ノルムの観点から境界を定式化する場合にも当てはまります。この場合、前の境界は、クラスの数に対して少なくとも平方根の依存性を示します。 （2）DNNの古典的なRademacher分析を適応させて、以前は非常に制限された仮定の下でのみ試みられた基本的な理論的重要性のタスクを組み込むようにします。私たちの結果では、各畳み込みフィルターは、適用回数に関係なく、境界に1回だけ寄与します。プーリングとスパース接続を活用するさらなる改善が提供されます。提示された境界は、パラメーターの数ではなく、パラメーター行列の基準としてスケーリングされます。特に、パラメーターカウントに基づく境界とは異なり、重みが初期化に近づくと、それらは漸近的にタイトになり（対数係数まで）、最適化手順に敏感な境界の基本的な要素として適しています。また、損失関数拡張の最近の手法を状況に適合させて、アプローチの利点を維持しながら、スペクトルノルムを経験的な類似物に置き換える方法も示します。,https://d3i71xaburhd42.cloudfront.net/5a94c7dde367b0864198baa76a168044aba950c3/7-Figure1-1.png
FixMyPose: Pose Correctional Captioning and Retrieval,"['Hyounghun Kim', 'Abhaysinh S Zala', 'Graham H Burri', 'Mohit Bansal']",,,,
Adaptive Verifiable Training Using Pairwise Class Similarity,"['Shiqi Wang', 'Kevin Eykholt', 'Taesung Lee', 'Jiyong Jang', 'Ian Molloy']",https://arxiv.org/abs/2012.07887,"Verifiable training has shown success in creating neural networks that are provably robust to a given amount of noise. However, despite only enforcing a single robustness criterion, its performance scales poorly with dataset complexity. On CIFAR10, a non-robust LeNet model has a 21.63% error rate, while a model created using verifiable training and a L-infinity robustness criterion of 8/255, has an error rate of 57.10%. Upon examination, we find that when labeling visually similar classes, the model's error rate is as high as 61.65%. We attribute the loss in performance to inter-class similarity. Similar classes (i.e., close in the feature space) increase the difficulty of learning a robust model. While it's desirable to train a robust model for a large robustness region, pairwise class similarities limit the potential gains. Also, consideration must be made regarding the relative cost of mistaking similar classes. In security or safety critical tasks, similar classes are likely to belong to the same group, and thus are equally sensitive. 
In this work, we propose a new approach that utilizes inter-class similarity to improve the performance of verifiable training and create robust models with respect to multiple adversarial criteria. First, we use agglomerate clustering to group similar classes and assign robustness criteria based on the similarity between clusters. Next, we propose two methods to apply our approach: (1) Inter-Group Robustness Prioritization, which uses a custom loss term to create a single model with multiple robustness guarantees and (2) neural decision trees, which trains multiple sub-classifiers with different robustness guarantees and combines them in a decision tree architecture. On Fashion-MNIST and CIFAR10, our approach improves clean performance by 9.63% and 30.89% respectively. On CIFAR100, our approach improves clean performance by 26.32%.",検証可能なトレーニングは、特定の量のノイズに対して確実に堅牢なニューラルネットワークの作成に成功したことを示しています。ただし、単一の堅牢性基準を適用するだけであるにもかかわらず、そのパフォーマンスはデータセットの複雑さに応じてスケーリングが不十分です。 CIFAR10では、ロバストでないLeNetモデルの21.63があります。この作業では、クラス間の類似性を利用して検証可能なトレーニングのパフォーマンスを向上させ、複数の敵対的基準に関してロバストなモデルを作成する新しいアプローチを提案します。まず、凝集クラスタリングを使用して類似のクラスをグループ化し、クラスター間の類似性に基づいて堅牢性基準を割り当てます。次に、このアプローチを適用する2つの方法を提案します。（1）カスタム損失項を使用して複数のロバスト性保証を備えた単一モデルを作成するグループ間ロバストネス優先順位付けと（2）複数のサブ分類子をトレーニングするニューラル決定木さまざまな堅牢性が保証され、決定木アーキテクチャでそれらを組み合わせます。 Fashion-MNISTとCIFAR10では、私たちのアプローチによりクリーンパフォーマンスが9.63向上します,https://d3i71xaburhd42.cloudfront.net/f77eded7672b3c18a4126ae72483eeb7505624ac/1-Figure1-1.png
Fair Representations by Compression,"['Xavier Gitiaux', 'Huzefa Rangwala']",,,,
Differentially Private k-Means via Exponential Mechanism and Max Cover,"['Huy Nguyen', 'Anamay Chaturvedi', 'Eric Z Xu']",,,,
Proportional Representation under Single-Crossing Preferences Revisited,"['Andrei Costin Constantinescu', 'Edith Elkind']",https://arxiv.org/abs/2010.08637,"We study the complexity of determining a winning committee under the Chamberlin--Courant voting rule when voters' preferences are single-crossing on a line, or, more generally, on a median graph (this class of graphs includes, e.g., trees and grids). For the line, Skowron et al. (2015) describe an $O(n^2mk)$ algorithm (where $n$, $m$, $k$ are the number of voters, the number of candidates and the committee size, respectively); we show that a simple tweak improves the time complexity to $O(nmk)$. We then improve this bound for $k=\Omega(\log n)$ by reducing our problem to the $k$-link path problem for DAGs with concave Monge weights, obtaining a $nm2^{O\left(\sqrt{\log k\log\log n}\right)}$ algorithm for the general case and a nearly linear algorithm for the Borda misrepresentation function. For trees, we point out an issue with the algorithm proposed by Clearwater, Puppe and Slinko (2015), and develop a $O(nmk)$ algorithm for this case as well. For grids, we formulate a conjecture about the structure of optimal solutions, and describe a polynomial-time algorithm that finds a winning committee if this conjecture is true; we also explain how to convert this algorithm into a bicriterial approximation algorithm whose correctness does not depend on the conjecture.",投票者の選好が線上、またはより一般的には中央値グラフ（このクラスのグラフには、たとえば、ツリーやグリッドが含まれます）で単一交差している場合に、ChamberlinCourant投票ルールの下で勝者委員会を決定することの複雑さを研究します。ラインについては、Skowron etal。 （2015）O（n2mk）アルゴリズムについて説明します（ここで、n、m、kはそれぞれ有権者の数、候補者の数、委員会の規模です）。単純な調整により、時間計算量がO（nmk）に向上することを示します。次に、問題を凹型モンジ重みを持つDAGのkリンクパス問題に減らし、$ nm2 ^ {O \ left（\ sqrt {\ log k \ log \ log）を取得することにより、k =（log n）のこの境界を改善します。 n} \ right）} $アルゴリズムは一般的な場合で、ほぼ線形のアルゴリズムはBordaの不表現関数です。樹木については、Clearwater、Puppe and Slinko（2015）によって提案されたアルゴリズムの問​​題を指摘し、この場合にもO（nmk）アルゴリズムを開発します。グリッドについては、最適解の構造についての推測を定式化し、この推測が真である場合に勝者委員会を見つける多項式時間アルゴリズムについて説明します。また、このアルゴリズムを、正確さが推測に依存しない二値近似アルゴリズムに変換する方法についても説明します。,https://d3i71xaburhd42.cloudfront.net/33d740382f3fe21e006a556afa4d9bc628cf86be/11-Figure1-1.png
CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-Cloud Stream Forecasting,"['Chaoyun Zhang', 'Marco Fiore', 'Iain Murray', 'Paul Patras']",,,,
We Can Explain Your Research in Layman's Terms: Towards Automating Science Journalism at Scale,"['Rumen R Dangovski', 'Michelle Shen', 'Dawson A Byrd', 'Li Jing', 'Desislava M Tsvetkova', 'Preslav Nakov', 'Marin Soljacic']",,,,
Learning Continuous High-Dimensional Models Using Mutual Information and Copula Bayesian Networks,"['Marvin Lasserre', 'Régis Lebrun', 'Pierre-Henri Wuillemin']",,,,
Unsupervised Learning of Discourse Structures Using a Tree Autoencoder,"['Patrick Huber', 'Giuseppe Carenini']",https://arxiv.org/abs/2012.09446,"Discourse information, as postulated by popular discourse theories, such as RST and PDTB, has been shown to improve an increasing number of downstream NLP tasks, showing positive effects and synergies of discourse with important real-world applications. While methods for incorporating discourse become more and more sophisticated, the growing need for robust and general discourse structures has not been sufficiently met by current discourse parsers, usually trained on small scale datasets in a strictly limited number of domains. This makes the prediction for arbitrary tasks noisy and unreliable. The overall resulting lack of high-quality, high-quantity discourse trees poses a severe limitation to further progress. In order the alleviate this shortcoming, we propose a new strategy to generate tree structures in a task-agnostic, unsupervised fashion by extending a latent tree induction framework with an auto-encoding objective. The proposed approach can be applied to any tree-structured objective, such as syntactic parsing, discourse parsing and others. However, due to the especially difficult annotation process to generate discourse trees, we initially develop a method to generate larger and more diverse discourse treebanks. In this paper we are inferring general tree structures of natural text in multiple domains, showing promising results on a diverse set of tasks.",RSTやPDTBなどの一般的な談話理論によって仮定されている談話情報は、ますます多くのダウンストリームNLPタスクを改善し、重要な実世界のアプリケーションとの談話のプラスの効果と相乗効果を示しています。談話を組み込む方法はますます洗練されていますが、堅牢で一般的な談話構造の必要性の高まりは、通常、厳密に限られた数のドメインの小規模データセットでトレーニングされている現在の談話パーサーでは十分に満たされていません。これにより、任意のタスクの予測にノイズが多く、信頼性が低くなります。結果として生じる高品質で大量の談話ツリーの全体的な欠如は、さらなる進歩に深刻な制限をもたらします。この欠点を軽減するために、自動エンコードの目的で潜在的なツリー帰納フレームワークを拡張することにより、タスクに依存しない、監視されていない方法でツリー構造を生成する新しい戦略を提案します。提案されたアプローチは、構文解析、談話構文解析など、ツリー構造の目的に適用できます。ただし、談話ツリーを生成するための注釈プロセスが特に難しいため、最初に、より大きく、より多様な談話ツリーバンクを生成する方法を開発します。この論文では、複数のドメインにおける自然なテキストの一般的なツリー構造を推測し、さまざまなタスクのセットで有望な結果を示しています。,https://d3i71xaburhd42.cloudfront.net/2f9b4b450983297628b2970f391481875894acf5/3-Figure1-1.png
Robustness to Spurious Correlations in Text Classification via Automatically Generated Counterfactuals,"['Zhao Wang', 'Aron Culotta']",https://arxiv.org/abs/2012.10040,"Spurious correlations threaten the validity of statistical classifiers. While model accuracy may appear high when the test data is from the same distribution as the training data, it can quickly degrade when the test distribution changes. For example, it has been shown that classifiers perform poorly when humans make minor modifications to change the label of an example. One solution to increase model reliability and generalizability is to identify causal associations between features and classes. In this paper, we propose to train a robust text classifier by augmenting the training data with automatically generated counterfactual data. We first identify likely causal features using a statistical matching approach. Next, we generate counterfactual samples for the original training data by substituting causal features with their antonyms and then assigning opposite labels to the counterfactual samples. Finally, we combine the original data and counterfactual data to train a robust classifier. Experiments on two classification tasks show that a traditional classifier trained on the original data does very poorly on human-generated counterfactual samples (e.g., 10%-37% drop in accuracy). However, the classifier trained on the combined data is more robust and performs well on both the original test data and the counterfactual test data (e.g., 12%-25% increase in accuracy compared with the traditional classifier). Detailed analysis shows that the robust classifier makes meaningful and trustworthy predictions by emphasizing causal features and de-emphasizing non-causal features.",疑似相関は、統計的分類子の有効性を脅かします。テストデータがトレーニングデータと同じ分布からのものである場合、モデルの精度は高く見える場合がありますが、テスト分布が変更されるとすぐに低下する可能性があります。たとえば、人間が例のラベルを変更するために小さな変更を加えると、分類器のパフォーマンスが低下することが示されています。モデルの信頼性と一般化可能性を高めるための1つの解決策は、機能とクラスの間の因果関係を特定することです。この論文では、自動生成された反事実データでトレーニングデータを補強することにより、堅牢なテキスト分類器をトレーニングすることを提案します。まず、統計的マッチングアプローチを使用して、考えられる原因となる特徴を特定します。次に、因果的特徴をそれらの反事実に置き換え、次に反対のラベルを反事実サンプルに割り当てることによって、元のトレーニングデータの反事実サンプルを生成します。最後に、元のデータと反事実データを組み合わせて、堅牢な分類器をトレーニングします。 2つの分類タスクでの実験は、元のデータでトレーニングされた従来の分類器が、人間が生成した反事実サンプル（たとえば、10,https://d3i71xaburhd42.cloudfront.net/a5b1169e536b806c2344261ebbbe3d97bc6e1cdb/4-Figure1-1.png
Generalization in Portfolio-Based Algorithm Selection,"['Maria-Florina Balcan', 'Tuomas Sandholm', 'Ellen Vitercik']",https://arxiv.org/abs/2012.13315,"Portfolio-based algorithm selection has seen tremendous practical success over the past two decades. This algorithm configuration procedure works by first selecting a portfolio of diverse algorithm parameter settings, and then, on a given problem instance, using an algorithm selector to choose a parameter setting from the portfolio with strong predicted performance. Oftentimes, both the portfolio and the algorithm selector are chosen using a training set of typical problem instances from the application domain at hand. In this paper, we provide the first provable guarantees for portfolio-based algorithm selection. We analyze how large the training set should be to ensure that the resulting algorithm selector’s average performance over the training set is close to its future (expected) performance. This involves analyzing three key reasons why these two quantities may diverge: 1) the learning-theoretic complexity of the algorithm selector, 2) the size of the portfolio, and 3) the learning-theoretic complexity of the algorithm’s performance as a function of its parameters. We introduce an end-to-end learning-theoretic analysis of the portfolio construction and algorithm selection together. We prove that if the portfolio is large, overfitting is inevitable, even with an extremely simple algorithm selector. With experiments, we illustrate a tradeoff exposed by our theoretical analysis: as we increase the portfolio size, we can hope to include a well-suited parameter setting for every possible problem instance, but it becomes impossible to avoid overfitting.",ポートフォリオベースのアルゴリズムの選択は、過去20年間で途方もない実用的な成功を収めてきました。このアルゴリズム構成手順は、最初にさまざまなアルゴリズムパラメーター設定のポートフォリオを選択し、次に特定の問題インスタンスで、アルゴリズムセレクターを使用して、強力な予測パフォーマンスを持つポートフォリオからパラメーター設定を選択することによって機能します。多くの場合、ポートフォリオとアルゴリズムセレクターの両方は、手元のアプリケーションドメインからの典型的な問題インスタンスのトレーニングセットを使用して選択されます。このホワイトペーパーでは、ポートフォリオベースのアルゴリズム選択のための最初の証明可能な保証を提供します。結果として得られるアルゴリズムセレクターのトレーニングセット全体の平均パフォーマンスが将来の（期待される）パフォーマンスに近いことを確認するために、トレーニングセットの大きさを分析します。これには、これら2つの量が発散する可能性がある3つの主な理由の分析が含まれます：1）アルゴリズムセレクターの学習理論の複雑さ、2）ポートフォリオのサイズ、および3）アルゴリズムパフォーマンスの学習理論の複雑さパラメーター。ポートフォリオ構築とアルゴリズム選択のエンドツーエンドの学習理論的分析を一緒に紹介します。ポートフォリオが大きい場合、非常に単純なアルゴリズムセレクターを使用しても、過剰適合は避けられないことを証明します。実験により、理論的分析によって明らかになったトレードオフを説明します。ポートフォリオサイズを大きくすると、考えられるすべての問題インスタンスに適切なパラメーター設定を含めることができますが、過剰適合を回避することは不可能になります。,https://d3i71xaburhd42.cloudfront.net/96cf13802df40124a8053530187e2879f6137699/11-Figure1-1.png
A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization,"['Ashraful Islam', 'Chengjiang Long', 'Richard Radke']",https://arxiv.org/abs/2101.00545,"Weakly supervised temporal action localization is a challenging vision task due to the absence of ground-truth temporal locations of actions in the training videos. With only videolevel supervision during training, most existing methods rely on a Multiple Instance Learning (MIL) framework to predict the start and end frame of each action category in a video. However, the existing MIL-based approach has a major limitation of only capturing the most discriminative frames of an action, ignoring the full extent of an activity. Moreover, these methods cannot model background activity effectively, which plays an important role in localizing foreground activities. In this paper, we present a novel framework named HAM-Net with a hybrid attention mechanism which includes temporal soft, semi-soft and hard attentions to address these issues. Our temporal soft attention module, guided by an auxiliary background class in the classification module, models the background activity by introducing an “action-ness” score for each video snippet. Moreover, our temporal semi-soft and hard attention modules, calculating two attention scores for each video snippet, help to focus on the less discriminative frames of an action to capture the full action boundary. Our proposed approach outperforms recent state-of-the-art methods by at least 2.2% mAP at IoU threshold 0.5 on the THUMOS14 dataset, and by at least 1.3% mAP at IoU threshold 0.75 on the ActivityNet1.2 dataset. Code can be found at: https://github.com/asrafulashiq/hamnet. Introduction Temporal action localization refers to the task of predicting the start and end times of all action instances in a video. There has been remarkable progress in fully-supervised temporal action localization (Tran et al. 2017; Zhao et al. 2017; Chao et al. 2018; Lin et al. 2018; Xu et al. 2019). However, annotating the precise temporal ranges of all action instances in a video dataset is expensive, time-consuming, and errorprone. On the contrary, weakly supervised temporal action localization (WTAL) can greatly simplify the data collection and annotation cost. WTAL aims at localizing and classifying all action instances in a video given only video-level category label during training stage. Most existing WTAL methods rely on the multiple instance learning (MIL) paradigm (Paul, Roy, Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. (a) Ground-Truth (b) Prediction from MIL-based framework (a)",トレーニングビデオにはアクションのグラウンドトゥルースの時間的位置がないため、弱く監視された時間的アクションのローカリゼーションは困難なビジョンタスクです。トレーニング中のビデオレベルの監視のみで、ほとんどの既存の方法は、ビデオ内の各アクションカテゴリの開始フレームと終了フレームを予測するためにMultiple Instance Learning（MIL）フレームワークに依存しています。ただし、既存のMILベースのアプローチには、アクティビティの全範囲を無視して、アクションの最も識別力のあるフレームのみをキャプチャするという大きな制限があります。さらに、これらの方法では、バックグラウンドアクティビティを効果的にモデル化できません。これは、フォアグラウンドアクティビティのローカライズに重要な役割を果たします。この論文では、これらの問題に対処するための一時的なソフト、セミソフト、ハードの注意を含むハイブリッド注意メカニズムを備えたHAM-Netという名前の新しいフレームワークを紹介します。分類モジュールの補助的な背景クラスによってガイドされる一時的なソフトアテンションモジュールは、各ビデオスニペットのアクションネススコアを導入することによって背景アクティビティをモデル化します。さらに、ビデオスニペットごとに2つの注意スコアを計算する一時的なセミソフトおよびハードアテンションモジュールは、アクションの識別力の低いフレームに焦点を合わせて、アクションの境界全体をキャプチャするのに役立ちます。私たちが提案するアプローチは、最近の最先端の方法を少なくとも2.2上回っています。,https://d3i71xaburhd42.cloudfront.net/641e2426b84f57ce0776e0cb238dcceb819601f7/1-Figure1-1.png
VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning,"['Xiaowei Hu', 'Xi Yin', 'Kevin Lin', 'Lei Zhang', 'Jianfeng Gao', 'Lijuan Wang', 'Zicheng Liu']",,,,
Style-Transfer and Paraphrase: Looking for a Sensible Semantic Similarity Metric,"['Ivan P Yamshchikov', 'Viacheslav A. Shibaev', 'Nikolay Khlebnikov', 'Alexey Tikhonov']",https://arxiv.org/abs/2004.05001,"The rapid development of such natural language processing tasks as style transfer, paraphrase, and machine translation often calls for the use of semantic preservation metrics. In recent years a lot of methods to control the semantic similarity of two short texts were developed. This paper provides a comprehensive analysis for more than a dozen of such methods. Using a new dataset of fourteen thousand sentence pairs human-labeled according to their semantic similarity, we demonstrate that none of the metrics widely used in the literature is close enough to human judgment to be used on its own in these tasks. The recently proposed Word Mover's Distance (WMD), along with bilingual evaluation understudy (BLEU) and part-of-speech (POS) distance, seem to form a reasonable complex solution to measure semantic preservation in reformulated texts. We encourage the research community to use the ensemble of these metrics until a better solution is found.","スタイル転送、言い換え、機械翻訳などの自然言語処理タスクの急速な発展により、多くの場合、セマンティック保存メトリックの使用が必要になります。近年、2つの短いテキストの意味的類似性を制御するための多くの方法が開発されました。このホワイトペーパーでは、このような方法の12を超える包括的な分析を提供します。意味的類似性に従って人間がラベル付けした14,000文のペアの新しいデータセットを使用して、文献で広く使用されているメトリックのいずれも、これらのタスクで単独で使用できるほど人間の判断に近いものではないことを示します。最近提案されたWordMovers Distance（WMD）は、バイリンガル評価アンダースタディ（BLEU）および品詞（POS）距離とともに、再定式化されたテキストの意味保存を測定するための合理的な複雑なソリューションを形成しているようです。より良い解決策が見つかるまで、研究コミュニティがこれらのメトリックのアンサンブルを使用することをお勧めします。",https://d3i71xaburhd42.cloudfront.net/b21d23b0bf97c42ad558835b4ab5f0ca224f55f4/7-Figure1-1.png
On Exploiting Hitting Sets for Model Reconciliation,"['Stylianos Loukas Vasileiou', 'Alessandro Previti', 'William Yeoh']",,,,
Continual Learning for Named Entity Recognition,"['Natawut Monaikul', 'Giuseppe Castellucci', 'Simone Filice', 'Oleg Rokhlenko']",,,,
Focused Inference and System P,"['Marco Wilhelm', 'Gabriele Kern-Isberner']",,,,
VSQL: Variational Shadow Quantum Learning for Classification,"['Guangxi Li', 'Zhixin Song', 'Xin Wang']",https://arxiv.org/abs/2012.08288,"Classification of quantum data is essential for quantum machine learning and near-term quantum technologies. In this paper, we propose a new hybrid quantum-classical framework for supervised quantum learning, which we call Variational Shadow Quantum Learning (VSQL). Our method in particular utilizes the classical shadows of quantum data, which fundamentally represent the side information of quantum data with respect to certain physical observables. Specifically, we first use variational shadow quantum circuits to extract classical features in a convolution way and then utilize a fully-connected neural network to complete the classification task. We show that this method could sharply reduce the number of parameters and thus better facilitate quantum circuit training. Simultaneously, less noise will be introduced since fewer quantum gates are employed in such shadow circuits. Moreover, we show that the Barren Plateau issue, a significant gradient vanishing problem in quantum machine learning, could be avoided in VSQL. Finally, we demonstrate the efficiency of VSQL in quantum classification via numerical experiments on the classification of quantum states and the recognition of multi-labeled handwritten digits. In particular, our VSQL approach outperforms existing variational quantum classifiers in the test accuracy in the binary case of handwritten digit recognition and notably requires much fewer parameters.",量子データの分類は、量子機械学習と短期的な量子技術にとって不可欠です。この論文では、教師あり量子学習のための新しいハイブリッド量子古典フレームワークを提案します。これを変分シャドウ量子学習（VSQL）と呼びます。特に私たちの方法は、量子データの古典的な影を利用します。これは、特定の物理的観測量に関する量子データの副次的情報を基本的に表します。具体的には、最初に変分シャドウ量子回路を使用して畳み込みの方法で古典的な特徴を抽出し、次に完全に接続されたニューラルネットワークを利用して分類タスクを完了します。この方法により、パラメーターの数が大幅に削減され、量子回路のトレーニングがより容易になることを示します。同時に、そのようなシャドウ回路で使用される量子ゲートが少ないため、導入されるノイズが少なくなります。さらに、量子機械学習における重要な勾配消失問題である不毛プラトーの問題をVSQLで回避できることを示します。最後に、量子状態の分類とマルチラベルの手書き数字の認識に関する数値実験を通じて、量子分類におけるVSQLの効率を示します。特に、私たちのVSQLアプローチは、手書き数字認識のバイナリの場合のテスト精度において、既存の変分量子分類器よりも優れており、特に必要なパラメータがはるかに少なくなっています。,https://d3i71xaburhd42.cloudfront.net/a24934da43ebc507be35b7a6facc5d4c71f505a3/3-Figure1-1.png
"Text-Based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines","['Keerthiram Murugesan', 'Mattia Atzeni', 'Pavan Kapanipathi', 'Pushkar Shukla', 'Sadhana Kumaravel', 'Gerald Tesauro', 'Kartik Talamadupula', 'Mrinmaya Sachan', 'Murray Campbell']",,,,
Knowledge-Driven Natural Language Understanding of English Text and its Applications,"['Kinjal Basu', 'Sarat Chandra Varanasi', 'Farhad Shakerin', 'Joaquín Arias', 'Gopal Gupta']",,,,
Judgment Prediction via Injecting Legal Knowledge into Neural Networks,"['Leilei Gan', 'Kun Kuang', 'Yi Yang', 'Fei Wu']",,,,
Faster and Better Simple Temporal Problems,"['Dario Ostuni', 'Alice Raffaele', 'Romeo Rizzi', 'Matteo Zavatteri']",,,,
One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline,"['Michele Bevilacqua', 'Rexhina Blloshmi', 'Roberto Navigli']",,,,
Argumentation Frameworks with Strong and Weak Constraints: Semantics and Complexity,"['Gianvincenzo Alfano', 'Sergio Greco', 'Francesco Parisi', 'Irina Trubitsyna']",,,,
A Unified Multi-Task Learning Framework for Joint Extraction of Entities and Relations,"['Tianyang Zhao', 'Zhao Yan', 'Yunbo Cao', 'Zhoujun Li']",,,,
Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach,"['Cuong Tran', 'Ferdinando Fioretto', 'Pascal Van Hentenryck']",https://arxiv.org/abs/2009.12562,"A critical concern in data-driven decision making is to build models whose outcomes do not discriminate against some demographic groups, including gender, ethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of the sensitive attributes is essential, while, in practice, these attributes may not be available due to legal and ethical requirements. To address this challenge, this paper studies a model that protects the privacy of the individuals sensitive information while also allowing it to learn non-discriminatory predictors. The method relies on the notion of differential privacy and the use of Lagrangian duality to design neural networks that can accommodate fairness constraints while guaranteeing the privacy of sensitive attributes. The paper analyses the tension between accuracy, privacy, and fairness and the experimental evaluation illustrates the benefits of the proposed model on several prediction tasks.",データ主導の意思決定における重大な懸念は、その結果が性別、民族、年齢などの一部の人口統計グループを差別しないモデルを構築することです。学習タスクで差別がないことを保証するには、機密属性の知識が不可欠ですが、実際には、これらの属性は、法的および倫理的要件のために利用できない場合があります。この課題に対処するために、このペーパーでは、個人の機密情報のプライバシーを保護すると同時に、差別のない予測子を学習できるようにするモデルを研究します。この方法は、差分プライバシーの概念とラグランジュ双対性の使用に依存して、機密属性のプライバシーを保証しながら公平性の制約に対応できるニューラルネットワークを設計します。このホワイトペーパーでは、正確性、プライバシー、公平性の間の緊張関係を分析し、実験的評価により、いくつかの予測タスクで提案されたモデルの利点を示しています。,https://d3i71xaburhd42.cloudfront.net/824fc6d70a1f88063fde107432116ca15889d99e/14-Figure1-1.png
On Fair and Efficient Allocations of Indivisible Goods,"['Aniket Murhekar', 'Jugal Garg']",,,,
Frivolous Units: Wider Networks Are Not Really That Wide,"['Stephen Casper', 'Xavier Boix', ""Vanessa D'Amario"", 'Ling Guo', 'Martin Schrimpf', 'Kasper Vinken', 'Gabriel Kreiman']",https://arxiv.org/abs/1912.04783,"A remarkable characteristic of overparameterized deep neural networks (DNNs) is that their accuracy does not degrade when the network's width is increased. Recent evidence suggests that developing compressible representations is key for adjusting the complexity of large networks to the learning task at hand. However, these compressible representations are poorly understood. A promising strand of research inspired from biology is understanding representations at the unit level as it offers a more granular and intuitive interpretation of the neural mechanisms. In order to better understand what facilitates increases in width without decreases in accuracy, we ask: Are there mechanisms at the unit level by which networks control their effective complexity as their width is increased? If so, how do these depend on the architecture, dataset, and training parameters? We identify two distinct types of ""frivolous"" units that proliferate when the network's width is increased: prunable units which can be dropped out of the network without significant change to the output and redundant units whose activities can be expressed as a linear combination of others. These units imply complexity constraints as the function the network represents could be expressed by a network without them. We also identify how the development of these units can be influenced by architecture and a number of training factors. Together, these results help to explain why the accuracy of DNNs does not degrade when width is increased and highlight the importance of frivolous units toward understanding implicit regularization in DNNs.",オーバーパラメーター化されたディープニューラルネットワーク（DNN）の注目すべき特性は、ネットワークの幅を広げても精度が低下しないことです。最近の証拠は、圧縮可能な表現を開発することが、目前の学習タスクに合わせて大規模ネットワークの複雑さを調整するための鍵であることを示唆しています。ただし、これらの圧縮可能な表現はよく理解されていません。生物学から着想を得た有望な研究は、神経メカニズムのより詳細で直感的な解釈を提供するため、ユニットレベルでの表現を理解することです。精度を低下させることなく幅の増加を促進するものをよりよく理解するために、次のように質問します。ネットワークが幅の増加に伴って効果的な複雑さを制御するメカニズムはユニットレベルにありますか？もしそうなら、これらはアーキテクチャ、データセット、トレーニングパラメータにどのように依存しますか？ネットワーク幅が増加すると増殖する2つの異なるタイプの「軽薄な」ユニットを識別します。出力を大幅に変更せずにネットワークからドロップできるプルーナブルユニットと、アクティビティを他の線形結合として表現できる冗長ユニットです。これらの単位は、ネットワークが表す機能がそれらのないネットワークによって表現される可能性があるため、複雑さの制約を意味します。また、これらのユニットの開発がアーキテクチャと多くのトレーニング要因によってどのように影響を受けるかを特定します。一緒に、これらの結果は、幅が増加したときにDNNの精度が低下しない理由を説明するのに役立ち、DNNの暗黙の正則化を理解するための軽薄なユニットの重要性を強調します。,https://d3i71xaburhd42.cloudfront.net/b834f10418f2073482f59f3293753692d6da5038/2-Figure1-1.png
Combining Preference Elicitation with Local Search and Greedy Search for Matroid Optimization,"['Nawal Benabbou', 'Cassandre Leroy', 'Thibaut Lust', 'Patrice Perny']",,,,
Stock Selection via Spatiotemporal Hypergraph Attention Network: A Learning to Rank Approach,"['Ramit Sawhney', 'Shivam Agarwal', 'Arnav Wadhwa', 'Tyler Derr', 'Rajiv Ratn Shah']",,,,
DSLR : Dynamic to Static Lidar Scan Reconstruction Using Adversarially Trained Auto Encoder,"['Prashant Kumar', 'Sabyasachi Sahoo', 'Vanshil Shah', 'Vineetha Kondameedi', 'Abhinav Jain', 'Akshaj Verma', 'Chiranjib Bhattacharyya', 'Vinay Vishwanath']",,,,
Enabling Fast and Universal Audio Adversarial Attack Using Generative Model,"['Yi Xie', 'Zhuohang Li', 'Cong Shi', 'Jian Liu', 'Yingying Chen', 'Bo Yuan']",https://arxiv.org/abs/2004.12261,"Recently, the vulnerability of DNN-based audio systems to adversarial attacks has obtained the increasing attention. However, the existing audio adversarial attacks allow the adversary to possess the entire user's audio input as well as granting sufficient time budget to generate the adversarial perturbations. These idealized assumptions, however, makes the existing audio adversarial attacks mostly impossible to be launched in a timely fashion in practice (e.g., playing unnoticeable adversarial perturbations along with user's streaming input). To overcome these limitations, in this paper we propose fast audio adversarial perturbation generator (FAPG), which uses generative model to generate adversarial perturbations for the audio input in a single forward pass, thereby drastically improving the perturbation generation speed. Built on the top of FAPG, we further propose universal audio adversarial perturbation generator (UAPG), a scheme crafting universal adversarial perturbation that can be imposed on arbitrary benign audio input to cause misclassification. Extensive experiments show that our proposed FAPG can achieve up to 167X speedup over the state-of-the-art audio adversarial attack methods. Also our proposed UAPG can generate universal adversarial perturbation that achieves much better attack performance than the state-of-the-art solutions.",最近、敵対的攻撃に対するDNNベースのオーディオシステムの脆弱性がますます注目を集めています。ただし、既存の音声敵対攻撃により、敵対者はユーザー全体の音声入力を所有できるだけでなく、敵対的混乱を生成するのに十分な時間予算を与えることができます。ただし、これらの理想化された仮定により、既存のオーディオ敵対攻撃を実際にタイムリーに開始することはほとんど不可能になります（たとえば、ユーザーが入力をストリーミングするとともに、目立たない敵対的摂動を再生する）。これらの制限を克服するために、本論文では、生成モデルを使用して単一のフォワードパスでオーディオ入力の敵対的摂動を生成し、それによって摂動生成速度を大幅に改善する高速オーディオ敵対的摂動ジェネレーター（FAPG）を提案します。 FAPGの上に構築され、ユニバーサルオーディオ敵対摂動ジェネレーター（UAPG）をさらに提案します。これは、任意の良性オーディオ入力に課して誤分類を引き起こす可能性のあるユニバーサル敵対的摂動を作成するスキームです。広範な実験により、提案されたFAPGは、最先端のオーディオ敵対攻撃方法よりも最大167倍のスピードアップを達成できることが示されています。また、提案されたUAPGは、最先端のソリューションよりもはるかに優れた攻撃パフォーマンスを実現する、普遍的な敵対的摂動を生成できます。,https://d3i71xaburhd42.cloudfront.net/ddbeddfe4d4afe5d1cf008447a6d657511c1ca76/2-Figure1-1.png
The Influence of Memory in Multi-Agent Consensus,"['David Kohan Marzagão', 'Luciana Basualdo Bonatto', 'Tiago Madeira', 'Marcelo Matheus Gauy', 'Peter McBurney']",,,,
Symbolic Music Generation with Transformer-GANs,"['Aashiq Muhamed', 'Liang Li', 'Xingjian Shi', 'Suri Yaddanapudi', 'Wayne Chi', 'Dylan Jackson', 'Suresh Rahul', 'Zachary Lipton', 'Alex J Smola']",,"Autoregressive models using Transformers have emerged as the dominant approach for music generation with the goal of synthesizing minute-long compositions that exhibit largescale musical structure. These models are commonly trained by minimizing the negative log-likelihood (NLL) of the observed sequence in an autoregressive manner. Unfortunately, the quality of samples from these models tends to degrade significantly for long sequences, a phenomenon attributed to exposure bias. Fortunately, we are able to detect these failures with classifiers trained to distinguish between real and sampled sequences, an observation that motivates our exploration of adversarial losses to complement the NLL objective. We use a pre-trained Span-BERT model for the discriminator of the GAN, which in our experiments helped with training stability. We use the Gumbel-Softmax trick to obtain a differentiable approximation of the sampling process. This makes discrete sequences amenable to optimization in GANs. In addition, we broke the sequences into smaller chunks to ensure that we stay within a given memory budget. We demonstrate via human evaluations and a new discriminative metric that the music generated by our approach outperforms a baseline trained with likelihood maximization, the state-of-the-art Music Transformer, and other GANs used for sequence generation. 57% of people prefer music generated via our approach while 43% prefer Music Transformer.",トランスフォーマーを使用した自己回帰モデルは、大規模な音楽構造を示す1分間の長さの楽曲を合成することを目的とした、音楽生成の主要なアプローチとして浮上しています。これらのモデルは通常、自己回帰法で観測されたシーケンスの負の対数尤度（NLL）を最小化することによってトレーニングされます。残念ながら、これらのモデルのサンプルの品質は、長いシーケンスでは大幅に低下する傾向があります。これは、露出バイアスに起因する現象です。幸い、実際のシーケンスとサンプリングされたシーケンスを区別するようにトレーニングされた分類器を使用してこれらの障害を検出できます。これは、NLLの目的を補完するために敵対的な損失の調査を動機付ける観察結果です。 GANの弁別子には、事前にトレーニングされたSpan-BERTモデルを使用します。これは、実験でトレーニングの安定性に役立ちました。 Gumbel-Softmaxトリックを使用して、サンプリングプロセスの微分可能な近似を取得します。これにより、離散シーケンスがGANでの最適化に適したものになります。さらに、シーケンスを小さなチャンクに分割して、指定されたメモリバジェット内にとどまるようにしました。人間による評価と新しい識別指標を介して、私たちのアプローチによって生成された音楽が、尤度最大化、最先端のミュージックトランスフォーマー、およびシーケンス生成に使用されるその他のGANでトレーニングされたベースラインよりも優れていることを示します。 57,https://d3i71xaburhd42.cloudfront.net/f07c5c540233b22f0ca154c80c713e2aed3c9606/7-Figure1-1.png
Dynamic Automaton-Guided Reward Shaping for Monte Carlo Tree Search,"['Alvaro Velasquez', 'Brett Bissey', 'Lior Barak', 'Andre Beckus', 'Ismail Alkhouri', 'Daniel Melcer', 'George Atia']",,,,
Learning General Planning Policies from Small Examples without Supervision,"['Guillem Frances', 'Blai Bonet', 'Hector Geffner']",https://arxiv.org/abs/2101.00692,"Generalized planning is concerned with the computation of general policies that solve multiple instances of a planning domain all at once. It has been recently shown that these policies can be computed in two steps: first, a suitable abstraction in the form of a qualitative numerical planning problem (QNP) is learned from sample plans, then the general policies are obtained from the learned QNP using a planner. In this work, we introduce an alternative approach for computing more expressive general policies which does not require sample plans or a QNP planner. The new formulation is very simple and can be cast in terms that are more standard in machine learning: a large but finite pool of features is defined from the predicates in the planning examples using a general grammar, and a small subset of features is sought for separating “good” from “bad” state transitions, and goals from non-goals. The problems of finding such a “separating surface” while labeling the transitions as “good” or “bad” are jointly addressed as a single combinatorial optimization problem expressed as a Weighted Max-SAT problem. The advantage of looking for the simplest policy in the given feature space that solves the given examples, possibly non-optimally, is that many domains have no general, compact policies that are optimal. The approach yields general policies for a number of benchmark domains.",一般化された計画は、計画ドメインの複数のインスタンスを一度に解決する一般的なポリシーの計算に関係しています。最近、これらのポリシーは2つのステップで計算できることが示されました。最初に、定性的数値計画問題（QNP）の形式の適切な抽象化がサンプル計画から学習され、次に一般的なポリシーが学習されたQNPからプランナー。この作業では、サンプルプランやQNPプランナーを必要としない、より表現力豊かな一般的なポリシーを計算するための代替アプローチを紹介します。新しい定式化は非常に単純で、機械学習でより標準的な用語でキャストできます。一般的な文法を使用して、計画例の述語から機能の大規模で有限のプールが定義され、機能の小さなサブセットが求められます。良い状態遷移と悪い状態遷移を分離し、目標を非目標から分離します。遷移を良好または不良としてラベル付けしながらそのような分離面を見つける問題は、加重最大SAT問題として表される単一の組み合わせ最適化問題として共同で対処されます。与えられた例を、おそらく最適ではなく解決する、与えられた特徴空間で最も単純なポリシーを探すことの利点は、多くのドメインに最適な一般的でコンパクトなポリシーがないことです。このアプローチにより、多くのベンチマークドメインの一般的なポリシーが得られます。,https://d3i71xaburhd42.cloudfront.net/beb5577af1e9be52922b9a7c13bea34e66be43a0/6-Table1-1.png
Learning to Scale Mixed-Integer Programs,"['Timo Berthold', 'Gregor Hendel']",,,,
Neural Latent Space Model for Dynamic Networks and Temporal Knowledge Graphs,"['Tony Gracious', 'Shubham Gupta', 'Arun Kanthali', 'Rui Castro', 'Ambedkar Dukkipati']",https://arxiv.org/abs/1911.11455,"Although static networks have been extensively studied in machine learning, data mining, and AI communities for many decades, the study of dynamic networks has recently taken center stage due to the prominence of social media and its effects on the dynamics of social networks. In this paper, we propose a statistical model for dynamically evolving networks, together with a variational inference approach. Our model, Neural Latent Space Model with Variational Inference, encodes edge dependencies across different time snapshots. It represents nodes via latent vectors and uses interaction matrices to model the presence of edges. These matrices can be used to incorporate multiple relations in heterogeneous networks by having a separate matrix for each of the relations. To capture the temporal dynamics, both node vectors and interaction matrices are allowed to evolve with time. Existing network analysis methods use representation learning techniques for modelling networks. These techniques are different for homogeneous and heterogeneous networks because heterogeneous networks can have multiple types of edges and nodes as opposed to a homogeneous network. Unlike these, we propose a unified model for homogeneous and heterogeneous networks in a variational inference framework. Moreover, the learned node latent vectors and interaction matrices may be interpretable and therefore provide insights on the mechanisms behind network evolution. We experimented with a single step and multi-step link forecasting on real-world networks of homogeneous, bipartite, and heterogeneous nature, and demonstrated that our model significantly outperforms existing models.",静的ネットワークは、機械学習、データマイニング、AIコミュニティで何十年にもわたって広く研究されてきましたが、ソーシャルメディアの卓越性とソーシャルネットワークのダイナミクスへの影響により、動的ネットワークの研究が最近注目を集めています。この論文では、変分推論アプローチとともに、動的に進化するネットワークの統計モデルを提案します。私たちのモデルである変分推論を使用したニューラル潜在空間モデルは、さまざまな時間スナップショットにわたるエッジの依存関係をエンコードします。潜在ベクトルを介してノードを表し、相互作用行列を使用してエッジの存在をモデル化します。これらのマトリックスを使用して、リレーションごとに個別のマトリックスを作成することにより、異種ネットワークに複数のリレーションを組み込むことができます。時間的ダイナミクスをキャプチャするために、ノードベクトルと相互作用行列の両方を時間とともに進化させることができます。既存のネットワーク分析方法は、ネットワークのモデリングに表現学習手法を使用します。異種ネットワークは同種ネットワークとは対照的に複数のタイプのエッジとノードを持つことができるため、これらの手法は同種ネットワークと異種ネットワークでは異なります。これらとは異なり、変分推論フレームワークにおける同種および異種ネットワークの統合モデルを提案します。さらに、学習されたノードの潜在ベクトルと相互作用行列は解釈可能である可能性があるため、ネットワークの進化の背後にあるメカニズムに関する洞察を提供します。同種、2部、および異種の性質の実世界ネットワークでシングルステップおよびマルチステップのリンク予測を実験し、モデルが既存のモデルを大幅に上回っていることを示しました。,https://d3i71xaburhd42.cloudfront.net/179b1d82704839b17ed03fb20653494ab067ecbe/10-Figure1-1.png
Sample Efficient Reinforcement Learning with REINFORCE,"['Junzi Zhang', 'Jongho Kim', ""Brendan O'Donoghue"", 'Stephen Boyd']",https://arxiv.org/abs/2010.11364,"Policy gradient methods are among the most effective methods for large-scale reinforcement learning, and their empirical success has prompted several works that develop the foundation of their global convergence theory. However, prior works have either required exact gradients or state-action visitation measure based mini-batch stochastic gradients with a diverging batch size, which limit their applicability in practical scenarios. In this paper, we consider classical policy gradient methods that compute an approximate gradient with a single trajectory or a fixed size mini-batch of trajectories, along with the widely-used REINFORCE gradient estimation procedure. By controlling the number of ""bad"" episodes and resorting to the classical doubling trick, we establish an anytime sub-linear high probability regret bound as well as almost sure global convergence of the average regret with an asymptotically sub-linear rate. These provide the first set of global convergence and sample efficiency results for the well-known REINFORCE algorithm and contribute to a better understanding of its performance in practice.",ポリシー勾配法は、大規模な強化学習に最も効果的な方法の1つであり、その経験的な成功により、グローバル収束理論の基礎を開発するいくつかの研究が促進されました。ただし、以前の作業では、正確な勾配またはバッチサイズが異なるミニバッチ確率的勾配に基づく状態アクション訪問測定のいずれかが必要であり、実際のシナリオでの適用が制限されていました。この論文では、広く使用されているREINFORCE勾配推定手順とともに、単一の軌道または軌道の固定サイズのミニバッチを使用して近似勾配を計算する従来のポリシー勾配法について検討します。 「悪い」エピソードの数を制御し、古典的なダブリングトリックに頼ることにより、いつでも劣線形の高確率後悔限界を確立し、漸近的に劣線形の割合で平均後悔のほぼ確実なグローバル収束を確立します。これらは、よく知られているREINFORCEアルゴリズムのグローバル収束とサンプル効率の結果の最初のセットを提供し、実際のパフォーマンスの理解を深めるのに役立ちます。,
Fairness in Forecasting and Learning Linear Dynamical Systems,"['Quan Zhou', 'Jakub Marecek', 'Robert Shorten']",https://arxiv.org/abs/2006.07315,"As machine learning becomes more pervasive, the urgency of assuring its fairness increases. Consider training data that capture the behaviour of multiple subgroups of some underlying population over time. When the amounts of training data for the subgroups are not controlled carefully, under-representation bias may arise. We introduce two natural concepts of subgroup fairness and instantaneous fairness to address such under-representation bias in forecasting problems. In particular, we consider the learning of a linear dynamical system from multiple trajectories of varying lengths, and the associated forecasting problems. We provide globally convergent methods for the subgroup-fair and instant-fair estimation using hierarchies of convexifications of non-commutative polynomial optimisation problems. We demonstrate both the beneficial impact of fairness considerations on the statistical performance and the encouraging effects of exploiting sparsity on the estimators' run-time in our computational experiments.",機械学習が普及するにつれて、その公平性を保証する緊急性が高まります。基礎となる母集団の複数のサブグループの行動を経時的にキャプチャするトレーニングデータを検討してください。サブグループのトレーニングデータの量が注意深く制御されていない場合、過小表示バイアスが発生する可能性があります。問題を予測する際のこのような過小評価バイアスに対処するために、サブグループの公平性と瞬間的な公平性の2つの自然な概念を紹介します。特に、さまざまな長さの複数の軌道からの線形動的システムの学習、および関連する予測の問題について検討します。非可換多項式最適化問題の凸面化の階層を使用して、部分群公正および即時公正推定のためのグローバルに収束する方法を提供します。統計的パフォーマンスに対する公平性の考慮の有益な影響と、計算実験における推定量の実行時間に対するスパース性の活用の有望な効果の両方を示します。,https://d3i71xaburhd42.cloudfront.net/ef52e1c7947817cdca7c5ab6cca004b5541075bc/9-Figure1-1.png
Context-Guided BERT for Targeted Aspect-Based Sentiment Analysis,"['Zhengxuan Wu', 'Desmond Ong']",,,,
Counting Maximal Satisfiable Subsets,"['Jaroslav Bendík', 'Kuldeep S Meel']",,,,
Bounding Causal Effects on Continuous Outcome,"['Junzhe Zhang', 'Elias Bareinboim']",,,,
Goal Blending for Responsive Shared Autonomy in a Navigating Vehicle,"['Yu-Sian Jiang', 'Garrett Warnell', 'Peter Stone']",,,,
Learning Invariant Representations Using Inverse Contrastive Loss,"['Aditya Kumar Akash', 'Vishnu Suresh Lokhande', 'Sathya Ravi', 'Vikas Singh']",,,,
Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain Detection,"['Alexander Podolskiy', 'Dmitry Lipin', 'Andrey Bout', 'Ekaterina Artyomova', 'Irina Piontkovskaya']",,,,
Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression,"['Christian Fiedler', 'Carsten Scherer', 'Trimpe Sebastian']",,,,
A Lightweight Neural Model for Biomedical Entity Linking,"['Lihu Chen', 'Gael P Varoquaux', 'Fabian Suchanek']",,,,
Enabling Fast Instruction-Based Modification of Learned Robot Skills,"['Tyler M Frasca', 'Bradley Oosterveld', 'Meia Chita-Tegmark', 'Matthias Scheutz']",,,,
NASTransfer: Analyzing Architecture Transferability in Large Scale Neural Architecture Search,"['Rameswar Panda', 'Michele Merler', 'Mayoore S Jaiswal', 'Hui Wu', 'Kandan Ramakrishnan', 'Ulrich Finkler', 'Chun-Fu Richard Chen', 'Minsik Cho', 'Rogerio Feris', 'David Kung', 'Bishwaranja Bhattacharjee']",https://arxiv.org/abs/2006.13314,"Neural Architecture Search (NAS) is an open and challenging problem in machine learning. While NAS offers great promise, the prohibitive computational demand of most of the existing NAS methods makes it difficult to directly search the architectures on large-scale tasks. The typical way of conducting large scale NAS is to search for an architectural building block on a small dataset (either using a proxy set from the large dataset or a completely different small scale dataset) and then transfer the block to a larger dataset. Despite a number of recent results that show the promise of transfer from proxy datasets, a comprehensive evaluation of different NAS methods studying the impact of different source datasets and training protocols has not yet been addressed. In this work, we propose to analyze the architecture transferability of different NAS methods by performing a series of experiments on large scale benchmarks such as ImageNet1K and ImageNet22K. We find that: (i) On average, transfer performance of architectures searched using completely different small datasets perform similarly to the architectures searched directly on proxy target datasets. However, design of proxy sets has considerable impact on rankings of different NAS methods. (ii) While the different NAS methods show similar performance on a source dataset (e.g., CIFAR10), they significantly differ on the transfer performance to a large dataset (e.g., ImageNet1K). (iii) Even on large datasets, the randomly sampled architecture baseline is very competitive and significantly outperforms many representative NAS methods. (iv) The training protocol has a larger impact on small datasets, but it fails to provide consistent improvements on large datasets. We believe that our NASTransfer benchmark will be key to designing future NAS strategies that consistently show superior transfer performance on large scale datasets.",Neural Architecture Search（NAS）は、機械学習におけるオープンで挑戦的な問題です。 NASは大きな期待を寄せていますが、既存のNASメソッドのほとんどは計算量が非常に多いため、大規模なタスクでアーキテクチャを直接検索することは困難です。大規模NASを実行する一般的な方法は、小規模データセットでアーキテクチャビルディングブロックを検索し（大規模データセットのプロキシセットまたは完全に異なる小規模データセットを使用）、ブロックを大規模データセットに転送することです。プロキシデータセットからの転送の可能性を示す最近の多くの結果にもかかわらず、さまざまなソースデータセットとトレーニングプロトコルの影響を研究するさまざまなNASメソッドの包括的な評価はまだ取り組まれていません。この作業では、ImageNet1KやImageNet22​​Kなどの大規模なベンチマークで一連の実験を実行することにより、さまざまなNASメソッドのアーキテクチャの転送可能性を分析することを提案します。 （i）平均して、完全に異なる小さなデータセットを使用して検索されたアーキテクチャの転送パフォーマンスは、プロキシターゲットデータセットで直接検索されたアーキテクチャと同様に機能します。ただし、プロキシセットの設計は、さまざまなNASメソッドのランキングに大きな影響を与えます。 （ii）さまざまなNASメソッドは、ソースデータセット（CIFAR10など）で同様のパフォーマンスを示しますが、大規模なデータセット（ImageNet1Kなど）への転送パフォーマンスでは大幅に異なります。 （iii）大規模なデータセットでも、ランダムにサンプリングされたアーキテクチャベースラインは非常に競争が激しく、多くの代表的なNASメソッドを大幅に上回っています。 （iv）トレーニングプロトコルは小さなデータセットに大きな影響を与えますが、大きなデータセットに一貫した改善を提供することはできません。 NASTransferベンチマークは、大規模なデータセットで優れた転送パフォーマンスを一貫して示す将来のNAS戦略を設計するための鍵になると信じています。,https://d3i71xaburhd42.cloudfront.net/c0152b279dca4bd11811e6edcfe110670dac6667/5-Figure3-1.png
NaturalConv: A Chinese Dialogue Dataset Towards Multi-Turn Topic-Driven Conversation,"['Xiaoyang Wang', 'Chen Li', 'Jianqiao Zhao', 'Dong Yu']",,,,
Reinforcement Learning of Sequential Price Mechanisms,"['Gianluca Brero', 'Alon Eden', 'Matthias Gerstgrasser', 'David Parkes', 'Duncan Rheingans-Yoo']",,,,
Robust Finite-State Controllers for Uncertain POMDPs,"['Murat Cubuktepe', 'Nils Jansen', 'Sebastian Junges', 'Ahmadreza Marandi', 'Marnix Suilen', 'Ufuk Topcu']",https://arxiv.org/abs/2009.11459,"Uncertain partially observable Markov decision processes (uPOMDPs) allow the probabilistic transition and observation functions of standard POMDPs to belong to a so-called uncertainty set. Such uncertainty sets capture uncountable sets of probability distributions. We develop an algorithm to compute finite-memory policies for uPOMDPs that robustly satisfy given specifications against any admissible distribution. In general, computing such policies is both theoretically and practically intractable. We provide an efficient solution to this problem in four steps. (1) We state the underlying problem as a nonconvex optimization problem with infinitely many constraints. (2) A dedicated dualization scheme yields a dual problem that is still nonconvex but has finitely many constraints. (3) We linearize this dual problem and (4) solve the resulting finite linear program to obtain locally optimal solutions to the original problem. The resulting problem formulation is exponentially smaller than those resulting from existing methods. We demonstrate the applicability of our algorithm using large instances of an aircraft collision-avoidance scenario and a novel spacecraft motion planning case study.",不確実な部分観測マルコフ決定過程（uPOMDP）により、標準POMDPの確率的遷移および観測関数をいわゆる不確実性セットに含めることができます。このような不確実性セットは、数え切れないほどの確率分布のセットをキャプチャします。許容される分布に対して特定の仕様を確実に満たすuPOMDPの有限メモリポリシーを計算するアルゴリズムを開発します。一般に、このようなポリシーの計算は、理論的にも実際的にも手に負えません。この問題に対する効率的な解決策を4つのステップで提供します。 （1）根底にある問題を、無限に多くの制約がある非凸最適化問題として述べます。 （2）専用の双対スキームは、依然として非凸であるが、有限に多くの制約がある双対問題を生成します。 （3）この双対問題を線形化し、（4）結果の有限線形計画法を解いて、元の問題に対する局所的に最適な解を取得します。結果として生じる問題の定式化は、既存の方法から生じるものよりも指数関数的に小さくなります。航空機の衝突回避シナリオの大規模なインスタンスと新しい宇宙船の動作計画のケーススタディを使用して、アルゴリズムの適用可能性を示します。,https://d3i71xaburhd42.cloudfront.net/d3b43e8a5cd8c30ac9c87c4ba14ce186b2b3e466/6-Figure1-1.png
Indecision Modeling,"['Duncan C McElfresh', 'Lok Chan', 'Kenzie Doyle', 'Walter Sinnott-Armstrong', 'Vincent Conitzer', 'Jana Schaich Borg', 'John P Dickerson']",https://arxiv.org/abs/2012.08485,"AI systems are often used to make or contribute to important decisions in a growing range of applications, including criminal justice, hiring, and medicine. Since these decisions impact human lives, it is important that the AI systems act in ways which align with human values. Techniques for preference modeling and social choice help researchers learn and aggregate peoples' preferences, which are used to guide AI behavior; thus, it is imperative that these learned preferences are accurate. These techniques often assume that people are willing to express strict preferences over alternatives; which is not true in practice. People are often indecisive, and especially so when their decision has moral implications. The philosophy and psychology literature shows that indecision is a measurable and nuanced behavior -- and that there are several different reasons people are indecisive. This complicates the task of both learning and aggregating preferences, since most of the relevant literature makes restrictive assumptions on the meaning of indecision. We begin to close this gap by formalizing several mathematical \emph{indecision} models based on theories from philosophy, psychology, and economics; these models can be used to describe (indecisive) agent decisions, both when they are allowed to express indecision and when they are not. We test these models using data collected from an online survey where participants choose how to (hypothetically) allocate organs to patients waiting for a transplant.",AIシステムは、刑事司法、雇用、医療など、さまざまなアプリケーションで重要な意思決定を行ったり、それに貢献したりするためによく使用されます。これらの決定は人間の生活に影響を与えるため、AIシステムが人間の価値観に沿った方法で機能することが重要です。選好モデリングと社会的選択の手法は、研究者がAIの行動を導くために使用される、人々の選好を学習して集約するのに役立ちます。したがって、これらの学習された設定が正確であることが不可欠です。これらの手法は、多くの場合、人々が代替案よりも厳格な好みを表明する用意があることを前提としています。これは実際には真実ではありません。人々はしばしば優柔不断であり、特に彼らの決定が道徳的な意味を持つ場合はそうです。哲学と心理学の文献は、優柔不断は測定可能で微妙な行動であり、人々が優柔不断であるいくつかの異なる理由があることを示しています。関連する文献のほとんどが優柔不断の意味について制限的な仮定をしているので、これは学習と好みの集約の両方のタスクを複雑にします。私たちは、哲学、心理学、経済学の理論に基づいたいくつかの数学的優柔不断モデルを形式化することによって、このギャップを埋め始めます。これらのモデルは、エージェントの決定を（決定的ではない）表現することを許可されている場合と許可されていない場合の両方で説明するために使用できます。参加者が移植を待っている患者に臓器を（仮想的に）割り当てる方法を選択するオンライン調査から収集されたデータを使用して、これらのモデルをテストします。,https://d3i71xaburhd42.cloudfront.net/85f24a03b710d304b1daf8658fc66a926c52c371/5-Figure1-1.png
Online Action Recognition,"['Alejandro Suárez-Hernández', 'Javier Segovia-Aguas', 'Carme Torras', 'Guillem Alenyà']",https://arxiv.org/abs/2012.07464,"Recognition in planning seeks to find agent intentions, goals or activities given a set of observations and a knowledge library (e.g. goal states, plans or domain theories). In this work we introduce the problem of Online Action Recognition. It consists in recognizing, in an open world, the planning action that best explains a partially observable state transition from a knowledge library of first-order STRIPS actions, which is initially empty. We frame this as an optimization problem, and propose two algorithms to address it: Action Unification (AU) and Online Action Recognition through Unification (OARU). The former builds on logic unification and generalizes two input actions using weighted partial MaxSAT. The latter looks for an action within the library that explains an observed transition. If there is such action, it generalizes it making use of AU, building in this way an AU hierarchy. Otherwise, OARU inserts a Trivial Grounded Action (TGA) in the library that explains just that transition. We report results on benchmarks from the International Planning Competition and PDDLGym, where OARU recognizes actions accurately with respect to expert knowledge, and shows real-time performance.",計画における認識は、一連の観察と知識ライブラリ（たとえば、目標の状態、計画、またはドメイン理論）を前提として、エージェントの意図、目標、または活動を見つけようとします。この作品では、オンライン行動認識の問題を紹介します。それは、オープンワールドで、最初は空である一次STRIPSアクションの知識ライブラリから部分的に観察可能な状態遷移を最もよく説明する計画アクションを認識することにあります。これを最適化問題と見なし、それに対処するための2つのアルゴリズムを提案します。アクション統合（AU）と統合によるオンラインアクション認識（OARU）です。前者は論理統合に基づいており、重み付けされた部分的なMaxSATを使用して2つの入力アクションを一般化します。後者は、観察された遷移を説明するライブラリ内のアクションを探します。そのようなアクションがある場合は、AUを利用して一般化し、このようにしてAU階層を構築します。それ以外の場合、OARUは、その遷移のみを説明するTrivial Grounded Action（TGA）をライブラリに挿入します。 OARUが専門知識に関して行動を正確に認識し、リアルタイムのパフォーマンスを示す、国際計画コンペティションとPDDLGymのベンチマークの結果を報告します。,https://d3i71xaburhd42.cloudfront.net/4d17b5ca2e90cc9a9d745197e6e254e67a85db8e/1-Figure1-1.png
Fair and Efficient Allocations with Limited Demands,"['Sushirdeep Narayana', 'Ian Kash']",,,,
Answering Regular Path Queries under Approximate Semantics in Lightweight Description Logics,"['Oliver Fernandez Gil', 'Anni-Yasmin Turhan']",,"Classical regular path queries (RPQs) can be too restrictive for some applications and answering such queries under approximate semantics to relax the query is desirable. While for answering regular path queries over graph databases under approximate semantics algorithms are available, such algorithms are scarce for the ontology-mediated setting. In this paper we extend an approach for answering RPQs over graph databases that uses weighted transducers to approximate paths from the query in two ways. The first extension is to answering approximate conjunctive 2-way regular path queries (C2RPQs) over graph databases and the second is to answering C2RPQs over ELH and DL-LiteR ontologies. We provide results on the computational complexity of the underlying reasoning problems and devise approximate query answering algorithms. ∗Supported by DFG grant BA 1122/20-1.",従来の通常パスクエリ（RPQ）は、一部のアプリケーションでは制限が厳しすぎる可能性があり、おおよそのセマンティクスの下でそのようなクエリに応答してクエリを緩和することが望ましいです。近似セマンティクスアルゴリズムの下でグラフデータベースに対する通常のパスクエリに応答するために利用できますが、そのようなアルゴリズムはオントロジーを介した設定にはほとんどありません。このホワイトペーパーでは、加重トランスデューサを使用してクエリからのパスを2つの方法で概算する、グラフデータベース上のRPQに回答するためのアプローチを拡張します。最初の拡張機能は、グラフデータベースを介したおおよその結合双方向通常パスクエリ（C2RPQ）に応答することであり、2番目の拡張機能は、ELHおよびDL-LiteRオントロジーを介したC2RPQに応答することです。根本的な推論問題の計算の複雑さに関する結果を提供し、おおよそのクエリ応答アルゴリズムを考案します。 DFGグラントBA1122 / 20-1でサポートされています。,https://d3i71xaburhd42.cloudfront.net/5c989d2bf3064dd77d8f09a87801e672cfa15b3e/9-Figure1-1.png
5* Knowledge Graph Embeddings with Projective Transformations,"['Mojtaba Nayyeri', 'Sahar Vahdati', 'Can Aykul', 'Jens Lehmann']",https://arxiv.org/abs/2006.04986,"Performing link prediction using knowledge graph embedding (KGE) models is a popular approach for knowledge graph completion. Such link predictions are performed by measuring the likelihood of links in the graph via a transformation function that maps nodes via edges into a vector space. Since the complex structure of the real world is reflected in multi-relational knowledge graphs, the transformation functions need to be able to represent this complexity. However, most of the existing transformation functions in embedding models have been designed in Euclidean geometry and only cover one or two simple transformations. Therefore, they are prone to underfitting and limited in their ability to embed complex graph structures. The area of projective geometry, however, fully covers inversion, reflection, translation, rotation, and homothety transformations. We propose a novel KGE model, which supports those transformations and subsumes other state-of-the-art models. The model has several favorable theoretical properties and outperforms existing approaches on widely used link prediction benchmarks.",知識グラフ埋め込み（KGE）モデルを使用してリンク予測を実行することは、知識グラフを完成させるための一般的なアプローチです。このようなリンク予測は、エッジを介してノードをベクトル空間にマッピングする変換関数を介して、グラフ内のリンクの尤度を測定することによって実行されます。実世界の複雑な構造はマルチリレーショナル知識グラフに反映されるため、変換関数はこの複雑さを表現できる必要があります。ただし、埋め込みモデルの既存の変換関数のほとんどはユークリッド幾何学で設計されており、1つまたは2つの単純な変換のみをカバーしています。したがって、それらは不適合になりがちであり、複雑なグラフ構造を埋め込む能力が制限されています。ただし、射影幾何学の領域は、反転、反射、平行移動、回転、および相似変換を完全にカバーしています。これらの変換をサポートし、他の最先端モデルを包含する新しいKGEモデルを提案します。このモデルにはいくつかの好ましい理論的特性があり、広く使用されているリンク予測ベンチマークでの既存のアプローチよりも優れています。,https://d3i71xaburhd42.cloudfront.net/3edceae594b88563bcda0db2502b23b3d0d076b1/3-Figure1-1.png
i-Algebra: Towards Interactive Interpretability of Deep Neural Networks,"['Xinyang Zhang', 'Pang Ren', 'Shouling Ji', 'Fenglong Ma', 'Ting Wang']",https://arxiv.org/abs/2101.09301,"Providing explanations for deep neural networks (DNNs) is essential for their use in domains wherein the interpretability of decisions is a critical prerequisite. Despite the plethora of work on interpreting DNNs, most existing solutions offer interpretability in an ad hoc, one-shot, and static manner, without accounting for the perception, understanding, or response of end-users, resulting in their poor usability in practice. In this paper, we argue that DNN interpretability should be implemented as the interactions between users and models. We present i-Algebra, a first-of-its-kind interactive framework for interpreting DNNs. At its core is a library of atomic, composable operators, which explain model behaviors at varying input granularity, during different inference stages, and from distinct interpretation perspectives. Leveraging a declarative query language, users are enabled to build various analysis tools (e.g.,""drill-down"",""comparative"",""what-if""analysis) via flexibly composing such operators. We prototype i-Algebra and conduct user studies in a set of representative analysis tasks, including inspecting adversarial inputs, resolving model inconsistency, and cleansing contaminated data, all demonstrating its promising usability.",ディープニューラルネットワーク（DNN）の説明を提供することは、意思決定の解釈可能性が重要な前提条件であるドメインでの使用に不可欠です。 DNNの解釈に関する多くの作業にもかかわらず、ほとんどの既存のソリューションは、エンドユーザーの認識、理解、または応答を考慮せずに、アドホック、ワンショット、および静的な方法で解釈可能性を提供し、実際のユーザビリティを低下させます。この論文では、DNNの解釈可能性は、ユーザーとモデルの間の相互作用として実装されるべきであると主張します。 DNNを解釈するための初めてのインタラクティブフレームワークであるi-Algebraを紹介します。その中核となるのは、さまざまな入力粒度、さまざまな推論段階、および明確な解釈の観点からのモデルの動作を説明する、アトミックで構成可能な演算子のライブラリです。宣言型クエリ言語を活用することで、ユーザーは、このような演算子を柔軟に構成することで、さまざまな分析ツール（「ドリルダウン」、「比較」、「what-if」分析など）を構築できます。 i-Algebraのプロトタイプを作成し、敵対的な入力の検査、モデルの不整合の解決、汚染されたデータのクレンジングなど、一連の代表的な分析タスクでユーザー調査を実施します。これらはすべて、その有望なユーザビリティを示しています。,
GenSynth: Synthesizing Datalog Programs without Language Bias,"['Jonathan Mendelson', 'Aaditya Naik', 'Mukund Raghothaman', 'Mayur Naik']",,"Existing techniques for learning logic programs from data typically rely on language bias mechanisms to restrict the hypothesis space. These methods are therefore limited by the user’s ability to tune them such that the hypothesis space is simultaneously large enough to include the target program but small enough to admit a tractable search. We propose a technique to learn Datalog programs from input-output examples without requiring the user to specify any language bias. It employs an evolutionary search strategy that mutates candidate programs and evaluates their fitness on the examples using an off-theshelf Datalog interpreter. We have implemented our approach in a tool called GENSYNTH and evaluate it on diverse tasks from knowledge discovery, program analysis, and relational queries. Our experiments show that GENSYNTH can learn correct programs from few examples, including for tasks that require recursion and invented predicates, and is robust to noise.",データから論理プログラムを学習するための既存の手法は、通常、言語バイアスメカニズムに依存して仮説空間を制限します。したがって、これらの方法は、仮説空間がターゲットプログラムを含めるのに十分な大きさであると同時に、扱いやすい検索を許可するのに十分な小ささになるように調整するユーザーの能力によって制限されます。ユーザーが言語バイアスを指定することなく、入出力の例からデータログプログラムを学習する手法を提案します。候補プログラムを変更し、既製のDatalogインタープリターを使用して、例に対する適合性を評価する進化的検索戦略を採用しています。 GENSYNTHと呼ばれるツールにアプローチを実装し、知識の発見、プログラム分析、リレーショナルクエリなどのさまざまなタスクでアプローチを評価しました。私たちの実験は、GENSYNTHが、再帰や発明された述語を必要とするタスクを含むいくつかの例から正しいプログラムを学習でき、ノイズに対してロバストであることを示しています。,https://d3i71xaburhd42.cloudfront.net/18bb1574af20159952ada909b88891d57ab6ef85/1-Figure1-1.png
Robustness Guarantees for Mode Estimation with an Application to Bandits,"['Aldo Pacchiano', 'Heinrich Jiang', 'Michael Jordan']",https://arxiv.org/abs/2003.02932,"Mode estimation is a classical problem in statistics with a wide range of applications in machine learning. Despite this, there is little understanding in its robustness properties under possibly adversarial data contamination. In this paper, we give precise robustness guarantees as well as privacy guarantees under simple randomization. We then introduce a theory for multi-armed bandits where the values are the modes of the reward distributions instead of the mean. We prove regret guarantees for the problems of top arm identification, top m-arms identification, contextual modal bandits, and infinite continuous arms top arm recovery. We show in simulations that our algorithms are robust to perturbation of the arms by adversarial noise sequences, thus rendering modal bandits an attractive choice in situations where the rewards may have outliers or adversarial corruptions.",モード推定は、機械学習の幅広いアプリケーションでの統計における古典的な問題です。それにもかかわらず、おそらく敵対的なデータ汚染の下でのその堅牢性の特性についてはほとんど理解されていません。このホワイトペーパーでは、単純なランダム化の下で、正確な堅牢性の保証とプライバシーの保証を提供します。次に、値が平均ではなく報酬分布のモードである多腕バンディットの理論を紹介します。トップアームの識別、トップmアームの識別、状況に応じたモーダルバンディット、および無限の連続アームのトップアームの回復の問題に対する後悔の保証を証明します。シミュレーションでは、アルゴリズムが敵対的なノイズシーケンスによる腕の摂動に対してロバストであることを示しています。したがって、報酬に外れ値や敵対的な破損がある可能性がある状況では、モーダルバンディットが魅力的な選択肢になります。,https://d3i71xaburhd42.cloudfront.net/df0d4e6036dd0679ae238c6352eeb7f77aab9076/2-Figure1-1.png
eTREE: Learning Tree-Structured Embeddings,"['Faisal Almutairi', 'Yunlong Wang', 'Dong Wang', 'Emily Zhao', 'Nicholas Sidiropoulos']",https://arxiv.org/abs/2012.10853,"Matrix factorization (MF) plays an important role in a wide range of machine learning and data mining models. MF is commonly used to obtain item embeddings and feature representations due to its ability to capture correlations and higherorder statistical dependencies across dimensions. In many applications, the categories of items exhibit a hierarchical tree structure. For instance, human diseases can be divided into coarse categories, e.g., bacterial, and viral. These categories can be further divided into finer categories, e.g., viral infections can be respiratory, gastrointestinal, and exanthematous viral diseases. In e-commerce, products, movies, books, etc., are grouped into hierarchical categories, e.g., clothing items are divided by gender, then by type (formal, casual, etc.). While the tree structure and the categories of the different items may be known in some applications, they have to be learned together with the embeddings in many others. In this work, we propose eTREE, a model that incorporates the (usually ignored) tree structure to enhance the quality of the embeddings. We leverage the special uniqueness properties of Nonnegative MF (NMF) to prove identifiability of eTREE. The proposed model not only exploits the tree structure prior, but also learns the hierarchical clustering in an unsupervised data-driven fashion. We derive an efficient algorithmic solution and a scalable implementation of eTREE that exploits parallel computing, computation caching, and warm start strategies. We showcase the effectiveness of eTREE on real data from various application domains: healthcare, recommender systems, and education. We also demonstrate the meaningfulness of the tree obtained from eTREE by means of domain experts interpretation.",マトリックス因数分解（MF）は、幅広い機械学習およびデータマイニングモデルで重要な役割を果たします。 MFは、ディメンション間の相関と高次の統計的依存関係をキャプチャする機能があるため、アイテムの埋め込みと特徴表現を取得するために一般的に使用されます。多くのアプリケーションでは、アイテムのカテゴリは階層ツリー構造を示します。たとえば、人間の病気は、細菌やウイルスなどの大まかなカテゴリに分類できます。これらのカテゴリーはさらに細かいカテゴリーに分類することができます。たとえば、ウイルス感染症は呼吸器、胃腸、および発疹性ウイルス性疾患である可能性があります。電子商取引では、製品、映画、本などが階層的なカテゴリにグループ化されます。たとえば、衣料品は性別、タイプ（フォーマル、カジュアルなど）で分類されます。一部のアプリケーションではツリー構造とさまざまなアイテムのカテゴリがわかっている場合がありますが、他の多くのアプリケーションでは埋め込みと一緒に学習する必要があります。この作業では、埋め込みの品質を向上させるために（通常は無視される）ツリー構造を組み込んだモデルであるeTREEを提案します。非負行列MF（NMF）の特別な一意性プロパティを活用して、eTREEの識別可能性を証明します。提案されたモデルは、以前のツリー構造を活用するだけでなく、教師なしデータ駆動方式で階層的クラスタリングを学習します。並列コンピューティング、計算キャッシング、およびウォームスタート戦略を活用する効率的なアルゴリズムソリューションとeTREEのスケーラブルな実装を導き出します。ヘルスケア、レコメンダーシステム、教育など、さまざまなアプリケーションドメインの実際のデータに対するeTREEの有効性を紹介します。また、ドメインエキスパートの解釈により、eTREEから取得したツリーの意味を示します。,https://d3i71xaburhd42.cloudfront.net/ac944fb86af10007e0f9ca0df5d8b6203cf593d1/1-Figure1-1.png
Illuminating Mario Scenes in the Latent Space of a Generative Adversarial Network,"['Matthew Fontaine', 'Ruilin Liu', 'Ahmed Khalifa', 'Jignesh Modi', 'Julian Togelius', 'Amy K. Hoover', 'Stefanos Nikolaidis']",https://arxiv.org/abs/2007.05674,"Recent developments in machine learning techniques have allowed automatic generation of video game levels that are stylistically similar to human-designed examples. While the output of machine learning models such as generative adversarial networks (GANs) is notoriously hard to control, the recently proposed latent variable evolution (LVE) technique searches the space of GAN parameters to generate outputs that optimize some objective performance metric, such as level playability. However, the question remains on how to automatically generate a diverse range of high-quality solutions based on a prespecified set of desired characteristics. We introduce a new method called latent space illumination (LSI), which uses state-of-the-art quality diversity algorithms designed to optimize in continuous spaces, i.e., MAP-Elites with a directional variation operator and Covariance Matrix Adaptation MAP-Elites, to effectively search the parameter space of theGAN along a set of multiple level mechanics. We show the performance of LSI algorithms in three experiments in SuperMario Bros., a benchmark domain for procedural content generation. Results suggest that LSI generates sets of Mario levels that are reliably mechanically diverse as well as playable.",機械学習技術の最近の開発により、人間が設計した例とスタイル的に類似したビデオゲームレベルの自動生成が可能になりました。生成的敵対的ネットワーク（GAN）などの機械学習モデルの出力は制御が難しいことで有名ですが、最近提案された潜在変数進化（LVE）手法は、GANパラメーターの空間を検索して、レベルなどの客観的なパフォーマンスメトリックを最適化する出力を生成します。プレイアビリティ。ただし、事前に指定された一連の望ましい特性に基づいて、さまざまな高品質のソリューションを自動的に生成する方法については疑問が残ります。潜在空間照明（LSI）と呼ばれる新しい方法を紹介します。これは、連続空間で最適化するように設計された最先端の品質ダイバーシティアルゴリズムを使用します。つまり、方向変動演算子を使用したMAP-Eliteと共分散マトリックス適応MAP-Eliteです。複数レベルのメカニズムのセットに沿ってGANのパラメータ空間を効果的に検索します。手続き型コンテンツ生成のベンチマークドメインであるスーパーマリオブラザーズでの3つの実験におけるLSIアルゴリズムのパフォーマンスを示します。結果は、LSIが確実に機械的に多様で再生可能なマリオレベルのセットを生成することを示唆しています。,https://d3i71xaburhd42.cloudfront.net/c703b09e3eab771f2f247cf8780254808a62399e/1-Figure1-1.png
Learning Precise Temporal Point Event Detection with Misaligned Labels,"['Julien Schroeter', 'Kirill Sidorov', 'David Marshall']",,,,
Multi-Goal Multi-Agent Path Finding via Decoupled and Integrated Goal Vertex Ordering,['Pavel Surynek'],https://arxiv.org/abs/2009.05161,"We introduce multi-goal multi agent path finding (MAPF$^{MG}$) which generalizes the standard discrete multi-agent path finding (MAPF) problem. While the task in MAPF is to navigate agents in an undirected graph from their starting vertices to one individual goal vertex per agent, MAPF$^{MG}$ assigns each agent multiple goal vertices and the task is to visit each of them at least once. Solving MAPF$^{MG}$ not only requires finding collision free paths for individual agents but also determining the order of visiting agent's goal vertices so that common objectives like the sum-of-costs are optimized. We suggest two novel algorithms using different paradigms to address MAPF$^{MG}$: a heuristic search-based search algorithm called Hamiltonian-CBS (HCBS) and a compilation-based algorithm built using the SMT paradigm, called SMT-Hamiltonian-CBS (SMT-HCBS). Experimental comparison suggests limitations of compilation-based approach.",標準の離散マルチエージェント経路探索（MAPF）問題を一般化するマルチゴールマルチエージェント経路探索（MAPF ^（MG））を紹介します。 MAPFのタスクは、無向グラフ内のエージェントを開始頂点からエージェントごとに1つの個別の目標頂点にナビゲートすることですが、MAPF ^（MG）は各エージェントに複数の目標頂点を割り当て、タスクは少なくとも1回は各エージェントにアクセスすることです。 MAPF ^（MG）を解くには、個々のエージェントの衝突のないパスを見つけるだけでなく、コストの合計などの一般的な目的が最適化されるように、訪問するエージェントのゴール頂点の順序を決定する必要があります。 MAPF ^（MG）に対処するために異なるパラダイムを使用する2つの新しいアルゴリズムを提案します。Hamiltonian-CBS（HCBS）と呼ばれるヒューリスティック検索ベースの検索アルゴリズムとSMT-Hamiltonian-CBS（SMT）と呼ばれるSMTパラダイムを使用して構築されたコンパイルベースのアルゴリズムです。 -HCBS）。実験的な比較は、コンパイルベースのアプローチの限界を示唆しています。,https://d3i71xaburhd42.cloudfront.net/d7e67462f756d2a6b759586bb763e2f3934e6f9b/2-Figure1-1.png
Interpretable Self-Supervised Facial Micro-Expression Learning to Predict Cognitive State and Neurological Disorders,"['Arun Das', 'Jeffrey R Mock', 'Yufei Huang', 'Edward J Golob', 'Peyman Najafirad']",,,,
SMART: A Situation Model for Algebra Story Problems via Attributed Grammar,"['Yining Hong', 'Qing Li', 'Ran Gong', 'Daniel Ciao', 'Siyuan Huang', 'Song-Chun Zhu']",https://arxiv.org/abs/2012.14011,"Solving algebra story problems remains a challenging task in artificial intelligence, which requires a detailed understanding of real-world situations and a strong mathematical reasoning capability. Previous neural solvers of math word problems directly translate problem texts into equations, lacking an explicit interpretation of the situations, and often fail to handle more sophisticated situations. To address such limits of neural solvers, we introduce the concept of a situation model, which originates from psychology studies to represent the mental states of humans in problem-solving, and propose SMART, which adopts attributed grammar as the representation of situation models for algebra story problems. Specifically, we first train an information extraction module to extract nodes, attributes, and relations from problem texts and then generate a parse graph based on a pre-defined attributed grammar. An iterative learning strategy is also proposed to improve the performance of SMART further. To rigorously study this task, we carefully curate a new dataset named ASP6.6k. Experimental results on ASP6.6k show that the proposed model outperforms all previous neural solvers by a large margin while preserving much better interpretability. To test these models’ generalization capability, we also design an out-of-distribution (OOD) evaluation, in which problems are more complex than those in the training set. Our model exceeds state-of-the-art models by 17% in the OOD evaluation, demonstrating its superior generalization ability.",代数の文章題を解決することは、人工知能において依然として困難な作業であり、現実世界の状況の詳細な理解と強力な数学的推論能力が必要です。数学の文章題の以前のニューラルソルバーは、問題のテキストを方程式に直接変換し、状況の明示的な解釈を欠いており、より洗練された状況を処理できないことがよくあります。このような神経ソルバーの限界に対処するために、心理学研究に端を発する問題解決における人間の精神状態を表す状況モデルの概念を紹介し、代数の状況モデルの表現として属性文法を採用するSMARTを提案します。物語の問題。具体的には、最初に情報抽出モジュールをトレーニングして、問題のあるテキストからノード、属性、および関係を抽出し、次に、事前定義された属性文法に基づいて解析グラフを生成します。 SMARTのパフォーマンスをさらに向上させるために、反復学習戦略も提案されています。このタスクを厳密に調査するために、ASP6.6kという名前の新しいデータセットを慎重にキュレートします。 ASP6.6kでの実験結果は、提案されたモデルが、はるかに優れた解釈可能性を維持しながら、以前のすべてのニューラルソルバーを大幅に上回っていることを示しています。これらのモデルの一般化機能をテストするために、問題がトレーニングセットの問題よりも複雑な、分布外（OOD）評価も設計します。私たちのモデルは、最先端のモデルを17だけ上回っています,https://d3i71xaburhd42.cloudfront.net/593ca71119fb6ee560926d9b304bde095267432d/4-Figure2-1.png
TAC: Towered Actor Critic for Handling Multiple Action Types in Reinforcement Learning for Drug Discovery,"['Sai Krishna Gottipati', 'Yashaswi Pathak', 'Boris Sattarov', '. Sahir', 'Rohan Nuttall', 'Mohammad Amini', 'Matthew E. Taylor', 'Sarath Chandar']",,,,
Conversational Neuro-Symbolic Commonsense Reasoning,"['Forough Arabshahi', 'Jennifer Lee', 'Mikayla Gawarecki ', 'Kathryn Mazaitis', 'Amos Azaria', 'Tom Mitchell']",https://arxiv.org/abs/2006.10022,"One aspect of human commonsense reasoning is the ability to make presumptions about daily experiences, activities and social interactions with others. We propose a new commonsense reasoning benchmark where the task is to uncover commonsense presumptions implied by imprecisely stated natural language commands in the form of if-then-because statements. For example, in the command ""If it snows at night then wake me up early because I don't want to be late for work"" the speaker relies on commonsense reasoning of the listener to infer the implicit presumption that it must snow enough to cause traffic slowdowns. Such if-then-because commands are particularly important when users instruct conversational agents. We release a benchmark data set for this task, collected from humans and annotated with commonsense presumptions. We develop a neuro-symbolic theorem prover that extracts multi-hop reasoning chains and apply it to this problem. We further develop an interactive conversational framework that evokes commonsense knowledge from humans for completing reasoning chains.",人間の常識的な推論の1つの側面は、日常の経験、活動、および他者との社会的相互作用について推測する能力です。私たちは、タスクがif-then-becauseステートメントの形で不正確に述べられた自然言語コマンドによって暗示される常識的な推定を明らかにすることである新しい常識的な推論ベンチマークを提案します。たとえば、「夜に雪が降ったら、仕事に遅れたくないので早く起こしてください」というコマンドでは、話者はリスナーの常識的な推論に基づいて、交通の減速を引き起こすのに十分な雪が必要であるという暗黙の推定を推測します。 。このようなif-then-becauseコマンドは、ユーザーが会話型エージェントに指示するときに特に重要です。人間から収集され、常識的な推定で注釈が付けられた、このタスクのベンチマークデータセットをリリースします。マルチホップ推論チェーンを抽出し、それをこの問題に適用する神経記号定理証明器を開発します。さらに、推論チェーンを完成させるために人間から常識的な知識を呼び起こすインタラクティブな会話フレームワークを開発します。,https://d3i71xaburhd42.cloudfront.net/0d5771c13307a00b79a8d9d7ddcc2defe2c495a9/4-Figure1-1.png
Learning with Safety Constraints: Sample Complexity of Reinforcement Learning for Constrained MDPs,"['Aria HasanzadeZonuzy', 'Archana Bura', 'Dileep Kalathil', 'Srinivas Shakkottai']",https://arxiv.org/abs/2008.00311,"Many physical systems have underlying safety considerations that require that the policy employed ensures the satisfaction of a set of constraints. The analytical formulation usually takes the form of a Constrained Markov Decision Process (CMDP). We focus on the case where the CMDP is unknown, and RL algorithms obtain samples to discover the model and compute an optimal constrained policy. Our goal is to characterize the relationship between safety constraints and the number of samples needed to ensure a desired level of accuracy---both objective maximization and constraint satisfaction---in a PAC sense. We explore two classes of RL algorithms, namely, (i) a generative model based approach, wherein samples are taken initially to estimate a model, and (ii) an online approach, wherein the model is updated as samples are obtained. Our main finding is that compared to the best known bounds of the unconstrained regime, the sample complexity of constrained RL algorithms are increased by a factor that is logarithmic in the number of constraints, which suggests that the approach may be easily utilized in real systems.",多くの物理システムには、採用されたポリシーが一連の制約の満足を保証することを要求する基本的な安全上の考慮事項があります。分析の定式化は通常、制約付きマルコフ決定過程（CMDP）の形式を取ります。 CMDPが不明な場合に焦点を当て、RLアルゴリズムはサンプルを取得してモデルを検出し、最適な制約付きポリシーを計算します。私たちの目標は、安全性の制約と、PACの意味での客観的な最大化と制約の満足の両方の望ましいレベルの精度を確保するために必要なサンプル数との関係を特徴づけることです。 RLアルゴリズムの2つのクラス、つまり（i）モデルを推定するために最初にサンプルが取得される生成モデルベースのアプローチと、（ii）サンプルが取得されるとモデルが更新されるオンラインアプローチを検討します。私たちの主な発見は、制約のないレジームの最もよく知られている境界と比較して、制約のあるRLアルゴリズムのサンプルの複雑さは、制約の数の対数である係数によって増加することです。これは、このアプローチが実際のシステムで簡単に利用できることを示唆しています。,
Solving Common-Payoff Games with Approximate Policy Iteration,"['Samuel Sokota', 'Edward Lockhart', 'Finbarr Timbers', 'Elnaz Davoodi', ""Ryan D'Orazio"", 'Neil Burch', 'Martin Schmid', 'Michael Bowling', 'Marc Lanctot']",https://arxiv.org/abs/2101.04237,"For artificially intelligent learning systems to have widespread applicability in real-world settings, it is important that they be able to operate decentrally. Unfortunately, decentralized control is difficult—computing even an epsilon-optimal joint policy is a NEXP complete problem. Nevertheless, a recently rediscovered insight—that a team of agents can coordinate via common knowledge—has given rise to algorithms capable of finding optimal joint policies in small common-payoff games. The Bayesian action decoder (BAD) leverages this insight and deep reinforcement learning to scale to games as large as two-player Hanabi. However, the approximations it uses to do so prevent it from discovering optimal joint policies even in games small enough to brute force optimal solutions. This work proposes CAPI, a novel algorithm which, like BAD, combines common knowledge with deep reinforcement learning. However, unlike BAD, CAPI prioritizes the propensity to discover optimal joint policies over scalability. While this choice precludes CAPI from scaling to games as large as Hanabi, empirical results demonstrate that, on the games to which CAPI does scale, it is capable of discovering optimal joint policies even when other modern multi-agent reinforcement learning algorithms are unable to do so.",人工知能学習システムが実際の環境で広く適用できるようにするには、それらが分散して動作できることが重要です。残念ながら、分散制御は、イプシロンに最適な共同ポリシーでさえNEXPの完全な問題であるとしても計算が困難です。それにもかかわらず、エージェントのチームが共通の知識を介して調整できるという最近再発見された洞察は、小さな共通のペイオフゲームで最適な共同ポリシーを見つけることができるアルゴリズムを生み出しました。ベイジアンアクションデコーダー（BAD）は、この洞察と深い強化学習を活用して、2人用の花火と同じ大きさのゲームに拡張します。ただし、これを行うために使用する近似は、ブルートフォース最適ソリューションを実行するのに十分小さいゲームでも、最適な共同ポリシーを発見できないようにします。この作品は、BADのように、一般的な知識と深い強化学習を組み合わせた新しいアルゴリズムであるCAPIを提案します。ただし、BADとは異なり、CAPIは、スケーラビリティよりも最適な共同ポリシーを見つける傾向を優先します。この選択により、CAPIは花火と同じ大きさのゲームにスケーリングできなくなりますが、経験的結果は、CAPIがスケーリングするゲームでは、他の最新のマルチエージェント強化学習アルゴリズムでは実行できない場合でも、最適な共同ポリシーを発見できることを示しています。そう。,https://d3i71xaburhd42.cloudfront.net/cdcd7ba7438f3f4510ddebcca6b6307953c6fe68/3-Figure1-1.png
Contextual Conditional Reasoning,"['Tommie Meyer', 'Giovanni Casini', 'Ivan J Varzinczak', 'Giovanni Casini']",,,,
Semi-Supervised Learning for Multi-Task Scene Understanding by Neural Graph Consensus,"['Marius Leordeanu', 'Mihai Cristian Pîrvu', 'Dragos Costea', 'Alina E Marcu', 'Emil Slusanschi', 'Rahul Sukthankar']",https://arxiv.org/abs/2010.01086,"We address the challenging problem of semi-supervised learning in the context of multiple visual interpretations of the world by finding consensus in a graph of neural networks. Each graph node is a scene interpretation layer, while each edge is a deep net that transforms one layer at one node into another from a different node. During the supervised phase edge networks are trained independently. During the next unsupervised stage edge nets are trained on the pseudo-ground truth provided by consensus among multiple paths that reach the nets' start and end nodes. These paths act as ensemble teachers for any given edge and strong consensus is used for high-confidence supervisory signal. The unsupervised learning process is repeated over several generations, in which each edge becomes a ""student"" and also part of different ensemble ""teachers"" for training other students. By optimizing such consensus between different paths, the graph reaches consistency and robustness over multiple interpretations and generations, in the face of unknown labels. We give theoretical justifications of the proposed idea and validate it on a large dataset. We show how prediction of different representations such as depth, semantic segmentation, surface normals and pose from RGB input could be effectively learned through self-supervised consensus in our graph. We also compare to state-of-the-art methods for multi-task and semi-supervised learning and show superior performance.",ニューラルネットワークのグラフでコンセンサスを見つけることにより、世界の複数の視覚的解釈のコンテキストでの半教師あり学習の困難な問題に対処します。各グラフノードはシーン解釈レイヤーであり、各エッジは、あるノードの1つのレイヤーを別のノードから別のレイヤーに変換するディープネットです。教師ありフェーズでは、エッジネットワークは個別にトレーニングされます。次の教師なしステージでは、エッジネットは、ネットの開始ノードと終了ノードに到達する複数のパス間のコンセンサスによって提供される疑似グラウンドトゥルースでトレーニングされます。これらのパスは、特定のエッジのアンサンブルティーチャーとして機能し、信頼性の高い監視信号には強力なコンセンサスが使用されます。教師なし学習プロセスは数世代にわたって繰り返され、各エッジは「学生」になり、他の学生をトレーニングするためのさまざまなアンサンブル「教師」の一部にもなります。異なるパス間のこのようなコンセンサスを最適化することにより、グラフは、未知のラベルに直面しても、複数の解釈と世代にわたって一貫性と堅牢性に到達します。提案されたアイデアの理論的正当化を示し、大規模なデータセットで検証します。 RGB入力からの深さ、セマンティックセグメンテーション、表面法線、ポーズなどのさまざまな表現の予測を、グラフ内の自己監視コンセンサスを通じて効果的に学習する方法を示します。また、マルチタスクおよび半教師あり学習の最先端の方法と比較し、優れたパフォーマンスを示します。,https://d3i71xaburhd42.cloudfront.net/a8dc3e8d4014fbaaec3647782a4f5679d6773b6a/2-Figure1-1.png
Learning Generalized Relational Heuristic Networks for Model-Agnostic Planning,"['Rushang V Karia', 'Siddharth Srivastava']",https://arxiv.org/abs/2007.06702,"Computing goal-directed behavior (sequential decision-making, or planning) is essential to designing efficient AI systems. Due to the computational complexity of planning, current approaches rely primarily upon hand-coded symbolic domain models and hand-coded heuristic-function generators for efficiency. Learned heuristics for such problems have been of limited utility as they are difficult to apply to problems with objects and object quantities that are significantly different from those in the training data. This paper develops a new approach for learning generalized heuristics in the absence of symbolic domain models using deep neural networks that utilize an input predicate vocabulary but are agnostic to object names and quantities. It uses an abstract state representation to facilitate data efficient, generalizable learning. Empirical evaluation on a range of benchmark domains show that in contrast to prior approaches, generalized heuristics computed by this method can be transferred easily to problems with different objects and with object quantities much larger than those in the training data.",効率的なAIシステムを設計するには、目標指向の動作（順次の意思決定または計画）を計算することが不可欠です。計画の計算の複雑さのために、現在のアプローチは、効率のために主に手作業でコーディングされたシンボリックドメインモデルと手作業でコーディングされたヒューリスティック関数発生器に依存しています。このような問題について学習したヒューリスティックは、トレーニングデータとは大幅に異なるオブジェクトおよびオブジェクト量の問題に適用することが難しいため、有用性が限られています。このペーパーでは、入力述語の語彙を利用するが、オブジェクトの名前と量にとらわれないディープニューラルネットワークを使用して、シンボリックドメインモデルがない場合に一般化されたヒューリスティックを学習するための新しいアプローチを開発します。抽象状態表現を使用して、データ効率の高い一般化可能な学習を促進します。一連のベンチマークドメインでの経験的評価は、以前のアプローチとは対照的に、この方法で計算された一般化されたヒューリスティックは、さまざまなオブジェクトやトレーニングデータよりもはるかに多いオブジェクト量の問題に簡単に転送できることを示しています。,https://d3i71xaburhd42.cloudfront.net/e19eb1a02d5aa8def09768c012592029596addb8/4-Figure1-1.png
Bias and Variance of Post-Processing in Differential Privacy,"['Keyu Zhu', 'Pascal Van Hentenryck', 'Ferdinando Fioretto']",https://arxiv.org/abs/2010.04327,"Post-processing immunity is a fundamental property of differential privacy: it enables the application of arbitrary data-independent transformations to the results of differentially private outputs without affecting their privacy guarantees. When query outputs must satisfy domain constraints, post-processing can be used to project the privacy-preserving outputs onto the feasible region. Moreover, when the feasible region is convex, a widely adopted class of post-processing steps is also guaranteed to improve accuracy. Post-processing has been applied successfully in many applications including census data-release, energy systems, and mobility. However, its effects on the noise distribution is poorly understood: It is often argued that post-processing may introduce bias and increase variance. This paper takes a first step towards understanding the properties of post-processing. It considers the release of census data and examines, both theoretically and empirically, the behavior of a widely adopted class of post-processing functions.",後処理イミュニティは、差分プライバシーの基本的な特性です。これにより、プライバシーの保証に影響を与えることなく、差分プライベート出力の結果に任意のデータに依存しない変換を適用できます。クエリ出力がドメインの制約を満たす必要がある場合は、後処理を使用して、プライバシーを保護する出力を実行可能領域に投影できます。さらに、実行可能領域が凸である場合、広く採用されているクラスの後処理ステップも精度を向上させることが保証されています。後処理は、国勢調査データのリリース、エネルギーシステム、モビリティなど、多くのアプリケーションで正常に適用されています。ただし、ノイズ分布への影響はよくわかっていません。後処理によってバイアスが発生し、分散が増加する可能性があるとよく言われます。このペーパーは、後処理の特性を理解するための第一歩を踏み出します。国勢調査データの公開を検討し、理論的および経験的に、広く採用されているクラスの後処理関数の動作を調べます。,https://d3i71xaburhd42.cloudfront.net/cdd9f0bfb13105ad20514cc6ed60a575d4f311ba/2-Figure1-1.png
Modeling the Compatibility of Stem Tracks to Generate Music Mashups,"['Jiawen Huang', 'Ju-Chiang Wang', 'Jordan B. L. Smith', 'Xuchen Song', 'Yuxuan Wang']",,,,
Asynchronous Stochastic Gradient Descent for Extreme-Scale Recommender Systems,"['Lewis Liu', 'Kun Zhao']",,,,
Perception Score: A Learned Metric for Open-Ended Text Generation Evaluation,"['Jing Gu', 'Qingyang Wu', 'Zhou Yu']",https://arxiv.org/abs/2008.03082,"Automatic evaluation for open-ended natural language generation tasks remains a challenge. Existing metrics such as BLEU show a low correlation with human judgment. We propose a novel and powerful learning-based evaluation metric: Perception Score. The method measures the overall quality of the generation and scores holistically instead of only focusing on one evaluation criteria, such as word overlapping. Moreover, it also shows the amount of uncertainty about its evaluation result. By connecting the uncertainty, Perception Score gives a more accurate evaluation for the generation system. Perception Score provides state-of-the-art results on two conditional generation tasks and two unconditional generation tasks.",オープンエンドの自然言語生成タスクの自動評価は、依然として課題です。 BLEUなどの既存の指標は、人間の判断との相関が低いことを示しています。斬新で強力な学習ベースの評価指標である知覚スコアを提案します。この方法では、単語の重複など、1つの評価基準だけに焦点を当てるのではなく、世代の全体的な品質を測定し、全体的にスコアを付けます。また、評価結果の不確実性も示しています。不確実性を結び付けることにより、知覚スコアは生成システムのより正確な評価を提供します。知覚スコアは、2つの条件付き生成タスクと2つの無条件生成タスクに関する最新の結果を提供します。,https://d3i71xaburhd42.cloudfront.net/c21075b86fe0608dee44c11e7667ac5b09cd4b0b/3-Figure1-1.png
Explainable Models with Consistent Interpretations,"['Vipin Pillai', 'Hamed Pirsiavash']",,"Given the widespread deployment of black box deep neural networks in computer vision applications, the interpretability aspect of these black box systems has recently gained traction. Various methods have been proposed to explain the results of such deep neural networks. However, some recent works have shown that such explanation methods are biased and do not produce consistent interpretations. Hence, rather than introducing a novel explanation method, we learn models that are encouraged to be interpretable given an explanation method. We use Grad-CAM as the explanation algorithm and encourage the network to learn consistent interpretations along with maximizing the log-likelihood of the correct class. We show that our method outperforms the baseline on the pointing game evaluation on ImageNet and MS-COCO datasets respectively. We also introduce new evaluation metrics that penalize the saliency map if it lies outside the ground truth bounding box or segmentation mask, and show that our method outperforms the baseline on these metrics as well. Moreover, our model trained with interpretation consistency generalizes to other explanation algorithms on all the evalua-",コンピュータビジョンアプリケーションにおけるブラックボックスディープニューラルネットワークの広範な展開を考えると、これらのブラックボックスシステムの解釈可能性の側面は最近注目を集めています。このようなディープニューラルネットワークの結果を説明するために、さまざまな方法が提案されています。しかし、最近のいくつかの研究では、そのような説明方法には偏りがあり、一貫した解釈が得られないことが示されています。したがって、新しい説明方法を導入するのではなく、説明方法が与えられた場合に解釈可能であることが奨励されるモデルを学習します。説明アルゴリズムとしてGrad-CAMを使用し、正しいクラスの対数尤度を最大化するとともに、ネットワークが一貫した解釈を学習することを推奨します。私たちの方法が、ImageNetおよびMS-COCOデータセットでのポインティングゲーム評価のベースラインをそれぞれ上回っていることを示します。また、顕著性マップがグラウンドトゥルースバウンディングボックスまたはセグメンテーションマスクの外側にある場合にペナルティを課す新しい評価メトリックを導入し、これらのメトリックのベースラインよりもメソッドが優れていることを示します。さらに、解釈の一貫性でトレーニングされたモデルは、すべての評価で他の説明アルゴリズムに一般化されます。,https://d3i71xaburhd42.cloudfront.net/13e5c87d143940a40ffcfa750470711c810e7d59/2-Figure1-1.png
Bayesian Persuasion under Ex Ante and Ex Post Constraints,"['Yakov Babichenko', 'Inbal Talgam-Cohen', 'Konstantin Zabarnyi']",https://arxiv.org/abs/2012.03272,"Bayesian persuasion, as introduced by Kamenica and Gentzkow in 2011, is the study of information sharing policies among strategic agents. A prime example is signaling in online ad auctions: what information should a platform signal to an advertiser regarding a user when selling the opportunity to advertise to her? Practical considerations such as preventing discrimination, protecting privacy or acknowledging limited attention of the information receiver impose constraints on information sharing. Despite their importance in real-life applications, such constraints are not usually taken into account in Bayesian persuasion literature. In our work, we propose and analyze a simple way to mathematically model such constraints as restrictions on Receiver's admissible posterior beliefs. We consider two families of constraints - ex ante and ex post, where the latter limits each instance of Sender-Receiver communication, while the former more general family can also pose restrictions in expectation. For both families, we show existence of a simple optimal signaling scheme in the sense of a small number of signals; our bounds for signal numbers are tight. We then provide an additive bi-criteria FPTAS for an optimal constrained signaling scheme when the number of states of nature is constant; we improve the approximation to single-criteria under a Slater-like regularity condition. The FPTAS holds under standard assumptions, and more relaxed assumptions yield a PTAS. Finally, we bound the ratio between Sender's optimal utility under convex ex ante constraints and the corresponding ex post constraints. We demonstrate how this bound can be applied to find an approximately welfare-maximizing constrained signaling scheme in ad auctions.",2011年にKamenicaとGentzkowによって導入されたベイズ説得は、戦略的エージェント間の情報共有ポリシーの研究です。代表的な例は、オンライン広告オークションでのシグナリングです。プラットフォームは、ユーザーに広告を出す機会を販売するときに、ユーザーに関してどのような情報を広告主に通知する必要がありますか？差別の防止、プライバシーの保護、情報受信者の限定的な注意の承認などの実際的な考慮事項は、情報共有に制約を課します。実際のアプリケーションでの重要性にもかかわらず、そのような制約は通常、ベイズ説得の文献では考慮されていません。私たちの仕事では、レシーバーの許容可能な事後信念の制限などの制約を数学的にモデル化する簡単な方法を提案し、分析します。事前と事後の2つの制約ファミリーを検討します。後者は送信者と受信者の通信の各インスタンスを制限しますが、前者のより一般的なファミリーも期待に制限を課す可能性があります。両方のファミリについて、少数の信号という意味での単純な最適な信号方式の存在を示します。信号番号の限界は厳しいです。次に、自然状態の数が一定である場合に、最適な制約付きシグナリングスキームのための加法的な2基準FPTASを提供します。 Slaterのような規則性条件下で単一基準への近似を改善します。 FPTASは標準的な仮定の下で成り立ち、より緩和された仮定はPTASを生成します。最後に、凸型の事前制約と対応する事後制約の下での送信者の最適効用の比率を制限しました。この限界を適用して、広告オークションでほぼ福祉を最大化する制約付きシグナリングスキームを見つける方法を示します。,
On the Tractability of SHAP Explanations,"['Guy Van den Broeck', 'Anton Lykov', 'Maximilian Schleich', 'Dan Suciu']",,,,
Outlier Impact Characterization for Time Series Data,"['Jianbo Li', 'Lecheng Zheng', 'Yada Zhu', 'Jingrui He']",,,,
Individual Fairness in Kidney Exchange Programs,"['Golnoosh Farnadi', 'William St-Arnaud ', 'Behrouz Babaki', 'Margarida Carvalho']",,,,
"General Policies, Representations, and Planning Width","['Blai Bonet', 'Hector Geffner']",,,,
Automated Lay Language Summarization of Biomedical Scientific Reviews,"['Yue Guo', 'Wei Qiu', 'Yizhong Wang', 'Trevor Cohen']",https://arxiv.org/abs/2012.12573,"Health literacy has emerged as a crucial factor in making appropriate health decisions and ensuring treatment outcomes. However, medical jargon and the complex structure of professional language in this domain make health information especially hard to interpret. Thus, there is an urgent unmet need for automated methods to enhance the accessibility of the biomedical literature to the general population. This problem can be framed as a type of translation problem between the language of healthcare professionals, and that of the general public. In this paper, we introduce the novel task of automated generation of lay language summaries of biomedical scientific reviews, and construct a dataset to support the development and evaluation of automated methods through which to enhance the accessibility of the biomedical literature. We conduct analyses of the various challenges in solving this task, including not only summarization of the key points but also explanation of background knowledge and simplification of professional language. We experiment with state-ofthe-art summarization models as well as several data augmentation techniques, and evaluate their performance using both automated metrics and human assessment. Results indicate that automatically generated summaries produced using contemporary neural architectures can achieve promising quality and readability as compared with reference summaries developed for the lay public by experts (best ROUGE-L of 50.24 and Flesch-Kincaid readability score of 13.30). We also discuss the limitations of the current attempt, providing insights and directions for future work.",ヘルスリテラシーは、適切な健康上の決定を下し、治療結果を確実にするための重要な要素として浮上しています。ただし、医療用語とこの分野の専門用語の複雑な構造により、健康情報の解釈が特に困難になっています。したがって、一般の人々への生物医学文献のアクセス可能性を高めるための自動化された方法に対する緊急の満たされていない必要性があります。この問題は、医療専門家の言語と一般の人々の言語との間の一種の翻訳問題として組み立てることができます。この論文では、生物医学科学レビューの一般言語要約の自動生成の新しいタスクを紹介し、生物医学文献のアクセシビリティを強化するための自動化された方法の開発と評価をサポートするデータセットを構築します。重要なポイントの要約だけでなく、背景知識の説明や専門用語の簡素化など、この課題を解決するためのさまざまな課題の分析を行います。最先端の要約モデルといくつかのデータ拡張手法を実験し、自動化された指標と人間による評価の両方を使用してそれらのパフォーマンスを評価します。結果は、現代の神経アーキテクチャを使用して生成された自動生成された要約は、専門家によって一般向けに開発された参照要約と比較して、有望な品質と読みやすさを達成できることを示しています（最高のROUGE-Lは50.24、Flesch-Kincaidの読みやすさスコアは13.30）。また、現在の試みの限界についても説明し、将来の作業のための洞察と方向性を提供します。,https://d3i71xaburhd42.cloudfront.net/a2c846a2f5d02e14e3d31859a3479d4f34752e9b/3-Table1-1.png
Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling,"['Wenxuan Zhou', 'Kevin Huang', 'Tengyu Ma', 'Jing Huang']",https://arxiv.org/abs/2010.11304,"Document-level relation extraction (RE) poses new challenges compared to its sentence-level RE counterpart. One document commonly contains multiple entity pairs, and one entity pair occurs multiple times in the document associated with multiple possible relations. In this paper, we propose two novel techniques, adaptive thresholding and localized context pooling, to solve the multilabel and multi-entity problems. The adaptive thresholding replaces the global threshold for multi-label classification in the prior work by a learnable entities-dependent threshold. The localized context pooling directly transfers attention from pre-trained language models to locate relevant context that is useful to decide the relation. We experiment on three document-level RE benchmark datasets: DocRED, a recently released large-scale RE dataset, and two datasets CDR and GDA in the biomedical domain. Our ATLOP (Adaptive Thresholding and Localized cOntext Pooling) model achieves an F1 score of 63.4; and also significantly outperforms existing models on both CDR and GDA.",ドキュメントレベルの関係抽出（RE）は、文レベルのREに比べて新しい課題をもたらします。通常、1つのドキュメントには複数のエンティティペアが含まれ、1つのエンティティペアは、複数の可能な関係に関連付けられたドキュメント内で複数回発生します。この論文では、マルチラベルとマルチエンティティの問題を解決するために、適応しきい値処理とローカライズされたコンテキストプーリングという2つの新しい手法を提案します。適応しきい値処理は、前の作業でのマルチラベル分類のグローバルしきい値を、学習可能なエンティティ依存のしきい値に置き換えます。ローカライズされたコンテキストプーリングは、事前にトレーニングされた言語モデルから直接注意を移し、関係を決定するのに役立つ関連コンテキストを見つけます。最近リリースされた大規模REデータセットであるDocREDと、生物医学分野の2つのデータセットCDRおよびGDAの3つのドキュメントレベルREベンチマークデータセットで実験します。 ATLOP（Adaptive Thresholding and Localized cOntext Pooling）モデルは、63.4のF1スコアを達成します。また、CDRとGDAの両方で既存のモデルを大幅に上回っています。,https://d3i71xaburhd42.cloudfront.net/3ac08d8c8210252cef12787539a81b0c8280ee3d/1-Figure1-1.png
SMT-Based Safety Checking of Parameterized Multi-Agent Systems,"['Paolo Felli', 'Alessandro Gianola', 'Marco Montali']",,,,
DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep Reinforcement Learning,"['Mohammadhosein Hasanbeig', 'Natasha Yogananda Jeppu', 'Alessandro Abate ', 'Tom Melham', 'Daniel Kroening']",https://arxiv.org/abs/1911.10244,"We propose a method for effective training of deep Reinforcement Learning (RL) agents when the reward is sparse and non-Markovian, but at the same time progress towards the reward requires the attainment of an unknown sequence of high-level objectives. Our method employs a recentlypublished algorithm for synthesis of compact automata to uncover this sequential structure. We synthesise an automaton from trace data generated through exploration of the environment by the deep RL agent. A product construction is then used to enrich the state space of the environment so that generation of an optimal control policy by deep RL is guided by the discovered structure encoded in the automaton. Our experiments show that our method is able to achieve training results that are otherwise difficult with state-of-the-art RL techniques unaided by external guidance.",報酬がまばらで非マルコフであるが、同時に報酬に向けて前進するには、未知の一連の高レベルの目標を達成する必要がある場合に、深層強化学習（RL）エージェントを効果的にトレーニングする方法を提案します。私たちの方法は、このシーケンシャル構造を明らかにするために、コンパクトオートマトンの合成に最近公開されたアルゴリズムを採用しています。ディープRLエージェントによる環境の探索を通じて生成されたトレースデータからオートマトンを合成します。次に、製品構造を使用して環境の状態空間を充実させ、ディープRLによる最適制御ポリシーの生成が、オートマトンにエンコードされた発見された構造によって導かれるようにします。私たちの実験は、私たちの方法が、外部のガイダンスによって支援された最先端のRL技術では他の方法では困難なトレーニング結果を達成できることを示しています。,https://d3i71xaburhd42.cloudfront.net/d7e8c8bef0c27bcfc62d7d88e30f511d2bad971a/4-Figure1-1.png
Steering a Historical Disease Forecasting Model under a Pandemic: Case of Flu and COVID-,['8325: Steering a Historical Disease Forecasting Model under a Pandemic: Case of Flu and COVID-'],,,,
"Alexander Rodríguez, Nikhil Muralidhar, Bijaya Adhikari, Anika Tabassum, Naren","['Ramakrishnan', 'B. Aditya Prakash']",,,,
IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization,"['Wenxuan Zhou', 'Bill Yuchen Lin', 'Xiang Ren']",https://arxiv.org/abs/2005.02178,"Fine-tuning pre-trained language models (PTLMs), such as BERT and its better variant RoBERTa, has been a common practice for advancing performance in natural language understanding (NLU) tasks. Recent advance in representation learning shows that isotropic (i.e., unit-variance and uncorrelated) embeddings can significantly improve performance on downstream tasks with faster convergence and better generalization. The isotropy of the pre-trained embeddings in PTLMs, however, is relatively under-explored. In this paper, we analyze the isotropy of the pre-trained [CLS] embeddings of PTLMs with straightforward visualization, and point out two major issues: high variance in their standard deviation, and high correlation between different dimensions. We also propose a new network regularization method, isotropic batch normalization (IsoBN) to address the issues, towards learning more isotropic representations in fine-tuning. This simple yet effective fine-tuning method yields about 1.0 absolute increment on the average of seven benchmark NLU tasks.",BERTやその優れたバリアントであるRoBERTaなどの事前トレーニング済み言語モデル（PTLM）を微調整することは、自然言語理解（NLU）タスクのパフォーマンスを向上させるための一般的な方法です。表現学習の最近の進歩は、等方性（つまり、単位分散と無相関）埋め込みが、より高速な収束とより優れた一般化により、ダウンストリームタスクのパフォーマンスを大幅に向上させることができることを示しています。ただし、PTLMで事前にトレーニングされた埋め込みの等方性は、比較的十分に検討されていません。この論文では、PTLMの事前トレーニング済み[CLS]埋め込みの等方性を簡単な視覚化で分析し、標準偏差の大きな分散と異なる次元間の高い相関という2つの主要な問題を指摘します。また、微調整でより等方性の表現を学習するために、問題に対処するための新しいネットワーク正則化手法である等方性バッチ正規化（IsoBN）を提案します。このシンプルで効果的な微調整方法により、7つのベンチマークNLUタスクの平均で約1.0の絶対増分が得られます。,https://d3i71xaburhd42.cloudfront.net/d04c572766d597fa4b8d59e5e5dce16e3a6c2a1b/2-Figure1-1.png
Persistence of Anti-Vaccine Sentiment in Social Networks through Strategic Interactions,"['A S M Ahsan-Ul Haque', 'Mugdha Thakur', 'Matthew Bielskas', 'Achla Marathe', 'Anil Vullikanti']",,,,
Successor Feature Sets: Generalizing Successor Representations across Policies,"['Kianté Brantley', 'Soroush Mehri', 'Geoff Gordon']",,,,
Classification with Strategically withheld Data,"['Anilesh K Krishnaswamy', 'Haoming Li', 'David Rein', 'Hanrui Zhang', 'Vincent Conitzer']",,,,
Adversarial Partial Multi-Label Learning with Label Disambiguation,"['Yan Yan', 'Yuhong Guo']",,,,
Fake it Till You Make it: Self-Supervised Semantic Shifts for Monolingual Word Embedding Tasks,"['Maurício G Gruppi', 'Pin-Yu Chen', 'Sibel Adali']",https://arxiv.org/abs/2102.00290,"The use of language is subject to variation over time as well as across social groups and knowledge domains, leading to differences even in the monolingual scenario. Such variation in word usage is often called lexical semantic change (LSC). The goal of LSC is to characterize and quantify language variations with respect to word meaning, to measure how distinct two language sources are (that is, people or language models). Because there is hardly any data available for such a task, most solutions involve unsupervised methods to align two embeddings and predict semantic change with respect to a distance measure. To that end, we propose a self-supervised approach to model lexical semantic change by generating training samples by introducing perturbations of word vectors in the input corpora. We show that our method can be used for the detection of semantic change with any alignment method. Furthermore, it can be used to choose the landmark words to use in alignment and can lead to substantial improvements over the existing techniques for alignment. We illustrate the utility of our techniques using experimental results on three different datasets, involving words with the same or different meanings. Our methods not only provide significant improvements but also can lead to novel findings for the LSC",言語の使用は、時間の経過とともに、社会集団や知識ドメイン間で変動する可能性があり、単一言語のシナリオでも違いが生じます。このような単語の使用法の変化は、しばしば語彙意味変化（LSC）と呼ばれます。 LSCの目標は、単語の意味に関して言語のバリエーションを特徴付けて定量化し、2つの言語ソース（つまり、人または言語モデル）がどれほど異なるかを測定することです。このようなタスクに使用できるデータはほとんどないため、ほとんどのソリューションには、2つの埋め込みを整列させ、距離測定に関する意味変化を予測する教師なしメソッドが含まれます。そのために、入力コーパスに単語ベクトルの摂動を導入してトレーニングサンプルを生成することにより、語彙の意味変化をモデル化するための自己教師ありアプローチを提案します。私たちの方法は、任意のアラインメント方法で意味変化の検出に使用できることを示します。さらに、アラインメントで使用するランドマークワードを選択するために使用でき、アラインメントの既存の手法を大幅に改善することができます。同じまたは異なる意味を持つ単語を含む、3つの異なるデータセットでの実験結果を使用して、私たちの手法の有用性を説明します。私たちの方法は、大幅な改善を提供するだけでなく、LSCの新しい発見につながる可能性があります,https://d3i71xaburhd42.cloudfront.net/99c74738730ed6a46f609e426b6a02119ef6f54e/2-Figure1-1.png
Encoding Syntactic Knowledge in Transformer Encoder for Intent Detection and Slot Filling,"['Jixuan Wang', 'Kai Wei', 'Martin Radfar', 'Weiwei Zhang', 'Clement Chung']",https://arxiv.org/abs/2012.11689,"We propose a novel Transformer encoder-based architecture with syntactical knowledge encoded for intent detection and slot filling. Specifically, we encode syntactic knowledge into the Transformer encoder by jointly training it to predict syntactic parse ancestors and part-of-speech of each token via multi-task learning. Our model is based on self-attention and feed-forward layers and does not require external syntactic information to be available at inference time. Experiments show that on two benchmark datasets, our models with only two Transformer encoder layers achieve state-of-the-art results. Compared to the previously best performed model without pre-training, our models achieve absolute F1 score and accuracy improvement of 1.59% and 0.85% for slot filling and intent detection on the SNIPS dataset, respectively. Our models also achieve absolute F1 score and accuracy improvement of 0.1% and 0.34% for slot filling and intent detection on the ATIS dataset, respectively, over the previously best performed model. Furthermore, the visualization of the selfattention weights illustrates the benefits of incorporating syntactic information during training.",インテント検出とスロット充填のためにエンコードされた構文知識を備えた、新しいTransformerエンコーダベースのアーキテクチャを提案します。具体的には、構文解析の祖先と各トークンの品詞をマルチタスク学習を介して予測するように共同でトレーニングすることにより、構文知識をTransformerエンコーダーにエンコードします。私たちのモデルは、自己注意層とフィードフォワード層に基づいており、推論時に外部の構文情報を利用できる必要はありません。実験によると、2つのベンチマークデータセットで、2つのTransformerエンコーダーレイヤーのみを使用したモデルが最先端の結果を達成しています。事前トレーニングなしで以前に最もよく実行されたモデルと比較して、私たちのモデルは絶対F1スコアと1.59の精度向上を達成します,https://d3i71xaburhd42.cloudfront.net/c31839ef4294e8b402a79f64e240deba2bd8dc39/1-Figure1-1.png
Context Matters: Graph-Based Self-Supervised Representation Learning for Medical Images,"['Li Sun', 'Ke Yu', 'Kayhan Batmanghelich']",https://arxiv.org/abs/2012.06457,"Supervised learning method requires a large volume of annotated datasets. Collecting such datasets is time-consuming and expensive. Until now, very few annotated COVID-19 imaging datasets are available. Although self-supervised learning enables us to bootstrap the training by exploiting unlabeled data, the generic self-supervised methods for natural images do not sufficiently incorporate the context. For medical images, a desirable method should be sensitive enough to detect deviation from normal-appearing tissue of each anatomical region; here, anatomy is the context. We introduce a novel approach with two levels of self-supervised representation learning objectives: one on the regional anatomical level and another on the patient-level. We use graph neural networks to incorporate the relationship between different anatomical regions. The structure of the graph is informed by anatomical correspondences between each patient and an anatomical atlas. In addition, the graph representation has the advantage of handling any arbitrarily sized image in full resolution. Experiments on large-scale Computer Tomography (CT) datasets of lung images show that our approach compares favorably to baseline methods that do not account for the context. We use the learnt embedding to quantify the clinical progression of COVID-19 and show that our method generalizes well to COVID-19 patients from different hospitals. Qualitative results suggest that our model can identify clinically relevant regions in the images.",教師あり学習方法では、大量の注釈付きデータセットが必要です。このようなデータセットの収集には、時間と費用がかかります。これまで、注釈付きのCOVID-19画像データセットはほとんどありません。自己教師あり学習では、ラベルのないデータを活用してトレーニングをブートストラップできますが、自然画像の一般的な自己教師あり方法では、コンテキストが十分に組み込まれていません。医用画像の場合、望ましい方法は、各解剖学的領域の正常に見える組織からの逸脱を検出するのに十分な感度が必要です。ここでは、解剖学がコンテキストです。 2つのレベルの自己教師あり表現学習目標を備えた新しいアプローチを紹介します。1つは地域の解剖学的レベルで、もう1つは患者レベルです。グラフニューラルネットワークを使用して、異なる解剖学的領域間の関係を組み込みます。グラフの構造は、各患者と解剖学的アトラスの間の解剖学的対応によって通知されます。さらに、グラフ表現には、任意のサイズの画像をフル解像度で処理できるという利点があります。肺画像の大規模なコンピューター断層撮影（CT）データセットでの実験は、私たちのアプローチがコンテキストを考慮しないベースライン方法と比べて遜色がないことを示しています。学習した埋め込みを使用して、COVID-19の臨床的進行を定量化し、私たちの方法がさまざまな病院のCOVID-19患者によく一般化することを示します。定性的な結果は、私たちのモデルが画像内の臨床的に関連する領域を識別できることを示唆しています。,https://d3i71xaburhd42.cloudfront.net/76d2a53b3e6c8db7a0139e0e4da671f5b0846bf4/11-Figure1-1.png
Inverse Reinforcement Learning with Explicit Policy Estimates,"['Navyata Sanghvi', 'Shinnosuke Usami', 'Mohit Sharma', 'Joachim Groeger', 'Kris Kitani']",,,,
LIREx: Augmenting Language Inference with Relevant Explanations,"['Xinyan Zhao', 'V.G.Vinod Vydiswaran']",https://arxiv.org/abs/2012.09157,"Natural language explanations (NLEs) are a special form of data annotation in which annotators identify rationales (most significant text tokens) when assigning labels to data instances, and write out explanations for the labels in natural language based on the rationales. NLEs have been shown to capture human reasoning better, but not as beneficial for natural language inference (NLI). In this paper, we analyze two primary flaws in the way NLEs are currently used to train explanation generators for language inference tasks. We find that the explanation generators do not take into account the variability inherent in human explanation of labels, and that the current explanation generation models generate spurious explanations. To overcome these limitations, we propose a novel framework, LIREx, that incorporates both a rationale-enabled explanation generator and an instance selector to select only relevant, plausible NLEs to augment NLI models. When evaluated on the standardized SNLI data set, LIREx achieved an accuracy of 91.87%, an improvement of 0.32 over the baseline and matching the best-reported performance on the data set. It also achieves significantly better performance than previous studies when transferred to the out-of-domain MultiNLI data set. Qualitative analysis shows that LIREx generates flexible, faithful, and relevant NLEs that allow the model to be more robust to spurious explanations. The code is available at this https URL.",自然言語の説明（NLE）は、アノテーターがデータインスタンスにラベルを割り当てるときに根拠（最も重要なテキストトークン）を識別し、根拠に基づいて自然言語でラベルの説明を書き出す特殊な形式のデータ注釈です。 NLEは、人間の推論をより適切に捉えることが示されていますが、自然言語推論（NLI）にはそれほど有益ではありません。この論文では、言語推論タスクの説明ジェネレーターをトレーニングするためにNLEが現在使用されている方法の2つの主要な欠陥を分析します。説明ジェネレーターは、ラベルの人間による説明に固有の変動性を考慮しておらず、現在の説明生成モデルは偽の説明を生成していることがわかります。これらの制限を克服するために、理論的根拠に対応した説明ジェネレーターとインスタンスセレクターの両方を組み込んで、関連するもっともらしいNLEのみを選択してNLIモデルを拡張する新しいフレームワークLIRExを提案します。標準化されたSNLIデータセットで評価した場合、LIRExは91.87の精度を達成しました。,https://d3i71xaburhd42.cloudfront.net/69b6ef8658ee9760e8f4a49590f1d6cd35dd0ae8/1-Figure1-1.png
A Scalable Two Stage Approach to Computing Optimal Decision Sets,"['Alexey Ignatiev', 'Edward Lam', 'Peter Stuckey', 'Joao Marques-Silva']",https://arxiv.org/abs/2102.01904,"Machine learning (ML) is ubiquitous in modern life. Since it is being deployed in technologies that affect our privacy and safety, it is often crucial to understand the reasoning behind its decisions, warranting the need for explainable AI. Rulebased models, such as decision trees, decision lists, and decision sets, are conventionally deemed to be the most interpretable. Recent work uses propositional satisfiability (SAT) solving (and its optimization variants) to generate minimumsize decision sets. Motivated by limited practical scalability of these earlier methods, this paper proposes a novel approach to learn minimum-size decision sets by enumerating individual rules of the target decision set independently of each other, and then solving a set cover problem to select a subset of rules. The approach makes use of modern maximum satisfiability and integer linear programming technologies. Experiments on a wide range of publicly available datasets demonstrate the advantage of the new approach over the state of the art in SAT-based decision set learning.",機械学習（ML）は、現代の生活に遍在しています。プライバシーと安全性に影響を与えるテクノロジーに導入されているため、その決定の背後にある理由を理解することが重要な場合が多く、説明可能なAIの必要性が保証されます。デシジョンツリー、デシジョンリスト、デシジョンセットなどのルールベースのモデルは、従来、最も解釈しやすいと見なされていました。最近の研究では、命題充足可能性（SAT）解法（およびその最適化バリアント）を使用して、最小サイズの意思決定セットを生成しています。これらの初期の方法の限られた実用的なスケーラビリティに動機付けられて、この論文は、互いに独立してターゲット決定セットの個々のルールを列挙し、次に集合被覆問題を解いてルールのサブセットを選択することによって最小サイズの決定セットを学習する新しいアプローチを提案します。 。このアプローチは、最新の最大充足可能性と整数線形計画技術を利用しています。広く公開されているデータセットでの実験は、SATベースの意思決定セット学習における最先端のアプローチに対する新しいアプローチの利点を示しています。,https://d3i71xaburhd42.cloudfront.net/a9b19f9e7805f278e3105b4f7bc5c914f860bd0b/6-Figure1-1.png
"Finding Diverse Trees, Paths, and More","['Tesshu Hanaka', 'Yasuaki Kobayashi', 'Kazuhiro Kurita', 'Yota Otachi']",https://arxiv.org/abs/2009.03687,"Mathematical modeling is a standard approach to solve many real-world problems and {\em diversity} of solutions is an important issue, emerging in applying solutions obtained from mathematical models to real-world problems. Many studies have been devoted to finding diverse solutions. Baste et al. (Algorithms 2019, IJCAI 2020) recently initiated the study of computing diverse solutions of combinatorial problems from the perspective of fixed-parameter tractability. They considered problems of finding $r$ solutions that maximize some diversity measures (the minimum or sum of the pairwise Hamming distances among them) and gave some fixed-parameter tractable algorithms for the diverse version of several well-known problems, such as {\sc Vertex Cover}, {\sc Feedback Vertex Set}, {\sc $d$-Hitting Set}, and problems on bounded-treewidth graphs. In this work, we investigate the (fixed-parameter) tractability of problems of finding diverse spanning trees, paths, and several subgraphs. In particular, we show that, given a graph $G$ and an integer $r$, the problem of computing $r$ spanning trees of $G$ maximizing the sum of the pairwise Hamming distances among them can be solved in polynomial time. To the best of the authors' knowledge, this is the first polynomial-time solvable case for finding diverse solutions of unbounded size.",数学的モデリングは多くの現実世界の問題を解決するための標準的なアプローチであり、解決策の多様性は重要な問題であり、数学的モデルから得られた解決策を現実世界の問題に適用する際に浮上します。多くの研究が多様な解決策を見つけることに専念してきました。バストら。 （Algorithms 2019、IJCAI 2020）は最近、固定パラメーターの扱いやすさの観点から、組み合わせ問題の多様なソリューションを計算する研究を開始しました。彼らは、いくつかの多様性尺度（それらの間のペアワイズハミング距離の最小値または合計）を最大化するr解を見つける問題を検討し、頂点被覆、フィードバックなど、いくつかのよく知られた問題の多様なバージョンに対していくつかの固定パラメーターの扱いやすいアルゴリズムを与えました。頂点セット、dヒットセット、および有界ツリー幅グラフの問題。この作業では、多様な全域木、パス、およびいくつかのサブグラフを見つける問題の（固定パラメーター）扱いやすさを調査します。特に、グラフGと整数rが与えられた場合、それらの間のペアワイズハミング距離の合計を最大化するGのスパニングツリーを計算する問題は、多項式時間で解くことができることを示します。著者の知る限りでは、これは無制限のサイズの多様な解を見つけるための最初の多項式時間で解けるケースです。,
A Hierarchical Approach to Multi-Event Survival Analysis,"['Donna E Tjandra', 'Yifei He', 'Jenna Wiens']",,,,
On the Softmax Bottleneck of Recurrent Language Models,"['Dwarak Govind Parthiban', 'Yongyi Mao', 'Diana Inkpen']",,,,
ALP-KD: Attention-Based Layer Projection for Knowledge Distillation,"['Peyman Passban', 'Yimeng Wu', 'Mehdi Rezagholizadeh', 'Qun Liu']",https://arxiv.org/abs/2012.14022,"Knowledge distillation is considered as a training and compression strategy in which two neural networks, namely a teacher and a student, are coupled together during training. The teacher network is supposed to be a trustworthy predictor and the student tries to mimic its predictions. Usually, a student with a lighter architecture is selected so we can achieve compression and yet deliver high-quality results. In such a setting, distillation only happens for final predictions whereas the student could also benefit from teacher’s supervision for internal components. Motivated by this, we studied the problem of distillation for intermediate layers. Since there might not be a one-to-one alignment between student and teacher layers, existing techniques skip some teacher layers and only distill from a subset of them. This shortcoming directly impacts quality, so we instead propose a combinatorial technique which relies on attention. Our model fuses teacher-side information and takes each layer’s significance into consideration, then performs distillation between combined teacher layers and those of the student. Using our technique, we distilled a 12-layer BERT (Devlin et al. 2019) into 6-, 4-, and 2-layer counterparts and evaluated them on GLUE tasks (Wang et al. 2018). Experimental results show that our combinatorial approach is able to outperform other existing techniques.",知識の蒸留は、2つのニューラルネットワーク、つまり教師と生徒がトレーニング中に結合されるトレーニングおよび圧縮戦略と見なされます。教師のネットワークは信頼できる予測子であると想定されており、生徒はその予測を模倣しようとします。通常、圧縮を実現しながら高品質の結果を提供できるように、アーキテクチャが軽い学生が選択されます。このような設定では、蒸留は最終的な予測に対してのみ発生しますが、生徒は内部コンポーネントに対する教師の監督からも恩恵を受けることができます。これを動機として、中間層の蒸留の問題を研究しました。生徒と教師のレイヤー間に1対1の調整がない可能性があるため、既存の手法では一部の教師レイヤーをスキップし、それらのサブセットからのみ抽出します。この欠点は品質に直接影響するため、代わりに注意に依存する組み合わせ手法を提案します。私たちのモデルは、教師側の情報を融合し、各レイヤーの重要性を考慮して、結合された教師レイヤーと生徒のレイヤーの間で蒸留を実行します。私たちの手法を使用して、12層のBERT（Devlin etal。2019）を6層、4層、および2層の対応物に蒸留し、GLUEタスクで評価しました（Wang et al.2018）。実験結果は、私たちの組み合わせアプローチが他の既存の技術をしのぐことができることを示しています。,https://d3i71xaburhd42.cloudfront.net/e339c5d31ffc7029c1f72d567ac07b4606701c72/2-Figure1-1.png
Membership Privacy for Machine Learning Models through Knowledge Transfer,"['Virat Shejwalkar', 'Amir Houmansadr']",https://arxiv.org/abs/1906.06589,"Large capacity machine learning (ML) models are prone to membership inference attacks (MIAs), which aim to infer whether the target sample is a member of the target model's training dataset. The serious privacy concerns due to the membership inference have motivated multiple defenses against MIAs, e.g., differential privacy and adversarial regularization. Unfortunately, these defenses produce ML models with unacceptably low classification performances. Our work proposes a new defense, called distillation for membership privacy (DMP), against MIAs that preserves the utility of the resulting models significantly better than prior defenses. DMP leverages knowledge distillation to train ML models with membership privacy. We provide a novel criterion to tune the data used for knowledge transfer in order to amplify the membership privacy of DMP. Our extensive evaluation shows that DMP provides significantly better tradeoffs between membership privacy and classification accuracies compared to state-of-the-art MIA defenses. For instance, DMP achieves ~100% accuracy improvement over adversarial regularization for DenseNet trained on CIFAR100, for similar membership privacy (measured using MIA risk): when the MIA risk is 53.7%, adversarially regularized DenseNet is 33.6% accurate, while DMP-trained DenseNet is 65.3% accurate.",大容量の機械学習（ML）モデルは、ターゲットサンプルがターゲットモデルトレーニングデータセットのメンバーであるかどうかを推測することを目的としたメンバーシップ推論攻撃（MIA）を起こしやすい傾向があります。メンバーシップの推論による深刻なプライバシーの懸念は、MIAに対する複数の防御、たとえば差分プライバシーや敵対的な正則化を動機付けています。残念ながら、これらの防御により、分類パフォーマンスが許容できないほど低いMLモデルが生成されます。私たちの仕事は、MIAに対する、メンバーシッププライバシーのための蒸留（DMP）と呼ばれる新しい防御を提案します。これにより、結果として得られるモデルの有用性が以前の防御よりも大幅に向上します。 DMPは、知識の蒸留を活用して、メンバーシップのプライバシーを備えたMLモデルをトレーニングします。 DMPのメンバーシップのプライバシーを強化するために、知識の伝達に使用されるデータを調整するための新しい基準を提供します。私たちの広範な評価は、DMPが、最先端のMIA防御と比較して、メンバーシップのプライバシーと分類の精度の間で大幅に優れたトレードオフを提供することを示しています。たとえば、DMPは100を達成します,
Consistency Regularization with High-Dimensional Non-Adversarial Source-Guided Perturbation for Unsupervised Domain Adaptation in Segmentation,"['Kaihong Wang', 'Chenhongyi Yang', 'Margrit Betke']",https://arxiv.org/abs/2009.08610,"Unsupervised domain adaptation for semantic segmentation has been intensively studied due to the low cost of the pixel-level annotation for synthetic data. The most common approaches try to generate images or features mimicking the distribution in the target domain while preserving the semantic contents in the source domain so that a model can be trained with annotations from the latter. However, such methods highly rely on an image translator or feature extractor trained in an elaborated mechanism including adversarial training, which brings in extra complexity and instability in the adaptation process. Furthermore, these methods mainly focus on taking advantage of the labeled source dataset, leaving the unlabeled target dataset not fully utilized. In this paper, we propose a bidirectional style-induced domain adaptation method, called BiSIDA, that employs consistency regularization to efficiently exploit information from the unlabeled target domain dataset, requiring only a simple neural style transfer model. BiSIDA aligns domains by not only transferring source images into the style of target images but also transferring target images into the style of source images to perform high-dimensional perturbation on the unlabeled target images, which is crucial to the success in applying consistency regularization in segmentation tasks. Extensive experiments show that our BiSIDA achieves new state-of-the-art on two commonly-used synthetic-to-real domain adaptation benchmarks: GTA5-to-CityScapes and SYNTHIA-to-CityScapes.",合成データのピクセルレベルの注釈のコストが低いため、セマンティックセグメンテーションの教師なしドメイン適応が集中的に研究されてきました。最も一般的なアプローチは、ソースドメインのセマンティックコンテンツを保持しながら、ターゲットドメインの分布を模倣する画像または特徴を生成しようとするため、ソースドメインの注釈を使用してモデルをトレーニングできます。ただし、このような方法は、敵対的トレーニングを含む精巧なメカニズムでトレーニングされた画像トランスレータまたは特徴抽出器に大きく依存しているため、適応プロセスがさらに複雑になり、不安定になります。さらに、これらの方法は主にラベル付きのソースデータセットを利用することに焦点を当てており、ラベルなしのターゲットデータセットは十分に活用されていません。この論文では、BiSIDAと呼ばれる双方向のスタイル誘導ドメイン適応方法を提案します。これは、一貫性の正則化を使用して、ラベルのないターゲットドメインデータセットからの情報を効率的に活用し、単純なニューラルスタイル転送モデルのみを必要とします。 BiSIDAは、ソース画像をターゲット画像のスタイルに転送するだけでなく、ターゲット画像をソース画像のスタイルに転送して、ラベルのないターゲット画像に高次元の摂動を実行することによってドメインを整列します。これは、セグメンテーションで一貫性の正則化を適用することに成功するために重要です。タスク。広範な実験により、BiSIDAは、GTA5からCityScapesおよびSYNTHIAからCityScapesという2つの一般的に使用される合成から実領域への適応ベンチマークで新しい最先端を達成することが示されています。,https://d3i71xaburhd42.cloudfront.net/2f52bb6d47360e531692dfa3ed8c46e8f7d6cc37/3-Figure1-1.png
A Permutation-Equivariant Neural Network Architecture for Auction Design,"['Jad Rahme', 'Samy Jelassi', 'Joan Bruna', 'S. Matthew Weinberg']",https://arxiv.org/abs/2003.01497,"Designing an incentive compatible auction that maximizes expected revenue is a central problem in Auction Design. Theoretical approaches to the problem have hit some limits in the past decades and analytical solutions are known for only a few simple settings. Computational approaches to the problem through the use of LPs have their own set of limitations. Building on the success of deep learning, a new approach was recently proposed by Duetting et al. (2019) in which the auction is modeled by a feed-forward neural network and the design problem is framed as a learning problem. The neural architectures used in that work are general purpose and do not take advantage of any of the symmetries the problem could present, such as permutation equivariance. In this work, we consider auction design problems that have permutation-equivariant symmetry and construct a neural architecture that is capable of perfectly recovering the permutation-equivariant optimal mechanism, which we show is not possible with the previous architecture. We demonstrate that permutation-equivariant architectures are not only capable of recovering previous results, they also have better generalization properties.",期待される収益を最大化するインセンティブ互換のオークションを設計することは、オークション設計の中心的な問題です。この問題への理論的アプローチは過去数十年でいくつかの限界に達し、分析ソリューションはいくつかの単純な設定でしか知られていません。 LPを使用した問題への計算アプローチには、独自の制限があります。ディープラーニングの成功に基づいて、最近、Duettingらによって新しいアプローチが提案されました。 （2019）オークションはフィードフォワードニューラルネットワークによってモデル化され、設計問題は学習問題として組み立てられます。その作業で使用されるニューラルアーキテクチャは汎用であり、順列同変など、問題が提示する可能性のある対称性を利用していません。この作業では、順列同変対称性を持つオークション設計の問題を検討し、前のアーキテクチャでは不可能であることを示す、順列同変最適メカニズムを完全に回復できるニューラルアーキテクチャを構築します。順列同変アーキテクチャは、以前の結果を回復できるだけでなく、より優れた一般化プロパティも備えていることを示します。,https://d3i71xaburhd42.cloudfront.net/8dd95de8846d17ccd4ad777699a646603663285f/8-Figure1-1.png
StatEcoNet: Statistical Ecology Neural Networks for Species Distribution Modeling,"['Eugene Seo', 'Rebecca Hutchinson', 'Xiao Fu', 'Chelsea A Li', 'Tyler A Hallman', 'John B Kilbride', 'W. Douglas Robinson']",,,,
A Controllable Model of Grounded Response Generation,"['Zeqiu Wu', 'Michel Galley', 'Chris Brockett', 'Yizhe Zhang', 'Xiang Gao', 'Chris Quirk', 'Rik Koncel-Kedziorski', 'Jianfeng Gao', 'Hannaneh Hajishirzi', 'Mari Ostendorf', 'Bill Dolan']",https://arxiv.org/abs/2005.00613,"Current end-to-end neural conversation models inherently lack the flexibility to impose semantic control in the response generation process. This control is essential to ensure that users' semantic intents are satisfied and to impose a degree of specificity on generated outputs. Attempts to boost informativeness alone come at the expense of factual accuracy, as attested by GPT-2's propensity to ""hallucinate"" facts. While this may be mitigated by access to background knowledge, there is scant guarantee of relevance and informativeness in generated responses. We propose a framework that we call controllable grounded response generation (CGRG), in which lexical control phrases are either provided by an user or automatically extracted by a content planner from dialogue context and grounding knowledge. Quantitative and qualitative results show that, using this framework, a GPT-2 based model trained on a conversation-like Reddit dataset outperforms strong generation baselines.",現在のエンドツーエンドのニューラル会話モデルは、本質的に、応答生成プロセスでセマンティック制御を課す柔軟性を欠いています。この制御は、ユーザーのセマンティックインテントが満たされていることを確認し、生成された出力にある程度の特異性を課すために不可欠です。事実を「幻覚化」するGPT-2の傾向によって証明されているように、情報提供のみを高める試みは、事実の正確さを犠牲にして行われます。これは背景知識へのアクセスによって軽減されるかもしれませんが、生成された応答の関連性と有益性の保証はほとんどありません。制御可能な接地応答生成（CGRG）と呼ばれるフレームワークを提案します。このフレームワークでは、字句制御フレーズがユーザーによって提供されるか、コンテンツプランナーによって対話コンテキストと接地知識から自動的に抽出されます。定量的および定性的な結果は、このフレームワークを使用して、会話のようなRedditデータセットでトレーニングされたGPT-2ベースのモデルが強力な生成ベースラインよりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/d596c6b9c7200195beb0cdab5d25d9941360fa6c/1-Figure1-1.png
Estimating Calibrated Individualized Survival Curves with Deep Learning,"['Fahad Kamran', 'Jenna Wiens']",,,,
Learning to Rationalize for Nonmonotonic Reasoning with Distant Supervision,"['Faeze FB Brahman', 'Vered Shwartz', 'Rachel Rudinger', 'Yejin Choi']",https://arxiv.org/abs/2012.08012,"The black-box nature of neural models has motivated a line of research that aims to generate natural language rationales to explain why a model made certain predictions. Such rationale generation models, to date, have been trained on dataset-specific crowdsourced rationales, but this approach is costly and is not generalizable to new tasks and domains. In this paper, we investigate the extent to which neural models can reason about natural language rationales that explain model predictions, relying only on distant supervision with no additional annotation cost for human-written rationales. We investigate multiple ways to automatically generate rationales using pre-trained language models, neural knowledge models, and distant supervision from related tasks, and train generative models capable of composing explanatory rationales for unseen instances. We demonstrate our approach on the defeasible inference task, a nonmonotonic reasoning task in which an inference may be strengthened or weakened when new information (an update) is introduced. Our model shows promises at generating post-hoc rationales explaining why an inference is more or less likely given the additional information, however, it mostly generates trivial rationales reflecting the fundamental limitations of neural language models. Conversely, the more realistic setup of jointly predicting the update or its type and generating rationale is more challenging, suggesting an important future direction.",ニューラルモデルのブラックボックスの性質は、モデルが特定の予測を行った理由を説明するための自然言語の理論的根拠を生成することを目的とした一連の研究の動機となっています。このような根拠生成モデルは、これまで、データセット固有のクラウドソーシングされた根拠に基づいてトレーニングされてきましたが、このアプローチはコストがかかり、新しいタスクやドメインに一般化することはできません。この論文では、人間が書いた理論的根拠に追加の注釈コストをかけずに、遠隔監視のみに依存して、神経モデルがモデル予測を説明する自然言語の理論的根拠について推論できる範囲を調査します。事前に訓練された言語モデル、神経知識モデル、および関連するタスクからの遠隔監視を使用して合理性を自動的に生成する複数の方法を調査し、目に見えないインスタンスの説明的合理性を構成できる生成モデルを訓練します。新しい情報（更新）が導入されたときに推論が強化または弱められる可能性がある非単調推論タスクである、実行不可能な推論タスクに対するアプローチを示します。私たちのモデルは、追加情報が与えられた場合に推論が多かれ少なかれ可能性が高い理由を説明する事後的根拠を生成する見込みを示していますが、ほとんどの場合、神経言語モデルの基本的な制限を反映する些細な根拠を生成します。逆に、更新またはそのタイプを共同で予測し、理論的根拠を生成するというより現実的な設定は、より困難であり、重要な将来の方向性を示唆しています。,https://d3i71xaburhd42.cloudfront.net/3a1311fbba348a13857f54b92c24be4ee75d1b41/1-Figure1-1.png
Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation,"['Umang Gupta', 'Aaron M Ferber', 'Bistra Dilkina', 'Greg Ver Steeg']",https://arxiv.org/abs/2101.04108,"Controlling bias in training datasets is vital for ensuring equal treatment, or parity, between different groups in downstream applications. A naive solution is to transform the data so that it is statistically independent of group membership, but this may throw away too much information when a reasonable compromise between fairness and accuracy is desired. Another common approach is to limit the ability of a particular adversary who seeks to maximize parity. Unfortunately, representations produced by adversarial approaches may still retain biases as their efficacy is tied to the complexity of the adversary used during training. To this end, we theoretically establish that by limiting the mutual information between representations and protected attributes, we can assuredly control the parity of any downstream classifier. We demonstrate an effective method for controlling parity through mutual information based on contrastive information estimators and show that they outperform approaches that rely on variational bounds based on complex generative models. We test our approach on UCI Adult and Heritage Health datasets and demonstrate that our approach provides more informative representations across a range of desired parity thresholds while providing strong theoretical guarantees on the parity of any downstream algorithm.",トレーニングデータセットのバイアスを制御することは、ダウンストリームアプリケーションの異なるグループ間で同等の扱いまたは同等性を確保するために不可欠です。単純な解決策は、データを変換してグループメンバーシップから統計的に独立させることですが、公平性と正確性の間の妥当な妥協が必要な場合、これにより多くの情報が破棄される可能性があります。別の一般的なアプローチは、パリティを最大化しようとする特定の敵の能力を制限することです。残念ながら、敵対的アプローチによって生成された表現は、その有効性がトレーニング中に使用される敵対者の複雑さに関係しているため、依然としてバイアスを保持している可能性があります。この目的のために、表現と保護された属性の間の相互情報量を制限することにより、ダウンストリーム分類器のパリティを確実に制御できることを理論的に確立します。対照的な情報推定量に基づく相互情報量を介してパリティを制御するための効果的な方法を示し、複雑な生成モデルに基づく変分境界に依存するアプローチよりも優れていることを示します。 UCIアダルトおよびヘリテージヘルスデータセットでアプローチをテストし、ダウンストリームアルゴリズムのパリティに関する強力な理論的保証を提供しながら、望ましいパリティしきい値の範囲全体でより有益な表現を提供することを示します。,https://d3i71xaburhd42.cloudfront.net/b74c5b7c97ded089caa481964207ba5e0e65b659/2-Figure1-1.png
IDOL: Inertial Deep Orientation-Estimation and Localization,"['Scott Sun', 'Dennis Melamed', 'Kris Kitani']",https://arxiv.org/abs/2102.04024,"Many smartphone applications use inertial measurement units (IMUs) to sense movement, but the use of these sensors for pedestrian localization can be challenging due to their noise characteristics. Recent data-driven inertial odometry approaches have demonstrated the increasing feasibility of inertial navigation. However, they still rely upon conventional smartphone orientation estimates that they assume to be accurate, while in fact these orientation estimates can be a significant source of error. To address the problem of inaccurate orientation estimates, we present a two-stage, data-driven pipeline using a commodity smartphone that first estimates device orientations and then estimates device position. The orientation module relies on a recurrent neural network and Extended Kalman Filter to obtain orientation estimates that are used to then rotate raw IMU measurements into the appropriate reference frame. The position module then passes those measurements through another recurrent network architecture to perform localization. Our proposed method outperforms state-of-the-art methods in both orientation and position error on a large dataset we constructed that contains 20 hours of pedestrian motion across 3 buildings and 15 subjects. Code and data are available at https://github.com/KlabCMU/IDOL.",多くのスマートフォンアプリケーションは、慣性測定ユニット（IMU）を使用して動きを感知しますが、歩行者の位置を特定するためにこれらのセンサーを使用することは、ノイズ特性のために困難な場合があります。最近のデータ駆動型慣性オドメトリアプローチは、慣性航法の実現可能性が高まっていることを示しています。ただし、実際にはこれらの向きの推定値が重大なエラーの原因となる可能性がある一方で、それらは依然として正確であると想定する従来のスマートフォンの向きの推定値に依存しています。不正確な向きの推定の問題に対処するために、最初にデバイスの向きを推定し、次にデバイスの位置を推定するコモディティスマートフォンを使用した2段階のデータ駆動型パイプラインを紹介します。オリエンテーションモジュールは、リカレントニューラルネットワークと拡張カルマンフィルターに依存して、生のIMU測定値を適切な参照フレームに回転させるために使用されるオリエンテーション推定値を取得します。次に、位置モジュールは、これらの測定値を別のリカレントネットワークアーキテクチャに渡して、ローカリゼーションを実行します。私たちが提案した方法は、3つの建物と15人の被験者にわたる20時間の歩行者の動きを含む、私たちが構築した大規模なデータセットで、方向と位置のエラーの両方で最先端の方法よりも優れています。コードとデータはhttps://github.com/KlabCMU/IDOLで入手できます。,https://d3i71xaburhd42.cloudfront.net/db7b3a85b6a3676b86627b1b5ae45373b2d066b7/1-Figure1-1.png
Graph Neural Networks with Heterophily,"['Jiong Zhu', 'Ryan A. Rossi', 'Anup Rao', 'Tung Mai', 'Nedim Lipka', 'Nesreen Ahmed', 'Danai Koutra']",https://arxiv.org/abs/2009.13566,"Graph Neural Networks (GNNs) have proven to be useful for many different practical applications. However, most existing GNN models have an implicit assumption of homophily among the nodes connected in the graph, and therefore have largely overlooked the important setting of heterophily. In this work, we propose a novel framework called CPGNN that generalizes GNNs for graphs with either homophily or heterophily. The proposed framework incorporates an interpretable compatibility matrix for modeling the heterophily or homophily level in the graph, which can be learned in an end-to-end fashion, enabling it to go beyond the assumption of strong homophily. Theoretically, we show that replacing the compatibility matrix in our framework with the identity (which represents pure homophily) reduces to GCN. Our extensive experiments demonstrate the effectiveness of our approach in more realistic and challenging experimental settings with significantly less training data compared to previous works: CPGNN variants achieve state-of-the-art results in heterophily settings with or without contextual node features, while maintaining comparable performance in homophily settings.",グラフニューラルネットワーク（GNN）は、さまざまな実用的なアプリケーションに役立つことが証明されています。ただし、ほとんどの既存のGNNモデルは、グラフで接続されたノード間でホモフィリーを暗黙的に想定しているため、ヘテロフィリーの重要な設定を見落としています。この作業では、ホモフィリーまたはヘテロフィリーのいずれかを使用してグラフのGNNを一般化するCPGNNと呼ばれる新しいフレームワークを提案します。提案されたフレームワークは、グラフ内のヘテロフィリーまたはホモフィリーレベルをモデル化するための解釈可能な互換性マトリックスを組み込んでおり、エンドツーエンドの方法で学習できるため、強いホモフィリーの仮定を超えることができます。理論的には、フレームワークの互換性マトリックスをアイデンティティ（純粋な同質性を表す）に置き換えると、GCNが減少することを示します。私たちの広範な実験は、以前の作品と比較して大幅に少ないトレーニングデータで、より現実的で挑戦的な実験設定でのアプローチの有効性を示しています：CPGNNバリアントは、同等のノード機能を維持しながら、コンテキストノード機能の有無にかかわらず異形設定で最先端の結果を達成しますホモフィリー設定でのパフォーマンス。,
Necessary and Sufficient Conditions for Avoiding Reopenings in Best First Suboptimal Search with General Bounding Functions,"['Jingwei Chen', 'Nathan R Sturtevant']",,"Recent work introduced XDP and XUP priority functions for best-first bounded-suboptimal search that do not need to perform state re-expansions as long as the search heuristic is consistent. However, that work had several limitations that are rectified here. This paper analyzes the sufficiency and necessity of the conditions used to formulate XDP and XUP. The analysis presents a simpler proof and generalizes the result in three aspects: (1) the priority function no longer has to be differentiable everywhere, (2) the quality of the solution does not have to be bounded by a constant factor, and (3) directed graphs are handled correctly. These results allow the introduction of more priority functions, such as piecewise linear functions, and more variants of bounded-suboptimal search, such as constant suboptimality. Several new priority functions are presented in this paper that, according to empirical results, can significantly outperform existing approaches including XDP.",最近の研究では、検索ヒューリスティックが一貫している限り、状態の再拡張を実行する必要がない、ベストファーストの制限付き準最適検索のためのXDPおよびXUP優先度関数が導入されました。ただし、その作業にはいくつかの制限があり、ここで修正されます。この論文は、XDPとXUPを定式化するために使用される条件の十分性と必要性​​を分析します。分析はより単純な証明を提示し、3つの側面で結果を一般化します：（1）優先度関数はもはやどこでも微分可能である必要はありません、（2）ソリューションの品質は一定の要因によって制限される必要はありません、そして（3 ）有向グラフは正しく処理されます。これらの結果により、区分的線形関数などのより優先度の高い関数や、一定の準最適性などの有界準最適検索のバリエーションをさらに導入できます。このホワイトペーパーでは、経験的な結果によると、XDPを含む既存のアプローチを大幅に上回ることができるいくつかの新しい優先度関数を紹介します。,https://d3i71xaburhd42.cloudfront.net/297956965fd461da0a1cd113602a1cf7fa86d023/2-Figure1-1.png
Have We Solved the Hard Problem? It’s Not Easy! Contextual Lexical Contrast as a Means to Probe Neural Coherence,"['Wenqiang Lei', 'Yisong Miao', 'Runpeng Xie', 'Bonnie Webber', 'Meichun Liu', 'Tat-Seng Chua', 'Nancy Chen']",,,,
Contract-Based Inter-User Usage Coordination in Free-Floating Car Sharing,"['Kentaro Takahira', 'Shigeo Matsubara']",,,,
Bayes-TrEx: a Bayesian Sampling Approach to Model Transparency by Example,"['Serena L Booth', 'Yilun Zhou', 'Ankit Shah', 'Julie A. Shah']",https://arxiv.org/abs/2002.10248,"Post-hoc explanation methods are gaining popularity for interpreting, understanding, and debugging neural networks. Most analyses using such methods explain decisions in response to inputs drawn from the test set. However, the test set may have few examples that trigger some model behaviors, such as high-confidence failures or ambiguous classifications. To address these challenges, we introduce a flexible model inspection framework: Bayes-TrEx. Given a data distribution, Bayes-TrEx finds in-distribution examples with a specified prediction confidence. We demonstrate several use cases of Bayes-TrEx, including revealing highly confident (mis)classifications, visualizing class boundaries via ambiguous examples, understanding novel-class extrapolation behavior, and exposing neural network overconfidence. We use Bayes-TrEx to study classifiers trained on CLEVR, MNIST, and Fashion-MNIST, and we show that this framework enables more flexible holistic model analysis than just inspecting the test set. Code is available at https://github.com/serenabooth/Bayes-TrEx.",事後説明方法は、ニューラルネットワークの解釈、理解、およびデバッグで人気が高まっています。このような方法を使用するほとんどの分析は、テストセットから引き出された入力に応じた決定を説明します。ただし、テストセットには、信頼性の高い失敗やあいまいな分類など、一部のモデルの動作をトリガーする例がほとんどない場合があります。これらの課題に対処するために、柔軟なモデル検査フレームワークであるベイズ-TrExを導入します。データ分布が与えられると、Bayes-TrExは、指定された予測信頼度を持つ分布内の例を見つけます。ベイズ-TrExのいくつかのユースケースを示します。これには、信頼性の高い（誤）分類の明らかに、あいまいな例によるクラス境界の視覚化、新規クラスの外挿動作の理解、ニューラルネットワークの自信過剰の暴露などが含まれます。 Bayes-TrExを使用して、CLEVR、MNIST、およびFashion-MNISTでトレーニングされた分類器を研究し、このフレームワークにより、テストセットを検査するだけでなく、より柔軟な全体モデル分析が可能になることを示します。コードはhttps://github.com/serenabooth/Bayes-TrExで入手できます。,
Improving Causal Discovery by Optimal Bayesian Network Learning,"['Ni Lu', 'Kun Zhang', 'Changhe Yuan']",,,,
Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection,"['Edward Raff', 'William Fleshman', 'Richard J Zak', 'Hyrum Anderson', 'Bobby Filar', 'Mark McLean']",https://arxiv.org/abs/2012.09390,"Recent works within machine learning have been tackling inputs of ever-increasing size, with cybersecurity presenting sequence classification problems of particularly extreme lengths. In the case of Windows executable malware detection, inputs may exceed $100$ MB, which corresponds to a time series with $T=100,000,000$ steps. To date, the closest approach to handling such a task is MalConv, a convolutional neural network capable of processing up to $T=2,000,000$ steps. The $\mathcal{O}(T)$ memory of CNNs has prevented further application of CNNs to malware. In this work, we develop a new approach to temporal max pooling that makes the required memory invariant to the sequence length $T$. This makes MalConv $116\times$ more memory efficient, and up to $25.8\times$ faster to train on its original dataset, while removing the input length restrictions to MalConv. We re-invest these gains into improving the MalConv architecture by developing a new Global Channel Gating design, giving us an attention mechanism capable of learning feature interactions across 100 million time steps in an efficient manner, a capability lacked by the original MalConv CNN. Our implementation can be found at this https URL",機械学習における最近の研究は、ますます増大するサイズの入力に取り組んでおり、サイバーセキュリティは特に極端な長さのシーケンス分類の問題を提示しています。 Windows実行可能マルウェア検出の場合、入力は100 MBを超える可能性があります。これは、T = 100、000、000ステップの時系列に対応します。現在まで、このようなタスクを処理するための最も近いアプローチは、T = 2、000、000ステップまで処理できる畳み込みニューラルネットワークであるMalConvです。 CNNのO（T）メモリにより、マルウェアへのCNNのさらなる適用が妨げられています。この作業では、必要なメモリをシーケンス長Tに対して不変にする、時間最大プーリングへの新しいアプローチを開発します。これにより、MalConv 116のメモリ効率が向上し、入力長を削除しながら、元のデータセットでのトレーニングが最大25.8高速になります。 MalConvへの制限。新しいグローバルチャネルゲーティング設計を開発することにより、これらの利益をMalConvアーキテクチャの改善に再投資し、元のMalConv CNNにはなかった、1億タイムステップにわたる機能の相互作用を効率的に学習できるアテンションメカニズムを提供します。私たちの実装はこのhttpsURLで見つけることができます,https://d3i71xaburhd42.cloudfront.net/5bd07b7b023b68d8f6d50716afbced6fc35369f9/3-Figure1-1.png
Hybrid-Order Stochastic Block Model,"['Xunxun Wu', 'Chang-Dong Wang', 'Pengfei Jiao']",,,,
Optimising Automatic Calibration of Electric Muscle Stimulation,"['Graeme Gange', 'Jarrod Knibbe']",,,,
Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning,"['Shangtong Zhang', 'Bo Liu', 'Shimon Whiteson']",https://arxiv.org/abs/2004.10888,"We present a mean-variance policy iteration (MVPI) framework for risk-averse control in a discounted infinite horizon MDP. MVPI enjoys great flexibility in that any policy evaluation method and risk-neutral control method can be dropped in for risk-averse control off the shelf, in both on- and off-policy settings. We propose risk-averse TD3 as an example instantiating MVPI, which outperforms vanilla TD3 and many previous risk-averse control methods in challenging Mujoco robot simulation tasks under a risk-aware performance metric. This risk-averse TD3 is the first to introduce deterministic policies and off-policy learning into risk-averse reinforcement learning, both of which are key to the performance boost we show in Mujoco domains. MVPI adopts a per-step reward perspective (Bisi et al., 2019) for risk-averse control, instead of the commonly used total reward perspective.",割引された無限の地平線MDPにおけるリスク回避制御のための平均分散ポリシー反復（MVPI）フレームワークを提示します。 MVPIは、オンポリシー設定とオフポリシー設定の両方で、あらゆるポリシー評価方法とリスク中立制御方法をドロップインして、リスク回避的な制御をすぐに実行できるという点で大きな柔軟性を備えています。 MVPIをインスタンス化する例として、リスク回避型TD3を提案します。これは、リスクを意識したパフォーマンスメトリックの下でMujocoロボットシミュレーションタスクに挑戦する際に、バニラTD3および以前の多くのリスク回避型制御方法よりも優れています。このリスク回避型TD3は、決定論的ポリシーとオフポリシー学習をリスク回避型強化学習に初めて導入したものであり、どちらもMujocoドメインで示すパフォーマンス向上の鍵となります。 MVPIは、一般的に使用される総報酬の観点ではなく、リスク回避的な管理のためにステップごとの報酬の観点（Bisi et al。、2019）を採用しています。,https://d3i71xaburhd42.cloudfront.net/6360732b834687909832ffd128a05ede91367e7e/7-Figure1-1.png
"Submodular Span, with Applications to Conditional Data Summarization","['Lilly Kumari', 'Jeff Bilmes']",,,,
Communication-Aware Collaborative Learning,"['Avrim Blum', 'Shelby L Heinecke', 'Lev Reyzin']",https://arxiv.org/abs/2012.10569,"Algorithms for noiseless collaborative PAC learning have been analyzed and optimized in recent years with respect to sample complexity. In this paper, we study collaborative PAC learning with the goal of reducing communication cost at essentially no penalty to the sample complexity. We develop communication efficient collaborative PAC learning algorithms using distributed boosting. We then consider the communication cost of collaborative learning in the presence of classification noise. As an intermediate step, we show how collaborative PAC learning algorithms can be adapted to handle classification noise. With this insight, we develop communication efficient algorithms for collaborative PAC learning robust to classification noise. Introduction Collaborative learning was recently formalized by Blum et al. (2017) as a PAC learning model. In this collaborative PAC setting, there is a domain X , over which are k distributions, referred to as players. There is also a center node that orchestrates the learning process. The goal of collaborative PAC learning is to learn classifiers from data provided by the players that generalize well on each of players’ distributions simultaneously. Note that this is distinct from the related distributed learning setting, where the goal is to learn classifiers that generalize well on the mixture of players’ distributions (Balcan et al. 2012). There are generally a few styles of collaborative PAC learning. In the personalized learning setting, which is the main focus of our paper, the goal is to learn a classifier for each player with generalization error less than ǫ, with probability 1 − δ. Another setting is the centralized learning setting, where the goal is learn a single classifier with generalization error less than ǫ on each players’ distribution with probability 1 − δ. The efficiency of a collaborative learning algorithm is assessed by its overhead, defined as the ratio of the sample complexity of learning in the collaborative setting to the sample complexity of learning in the single player setting. An overhead of at least k indicates that the collaborative learning algorithm offers no sample complexity benefit over individual PAC learning. An overhead less than k indicates that the collaborative algorithm is more sample efficient than individual PAC learning. Collaborative PAC learning algorithms have been optimized in subsequent works with respect to overhead, and hence sample complexity (Blum et al. 2017; Chen, Zhang, and Zhou 2018; Nguyen and Zakynthinou 2018; Qiao 2018). Certain difficulties may arise in real-world applications of collaborative PAC learning. First, communicating data between players and the center can be costly. Second, the data from players may be noisy. Consider the example described in (Blum et al. 2017) where k players represent hospitals serving different demographics of the population. In this network of hospitals, each of which generates an abundance of data, transmitting data to the center is costly and thus hospitals want to minimize the amount of data transmitted. Additionally, mistakes may be present in the labels of the data at the hospitals, due to clerical errors and misdiagnoses, among other reasons. Given access to only the noisy data from the hospitals, we wish to learn classifiers that generalize well with respect to each hospital’s underlying noiseless distribution. We tackle both difficulties in this paper. First, we develop communication-aware collaborative learning algorithms in the noiseless setting that enjoy reduced communication costs at no penalty to the sample complexity. Then, we develop communication-aware collaborative learning algorithms in the presence of classification noise, where each player has label noise rate ηi < 1 2 . The algorithms and analysis in this work focus on personalized learning. We discuss the applications of our insights and analyses to the centralized learning setting in the Appendix. Omitted proofs are also included in the Appendix. Previous work Algorithms for collaborative PAC learning have been analyzed and optimized in (Blum et al. 2017; Chen, Zhang, and Zhou 2018; Nguyen and Zakynthinou 2018; Qiao 2018) with respect to sample complexity. The collaborative PAC framework was formalized in (Blum et al. 2017), where they also develop an optimal algorithm in the personalized setting with O(ln(k)) overhead and a suboptimal algorithm in the centralized setting with O(ln(k)) overhead. We recall their algorithm, which we refer to as Personalized Learning (Algorithm 1), and the corresponding sample complexity result below. Theorem 1 (Blum et al. 2017). For any ǫ, δ > 0, and hypothesis class H of finite VC-dimension d, the sample comAlgorithm 1: Personalized Learning (Blum et al. 2017) Input: H , k distributions Di ∼ X , δ ′ = δ/2 log(k), ǫ > 0 Output: f1, ..., fk ∈ H Let N1 = {1, ..., k}; for j = 1, ..., ⌈log(k)⌉ do Draw sample S of size mǫ/4,δ′ from mixture DNj = 1 |Nj| ∑ i∈Nj Di; Select consistent hypothesis hj ∈ H on S; Gj ← TEST(hj, Nj, ǫ, δ ′ ); Nj+1 = Nj \Gj ; for i ∈ Gj do fi ← hj ; end end return f1, ..., fk Procedure TEST(h,N, ǫ, δ) for i ∈ N do Draw Ti = O (",ノイズのない協調的PAC学習のアルゴリズムは、サンプルの複雑さに関して近年分析および最適化されています。この論文では、サンプルの複雑さに本質的にペナルティを課すことなく通信コストを削減することを目的として、協調的PAC学習を研究します。分散ブースティングを使用して、通信効率の高い協調PAC学習アルゴリズムを開発します。次に、分類ノイズが存在する場合の共同学習の通信コストを検討します。中間ステップとして、協調PAC学習アルゴリズムを適応させて分類ノイズを処理する方法を示します。この洞察を基に、分類ノイズに対してロバストな協調PAC学習のための通信効率の高いアルゴリズムを開発します。はじめに共同学習は最近、Blumらによって形式化されました。 （2017）PAC学習モデルとして。この協調的なPAC設定には、ドメインXがあり、その上にプレーヤーと呼ばれるk個の分布があります。学習プロセスを調整するセンターノードもあります。協調的PAC学習の目標は、各プレーヤーの分布を同時に一般化するプレーヤーから提供されたデータから分類器を学習することです。これは、関連する分散学習設定とは異なることに注意してください。この設定では、プレーヤーの分布の混合を一般化する分類器を学習することが目標です（Balcan et al.2012）。一般に、PACの共同学習にはいくつかのスタイルがあります。私たちの論文の主な焦点であるパー​​ソナライズされた学習設定では、目標は、確率1で、汎化誤差がo未満の各プレーヤーの分類器を学習することです。もう1つの設定は、集中学習設定です。ここでの目標は、確率1の各プレーヤー分布で汎化誤差がo未満の単一の分類器を学習することです。共同学習アルゴリズムの効率は、そのオーバーヘッドによって評価されます。これは、単一プレーヤー設定での学習のサンプルの複雑さに対する、共同設定での学習のサンプルの複雑さの比率として定義されます。少なくともkのオーバーヘッドは、協調学習アルゴリズムが個々のPAC学習に比べてサンプルの複雑さの利点を提供しないことを示します。 k未満のオーバーヘッドは、協調アルゴリズムが個々のPAC学習よりもサンプル効率が高いことを示します。協調的PAC学習アルゴリズムは、オーバーヘッド、したがってサンプルの複雑さに関して後続の作業で最適化されています（Blum et al.2017; Chen、Zhang、and Zhou 2018; Nguyen and Zakynthinou 2018; Qiao 2018）。共同PAC学習の実際のアプリケーションでは、特定の問題が発生する可能性があります。まず、プレーヤーとセンターの間でデータを通信するにはコストがかかる可能性があります。第二に、プレイヤーからのデータはノイズが多い可能性があります。 （Blum etal。2017）で説明されている例を考えてみましょう。ここでは、k人のプレーヤーが人口のさまざまな人口統計にサービスを提供している病院を表しています。それぞれが豊富なデータを生成するこの病院のネットワークでは、センターへのデータの送信にはコストがかかるため、病院は送信されるデータの量を最小限に抑えたいと考えています。さらに、他の理由の中でもとりわけ、誤記や誤診のために、病院のデータのラベルに誤りが存在する可能性があります。病院からのノイズの多いデータのみにアクセスできることを考えると、ノイズのない分布の基礎となる各病院に関して一般化された分類器を学習したいと思います。このホワイトペーパーでは、両方の問題に取り組んでいます。まず、サンプルの複雑さを損なうことなく通信コストを削減できる、ノイズのない設定での通信対応の共同学習アルゴリズムを開発します。次に、分類ノイズが存在する場合の通信対応の協調学習アルゴリズムを開発します。各プレーヤーのラベルノイズ率はi &lt;12です。この作業のアルゴリズムと分析は、パーソナライズされた学習に焦点を当てています。付録では、一元化された学習設定への洞察と分析の適用について説明します。省略された証明も付録に含まれています。共同PAC学習の以前の作業アルゴリズムは、サンプルの複雑さに関して分析され、最適化されています（Blum et al.2017; Chen、Zhang、and Zhou 2018; Nguyen and Zakynthinou 2018; Qiao 2018）。協調的PACフレームワークは（Blum etal。2017）で形式化され、O（ln（k））オーバーヘッドを使用したパーソナライズされた設定での最適なアルゴリズムとO（ln（k））を使用した集中設定での次善のアルゴリズムも開発しています）オーバーヘッド。パーソナライズされた学習（アルゴリズム1）と呼ばれるそれらのアルゴリズムと、対応するサンプルの複雑さの結果を以下に思い出します。定理1（Blum et al.2017）。任意のo、&gt; 0、および有限VC次元dの仮説クラスHの場合、サンプルcomAlgorithm 1：Personalized Learning（Blum etal。2017）入力：H、k分布Di X、= / 2 log（k）、o &gt; 0出力：f1、...、fk H N1 = 1、...、kとします。 for j = 1、...、log（k）do混合物DNj = 1 | Nj |からサイズmo / 4のサンプルSを描画します。 iNj Di; Sで一貫した仮説hjHを選択します。 Gj TEST（hj、Nj、o、）; Nj + 1 = Nj; for i Gj do fi hj; end end return f1、...、fkプロシージャTEST（h、N、o、）for i N do Draw Ti = O（,https://d3i71xaburhd42.cloudfront.net/178e8d695fd3d72c914f35e52da9164e33d68b49/4-Table1-1.png
Iterative Bounding MDPs: Learning Interpretable Policies via Non-Interpretable Methods,"['Nicholay Topin', 'Stephanie Milani', 'Fei Fang', 'Manuela Veloso']",,,,
Adversarial Linear Contextual Bandits with Graph-Structured Side Observations,"['Lingda Wang', 'Bingcong Li', 'Huozhi Zhou', 'Georgios B. Giannakis', 'Lav Varshney', 'Zhizhen Zhao']",https://arxiv.org/abs/2012.05756,"This paper studies the adversarial graphical contextual bandits, a variant of adversarial multi-armed bandits that leverage two categories of the most common side information: \emph{contexts} and \emph{side observations}. In this setting, a learning agent repeatedly chooses from a set of $K$ actions after being presented with a $d$-dimensional context vector. The agent not only incurs and observes the loss of the chosen action, but also observes the losses of its neighboring actions in the observation structures, which are encoded as a series of feedback graphs. This setting models a variety of applications in social networks, where both contexts and graph-structured side observations are available. Two efficient algorithms are developed based on \texttt{EXP3}. Under mild conditions, our analysis shows that for undirected feedback graphs the first algorithm, \texttt{EXP3-LGC-U}, achieves the regret of order $\mathcal{O}(\sqrt{(K+\alpha(G)d)T\log{K}})$ over the time horizon $T$, where $\alpha(G)$ is the average \emph{independence number} of the feedback graphs. A slightly weaker result is presented for the directed graph setting as well. The second algorithm, \texttt{EXP3-LGC-IX}, is developed for a special class of problems, for which the regret is reduced to $\mathcal{O}(\sqrt{\alpha(G)dT\log{K}\log(KT)})$ for both directed as well as undirected feedback graphs. Numerical tests corroborate the efficiency of proposed algorithms.",このホワイトペーパーでは、最も一般的なサイド情報の2つのカテゴリであるコンテキストとサイドオブザベーションを活用する、敵対的な多腕バンディットの変形である、敵対的なグラフィカルコンテキストバンディットについて説明します。この設定では、学習エージェントは、d次元のコンテキストベクトルが提示された後、K個のアクションのセットから繰り返し選択します。エージェントは、選択されたアクションの損失を被って観察するだけでなく、一連のフィードバックグラフとしてエンコードされている観察構造内の隣接するアクションの損失も観察します。この設定は、コンテキストとグラフ構造の側面観察の両方が利用可能なソーシャルネットワークのさまざまなアプリケーションをモデル化します。 EXP3に基づいて2つの効率的なアルゴリズムが開発されています。穏やかな条件下で、私たちの分析は、無向フィードバックグラフの場合、最初のアルゴリズムEXP3-LGC-Uが$ \ mathcal {O}（\ sqrt {（K + \ alpha（G）d）T \ log {の順序の後悔を達成することを示しています。 K}}）$期間Tにわたって、ここで（G）はフィードバックグラフの平均独立数です。有向グラフの設定でも、わずかに弱い結果が表示されます。 2番目のアルゴリズムEXP3-LGC-IXは、特別なクラスの問題のために開発されており、後悔は$ \ mathcal {O}（\ sqrt {\ alpha（G）dT \ log {K} \ log（ KT）}）$は、有向フィードバックグラフと無向フィードバックグラフの両方に対応します。数値テストは、提案されたアルゴリズムの効率を裏付けます。,https://d3i71xaburhd42.cloudfront.net/2ffbf836e0392fd3d4b6e4842b6d727f187e79bf/9-Figure1-1.png
How Robust are Model Rankings : A Leaderboard Customization Approach for Equitable Evaluation,"['Swaroop Ranjan Mishra', 'Anjana Arunkumar']",,,,
Visual Concept Reasoning Networks,"['Taesup Kim', 'Sungwoong Kim', 'Yoshua Bengio']",https://arxiv.org/abs/2008.11783,"A split-transform-merge strategy has been broadly used as an architectural constraint in convolutional neural networks for visual recognition tasks. It approximates sparsely connected networks by explicitly defining multiple branches to simultaneously learn representations with different visual concepts or properties. Dependencies or interactions between these representations are typically defined by dense and local operations, however, without any adaptiveness or high-level reasoning. In this work, we propose to exploit this strategy and combine it with our Visual Concept Reasoning Networks (VCRNet) to enable reasoning between high-level visual concepts. We associate each branch with a visual concept and derive a compact concept state by selecting a few local descriptors through an attention module. These concept states are then updated by graph-based interaction and used to adaptively modulate the local descriptors. We describe our proposed model by split-transform-attend-interact-modulate-merge stages, which are implemented by opting for a highly modularized architecture. Extensive experiments on visual recognition tasks such as image classification, semantic segmentation, object detection, scene recognition, and action recognition show that our proposed model, VCRNet, consistently improves the performance by increasing the number of parameters by less than 1%.",分割変換マージ戦略は、視覚認識タスクの畳み込みニューラルネットワークのアーキテクチャ上の制約として広く使用されています。複数のブランチを明示的に定義して、異なる視覚的概念またはプロパティを持つ表現を同時に学習することにより、まばらに接続されたネットワークを近似します。これらの表現間の依存関係または相互作用は、通常、密なローカル操作によって定義されますが、適応性や高レベルの推論はありません。この作業では、この戦略を活用し、それをVisual Concept Reasoning Networks（VCRNet）と組み合わせて、高レベルの視覚的概念間の推論を可能にすることを提案します。各ブランチを視覚的な概念に関連付け、アテンションモジュールを介していくつかのローカル記述子を選択することにより、コンパクトな概念の状態を導き出します。これらの概念状態は、グラフベースの相互作用によって更新され、ローカル記述子を適応的に変調するために使用されます。高度にモジュール化されたアーキテクチャを選択することによって実装されるsplit-transform-attend-interact-modulate-mergeステージによって、提案されたモデルについて説明します。画像分類、セマンティックセグメンテーション、オブジェクト検出、シーン認識、アクション認識などの視覚認識タスクに関する広範な実験により、提案されたモデルVCRNetは、パラメータの数を1未満増やすことで、パフォーマンスを一貫して向上させることが示されています。,https://d3i71xaburhd42.cloudfront.net/fab4598dc40ee5840196dd2c85e62f1238f11a48/3-Figure1-1.png
Apparently Irrational Choice as Optimal Sequential Decision Making,"['Haiyang Chen', 'Hyung Jin Chang', 'Andrew Howes']",,,,
Understanding Decoupled and Early Weight Decay,"['Johan Björck', 'Kilian Weinberger', 'Carla P Gomes']",https://arxiv.org/abs/2012.13841,"Weight decay (WD) is a traditional regularization technique in deep learning, but despite its ubiquity, its behavior is still an area of active research. Golatkar et al. have recently shown that WD only matters at the start of the training in computer vision, upending traditional wisdom. Loshchilov et al. show that for adaptive optimizers, manually decaying weights can outperform adding an l2 penalty to the loss. This technique has become increasingly popular and is referred to as decoupled WD. The goal of this paper is to investigate these two recent empirical observations. We demonstrate that by applying WD only at the start, the network norm stays small throughout training. This has a regularizing effect as the effective gradient updates become larger. However, traditional generalizations metrics fail to capture this effect of WD, and we show how a simple scale-invariant metric can. We also show how the growth of network weights is heavily influenced by the dataset and its generalization properties. For decoupled WD, we perform experiments in NLP and RL where adaptive optimizers are the norm. We demonstrate that the primary issue that decoupled WD alleviates is the mixing of gradients from the objective function and the l2 penalty in the buffers of Adam (which stores the estimates of the first-order moment). Adaptivity itself is not problematic and decoupled WD ensures that the gradients from the l2 term cannot ”drown out” the true objective, facilitating easier hyperparameter tuning.",重み減衰（WD）は、深層学習における従来の正則化手法ですが、その遍在性にもかかわらず、その動作は依然として活発な研究の領域です。 Golatkar etal。最近、WDはコンピュータービジョンのトレーニングの開始時にのみ重要であり、従来の知恵を覆すことを示しました。 Loshchilov etal。アダプティブオプティマイザの場合、手動で減衰する重みが、損失にl2ペナルティを追加するよりも優れている可能性があることを示します。この手法はますます普及しており、分離WDと呼ばれています。この論文の目的は、これら2つの最近の経験的観察を調査することです。開始時にのみWDを適用することにより、トレーニング全体を通じてネットワークの基準が小さいままであることを示します。これは、効果的な勾配の更新が大きくなるにつれて、正則化効果があります。ただし、従来の一般化メトリックはWDのこの効果をキャプチャできず、単純なスケール不変メトリックがどのようにできるかを示します。また、ネットワークの重みの増加がデータセットとその一般化プロパティによってどのように大きく影響されるかを示します。分離されたWDの場合、適応オプティマイザーが標準であるNLPとRLで実験を実行します。 WDを分離した主な問題は、目的関数からの勾配の混合と、Adamのバッファー（1次モーメントの推定値を格納する）でのl2ペナルティであることを示します。適応性自体は問題ではなく、分離されたWDにより、l2項からの勾配が真の目的を損なうことがなくなり、ハイパーパラメーターの調整が容易になります。,https://d3i71xaburhd42.cloudfront.net/cdba52cdc8dcadd8964591170d41bdeeef2355c8/2-Figure1-1.png
Adversarial Training and Provable Robustness: A Tale of Two Objectives,"['Jiamneg Fan', 'Wenchao Li']",,,,
Smooth Convex Optimization Using Sub-Zeroth-Order Oracles,"['Mustafa O Karabag', 'Cyrus Neary', 'Ufuk Topcu']",,,,
PID-Based Approach to Adversarial Attacks,"['Chen Wan', 'Biaohua Ye', 'Fangjun Huang']",,,,
Continual General Chunking Problem and SyncMap,"['Danilo Vasconcellos Vargas', 'Toshitake Asabuki']",https://arxiv.org/abs/2006.07853,"Humans possess an inherent ability to chunk sequences into their constituent parts. In fact, this ability is thought to bootstrap language skills to the learning of image patterns which might be a key to a more animal-like type of intelligence. Here, we propose a continual generalization of the chunking problem (an unsupervised problem), encompassing fixed and probabilistic chunks, discovery of temporal and causal structures and their continual variations. Additionally, we propose an algorithm called SyncMap that can learn and adapt to changes in the problem by creating a dynamic map which preserves the correlation between variables. Results of SyncMap suggest that the proposed algorithm learn near optimal solutions, despite the presence of many types of structures and their continual variation. When compared to Word2vec, PARSER and MRIL, SyncMap surpasses or ties with the best algorithm on $77\%$ of the scenarios while being the second best in the remaing $23\%$.",人間は、シーケンスを構成要素にチャンクする固有の能力を持っています。実際、この能力は、より動物のようなタイプの知性の鍵となる可能性のある画像パターンの学習に言語スキルをブートストラップすると考えられています。ここでは、固定および確率的チャンク、時間的および因果構造の発見、およびそれらの継続的な変動を含む、チャンキング問題（教師なし問題）の継続的な一般化を提案します。さらに、変数間の相関関係を保持する動的マップを作成することにより、問題の変化を学習して適応できるSyncMapと呼ばれるアルゴリズムを提案します。 SyncMapの結果は、提案されたアルゴリズムが、多くのタイプの構造とそれらの継続的な変動の存在にもかかわらず、ほぼ最適なソリューションを学習することを示唆しています。 Word2vec、PARSER、MRILと比較すると、SyncMapは、シナリオの77％で最高のアルゴリズムを上回っているか、それと結びついていますが、残りの23％では2番目に優れています。,https://d3i71xaburhd42.cloudfront.net/cab9e33e7c478c811684f633147a60983cc73894/6-Figure1-1.png
Sequential Attacks on Kalman Filter-Based Forward Collision Warning Systems,"['Yuzhe Ma', 'Jon A Sharp', 'Ruizhe Wang', 'Earlence Fernandes', 'Xiaojin Zhu']",https://arxiv.org/abs/2012.08704,"Kalman Filter (KF) is widely used in various domains to perform sequential learning or variable estimation. In the context of autonomous vehicles, KF constitutes the core component of many Advanced Driver Assistance Systems (ADAS), such as Forward Collision Warning (FCW). It tracks the states (distance, velocity etc.) of relevant traffic objects based on sensor measurements. The tracking output of KF is often fed into downstream logic to produce alerts, which will then be used by human drivers to make driving decisions in near-collision scenarios. In this paper, we study adversarial attacks on KF as part of the more complex machine-human hybrid system of Forward Collision Warning. Our attack goal is to negatively affect human braking decisions by causing KF to output incorrect state estimations that lead to false or delayed alerts. We accomplish this by sequentially manipulating measure ments fed into the KF, and propose a novel Model Predictive Control (MPC) approach to compute the optimal manipulation. Via experiments conducted in a simulated driving environment, we show that the attacker is able to successfully change FCW alert signals through planned manipulation over measurements prior to the desired target time. These results demonstrate that our attack can stealthily mislead a distracted human driver and cause vehicle collisions.",カルマンフィルター（KF）は、順次学習または変数推定を実行するために、さまざまなドメインで広く使用されています。自動運転車のコンテキストでは、KFは、前方衝突警告（FCW）などの多くの先進運転支援システム（ADAS）のコアコンポーネントを構成します。センサー測定に基づいて、関連する交通オブジェクトの状態（距離、速度など）を追跡します。 KFの追跡出力は、多くの場合、ダウンストリームロジックに送られ、アラートが生成されます。アラートは、衝突に近いシナリオで運転を決定するために人間のドライバーによって使用されます。この論文では、前方衝突警告のより複雑な機械と人間のハイブリッドシステムの一部として、KFに対する敵対的攻撃を研究します。私たちの攻撃の目標は、KFに誤った状態推定を出力させ、誤ったアラートまたは遅延アラートを発生させることにより、人間のブレーキの決定に悪影響を与えることです。 KFに入力された測定値を順次操作することでこれを実現し、最適な操作を計算するための新しいモデル予測制御（MPC）アプローチを提案します。シミュレートされた運転環境で実施された実験を通じて、攻撃者が目的の目標時間より前に測定を計画的に操作することで、FCWアラート信号を正常に変更できることを示しています。これらの結果は、私たちの攻撃が気を散らされた人間のドライバーを密かに誤解させ、車両の衝突を引き起こす可能性があることを示しています。,https://d3i71xaburhd42.cloudfront.net/92c6ab0a11680f1cf8a4a2b5f2070c2b2486465d/2-Figure1-1.png
Inductive Graph Neural Networks for Spatiotemporal Kriging,"['Yuankai Wu', 'Dingyi Zhuang', 'Aurelie Labbe', 'Lijun Sun']",https://arxiv.org/abs/2006.07527,"Time series forecasting and spatiotemporal kriging are the two most important tasks in spatiotemporal data analysis. Recent research on graph neural networks has made substantial progress in time series forecasting, while little attention is paid to the kriging problem---recovering signals for unsampled locations/sensors. Most existing scalable kriging methods (e.g., matrix/tensor completion) are transductive, and thus full retraining is required when we have a new sensor to interpolate. In this paper, we develop an Inductive Graph Neural Network Kriging (IGNNK) model to recover data for unsampled sensors on a network/graph structure. To generalize the effect of distance and reachability, we generate random subgraphs as samples and reconstruct the corresponding adjacency matrix for each sample. By reconstructing all signals on each sample subgraph, IGNNK can effectively learn the spatial message passing mechanism. Empirical results on several real-world spatiotemporal datasets demonstrate the effectiveness of our model. In addition, we also find that the learned model can be successfully transferred to the same type of kriging tasks on an unseen dataset. Our results show that: 1) GNN is an efficient and effective tool for spatial kriging; 2) inductive GNNs can be trained using dynamic adjacency matrices; and 3) a trained model can be transferred to new graph structures.",時系列予測と時空間クリギングは、時空間データ分析で最も重要な2つのタスクです。グラフニューラルネットワークに関する最近の研究は、時系列予測において実質的な進歩を遂げましたが、サンプリングされていない場所/センサーの信号を回復するクリギングの問題にはほとんど注意が払われていません。ほとんどの既存のスケーラブルなクリギング方法（マトリックス/テンソル補完など）はトランスダクティブであるため、補間する新しいセンサーがある場合は完全な再トレーニングが必要です。この論文では、ネットワーク/グラフ構造上の非サンプリングセンサーのデータを回復するための誘導グラフニューラルネットワーククリギング（IGNNK）モデルを開発します。距離と到達可能性の影響を一般化するために、サンプルとしてランダムなサブグラフを生成し、各サンプルに対応する隣接行列を再構築します。各サンプルサブグラフのすべての信号を再構築することにより、IGNNKは空間メッセージパッシングメカニズムを効果的に学習できます。いくつかの実世界の時空間データセットでの経験的結果は、モデルの有効性を示しています。さらに、学習したモデルを、見えないデータセットの同じタイプのクリギングタスクに正常に転送できることもわかりました。私たちの結果は次のことを示しています。1）GNNは空間クリギングのための効率的で効果的なツールです。 2）帰納的GNNは、動的隣接行列を使用してトレーニングできます。 3）トレーニングされたモデルを新しいグラフ構造に転送できます。,https://d3i71xaburhd42.cloudfront.net/3bb50191b712e9dbfc4dbe7a6fa45b0a321caf3e/2-Figure1-1.png
Temporal-Logic-Based Reward Shaping for Continuing Reinforcement Learning Tasks,"['Yuqian Jiang', 'Sudarshanan Bharadwaj', 'Bo Wu', 'Rishi Shah', 'Ufuk Topcu', 'Peter Stone']",,"In continuing tasks, average-reward reinforcement learning may be a more appropriate problem formulation than the more common discounted reward formulation. As usual, learning an optimal policy in this setting typically requires a large amount of training experiences. Reward shaping is a common approach for incorporating domain knowledge into reinforcement learning in order to speed up convergence to an optimal policy. However, to the best of our knowledge, the theoretical properties of reward shaping have thus far only been established in the discounted setting. This paper presents the first reward shaping framework for averagereward learning and proves that, under standard assumptions, the optimal policy under the original reward function can be recovered. In order to avoid the need for manual construction of the shaping function, we introduce a method for utilizing domain knowledge expressed as a temporal logic formula. The formula is automatically translated to a shaping function that provides additional reward throughout the learning process. We evaluate the proposed method on three continuing tasks. In all cases, shaping speeds up the average-reward learning rate without any reduction in the performance of the learned policy compared to relevant baselines.",継続的なタスクでは、平均報酬強化学習は、より一般的な割引報酬の定式化よりも適切な問題の定式化である可能性があります。いつものように、この設定で最適なポリシーを学習するには、通常、大量のトレーニング経験が必要です。報酬の形成は、最適なポリシーへの収束を加速するために、ドメイン知識を強化学習に組み込むための一般的なアプローチです。しかし、私たちの知る限りでは、報酬形成の理論的特性は、これまでのところ、割引された設定でのみ確立されています。この論文は、平均的な報酬学習のための最初の報酬形成フレームワークを提示し、標準的な仮定の下で、元の報酬関数の下での最適なポリシーを回復できることを証明します。シェーピング関数を手動で作成する必要がないように、時相論理式で表現されたドメイン知識を活用する方法を紹介します。数式は、学習プロセス全体で追加の報酬を提供するシェーピング関数に自動的に変換されます。提案された方法を3つの継続的なタスクで評価します。すべての場合において、シェーピングは、関連するベースラインと比較して、学習されたポリシーのパフォーマンスを低下させることなく、平均報酬学習率をスピードアップします。,https://d3i71xaburhd42.cloudfront.net/691c36c2ca85b6b7e412b79ade52c9a58d988018/4-Figure1-1.png
Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork,"['Gagan Bansal', 'Besmira Nushi', 'Ece Kamar', 'Eric Horvitz', 'Daniel Weld']",,"AI practitioners typically strive to develop the most accurate systems, making an implicit assumption that the AI system will function autonomously. However, in practice, AI systems often are used to provide advice to people in domains ranging from criminal justice and finance to healthcare. In such AIadvised decision making, humans and machines form a team, where the human is responsible for making final decisions. But is the most accurate AI the best teammate? We argue “No” — predictable performance may be worth a slight sacrifice in AI accuracy. Instead, we argue that AI systems should be trained in a human-centered manner, directly optimized for team performance. We study this proposal for a specific type of human-AI teaming, where the human overseer chooses to either accept the AI recommendation or solve the task themselves. To optimize the team performance for this setting we maximize the team’s expected utility, expressed in terms of the quality of the final decision, cost of verifying, and individual accuracies of people and machines. Our experiments with linear and non-linear models on real-world, high-stakes datasets show that the most accuracy AI may not lead to highest team performance and show the benefit of modeling teamwork during training through improvements in expected team utility across datasets, considering parameters such as human skill and the cost of mistakes. We discuss the shortcoming of current optimization approaches beyond well-studied loss functions such as log-loss, and encourage future work on AI optimization problems motivated by human-AI collaboration.",AIの実践者は通常、AIシステムが自律的に機能することを暗黙のうちに想定して、最も正確なシステムの開発に努めています。ただし、実際には、AIシステムは、刑事司法や金融から医療に至るまでの分野の人々にアドバイスを提供するためによく使用されます。このようなAIのアドバイスによる意思決定では、人間と機械がチームを形成し、人間が最終的な意思決定を行う責任があります。しかし、最も正確なAIは最高のチームメイトですか？ AIの精度を少し犠牲にするだけの価値のある予測可能なパフォーマンスはないと私たちは主張します。代わりに、AIシステムは人間中心の方法でトレーニングし、チームのパフォーマンスに直接最適化する必要があると主張します。人間の監督者がAIの推奨事項を受け入れるか、タスクを自分で解決するかを選択する、特定のタイプの人間とAIのチーム化についてこの提案を検討します。この設定でチームのパフォーマンスを最適化するために、最終決定の品質、検証のコスト、および人とマシンの個々の精度の観点から表される、チームの期待効用を最大化します。実世界のハイステークスデータセットで線形モデルと非線形モデルを使用した実験では、AIの精度が最も高いとチームのパフォーマンスが最高にならない可能性があり、データセット全体で期待されるチームユーティリティの改善を通じて、トレーニング中にチームワークをモデル化する利点が示されます。人間のスキルやミスのコストなどのパラメータ。ログ損失などの十分に研究された損失関数を超えた現在の最適化アプローチの欠点について説明し、人間とAIのコラボレーションによって動機付けられたAI最適化問題に関する将来の作業を奨励します。,https://d3i71xaburhd42.cloudfront.net/198838f8b7b504c04214fffb8646d11c6152ba5e/1-Figure1-1.png
Stochastic Bandits with Graph Feedback in Non-Stationary Environments,"['Shiyin Lu', 'Yao Hu', 'Lijun Zhang']",,,,
Learning Graphons via Structured Gromov-Wasserstein Barycenters,"['Hongteng Xu', 'Dixin Luo', 'Hongyuan Zha', 'Lawrence Carin Duke']",https://arxiv.org/abs/2012.05644,"We propose a novel and principled method to learn a nonparametric graph model called graphon, which is defined in an infinite-dimensional space and represents arbitrary-size graphs. Based on the weak regularity lemma from the theory of graphons, we leverage a step function to approximate a graphon. We show that the cut distance of graphons can be relaxed to the Gromov-Wasserstein distance of their step functions. Accordingly, given a set of graphs generated by an underlying graphon, we learn the corresponding step function as the Gromov-Wasserstein barycenter of the given graphs. Furthermore, we develop several enhancements and extensions of the basic algorithm, $e.g.$, the smoothed Gromov-Wasserstein barycenter for guaranteeing the continuity of the learned graphons and the mixed Gromov-Wasserstein barycenters for learning multiple structured graphons. The proposed approach overcomes drawbacks of prior state-of-the-art methods, and outperforms them on both synthetic and real-world data. The code is available at this https URL.",無限次元空間で定義され、任意のサイズのグラフを表す、graphonと呼ばれるノンパラメトリックグラフモデルを学習するための新しい原理的な方法を提案します。グラフォンの理論からの弱い規則性の補題に基づいて、ステップ関数を利用してグラフォンを近似します。グラフォンのカット距離は、ステップ関数のGromov-Wasserstein距離に緩和できることを示します。したがって、基礎となるグラフォンによって生成された一連のグラフが与えられると、与えられたグラフのGromov-Wasserstein重心として対応するステップ関数を学習します。さらに、基本アルゴリズムのいくつかの拡張機能と拡張機能を開発します。たとえば、学習したグラフォンの連続性を保証するための平滑化されたGromov-Wasserstein重心や、複数の構造化グラフォンを学習するための混合Gromov-Wasserstein重心などです。提案されたアプローチは、以前の最先端の方法の欠点を克服し、合成データと実世界のデータの両方でそれらを上回ります。コードはこのhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/29d52d1457677a259977113579a3d39b5345bd6d/2-Figure1-1.png
Low-Rank Registration Based Manifolds for Convection-Dominated PDEs,"['Rambod Mojgani', 'Maciej Balajewicz']",,,,
Learning Graph Neural Networks with Approximate Gradient Descent,"['Qunwei Li', 'Shaofeng Zou', 'Wenliang Zhong']",,,,
Probabilistic Dependency Graphs,"['Oliver E Richardson', 'Joseph Y Halpern']",,,,
Stratified Rule-Aware Network for Abstract Visual Reasoning,"['Sheng Hu', 'Yuqing Ma', 'Xianglong Liu', 'Yanlu Wei', 'Shihao Bai']",,,,
HyDRA: Hypergradient Data Relevance Analysis for Interpreting Deep Neural Networks,"['Yuanyuan Chen', 'Boyang Li', 'Han Yu', 'Pengcheng Wu', 'Chunyan Miao']",,,,
AttnMove: History Enhanced Trajectory Recovery via Attentional Network,"['Tong Xia', 'Jie Feng', 'Yunhan Qi', 'Fengli Xu', 'Yong Li', 'Diansheng Guo', 'Funing Sun']",https://arxiv.org/abs/2101.00646,"A considerable amount of mobility data has been accumulated due to the proliferation of location-based service. Nevertheless, compared with mobility data from transportation systems like the GPS module in taxis, this kind of data is commonly sparse in terms of individual trajectories in the sense that users do not access mobile services and contribute their data all the time. Consequently, the sparsity inevitably weakens the practical value of the data even it has a high user penetration rate. To solve this problem, we propose a novel attentional neural network-based model, named AttnMove, to densify individual trajectories by recovering unobserved locations at a fine-grained spatial-temporal resolution. To tackle the challenges posed by sparsity, we design various intraand intertrajectory attention mechanisms to better model the mobility regularity of users and fully exploit the periodical pattern from long-term history. We evaluate our model on two real-world datasets, and extensive results demonstrate the performance gain compared with the state-of-the-art methods. This also shows that, by providing high-quality mobility data, our model can benefit a variety of mobility-oriented down-stream applications.",位置情報サービスの急増により、かなりの量のモビリティデータが蓄積されています。それにもかかわらず、タクシーのGPSモジュールのような輸送システムからのモビリティデータと比較すると、この種のデータは、ユーザーがモバイルサービスにアクセスしてデータを常に提供するわけではないという意味で、個々の軌道に​​関して一般的にまばらです。その結果、スパース性は、ユーザーの浸透率が高い場合でも、必然的にデータの実用的な価値を弱めます。この問題を解決するために、AttnMoveという名前の新しい注意ニューラルネットワークベースのモデルを提案し、観測されていない場所をきめ細かい時空間分解能で復元することにより、個々の軌道を高密度化します。スパース性によってもたらされる課題に取り組むために、ユーザーのモビリティの規則性をより適切にモデル化し、長期的な歴史からの定期的なパターンを十分に活用するために、さまざまな軌道内および軌道間の注意メカニズムを設計します。 2つの実際のデータセットでモデルを評価し、広範な結果により、最先端の方法と比較してパフォーマンスが向上していることが示されています。これは、高品質のモビリティデータを提供することで、私たちのモデルがさまざまなモビリティ指向のダウンストリームアプリケーションに役立つことも示しています。,https://d3i71xaburhd42.cloudfront.net/e5c303d73b7ce89f880fecb1dc6943a2359385a0/2-Figure1-1.png
Interpretable Graph Capsule Networks for Object Recognition,['Jindong Gu'],https://arxiv.org/abs/2012.01674,"Capsule Networks, as alternatives to Convolutional Neural Networks, have been proposed to recognize objects from images. The current literature demonstrates many advantages of CapsNets over CNNs. However, how to create explanations for individual classifications of CapsNets has not been well explored. The widely used saliency methods are mainly proposed for explaining CNN-based classifications; they create saliency map explanations by combining activation values and the corresponding gradients, e.g., Grad-CAM. These saliency methods require a specific architecture of the underlying classifiers and cannot be trivially applied to CapsNets due to the iterative routing mechanism therein. To overcome the lack of interpretability, we can either propose new post-hoc interpretation methods for CapsNets or modifying the model to have build-in explanations. In this work, we explore the latter. Specifically, we propose interpretable Graph Capsule Networks (GraCapsNets), where we replace the routing part with a multi-head attention-based Graph Pooling approach. In the proposed model, individual classification explanations can be created effectively and efficiently. Our model also demonstrates some unexpected benefits, even though it replaces the fundamental part of CapsNets. Our GraCapsNets achieve better classification performance with fewer parameters and better adversarial robustness, when compared to CapsNets. Besides, GraCapsNets also keep other advantages of CapsNets, namely, disentangled representations and affine transformation robustness.",畳み込みニューラルネットワークの代替として、画像からオブジェクトを認識するカプセルネットワークが提案されています。現在の文献は、CNNに対するCapsNetの多くの利点を示しています。ただし、CapsNetsの個々の分類の説明を作成する方法は十分に検討されていません。広く使用されている顕著性の方法は、主にCNNベースの分類を説明するために提案されています。それらは、アクティベーション値と対応する勾配を組み合わせることにより、顕著性マップの説明を作成します（例：Grad-CAM）。これらの顕著性メソッドは、基礎となる分類子の特定のアーキテクチャを必要とし、その中の反復ルーティングメカニズムのためにCapsNetsに簡単に適用することはできません。解釈可能性の欠如を克服するために、CapsNetsの新しい事後解釈方法を提案するか、モデルを変更して説明を組み込むことができます。この作品では、後者を探求します。具体的には、解釈可能なグラフカプセルネットワーク（GraCapsNets）を提案します。ここでは、ルーティング部分をマルチヘッドアテンションベースのグラフプーリングアプローチに置き換えます。提案されたモデルでは、個々の分類の説明を効果的かつ効率的に作成できます。私たちのモデルは、CapsNetsの基本的な部分を置き換えたとしても、いくつかの予期しない利点も示しています。当社のGraCapsNetは、CapsNetと比較して、より少ないパラメータとより優れた敵対的ロバスト性でより優れた分類パフォーマンスを実現します。さらに、GraCapsNetsは、CapsNetsの他の利点、つまり、解きほぐされた表現とアフィン変換の堅牢性も保持します。,https://d3i71xaburhd42.cloudfront.net/e01683ec4bb2831abf4d3b1138a4eea248cdfd4b/3-Figure1-1.png
Empowering Adaptive Early-Exit Inference with Latency Awareness,"['Xinrui Tan', 'Hongjia Li', 'Liming Wang', 'Xueqing Huang', 'Zhen Xu']",,,,
Embracing Domain Differences in Fake News: Cross-Domain Fake News Detection Using Multi-Modal Data,"['Amila Ruwansiri Silva', 'Ling Luo', 'Shanika Karunasekera', 'Christopher Leckie']",,,,
Improving Robustness to Model Inversion Attacks via Mutual Information Regularization,"['Tianhao Wang', 'Yuheng Zhang', 'Ruoxi Jia']",https://arxiv.org/abs/2009.05241,"This paper studies defense mechanisms against model inversion (MI) attacks -- a type of privacy attacks aimed at inferring information about the training data distribution given the access to a target machine learning model. Existing defense mechanisms rely on model-specific heuristics or noise injection. While being able to mitigate attacks, existing methods significantly hinder model performance. There remains a question of how to design a defense mechanism that is applicable to a variety of models and achieves better utility-privacy tradeoff. In this paper, we propose the Mutual Information Regularization based Defense (MID) against MI attacks. The key idea is to limit the information about the model input contained in the prediction, thereby limiting the ability of an adversary to infer the private training attributes from the model prediction. Our defense principle is model-agnostic and we present tractable approximations to the regularizer for linear regression, decision trees, and neural networks, which have been successfully attacked by prior work if not attached with any defenses. We present a formal study of MI attacks by devising a rigorous game-based definition and quantifying the associated information leakage. Our theoretical analysis sheds light on the inefficacy of DP in defending against MI attacks, which has been empirically observed in several prior works. Our experiments demonstrate that MID leads to state-of-the-art performance for a variety of MI attacks, target models and datasets.",このホワイトペーパーでは、モデル反転（MI）攻撃に対する防御メカニズムを研究し、ターゲットの機械学習モデルへのアクセスを前提として、トレーニングデータの配布に関する情報を推測することを目的としたプライバシー攻撃の一種です。既存の防御メカニズムは、モデル固有のヒューリスティックまたはノイズ注入に依存しています。攻撃を軽減することはできますが、既存の方法はモデルのパフォーマンスを大幅に妨げます。さまざまなモデルに適用可能で、ユーティリティとプライバシーのトレードオフを向上させる防御メカニズムをどのように設計するかという問題が残っています。この論文では、MI攻撃に対する相互情報量正則化ベースの防御（MID）を提案します。重要なアイデアは、予測に含まれるモデル入力に関する情報を制限し、それによって、モデル予測からプライベートトレーニング属性を推測する敵の能力を制限することです。私たちの防御原理はモデルにとらわれず、線形回帰、決定木、ニューラルネットワークの正則化の扱いやすい近似を提示します。これらは、防御がない場合は以前の作業によって正常に攻撃されています。厳密なゲームベースの定義を考案し、関連する情報漏えいを定量化することにより、MI攻撃の正式な研究を提示します。私たちの理論的分析は、MI攻撃に対する防御におけるDPの非効率性に光を当てます。これは、以前のいくつかの研究で経験的に観察されています。私たちの実験は、MIDがさまざまなMI攻撃、ターゲットモデル、およびデータセットに対して最先端のパフォーマンスをもたらすことを示しています。,https://d3i71xaburhd42.cloudfront.net/7b26823c1acbc10fadd53c3b71da55a95c8ae576/3-Figure1-1.png
Keyword-Guided Neural Conversational Model,"['Peixiang Zhong', 'Yong Liu', 'Hao Wang', 'Chunyan Miao']",https://arxiv.org/abs/2012.08383,"We study the problem of imposing conversational goals/keywords on open-domain conversational agents, where the agent is required to lead the conversation to a target keyword smoothly and fast. Solving this problem enables the application of conversational agents in many real-world scenarios, e.g., recommendation and psychotherapy. The dominant paradigm for tackling this problem is to 1) train a next-turn keyword classifier, and 2) train a keyword-augmented response retrieval model. However, existing approaches in this paradigm have two limitations: 1) the training and evaluation datasets for next-turn keyword classification are directly extracted from conversations without human annotations, thus, they are noisy and have low correlation with human judgements, and 2) during keyword transition, the agents solely rely on the similarities between word embeddings to move closer to the target keyword, which may not reflect how humans converse. In this paper, we assume that human conversations are grounded on commonsense and propose a keyword-guided neural conversational model that can leverage external commonsense knowledge graphs (CKG) for both keyword transition and response retrieval. Automatic evaluations suggest that commonsense improves the performance of both next-turn keyword prediction and keyword-augmented response retrieval. In addition, both self-play and human evaluations show that our model produces responses with smoother keyword transition and reaches the target keyword faster than competitive baselines.",オープンドメインの会話エージェントに会話の目標/キーワードを課す問題を研究します。エージェントは、会話をターゲットキーワードにスムーズかつ迅速に導く必要があります。この問題を解決することで、推奨や心理療法など、多くの現実のシナリオで会話エージェントを適用できるようになります。この問題に取り組むための主要なパラダイムは、1）次のターンのキーワード分類子をトレーニングし、2）キーワード拡張応答検索モデルをトレーニングすることです。ただし、このパラダイムの既存のアプローチには2つの制限があります。1）次のターンのキーワード分類のトレーニングおよび評価データセットは、人間の注釈なしで会話から直接抽出されるため、ノイズが多く、人間の判断との相関が低くなります。キーワード遷移では、エージェントは単語の埋め込み間の類似性のみに依存して、ターゲットキーワードに近づきます。これは、人間の会話方法を反映していない可能性があります。この論文では、人間の会話が常識に基づいていると仮定し、キーワード遷移と応答検索の両方に外部の常識知識グラフ（CKG）を活用できるキーワード誘導ニューラル会話モデルを提案します。自動評価は、常識が次のターンのキーワード予測とキーワード拡張応答検索の両方のパフォーマンスを向上させることを示唆しています。さらに、セルフプレイと人間による評価の両方で、モデルがよりスムーズなキーワード遷移で応答を生成し、競合するベースラインよりも早くターゲットキーワードに到達することが示されています。,https://d3i71xaburhd42.cloudfront.net/e0871627fd99ab0344d79c9f992e140d188e4601/1-Figure1-1.png
CARE: Commonsense-Aware Emotional Response Generation with Latent Concepts,"['Peixiang Zhong', 'Di Wang', 'Pengfei Li', 'Chen Zhang', 'Hao Wang', 'Chunyan Miao']",,,,
Online 3D Bin Packing with Constrained Deep Reinforcement Learning,"['Hang Zhao', 'Qijin She', 'Chenyang Zhu', 'Yin Yang', 'Kai Xu']",,,,
Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs,"['Wen-Yi Hsiao', 'Jen-Yu Liu', 'Yin-Cheng Yeh', 'Yi-Hsuan Yang']",,,,
Adaptive Beam Search Decoding for Discrete Keyphrase Generation,"['Xiaoli Huang', 'Tongge Xu', 'Lvan Jiao', 'Yueran Zu', 'Youmin Zhang']",,,,
Learned Extragradient ISTA with Interpretable Residual Structures for Sparse Coding,"['Yangyang Li', 'Lin Kong', 'Fanhua Shang', 'Yuanyuan Liu', 'Hongying Liu', 'Zhouchen Lin']",,,,
Attribute-Guided Adversarial Training for Robustness to Natural Perturbations,"['Tejas Gokhale', 'Rushil Anirudh', 'Bhavya Kailkhura', 'Jayaraman J. Thiagarajan', 'Chitta Baral', 'Yezhou Yang']",,,,
Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction,"['Benfeng Xu', 'Quan Wang', 'Yajuan Lyu', 'Yong Zhu', 'Zhendong Mao']",,,,
Minimizing Labeling Cost for Nuclei Instance Segmentation and Classificationwith Cross-Domain Images and Weak Labels,"['Siqi Yang', 'Jun Zhang', 'Junzhou Huang', 'Brian C Lovell', 'Xiao Han']",,,,
Bag of Tricks for Long-Tailed Visual Recognition with Deep Convolutional Neural Networks,"['Yongshun Zhang', 'Xiu-Shen Wei', 'Boyan Zhou', 'Jianxin Wu']",,,,
DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic Dialogues,"['Qi Jia', 'Hongru Huang', 'Kenny Zhu']",,,,
Hindsight and Sequential Rationality of Correlated Play,"['Dustin Morrill', ""Ryan D'Orazio"", 'Reca Sarfati', 'Marc Lanctot', 'James R Wright', 'Amy R Greenwald', 'Michael Bowling']",,,,
DeHiB: Deep Hidden Backdoor Attack on Semi-Supervised Learning via Adversarial Perturbation,"['Zhicong Yan', 'Gaolei Li', 'Yuan Tian', 'Jun Wu', 'Shenghong Li', 'Mingzhe Chen', 'H. Vincent Poor']",,,,
Single Player Monte-Carlo Tree Search Based on the Plackett-Luce Model,"['Felix Mohr', 'Viktor Bengs', 'Eyke Hüllermeier']",,,,
Flexible Non-Autoregressive Extractive Summarization with Threshold: How to Extract a Non-Fixed Number of Summary Sentences,"['Ruipeng Jia', 'Yanan Cao', 'Haichao Shi', 'Fang Fang', 'Pengfei Yin', 'Shi Wang']",,,,
Universal Adversarial Perturbations through the Lens of Deep Steganography: Towards a Fourier Perspective,"['Chaoning Zhang', 'Philipp Benz', 'Adil Karjauv', 'In So Kweon']",,,,
Adversarial Meta Sampling for Multilingual Low-Resource Speech Recognition,"['Yubei Xiao', 'Ke Gong', 'Pan Zhou', 'Guolin Zheng', 'Xiaodan Liang', 'Liang Lin']",https://arxiv.org/abs/2012.11896,"Low-resource automatic speech recognition (ASR) is challenging, as the low-resource target language data cannot well train an ASR model. To solve this issue, meta-learning formulates ASR for each source language into many small ASR tasks and meta-learns a model initialization on all tasks from different source languages to access fast adaptation on unseen target languages. However, for different source languages, the quantity and difficulty vary greatly because of their different data scales and diverse phonological systems, which leads to task-quantity and task-difficulty imbalance issues and thus a failure of multilingual meta-learning ASR (MML-ASR). In this work, we solve this problem by developing a novel adversarial meta sampling (AMS) approach to improve MML-ASR. When sampling tasks in MML-ASR, AMS adaptively determines the task sampling probability for each source language. Specifically, for each source language, if the query loss is large, it means that its tasks are not well sampled to train ASR model in terms of its quantity and difficulty and thus should be sampled more frequently for extra learning. Inspired by this fact, we feed the historical task query loss of all source language domain into a network to learn a task sampling policy for adversarially increasing the current query loss of MMLASR. Thus, the learnt task sampling policy can master the learning situation of each language and thus predicts good task sampling probability for each language for more effective learning. Finally, experiment results on two multilingual datasets show significant performance improvement when applying our AMS on MML-ASR, and also demonstrate the applicability of AMS to other low-resource speech tasks and transfer learning ASR approaches. Our codes are available at: https://github.com/iamxiaoyubei/AMS.",低リソースのターゲット言語データではASRモデルを適切にトレーニングできないため、低リソースの自動音声認識（ASR）は困難です。この問題を解決するために、メタ学習は各ソース言語のASRを多くの小さなASRタスクに定式化し、さまざまなソース言語からのすべてのタスクのモデル初期化をメタ学習して、見えないターゲット言語の高速適応にアクセスします。ただし、ソース言語が異なれば、データスケールや音韻システムが異なるため、量と難易度が大きく異なり、タスクの量と難易度の不均衡の問題が発生し、多言語メタ学習ASR（MML-ASR）が失敗します。 ）。この作業では、MML-ASRを改善するための新しい敵対的メタサンプリング（AMS）アプローチを開発することにより、この問題を解決します。 MML-ASRでタスクをサンプリングする場合、AMSは各ソース言語のタスクサンプリング確率を適応的に決定します。具体的には、ソース言語ごとに、クエリの損失が大きい場合、そのタスクは、量と難易度の観点からASRモデルをトレーニングするために十分にサンプリングされていないため、追加の学習のためにより頻繁にサンプリングする必要があります。この事実に触発されて、すべてのソース言語ドメインの過去のタスククエリ損失をネットワークにフィードして、MMLASRの現在のクエリ損失を逆に増加させるためのタスクサンプリングポリシーを学習します。したがって、学習されたタスクサンプリングポリシーは、各言語の学習状況をマスターできるため、より効果的な学習のために、各言語の適切なタスクサンプリング確率を予測できます。最後に、2つの多言語データセットでの実験結果は、MML-ASRにAMSを適用するとパフォーマンスが大幅に向上することを示し、他の低リソース音声タスクおよび転移学習ASRアプローチへのAMSの適用性も示しています。コードはhttps://github.com/iamxiaoyubei/AMSで入手できます。,https://d3i71xaburhd42.cloudfront.net/535f1684de5ce59ce2be17e876e55ce9e7692ad9/2-Figure1-1.png
Traffic Shaping in E-Commercial Search Engine: Multi-Objective Online Welfare Maximization,"['Liucheng Sun', 'Chenwei Weng', 'Chengfu Huo', 'Weijun Ren', 'Guochuan Zhang', 'Xin Li']",,,,
Physics-Constrained Automatic Feature Engineering for Predictive Modeling in Materials Science,"['Ziyu Xiang', 'Mingzhou Fan', 'Guillermo Vazquez', 'William Trehern', 'Byung-Jun Yoon', 'Xiaofeng Qian', 'Raymundo Arroyave', 'Xiaoning Qian']",,,,
On Estimating Recommendation Evaluation Metrics under Sampling,"['Ruoming Jin', 'Dong Li', 'Benjamin Mudrak', 'Jing Gao', 'Zhi Liu']",,,,
Robust Fairness under Covariate Shift,"['Ashkan Rezaei', 'Anqi Liu', 'Omid Memarrast', 'Brian Ziebart']",https://arxiv.org/abs/2010.05166,"Making predictions that are fair with regard to protected group membership (race, gender, age, etc.) has become an important requirement for classification algorithms. Existing techniques derive a fair model from sampled labeled data relying on the assumption that training and testing data are identically and independently drawn (iid) from the same this http URL practice, distribution shift can and does occur between training and testing datasets as the characteristics of individuals interacting with the machine learning system -- and which individuals interact with the system -- change. We investigate fairness under covariate shift, a relaxation of the iid assumption in which the inputs or covariates change while the conditional label distribution remains the same. We seek fair decisions under these assumptions on target data with unknown labels.We propose an approach that obtains the predictor that is robust to the worst-case in terms of target performance while satisfying target fairness requirements and matching statistical properties of the source data. We demonstrate the benefits of our approach on benchmark prediction tasks.",保護されたグループメンバーシップ（人種、性別、年齢など）に関して公正な予測を行うことは、分類アルゴリズムの重要な要件になっています。既存の手法は、トレーニングとテストのデータが同じhttp URLプラクティスから同一かつ独立して抽出される（iid）という仮定に基づいて、サンプリングされたラベル付きデータから公正なモデルを導き出します。分布のシフトは、トレーニングとテストのデータセット間で発生する可能性があります。機械学習システムと対話する個人と、システムと対話する個人の変更。共変量シフト、つまり条件付きラベル分布が同じままで入力または共変量が変化するiid仮定の緩和の下での公平性を調査します。ラベルが不明なターゲットデータについて、これらの仮定の下で公正な決定を求めます。ターゲットの公平性要件を満たし、ソースデータの統計的特性を一致させながら、ターゲットのパフォーマンスに関して最悪の場合にロバストな予測子を取得するアプローチを提案します。ベンチマーク予測タスクに対するアプローチの利点を示します。,https://d3i71xaburhd42.cloudfront.net/f7ccb707c194fb0dfe9f38a18e2d8e457ae0aa78/2-Figure1-1.png
Boosting Multi-task Learning through Combination of Task Labels - with Applications in ECG Phenotyping,"['Ming-En Hsieh', 'Vincent Tseng']",,,,
Estimating Identifiable Causal Effects through Double Machine Learning,"['Yonghan Jung', 'Jin Tian', 'Elias Bareinboim']",,,,
Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning,"['Syed Zawad', 'Ahsan Ali', 'Pin-Yu Chen', 'Ali Anwar', 'Yi Zhou', 'Nathalie Baracaldo', 'Yuan Tian', 'Feng Yan']",https://arxiv.org/abs/2102.00655,"Data heterogeneity has been identified as one of the key features in federated learning but often overlooked in the lens of robustness to adversarial attacks. This paper focuses on characterizing and understanding its impact on backdooring attacks in federated learning through comprehensive experiments using synthetic and the LEAF benchmarks. The initial impression driven by our experimental results suggests that data heterogeneity is the dominant factor in the effectiveness of attacks and it may be a redemption for defending against backdooring as it makes the attack less efficient, more challenging to design effective attack strategies, and the attack result also becomes less predictable. However, with further investigations, we found data heterogeneity is more of a curse than a redemption as the attack effectiveness can be significantly boosted by simply adjusting the client-side backdooring timing. More importantly,data heterogeneity may result in overfitting at the local training of benign clients, which can be utilized by attackers to disguise themselves and fool skewed-feature based defenses. In addition, effective attack strategies can be made by adjusting attack data distribution. Finally, we discuss the potential directions of defending the curses brought by data heterogeneity. The results and lessons learned from our extensive experiments and analysis offer new insights for designing robust federated learning methods",データの不均一性は、連合学習の重要な機能の1つとして識別されていますが、敵対的な攻撃に対する堅牢性という観点から見過ごされがちです。このホワイトペーパーでは、合成ベンチマークとLEAFベンチマークを使用した包括的な実験を通じて、フェデレーション学習におけるバックドア攻撃への影響を特徴づけて理解することに焦点を当てています。私たちの実験結果に基づく最初の印象は、データの不均一性が攻撃の有効性の支配的な要因であり、攻撃の効率を低下させ、効果的な攻撃戦略の設計をより困難にするため、バックドアからの防御の贖いになる可能性があることを示唆しています。結果も予測できなくなります。ただし、さらに調査したところ、クライアント側のバックドアのタイミングを調整するだけで攻撃の効果を大幅に高めることができるため、データの不均一性は償還よりも呪いであることがわかりました。さらに重要なことに、データの不均一性により、良性のクライアントのローカルトレーニングで過剰適合が発生する可能性があります。これは、攻撃者が自分自身を偽装し、機能に基づく防御をだますために利用できます。さらに、攻撃データの分布を調整することで、効果的な攻撃戦略を立てることができます。最後に、データの不均一性によってもたらされる呪いを防御するための潜在的な方向性について説明します。広範な実験と分析から学んだ結果と教訓は、堅牢な統合学習方法を設計するための新しい洞察を提供します,https://d3i71xaburhd42.cloudfront.net/60153b7dddb861048f16ec07a9067c47261c6178/4-Figure2-1.png
Differentially Private Link Prediction with Protected Connections,"['Abir De', 'Soumen Chakrabarti']",https://arxiv.org/abs/1908.04849,"Link prediction (LP) algorithms propose to each node a ranked list of nodes that are currently non-neighbors, as the most likely candidates for future linkage. Owing to increasing concerns about privacy, users (nodes) may prefer to keep some of their connections protected or private. Motivated by this observation, our goal is to design a differentially private LP algorithm, which trades off between privacy of the protected node-pairs and the link prediction accuracy. More specifically, we first propose a form of differential privacy on graphs, which models the privacy loss only of those node-pairs which are marked as protected. Next, we develop DPLP , a learning to rank algorithm, which applies a monotone transform to base scores from a non-private LP system, and then adds noise. DPLP is trained with a privacy induced ranking loss, which optimizes the ranking utility for a given maximum allowed level of privacy leakage of the protected node-pairs. Under a recently-introduced latent node embedding model, we present a formal trade-off between privacy and LP utility. Extensive experiments with several real-life graphs and several LP heuristics show that DPLP can trade off between privacy and predictive performance more effectively than several alternatives.",リンク予測（LP）アルゴリズムは、将来のリンクの最も可能性の高い候補として、現在非隣接ノードのランク付けされたリストを各ノードに提案します。プライバシーに関する懸念が高まっているため、ユーザー（ノード）は接続の一部を保護または非公開にすることを好む場合があります。この観察に動機付けられて、私たちの目標は、保護されたノードペアのプライバシーとリンク予測の精度の間でトレードオフを行う差分プライベートLPアルゴリズムを設計することです。より具体的には、最初にグラフ上で差分プライバシーの形式を提案します。これは、保護されているとマークされたノードペアのプライバシー損失のみをモデル化します。次に、非プライベートLPシステムからのベーススコアに単調変換を適用し、ノイズを追加する、ランク付け学習アルゴリズムであるDPLPを開発します。 DPLPは、プライバシーによって引き起こされるランキング損失でトレーニングされます。これにより、保護されたノードペアのプライバシー漏洩の特定の最大許容レベルに対してランキングユーティリティが最適化されます。最近導入された潜在ノード埋め込みモデルの下で、プライバシーとLPユーティリティの間の正式なトレードオフを提示します。いくつかの実際のグラフといくつかのLPヒューリスティックを使用した広範な実験は、DPLPがいくつかの代替案よりも効果的にプライバシーと予測パフォーマンスの間でトレードオフできることを示しています。,
PAC Learning of Causal Trees with Latent Variables,"['Prasad Tadepalli', 'Stuart Russell']",,,,
DeepPseudo: Pseudo Value Based Deep Learning Models for Competing Risk Analysis,"['Md Mahmudur Rahman', 'Koji Matsuo', 'Shinya Matsuzaki', 'Sanjay Purushotham']",,,,
Adversarial Permutation Guided Node Representations for Link Prediction,"['Indradyumna Roy', 'Abir De', 'Soumen Chakrabarti']",https://arxiv.org/abs/2012.08974,"After observing a snapshot of a social network, a link prediction (LP) algorithm identifies node pairs between which new edges will likely materialize in future. Most LP algorithms estimate a score for currently non-neighboring node pairs, and rank them by this score. Recent LP systems compute this score by comparing dense, low dimensional vector representations of nodes. Graph neural networks (GNNs), in particular graph convolutional networks (GCNs), are popular examples. For two nodes to be meaningfully compared, their embeddings should be indifferent to reordering of their neighbors. GNNs typically use simple, symmetric set aggregators to ensure this property, but this design decision has been shown to produce representations with limited expressive power. Sequence encoders are more expressive, but are permutation sensitive by design. Recent efforts to overcome this dilemma turn out to be unsatisfactory for LP tasks. In response, we propose PermGNN, which aggregates neighbor features using a recurrent, order-sensitive aggregator and directly minimizes an LP loss while it is `attacked' by adversarial generator of neighbor permutations. By design, PermGNN{} has more expressive power compared to earlier symmetric aggregators. Next, we devise an optimization framework to map PermGNN's node embeddings to a suitable locality-sensitive hash, which speeds up reporting the top-$K$ most likely edges for the LP task. Our experiments on diverse datasets show that \our outperforms several state-of-the-art link predictors by a significant margin, and can predict the most likely edges fast.",ソーシャルネットワークのスナップショットを観察した後、リンク予測（LP）アルゴリズムは、新しいエッジが将来実現する可能性が高いノードペアを識別します。ほとんどのLPアルゴリズムは、現在隣接していないノードペアのスコアを推定し、このスコアでランク付けします。最近のLPシステムは、ノードの高密度で低次元のベクトル表現を比較することによってこのスコアを計算します。グラフニューラルネットワーク（GNN）、特にグラフ畳み込みネットワーク（GCN）が一般的な例です。 2つのノードを有意義に比較するには、それらの埋め込みが隣接ノードの並べ替えに無関心である必要があります。 GNNは通常、このプロパティを確保するために単純な対称セットアグリゲーターを使用しますが、この設計上の決定により、表現力が制限された表現が生成されることが示されています。シーケンスエンコーダーはより表現力がありますが、設計上順列に敏感です。このジレンマを克服するための最近の取り組みは、LPタスクには不十分であることが判明しています。それに応じて、PermGNNを提案します。これは、繰り返しの順序に敏感なアグリゲーターを使用して隣接機能を集約し、隣接順列の敵対的なジェネレーターによって攻撃されている間、LP損失を直接最小化します。設計上、PermGNNは、以前の対称アグリゲーターと比較して、より表現力があります。次に、PermGNNノードの埋め込みを適切な局所性鋭敏型ハッシュにマッピングするための最適化フレームワークを考案します。これにより、LPタスクの上位K個の最も可能性の高いエッジのレポートが高速化されます。さまざまなデータセットでの実験では、いくつかの最先端のリンク予測子よりも大幅に優れており、最も可能性の高いエッジをすばやく予測できることが示されています。,https://d3i71xaburhd42.cloudfront.net/7ba03ffe68cbdb0e43c3c1f2c0bd3f2adb7e33fd/5-Figure1-1.png
Single View Point Cloud Generation via Unified 3D Prototype,"['Yu Lin', 'Yigong Wang', 'Yi-Fan Li', 'Zhuoyi Wang', 'Yang Gao', 'Latifur Khan']",,,,
Knowledge-Aware Coupled Graph Neural Network for Social Recommendation,"['Chao Huang', 'Huance Xu', 'Yong Xu', 'Peng Dai', 'Lianghao Xia', 'Mengyin Lu', 'Liefeng Bo', 'Hao Xing', 'Xiaoping Lai', 'Yanfang Ye']",,,,
Computational Analyses of the Electoral College: Campaigning Is Hard but Approximately Manageable,"['Sina Dehghani', 'Hamed Saleh', 'Saeed Seddighin', 'Shanghua Teng']",,"In the classical discrete Colonel Blotto game—introduced by Borel in 1921—two colonels simultaneously distribute their troops across multiple battlefields. The winner of each battlefield is determined by a winner-take-all rule, independently of other battlefields. In the original formulation, each colonel’s goal is to win as many battlefields as possible. The Blotto game and its extensions have been used in a wide range of applications from political campaign—exemplified by the U.S presidential election—to marketing campaign, from (innovative) technology competition to sports competition. Despite persistent efforts, efficient methods for finding the optimal strategies in Blotto games have been elusive for almost a century—due to exponential explosion in the organic solution space—until Ahmadinejad, Dehghani, Hajiaghayi, Lucier, Mahini, and Seddighin developed the first polynomial-time algorithm for this fundamental gametheoretical problem in 2016. However, that breakthrough polynomial-time solution has some structural limitation. It applies only to the case where troops are homogeneous with respect to battlegruounds, as in Borel’s original formulation: For each battleground, the only factor that matters to the winner’s payoff is how many troops as opposed to which sets of troops are opposing one another in that battleground. In this paper, we consider a more general setting of the two-player-multi-battleground game, in which multifaceted resources (troops) may have different contributions to different battlegrounds. In the case of U.S presidential campaign, for example, one may interpret this as different types of resources—human, financial, political—that teams can invest in each state. We provide a complexity-theoretical evidence that, in contrast to Borel’s homogeneous setting, finding optimal strategies in multifaceted Colonel Blotto games is intractable. We complement this complexity result with a polynomial-time algorithm that finds approximately optimal strategies with provable guarantees. We also study a further generalization when two competitors do not have zerosum/constant-sum payoffs. We show that optimal strategies in these two-player-multi-battleground games are as hard to compute and approximate as Nash equilibria in general noncooperative games and economic equilibria in exchange mar-",1921年にボレルによって導入された古典的な離散大佐ブロットゲームでは、2人の大佐が同時に複数の戦場に軍隊を分配します。各戦場の勝者は、他の戦場とは関係なく、勝者全員ルールによって決定されます。元の定式化では、各大佐の目標は、できるだけ多くの戦場に勝つことです。 Blottoゲームとその拡張機能は、米国大統領選挙で例示された政治キャンペーンからマーケティングキャンペーンまで、（革新的な）テクノロジー競争からスポーツ競争まで、幅広いアプリケーションで使用されてきました。アフマディネジャド、デガニ、ハジアガイ、ルシエ、マヒニ、セディギンがこのための最初の多項式時間アルゴリズムを開発するまで、Blottoゲームで最適な戦略を見つけるための効率的な方法は、有機溶液空間での指数関数的爆発のため、ほぼ1世紀の間とらえどころのないものでした。 2016年の基本的なゲーム理論上の問題。ただし、その画期的な多項式時間ソリューションには、いくつかの構造上の制限があります。これは、ボレルの元の定式化のように、軍隊が戦場に関して同質である場合にのみ適用されます。各戦場で、勝者の見返りに重要な唯一の要因は、どの部隊が互いに対立しているかではなく、部隊の数です。その戦場。このホワイトペーパーでは、多面的なリソース（軍隊）がさまざまな戦場にさまざまな貢献をする可能性がある、2人用マルチ戦場ゲームのより一般的な設定について検討します。たとえば、米国大統領選挙の場合、これは、チームが各州に投資できる人的、財政的、政治的なさまざまな種類のリソースとして解釈される可能性があります。 Borelsの均質な設定とは対照的に、多面的な大佐Blottoゲームで最適な戦略を見つけることは困難であるという複雑さ理論的な証拠を提供します。この複雑な結果を、証明可能な保証を備えたほぼ最適な戦略を見つける多項式時間アルゴリズムで補完します。また、2人の競合他社がゼロサム/コンスタントサムのペイオフを持っていない場合のさらなる一般化についても検討します。これらの2人用マルチバトルグラウンドゲームの最適戦略は、一般的な非協力ゲームのナッシュ均衡や交換市場の経済均衡と同じくらい計算と近似が難しいことを示しています。,https://d3i71xaburhd42.cloudfront.net/f3f3467c363e1a304f208feac0961bfcbf0a286e/2-Figure1-1.png
(Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs,"['Jena D Hwang', 'Chandra Bhagavatula', 'Ronan Le Bras', 'Jeff Da', 'Keisuke Sakaguchi', 'Antoine Bosselut', 'Yejin Choi']",https://arxiv.org/abs/2010.05953,"Recent years have brought about a renewed interest in commonsense representation and reasoning in the field of natural language understanding. The development of new commonsense knowledge graphs (CSKG) has been central to these advances as their diverse facts can be used and referenced by machine learning models for tackling new and challenging tasks. At the same time, there remain questions about the quality and coverage of these resources due to the massive scale required to comprehensively encompass general commonsense knowledge. 
In this work, we posit that manually constructed CSKGs will never achieve the coverage necessary to be applicable in all situations encountered by NLP agents. Therefore, we propose a new evaluation framework for testing the utility of KGs based on how effectively implicit knowledge representations can be learned from them. 
With this new goal, we propose ATOMIC 2020, a new CSKG of general-purpose commonsense knowledge containing knowledge that is not readily available in pretrained language models. We evaluate its properties in comparison with other leading CSKGs, performing the first large-scale pairwise study of commonsense knowledge resources. Next, we show that ATOMIC 2020 is better suited for training knowledge models that can generate accurate, representative knowledge for new, unseen entities and events. Finally, through human evaluation, we show that the few-shot performance of GPT-3 (175B parameters), while impressive, remains ~12 absolute points lower than a BART-based knowledge model trained on ATOMIC 2020 despite using over 430x fewer parameters.",近年、自然言語理解の分野における常識的な表現と推論への新たな関心がもたらされました。新しい常識的な知識グラフ（CSKG）の開発は、それらの多様な事実を機械学習モデルで使用および参照して、新しく困難なタスクに取り組むことができるため、これらの進歩の中心となっています。同時に、一般的な常識知識を包括的に網羅するために必要な大規模な規模のため、これらのリソースの品質と適用範囲については疑問が残ります。この作業では、手動で構築されたCSKGは、NLPエージェントが遭遇するすべての状況に適用できるようにするために必要なカバレッジを達成することは決してないと考えています。したがって、暗黙知表現をKGからどれだけ効果的に学習できるかに基づいて、KGの有用性をテストするための新しい評価フレームワークを提案します。この新しい目標を掲げて、事前に訓練された言語モデルでは容易に利用できない知識を含む汎用常識知識の新しいCSKGであるATOMIC2020を提案します。他の主要なCSKGと比較してその特性を評価し、常識知識リソースの最初の大規模なペアワイズ研究を実行します。次に、ATOMIC 2020は、新しい、目に見えないエンティティやイベントの正確で代表的な知識を生成できる知識モデルのトレーニングに適していることを示します。最後に、人間による評価を通じて、GPT-3（175Bパラメーター）の数ショットのパフォーマンスは印象的ですが、430倍以上少ないパラメーターを使用しているにもかかわらず、ATOMIC2020でトレーニングされたBARTベースの知識モデルよりも12絶対ポイント低いままであることを示します。,https://d3i71xaburhd42.cloudfront.net/e39503e01ebb108c6773948a24ca798cd444eb62/1-Figure1-1.png
Span-Based Event Coreference Resolution,"['Jing Lu', 'Vincent Ng']",,,,
Near Lossless Transfer Learning for Spiking Neural Networks,"['Zhanglu Yan', 'Jun Zhou', 'Weng-Fai Wong']",,,,
Game of Gradients: Mitigating Irrelevant Clients in Federated Learning,"['Lokesh Nagalapatti', 'Ramasuri Narayanam']",,,,
PenDer: Incorporating Shape Constraints via Penalized Derivatives,"['Akhil Gupta', 'Lavanya Marla', 'Ruoyu Sun', 'Naman Shukla', 'Arinbjörn Kolbeinsson']",,,,
Robust Bandit Learning with Imperfect Context,"['Jianyi Yang', 'Shaolei Ren']",https://arxiv.org/abs/2102.05018,"A standard assumption in contextual multi-arm bandit is that the true context is perfectly known before arm selection. Nonetheless, in many practical applications (e.g., cloud resource management), prior to arm selection, the context information can only be acquired by prediction subject to errors or adversarial modification. In this paper, we study a contextual bandit setting in which only imperfect context is available for arm selection while the true context is revealed at the end of each round. We propose two robust arm selection algorithms: MaxMinUCB (Maximize Minimum UCB) which maximizes the worst-case reward, and MinWD (Minimize Worst-case Degradation) which minimizes the worst-case regret. Importantly, we analyze the robustness of MaxMinUCB and MinWD by deriving both regret and reward bounds compared to an oracle that knows the true context. Our results show that as time goes on, MaxMinUCB and MinWD both perform as asymptotically well as their optimal counterparts that know the reward function. Finally, we apply MaxMinUCB and MinWD to online edge datacenter selection, and run synthetic simulations to validate our theoretical analysis.",コンテキストマルチアームバンディットの標準的な仮定は、アーム選択の前に真のコンテキストが完全にわかっているということです。それにもかかわらず、多くの実際のアプリケーション（たとえば、クラウドリソース管理）では、アームを選択する前に、コンテキスト情報は、エラーまたは敵対的な変更の対象となる予測によってのみ取得できます。この論文では、腕の選択に不完全なコンテキストしか利用できず、各ラウンドの終わりに真のコンテキストが明らかになるコンテキストバンディット設定を研究します。最悪の場合の報酬を最大化するMaxMinUCB（最大化最小UCB）と最悪の場合の後悔を最小化するMinWD（最小化最悪の場合の劣化）の2つの堅牢なアーム選択アルゴリズムを提案します。重要なのは、真のコンテキストを知っているオラクルと比較して、後悔と報酬の両方の範囲を導き出すことによって、MaxMinUCBとMinWDの堅牢性を分析することです。私たちの結果は、時間が経つにつれて、MaxMinUCBとMinWDの両方が、報酬関数を知っている最適な対応物と同様に漸近的に機能することを示しています。最後に、MaxMinUCBとMinWDをオンラインエッジデータセンターの選択に適用し、合成シミュレーションを実行して理論的分析を検証します。,https://d3i71xaburhd42.cloudfront.net/879289c0d7978580235fd12cb16b7be9bd39bb52/4-Figure1-1.png
Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding,"['Long Chen', 'Wenbo Ma', 'Jun Xiao', 'Hanwang Zhang', 'Shih-Fu Chang']",https://arxiv.org/abs/2009.01449,"The prevailing framework for solving referring expression grounding is based on a two-stage process: 1) detecting proposals with an object detector and 2) grounding the referent to one of the proposals. Existing two-stage solutions mostly focus on the grounding step, which aims to align the expressions with the proposals. In this paper, we argue that these methods overlook an obvious mismatch between the roles of proposals in the two stages: they generate proposals solely based on the detection confidence (i.e., expression-agnostic), hoping that the proposals contain all right instances in the expression (i.e., expression-aware). Due to this mismatch, current two-stage methods suffer from a severe performance drop between detected and ground-truth proposals. To this end, we propose Ref-NMS, which is the first method to yield expression-aware proposals at the first stage. Ref-NMS regards all nouns in the expression as critical objects, and introduces a lightweight module to predict a score for aligning each box with a critical object. These scores can guide the NMSoperation to filter out the boxes irrelevant to the expression, increasing the recall of critical objects, resulting in a significantly improved grounding performance. Since Ref-NMS is agnostic to the grounding step, it can be easily integrated into any state-of-the-art two-stage method. Extensive ablation studies on several backbones, benchmarks, and tasks consistently demonstrate the superiority of Ref-NMS.",参照表現の接地を解決するための一般的なフレームワークは、2段階のプロセスに基づいています。1）オブジェクト検出器を使用して提案を検出し、2）指示対象を提案の1つに接地します。既存の2段階のソリューションは、主に、表現と提案を一致させることを目的とした接地ステップに焦点を合わせています。この論文では、これらの方法は、2つの段階での提案の役割間の明らかな不一致を見落としていると主張します。提案がすべての適切なインスタンスを含むことを期待して、検出の信頼性（つまり、表現にとらわれない）のみに基づいて提案を生成します。式（つまり、式を意識する）。この不一致のために、現在の2段階の方法では、検出された提案とグラウンドトゥルースの提案の間でパフォーマンスが大幅に低下します。そのために、最初の段階で表現を意識した提案を行う最初の方法であるRef-NMSを提案します。 Ref-NMSは、式内のすべての名詞を重要なオブジェクトと見なし、各ボックスを重要なオブジェクトに揃えるためのスコアを予測する軽量モジュールを導入します。これらのスコアは、NMS操作をガイドして、式に関係のないボックスを除外し、重要なオブジェクトのリコールを増やして、接地パフォーマンスを大幅に向上させることができます。 Ref-NMSは接地ステップに依存しないため、最先端の2段階の方法に簡単に統合できます。いくつかのバックボーン、ベンチマーク、およびタスクに関する広範なアブレーション研究は、Ref-NMSの優位性を一貫して示しています。,https://d3i71xaburhd42.cloudfront.net/62ea5fe5ac1795297343b20fbaad9397c0f0b6ff/2-Figure1-1.png
Exploiting Learnable Joint Groups for Hand Pose Estimation,"['Moran Li', 'Yuan Gao', 'Nong Sang']",https://arxiv.org/abs/2012.09496,"In this paper, we propose to estimate 3D hand pose by recovering the 3D coordinates of joints in a group-wise manner, where less-related joints are automatically categorized into different groups and exhibit different features. This is different from the previous methods where all the joints are considered holistically and share the same feature. The benefits of our method are illustrated by the principle of multi-task learning (MTL), i.e., by separating less-related joints into different groups (as different tasks), our method learns different features for each of them, therefore efficiently avoids the negative transfer (among less related tasks/groups of joints). The key of our method is a novel binary selector that automatically selects related joints into the same group. We implement such a selector with binary values stochastically sampled from a Concrete distribution, which is constructed using Gumbel softmax on trainable parameters. This enables us to preserve the differentiable property of the whole network. We further exploit features from those less-related groups by carrying out an additional feature fusing scheme among them, to learn more discriminative features. This is realized by implementing multiple 1x1 convolutions on the concatenated features, where each joint group contains a unique 1x1 convolution for feature fusion. The detailed ablation analysis and the extensive experiments on several benchmark datasets demonstrate the promising performance of the proposed method over the state-of-the-art (SOTA) methods. Besides, our method achieves top-1 among all the methods that do not exploit the dense 3D shape labels on the most recently released FreiHAND competition at the submission date. The source code and models are available at this https URL moranli-aca/LearnableGroups-Hand.",本論文では、関節の3D座標をグループごとに復元することにより、3D手のポーズを推定することを提案します。この場合、関連性の低い関節は自動的に異なるグループに分類され、異なる特徴を示します。これは、すべてのジョイントが全体的に考慮され、同じ機能を共有する以前の方法とは異なります。私たちの方法の利点は、マルチタスク学習（MTL）の原理によって示されます。つまり、関連性の低い関節を（異なるタスクとして）異なるグループに分割することにより、私たちの方法はそれぞれの異なる機能を学習するため、効率的に回避します。ネガティブトランスファー（関連性の低いタスク/ジョイントのグループ間）。私たちの方法の鍵は、関連する関節を同じグループに自動的に選択する新しいバイナリセレクターです。トレーニング可能なパラメーターでガンベルソフトマックスを使用して構築されたコンクリート分布から確率的にサンプリングされたバイナリ値を使用して、このようなセレクターを実装します。これにより、ネットワーク全体の微分可能なプロパティを保持できます。さらに、それらの間で追加の機能融合スキームを実行することにより、これらの関連性の低いグループの機能を活用して、より識別力のある機能を学習します。これは、連結されたフィーチャに複数の1x1畳み込みを実装することで実現されます。ここで、各ジョイントグループには、フィーチャ融合のための一意の1x1畳み込みが含まれています。詳細なアブレーション分析といくつかのベンチマークデータセットでの広範な実験は、最先端の（SOTA）メソッドに対する提案されたメソッドの有望なパフォーマンスを示しています。その上、私たちの方法は、提出日に最近リリースされたFreiHANDコンペティションで高密度の3D形状ラベルを利用しないすべての方法の中でトップ1を達成します。ソースコードとモデルは、このhttps URL moranli-aca / LearnableGroups-Handで入手できます。,https://d3i71xaburhd42.cloudfront.net/d2273109e1d58488092651f060acd1b52a7ba431/3-Figure1-1.png
Proposal-Free Video Grounding with Contextual Pyramid Network,"['Kun Li', 'Dan Guo', 'Meng Wang']",,,,
Graph-Enhanced Multi-Task Learning of Multi-Level Transition Dynamics for Session-Based Recommendation,"['Chao Huang', 'Jiahui Chen', 'Lianghao Xia', 'Yong Xu', 'Peng Dai', 'Yanqing Chen', 'Liefeng Bo', 'Jiashu Zhao', 'Jimmy Huang']",,,,
Segmentation of Tweets with URLs and its Applications to Sentiment Analysis,"['Abdullah Aljebreen', 'Weiyi Meng', 'Eduard Dragut']",,,,
StarNet: Towards Weakly Supervised Few-Shot Object Detection,"['Leonid Karlinsky', 'Joseph Shtok', 'Amit Alfassy', 'Moshe Lichtenstein', 'Sivan Harary', 'Eli Schwartz', 'Sivan Doveh', 'Prasanna Sattigeri', 'Rogerio Feris', 'Alex Bronstein', 'Raja Giryes']",https://arxiv.org/abs/2003.06798,"Few-shot detection and classification have advanced significantly in recent years. Yet, detection approaches require strong annotation (bounding boxes) both for pre-training and for adaptation to novel classes, and classification approaches rarely provide localization of objects in the scene. In this paper, we introduce StarNet - a few-shot model featuring an end-to-end differentiable non-parametric star-model detection and classification head. Through this head, the backbone is meta-trained using only image-level labels to produce good features for jointly localizing and classifying previously unseen categories of few-shot test tasks using a star-model that geometrically matches between the query and support images (to find corresponding object instances). Being a few-shot detector, StarNet does not require any bounding box annotations, neither during pre-training nor for novel classes adaptation. It can thus be applied to the previously unexplored and challenging task of Weakly Supervised Few-Shot Object Detection (WS-FSOD), where it attains significant improvements over the baselines. In addition, StarNet shows significant gains on few-shot classification benchmarks that are less cropped around the objects (where object localization is key).",近年、数ショットの検出と分類が大幅に進歩しています。それでも、検出アプローチでは、事前トレーニングと新しいクラスへの適応の両方に強力な注釈（境界ボックス）が必要であり、分類アプローチでは、シーン内のオブジェクトのローカリゼーションが提供されることはめったにありません。この論文では、StarNetを紹介します。これは、エンドツーエンドの微分可能なノンパラメトリックスターモデル検出および分類ヘッドを特徴とする数ショットモデルです。このヘッドを通じて、バックボーンは画像レベルのラベルのみを使用してメタトレーニングされ、クエリ画像とサポート画像の間で幾何学的に一致するスターモデルを使用して、これまでに見られなかった数ショットのテストタスクのカテゴリを共同でローカライズおよび分類するための優れた機能を生成します（対応するオブジェクトインスタンスを検索します）。数ショットの検出器であるため、StarNetは、事前トレーニング中でも、新しいクラスの適応でも、バウンディングボックスの注釈を必要としません。したがって、これまで未踏で困難なタスクである弱教師あり少数ショットオブジェクト検出（WS-FSOD）に適用でき、ベースラインを大幅に上回ります。さらに、StarNetは、オブジェクトの周囲でトリミングされていない数ショットの分類ベンチマークで大幅な向上を示しています（オブジェクトのローカリゼーションが重要です）。,
Knowledge-Aware Named Entity Recognition with Alleviating Heterogeneity,"['Binling Nie', 'Ruixue Ding', 'Pengjun Xie', 'Fei Huang', 'Chen Qian', 'Luo Si']",,,,
FILTER: An Enhanced Fusion Method for Cross-Lingual Language Understanding,"['Yuwei Fang', 'Shuohang Wang', 'Zhe Gan', 'Siqi Sun', 'Jingjing Liu']",https://arxiv.org/abs/2009.05166,"Large-scale cross-lingual language models (LM), such as mBERT, Unicoder and XLM, have achieved great success in cross-lingual representation learning. However, when applied to zero-shot cross-lingual transfer tasks, most existing methods use only single-language input for LM finetuning, without leveraging the intrinsic cross-lingual alignment between different languages that is essential for multilingual tasks. In this paper, we propose FILTER, an enhanced fusion method that takes cross-lingual data as input for XLM finetuning. Specifically, FILTER first encodes text input in the source language and its translation in the target language independently in the shallow layers, then performs cross-lingual fusion to extract multilingual knowledge in the intermediate layers, and finally performs further language-specific encoding. During inference, the model makes predictions based on the text input in the target language and its translation in the source language. For simple tasks such as classification, translated text in the target language shares the same label as the source language. However, this shared label becomes less accurate or even unavailable for more complex tasks such as question answering, NER and POS tagging. For better model scalability, we further propose an additional KL-divergence self-teaching loss for model training, based on auto-generated soft pseudo-labels for translated text in the target language. Extensive experiments demonstrate that FILTER achieves new state of the art (77.0 on average) on the challenging multilingual multi-task benchmark, XTREME.",mBERT、Unicoder、XLMなどの大規模なクロスリンガル言語モデル（LM）は、クロスリンガル表現学習で大きな成功を収めています。ただし、ゼロショットの言語間転送タスクに適用する場合、ほとんどの既存の方法では、多言語タスクに不可欠な異なる言語間の固有の言語間調整を利用せずに、LMの微調整に単一言語の入力のみを使用します。本論文では、XLM微調整の入力として言語間データを取得する拡張融合法であるFILTERを提案します。具体的には、FILTERは、最初にソース言語でのテキスト入力とターゲット言語でのその翻訳を浅いレイヤーで個別にエンコードし、次に言語間の融合を実行して中間レイヤーで多言語の知識を抽出し、最後にさらに言語固有のエンコードを実行します。推論中、モデルは、ターゲット言語で入力されたテキストとソース言語でのその翻訳に基づいて予測を行います。分類などの単純なタスクの場合、ターゲット言語で翻訳されたテキストは、ソース言語と同じラベルを共有します。ただし、この共有ラベルは、質問応答、NER、POSタグ付けなどのより複雑なタスクでは精度が低下するか、使用できなくなります。モデルのスケーラビリティを向上させるために、ターゲット言語で翻訳されたテキストの自動生成されたソフト疑似ラベルに基づいて、モデルトレーニング用の追加のKL発散自己学習損失をさらに提案します。広範な実験により、FILTERは、挑戦的な多言語マルチタスクベンチマークであるXTREMEで、新しい最先端技術（平均77.0）を達成していることが実証されています。,https://d3i71xaburhd42.cloudfront.net/7b567f31715e0be5b0d9bc668b1a787df4010f8b/2-Figure1-1.png
Classification under Human Assistance,"['Abir De', 'Nastaran Okati', 'Ali Zarezade', 'Manuel Gomez Rodriguez']",https://arxiv.org/abs/2006.11845,"Most supervised learning models are trained for full automation. However, their predictions are sometimes worse than those by human experts on some specific instances. Motivated by this empirical observation, our goal is to design classifiers that are optimized to operate under different automation levels. More specifically, we focus on convex margin-based classifiers and first show that the problem is NP-hard. Then, we further show that, for support vector machines, the corresponding objective function can be expressed as the difference of two functions f = g - c, where g is monotone, non-negative and {\gamma}-weakly submodular, and c is non-negative and modular. This representation allows a recently introduced deterministic greedy algorithm, as well as a more efficient randomized variant of the algorithm, to enjoy approximation guarantees at solving the problem. Experiments on synthetic and real-world data from several applications in medical diagnosis illustrate our theoretical findings and demonstrate that, under human assistance, supervised learning models trained to operate under different automation levels can outperform those trained for full automation as well as humans operating alone.",ほとんどの教師あり学習モデルは、完全自動化のためにトレーニングされています。ただし、特定の事例では、人間の専門家による予測よりも予測が悪い場合があります。この経験的観察に動機付けられて、私たちの目標は、さまざまな自動化レベルで動作するように最適化された分類器を設計することです。より具体的には、凸マージンベースの分類器に焦点を当て、最初に問題がNP困難であることを示します。次に、サポートベクターマシンの場合、対応する目的関数が2つの関数f = g --cの差として表現できることをさらに示します。ここで、gは単調で、非負で、弱く劣モジュラであり、cは非負です。とモジュラー。この表現により、最近導入された決定論的欲張りアルゴリズム、およびアルゴリズムのより効率的なランダム化されたバリアントが、問題を解決する際の近似保証を享受することができます。医療診断のいくつかのアプリケーションからの合成データと実世界データの実験は、私たちの理論的発見を示し、人間の支援の下で、さまざまな自動化レベルで動作するように訓練された教師あり学習モデルが、完全自動化と単独で動作する人間のために訓練されたモデルよりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/917a83e0aeefa37b4fd1a1dbaa125afe28f6ccb1/4-Figure1-1.png
Lenient Regret for Multi-Armed Bandits,"['Nadav Merlis', 'Shie Mannor']",https://arxiv.org/abs/2008.03959,"We consider the Multi-Armed Bandit (MAB) problem, where an agent sequentially chooses actions and observes rewards for the actions it took. While the majority of algorithms try to minimize the regret, i.e., the cumulative difference between the reward of the best action and the agent's action, this criterion might lead to undesirable results. For example, in large problems, or when the interaction with the environment is brief, finding an optimal arm is infeasible, and regret-minimizing algorithms tend to over-explore. To overcome this issue, algorithms for such settings should instead focus on playing near-optimal arms. To this end, we suggest a new, more lenient, regret criterion that ignores suboptimality gaps smaller than some $\epsilon$. We then present a variant of the Thompson Sampling (TS) algorithm, called $\epsilon$-TS, and prove its asymptotic optimality in terms of the lenient regret. Importantly, we show that when the mean of the optimal arm is high enough, the lenient regret of $\epsilon$-TS is bounded by a constant. Finally, we show that $\epsilon$-TS can be applied to improve the performance when the agent knows a lower bound of the suboptimality gaps.",エージェントがアクションを順番に選択し、実行したアクションに対する報酬を観察する、多腕バンディット（MAB）問題を検討します。アルゴリズムの大部分は後悔、つまり最高のアクションの報酬とエージェントのアクションの累積的な違いを最小限に抑えようとしますが、この基準は望ましくない結果につながる可能性があります。たとえば、大きな問題の場合、または環境との相互作用が短い場合、最適なアームを見つけることは実行不可能であり、後悔を最小限に抑えるアルゴリズムは過度に探索される傾向があります。この問題を克服するには、そのような設定のアルゴリズムは、代わりにほぼ最適な武器の再生に焦点を当てる必要があります。この目的のために、いくつかよりも小さい準最適性のギャップを無視する、新しい、より寛大な、後悔の基準を提案します。次に、-TSと呼ばれるThompson Sampling（TS）アルゴリズムの変形を提示し、寛大な後悔の観点からその漸近的最適性を証明します。重要なのは、最適なアームの平均が十分に高い場合、-TSの寛大な後悔は定数によって制限されることを示しています。最後に、エージェントが準最適性ギャップの下限を知っている場合に、-TSを適用してパフォーマンスを向上できることを示します。,
A Blind Block Term Decomposition of High Order Tensors,"['Yunfeng Cai', 'Ping Li']",,,,
A Unified Pretraining Framework for Passage Ranking and Expansion,"['Ming Yan', 'Chenliang Li', 'Bin Bi', 'Wei Wang', 'Songfang Huang']",,,,
Image-to-Image Retrieval by Learning Similarity between Scene Graphs,"['Sangwoong Yoon', 'Woo Young Kang', 'Sungwook Jeon', 'SeongEun Lee', 'Changjin Han', 'Jonghun Park', 'Eun-Sol Kim']",https://arxiv.org/abs/2012.14700,"As a scene graph compactly summarizes the high-level content of an image in a structured and symbolic manner, the similarity between scene graphs of two images reflects the relevance of their contents. Based on this idea, we propose a novel approach for image-to-image retrieval using scene graph similarity measured by graph neural networks. In our approach, graph neural networks are trained to predict the proxy image relevance measure, computed from humanannotated captions using a pre-trained sentence similarity model. We collect and publish the dataset for image relevance measured by human annotators to evaluate retrieval algorithms. The collected dataset shows that our method agrees well with the human perception of image similarity than other competitive baselines.",シーングラフは、画像の高レベルのコンテンツを構造化された象徴的な方法でコンパクトに要約するため、2つの画像のシーングラフ間の類似性は、それらのコンテンツの関連性を反映しています。この考えに基づいて、グラフニューラルネットワークによって測定されたシーングラフの類似性を使用した画像間検索の新しいアプローチを提案します。私たちのアプローチでは、グラフニューラルネットワークは、事前にトレーニングされた文の類似性モデルを使用して、人間が注釈を付けたキャプションから計算されたプロキシ画像の関連性の尺度を予測するようにトレーニングされます。検索アルゴリズムを評価するために、人間のアノテーターによって測定された画像の関連性のデータセットを収集して公開します。収集されたデータセットは、私たちの方法が他の競合するベースラインよりも画像の類似性に対する人間の認識とよく一致していることを示しています。,https://d3i71xaburhd42.cloudfront.net/2e0570df4e56d51be58b53166e853d848ef767af/1-Figure1-1.png
Faster Game Solving via Predictive Blackwell Approachability: Connecting Regret Matching and Mirror Descent,"['Gabriele Farina', 'Christian Kroer', 'Tuomas Sandholm']",https://arxiv.org/abs/2007.14358,"Blackwell approachability is a framework for reasoning about repeated games with vector-valued payoffs. We introduce predictive Blackwell approachability, where an estimate of the next payoff vector is given, and the decision maker tries to achieve better performance based on the accuracy of that estimator. In order to derive algorithms that achieve predictive Blackwell approachability, we start by showing a powerful connection between four well-known algorithms. Follow-the-regularized-leader (FTRL) and online mirror descent (OMD) are the most prevalent regret minimizers in online convex optimization. In spite of this prevalence, the regret matching (RM) and regret matching+ (RM+) algorithms have been preferred in the practice of solving large-scale games (as the local regret minimizers within the counterfactual regret minimization framework). We show that RM and RM+ are the algorithms that result from running FTRL and OMD, respectively, to select the halfspace to force at all times in the underlying Blackwell approachability game. By applying the predictive variants of FTRL or OMD to this connection, we obtain predictive Blackwell approachability algorithms, as well as predictive variants of RM and RM+. In experiments across 18 common zero-sum extensive-form benchmark games, we show that predictive RM+ coupled with counterfactual regret minimization converges vastly faster than the fastest prior algorithms (CFR+, DCFR, LCFR) across all games but two of the poker games and Liar's Dice, sometimes by two or more orders of magnitude.",ブラックウェルの親しみやすさは、ベクトル値のペイオフを伴う繰り返しゲームについて推論するためのフレームワークです。次のペイオフベクトルの推定値が与えられ、意思決定者がその推定量の精度に基づいてより良いパフォーマンスを達成しようとする、予測ブラックウェルアプローチ可能性を紹介します。ブラックウェルの予測的接近性を実現するアルゴリズムを導出するために、4つのよく知られたアルゴリズム間の強力な接続を示すことから始めます。 Follow-the-regularized-leader（FTRL）とonline Mirror descent（OMD）は、オンライン凸最適化で最も一般的な後悔の最小化です。この普及にもかかわらず、後悔マッチング（RM）および後悔マッチング+（RM +）アルゴリズムは、大規模なゲームを解決する実践において（反事実的後悔最小化フレームワーク内のローカル後悔最小化として）好まれてきました。 RMとRM +は、それぞれFTRLとOMDを実行して、基礎となるBlackwellアプローチ可能性ゲームで常に強制する半空間を選択することで得られるアルゴリズムであることを示します。 FTRLまたはOMDの予測バリアントをこの接続に適用することにより、予測ブラックウェル接近可能性アルゴリズム、およびRMとRM +の予測バリアントを取得します。 18の一般的なゼロサム展開型ベンチマークゲームでの実験では、予測RM +と反事実的な後悔の最小化を組み合わせて、ポーカーゲームと嘘つきの2つを除くすべてのゲームで、以前の最速のアルゴリズム（CFR +、DCFR、LCFR）よりもはるかに速く収束することを示しています。時には2桁以上のサイコロ。,https://d3i71xaburhd42.cloudfront.net/7a9043a0b2686445e7da328408c370833da56476/5-Figure1-1.png
Visualization of Supervised and Self-Supervised Neural Networks via Attribution Guided Factorization,"['Shir Gur', 'Ameen Ali', 'Lior Wolf']",https://arxiv.org/abs/2012.02166,"Neural network visualization techniques mark image locations by their relevancy to the network's classification. Existing methods are effective in highlighting the regions that affect the resulting classification the most. However, as we show, these methods are limited in their ability to identify the support for alternative classifications, an effect we name {\em the saliency bias} hypothesis. In this work, we integrate two lines of research: gradient-based methods and attribution-based methods, and develop an algorithm that provides per-class explainability. The algorithm back-projects the per pixel local influence, in a manner that is guided by the local attributions, while correcting for salient features that would otherwise bias the explanation. In an extensive battery of experiments, we demonstrate the ability of our methods to class-specific visualization, and not just the predicted label. Remarkably, the method obtains state of the art results in benchmarks that are commonly applied to gradient-based methods as well as in those that are employed mostly for evaluating attribution methods. Using a new unsupervised procedure, our method is also successful in demonstrating that self-supervised methods learn semantic information.",ニューラルネットワークの視覚化手法は、ネットワーク分類との関連性によって画像の場所をマークします。既存の方法は、結果の分類に最も影響を与える領域を強調表示するのに効果的です。ただし、私たちが示すように、これらの方法は、代替分類のサポートを識別する能力に制限があります。これは、顕著性バイアス仮説と名付けた効果です。この作業では、勾配ベースの方法と帰属ベースの方法の2つの研究ラインを統合し、クラスごとの説明性を提供するアルゴリズムを開発します。アルゴリズムは、ローカル属性によって導かれる方法で、ピクセルごとのローカル影響を逆投影しますが、そうでなければ説明にバイアスをかける顕著な特徴を修正します。一連の広範な実験で、予測されたラベルだけでなく、クラス固有の視覚化に対するメソッドの能力を示します。注目すべきことに、このメソッドは、グラジエントベースのメソッドに一般的に適用されるベンチマークと、主にアトリビューションメソッドの評価に使用されるベンチマークで最先端の結果を取得します。新しい教師なし手順を使用して、私たちのメソッドは、自己教師ありメソッドが意味情報を学習することを実証することにも成功しています。,https://d3i71xaburhd42.cloudfront.net/485f7c07da4e262f9e3389808076920062612e67/2-Figure1-1.png
Human Uncertainty Inference via Deterministic Ensemble Neural Networks,"['Yujin Cha', 'Sang Wan Lee']",,,,
Rejection Sampling for Weighted Jaccard Similarity Revisited,"['Xiaoyun Li', 'Ping Li']",,,,
Asynchronous Optimization Methods for Efficient Training of Deep Neural Networks with Guarantees,"['Vyacheslav Kungurtsev', 'Malcolm Egan', 'Bapi Chatterjee', 'Dan Alistarh']",https://arxiv.org/abs/1905.11845,"Asynchronous distributed algorithms are a popular way to reduce synchronization costs in large-scale optimization, and in particular for neural network training. However, for nonsmooth and nonconvex objectives, few convergence guarantees exist beyond cases where closed-form proximal operator solutions are available. As most popular contemporary deep neural networks lead to nonsmooth and nonconvex objectives, there is now a pressing need for such convergence guarantees. In this paper, we analyze for the first time the convergence of stochastic asynchronous optimization for this general class of objectives. In particular, we focus on stochastic subgradient methods allowing for block variable partitioning, where the shared-memory-based model is asynchronously updated by concurrent processes. To this end, we first introduce a probabilistic model which captures key features of real asynchronous scheduling between concurrent processes; under this model, we establish convergence with probability one to an invariant set for stochastic subgradient methods with momentum. 
From the practical perspective, one issue with the family of methods we consider is that it is not efficiently supported by machine learning frameworks, as they mostly focus on distributed data-parallel strategies. To address this, we propose a new implementation strategy for shared-memory based training of deep neural networks, whereby concurrent parameter servers are utilized to train a partitioned but shared model in single- and multi-GPU settings. Based on this implementation, we achieve on average 1.2x speed-up in comparison to state-of-the-art training methods for popular image classification tasks without compromising accuracy.",非同期分散アルゴリズムは、大規模な最適化、特にニューラルネットワークのトレーニングで同期コストを削減するための一般的な方法です。ただし、滑らかでない目的と凸でない目的の場合、閉じた形式の近位演算子ソリューションが利用できる場合を超えて、収束の保証はほとんどありません。最も人気のある現代のディープニューラルネットワークは、滑らかでなく凸面でない目的につながるため、そのような収束保証が差し迫った必要性があります。この論文では、この一般的なクラスの目的に対する確率的非同期最適化の収束を初めて分析します。特に、共有メモリベースのモデルが並行プロセスによって非同期的に更新される、ブロック変数の分割を可能にする確率的劣勾配法に焦点を当てています。この目的のために、最初に、並行プロセス間の実際の非同期スケジューリングの主要な機能をキャプチャする確率モデルを紹介します。このモデルの下で、運動量を伴う確率的劣勾配法の不変集合への確率1の収束を確立します。実用的な観点から、私たちが検討する一連のメソッドの1つの問題は、分散データ並列戦略に主に焦点を当てているため、機械学習フレームワークによって効率的にサポートされていないことです。これに対処するために、ディープニューラルネットワークの共有メモリベースのトレーニングの新しい実装戦略を提案します。これにより、同時パラメーターサーバーを使用して、単一およびマルチGPU設定でパーティション化されているが共有モデルをトレーニングします。この実装に基づいて、精度を損なうことなく、一般的な画像分類タスクの最先端のトレーニング方法と比較して、平均1.2倍の速度向上を実現します。,
Learning to Reweight with Deep Interactions,"['Yang Fan', 'Yingce Xia', 'Lijun Wu', 'Shufang Xie', 'Weiqing Liu', 'Jiang Bian', 'Tao Qin', 'Xiangyang Li']",https://arxiv.org/abs/2007.04649,"Recently, the concept of teaching has been introduced into machine learning, in which a teacher model is used to guide the training of a student model (which will be used in real tasks) through data selection, loss function design, etc. Learning to reweight, which is a specific kind of teaching that reweights training data using a teacher model, receives much attention due to its simplicity and effectiveness. In existing learning to reweight works, the teacher model only utilizes shallow/surface information such as training iteration number and loss/accuracy of the student model from training/validation sets, but ignores the internal states of the student model, which limits the potential of learning to reweight. In this work, we propose an improved data reweighting algorithm, in which the student model provides its internal states to the teacher model, and the teacher model returns adaptive weights of training samples to enhance the training of the student model. The teacher model is jointly trained with the student model using meta gradients propagated from a validation set. Experiments on image classification with clean/noisy labels and neural machine translation empirically demonstrate that our algorithm makes significant improvement over previous methods.",最近、教育の概念が機械学習に導入されました。この概念では、教師モデルを使用して、データ選択、損失関数の設計などを通じて、学生モデル（実際のタスクで使用される）のトレーニングをガイドします。は、教師モデルを使用してトレーニングデータを再重み付けする特定の種類の教育であり、その単純さと有効性のために大きな注目を集めています。作品を再重み付けする既存の学習では、教師モデルは、トレーニングの反復回数やトレーニング/検証セットからの学生モデルの損失/精度などの浅い/表面的な情報のみを利用しますが、学生モデルの内部状態を無視します。再加重を学ぶ。この作業では、学生モデルがその内部状態を教師モデルに提供し、教師モデルがトレーニングサンプルの適応重みを返し、学生モデルのトレーニングを強化する、改良されたデータ再重み付けアルゴリズムを提案します。教師モデルは、検証セットから伝播されたメタ勾配を使用して、学生モデルと共同でトレーニングされます。クリーン/ノイズの多いラベルとニューラル機械翻訳を使用した画像分類の実験は、私たちのアルゴリズムが以前の方法よりも大幅に改善されていることを経験的に示しています。,
Facility’s Perspective to Fair Facility Location Problems,"['Hau Chan', 'Minming Li', 'Chenhao Wang', 'Xiaoying Wu']",,,,
Online DR-Submodular Maximization: Minimizing Regret and Constraint Violation,"['Prasanna S Raut', 'Omid Sadeghi', 'Maryam Fazel']",,,,
Deep Transfer Tensor Decomposition with Orthogonal Constraint for Recommender Systems,"['Zhengyu Chen', 'Ziqing Xu', 'Donglin Wang']",,,,
Sample Complexity of Policy Gradient Finding Second-Order Stationary Points,"['Long Yang', 'Qian Zheng', 'Gang Pan']",https://arxiv.org/abs/2012.01491,"The goal of policy-based reinforcement learning (RL) is to search the maximal point of its objective. However, due to the inherent non-concavity of its objective, convergence to a first-order stationary point (FOSP) can not guarantee the policy gradient methods finding a maximal point. A FOSP can be a minimal or even a saddle point, which is undesirable for RL. Fortunately, if all the saddle points are \emph{strict}, all the second-order stationary points (SOSP) are exactly equivalent to local maxima. Instead of FOSP, we consider SOSP as the convergence criteria to character the sample complexity of policy gradient. Our result shows that policy gradient converges to an $(\epsilon,\sqrt{\epsilon\chi})$-SOSP with probability at least $1-\widetilde{\mathcal{O}}(\delta)$ after the total cost of $\mathcal{O}\left(\dfrac{\epsilon^{-\frac{9}{2}}}{(1-\gamma)\sqrt\chi}\log\dfrac{1}{\delta}\right)$, where $\gamma\in(0,1)$. Our result improves the state-of-the-art result significantly where it requires $\mathcal{O}\left(\dfrac{\epsilon^{-9}\chi^{\frac{3}{2}}}{\delta}\log\dfrac{1}{\epsilon\chi}\right)$. Our analysis is based on the key idea that decomposes the parameter space $\mathbb{R}^p$ into three non-intersected regions: non-stationary point, saddle point, and local optimal region, then making a local improvement of the objective of RL in each region. This technique can be potentially generalized to extensive policy gradient methods.",ポリシーベースの強化学習（RL）の目標は、その目的の最大点を検索することです。ただし、その目的には固有の非凹面があるため、1次停留点（FOSP）への収束は、最大点を見つけるポリシー勾配法を保証できません。 FOSPは最小または鞍点でさえあり得、これはRLにとって望ましくありません。幸い、すべての鞍点が厳密である場合、すべての2次停留点（SOSP）は極大値とまったく同じです。 FOSPの代わりに、ポリシー勾配のサンプルの複雑さを特徴付ける収束基準としてSOSPを検討します。私たちの結果は、ポリシーの勾配が$（\ epsilon、\ sqrt {\ epsilon \ chi}）$-SOSPに収束し、総コストの後で少なくとも$ 1- \ widetilde {\ mathcal {O}}（\ delta）$になることを示しています。 $ \ mathcal {O} \ left（\ dfrac {\ epsilon ^ {-\ frac {9} {2}}} {（1- \ gamma）\ sqrt \ chi} \ log \ dfrac {1} {\ deltaの} \ right）$、ここで（0、1）。私たちの結果は、$ \ mathcal {O} \ left（\ dfrac {\ epsilon ^ {-9} \ chi ^ {\ frac {3} {2}}} {が必要な場合に、最先端の結果を大幅に改善します。 \ delta} \ log \ dfrac {1} {\ epsilon \ chi} \ right）$。私たちの分析は、パラメーター空間R ^（p）を3つの非交差領域（非停留点、鞍点、局所最適領域）に分解し、それぞれのRLの目的を局所的に改善するという重要なアイデアに基づいています。領域。この手法は、広範なポリシー勾配法に一般化できる可能性があります。,https://d3i71xaburhd42.cloudfront.net/f2f6502c85228c2dc69f712798f2aba54241d7d6/6-Figure1-1.png
Exploring Explainable Selection to Control Abstractive Summarization,"['Haonan Wang', 'Yang Gao', 'Yu Bai', 'Mirella Lapata', 'Heyan Huang']",,,,
Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning,"['Elad Amrani', 'Rami Ben-Ari', 'Daniel Rotman', 'Alex Bronstein']",,,,
Turbocharging Treewidth-Bounded Bayesian Network Structure Learning,"['P. R. Vaidyanathan', 'Stefan Szeider']",,,,
Tightening Robustness Verification of Convolutional Neural Networks with Fine-Grained Linear Approximation,"['Yiting Wu', 'Min Zhang']",,,,
A Sharp Leap from Quantified Boolean Formula to Stochastic Boolean Satisfiability Solving,"['Pei-Wei Chen', 'Yu-Ching Huang', 'Jie-Hong R Jiang']",,,,
Loop Estimator for Discounted Values in Markov Reward Processes,"['Falcon Dai', 'Matthew Walter']",https://arxiv.org/abs/2002.06299,"At the working heart of policy iteration algorithms commonly used and studied in the discounted setting of reinforcement learning, the policy evaluation step estimates the value of state with samples from a Markov reward process induced by following a Markov policy in a Markov decision process. We propose a simple and efficient estimator called \emph{loop estimator} that exploits the regenerative structure of Markov reward processes without explicitly estimating a full model. Our method enjoys a space complexity of $O(1)$ when estimating the value of a single positive recurrent state $s$ unlike TD with $O(S)$ or model-based methods with $O\left(S^2\right)$. Moreover, the regenerative structure enables us to show, without relying on the generative model approach, that the estimator has an instance-dependent convergence rate of $\widetilde{O}\left(\sqrt{\tau_s/T}\right)$ over steps $T$ on a single sample path, where $\tau_s$ is the maximal expected hitting time to state $s$. In preliminary numerical experiments, the loop estimator outperforms model-free methods, such as TD(k), and is competitive with the model-based estimator.",強化学習の割引設定で一般的に使用および研究されているポリシー反復アルゴリズムの中心で、ポリシー評価ステップは、マルコフ決定プロセスでマルコフポリシーに従うことによって誘導されるマルコフ報酬プロセスからのサンプルを使用して状態の値を推定します。完全なモデルを明示的に推定することなく、マルコフ報酬プロセスの再生構造を活用するループ推定量と呼ばれる単純で効率的な推定量を提案します。私たちの方法は、O（S）を使用したTDやO（S2）を使用したモデルベースの方法とは異なり、単一の正の再発状態の値を推定するときにO（1）の空間の複雑さを享受します。さらに、再生構造により、生成モデルアプローチに依存することなく、推定量のインスタンス依存の収束率が$ \ widetilde {O} \ left（\ sqrt {\ taus / T} \ right）$であることを示すことができます。単一のサンプルパス上のステップTで、（s）は状態sまでの最大予想ヒット時間です。予備的な数値実験では、ループ推定器はTD（k）などのモデルフリーの方法よりも優れており、モデルベースの推定器と競合します。,https://d3i71xaburhd42.cloudfront.net/6a3cd40b02d310faf807338949132ea148e12315/5-Figure1-1.png
Liquid Time-Constant Networks,"['Ramin Hasani', 'Mathias Lechner', 'Alexander Amini', 'Daniela Rus', 'Radu Grosu']",https://arxiv.org/abs/2006.04439,"We introduce a new class of time-continuous recurrent neural network models. Instead of declaring a learning system's dynamics by implicit nonlinearities, we construct networks of linear first-order dynamical systems modulated via nonlinear interlinked gates. The resulting models represent dynamical systems with varying (i.e., \emph{liquid}) time-constants coupled to their hidden state, with outputs being computed by numerical differential equation solvers. These neural networks exhibit stable and bounded behavior, yield superior expressivity within the family of neural ordinary differential equations, and give rise to improved performance on time-series prediction tasks. To demonstrate these properties, we first take a theoretical approach to find bounds over their dynamics, and compute their expressive power by the \emph{trajectory length} measure in a latent trajectory space. We then conduct a series of time-series prediction experiments to manifest the approximation capability of Liquid Time-Constant Networks (LTCs) compared to modern RNNs. Code and data are available at this https URL",新しいクラスの時間連続リカレントニューラルネットワークモデルを紹介します。暗黙の非線形性によって学習システムのダイナミクスを宣言する代わりに、非線形の相互リンクされたゲートを介して変調された線形1次動的システムのネットワークを構築します。結果として得られるモデルは、さまざまな（つまり液体の）時定数が隠れた状態に結合された動的システムを表しており、出力は数値微分方程式ソルバーによって計算されます。これらのニューラルネットワークは、安定した制限された動作を示し、ニューラル常微分方程式のファミリー内で優れた表現力を生み出し、時系列予測タスクのパフォーマンスを向上させます。これらの特性を実証するために、まず理論的アプローチを採用してダイナミクスの境界を見つけ、潜在軌道空間での軌道長さの尺度によって表現力を計算します。次に、一連の時系列予測実験を実行して、最新のRNNと比較したLiquid Time-Constant Networks（LTC）の近似機能を明らかにします。コードとデータはこのhttpsURLで入手できます,https://d3i71xaburhd42.cloudfront.net/1b9a07702cd346673b4c5e798d2256157fab1d3f/1-Figure1-1.png
The Heads Hypothesis: A Unifying Statistical Approach towards Understanding Multi-Headed Attention in BERT,"['Madhura Pande', 'Aakriti Budhraja', 'Preksha Nema', 'Pratyush Kumar', 'Mitesh M. Khapra']",https://arxiv.org/abs/2101.09115,"Multi-headed attention heads are a mainstay in transformerbased models. Different methods have been proposed to classify the role of each attention head based on the relations between tokens which have high pair-wise attention. These roles include syntactic (tokens with some syntactic relation), local (nearby tokens), block (tokens in the same sentence) and delimiter (the special [CLS], [SEP] tokens). There are two main challenges with existing methods for classification: (a) there are no standard scores across studies or across functional roles, and (b) these scores are often average quantities measured across sentences without capturing statistical significance. In this work, we formalize a simple yet effective score that generalizes to all the roles of attention heads and employs hypothesis testing on this score for robust inference. This provides us the right lens to systematically analyze attention heads and confidently comment on many commonly posed questions on analyzing the BERT model. In particular, we comment on the co-location of multiple functional roles in the same attention head, the distribution of attention heads across layers, and effect of fine-tuning for specific NLP tasks on these functional roles. Code is made publicly available. 1",マルチヘッドアテンションヘッドは、トランスベースモデルの主力です。ペアワイズ注意が高いトークン間の関係に基づいて、各注意ヘッドの役割を分類するために、さまざまな方法が提案されています。これらの役割には、構文（構文関係のあるトークン）、ローカル（近くのトークン）、ブロック（同じ文のトークン）、および区切り文字（特別な[CLS]、[SEP]トークン）が含まれます。既存の分類方法には2つの主な課題があります。（a）研究間または機能的役割間で標準スコアがないこと、および（b）これらのスコアは、統計的有意性を取得せずに文全体で測定された平均量であることがよくあります。この作業では、注意の頭のすべての役割に一般化するシンプルで効果的なスコアを形式化し、このスコアで仮説検定を使用して堅牢な推論を行います。これにより、注意の頭を体系的に分析し、BERTモデルの分析に関してよく寄せられる多くの質問に自信を持ってコメントするための適切なレンズが提供されます。特に、同じアテンションヘッド内の複数の機能的役割のコロケーション、レイヤー間のアテンションヘッドの分散、およびこれらの機能的役割に対する特定のNLPタスクの微調整の影響についてコメントします。コードは公開されています。 1,https://d3i71xaburhd42.cloudfront.net/dd24067c396f4b5a6500a71101ff1dc8ccb8811f/4-Figure1-1.png
End-to-End Semantic Role Labeling with Neural Transition-Based Model,"['Hao Fei', 'Meishan Zhang', 'Bobo Li', 'Donghong Ji']",https://arxiv.org/abs/2101.00394,"End-to-end semantic role labeling (SRL) has been received increasing interest. It performs the two subtasks of SRL: predicate identification and argument role labeling, jointly. Recent work is mostly focused on graph-based neural models, while the transition-based framework with neural networks which has been widely used in a number of closely-related tasks, has not been studied for the joint task yet. In this paper, we present the first work of transition-based neural models for end-to-end SRL. Our transition model incrementally discovers all sentential predicates as well as their arguments by a set of transition actions. The actions of the two subtasks are executed mutually for full interactions. Besides, we suggest high-order compositions to extract non-local features, which can enhance the proposed transition model further. Experimental results on CoNLL09 and Universal Proposition Bank show that our final model can produce state-of-the-art performance, and meanwhile keeps highly efficient in decoding. We also conduct detailed experimental analysis for a deep understanding of our proposed model.",エンドツーエンドのセマンティックロールラベリング（SRL）への関心が高まっています。これは、SRLの2つのサブタスクである述語の識別と引数の役割のラベル付けを共同で実行します。最近の研究は主にグラフベースのニューラルモデルに焦点を当てていますが、密接に関連する多くのタスクで広く使用されているニューラルネットワークを使用した遷移ベースのフレームワークは、共同タスクについてはまだ研究されていません。この論文では、エンドツーエンドSRLの遷移ベースのニューラルモデルの最初の作業を紹介します。私たちの遷移モデルは、一連の遷移アクションによって、すべてのセンテンス述語とそれらの引数を段階的に検出します。 2つのサブタスクのアクションは、完全な相互作用のために相互に実行されます。さらに、提案された遷移モデルをさらに強化できる非局所的特徴を抽出するための高次組成を提案します。 CoNLL09とUniversalProposition Bankの実験結果は、私たちの最終モデルが最先端のパフォーマンスを生み出すことができ、その一方でデコードにおいて非常に効率的であることを示しています。また、提案モデルを深く理解するために、詳細な実験分析を行っています。,https://d3i71xaburhd42.cloudfront.net/4ec3ad4df9b5b856184def79404312958d9f0fe5/1-Figure1-1.png
A General Offline Reinforcement Learning Framework for Interactive Recommendation,"['Teng Xiao', 'Donglin Wang']",,,,
Efficient Certification of Spatial Robustness,"['Anian Ruoss', 'Maximilian Baader', 'Mislav Balunovic', 'Martin Vechev']",https://arxiv.org/abs/2009.09318,"Recent work has exposed the vulnerability of computer vision models to spatial transformations. Due to the widespread usage of such models in safety-critical applications, it is crucial to quantify their robustness against spatial transformations. However, existing work only provides empirical quantification of spatial robustness via adversarial attacks, which lack provable guarantees. In this work, we propose novel convex relaxations, which enable us, for the first time, to provide a certificate of robustness against spatial transformations. Our convex relaxations are model-agnostic and can be leveraged by a wide range of neural network verifiers. Experiments on several network architectures and different datasets demonstrate the effectiveness and scalability of our method.",最近の研究により、コンピュータービジョンモデルの脆弱性が空間変換にさらされています。セーフティクリティカルなアプリケーションでこのようなモデルが広く使用されているため、空間変換に対するロバスト性を定量化することが重要です。ただし、既存の作業では、敵対的攻撃による空間的堅牢性の経験的定量化しか提供されておらず、証明可能な保証がありません。この作業では、初めて、空間変換に対するロバスト性の証明書を提供することを可能にする、新しい凸状緩和を提案します。私たちの凸状緩和はモデルにとらわれず、幅広いニューラルネットワーク検証器で活用できます。いくつかのネットワークアーキテクチャとさまざまなデータセットでの実験は、私たちの方法の有効性とスケーラビリティを示しています。,https://d3i71xaburhd42.cloudfront.net/0892b242f64779c95eb7dec11c603555573b45c3/1-Figure1-1.png
Exploiting Unlabeled Data via Partial Label Assignment for Multi-Class Semi-Supervised Learning,"['Zhen-Ru Zhang', 'Qian-Wen Zhang', 'Yunbo Cao', 'Min-Ling Zhang']",,,,
On-Line Learning of Planning Domains from Sensor Data in PAL: Scaling up to Large State Spaces,"['Leonardo Lamanna', 'Alfonso Gerevini', 'Alessandro Saetti', 'Luciano Serafini', 'Paolo Traverso']",,"We propose an approach to learn an extensional representation of a discrete deterministic planning domain from observations in a continuous space navigated by the agent actions. This is achieved through the use of a perception function providing the likelihood of a real-value observation being in a given state of the planning domain after executing an action. The agent learns an extensional representation of the domain (the set of states, the transitions from states to states caused by actions) and the perception function on-line, while it acts for accomplishing its task. In order to provide a practical approach that can scale up to large state spaces, a “sketched” intensional (PDDL-based) model of the planning domain is used to guide the exploration of the environment and learn the states and state transitions. The proposed approach uses a novel algorithm to (i) construct the extensional representation of the domain by interleaving symbolic planning in the PDDL intensional representation and search in the state-transition graph of the extensional representation; (ii) incrementally refine the intensional representation taking into account information about the actions that the agent cannot execute. An experimental analysis shows that the novel approach can scale up to large state spaces, thus overcoming the limits in scalability of the previous work.",エージェントのアクションによってナビゲートされる連続空間での観測から、離散的な決定論的計画ドメインの拡張表現を学習するアプローチを提案します。これは、アクションの実行後に実際の値の観測値が計画ドメインの特定の状態にある可能性を提供する知覚関数を使用することで実現されます。エージェントは、ドメインの拡張表現（状態のセット、アクションによって引き起こされる状態から状態への遷移）と認識機能をオンラインで学習し、そのタスクを実行します。大きな状態空間にスケールアップできる実用的なアプローチを提供するために、計画ドメインのスケッチされた内包（PDDLベース）モデルを使用して、環境の探索をガイドし、状態と状態遷移を学習します。提案されたアプローチは、新しいアルゴリズムを使用して、（i）PDDL内包表現でシンボリック計画をインターリーブし、拡張表現の状態遷移グラフで検索することにより、ドメインの拡張表現を構築します。 （ii）エージェントが実行できないアクションに関する情報を考慮して、内包的表現を段階的に改良します。実験的分析は、新しいアプローチが大きな状態空間にスケールアップできることを示しており、したがって、前の作業のスケーラビリティの限界を克服しています。,https://d3i71xaburhd42.cloudfront.net/9dbfe15981311081db7ae576690ed81c1badba92/3-Figure1-1.png
Weighting-Based Variable Neighborhood Search for Optimal Camera Placement,"['Zhouxing Su', 'Qingyun Zhang', 'Zhipeng Lü', 'Chumin Li', 'Weibo Lin', 'Fuda Ma']",,,,
Token-Aware Virtual Adversarial Training in Natural Language Understanding,"['Linyang Li', 'Xipeng Qiu']",,,,
An Information-Theoretic Framework for Unifying Active Learning Problems,"['Quoc Phong Nguyen', 'Bryan Kian Hsiang Low', 'Patrick Jaillet']",https://arxiv.org/abs/2012.10695,"This paper presents an information-theoretic framework for unifying active learning problems: level set estimation (LSE), Bayesian optimization (BO), and their generalized variant. We first introduce a novel active learning criterion that subsumes an existing LSE algorithm and achieves state-of-theart performance in LSE problems with a continuous input domain. Then, by exploiting the relationship between LSE and BO, we design a competitive information-theoretic acquisition function for BO that has interesting connections to upper confidence bound and max-value entropy search (MES). The latter connection reveals a drawback of MES which has important implications on not only MES but also on other MES-based acquisition functions. Finally, our unifying information-theoretic framework can be applied to solve a generalized problem of LSE and BO involving multiple level sets in a data-efficient manner. We empirically evaluate the performance of our proposed algorithms using synthetic benchmark functions, a real-world dataset, and in hyperparameter tuning of machine learning models.",この論文は、能動学習問題を統合するための情報理論的フレームワークを提示します：レベル集合推定（LSE）、ベイズ最適化（BO）、およびそれらの一般化された変形。最初に、既存のLSEアルゴリズムを包含し、連続入力ドメインを使用したLSE問題で最先端のパフォーマンスを実現する新しいアクティブラーニング基準を紹介します。次に、LSEとBOの関係を利用して、信頼限界の上限と最大値エントロピー検索（MES）に興味深い関係があるBOの競争力のある情報理論的取得関数を設計します。後者の接続は、MESだけでなく、他のMESベースの取得機能にも重要な影響を与えるMESの欠点を明らかにします。最後に、私たちの統合情報理論フレームワークは、データ効率の高い方法で複数のレベルセットを含むLSEとBOの一般化された問題を解決するために適用できます。合成ベンチマーク関数、実際のデータセット、および機械学習モデルのハイパーパラメータ調整を使用して、提案されたアルゴリズムのパフォーマンスを経験的に評価します。,https://d3i71xaburhd42.cloudfront.net/c55349c6f4e93eb4ab4c1d2a3167a0c52f2bc3ba/3-Figure1-1.png
On the Verification of Neural ODEs with Stochastic Guarantees,"['Sophie Grünbacher', 'Ramin Hasani', 'Mathias Lechner', 'Jacek Cyranka', 'Scott A. Smolka', 'Radu Grosu']",,,,
Minimax Regret Optimisation for Robust Planning in Uncertain Markov Decision Processes,"['Marc Rigter', 'Bruno Lacerda', 'Nick Hawes']",https://arxiv.org/abs/2012.04626,"The parameters for a Markov Decision Process (MDP) often cannot be specified exactly. Uncertain MDPs (UMDPs) capture this model ambiguity by defining sets which the parameters belong to. Minimax regret has been proposed as an objective for planning in UMDPs to find robust policies which are not overly conservative. In this work, we focus on planning for Stochastic Shortest Path (SSP) UMDPs with uncertain cost and transition functions. We introduce a Bellman equation to compute the regret for a policy. We propose a dynamic programming algorithm that utilises the regret Bellman equation, and show that it optimises minimax regret exactly for UMDPs with independent uncertainties. For coupled uncertainties, we extend our approach to use options to enable a trade off between computation and solution quality. We evaluate our approach on both synthetic and real-world domains, showing that it significantly outperforms existing baselines.",マルコフ決定過程（MDP）のパラメーターは、正確に指定できないことがよくあります。不確実なMDP（UMDP）は、パラメーターが属するセットを定義することにより、このモデルのあいまいさをキャプチャします。ミニマックスの後悔は、過度に保守的ではない堅牢なポリシーを見つけるためにUMDPで計画する目的として提案されています。この作業では、コストと遷移関数が不確実な確率的最短経路（SSP）UMDPの計画に焦点を当てます。ポリシーに対する後悔を計算するためのベルマン方程式を導入します。後悔ベルマン方程式を利用する動的計画法アルゴリズムを提案し、独立した不確実性を持つUMDPに対して正確にミニマックス後悔を最適化することを示します。結合された不確実性については、オプションを使用して計算とソリューション品質の間のトレードオフを可能にするアプローチを拡張します。合成ドメインと実世界ドメインの両方でアプローチを評価し、既存のベースラインを大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/fd57b053a67826416ec24cea3cf0054770edf897/7-Figure1-1.png
Planning from Pixels in Atari with Learned Symbolic Representations,"['Andrea Dittadi', 'Frederik K Drachmann', 'Thomas Bolander']",https://arxiv.org/abs/2012.09126,"Width-based planning methods have been shown to yield state-of-the-art performance in the Atari 2600 domain using pixel input. One successful approach, RolloutIW, represents states with the B-PROST boolean feature set. An augmented version of RolloutIW, $\pi$-IW, shows that learned features can be competitive with handcrafted ones for width-based search. In this paper, we leverage variational autoencoders (VAEs) to learn features directly from pixels in a principled manner, and without supervision. The inference model of the trained VAEs extracts boolean features from pixels, and RolloutIW plans with these features. The resulting combination outperforms the original RolloutIW and human professional play on Atari 2600 and drastically reduces the size of the feature set.",幅ベースの計画方法は、ピクセル入力を使用してAtari2600ドメインで最先端のパフォーマンスを実現することが示されています。成功したアプローチの1つであるRolloutIWは、B-PROSTブール機能セットを使用して状態を表します。 RolloutIWの拡張バージョンである-IWは、学習された機能が、幅ベースの検索で手作りの機能と競合する可能性があることを示しています。このホワイトペーパーでは、変分オートエンコーダ（VAE）を活用して、監視なしで、原理的にピクセルから直接特徴を学習します。トレーニングされたVAEの推論モデルは、ピクセルからブール値の特徴を抽出し、RolloutIWはこれらの特徴を使用して計画します。結果として得られる組み合わせは、Atari 2600での元のRolloutIWと人間のプロのプレイを上回り、機能セットのサイズを大幅に削減します。,https://d3i71xaburhd42.cloudfront.net/dd68f268c88005c5b281147e0d775bd80a92d73a/6-Figure1-1.png
Randomized Generation of Adversary-Aware Fake Knowledge Graphs to Combat Intellectual Property Theft,"['Snow Kang', 'Cristian Molinaro', 'Andrea Pugliese', 'V. S. Subrahmanian']",,,,
Progressive Network Grafting for Few-Shot Knowledge Distillation,"['Chengchao Shen', 'Xinchao Wang', 'Youtan Yin', 'Jie Song', 'Sihui Luo', 'Mingli Song']",https://arxiv.org/abs/2012.04915,"Knowledge distillation has demonstrated encouraging performances in deep model compression. Most existing approaches, however, require massive labeled data to accomplish the knowledge transfer, making the model compression a cumbersome and costly process. In this paper, we investigate the practical few-shot knowledge distillation scenario, where we assume only a few samples without human annotations are available for each category. To this end, we introduce a principled dual-stage distillation scheme tailored for few-shot data. In the first step, we graft the student blocks one by one onto the teacher, and learn the parameters of the grafted block intertwined with those of the other teacher blocks. In the second step, the trained student blocks are progressively connected and then together grafted onto the teacher network, allowing the learned student blocks to adapt themselves to each other and eventually replace the teacher network. Experiments demonstrate that our approach, with only a few unlabeled samples, achieves gratifying results on CIFAR10, CIFAR100, and ILSVRC-2012. On CIFAR10 and CIFAR100, our performances are even on par with those of knowledge distillation schemes that utilize the full datasets. The source code is available at https://github.com/zju-vipa/NetGraft.",知識の蒸留は、深いモデル圧縮で有望なパフォーマンスを示しています。ただし、ほとんどの既存のアプローチでは、知識の伝達を実現するために大量のラベル付きデータが必要であるため、モデルの圧縮は面倒でコストのかかるプロセスになります。この論文では、実際の数ショットの知識蒸留シナリオを調査します。ここでは、人間の注釈のない少数のサンプルのみが各カテゴリで利用可能であると想定しています。この目的のために、我々は、数ショットのデータに合わせて調整された原理的な二段蒸留スキームを紹介します。最初のステップでは、生徒のブロックを1つずつ教師に移植し、他の教師のブロックのパラメータと絡み合った移植されたブロックのパラメータを学習します。 2番目のステップでは、トレーニングを受けた生徒のブロックが徐々に接続され、教師のネットワークに一緒に移植されます。これにより、学習した生徒のブロックが互いに適応し、最終的に教師のネットワークに置き換わります。実験は、ラベルのないサンプルがわずかしかない私たちのアプローチが、CIFAR10、CIFAR100、およびILSVRC-2012で満足のいく結果を達成することを示しています。 CIFAR10およびCIFAR100では、完全なデータセットを利用する知識蒸留スキームのパフォーマンスと同等のパフォーマンスが得られます。ソースコードはhttps://github.com/zju-vipa/NetGraftで入手できます。,https://d3i71xaburhd42.cloudfront.net/883ea3b74ec1e26ad20f2c5c94f45e0d6db16364/3-Figure1-1.png
Probabilistic Programming Bots in Intuitive Physics Game Play,"['Fahad Alhasoun', 'Sarah Alnegheimish']",,,,
UWSpeech: Speech to Speech Translation for Unwritten Languages,"['Chen Zhang', 'Xu Tan', 'Yi Ren', 'Tao Qin', 'Kejun Zhang', 'Tieyan Liu']",https://arxiv.org/abs/2006.07926,"Existing speech to speech translation systems heavily rely on the text of target language: they usually translate source language either to target text and then synthesize target speech from text, or directly to target speech with target text for auxiliary training. However, those methods cannot be applied to unwritten target languages, which have no written text or phoneme available. In this paper, we develop a translation system for unwritten languages, named as UWSpeech, which converts target unwritten speech into discrete tokens with a converter, and then translates source-language speech into target discrete tokens with a translator, and finally synthesizes target speech from target discrete tokens with an inverter. We propose a method called XL-VAE, which enhances vector quantized variational autoencoder (VQ-VAE) with cross-lingual (XL) speech recognition, to train the converter and inverter of UWSpeech jointly. Experiments on Fisher Spanish-English conversation translation dataset show that UWSpeech outperforms direct translation and VQ-VAE baseline by about 16 and 10 BLEU points respectively, which demonstrate the advantages and potentials of UWSpeech.",既存の音声から音声への翻訳システムは、ターゲット言語のテキストに大きく依存しています。通常、ソース言語をターゲットテキストに翻訳してから、テキストからターゲット音声を合成するか、補助トレーニングのためにターゲットテキストを使用してターゲット音声に直接翻訳します。ただし、これらのメソッドは、書かれたテキストや音素が利用できない、書かれていないターゲット言語には適用できません。本稿では、UWSpeechという名前の未書き込み言語の翻訳システムを開発します。このシステムは、コンバーターを使用してターゲットの未書き込み音声を個別のトークンに変換し、次にトランスレーターを使用してソース言語の音声をターゲットの個別トークンに変換し、最後にインバーターで個別のトークンをターゲットにします。 UWSpeechのコンバーターとインバーターを共同でトレーニングするために、ベクトル量子化変分オートエンコーダー（VQ-VAE）をクロスリンガル（XL）音声認識で強化するXL-VAEと呼ばれる方法を提案します。フィッシャースペイン語-英語会話翻訳データセットでの実験は、UWSpeechが直接翻訳とVQ-VAEベースラインをそれぞれ約16と10 BLEUポイント上回っていることを示しており、UWSpeechの利点と可能性を示しています。,https://d3i71xaburhd42.cloudfront.net/e32669ec184f2beae7e47d8f29453b317ec0fd7d/3-Figure1-1.png
Variational Inference for Learning Representations of Natural Language Edits,"['Edison Marrese-Taylor', 'Machel O Reid', 'Yutaka Matsuo']",https://arxiv.org/abs/2004.09143,"Document editing has become a pervasive component of production of information, with version control systems enabling edits to be efficiently stored and applied. In light of this, the task of learning distributed representations of edits has been recently proposed. With this in mind, we propose a novel approach that employs variational inference to learn a continuous latent space of vector representations to capture the underlying semantic information with regard to the document editing process. We achieve this by introducing a latent variable to explicitly model the aforementioned features. This latent variable is then combined with a document representation to guide the generation of an edited-version of this document. Additionally, to facilitate standardized automatic evaluation of edit representations, which has heavily relied on direct human input thus far, we also propose a suite of downstream tasks, PEER, specifically designed to measure the quality of edit representations in the context of Natural Language Processing.",ドキュメント編集は、編集を効率的に保存および適用できるバージョン管理システムを備えた、情報生成の普及したコンポーネントになっています。これに照らして、編集の分散表現を学習するタスクが最近提案されました。これを念頭に置いて、変分推論を使用してベクトル表現の連続潜在空間を学習し、ドキュメント編集プロセスに関する基礎となるセマンティック情報をキャプチャする新しいアプローチを提案します。前述の機能を明示的にモデル化する潜在変数を導入することで、これを実現します。次に、この潜在変数をドキュメント表現と組み合わせて、このドキュメントの編集バージョンの生成をガイドします。さらに、これまで人間の直接入力に大きく依存してきた編集表現の標準化された自動評価を容易にするために、自然言語処理のコンテキストで編集表現の品質を測定するように特別に設計された一連のダウンストリームタスクPEERも提案します。,https://d3i71xaburhd42.cloudfront.net/305df7fdd241ba877fd8914e108ec0a056eb7a27/5-Figure1-1.png
Analogy Training Multilingual Encoders,"['Nicolas Garneau', 'Mareike Hartmann', 'Anders T Sandholm', 'Sebastian Ruder', 'Ivan Vulić', 'Anders Søgaard']",,,,
Teaching the Old Dog New Tricks: Supervised Learning with Constraints,"['Fabrizio Detassis', 'Michele Lombardi', 'Michela Milano']",https://arxiv.org/abs/2002.10766,"Methods for taking into account external knowledge in Machine Learning models have the potential to address outstanding issues in data-driven AI methods, such as improving safety and fairness, and can simplify training in the presence of scarce data. We propose a simple, but effective, method for injecting constraints at training time in supervised learning, based on decomposition and bi-level optimization: a master step is in charge of enforcing the constraints, while a learner step takes care of training the model. The process leads to approximate constraint satisfaction. The method is applicable to any ML approach for which the concept of label (or target) is well defined (most regression and classification scenarios), and allows to reuse existing training algorithms with no modifications. We require no assumption on the constraints, although their properties affect the shape and complexity of the master problem. Convergence guarantees are hard to provide, but we found that the approach performs well on ML tasks with fairness constraints and on classical datasets with synthetic constraints.",機械学習モデルで外部の知識を考慮に入れる方法は、安全性と公平性の向上など、データ駆動型AI方法の未解決の問題に対処する可能性があり、データが不足している場合のトレーニングを簡素化できます。分解と2レベルの最適化に基づいて、教師あり学習のトレーニング時に制約を挿入するためのシンプルで効果的な方法を提案します。マスターステップが制約の適用を担当し、学習者ステップがモデルのトレーニングを担当します。このプロセスにより、おおよその制約が満たされます。この方法は、ラベル（またはターゲット）の概念が明確に定義されているすべてのMLアプローチ（ほとんどの回帰および分類シナリオ）に適用でき、変更なしで既存のトレーニングアルゴリズムを再利用できます。それらの特性はマスター問題の形状と複雑さに影響しますが、制約についての仮定は必要ありません。収束の保証を提供するのは困難ですが、このアプローチは、公平性の制約があるMLタスクと、合成の制約がある従来のデータセットでうまく機能することがわかりました。,https://d3i71xaburhd42.cloudfront.net/ec29a4b15eb1e501183a17ce5dc59af74abebee9/3-Figure1-1.png
Automated Cross-Prompt Scoring of Essay Traits,"['Robert Ridley', 'Liang He', 'Xin-yu Dai', 'Shujian Huang', 'Jiajun Chen']",,,,
Commonsense Knowledge Augmentation for Low-Resource Languages via Adversarial Learning,"['Bosung Kim', 'Juae Kim', 'Youngjoong Ko', 'Jungyun Seo']",,,,
Towards Generalized Implementation of Wasserstein Distance in GANs,['Minkai Xu'],https://arxiv.org/abs/2012.03420,"Wasserstein GANs (WGANs), built upon the Kantorovich-Rubinstein (KR) duality of Wasserstein distance, is one of the most theoretically sound GAN models. However, in practice it does not always outperform other variants of GANs. This is mostly due to the imperfect implementation of the Lipschitz condition required by the KR duality. Extensive work has been done in the community with different implementations of the Lipschitz constraint, which, however, is still hard to satisfy the restriction perfectly in practice. In this paper, we argue that the strong Lipschitz constraint might be unnecessary for optimization. Instead, we take a step back and try to relax the Lipschitz constraint. Theoretically, we first demonstrate a more general dual form of the Wasserstein distance called the Sobolev duality, which relaxes the Lipschitz constraint but still maintains the favorable gradient property of the Wasserstein distance. Moreover, we show that the KR duality is actually a special case of the Sobolev duality. Based on the relaxed duality, we further propose a generalized WGAN training scheme named Sobolev Wasserstein GAN (SWGAN), and empirically demonstrate the improvement of SWGAN over existing methods with extensive experiments.",ワッサースタイン距離のカントロビッチ-ルビンスタイン（KR）双対性に基づいて構築されたワッサースタインGAN（WGAN）は、最も理論的に健全なGANモデルの1つです。ただし、実際には、GANの他のバリアントよりも常に優れているとは限りません。これは主に、KRの二重性に必要なリプシッツ条件の不完全な実装によるものです。リプシッツ制約のさまざまな実装を使用してコミュニティで広範な作業が行われていますが、実際には制限を完全に満たすのは依然として困難です。この論文では、強いリプシッツ制約は最適化には不要かもしれないと主張します。代わりに、一歩下がってリプシッツ制約を緩和しようとします。理論的には、最初に、ソボレフ双対性と呼ばれるワッサースタイン距離のより一般的な二重形式を示します。これは、リプシッツ制約を緩和しますが、ワッサースタイン距離の好ましい勾配特性を維持します。さらに、KR双対性が実際にはソボレフ双対性の特殊なケースであることを示します。緩和された二重性に基づいて、Sobolev Wasserstein GAN（SWGAN）という名前の一般化されたWGANトレーニングスキームをさらに提案し、広範な実験で既存の方法に対するSWGANの改善を経験的に示します。,
Foresee then Evaluate: Decomposing Value Estimation with Latent Future Prediction,"['Hongyao Tang', 'Zhaopeng Meng', 'Guangyong Chen', 'Pengfei Chen', 'Chen Chen', 'Yaodong Yang', 'Luo Zhang', 'Wulong Liu', 'Jianye Hao']",,,,
Modular Graph Transformer Networks for Multi-Label Image Classification,"['Hoang D. Nguyen', 'Xuan-Son Vu', 'Duc-Trong Le']",,,,
IB-GAN: Disengangled Representation Learning with Information Bottleneck Generative Adversarial Networks,"['Insu Jeon', 'Wonkwang Lee', 'Myeongjang Pyeon', 'Gunhee Kim']",,,,
Using Hindsight to Anchor Past Knowledge in Continual Learning,"['Arslan Chaudhry', 'Albert Gordo', 'Puneet Dokania', 'Philip Torr', 'David Lopez-Paz']",https://arxiv.org/abs/2002.08165,"In continual learning, the learner faces a stream of data whose distribution changes over time. Modern neural networks are known to suffer under this setting, as they quickly forget previously acquired knowledge. To address such catastrophic forgetting, many continual learning methods implement different types of experience replay, re-learning on past data stored in a small buffer known as episodic memory. In this work, we complement experience replay with a new objective that we call anchoring, where the learner uses bilevel optimization to update its knowledge on the current task, while keeping intact the predictions on some anchor points of past tasks. These anchor points are learned using gradient-based optimization to maximize forgetting, which is approximated by fine-tuning the currently trained model on the episodic memory of past tasks. Experiments on several supervised learning benchmarks for continual learning demonstrate that our approach improves the standard experience replay in terms of both accuracy and forgetting metrics and for various sizes of episodic memories.",継続学習では、学習者は、時間の経過とともに分布が変化するデータのストリームに直面します。現代のニューラルネットワークは、以前に取得した知識をすぐに忘れてしまうため、この設定で苦しむことが知られています。このような壊滅的な忘却に対処するために、多くの継続的な学習方法は、エピソード記憶と呼ばれる小さなバッファーに保存された過去のデータを再学習する、さまざまなタイプの体験再生を実装します。この作業では、学習者が過去のタスクのいくつかのアンカーポイントの予測をそのまま維持しながら、バイレベル最適化を使用して現在のタスクに関する知識を更新する、アンカーと呼ばれる新しい目的でエクスペリエンスリプレイを補完します。これらのアンカーポイントは、忘却を最大化するための勾配ベースの最適化を使用して学習されます。これは、過去のタスクのエピソード記憶で現在トレーニングされているモデルを微調整することで近似されます。継続学習のためのいくつかの教師あり学習ベンチマークでの実験は、私たちのアプローチが、精度と忘却の両方の指標、およびさまざまなサイズのエピソード記憶の点で、標準的な体験の再生を改善することを示しています。,https://d3i71xaburhd42.cloudfront.net/680f1bf7c3635e87d4064a2757ec0d68c01d69f3/7-Figure1-1.png
End-to-End Differentiable Learning to HDR Image Synthesis for Multi-Exposure Images,"['Junghee Kim', 'Siyeong Lee', 'Suk-Ju Kang']",https://arxiv.org/abs/2006.15833,"Recent deep learning-based methods have reconstructed a high dynamic range (HDR) image from a single low dynamic range (LDR) image by focusing on the exposure transfer task to reconstruct the multi-exposure stack. However, these methods often fail to fuse the multi-exposure stack into a perceptually pleasant HDR image as the local inversion artifacts are formed in the HDR imaging (HDRI) process. The artifacts arise from the impossibility of learning the whole HDRI process due to its non-differentiable structure of the camera response recovery. Therefore, we tackle the major challenge in stack reconstruction-based methods by proposing a novel framework with the fully differentiable HDRI process. Our framework enables a neural network to train the HDR image generation based on the end-to-end structure. Hence, a deep neural network can train the precise correlations between multi-exposure images in the HDRI process using our differentiable HDR synthesis layer. In addition, our network uses the image decomposition and the recursive process to facilitate the exposure transfer task and to adaptively respond to recursion frequency. The experimental results show that the proposed network outperforms the state-of-the-art quatitative and qualitative results in terms of both the exposure transfer tasks and the whole HDRI process.",最近の深層学習ベースの方法では、多重露光スタックを再構築するための露出転送タスクに焦点を当てることにより、単一の低ダイナミックレンジ（LDR）画像から高ダイナミックレンジ（HDR）画像を再構築しました。ただし、これらの方法では、HDRイメージング（HDRI）プロセスでローカル反転アーティファクトが形成されるため、多重露光スタックを知覚的に快適なHDR画像に融合できないことがよくあります。アーティファクトは、カメラの応答回復の構造を区別できないため、HDRIプロセス全体を学習できないことから発生します。したがって、完全に微分可能なHDRIプロセスを備えた新しいフレームワークを提案することにより、スタック再構築ベースの方法における主要な課題に取り組みます。私たちのフレームワークは、ニューラルネットワークがエンドツーエンドの構造に基づいてHDR画像生成をトレーニングすることを可能にします。したがって、ディープニューラルネットワークは、微分可能なHDR合成レイヤーを使用して、HDRIプロセスで多重露光画像間の正確な相関関係をトレーニングできます。さらに、私たちのネットワークは、画像分解と再帰的プロセスを使用して、露出転送タスクを容易にし、再帰的頻度に適応的に応答します。実験結果は、提案されたネットワークが、露出転送タスクとHDRIプロセス全体の両方の点で、最先端の定性的および定性的結果よりも優れていることを示しています。,https://d3i71xaburhd42.cloudfront.net/70216e8cd6312bfcae3f3639308acf520bcf1492/3-Figure1-1.png
Multi-Decoder Attention Model with Embedding Glimpse for Solving Vehicle Routing Problems,"['Liang Xin', 'Wen Song', 'Zhiguang Cao', 'Jie Zhang']",https://arxiv.org/abs/2012.10638,"We present a novel deep reinforcement learning method to learn construction heuristics for vehicle routing problems. In specific, we propose a Multi-Decoder Attention Model (MDAM) to train multiple diverse policies, which effectively increases the chance of finding good solutions compared with existing methods that train only one policy. A customized beam search strategy is designed to fully exploit the diversity of MDAM. In addition, we propose an Embedding Glimpse layer in MDAM based on the recursive nature of construction, which can improve the quality of each policy by providing more informative embeddings. Extensive experiments on six different routing problems show that our method significantly outperforms the state-of-the-art deep learning based models.",配車ルート問題の構築ヒューリスティックスを学習するための新しい深層強化学習法を提示します。具体的には、複数の多様なポリシーをトレーニングするためのマルチデコーダアテンションモデル（MDAM）を提案します。これにより、1つのポリシーのみをトレーニングする既存の方法と比較して、適切なソリューションを見つける可能性が効果的に高まります。カスタマイズされたビーム検索戦略は、MDAMの多様性を十分に活用するように設計されています。さらに、建設の再帰的な性質に基づいてMDAMに埋め込みの垣間見るレイヤーを提案します。これにより、より有益な埋め込みを提供することで、各ポリシーの品質を向上させることができます。 6つの異なるルーティング問題に関する広範な実験は、私たちの方法が最先端の深層学習ベースのモデルを大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/de741d317507e21d3f7d3f8107d5b685db455aff/3-Figure1-1.png
Augmented Partial Mutual Learning with Frame Masking for Video Captioning,"['Ke Lin', 'Zhuoxin Gan', 'Liwei Wang']",,,,
Joint Semantic Analysis with Document-Level Cross-Task Coherence Rewards,"['Rahul Aralikatte', 'Mostafa Abdou', 'Heather C Lent', 'Daniel Hershcovich', 'Anders Søgaard']",https://arxiv.org/abs/2010.05567,"Coreference resolution and semantic role labeling are NLP tasks that capture different aspects of semantics, indicating respectively, which expressions refer to the same entity, and what semantic roles expressions serve in the sentence. However, they are often closely interdependent, and both generally necessitate natural language understanding. Do they form a coherent abstract representation of documents? We present a neural network architecture for joint coreference resolution and semantic role labeling for English, and train graph neural networks to model the 'coherence' of the combined shallow semantic graph. Using the resulting coherence score as a reward for our joint semantic analyzer, we use reinforcement learning to encourage global coherence over the document and between semantic annotations. This leads to improvements on both tasks in multiple datasets from different domains, and across a range of encoders of different expressivity, calling, we believe, for a more holistic approach to semantics in NLP.",共参照解決とセマンティックロールラベリングは、セマンティクスのさまざまな側面をキャプチャするNLPタスクであり、それぞれ、どの式が同じエンティティを参照しているか、およびどのセマンティックロール式が文で機能するかを示します。しかし、それらはしばしば密接に相互依存しており、どちらも一般的に自然言語理解を必要とします。それらは文書の首尾一貫した抽象的な表現を形成しますか？英語の共同共参照解決と意味役割ラベリングのためのニューラルネットワークアーキテクチャを提示し、結合された浅い意味グラフのコヒーレンスをモデル化するためにグラフニューラルネットワークをトレーニングします。結果のコヒーレンススコアを共同セマンティックアナライザーの報酬として使用し、強化学習を使用して、ドキュメント全体およびセマンティックアノテーション間のグローバルコヒーレンスを促進します。これにより、さまざまなドメインの複数のデータセット内の両方のタスクが改善され、表現力の異なるさまざまなエンコーダー全体で、NLPのセマンティクスに対するより包括的なアプローチが求められると考えられます。,https://d3i71xaburhd42.cloudfront.net/506d05bf93b0807ae17ac990584d7aa5895c0f91/1-Figure1-1.png
Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning,"['Tuan Anh Nguyen', 'Hyewon Jeong', 'Eunho Yang', 'Sung Ju Hwang']",https://arxiv.org/abs/2006.12777,"Although recent multi-task learning methods have shown to be effective in improving the generalization of deep neural networks, they should be used with caution for safety-critical applications, such as clinical risk prediction. This is because even if they achieve improved task-average performance, they may still yield degraded performance on individual tasks, which may be critical (e.g., prediction of mortality risk). Existing asymmetric multi-task learning methods tackle this negative transfer problem by performing knowledge transfer from tasks with low loss to tasks with high loss. However, using loss as a measure of reliability is risky since it could be a result of overfitting. In the case of time-series prediction tasks, knowledge learned for one task (e.g., predicting the sepsis onset) at a specific timestep may be useful for learning another task (e.g., prediction of mortality) at a later timestep, but lack of loss at each timestep makes it difficult to measure the reliability at each timestep. To capture such dynamically changing asymmetric relationships between tasks in time-series data, we propose a novel temporal asymmetric multi-task learning model that performs knowledge transfer from certain tasks/timesteps to relevant uncertain tasks, based on feature-level uncertainty. We validate our model on multiple clinical risk prediction tasks against various deep learning models for time-series prediction, which our model significantly outperforms, without any sign of negative transfer. Further qualitative analysis of learned knowledge graphs by clinicians shows that they are helpful in analyzing the predictions of the model. Our final code is available at this https URL.",最近のマルチタスク学習方法は、ディープニューラルネットワークの一般化を改善するのに効果的であることが示されていますが、臨床リスク予測などのセーフティクリティカルなアプリケーションでは注意して使用する必要があります。これは、タスクの平均パフォーマンスが向上したとしても、個々のタスクのパフォーマンスが低下する可能性があるためです。これは重要な場合があります（たとえば、死亡リスクの予測）。既存の非対称マルチタスク学習方法は、損失の少ないタスクから損失の多いタスクへの知識の伝達を実行することにより、この負の伝達の問題に取り組みます。ただし、損失を信頼性の尺度として使用することは、過剰適合の結果である可能性があるため、リスクがあります。時系列予測タスクの場合、特定のタイムステップで1つのタスクについて学習した知識（敗血症の発症の予測など）は、後のタイムステップで別のタスク（死亡率の予測など）を学習するのに役立つ場合がありますが、損失はありません。各タイムステップで、各タイムステップでの信頼性を測定することは困難です。時系列データ内のタスク間のこのような動的に変化する非対称関係をキャプチャするために、機能レベルの不確実性に基づいて、特定のタスク/タイムステップから関連する不確実なタスクへの知識転送を実行する新しい時間非対称マルチタスク学習モデルを提案します。時系列予測のさまざまな深層学習モデルに対して、複数の臨床リスク予測タスクでモデルを検証します。このモデルは、負の転送の兆候がなく、大幅に優れています。臨床医による学習された知識グラフのさらなる定性分析は、それらがモデルの予測を分析するのに役立つことを示しています。最終的なコードは、このhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/4e9dcfe17312d8a4a6092afc36b37348923de347/2-Figure1-1.png
Empower Distantly Supervised Relation Extraction with Collaborative Adversarial Training,"['Tao Chen', 'Haochen Shi', 'Liyuan Liu', 'Siliang Tang', 'Jian Shao', 'Zhigang Chen', 'Yueting Zhuang']",,,,
Visual Pivoting for (Unsupervised) Entity Alignment,"['Fangyu Liu', 'Muhao Chen', 'Dan Roth', 'Nigel Collier']",https://arxiv.org/abs/2009.13603,"This work studies the use of visual semantic representations to align entities in heterogeneous knowledge graphs (KGs). Images are natural components of many existing KGs. By combining visual knowledge with other auxiliary information, we show that the proposed new approach, EVA, creates a holistic entity representation that provides strong signals for cross-graph entity alignment. Besides, previous entity alignment methods require human labelled seed alignment, restricting availability. EVA provides a completely unsupervised solution by leveraging the visual similarity of entities to create an initial seed dictionary (visual pivots). Experiments on benchmark data sets DBP15k and DWY15k show that EVA offers state-of-the-art performance on both monolingual and cross-lingual entity alignment tasks. Furthermore, we discover that images are particularly useful to align long-tail KG entities, which inherently lack the structural contexts necessary for capturing the correspondences.",この作業では、視覚的意味表現を使用して、異種知識グラフ（KG）内のエンティティを整列させます。画像は、多くの既存のKGの自然な構成要素です。視覚的知識を他の補助情報と組み合わせることにより、提案された新しいアプローチであるEVAが、クロスグラフエンティティの位置合わせに強力な信号を提供する全体的なエンティティ表現を作成することを示します。さらに、以前のエンティティアラインメント方法では、人間がラベルを付けたシードアラインメントが必要であり、可用性が制限されていました。 EVAは、エンティティの視覚的な類似性を活用して初期シードディクショナリ（視覚的なピボット）を作成することにより、完全に監視されていないソリューションを提供します。ベンチマークデータセットDBP15kおよびDWY15kでの実験は、EVAが単一言語およびクロスリンガルのエンティティアラインメントタスクの両方で最先端のパフォーマンスを提供することを示しています。さらに、画像は、対応をキャプチャするために必要な構造的コンテキストを本質的に欠いているロングテールKGエンティティを整列させるのに特に有用であることを発見しました。,https://d3i71xaburhd42.cloudfront.net/083b2d08cfce5cf397a965c29168c78eb1ddb1cb/2-Figure1-1.png
Deep Open Intent Classification with Adaptive Decision Boundary,"['Hanlei Zhang', 'Hua Xu', 'Ting-En Lin']",https://arxiv.org/abs/2012.10209,"Open intent classification is a challenging task in dialogue system. On the one hand, we should ensure the classification quality of known intents. On the other hand, we need to identify the open (unknown) intent during testing. Current models are limited in finding the appropriate decision boundary to balance the performance of both known and open intents. In this paper, we propose a post-processing method to learn the adaptive decision boundary (ADB) for open intent classification. We first utilize the labeled known intent samples to pre-train the model. Then, we use the well-trained features to automatically learn the adaptive spherical decision boundaries for each known intent. Specifically, we propose a new loss function to balance both the empirical risk and the open space risk. Our method does not need unknown samples and is free from modifying the model architecture. We find our approach is surprisingly insensitive with less labeled data and fewer known intents. Extensive experiments on three benchmark datasets show that our method yields significant improvements compared with the state-of-the-art methods.",オープンインテント分類は、対話システムにおける挑戦的なタスクです。一方では、既知の意図の分類品質を確保する必要があります。一方、テスト中にオープンな（不明な）意図を特定する必要があります。現在のモデルは、既知のインテントとオープンインテントの両方のパフォーマンスのバランスをとるための適切な決定境界を見つけることに制限があります。本論文では、オープンインテント分類のための適応決定境界（ADB）を学習するための後処理方法を提案した。まず、ラベル付けされた既知の意図サンプルを利用して、モデルを事前トレーニングします。次に、十分にトレーニングされた機能を使用して、既知の各意図の適応球形決定境界を自動的に学習します。具体的には、経験的リスクとオープンスペースリスクの両方のバランスをとるための新しい損失関数を提案します。私たちの方法は未知のサンプルを必要とせず、モデルアーキテクチャを変更する必要がありません。私たちのアプローチは、ラベル付けされたデータが少なく、既知の意図が少ないため、驚くほど鈍感であることがわかりました。 3つのベンチマークデータセットでの広範な実験は、私たちの方法が最先端の方法と比較して大幅な改善をもたらすことを示しています。,https://d3i71xaburhd42.cloudfront.net/39712b9d2a1f79c5cc41cad4076d4f4fdb9a2edc/1-Figure1-1.png
Movie Summarization via Sparse Graph Construction,"['Pinelopi Papalampidi', 'Frank Keller', 'Mirella Lapata']",https://arxiv.org/abs/2012.07536,"We summarize full-length movies by creating shorter videos containing their most informative scenes. We explore the hypothesis that a summary can be created by assembling scenes which are turning points (TPs), i.e., key events in a movie that describe its storyline. We propose a model that identifies TP scenes by building a sparse movie graph that represents relations between scenes and is constructed using multimodal information. According to human judges, the summaries created by our approach are more informative and complete, and receive higher ratings, than the outputs of sequence-based models and general-purpose summarization algorithms. The induced graphs are interpretable, displaying different topology for different movie genres. Introduction Automatic summarization has received considerable attention due to its importance for downstream applications. Although current research has primarily focused on news articles (Grusky, Naaman, and Artzi 2018; Narayan, Cohen, and Lapata 2018; Liu and Lapata 2019), other application domains include meetings (Murray et al. 2007), lectures (Fujii, Kitaoka, and Nakagawa 2007), social media (Syed et al. 2018), scientific articles (Teufel and Moens 2002), and narratives ranging from short stories (Goyal, Riloff, and Daumé III 2010; Finlayson 2012) to books (Mihalcea and Ceylan 2007), and movies (Gorinski and Lapata 2015). In this work, we aim at summarizing full-length movies by creating shorter video summaries encapsulating their most informative parts. Aside from enabling users to skim through movies quickly — Netflix alone has over 148 million subscribers worldwide, with more than 6000–7000 movies, series, and shows available — movie summarization is an ideal platform for real-world natural language understanding and the complex inferences associated with it. Movies are often based on elaborate stories, with non-linear structure and multiple characters, rendering the application of popular summarization approaches based on position biases, importance, and diversity problematic (Jung et al. 2019). Another key challenge in movie summarization lies in the scarcity of labeled Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. We make our data and code publicly available at https:// github.com/ppapalampidi/GraphTP. 1. Opportunity Introductory event that occurs after presentation of setting and background of main characters. (Juno discovers she is pregnant with a child fathered by her friend and longtime admirer.) 2. Change of Plans Main goal of story is defined; action begins to increase. (Juno decides to give the baby up for adoption.) 3. Point of No Return Event that pushes the main characters to fully commit to their goal. (Juno meets a couple, and agrees to a closed adoption.) 4. Major Setback Event where everything falls apart, temporarily or permanently. (Juno watches the couple’s marriage fall apart.) 5. Climax Final event of the main story, moment of resolution and “biggest spoiler”. (Juno gives birth and spouse from ex-couple claims newborn as single adoptive mother.) Figure 1: Turning points (from the movie “Juno”) and their definitions. data. For most movies there are no naturally occurring summaries (trailers aim to attract an audience to a film without revealing spoilers which a summary will contain), and manually creating these would be a major undertaking requiring substantial effort to collect, watch, preprocess, and annotate videos. As a result, the majority of available movie datasets contain at most a few hundred movies focusing on tasks like Question-Answering (QA) or the alignment between video clips and captions (Tapaswi et al. 2016; Xiong et al. 2019; Rohrbach et al. 2015) which are limited to video snippets rather than entire movies, or restricted to screenplays disregarding the video (Gorinski and Lapata 2015; Papalampidi et al. 2020). Following previous work (Gorinski and Lapata 2015), we formalize movie summarization as the selection of a few important scenes from a movie. We further assume that important scenes display events which determine the progression of the movie’s narrative and segment it into thematic sections. Screenwriting theory (Thompson 1999; Cutting 2016; Hauge 2017) reserves the term turning points (TPs) for events which have specific functionality inside a narrative and reveal its storyline. TPs are considered key for making successful movies whose stories are expected to consist of six basic stages, defined by five key turning points in the plot. An example of ar X iv :2 01 2. 07 53 6v 1 [ cs .C L ] 1 4 D ec 2 02 0 TPs and their definitions is given in Figure 1. Interestingly, TPs are assumed to be the same, no matter the movie genre, and occupy the same positions in the story (e.g., the Opportunity occurs after the first 10% of a 90-minute comedy or a three-hour epic). We propose that automatic movie summarization can be reduced to turning point identification building on earlier work (Lehnert 1981; Lohnert, Black, and Reiser 1981; Mihalcea and Ceylan 2007) which claims that high level analysis is necessary for revealing concepts central to a story. Although there exist several theories of narrative structure (Cutting 2016), we argue that turning points are ideally suited to summarizing movies for at least three reasons. Firstly, they are intuitive, and can be identified by naive viewers (Papalampidi, Keller, and Lapata 2019), so there is hope the process can be automated. Secondly, TPs have specific definitions and expected positions which facilitate automatic identification especially in low resource settings by providing prior knowledge (semantic and positional). Thirdly, they provide data efficiency, since the summarization problem is re-formulated as a scene-level classification task and no additional resources are required for creating the movie summaries over and above those developed for identifying turning points. We model TP identification (and by extension summarization) as a supervised classification task. However, we depart from previous approaches to movie analysis which mostly focus on interactions between characters (Do, Tran, and Tran 2018; Tran et al. 2017; Gorinski and Lapata 2015) and model connections between events. Moreover, we discard the simplifying assumption that a screenplay consists of a sequence of scenes (Gorinski and Lapata 2015; Papalampidi, Keller, and Lapata 2019; Papalampidi et al. 2020) and instead represent interactions between scenes as a sparse graph. Specifically, we view the screenplay of a movie as a graph whose nodes correspond to scenes (self-contained events) and edges denote relations between them which we compute based on their linguistic and audiovisual similarity. In contrast to previous work on general-purpose summarization that relies on fully connected graphs (Mihalcea and Tarau 2004; Zheng and Lapata 2019; Wang et al. 2020), we induce sparse graphs by selecting a subset of nodes as neighbors for a scene; the size of this subset is not set in advance but learnt as part of the network. Sparse graphs provide better contextualization for scenes and tend to be more informative, as different genres present different degrees of connectivity between important events. We rely on Graph Convolutional Networks (GCNs; Duvenaud et al. 2015; Kearnes et al. 2016; Kipf and Welling 2017) to encode relevant neighborhood information in the sparsified graph for every scene which in turn contributes to deciding whether it acts as a TP and should be included in the summary. Our contributions can be summarized as follows: (a) we approach movie summarization directly via TP identification which we argue is a well-defined and possibly less subjective task; (b) we propose a TP identification model which relies on sparse graphs and is constructed based on multimodal information; (c) we find that the induced graphs are meaningful with differing graph topologies corresponding to different movie genres. Related Work The computational treatment of narratives has assumed various guises in the literature (Mani 2012; Richards, Finlayson, and Winston 2009). Previous work has attempted to analyze stories by examining the sequence of events in them (Schank and Abelson 1975; Chambers and Jurafsky 2009), plot units (McIntyre and Lapata 2010; Goyal, Riloff, and Daumé III 2010) and their structure (Lehnert 1981; Rumelhart 1980), or the interactions of characters in the narrative (Black and Wilensky 1979; Propp 1968; Valls-Vargas, Zhu, and Ontanon 2014; Srivastava, Chaturvedi, and Mitchell 2016). The summarization of narratives has received less attention, possibly due to the lack of annotated data for modeling and evaluation. Nevertheless, Kazantseva and Szpakowicz (2010) summarize short stories as a browsing aids to help users decide whether a story is interesting to read. Other work (Mihalcea and Ceylan 2007; Gorinski and Lapata 2015; Tsoneva, Barbieri, and Weda 2007) focuses on long-form narratives such as books or movies and adopts primarily unsupervised, graph-based methods. More recently, Papalampidi, Keller, and Lapata (2019) released TRIPOD, a dataset containing screenplays and TP annotations and showed that TPs can be automatically identified in movie narratives. In follow-on work, Papalampidi et al. (2020) further demonstrate that TPs provide useful information when summarizing episodes from the TV series CSI. In this work, we consider scenes as the basic summarization units, and reduce the scene selection task to a TP identification problem. Work on video understanding has also looked at movies. Existing datasets (Tapaswi et al. 2016; Rohrbach et al. 2015) do not contain more than a few hundred movies and focus mostly on isolated video clips rather than entire narratives. For example, Tapaswi, Bauml, and Stiefelhagen (2015) align movie scenes to book chapters, while Xiong et al. (2019) align movie segments to descriptions using a graph-based ",最も有益なシーンを含む短いビデオを作成することにより、フルレングスの映画を要約します。ターニングポイント（TP）であるシーン、つまりストーリーラインを説明する映画の重要なイベントを組み立てることで要約を作成できるという仮説を探ります。シーン間の関係を表すスパースムービーグラフを構築し、マルチモーダル情報を使用して構築することにより、TPシーンを識別するモデルを提案します。人間の裁判官によると、私たちのアプローチによって作成された要約は、シーケンスベースのモデルや汎用の要約アルゴリズムの出力よりも、より有益で完全であり、高い評価を受けています。誘導されたグラフは解釈可能であり、映画のジャンルごとに異なるトポロジを表示します。はじめに自動要約は、ダウンストリームアプリケーションにとって重要であるため、かなりの注目を集めています。現在の研究は主にニュース記事（Grusky、Naaman、Artzi 2018、Narayan、Cohen、Lapata 2018、Liu、Lapata 2019）に焦点を当てていますが、他のアプリケーションドメインには、会議（Murray etal。2007）、講義（Fujii、Kitaoka）が含まれます。 、および中川2007）、ソーシャルメディア（Syed etal。2018）、科学記事（Teufel and Moens 2002）、および短編小説（Goyal、Riloff、およびDaume III 2010; Finlayson 2012）から本（Mihalcea and Ceylan）までの物語2007）、および映画（Gorinski and Lapata 2015）。この作品では、最も有益な部分をカプセル化した短いビデオ要約を作成することにより、フルレングスの映画を要約することを目指しています。ユーザーが映画をすばやくざっと見ることができるようにするだけでなく、Netflixだけでも世界中に1億4800万人以上の加入者があり、60007000以上の映画、シリーズ、番組を利用できます。映画の要約は、現実世界の自然言語理解とそれに関連する複雑な推論にとって理想的なプラットフォームです。映画は多くの場合、非線形構造と複数のキャラクターを備えた精巧なストーリーに基づいており、位置の偏り、重要性、多様性に基づく一般的な要約アプローチの適用に問題があります（Jung et al.2019）。映画の要約におけるもう1つの重要な課題は、Copyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）というラベルの不足にあります。全著作権所有。データとコードはhttps://github.com/ppapalampidi/GraphTPで公開されています。 1.主人公の設定や背景を紹介した後に行われるオポチュニティ紹介イベント。 （ジュノは、彼女が彼女の友人と長年の崇拝者によって父親にされた子供を妊娠していることを発見します。）2。計画の変更物語の主な目標が定義されています。アクションが増加し始めます。 （ジュノは養子縁組のために赤ちゃんをあきらめることにしました。）3。主人公を彼らの目標に完全にコミットするようにプッシュするノーリターンイベントのポイント。 （ジュノはカップルに会い、クローズド養子縁組に同意します。）4。一時的または恒久的にすべてが崩壊する主要な後退イベント。 （ジュノは夫婦の結婚が崩壊するのを見る。）5。クライマックス本編のファイナルイベント、決意の瞬間、そして最大のネタバレ。 （ジュノは、単一の養母として生まれたばかりの元夫婦の主張から出産と配偶者を出します。）図1：ターニングポイント（映画ジュノから）とその定義。データ。ほとんどの映画には、自然に発生する要約はありません（予告編は、要約に含まれるネタバレを明らかにすることなく、視聴者を映画に引き付けることを目的としています）。これらを手動で作成することは、収集、視聴、前処理、および注釈付けにかなりの労力を必要とする主要な作業になります。ビデオ。その結果、利用可能な映画データセットの大部分には、質問応答（QA）やビデオクリップとキャプションの配置などのタスクに焦点を当てた最大数百の映画が含まれています（Tapaswi et al.2016; Xiong et al.2019; Rohrbach et al。2015）は、映画全体ではなくビデオスニペットに制限されているか、ビデオを無視した脚本に制限されています（Gorinski and Lapata 2015; Papalampidi et al.2020）。前作（Gorinski and Lapata 2015）に続き、映画の要約を映画からのいくつかの重要なシーンの選択として形式化します。さらに、重要なシーンには、映画の物語の進行を決定するイベントが表示され、テーマ別のセクションに分割されると想定しています。脚本理論（Thompson 1999; Cutting 2016; Hauge 2017）は、物語の中に特定の機能を持ち、そのストーリーを明らかにするイベントのターニングポイント（TP）という用語を予約しています。 TPは、ストーリーがプロットの5つの主要なターニングポイントによって定義される6つの基本的な段階で構成されると予想される映画を成功させるための鍵と見なされます。 ar X iv：2 01 2. 07 53 6v 1 [cs .CL] 1 4 D ec 2 02 0 TPの例とその定義を図1に示します。興味深いことに、TPは同じであると想定されています。映画のジャンルであり、ストーリー内で同じ位置を占めます（たとえば、機会は最初の10の後に発生します,https://d3i71xaburhd42.cloudfront.net/d739bc3eafbac3304be528c706f127dda243dc9c/1-Figure1-1.png
Towards Semantics-Enhanced Pre-Training: Can Lexicon Definitions Help Learning Sentence Meanings?,"['Xuancheng Ren', 'Xu Sun', 'Houfeng Wang', 'Qun Liu']",,,,
The Gap on Gap: Tackling the Problem of Differing Data Distributions in Bias-Measuring Datasets,"['Vid Kocijan', 'Oana-Maria Camburu', 'Thomas Lukasiewicz']",,,,
Fact-Enhanced Synthetic News Generation,"['Kai Shu', 'Yichuan Li', 'Kaize Ding', 'Huan Liu']",,,,
Clinical Temporal Relation Extraction with Probabilistic Soft Logic Regularization and Global Inference,"['Yichao Zhou', 'Yu Yan', 'Rujun Han', 'J. Harry Caufield', 'Kai-Wei Chang', 'Yizhou Sun', 'Peipei Ping', 'Wei Wang']",,,,
Self-Supervised Self Supervision by Combining Deep Learning and Probabilistic Logic,"['Hunter Lang', 'Hoifung Poon']",,,,
TreeCaps: Tree-Based Capsule Networks for Source Code Processing,"['Nghi Bui', 'Yijun Yu', 'Lingxiao Jiang']",https://arxiv.org/abs/2009.09777,"Recently program learning techniques have been proposed to process source code based on syntactical structures (e.g., Abstract Syntax Trees) and/or semantic information (e.g., Dependency Graphs). Although graphs may be better at capturing various viewpoints of code semantics than trees, constructing graph inputs from code needs static code semantic analysis that may not be accurate and introduces noise during learning. Although syntax trees are precisely defined according to the language grammar and easier to construct and process than graphs, previous tree-based learning techniques have not been able to learn semantic information from trees to achieve better accuracy than graph-based techniques. We propose a new learning technique, named TreeCaps, by fusing together capsule networks with tree-based convolutional neural networks, to achieve learning accuracy higher than existing graph-based techniques while it is based only on trees. TreeCaps introduces novel variable-to-static routing algorithms into the capsule networks to compensate for the loss of previous routing algorithms. Aside from accuracy, we also find that TreeCaps is the most robust to withstand those semantic-preserving program transformations that change code syntax without modifying the semantics. Evaluated on a large number of Java and C/C++ programs, TreeCaps models outperform prior deep learning models of program source code, in terms of both accuracy and robustness for program comprehension tasks such as code functionality classification and function name prediction",最近、構文構造（例えば、抽象構文木）および／または意味情報（例えば、依存関係グラフ）に基づいてソースコードを処理するためのプログラム学習技術が提案されてきた。グラフはツリーよりもコードセマンティクスのさまざまな視点をキャプチャするのに優れている場合がありますが、コードからグラフ入力を構築するには静的コードセマンティクス分析が必要であり、正確ではなく、学習中にノイズが発生します。構文木は言語文法に従って正確に定義され、グラフよりも構築と処理が簡単ですが、以前のツリーベースの学習手法では、グラフベースの手法よりも高い精度を達成するためにツリーから意味情報を学習できませんでした。カプセルネットワークとツリーベースの畳み込みニューラルネットワークを融合することにより、TreeCapsという名前の新しい学習手法を提案し、ツリーのみに基づく既存のグラフベースの手法よりも高い学習精度を実現します。 TreeCapsは、カプセルネットワークに新しい可変から静的へのルーティングアルゴリズムを導入して、以前のルーティングアルゴリズムの損失を補います。正確さは別として、TreeCapsは、セマンティクスを変更せずにコード構文を変更するセマンティクスを保持するプログラム変換に耐えるのに最も堅牢であることがわかります。多数のJavaおよびC / C ++プログラムで評価された、TreeCapsモデルは、コード機能の分類や関数名の予測などのプログラム理解タスクの精度と堅牢性の両方の点で、プログラムソースコードの以前の深層学習モデルよりも優れています。,https://d3i71xaburhd42.cloudfront.net/718b903e8991adc9c2a1153e96525352b12fae1d/3-Figure1-1.png
Dialog Policy Learning for Joint Clarification and Active Learning Queries,"['Aishwarya Padmakumar', 'Raymond Mooney']",https://arxiv.org/abs/2006.05456,"Intelligent systems need to be able to recover from mistakes, resolve uncertainty, and adapt to novel concepts not seen during training. Dialog interaction can enable this by the use of clarifications for correction and resolving uncertainty, and active learning queries to learn new concepts encountered during operation. Prior work on dialog systems has either focused on exclusively learning how to perform clarification/ information seeking, or to perform active learning. In this work, we train a hierarchical dialog policy to jointly perform {\it both} clarification and active learning in the context of an interactive language-based image retrieval task motivated by an on-line shopping application, and demonstrate that jointly learning dialog policies for clarification and active learning is more effective than the use of static dialog policies for one or both of these functions.",インテリジェントシステムは、ミスから回復し、不確実性を解決し、トレーニング中には見ら​​れない新しい概念に適応できる必要があります。ダイアログの相互作用は、不確実性を修正および解決するための説明と、操作中に遭遇する新しい概念を学習するためのアクティブラーニングクエリを使用することにより、これを可能にします。ダイアログシステムに関するこれまでの研究は、明確化/情報探索を実行する方法を排他的に学習すること、または能動学習を実行することに焦点を合わせていました。この作業では、オンラインショッピングアプリケーションによって動機付けられたインタラクティブな言語ベースの画像検索タスクのコンテキストで、明確化とアクティブラーニングの両方を共同で実行する階層ダイアログポリシーをトレーニングし、明確化とアクティブラーニングのダイアログポリシーを共同で学習することを示します学習は、これらの機能の一方または両方に静的ダイアログポリシーを使用するよりも効果的です。,https://d3i71xaburhd42.cloudfront.net/551b0d1933254f4f4a47fae81e4990c135ea08eb/1-Figure1-1.png
Semantics-Aware Inferential Network for Natural Language Understanding,"['Shuiliang Zhang', 'Hai Zhao', 'Junru Zhou', 'Xi Zhou', 'Xiang Zhou']",,,,
Topic-Aware Multi-Turn Dialogue Modeling,"['Yi Xu', 'Hai Zhao', 'Zhuosheng Zhang']",https://arxiv.org/abs/2009.12539,"In the retrieval-based multi-turn dialogue modeling, it remains a challenge to select the most appropriate response according to extracting salient features in context utterances. As a conversation goes on, topic shift at discourse-level naturally happens through the continuous multi-turn dialogue context. However, all known retrieval-based systems are satisfied with exploiting local topic words for context utterance representation but fail to capture such essential global topic-aware clues at discourse-level. Instead of taking topic-agnostic n-gram utterance as processing unit for matching purpose in existing systems, this paper presents a novel topic-aware solution for multi-turn dialogue modeling, which segments and extracts topic-aware utterances in an unsupervised way, so that the resulted model is capable of capturing salient topic shift at discourse-level in need and thus effectively track topic flow during multi-turn conversation. Our topic-aware modeling is implemented by a newly proposed unsupervised topic-aware segmentation algorithm and Topic-Aware Dual-attention Matching (TADAM) Network, which matches each topic segment with the response in a dual cross-attention way. Experimental results on three public datasets show TADAM can outperform the state-of-the-art method by a large margin, especially by 3.4% on E-commerce dataset that has an obvious topic shift.",検索ベースのマルチターンダイアログモデリングでは、コンテキスト発話の顕著な特徴を抽出することに従って、最も適切な応答を選択することは依然として課題です。会話が進むにつれて、談話レベルでのトピックのシフトは、継続的なマルチターンの対話コンテキストを通じて自然に発生します。ただし、すべての既知の検索ベースのシステムは、コンテキスト発話表現のためにローカルトピックワードを利用することに満足していますが、談話レベルでそのような本質的なグローバルトピック認識の手がかりをキャプチャすることはできません。トピックにとらわれないn-gram発話を既存のシステムのマッチング目的の処理単位として使用する代わりに、このペーパーでは、トピック認識発話を監視なしでセグメント化および抽出する、マルチターンダイアログモデリングのための新しいトピック認識ソリューションを紹介します。結果として得られるモデルは、必要な談話レベルで顕著なトピックシフトをキャプチャできるため、マルチターン会話中のトピックフローを効果的に追跡できます。私たちのトピックアウェアモデリングは、新しく提案された教師なしトピックアウェアセグメンテーションアルゴリズムとトピックアウェアデュアルアテンションマッチング（TADAM）ネットワークによって実装されます。これは、各トピックセグメントをデュアルクロスアテンション方式で応答と照合します。 3つの公開データセットでの実験結果は、TADAMが最先端の方法を大幅に、特に3.4で上回ることができることを示しています。,https://d3i71xaburhd42.cloudfront.net/40b1ea56c49751366b05f90f91f98d9d4a12e290/4-Figure1-1.png
Reward-Biased Maximum Likelihood Estimation for Linear Stochastic Bandits,"['Yu Heng Hung', 'Ping-Chun Hsieh', 'Xi Liu', 'P. R. Kumar']",https://arxiv.org/abs/2010.04091,"Modifying the reward-biased maximum likelihood method originally proposed in the adaptive control literature, we propose novel learning algorithms to handle the explore-exploit trade-off in linear bandits problems as well as generalized linear bandits problems. We develop novel index policies that we prove achieve order-optimality, and show that they achieve empirical performance competitive with the state-of-the-art benchmark methods in extensive experiments. The new policies achieve this with low computation time per pull for linear bandits, and thereby resulting in both favorable regret as well as computational efficiency.",適応制御の文献で最初に提案された報酬バイアス最尤法を変更して、線形バンディット問題と一般化線形バンディット問題の探索と活用のトレードオフを処理するための新しい学習アルゴリズムを提案します。私たちは、順序の最適性を達成することを証明する新しいインデックスポリシーを開発し、それらが広範な実験で最先端のベンチマーク手法と競合する経験的パフォーマンスを達成することを示します。新しいポリシーは、線形盗賊のプルあたりの計算時間を短くしてこれを実現し、それによって、好ましい後悔と計算効率の両方をもたらします。,https://d3i71xaburhd42.cloudfront.net/5a29de624baa172236f3f544f3c5726293fe9399/7-Figure1-1.png
Stylized Dialogue Response Generation Using Stylized Unpaired Texts,"['Yinhe Zheng', 'Zikai Chen', 'Rongsheng Zhang', 'Shilei Huang', 'Xiaoxi Mao', 'Minlie Huang']",,,,
Exploiting Audio-Visual Consistency with Partial Supervision for Spatial Audio Generation,"['Yan-Bo Lin', 'Yu-Chiang Frank Wang']",,,,
Error-Correcting Output Codes with Ensemble Diversity for Robust Learning in Neural Networks,"['Yang Song', 'Qiyu Kang', 'Wee Peng Tay']",,,,
Memory and Computation-Efficient Kernel SVM via Binary Embedding and Ternary Coefficients,"['Zijian Lei', 'Liang Lan']",,,,
The Power of Literal Equivalence in Model Counting,"['Yong Lai', 'Kuldeep S Meel', 'Roland Yap']",,"The past two decades have seen the significant improvements of the scalability of practical model counters, which have been quite influential in many applications from artificial intelligence to formal verification. While most of exact counters fall into two categories, search-based and compilation-based, Huang and Darwiche’s remarkable observation ties these two categories: the trace of a search-based exact model counter corresponds to a Decision-DNNF formula (Huang and Darwiche 2007). Taking advantage of literal equivalences, this paper designs an efficient model counting technique such that its trace is a generalization of Decision-DNNF. We first propose a generalization of Decision-DNNF, called CCDD, to capture literal equivalences, then show that CCDD supports model counting in linear time, and finally design a model counter, called ExactMC, whose trace corresponds to CCDD. We perform an extensive experimental evaluation over a comprehensive set of benchmarks and conduct performance comparison of ExactMC vis-a-vis the state of the art counters, c2d, miniC2D, D4, ADDMC, and Ganak. Our empirical evaluation demonstrates ExactMC can solve 885 instances while the prior state of the art could solve only 843 instances, representing a significant improvement of 42 instances.",過去20年間で、実用的なモデルカウンターのスケーラビリティが大幅に向上しました。これは、人工知能からフォーマル検証まで、多くのアプリケーションに大きな影響を与えてきました。正確なカウンターのほとんどは検索ベースとコンパイルベースの2つのカテゴリに分類されますが、HuangとDarwichesの注目すべき観察結果は、これら2つのカテゴリを結び付けています。検索ベースの正確なモデルカウンターのトレースは、Decision-DNNF式に対応します（Huang and Darwiche 2007 ）。この論文では、文字通りの同等性を利用して、そのトレースがDecision-DNNFの一般化であるように効率的なモデルカウント手法を設計します。最初に、CCDDと呼ばれるDecision-DNNFの一般化を提案して、リテラルの同等性をキャプチャし、次にCCDDが線形時間でのモデルカウントをサポートすることを示し、最後に、トレースがCCDDに対応するExactMCと呼ばれるモデルカウンターを設計します。包括的な一連のベンチマークに対して広範な実験的評価を実行し、最先端のカウンター、c2d、miniC2D、D4、ADDMC、およびGanakに対してExactMCのパフォーマンス比較を実施します。私たちの経験的評価は、ExactMCが885インスタンスを解決できるのに対し、以前の最先端技術では843インスタンスしか解決できず、42インスタンスの大幅な改善を示しています。,https://d3i71xaburhd42.cloudfront.net/5c937cc544f4fb052659ece6068144a40e81f5b9/4-Figure1-1.png
Vid-ODE: Continuous-Time Video Generation with Neural Ordinary Differential Equation,"['Sunghyun Park', 'Kangyeol Kim', 'Junsoo Lee', 'Jaegul Choo', 'Joonseok Lee', 'Sookyung Kim', 'Edward Choi']",https://arxiv.org/abs/2010.08188,"Video generation models often operate under the assumption of fixed frame rates, which leads to suboptimal performance when it comes to handling flexible frame rates (e.g., increasing the frame rate of more dynamic portion of the video as well as handling missing video frames). To resolve the restricted nature of existing video generation models' ability to handle arbitrary timesteps, we propose continuous-time video generation by combining neural ODE (Vid-ODE) with pixel-level video processing techniques. Using ODE-ConvGRU as an encoder, a convolutional version of the recently proposed neural ODE, which enables us to learn continuous-time dynamics, Vid-ODE can learn the spatio-temporal dynamics of input videos of flexible frame rates. The decoder integrates the learned dynamics function to synthesize video frames at any given timesteps, where the pixel-level composition technique is used to maintain the sharpness of individual frames. With extensive experiments on four real-world video datasets, we verify that the proposed Vid-ODE outperforms state-of-the-art approaches under various video generation settings, both within the trained time range (interpolation) and beyond the range (extrapolation). To the best of our knowledge, Vid-ODE is the first work successfully performing continuous-time video generation using real-world videos.",ビデオ生成モデルは、固定フレームレートを想定して動作することが多く、柔軟なフレームレートの処理（たとえば、ビデオのより動的な部分のフレームレートの増加や、欠落しているビデオフレームの処理）に関しては、パフォーマンスが最適ではありません。任意のタイムステップを処理する既存のビデオ生成モデル機能の制限された性質を解決するために、ニューラルODE（Vid-ODE）をピクセルレベルのビデオ処理技術と組み合わせることにより、連続時間ビデオ生成を提案します。 Vid-ODEは、最近提案されたニューラルODEの畳み込みバージョンであるODE-ConvGRUをエンコーダーとして使用して、連続時間のダイナミクスを学習できるようにします。Vid-ODEは、柔軟なフレームレートの入力ビデオの時空間ダイナミクスを学習できます。デコーダーは、学習したダイナミクス機能を統合して、任意のタイムステップでビデオフレームを合成します。ここで、ピクセルレベルの合成手法を使用して、個々のフレームのシャープネスを維持します。 4つの実際のビデオデータセットでの広範な実験により、提案されたVid-ODEが、トレーニングされた時間範囲内（内挿）と範囲外（外挿）の両方で、さまざまなビデオ生成設定の下で最先端のアプローチよりも優れていることを確認します。 。私たちの知る限り、Vid-ODEは、実世界のビデオを使用して連続時間のビデオ生成を正常に実行する最初の作業です。,https://d3i71xaburhd42.cloudfront.net/58db26d7064d16bd45d2fda6b5ded997f47278e5/1-Figure1-1.png
Scalable and Explainable 1-Bit Matrix Completion via Graph Signal Learning,"['Chao Chen', 'Dongsheng Li', 'Junchi Yan', 'Hanchi Huang', 'Xiaokang Yang']",,,,
"Show, Attend and Distill: Knowledge Distillation via Attention-Based Feature Matching","['Mingi Ji', 'Byeongho Heo', 'Sungrae Park']",https://arxiv.org/abs/2102.02973,"Knowledge distillation extracts general knowledge from a pretrained teacher network and provides guidance to a target student network. Most studies manually tie intermediate features of the teacher and student, and transfer knowledge through predefined links. However, manual selection often constructs ineffective links that limit the improvement from the distillation. There has been an attempt to address the problem, but it is still challenging to identify effective links under practical scenarios. In this paper, we introduce an effective and efficient feature distillation method utilizing all the feature levels of the teacher without manually selecting the links. Specifically, our method utilizes an attention-based meta-network that learns relative similarities between features, and applies identified similarities to control distillation intensities of all possible pairs. As a result, our method determines competent links more efficiently than the previous approach and provides better performance on model compression and transfer learning tasks. Further qualitative analyses and ablative studies describe how our method contributes to better distillation. The implementation code is available at github.com/clovaai/attention-feature-distillation.",知識蒸留は、事前に訓練された教師ネットワークから一般的な知識を抽出し、対象の学生ネットワークにガイダンスを提供します。ほとんどの研究は、教師と生徒の中間機能を手動で結び付け、事前定義されたリンクを介して知識を伝達します。ただし、手動で選択すると、蒸留による改善を制限する効果のないリンクが作成されることがよくあります。この問題に対処する試みがなされてきましたが、実際のシナリオで効果的なリンクを特定することは依然として困難です。本論文では、手動でリンクを選択することなく、教師のすべての特徴レベルを利用する効果的かつ効率的な特徴蒸留法を紹介します。具体的には、私たちの方法は、特徴間の相対的な類似性を学習し、識別された類似性を適用してすべての可能なペアの蒸留強度を制御する注意ベースのメタネットワークを利用します。その結果、私たちの方法は、以前のアプローチよりも効率的にコンピテントリンクを決定し、モデルの圧縮と転送学習タスクでより良いパフォーマンスを提供します。さらなる定性分析とアブレーション研究は、私たちの方法がより良い蒸留にどのように貢献するかを説明しています。実装コードはgithub.com/clovaai/attention-feature-distillationで入手できます。,https://d3i71xaburhd42.cloudfront.net/e9f0b81fe2f7f47a68d2d87fc1747d739cdbcd05/2-Figure1-1.png
Federated Block Coordinate Descent Scheme for Learning Global and Personalized Models,"['Ruiyuan Wu', 'Anna Scaglione', 'Hoi-To Wai', 'Nurullah Karakoc', 'Kari Hreinsson', 'Wing-Kin Ma']",https://arxiv.org/abs/2012.13900,"In federated learning, models are learned from users’ data that are held private in their edge devices, by aggregating them in the service provider’s “cloud” to obtain a global model. Such global model is of great commercial value in, e.g., improving the customers’ experience. In this paper we focus on two possible areas of improvement of the state of the art. First, we take the difference between user habits into account and propose a quadratic penalty-based formulation, for efficient learning of the global model that allows to personalize local models. Second, we address the latency issue associated with the heterogeneous training time on edge devices, by exploiting a hierarchical structure modeling communication not only between the cloud and edge devices, but also within the cloud. Specifically, we devise a tailored block coordinate descent-based computation scheme, accompanied with communication protocols for both the synchronous and asynchronous cloud settings. We characterize the theoretical convergence rate of the algorithm, and provide a variant that performs empirically better. We also prove that the asynchronous protocol, inspired by multi-agent consensus technique, has the potential for large gains in latency compared to a synchronous setting when the edge-device updates are intermittent. Finally, experimental results are provided that corroborate not only the theory, but also show that the system leads to faster convergence for personalized models on the edge devices, compared to the state of the art.",フェデレーション学習では、モデルは、エッジデバイスでプライベートに保持されているユーザーデータから、サービスプロバイダークラウドでそれらを集約してグローバルモデルを取得することによって学習されます。このようなグローバルモデルは、顧客体験の向上などにおいて大きな商業的価値があります。この論文では、最先端技術の改善の2つの可能な領域に焦点を当てます。まず、ユーザーの習慣の違いを考慮に入れ、ローカルモデルをパーソナライズできるグローバルモデルを効率的に学習するために、2次ペナルティベースの定式化を提案します。次に、クラウドとエッジデバイス間だけでなく、クラウド内の通信をモデル化する階層構造を活用することで、エッジデバイスでの異種トレーニング時間に関連する遅延の問題に対処します。具体的には、同期と非同期の両方のクラウド設定用の通信プロトコルを伴う、調整されたブロック座標降下ベースの計算スキームを考案します。アルゴリズムの理論的な収束率を特徴づけ、経験的に優れたパフォーマンスを発揮するバリアントを提供します。また、マルチエージェントコンセンサス手法に触発された非同期プロトコルは、エッジデバイスの更新が断続的である場合の同期設定と比較して、遅延が大幅に増加する可能性があることも証明します。最後に、理論を裏付けるだけでなく、システムが最先端技術と比較して、エッジデバイス上のパーソナライズされたモデルの収束を高速化することを示す実験結果が提供されます。,https://d3i71xaburhd42.cloudfront.net/b3a0aa5b3ba94cecf9c4c78f9aba6ad8428b8358/4-Figure1-1.png
DropLoss for Long-Tail Instance Segmentation,"['Ting-I Hsieh', 'Esther A Robb', 'Hwann-Tzong Chen', 'Jia-Bin Huang']",,,,
Generating Diversified Comments via Reader-Aware Topic Modeling and Saliency Detection,"['Wei Wang', 'Piji Li', 'Hai-Tao Zheng']",,,,
Combining Reinforcement Learning and Constraint Programming for Combinatorial Optimization,"['Quentin Cappart', 'Thierry Moisan', 'Louis-Martin Rousseau', 'Isabeau Prémont-Schwarz', 'Andre Cire']",https://arxiv.org/abs/2006.01610,"Combinatorial optimization has found applications in numerous fields, from aerospace to transportation planning and economics. The goal is to find an optimal solution among a finite set of possibilities. The well-known challenge one faces with combinatorial optimization is the state-space explosion problem: the number of possibilities grows exponentially with the problem size, which makes solving intractable for large problems. In the last years, deep reinforcement learning (DRL) has shown its promise for designing good heuristics dedicated to solve NP-hard combinatorial optimization problems. However, current approaches have two shortcomings: (1) they mainly focus on the standard travelling salesman problem and they cannot be easily extended to other problems, and (2) they only provide an approximate solution with no systematic ways to improve it or to prove optimality. In another context, constraint programming (CP) is a generic tool to solve combinatorial optimization problems. Based on a complete search procedure, it will always find the optimal solution if we allow an execution time large enough. A critical design choice, that makes CP non-trivial to use in practice, is the branching decision, directing how the search space is explored. In this work, we propose a general and hybrid approach, based on DRL and CP, for solving combinatorial optimization problems. The core of our approach is based on a dynamic programming formulation, that acts as a bridge between both techniques. We experimentally show that our solver is efficient to solve two challenging problems: the traveling salesman problem with time windows, and the 4-moments portfolio optimization problem. Results obtained show that the framework introduced outperforms the stand-alone RL and CP solutions, while being competitive with industrial solvers.",組み合わせ最適化は、航空宇宙から輸送計画、経済学まで、さまざまな分野で応用されています。目標は、限られた可能性の中から最適な解決策を見つけることです。組み合わせ最適化で直面するよく知られた課題は、状態空間爆発問題です。問題のサイズに応じて可能性の数が指数関数的に増加するため、大きな問題の解決が困難になります。過去数年間、深層強化学習（DRL）は、NP困難な組み合わせ最適化問題を解決するための優れたヒューリスティックを設計する可能性を示しています。ただし、現在のアプローチには2つの欠点があります。（1）主に標準的な巡回セールスマン問題に焦点を当てており、他の問題に簡単に拡張することはできません。（2）近似的な解決策を提供するだけであり、それを改善または証明する体系的な方法はありません。最適性。別のコンテキストでは、制約プログラミング（CP）は、組み合わせ最適化の問題を解決するための汎用ツールです。完全な検索手順に基づいて、実行時間を十分に長くすると、常に最適なソリューションが見つかります。 CPを実際に使用するのに重要な設計上の選択は、分岐の決定であり、検索スペースの探索方法を指示します。この作業では、組み合わせ最適化問題を解決するために、DRLとCPに基づく一般的なハイブリッドアプローチを提案します。私たちのアプローチの中核は、動的計画法の定式化に基づいており、両方の手法の間の架け橋として機能します。ソルバーが2つの困難な問題を解決するのに効率的であることを実験的に示します。時間枠のある巡回セールスマン問題と4モーメントポートフォリオ最適化問題です。得られた結果は、導入されたフレームワークがスタンドアロンのRLおよびCPソリューションよりも優れている一方で、産業用ソルバーと競合していることを示しています。,https://d3i71xaburhd42.cloudfront.net/6eaeb3687648b8fc8fd23667fa4a66bf49fdba2f/3-Figure1-1.png
MAMBA: Multi-level Aggregation via Memory Bank for Video Object Detection,"['Guanxiong Sun', 'Yang Hua', 'Guosheng Hu', 'Neil Robertson']",,,,
Improved Consistency Regularization for GANs,"['Zhengli Zhao', 'Sameer Singh', 'Honglak Lee', 'Zizhao Zhang', 'Augustus Odena', 'Han Zhang']",https://arxiv.org/abs/2002.04724,"Recent work has increased the performance of Generative Adversarial Networks (GANs) by enforcing a consistency cost on the discriminator. We improve on this technique in several ways. We first show that consistency regularization can introduce artifacts into the GAN samples and explain how to fix this issue. We then propose several modifications to the consistency regularization procedure designed to improve its performance. We carry out extensive experiments quantifying the benefit of our improvements. For unconditional image synthesis on CIFAR-10 and CelebA, our modifications yield the best known FID scores on various GAN architectures. For conditional image synthesis on CIFAR-10, we improve the state-of-the-art FID score from 11.48 to 9.21. Finally, on ImageNet-2012, we apply our technique to the original BigGAN model and improve the FID from 6.66 to 5.38, which is the best score at that model size.",最近の作業では、ディスクリミネーターに一貫性のコストを適用することにより、生成的敵対的ネットワーク（GAN）のパフォーマンスが向上しています。この手法をいくつかの方法で改善します。最初に、整合性の正則化によってGANサンプルにアーティファクトが導入される可能性があることを示し、この問題を修正する方法を説明します。次に、パフォーマンスを向上させるために設計された整合性正則化手順にいくつかの変更を提案します。私たちは、改善のメリットを定量化する広範な実験を実施しています。 CIFAR-10およびCelebAでの無条件の画像合成の場合、変更により、さまざまなGANアーキテクチャで最もよく知られているFIDスコアが得られます。 CIFAR-10での条件付き画像合成では、最先端のFIDスコアが11.48から9.21に改善されています。最後に、ImageNet-2012で、元のBigGANモデルに手法を適用し、FIDを6.66から5.38に改善します。これは、そのモデルサイズで最高のスコアです。,https://d3i71xaburhd42.cloudfront.net/e8cf0666efb454790a781a8552d5a62b345c6e49/2-Figure1-1.png
Quantum Exploration Algorithms for Multi-Armed Bandits,"['Daochen Wang', 'Xuchen You', 'Tongyang Li', 'Andrew Childs']",https://arxiv.org/abs/2007.07049,"Identifying the best arm of a multi-armed bandit is a central problem in bandit optimization. We study a quantum computational version of this problem with coherent oracle access to states encoding the reward probabilities of each arm as quantum amplitudes. Specifically, we show that we can find the best arm with fixed confidence using $\tilde{O}\bigl(\sqrt{\sum_{i=2}^n\Delta^{\smash{-2}}_i}\bigr)$ quantum queries, where $\Delta_{i}$ represents the difference between the mean reward of the best arm and the $i^\text{th}$-best arm. This algorithm, based on variable-time amplitude amplification and estimation, gives a quadratic speedup compared to the best possible classical result. We also prove a matching quantum lower bound (up to poly-logarithmic factors).",多腕バンディットの最良のアームを特定することは、バンディット最適化の中心的な問題です。各アームの報酬確率を量子振幅としてエンコードする状態へのコヒーレントなオラクルアクセスを使用して、この問題の量子計算バージョンを研究します。具体的には、$ \ tilde {O} \ bigl（\ sqrt {\ sum {i = 2} ^ n \ Delta ^ {\ smash {-2}} i} \を使用して、一定の信頼度で最良の腕を見つけることができることを示します。 bigr）$量子クエリ。ここで、（i）は、最良のアームの平均報酬とi ^（th）-最良のアームの平均報酬の差を表します。このアルゴリズムは、可変時間の振幅増幅と推定に基づいており、可能な限り最良の古典的な結果と比較して、2次の速度向上をもたらします。また、一致する量子の下限（多対数因子まで）を証明します。,
A Case Study of the Shortcut Effects in Visual Commonsense Reasoning,"['Keren Ye', 'Adriana Kovashka']",,,,
Infinite Gaussian Mixture Modeling with an Improved Estimation of the Number of Clusters,"['Avi Matza', 'Yuval Bistritz']",,,,
Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies,"['Jason Jo', 'Giulia Zarpellon', 'Andrea Lodi', 'Yoshua Bengio']",,,,
Differentiable Fluids with Solid Coupling for Learning and Control,"['Tetsuya Takahashi', 'Junbang Liang', 'Yi-Ling Qiao', 'Ming C Lin']",,,,
GraphMix: Improved Training of GNNs for Semi-Supervised Learning,"['Vikas Verma', 'Meng Qu', 'Kenji Kawaguchi', 'Alex M Lamb', 'Yoshua Bengio', 'Juho Kannala', 'Jian Tang']",https://arxiv.org/abs/1909.11715,"We present GraphMix, a regularization method for Graph Neural Network based semi-supervised object classification, whereby we propose to train a fully-connected network jointly with the graph neural network via parameter sharing and interpolation-based regularization. Further, we provide a theoretical analysis of how GraphMix improves the generalization bounds of the underlying graph neural network, without making any assumptions about the ""aggregation"" layer or the depth of the graph neural networks. We experimentally validate this analysis by applying GraphMix to various architectures such as Graph Convolutional Networks, Graph Attention Networks and Graph-U-Net. Despite its simplicity, we demonstrate that GraphMix can consistently improve or closely match state-of-the-art performance using even simpler architectures such as Graph Convolutional Networks, across three established graph benchmarks: Cora, Citeseer and Pubmed citation network datasets, as well as three newly proposed datasets: Cora-Full, Co-author-CS and Co-author-Physics.",グラフニューラルネットワークベースの半教師ありオブジェクト分類の正則化手法であるGraphMixを紹介します。これにより、パラメータ共有と補間ベースの正則化を介して、グラフニューラルネットワークと共同で完全接続ネットワークをトレーニングすることを提案します。さらに、GraphMixが、「集約」層やグラフニューラルネットワークの深さについて何も仮定せずに、基礎となるグラフニューラルネットワークの一般化範囲をどのように改善するかについての理論的分析を提供します。 GraphMixをGraphConvolutional Networks、Graph Attention Networks、Graph-U-Netなどのさまざまなアーキテクチャに適用することにより、この分析を実験的に検証します。その単純さにもかかわらず、GraphMixは、3つの確立されたグラフベンチマーク（Cora、Citeseer、Pubmed引用ネットワークデータセット）全体で、Graph Convolutional Networksなどのさらに単純なアーキテクチャを使用して、最先端のパフォーマンスを一貫して改善または厳密に一致させることができることを示します。新しく提案された3つのデータセット：Cora-Full、Co-author-CS、Co-author-Physics。,
Brain Decoding Using fNIRS,"['Lu Cao', 'Dandan Huang', 'Yue Zhang', 'Xiaowei Jiang', 'Yanan Chen']",,,,
Contextualized Rewriting for Text Summarization,"['Guangsheng Bao', 'Yue Zhang']",https://arxiv.org/abs/2102.00385,"Extractive summarization suffers from irrelevance, redundancy and incoherence. Existing work shows that abstractive rewriting for extractive summaries can improve the conciseness and readability. These rewriting systems consider extracted summaries as the only input, which is relatively focused but can lose important background knowledge. In this paper, we investigate contextualized rewriting, which ingests the entire original document. We formalize contextualized rewriting as a seq2seq problem with group alignments, introducing group tag as a solution to model the alignments, identifying extracted summaries through content-based addressing. Results show that our approach significantly outperforms non-contextualized rewriting systems without requiring reinforcement learning, achieving strong improvements on ROUGE scores upon multiple extractive summarizers.",抽出要約は、無関係、冗長性、および一貫性の欠如に悩まされています。既存の研究は、抽出的な要約のための抽象的な書き直しが簡潔さと読みやすさを改善できることを示しています。これらの書き換えシステムは、抽出された要約を唯一の入力と見なします。これは比較的焦点が絞られていますが、重要な背景知識を失う可能性があります。このホワイトペーパーでは、元のドキュメント全体を取り込むコンテキスト化された書き換えについて調査します。コンテキスト化された書き換えをグループアラインメントのseq2seq問題として形式化し、アラインメントをモデル化するソリューションとしてグループタグを導入し、コンテンツベースのアドレス指定を通じて抽出された要約を識別します。結果は、私たちのアプローチが強化学習を必要とせずにコンテキスト化されていない書き換えシステムを大幅に上回り、複数の抽出サマライザーでROUGEスコアを大幅に改善することを示しています。,https://d3i71xaburhd42.cloudfront.net/ab9d485cb40c1c0dc3474b2d3f62bcc9fd184d5c/2-Figure2-1.png
Consecutive Decoding for Speech-to-Text Translation,"['Qianqian Q Dong', 'Mingxuan Wang', 'Hao Zhou', 'Shuang Xu', 'Bo Xu', 'Lei Li']",https://arxiv.org/abs/2009.09737,"Speech-to-text translation (ST), which directly translates the source language speech to the target language text, has attracted intensive attention recently. However, the combination of speech recognition and machine translation in a single model poses a heavy burden on the direct cross-modal cross-lingual mapping. To reduce the learning difficulty, we propose COnSecutive Transcription and Translation (COSTT), an integral framework for speech-to-text translation. Our method is verified on three mainstream datasets, including Augmented LibriSpeech English-French dataset, TED English-German dataset, and TED English-Chinese dataset. Experiments show that our proposed COSTT outperforms the previous state-of-the-art methods. Our code is available at https://github.com/dqqcasia/st.",ソース言語の音声をターゲット言語のテキストに直接翻訳する音声からテキストへの翻訳（ST）は、最近注目を集めています。ただし、単一モデルでの音声認識と機械翻訳の組み合わせは、直接のクロスモーダルクロスリンガルマッピングに大きな負担をかけます。学習障害を軽減するために、音声からテキストへの翻訳に不可欠なフレームワークであるCOnSecutive Transcription and Translation（COSTT）を提案します。私たちの方法は、拡張LibriSpeech英語-フランス語データセット、TED英語-ドイツ語データセット、およびTED英語-中国語データセットを含む3つの主流データセットで検証されています。実験は、提案されたCOSTTが以前の最先端の方法よりも優れていることを示しています。私たちのコードはhttps://github.com/dqqcasia/stで入手できます。,
Anytime Inference with Distilled Hierarchical Neural Ensembles,"['Adria Ruiz', 'Jakob Verbeek']",https://arxiv.org/abs/2003.01474,"Inference in deep neural networks can be computationally expensive, and networks capable of anytime inference are important in mscenarios where the amount of compute or quantity of input data varies over time. In such networks the inference process can interrupted to provide a result faster, or continued to obtain a more accurate result. We propose Hierarchical Neural Ensembles (HNE), a novel framework to embed an ensemble of multiple networks in a hierarchical tree structure, sharing intermediate layers. In HNE we control the complexity of inference on-the-fly by evaluating more or less models in the ensemble. Our second contribution is a novel hierarchical distillation method to boost the prediction accuracy of small ensembles. This approach leverages the nested structure of our ensembles, to optimally allocate accuracy and diversity across the individual models. Our experiments show that, compared to previous anytime inference models, HNE provides state-of-the-art accuracy-computate trade-offs on the CIFAR-10/100 and ImageNet datasets.",ディープニューラルネットワークでの推論は計算コストがかかる可能性があり、いつでも推論できるネットワークは、計算量または入力データの量が時間とともに変化するmscenariosで重要です。このようなネットワークでは、推論プロセスを中断して結果をより速く提供したり、より正確な結果を取得し続けたりすることができます。複数のネットワークのアンサンブルを階層ツリー構造に埋め込み、中間層を共有する新しいフレームワークであるHierarchical Neural Ensembles（HNE）を提案します。 HNEでは、アンサンブル内のモデルを多かれ少なかれ評価することにより、オンザフライで推論の複雑さを制御します。 2番目の貢献は、小さなアンサンブルの予測精度を高めるための新しい階層的蒸留法です。このアプローチは、アンサンブルのネストされた構造を活用して、個々のモデル全体に​​精度と多様性を最適に割り当てます。私たちの実験は、以前のいつでも推論モデルと比較して、HNEがCIFAR-10 / 100およびImageNetデータセットで最先端の精度と計算上のトレードオフを提供することを示しています。,
Active Feature Selection for the Mutual Information Criterion,"['Shachar Schnapp', 'Sivan Sabato']",https://arxiv.org/abs/2012.06979,"We study active feature selection, a novel feature selection setting in which unlabeled data is available, but the budget for labels is limited, and the examples to label can be actively selected by the algorithm. We focus on feature selection using the classical mutual information criterion, which selects the $k$ features with the largest mutual information with the label. In the active feature selection setting, the goal is to use significantly fewer labels than the data set size and still find $k$ features whose mutual information with the label based on the \emph{entire} data set is large. We explain and experimentally study the choices that we make in the algorithm, and show that they lead to a successful algorithm, compared to other more naive approaches. Our design draws on insights which relate the problem of active feature selection to the study of pure-exploration multi-armed bandits settings. While we focus here on mutual information, our general methodology can be adapted to other feature-quality measures as well. The code is available at the following url: https://github.com/ShacharSchnapp/ActiveFeatureSelection.",ラベルなしデータが利用可能であるが、ラベルの予算が限られており、ラベル付けする例をアルゴリズムによってアクティブに選択できる、新しい特徴選択設定であるアクティブな特徴選択を研究します。ラベルで相互情報量が最大のk個の特徴を選択する古典的な相互情報量基準を使用した特徴選択に焦点を当てます。アクティブな特徴選択設定では、目標は、データセットのサイズよりも大幅に少ないラベルを使用し、データセット全体に基づくラベルとの相互情報量が大きいk個の特徴を見つけることです。アルゴリズムで行った選択について説明し、実験的に研究し、他のより単純なアプローチと比較して、それらがアルゴリズムの成功につながることを示します。私たちの設計は、アクティブな特徴選択の問題を純粋な探索の多腕バンディット設定の研究に関連付ける洞察を利用しています。ここでは相互情報量に焦点を当てていますが、一般的な方法論は他の機能品質の測定にも適用できます。コードは次のURLで入手できます：https：//github.com/ShacharSchnapp/ActiveFeatureSelection。,https://d3i71xaburhd42.cloudfront.net/dfa6e7e6e77528085a683bed033fa73b5c767173/4-Figure1-1.png
Distributional Reinforcement Learning via Moment Matching,"['Thanh Tang Nguyen', 'Sunil Gupta', 'Svetha Venkatesh']",https://arxiv.org/abs/2007.12354,"We consider the problem of learning a set of probability distributions from the empirical Bellman dynamics in distributional reinforcement learning (RL), a class of state-of-the-art methods that estimate the distribution, as opposed to only the expectation, of the total return. We formulate a method that learns a finite set of statistics from each return distribution via neural networks, as in (Bellemare, Dabney, and Munos 2017; Dabney et al. 2018b). Existing distributional RL methods however constrain the learned statistics to \emph{predefined} functional forms of the return distribution which is both restrictive in representation and difficult in maintaining the predefined statistics. Instead, we learn \emph{unrestricted} statistics, i.e., deterministic (pseudo-)samples, of the return distribution by leveraging a technique from hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simpler objective amenable to backpropagation. Our method can be interpreted as implicitly matching all orders of moments between a return distribution and its Bellman target. We establish sufficient conditions for the contraction of the distributional Bellman operator and provide finite-sample analysis for the deterministic samples in distribution approximation. Experiments on the suite of Atari games show that our method outperforms the standard distributional RL baselines and sets a new record in the Atari games for non-distributed agents.",分布強化学習（RL）で、経験的なベルマンダイナミクスから一連の確率分布を学習する問題を検討します。これは、全体の期待値だけではなく、分布を推定する最先端の方法のクラスです。戻る。 （Bellemare、Dabney、and Munos 2017; Dabney etal。2018b）のように、ニューラルネットワークを介して各リターン分布から有限の統計セットを学習する方法を定式化します。ただし、既存の分布RLメソッドは、学習された統計を、表現が制限され、事前定義された統計を維持するのが難しいリターン分布の事前定義された関数形式に制約します。代わりに、最大平均不一致（MMD）として知られる仮説検定の手法を活用することにより、リターン分布の無制限の統計、つまり決定論的（疑似）サンプルを学習します。これにより、バックプロパゲーションに適したより単純な目的が得られます。私たちの方法は、リターン分布とそのベルマンターゲットの間のすべてのモーメントの次数を暗黙的に一致させるものとして解釈できます。分布ベルマン演算子の収縮のための十分条件を確立し、分布近似における決定論的サンプルの有限サンプル分析を提供します。 Atariゲームのスイートでの実験は、私たちの方法が標準の分散RLベースラインを上回り、非分散エージェントのAtariゲームで新記録を樹立することを示しています。,
Learning Dynamics Models with Stable Invariant Sets,"['Naoya Takeishi', 'Yoshinobu Kawahara']",https://arxiv.org/abs/2006.08935,"Stable invariant sets are an essential notion in the analysis and application of dynamical systems. It is thus of great interest to learn dynamical systems with provable existence of stable invariant sets. However, existing methods can only deal with the stability of discrete equilibria, which hinders many applications. In this paper, we propose a method to ensure that a learned dynamics model has a stable invariant set of general classes. To this end, we modify a base dynamics model using a learnable Lyapunov-like function so that the modified dynamics attain the invariance and the stability of a specific subset. We model such a subset by transforming primitive shapes (e.g., spheres) via a learnable bijective function. We may specify such a primitive shape following prior knowledge of the dynamics if any, or it can also be learned from data. We introduce an example of the implementation of the proposed dynamics models using neural networks and present experimental results that show the validity of the proposed method.",安定した不変集合は、動的システムの分析と適用において不可欠な概念です。したがって、安定した不変集合が存在することが証明できる動的システムを学ぶことは非常に興味深いことです。ただし、既存の方法では離散平衡の安定性しか処理できないため、多くのアプリケーションが妨げられます。この論文では、学習したダイナミクスモデルが安定した不変の一般クラスのセットを持つことを保証する方法を提案します。この目的のために、修正されたダイナミクスが特定のサブセットの不変性と安定性を達成するように、学習可能なリアプノフのような関数を使用して基本ダイナミクスモデルを変更します。学習可能な全単射関数を介してプリミティブ形状（球など）を変換することにより、このようなサブセットをモデル化します。ダイナミクスの事前知識がある場合は、そのようなプリミティブ形状を指定することも、データから学習することもできます。ニューラルネットワークを用いた提案ダイナミクスモデルの実装例を紹介し、提案手法の妥当性を示す実験結果を提示します。,https://d3i71xaburhd42.cloudfront.net/af1fcab73ca0b05dda493143dfb0b34fcb21fed6/4-Figure1-1.png
Interpreting Multivariate Shapley Interactions in DNNs,"['Hao Zhang', 'Yichen Xie', 'Longjie Zheng', 'Die Zhang', 'Quanshi Zhang']",https://arxiv.org/abs/2010.05045,"This paper aims to explain deep neural networks (DNNs) from the perspective of multivariate interactions. In this paper, we define and quantify the significance of interactions among multiple input variables of the DNN. Input variables with strong interactions usually form a coalition and reflect prototype features, which are memorized and used by the DNN for inference. We define the significance of interactions based on the Shapley value, which is designed to assign the attribution value of each input variable to the inference. We have conducted experiments with various DNNs. Experimental results have demonstrated the effectiveness of the proposed method.",この論文は、多変量相互作用の観点からディープニューラルネットワーク（DNN）を説明することを目的としています。この論文では、DNNの複数の入力変数間の相互作用の重要性を定義および定量化します。強い相互作用を持つ入力変数は通常、連合を形成し、プロトタイプの機能を反映します。プロトタイプの機能は、DNNによって記憶され、推論に使用されます。相互作用の重要性は、各入力変数の属性値を推論に割り当てるように設計されたシャープレイ値に基づいて定義します。さまざまなDNNで実験を行ってきました。実験結果は提案された方法の有効性を示した。,
Learning from eXtreme Bandit Feedback,"['Romain Lopez', 'Inderjit S. Dhillon', 'Michael Jordan']",https://arxiv.org/abs/2009.12947,"We study the problem of batch learning from bandit feedback in the setting of extremely large action spaces. Learning from extreme bandit feedback is ubiquitous in recommendation systems, in which billions of decisions are made over sets consisting of millions of choices in a single day, yielding massive observational data. In these large-scale real-world applications, supervised learning frameworks such as eXtreme Multi-label Classification (XMC) are widely used despite the fact that they incur significant biases due to the mismatch between bandit feedback and supervised labels. Such biases can be mitigated by importance sampling techniques, but these techniques suffer from impractical variance when dealing with a large number of actions. In this paper, we introduce a selective importance sampling estimator (sIS) that operates in a significantly more favorable bias-variance regime. The sIS estimator is obtained by performing importance sampling on the conditional expectation of the reward with respect to a small subset of actions for each instance (a form of Rao-Blackwellization). We employ this estimator in a novel algorithmic procedure---named Policy Optimization for eXtreme Models (POXM)---for learning from bandit feedback on XMC tasks. In POXM, the selected actions for the sIS estimator are the top-p actions of the logging policy, where p is adjusted from the data and is significantly smaller than the size of the action space. We use a supervised-to-bandit conversion on three XMC datasets to benchmark our POXM method against three competing methods: BanditNet, a previously applied partial matching pruning strategy, and a supervised learning baseline. Whereas BanditNet sometimes improves marginally over the logging policy, our experiments show that POXM systematically and significantly improves over all baselines.",非常に大きなアクションスペースの設定で、盗賊のフィードバックからバッチ学習の問題を研究します。極端な盗賊のフィードバックから学ぶことは、レコメンデーションシステムに遍在します。レコメンデーションシステムでは、1日で数百万の選択肢からなるセットに対して数十億の決定が行われ、大量の観測データが生成されます。これらの大規模な実世界のアプリケーションでは、eXtremeマルチラベル分類（XMC）などの教師あり学習フレームワークが広く使用されていますが、盗賊のフィードバックと教師ありラベルの不一致により大きなバイアスが発生します。このようなバイアスは、重要度サンプリング手法によって軽減できますが、これらの手法は、多数のアクションを処理するときに非現実的な変動に悩まされます。この論文では、有意に有利な偏りと分散レジームで動作する選択的重要度サンプリング推定量（sIS）を紹介します。 sIS推定量は、各インスタンスのアクションの小さなサブセット（Rao-Blackwellizationの形式）に関して、報酬の条件付き期待値に対して重要度サンプリングを実行することによって取得されます。この推定量は、XMCタスクに関する盗賊のフィードバックから学習するためのeXtremeモデルのポリシー最適化（POXM）という名前の新しいアルゴリズム手順で使用されます。 POXMでは、sIS推定器に対して選択されたアクションは、ロギングポリシーの上位pアクションです。ここで、pはデータから調整され、アクションスペースのサイズよりも大幅に小さくなります。 3つのXMCデータセットで教師ありからバンディットへの変換を使用して、POXMメソッドを3つの競合するメソッド（以前に適用された部分マッチングプルーニング戦略であるBanditNet、および教師あり学習ベースライン）に対してベンチマークします。 BanditNetはロギングポリシーよりもわずかに改善することがありますが、私たちの実験では、POXMがすべてのベースラインに対して体系的かつ大幅に改善することが示されています。,https://d3i71xaburhd42.cloudfront.net/675da5104616f4b869f7a71d10270f736cc79a24/5-Figure1-1.png
Non-Asymptotic Convergence of Adam-Type Reinforcement Learning Algorithms under Markovian Sampling,"['Huaqing Xiong', 'Tengyu Xu', 'Yingbin Liang', 'Wei Zhang']",https://arxiv.org/abs/2002.06286,"Despite the wide applications of Adam in reinforcement learning (RL), the theoretical convergence of Adam-type RL algorithms has not been established. This paper provides the first such convergence analysis for two fundamental RL algorithms of policy gradient (PG) and temporal difference (TD) learning that incorporate AMSGrad updates (a standard alternative of Adam in theoretical analysis), referred to as PG-AMSGrad and TD-AMSGrad, respectively. Moreover, our analysis focuses on Markovian sampling for both algorithms. We show that under general nonlinear function approximation, PG-AMSGrad with a constant stepsize converges to a neighborhood of a stationary point at the rate of $\mathcal{O}(1/T)$ (where $T$ denotes the number of iterations), and with a diminishing stepsize converges exactly to a stationary point at the rate of $\mathcal{O}(\log^2 T/\sqrt{T})$. Furthermore, under linear function approximation, TD-AMSGrad with a constant stepsize converges to a neighborhood of the global optimum at the rate of $\mathcal{O}(1/T)$, and with a diminishing stepsize converges exactly to the global optimum at the rate of $\mathcal{O}(\log T/\sqrt{T})$. Our study develops new techniques for analyzing the Adam-type RL algorithms under Markovian sampling.",強化学習（RL）におけるAdamの幅広いアプリケーションにもかかわらず、AdamタイプのRLアルゴリズムの理論的収束は確立されていません。このホワイトペーパーでは、PG-AMSGradおよびTD-と呼ばれるAMSGrad更新（理論分析におけるAdamの標準的な代替）を組み込んだ、ポリシー勾配（PG）および時間差（TD）学習の2つの基本的なRLアルゴリズムの最初の収束分析を提供します。それぞれAMSGrad。さらに、私たちの分析は、両方のアルゴリズムのマルコフサンプリングに焦点を当てています。一般的な非線形関数近似の下で、一定のステップサイズを持つPG-AMSGradがO（1 / T）（Tは反復回数を表す）の速度で停留点の近傍に収束し、減少するステップサイズで収束することを示します。 $ \ mathcal {O}（\ log ^ 2 T / \ sqrt {T}）$の割合で停留点まで正確に。さらに、線形関数近似では、ステップサイズが一定のTD-AMSGradは、O（1 / T）のレートでグローバル最適値の近傍に収束し、ステップサイズが減少すると、$ \のレートでグローバル最適値に正確に収束します。 mathcal {O}（\ log T / \ sqrt {T}）$。私たちの研究は、マルコフサンプリングの下で​​アダム型RLアルゴリズムを分析するための新しい手法を開発しています。,
Power up! Robust Graph Convolutional Network via Graph Powering,"['Heng Chang', 'Ming Jin', 'Wenwu Zhu', 'Somayeh Sojoudi']",,,,
Task-Agnostic Exploration via Policy Gradient of a Non-Parametric State Entropy Estimate,"['Mirco Mutti', 'Lorenzo Pratissoli', 'Marcello Restelli']",,,,
Projection-Free Bandit Optimization with Privacy Guarantees,"['Alina Ene', 'Huy Nguyen', 'Adrian Vladu']",https://arxiv.org/abs/2012.12138,"We design differentially private algorithms for the bandit convex optimization problem in the projection-free setting. This setting is important whenever the decision set has a complex geometry, and access to it is done efficiently only through a linear optimization oracle, hence Euclidean projections are unavailable (e.g. matroid polytope, submodular base polytope). This is the first differentially-private algorithm for projection-free bandit optimization, and in fact our bound of Õ(T ) matches the best known non-private projection-free algorithm (GarberKretzu, AISTATS ‘20) and the best known private algorithm, even for the weaker setting when projections are available (Smith-Thakurta, NeurIPS ‘13).",射影のない設定でのバンディット凸最適化問題のための差分プライベートアルゴリズムを設計します。この設定は、決定セットのジオメトリが複雑であり、線形最適化オラクルを介してのみ効率的にアクセスできる場合は常に重要です。したがって、ユークリッド射影は使用できません（たとえば、マトロイドポリトープ、劣モジュラベースポリトープ）。これは、プロジェクションフリーバンディット最適化のための最初の差分プライベートアルゴリズムであり、実際、O（T）の範囲は、最もよく知られている非プライベートプロジェクションフリーアルゴリズム（GarberKretzu、AISTATS 20）および最もよく知られているプラ​​イベートアルゴリズムと一致します。投影が利用可能な場合の弱い設定（Smith-Thakurta、NeurIPS 13）。,
Weakly-Supervised Hierarchical Models for Predicting Persuasive Strategies in Good-Faith Textual Requests,"['Jiaao Chen', 'Diyi Yang']",https://arxiv.org/abs/2101.06351,"Modeling persuasive language has the potential to better facilitate our decision-making processes. Despite its importance, computational modeling of persuasion is still in its infancy, largely due to the lack of benchmark datasets that can provide quantitative labels of persuasive strategies to expedite this line of research. To this end, we introduce a large-scale multi-domain text corpus for modeling persuasive strategies in good-faith text requests. Moreover, we design a hierarchical weakly-supervised latent variable model that can leverage partially labeled data to predict such associated persuasive strategies for each sentence, where the supervision comes from both the overall document-level labels and very limited sentence-level labels. Experimental results showed that our proposed method outperformed existing semi-supervised baselines significantly. We have publicly released our code at https://github.com/GT-SALT/Persuasion_Strategy_WVAE.",説得力のある言語のモデリングは、意思決定プロセスをより容易にする可能性があります。その重要性にもかかわらず、説得の計算モデリングはまだ初期段階にあります。これは主に、この一連の研究を促進するための説得戦略の定量的ラベルを提供できるベンチマークデータセットがないためです。この目的のために、誠実なテキスト要求で説得力のある戦略をモデル化するための大規模なマルチドメインテキストコーパスを紹介します。さらに、部分的にラベル付けされたデータを活用して、各文に関連する説得力のある戦略を予測できる、階層的な弱教師あり潜在変数モデルを設計します。監視は、全体的なドキュメントレベルのラベルと非常に限られた文レベルのラベルの両方から行われます。実験結果は、提案された方法が既存の半教師ありベースラインを大幅に上回っていることを示しました。コードはhttps://github.com/GT-SALT/Persuasion_Strategy_WVAEで公開されています。,https://d3i71xaburhd42.cloudfront.net/042c440c049b1d8ba4daeba914d8aa89212ee141/4-Figure1-1.png
GO Hessian for Expectation-Based Objectives,"['Yulai Cong', 'Miaoyun Zhao', 'Jianqiao Li', 'Junya Chen', 'Lawrence Carin Duke']",https://arxiv.org/abs/2006.08873,"An unbiased low-variance gradient estimator, termed GO gradient, was proposed recently for expectation-based objectives $\mathbb{E}_{q_{\boldsymbol{\gamma}}(\boldsymbol{y})} [f(\boldsymbol{y})]$, where the random variable (RV) $\boldsymbol{y}$ may be drawn from a stochastic computation graph with continuous (non-reparameterizable) internal nodes and continuous/discrete leaves. Upgrading the GO gradient, we present for $\mathbb{E}_{q_{\boldsymbol{\boldsymbol{\gamma}}}(\boldsymbol{y})} [f(\boldsymbol{y})]$ an unbiased low-variance Hessian estimator, named GO Hessian. Considering practical implementation, we reveal that GO Hessian is easy-to-use with auto-differentiation and Hessian-vector products, enabling efficient cheap exploitation of curvature information over stochastic computation graphs. As representative examples, we present the GO Hessian for non-reparameterizable gamma and negative binomial RVs/nodes. Based on the GO Hessian, we design a new second-order method for $\mathbb{E}_{q_{\boldsymbol{\boldsymbol{\gamma}}}(\boldsymbol{y})} [f(\boldsymbol{y})]$, with rigorous experiments conducted to verify its effectiveness and efficiency.",GO勾配と呼ばれる不偏の低分散勾配推定量が、期待値ベースの目的E（q（）（Y））[f（Y）]に対して最近提案されました。ここで、確率変数（RV）Yは確率変数から引き出されます。連続（再パラメーター化不可能）内部ノードと連続/離散リーフを含む計算グラフ。 GO勾配をアップグレードして、E（q（）（Y））[f（Y）]に対して、GOHessianという名前の不偏低分散ヘッセ推定量を提示します。実際の実装を検討すると、GO Hessianは自動微分およびヘッセベクトル積で使いやすく、確率計算グラフ上で曲率情報を効率的に安価に利用できることがわかります。代表的な例として、パラメータを変更できないガンマおよび負の二項RV /ノードのGOヘシアンを示します。 GO Hessianに基づいて、E（q（）（Y））[f（Y）]の新しい2次メソッドを設計し、その有効性と効率を検証するために厳密な実験を行います。,https://d3i71xaburhd42.cloudfront.net/fc6f2fddd21f0a638ec8cfd26573ce908dc80e3f/4-Figure1-1.png
Context-Aware Attentional Pooling (CAP) for Fine-Grained Visual Classification,"['Ardhendu Behera', 'Zachary Wharton', 'Pradeep R P G Hewage', 'ASISH BERA']",https://arxiv.org/abs/2101.06635,"Deep convolutional neural networks (CNNs) have shown a strong ability in mining discriminative object pose and parts information for image recognition. For fine-grained recognition, context-aware rich feature representation of object/scene plays a key role since it exhibits a significant variance in the same subcategory and subtle variance among different subcategories. Finding the subtle variance that fully characterizes the object/scene is not straightforward. To address this, we propose a novel context-aware attentional pooling (CAP) that effectively captures subtle changes via sub-pixel gradients, and learns to attend informative integral regions and their importance in discriminating different subcategories without requiring the bounding-box and/or distinguishable part annotations. We also introduce a novel feature encoding by considering the intrinsic consistency between the informativeness of the integral regions and their spatial structures to capture the semantic correlation among them. Our approach is simple yet extremely effective and can be easily applied on top of a standard classification backbone network. We evaluate our approach using six state-of-the-art (SotA) backbone networks and eight benchmark datasets. Our method significantly outperforms the SotA approaches on six datasets and is very competitive with the remaining two. Introduction Over recent years, there has been significant progress in the landscape of computer vision due to the adaptation and enhancement of a fast, scalable and end-to-end learning framework, the CNN (LeCun et al. 1998). This is not a recent invention, but we now see a profusion of CNN-based models achieving SotA results in visual recognition (He et al. 2016; Huang et al. 2017; Zoph et al. 2018; Sandler et al. 2018). The performance gain primarily comes from the model’s ability to reason about image content by disentangling discriminative object pose and part information from texture and shape. Most discriminative features are often based on changes in global shape and appearance. They are often ill-suited to distinguish subordinate categories, involving subtle visual differences within various natural objects such as bird species (Wah et al. 2011; Van Horn et al. 2015), flower categories (Nilsback and Zisserman 2008), dog breeds (Khosla et al. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 2011), pets (Parkhi et al. 2012) and man-made objects like aircraft types (Maji et al. 2013), car models (Krause et al. 2013), etc. To address this, a global descriptor is essential which ensembles features from multiple local parts and their hierarchy so that the subtle changes can be discriminated as a misalignment of local parts or pattern. The descriptor should also be able to emphasize the importance of a part. There have been some excellent works on fine-grained visual recognition (FGVC) using weakly-supervised complementary parts (Ge, Lin, and Yu 2019), part attention (Liu et al. 2016), object-part attention (Peng, He, and Zhao 2018), multi-agent cooperative learning (Yang et al. 2018), recurrent attention (Fu, Zheng, and Mei 2017), and destruction and construction learning (Chen et al. 2019). All these approaches avoid part-level annotations and automatically discriminate local parts in an unsupervised/weakly-supervised manner. Many of them use a pre-trained object/parts detector and lack rich representation of regions/parts to capture the object-parts relationships better. To truly describe an image, we need to consider the image generation process from pixels to object to the scene in a more fine-grained way, not only to regulate the object/parts and their spatial arrangements but also defining their appearances using multiple partial descriptions as well as their importance in discriminating subtle changes. These partial descriptions should be rich and complementary to each other to provide a complete description of the object/image. In this work, we propose a simple yet compelling approach that embraces the above properties systematically to address the challenges associated with the FGVC. Thus, it can benefit to a wide variety of applications such as image captioning (Herdade et al. 2019; Huang et al. 2019a; Li et al. 2019), expert-level image recognition (Valan et al. 2019; Krause et al. 2016), and so on. Our work: To describe objects in a conventional way as in CNNs as well as maintaining their visual appearance, we design a context-aware attentional pooling (CAP) to encode spatial arrangements and visual appearance of the parts effectively. The module takes the input as a convolutional feature from a base CNN and then learns to emphasize the latent representation of multiple integral regions (varying coarseness) to describe hierarchies within objects and parts. Each region has an anchor in the feature map, and thus many regions have the same anchor due to the integral characteristics. These integral regions are then fed into a recurrent netar X iv :2 10 1. 06 63 5v 1 [ cs .C V ] 1 7 Ja n 20 21 work (e.g. LSTM) to capture their spatial arrangements, and is inspired by the visual recognition literature, which suggests that humans do not focus their attention on an entire scene at once. Instead, they focus sequentially by attending different parts to extract relevant information (Zoran et al. 2020). A vital characteristic of our CAP is that it generates a new feature map by focusing on a given region conditioned on all other regions and itself. Moreover, it efficiently captures subtle variations in each region by the sub-pixel gradients via bilinear pooling. The recurrent networks are mainly designed for sequence analysis/recognition. We aim to capture the subtle changes between integral regions and their spatial arrangements. Thus, we introduce a learnable pooling to emphasize the most-informative hidden states of the recurrent network, automatically. It learns to encode the spatial arrangement of the latent representation of integral regions and uses it to infer the fine-grained subcategories. Our contributions: Our main contributions can be summarized as: 1) an easy-to-use extension to SotA base CNNs by incorporating context-aware attention to achieve a considerable improvement in FGVC; 2) to discriminate the subtle changes in an object/scene, context-aware attentionguided rich representation of integral regions is proposed; 3) a learnable pooling is also introduced to automatically select the hidden states of a recurrent network to encode spatial arrangement and appearance features; 4) extensive analysis of the proposed model on eight FGVC datasets, obtaining SotA results; and 5) analysis of various base networks for the wider applicability of our CAP. Related Work Unsupervised/weakly-supervised parts/regions based approaches: Such methods learn a diverse collection of discriminative parts/regions to represent the complete description of an image. In (Chen et al. 2019), the global structure of an image is substantially changed by a random patch-shuffling mechanism to select informative regions. An adversarial loss is used to learn essential patches. In (Ge, Lin, and Yu 2019), Mask R-CNN and conditional random field are used for object detection and segmentation. A bidirectional LSTM is used to encode rich complementary information from selected part proposals for classification. A hierarchical bilinear pooling framework is presented in (Yu et al. 2018a) to learn the inter-layer part feature interaction from intermediate convolution layers. This pooling scheme enables inter-layer feature interaction and discriminative part feature learning in a mutually reinforced manner. In (Cai, Zuo, and Zhang 2017), a higher-order integration of hierarchical convolutional features is described for representing parts semantic at different scales. A polynomial kernel-based predictor is defined for modelling part interaction using higher-order statistics of convolutional activations. A general pooling scheme is demonstrated in (Cui et al. 2017) to represent higher-order and nonlinear feature interactions via compact and explicit feature mapping using kernels. Our approach is complementary to these approaches by exploring integral regions and learns to attend these regions using a bilinear pooling that encodes partial information from multiple integral regions to a comprehensive feature vector for subordinate classification. Object and/or part-level attention-based approaches: Recently, there has been significant progress to include attention mechanisms (Zhao, Jia, and Koltun 2020; Leng, Liu, and Chen 2019; Bello et al. 2019; Parmar et al. 2019) to boost image recognition accuracy. It is also explored in FGVC (Zheng et al. 2019; Ji et al. 2018; Sun et al. 2018). In (Zheng et al. 2020), a part proposal network produces several local attention maps, and a part rectification network learns rich part hierarchies. Recurrent attention in (Fu, Zheng, and Mei 2017) learns crucial regions at multiple scales. The attended regions are cropped and scaled up with a higher resolution to compute rich features. Object-part attention model (OPAM) in (Peng, He, and Zhao 2018) incorporates object-level attention for object localization, and part-level attention for the vital parts selection. Both jointly learn multi-view and multi-scale features to improve performance. In (Liu et al. 2019), a bidirectional attentionrecognition model (BARM) is proposed to optimize the region proposals via a feedback path from the recognition module to the part localization module. Similarly, in attention pyramid hierarchy (Ding et al. 2020), top-down and bottom-up attentions are integrated to learn both high-level semantic and low-level detailed feature representations. In (Rodrı́guez et al. 2020), a modular feed-forward attention mechanism consisting of attention modules and attention gates is applied to learn low-level feature activations. Our novel",深い畳み込みニューラルネットワーク（CNN）は、画像認識のために識別可能なオブジェクトのポーズとパーツ情報をマイニングする強力な能力を示しています。きめ細かい認識では、オブジェクト/シーンのコンテキストアウェアな豊富な機能表現が重要な役割を果たします。これは、同じサブカテゴリで大きな差異があり、異なるサブカテゴリ間で微妙な差異があるためです。オブジェクト/シーンを完全に特徴付ける微妙な差異を見つけることは簡単ではありません。これに対処するために、サブピクセル勾配を介して微妙な変化を効果的にキャプチャし、バウンディングボックスやバウンディングボックスを必要とせずにさまざまなサブカテゴリを区別する上での有益な積分領域とその重要性に参加することを学ぶ、新しいコンテキストアウェアアテンションプーリング（CAP）を提案します。識別可能なパーツの注釈。また、積分領域の有益性とそれらの空間構造の間の本質的な一貫性を考慮して、それらの間の意味的相関をキャプチャすることにより、新しい機能エンコーディングを紹介します。私たちのアプローチはシンプルでありながら非常に効果的であり、標準的な分類バックボーンネットワークの上に簡単に適用できます。 6つの最先端（SotA）バックボーンネットワークと8つのベンチマークデータセットを使用して、アプローチを評価します。私たちの方法は、6つのデータセットでSotAアプローチを大幅に上回り、残りの2つと非常に競争力があります。はじめに近年、高速でスケーラブルなエンドツーエンドの学習フレームワークであるCNNの適応と強化により、コンピュータービジョンの展望に大きな進歩が見られました（LeCun et al.1998）。これは最近の発明ではありませんが、SotAの結果を視覚的に認識できるCNNベースのモデルが数多く見られます（He et al.2016; Huang et al.2017; Zoph et al.2018; Sandler et al.2018）。パフォーマンスの向上は、主に、識別可能なオブジェクトのポーズとパーツ情報をテクスチャと形状から解きほぐすことによって、画像コンテンツについて推論するモデルの機能に由来します。ほとんどの識別機能は、多くの場合、グローバルな形状と外観の変化に基づいています。それらは、鳥の種（Wahetal。2011; Van Horn etal。2015）、花のカテゴリー（Nilsback and Zisserman 2008）、犬の品種（Nilsback and Zisserman 2008）などのさまざまな自然物内の微妙な視覚的差異を含む下位カテゴリーを区別するのに適していないことがよくあります。 Khoslaetal。Copyright2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。Allrightsreserved。2011）、ペット（Parkhi etal。2012）、航空機タイプなどの人工物（Maji etal。 2013）、車のモデル（Krause etal。2013）など。これに対処するには、複数のローカルパーツとその階層からのフィーチャをアンサンブルするグローバル記述子が不可欠であり、微妙な変更をローカルパーツまたはパターンの不整合として識別できます。 。記述子は、パーツの重要性を強調できる必要もあります。弱く監視された補完部分（Ge、Lin、およびYu 2019）、部分注意（Liu etal。2016）、オブジェクト部分注意（Peng、He、）を使用したきめ細かい視覚認識（FGVC）に関するいくつかの優れた作品があります。およびZhao2018）、マルチエージェント協調学習（Yang etal。2018）、繰り返し注意（Fu、Zheng、およびMei 2017）、および破壊と建設の学習（Chen et al.2019）。これらのアプローチはすべて、パーツレベルの注釈を回避し、監視されていない/監視されていない方法でローカルパーツを自動的に識別します。それらの多くは、事前にトレーニングされたオブジェクト/パーツ検出器を使用し、オブジェクトとパーツの関係をより適切にキャプチャするための領域/パーツの豊富な表現を欠いています。画像を真に記述するためには、ピクセルからオブジェクト、シーンへの画像生成プロセスをよりきめ細かく検討する必要があります。これは、オブジェクト/パーツとその空間配置を調整するだけでなく、複数の部分的な記述を使用して外観を定義するためです。微妙な変化を区別する上でのそれらの重要性と同様に。これらの部分的な説明は、オブジェクト/画像の完全な説明を提供するために、豊富で相互に補完的である必要があります。この作業では、FGVCに関連する課題に対処するために、上記のプロパティを体系的に採用する、シンプルでありながら説得力のあるアプローチを提案します。したがって、画像キャプション（Herdade et al.2019; Huang et al.2019a; Li et al.2019）、専門家レベルの画像認識（Valan et al.2019; Krause et al.2019）などのさまざまなアプリケーションにメリットがあります。 。2016）など。私たちの仕事：CNNのように従来の方法でオブジェクトを記述し、それらの視覚的外観を維持するために、空間配置とパーツの視覚的外観を効果的にエンコードするコンテキストアウェアアテンションプーリング（CAP）を設計します。このモジュールは、入力をベースCNNからの畳み込み特徴として受け取り、オブジェクトおよびパーツ内の階層を記述するために、複数の積分領域（さまざまな粗さ）の潜在的な表現を強調することを学習します。各地域はフィーチャマップにアンカーを持っているため、多くの地域は統合された特性のために同じアンカーを持っています。次に、これらの積分領域は、繰り返しネターに供給されますX iv：2 10 1. 06 63 5v 1 [cs .CV] 1 7 Ja n 20 21作業（例：LSTM）空間配置をキャプチャし、視覚認識に触発されます人間が一度にシーン全体に注意を向けないことを示唆する文学。代わりに、彼らは関連情報を抽出するためにさまざまな部分に参加することによって順番に焦点を合わせます（Zoran et al.2020）。 CAPの重要な特徴は、他のすべての領域とそれ自体を条件とする特定の領域に焦点を当てることにより、新しいフィーチャマップを生成することです。さらに、双線形プーリングを介したサブピクセル勾配によって、各領域の微妙な変化を効率的にキャプチャします。リカレントネットワークは、主にシーケンス分析/認識用に設計されています。積分領域とその空間配置の間の微妙な変化を捉えることを目指しています。したがって、リカレントネットワークの最も有益な隠れた状態を自動的に強調するために、学習可能なプーリングを導入します。積分領域の潜在的表現の空間配置をエンコードすることを学習し、それを使用して細粒度のサブカテゴリを推測します。私たちの貢献：私たちの主な貢献は次のように要約できます。1）FGVCの大幅な改善を達成するために、コンテキストアウェアな注意を組み込むことによる、SotAベースCNNへの使いやすい拡張。 2）オブジェクト/シーンの微妙な変化を区別するために、統合領域のコンテキストアウェアな注意誘導の豊富な表現が提案されます。 3）学習可能なプーリングも導入され、リカレントネットワークの隠れた状態を自動的に選択して、空間配置と外観の特徴をエンコードします。 4）8つのFGVCデータセットで提案されたモデルを詳細に分析し、SotAの結果を取得します。 5）CAPの幅広い適用性のためのさまざまなベースネットワークの分析。関連作業監視されていない/監視されていない部分/領域ベースのアプローチ：このような方法は、画像の完全な説明を表すために、識別可能な部分/領域の多様なコレクションを学習します。 （Chen etal。2019）では、画像のグローバル構造は、有益な領域を選択するためのランダムなパッチシャッフルメカニズムによって大幅に変更されています。敵対的損失は、重要なパッチを学習するために使用されます。 （Ge、Lin、およびYu 2019）では、マスクR-CNNと条件付き確率場がオブジェクトの検出とセグメンテーションに使用されます。双方向LSTMは、分類のために選択された部品提案からの豊富な補足情報をエンコードするために使用されます。階層的な双線形プーリングフレームワークが（Yu etal。2018a）に示され、中間の畳み込みレイヤーからレイヤー間のパーツ機能の相互作用を学習します。このプーリングスキームにより、相互に強化された方法で、レイヤー間の機能の相互作用と識別可能なパーツ機能の学習が可能になります。 （Cai、Zuo、およびZhang 2017）では、階層畳み込み特徴の高次統合が、さまざまなスケールでセマンティックな部分を表すために説明されています。畳み込み活性化の高次統計を使用してパーツの相互作用をモデル化するために、多項式カーネルベースの予測子が定義されています。一般的なプーリングスキームは（Cui etal。2017）に示され、カーネルを使用したコンパクトで明示的な特徴マッピングを介して、高次の非線形特徴の相互作用を表します。私たちのアプローチは、積分領域を探索することによってこれらのアプローチを補完し、複数の積分領域からの部分情報を下位分類のための包括的な特徴ベクトルにエンコードする双一次プーリングを使用してこれらの領域に参加することを学習します。オブジェクトおよび/または部分レベルの注意ベースのアプローチ：最近、注意メカニズムを含めるための重要な進歩がありました（Zhao、Jia、およびKoltun 2020; Leng、Liu、およびChen 2019; Bello et al.2019; Parmar etal。 2019）画像認識精度を高めるため。また、FGVCでも調査されています（Zheng et al.2019; Ji et al.2018; Sun et al.2018）。 （Zheng etal。2020）では、パーツ提案ネットワークがいくつかのローカルアテンションマップを作成し、パーツ修正ネットワークが豊富なパーツ階層を学習します。 （Fu、Zheng、Mei 2017）で繰り返し注目されるのは、重要な地域を複数のスケールで学習することです。参加地域は、豊富な機能を計算するために、より高い解像度でトリミングおよびスケールアップされます。 （Peng、He、およびZhao 2018）のオブジェクトパーツアテンションモデル（OPAM）には、オブジェクトのローカリゼーションのためのオブジェクトレベルのアテンションと、重要なパーツの選択のためのパーツレベルのアテンションが組み込まれています。両者は、パフォーマンスを向上させるために、マルチビュー機能とマルチスケール機能を共同で学習します。 （Liu etal。2019）では、双方向注意認識モデル（BARM）が提案され、認識モジュールからパーツローカリゼーションモジュールへのフィードバックパスを介して領域提案を最適化します。同様に、注意ピラミッド階層（Ding etal。2020）では、トップダウンとボトムアップの注意が統合されて、高レベルのセマンティック表現と低レベルの詳細な特徴表現の両方を学習します。 （Rodrguez etal。2020）では、注意モジュールと注意ゲートで構成されるモジュール式フィードフォワード注意メカニズムを適用して、低レベルの機能のアクティブ化を学習します。私たちの小説,https://d3i71xaburhd42.cloudfront.net/48913aecd8da6475d93fae7beb13d7ef939b3d8a/3-Figure1-1.png
Revisiting Consistent Hashing with Bounded Loads,"['John Chen', 'Benjamin Coleman', 'Anshumali Shrivastava']",,,,
Ordinal Historical Dependence in Graphical Event Models with Tree Representations,"['Debarun Bhattacharjya', 'Tian Gao', 'Dharmashankar Subramanian']",,,,
If You Like Shapley Then You’ll Love the Core,"['Tom Yan', 'Ariel D Procaccia']",,"The prevalent approach to problems of credit assignment in machine learning — such as feature attribution and data valuation — is to model the problem at hand as a cooperative game and solve it using the Shapley value. But cooperative game theory offers a rich menu of alternative solution concepts, which famously includes the core and its variants. Our goal is to challenge the machine learning community’s surprising consensus around the Shapley value, and make a case for the core as a viable alternative. To that end, we prove that arbitrarily good approximations to the least core — a core relaxation that is always feasible — can be computed efficiently (but prove an impossibility for a more refined solution concept, the nucleolus). We also perform experiments that corroborate these theoretical results.",特徴帰属やデータ評価などの機械学習におけるクレジット割り当ての問題に対する一般的なアプローチは、手元の問題を協力ゲームとしてモデル化し、シャープレイ値を使用して解決することです。しかし、協力ゲーム理論は、コアとそのバリアントを含むことで有名な代替ソリューションの概念の豊富なメニューを提供します。私たちの目標は、機械学習コミュニティにシャープレイ値に関する驚くべきコンセンサスに挑戦し、実行可能な代替手段としてコアを主張することです。そのために、常に実行可能なコア緩和を最小コアに任意に適切に近似できることを効率的に計算できることを証明します（ただし、より洗練された解概念である核小体では不可能であることを証明します）。また、これらの理論的結果を裏付ける実験も行っています。,https://d3i71xaburhd42.cloudfront.net/02e32987366c1ebfcc56d7c2ab822473e4c9032e/7-Figure1-1.png
Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance,"['Shibo Zhou', 'Xiaohua Li', 'Ying Chen', 'Sanjeev Tannirkulam Chandrasekaran', 'Arindam Sanyal']",https://arxiv.org/abs/1909.10837,"Spiking neural network (SNN) is interesting both theoretically and practically because of its strong bio-inspiration nature and potentially outstanding energy efficiency. Unfortunately, its development has fallen far behind the conventional deep neural network (DNN), mainly because of difficult training and lack of widely accepted hardware experiment platforms. In this paper, we show that a deep temporal-coded SNN can be trained easily and directly over the benchmark datasets CIFAR10 and ImageNet, with testing accuracy within 1% of the DNN of equivalent size and architecture. Training becomes similar to DNN thanks to the closed-form solution to the spiking waveform dynamics. Considering that SNNs should be implemented in practical neuromorphic hardwares, we train the deep SNN with weights quantized to 8, 4, 2 bits and with weights perturbed by random noise to demonstrate its robustness in practical applications. In addition, we develop a phase-domain signal processing circuit schematic to implement our spiking neuron with 90% gain of energy efficiency over existing work. This paper demonstrates that the temporal-coded deep SNN is feasible for applications with high performance and high energy efficient.",スパイキングニューラルネットワーク（SNN）は、その強力なバイオインスピレーションの性質と潜在的に卓越したエネルギー効率のために、理論的にも実際的にも興味深いものです。残念ながら、その開発は、主にトレーニングが困難であり、広く受け入れられているハードウェア実験プラットフォームがないために、従来のディープニューラルネットワーク（DNN）に大きく遅れをとっています。このホワイトペーパーでは、深側頭神経コード化されたSNNを、ベンチマークデータセットCIFAR10およびImageNet上で簡単かつ直接トレーニングでき、テスト精度が1以内であることを示します。,
TempLe: Learning Template of Transitions for Sample Efficient Multi-Task RL,"['Yanchao Sun', 'Xiangyu Yin', 'Furong Huang']",https://arxiv.org/abs/2002.06659,"Transferring knowledge among various environments is important to efficiently learn multiple tasks online. Most existing methods directly use the previously learned models or previously learned optimal policies to learn new tasks. However, these methods may be inefficient when the underlying models or optimal policies are substantially different across tasks. In this paper, we propose Template Learning (TempLe), the first PAC-MDP method for multi-task reinforcement learning that could be applied to tasks with varying state/action space. TempLe generates transition dynamics templates, abstractions of the transition dynamics across tasks, to gain sample efficiency by extracting similarities between tasks even when their underlying models or optimal policies have limited commonalities. We present two algorithms for an ""online"" and a ""finite-model"" setting respectively. We prove that our proposed TempLe algorithms achieve much lower sample complexity than single-task learners or state-of-the-art multi-task methods. We show via systematically designed experiments that our TempLe method universally outperforms the state-of-the-art multi-task methods (PAC-MDP or not) in various settings and regimes.",オンラインで複数のタスクを効率的に学習するには、さまざまな環境間で知識を伝達することが重要です。ほとんどの既存の方法は、以前に学習したモデルまたは以前に学習した最適なポリシーを直接使用して、新しいタスクを学習します。ただし、基礎となるモデルまたは最適なポリシーがタスク間で大幅に異なる場合、これらの方法は非効率的である可能性があります。この論文では、さまざまな状態/アクション空間を持つタスクに適用できるマルチタスク強化学習のための最初のPAC-MDPメソッドであるテンプレート学習（TempLe）を提案します。 TempLeは、移行ダイナミクステンプレート、つまりタスク間の移行ダイナミクスの抽象化を生成し、基になるモデルまたは最適なポリシーの共通性が限られている場合でも、タスク間の類似性を抽出することでサンプルの効率を高めます。 「オンライン」設定と「有限モデル」設定の2つのアルゴリズムをそれぞれ示します。提案されたTempLeアルゴリズムは、シングルタスク学習者や最先端の​​マルチタスク手法よりもはるかに低いサンプルの複雑さを実現することを証明します。体系的に設計された実験を通じて、TempLeメソッドがさまざまな設定や体制で最先端のマルチタスクメソッド（PAC-MDPかどうか）を普遍的に上回っていることを示します。,https://d3i71xaburhd42.cloudfront.net/49fccb8d1a43b44ae1729257f15c7408f04ce674/2-Figure1-1.png
Characterizing Deep Gaussian Processes via Nonlinear Recurrence Systems,"['Anh Tong', 'Jaesik Choi']",https://arxiv.org/abs/2010.09301,"Recent advances in Deep Gaussian Processes (DGPs) show the potential to have more expressive representation than that of traditional Gaussian Processes (GPs). However, there exists a pathology of deep Gaussian processes that their learning capacities reduce significantly when the number of layers increases. In this paper, we present a new analysis in DGPs by studying its corresponding nonlinear dynamic systems to explain the issue. Existing work reports the pathology for the squared exponential kernel function. We extend our investigation to four types of common stationary kernel functions. The recurrence relations between layers are analytically derived, providing a tighter bound and the rate of convergence of the dynamic systems. We demonstrate our finding with a number of experimental results.",ディープガウス過程（DGP）の最近の進歩は、従来のガウス過程（GP）よりも表現力豊かな表現を持つ可能性を示しています。ただし、層の数が増えると学習能力が大幅に低下する深いガウス過程の病理が存在します。この論文では、問題を説明するために対応する非線形動的システムを研究することにより、DGPの新しい分析を提示します。既存の作業は、二乗指数カーネル関数の病理を報告します。調査を4種類の一般的な固定カーネル関数に拡張します。層間の漸化式は分析的に導き出され、動的システムのより厳密な境界と収束率を提供します。私たちは、いくつかの実験結果で私たちの発見を示しています。,https://d3i71xaburhd42.cloudfront.net/8724ccf443b1690778e10c03ef3e8bf1961fa3e8/2-Figure1-1.png
On the Importance of Word Order Information in Cross-Lingual Sequence Labeling,"['Zihan Liu', 'Genta I Winata', 'Samuel Cahyawijaya', 'Andrea Madotto', 'Zhaojiang Lin', 'Pascale Fung']",https://arxiv.org/abs/2001.11164,"Word order variances generally exist in different languages. In this paper, we hypothesize that cross-lingual models that fit into the word order of the source language might fail to handle target languages. To verify this hypothesis, we investigate whether making models insensitive to the word order of the source language can improve the adaptation performance in target languages. To do so, we reduce the source language word order information fitted to sequence encoders and observe the performance changes. In addition, based on this hypothesis, we propose a new method for fine-tuning multilingual BERT in downstream cross-lingual sequence labeling tasks. Experimental results on dialogue natural language understanding, part-of-speech tagging, and named entity recognition tasks show that reducing word order information fitted to the model can achieve better zero-shot cross-lingual performance. Furthermore, our proposed methods can also be applied to strong cross-lingual baselines, and improve their performances.",語順の違いは通常、さまざまな言語で存在します。この論文では、ソース言語の語順に適合するクロスリンガルモデルがターゲット言語を処理できない可能性があると仮定します。この仮説を検証するために、モデルをソース言語の語順に鈍感にすることで、ターゲット言語の適応パフォーマンスを改善できるかどうかを調査します。そのために、シーケンスエンコーダーに適合したソース言語の語順情報を減らし、パフォーマンスの変化を観察します。さらに、この仮説に基づいて、下流のクロスリンガルシーケンスラベリングタスクで多言語BERTを微調整するための新しい方法を提案します。会話の自然言語理解、品詞のタグ付け、および名前付きエンティティの認識タスクに関する実験結果は、モデルに適合した語順情報を減らすことで、より優れたゼロショットの言語間パフォーマンスを実現できることを示しています。さらに、提案された方法は、強力なクロスリンガルベースラインにも適用でき、パフォーマンスを向上させることができます。,
Humor Knowledge Enriched Transformer for Understanding Multimodal Humor,"['Md Kamrul Hasan', 'Sangwu Lee', 'Wasifur Rahman', 'Amir Zadeh', 'Rada Mihalcea', 'Louis-Philippe Morency', 'Ehsan Hoque']",,,,
Combinatorial Pure Exploration with Full-Bandit or Partial Linear Feedback,"['Yihan Du', 'Yuko Kuroki', 'Wei Chen']",https://arxiv.org/abs/2006.07905,"In this paper, we first study the problem of combinatorial pure exploration with full-bandit feedback (CPE-BL), where a learner is given a combinatorial action space $\mathcal{X} \subseteq \{0,1\}^d$, and in each round the learner pulls an action $x \in \mathcal{X}$ and receives a random reward with expectation $x^{\top} \theta$, with $\theta \in \mathbb{R}^d$ a latent and unknown environment vector. The objective is to identify the optimal action with the highest expected reward, using as few samples as possible. For CPE-BL, we design the first {\em polynomial-time adaptive} algorithm, whose sample complexity matches the lower bound (within a logarithmic factor) for a family of instances and has a light dependence of $\Delta_{\min}$ (the smallest gap between the optimal action and sub-optimal actions). Furthermore, we propose a novel generalization of CPE-BL with flexible feedback structures, called combinatorial pure exploration with partial linear feedback (CPE-PL), which encompasses several families of sub-problems including full-bandit feedback, semi-bandit feedback, partial feedback and nonlinear reward functions. In CPE-PL, each pull of action $x$ reports a random feedback vector with expectation of $M_{x} \theta $, where $M_x \in \mathbb{R}^{m_x \times d}$ is a transformation matrix for $x$, and gains a random (possibly nonlinear) reward related to $x$. For CPE-PL, we develop the first {\em polynomial-time} algorithm, which simultaneously addresses limited feedback, general reward function and combinatorial action space, and provide its sample complexity analysis. Our empirical evaluation demonstrates that our algorithms run orders of magnitude faster than the existing ones, and our CPE-BL algorithm is robust across different $\Delta_{\min}$ settings while our CPE-PL algorithm is the only one returning correct answers for nonlinear reward functions.",この論文では、最初に、学習者に組み合わせアクションスペースX {0、1} ^（d）が与えられ、各ラウンドで学習者が与えられる、フルバンディットフィードバック（CPE-BL）を使用した組み合わせ純粋探索の問題を研究します。アクションxXをプルし、期待値x ^（）でランダムな報酬を受け取ります。R^（d）は潜在的で未知の環境ベクトルです。目的は、可能な限り少ないサンプルを使用して、期待される報酬が最も高い最適なアクションを特定することです。 CPE-BLの場合、最初の多項式時間適応アルゴリズムを設計します。このアルゴリズムのサンプルの複雑さは、インスタンスファミリーの下限（対数係数内）に一致し、（最小）の光依存性（最適なアクション間の最小ギャップ）を持ちます。および次善のアクション）。さらに、フルバンディットフィードバック、セミバンディットフィードバック、パーシャルを含むサブ問題のいくつかのファミリを含む、部分線形フィードバックを使用した組み合わせ純粋探索（CPE-PL）と呼ばれる、柔軟なフィードバック構造を備えたCPE-BLの新しい一般化を提案します。フィードバックおよび非線形報酬関数。 CPE-PLでは、アクションxの各プルは、M（x）を期待するランダムフィードバックベクトルを報告します。ここで、M（x）R ^（m（x）d）はxの変換行列であり、ランダム（おそらく非線形）xに関連する報酬。 CPE-PLの場合、最初の多項式時間アルゴリズムを開発します。これは、限られたフィードバック、一般的な報酬関数、および組み合わせアクションスペースに同時に対処し、そのサンプルの複雑さの分析を提供します。私たちの経験的評価は、私たちのアルゴリズムが既存のものよりも桁違いに速く実行され、CPE-BLアルゴリズムがさまざまな（最小）設定にわたって堅牢であるのに対し、CPE-PLアルゴリズムは非線形報酬関数の正解を返す唯一のアルゴリズムであることを示しています。,
Denoising Distantly Supervised Named Entity Recognition via a Hypergeometric Probabilistic Model,"['Hongyu Lin', 'Wenkai Zhang', 'Xianpei Han', 'Le Sun', 'Huidan Liu', 'Nicholas Yuan', 'Zhicheng Wei']",,,,
Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network for Emotional Conversation Generation,"['Yunlong Liang', 'Fandong Meng', 'Ying Zhang', 'Yufeng Chen', 'Jinan Xu', 'Jie Zhou']",https://arxiv.org/abs/2012.04882,"The success of emotional conversation systems depends on sufficient perception and appropriate expression of emotions. In a real-world conversation, we firstly instinctively perceive emotions from multi-source information, including the emotion flow of dialogue history, facial expressions, and personalities of speakers, and then express suitable emotions according to our personalities, but these multiple types of information are insufficiently exploited in emotional conversation fields. To address this issue, we propose a heterogeneous graph-based model for emotional conversation generation. Specifically, we design a Heterogeneous Graph-Based Encoder to represent the conversation content (i.e., the dialogue history, its emotion flow, facial expressions, and speakers' personalities) with a heterogeneous graph neural network, and then predict suitable emotions for feedback. After that, we employ an Emotion-Personality-Aware Decoder to generate a response not only relevant to the conversation context but also with appropriate emotions, by taking the encoded graph representations, the predicted emotions from the encoder and the personality of the current speaker as inputs. Experimental results show that our model can effectively perceive emotions from multi-source knowledge and generate a satisfactory response, which significantly outperforms previous state-of-the-art models.",感情的な会話システムの成功は、感情の十分な認識と適切な表現に依存します。実世界の会話では、まず会話履歴の感情の流れ、表情、話者の性格など、複数の情報源から感情を本能的に知覚し、次に性格に応じて適切な感情を表現しますが、これらの複数の種類の情報感情的な会話の分野では十分に活用されていません。この問題に対処するために、感情的な会話を生成するための異種グラフベースのモデルを提案します。具体的には、異種グラフニューラルネットワークを使用して会話コンテンツ（つまり、会話の履歴、その感情の流れ、表情、話者の性格）を表す異種グラフベースのエンコーダーを設計し、フィードバックに適した感情を予測します。その後、Emotion-Personality-Aware Decoderを使用して、エンコードされたグラフ表現、エンコーダーからの予測された感情、および現在の話者の性格を次のように取得することにより、会話コンテキストだけでなく適切な感情にも関連する応答を生成します。入力。実験結果は、私たちのモデルがマルチソースの知識から感情を効果的に認識し、満足のいく応答を生成できることを示しています。これは、以前の最先端モデルを大幅に上回っています。,https://d3i71xaburhd42.cloudfront.net/e69ff1f5b342ba5b6e7fbfcee21b58a041ee3608/1-Figure1-1.png
A New Bounding Scheme for Influence Diagrams,"['Radu Marinescu', 'Junkyu Lee', 'Rina Dechter']",,,,
Searching for Machine Learning Pipelines Using a Context-Free Grammar,"['Radu Marinescu', 'Akihiro Kishimoto', 'Parikshit Ram', 'Ambrish Rawat', 'Martin Wistuba', 'Paulito P. Palmes', 'Adi Botea']",,,,
Artificial Dummies for Urban Dataset Augmentation,"['Antonin Vobecky', 'David Hurych', 'Michal Uricar', 'Patrick Pérez', 'Josef Sivic']",https://arxiv.org/abs/2012.08274,"Existing datasets for training pedestrian detectors in images suffer from limited appearance and pose variation. The most challenging scenarios are rarely included because they are too difficult to capture due to safety reasons, or they are very unlikely to happen. The strict safety requirements in assisted and autonomous driving applications call for an extra high detection accuracy also in these rare situations. Having the ability to generate people images in arbitrary poses, with arbitrary appearances and embedded in different background scenes with varying illumination and weather conditions, is a crucial component for the development and testing of such applications. The contributions of this paper are three-fold. First, we describe an augmentation method for controlled synthesis of urban scenes containing people, thus producing rare or never-seen situations. This is achieved with a data generator (called DummyNet) with disentangled control of the pose, the appearance, and the target background scene. Second, the proposed generator relies on novel network architecture and associated loss that takes into account the segmentation of the foreground person and its composition into the background scene. Finally, we demonstrate that the data generated by our DummyNet improve performance of several existing person detectors across various datasets as well as in challenging situations, such as night-time conditions, where only a limited amount of training data is available. In the setup with only day-time data available, we improve the night-time detector by $17\%$ log-average miss rate over the detector trained with the day-time data only.",画像で歩行者検出器をトレーニングするための既存のデータセットは、外観とポーズのばらつきが限られています。最も困難なシナリオが含まれることはめったにありません。安全上の理由からキャプチャするのが難しすぎるか、発生する可能性が非常に低いためです。支援型および自動運転アプリケーションの厳格な安全要件により、これらのまれな状況でも非常に高い検出精度が求められます。任意のポーズ、任意の外観、さまざまな照明や気象条件のさまざまな背景シーンに埋め込まれた人物画像を生成する機能を持つことは、このようなアプリケーションの開発とテストにとって重要なコンポーネントです。この論文の貢献は3つあります。まず、人を含む都市のシーンを制御して合成し、まれな状況や見たことのない状況を作り出すための拡張方法について説明します。これは、ポーズ、外観、およびターゲットの背景シーンを解きほぐした制御を備えたデータジェネレーター（DummyNetと呼ばれる）を使用して実現されます。第二に、提案されたジェネレータは、前景の人物のセグメンテーションと背景シーンへのその構成を考慮に入れた、新しいネットワークアーキテクチャと関連する損失に依存しています。最後に、DummyNetによって生成されたデータが、さまざまなデータセット全体で、また限られた量のトレーニングデータしか利用できない夜間の条件などの困難な状況で、いくつかの既存の人物検出器のパフォーマンスを向上させることを示します。利用可能な日中のデータのみを使用するセットアップでは、日中のデータのみでトレーニングされた検出器よりも、夜間の検出器の対数平均ミス率が17％向上します。,https://d3i71xaburhd42.cloudfront.net/3ff24d04b7964b60dab1f7f8db59ab29f556b34d/2-Figure1-1.png
Explaining Neural Matrix Factorization with Gradient Rollback,"['Carolin Lawrence', 'Timo Sztyler', 'Mathias Niepert']",https://arxiv.org/abs/2010.05516,"Explaining the predictions of neural black-box models is an important problem, especially when such models are used in applications where user trust is crucial. Estimating the influence of training examples on a learned neural model's behavior allows us to identify training examples most responsible for a given prediction and, therefore, to faithfully explain the output of a black-box model. The most generally applicable existing method is based on influence functions, which scale poorly for larger sample sizes and models. 
We propose gradient rollback, a general approach for influence estimation, applicable to neural models where each parameter update step during gradient descent touches a smaller number of parameters, even if the overall number of parameters is large. Neural matrix factorization models trained with gradient descent are part of this model class. These models are popular and have found a wide range of applications in industry. Especially knowledge graph embedding methods, which belong to this class, are used extensively. We show that gradient rollback is highly efficient at both training and test time. Moreover, we show theoretically that the difference between gradient rollback's influence approximation and the true influence on a model's behavior is smaller than known bounds on the stability of stochastic gradient descent. This establishes that gradient rollback is robustly estimating example influence. We also conduct experiments which show that gradient rollback provides faithful explanations for knowledge base completion and recommender datasets.",ニューラルブラックボックスモデルの予測を説明することは重要な問題です。特に、そのようなモデルがユーザーの信頼が重要なアプリケーションで使用される場合はそうです。学習した神経モデルの動作に対するトレーニング例の影響を推定することで、特定の予測に最も責任のあるトレーニング例を特定できるため、ブラックボックスモデルの出力を忠実に説明できます。最も一般的に適用可能な既存の方法は、影響関数に基づいています。影響関数は、サンプルサイズとモデルが大きいほどスケーリングが不十分です。影響推定の一般的なアプローチである勾配ロールバックを提案します。これは、パラメーターの総数が多い場合でも、勾配降下中の各パラメーター更新ステップが少数のパラメーターに触れるニューラルモデルに適用できます。勾配降下法でトレーニングされた神経行列因数分解モデルは、このモデルクラスの一部です。これらのモデルは人気があり、業界で幅広い用途があります。特に、このクラスに属する知識グラフ埋め込みメソッドが広く使用されています。勾配ロールバックがトレーニング時とテスト時の両方で非常に効率的であることを示します。さらに、勾配ロールバックの違いが近似に影響を与え、モデルの動作に対する実際の影響が確率的勾配降下法の安定性に関する既知の境界よりも小さいことを理論的に示します。これにより、勾配ロールバックが例の影響を確実に推定していることがわかります。また、勾配ロールバックがナレッジベースの完成と推奨データセットの忠実な説明を提供することを示す実験も実施します。,https://d3i71xaburhd42.cloudfront.net/bdc5ac75729d195dfb6e03c47745602f720d93f0/3-Figure1-1.png
Binary Matrix Factorisation via Column Generation,"['Reka A Kovacs', 'Oktay Gunluk', 'Raphael Hauser']",https://arxiv.org/abs/2011.04457,"Identifying discrete patterns in binary data is an important dimensionality reduction tool in machine learning and data mining. In this paper, we consider the problem of low-rank binary matrix factorisation (BMF) under Boolean arithmetic. Due to the NP-hardness of this problem, most previous attempts rely on heuristic techniques. We formulate the problem as a mixed integer linear program and use a large scale optimisation technique of column generation to solve it without the need of heuristic pattern mining. Our approach focuses on accuracy and on the provision of optimality guarantees. Experimental results on real world datasets demonstrate that our proposed method is effective at producing highly accurate factorisations and improves on the previously available best known results for 16 out of 24 problem instances.",バイナリデータの離散パターンを特定することは、機械学習とデータマイニングにおける重要な次元削減ツールです。この論文では、ブール代数の下での低ランクのバイナリ行列因数分解（BMF）の問題を検討します。この問題のNP困難性のため、これまでのほとんどの試みはヒューリスティック手法に依存しています。問題を混合整数線形計画として定式化し、列生成の大規模最適化手法を使用して、ヒューリスティックパターンマイニングを必要とせずに問題を解決します。私たちのアプローチは、正確さと最適性の保証の提供に焦点を当てています。実世界のデータセットでの実験結果は、提案された方法が非常に正確な因数分解を生成するのに効果的であり、24の問題インスタンスのうち16について以前に利用可能な最もよく知られている結果を改善することを示しています。,https://d3i71xaburhd42.cloudfront.net/6f8f284d9ae3e611b91ac402fe0b3544898abddd/6-Figure1-1.png
Learning to Pre-Train Graph Neural Networks,"['Yuanfu Lu', 'Xunqiang Jiang', 'Yuan Fang', 'Chuan Shi']",,,,
Towards Reusable Network Components by Learning Compatible Representations,"['Michael Gygli', 'Jasper Uijlings', 'Vittorio Ferrari']",https://arxiv.org/abs/2004.03898,"This paper proposes to make a first step towards compatible and hence reusable network components. Rather than training networks for different tasks independently, we adapt the training process to produce network components that are compatible across tasks. In particular, we split a network into two components, a features extractor and a target task head, and propose various approaches to accomplish compatibility between them. We systematically analyse these approaches on the task of image classification using CIFAR-10 and STL-10. We demonstrate that we can produce components which are directly compatible without any finetuning or compromising accuracy on the original tasks. Afterwards, we demonstrate the use of compatible components on three applications: Unsupervised domain adaptation, transferring classifiers across feature extractors with different architectures, and increasing the computational efficiency of transfer learning.",このホワイトペーパーでは、互換性があり、したがって再利用可能なネットワークコンポーネントに向けた第一歩を踏み出すことを提案します。さまざまなタスクのネットワークを個別にトレーニングするのではなく、トレーニングプロセスを適応させて、タスク間で互換性のあるネットワークコンポーネントを作成します。特に、ネットワークを機能抽出とターゲットタスクヘッドの2つのコンポーネントに分割し、それらの間の互換性を実現するためのさまざまなアプローチを提案します。 CIFAR-10とSTL-10を使用して、画像分類のタスクに関するこれらのアプローチを体系的に分析します。元のタスクの精度を微調整したり妥協したりすることなく、直接互換性のあるコンポーネントを作成できることを示します。その後、3つのアプリケーションで互換性のあるコンポーネントを使用する方法を示します。教師なしドメインの適応、異なるアーキテクチャの特徴抽出器間での分類子の転送、転送学習の計算効率の向上です。,
Stable Adversarial Learning under Distributional Shifts,"['Jiashuo Liu', 'Zheyan Shen', 'Peng Cui', 'Linjun Zhou', 'Kun Kuang', 'Bo Li', 'Yishi Lin']",,,,
"Sub-Seasonal Climate Forecasting via Machine Learning: Challenges, Analysis, and Advances","['Sijie He', 'Xinyan Li', 'Timothy DelSole', 'Pradeep Ravikumar', 'Arindam Banerjee']",https://arxiv.org/abs/2006.07972,"Sub-seasonal climate forecasting (SSF) focuses on predicting key climate variables such as temperature and precipitation in the 2-week to 2-month time scales. Skillful SSF would have immense societal value, in areas such as agricultural productivity, water resource management, transportation and aviation systems, and emergency planning for extreme weather events. However, SSF is considered more challenging than either weather prediction or even seasonal prediction. In this paper, we carefully study a variety of machine learning (ML) approaches for SSF over the US mainland. While atmosphere-land-ocean couplings and the limited amount of good quality data makes it hard to apply black-box ML naively, we show that with carefully constructed feature representations, even linear regression models, e.g., Lasso, can be made to perform well. Among a broad suite of 10 ML approaches considered, gradient boosting performs the best, and deep learning (DL) methods show some promise with careful architecture choices. Overall, suitable ML methods are able to outperform the climatological baseline, i.e., predictions based on the 30-year average at a given location and time. Further, based on studying feature importance, ocean (especially indices based on climatic oscillations such as El Nino) and land (soil moisture) covariates are found to be predictive, whereas atmospheric covariates are not considered helpful.",サブシーズン気候予測（SSF）は、気温や降水量などの主要な気候変数を2週間から2か月の時間スケールで予測することに重点を置いています。熟練したSSFは、農業生産性、水資源管理、輸送および航空システム、異常気象の緊急計画などの分野で、計り知れない社会的価値を持っています。ただし、SSFは、天気予報や季節予報よりも難しいと考えられています。このホワイトペーパーでは、米国本土でのSSFのさまざまな機械学習（ML）アプローチを注意深く研究します。大気-陸-海の結合と限られた量の良質のデータにより、ブラックボックスMLを素朴に適用することは困難ですが、慎重に構築された特徴表現を使用すると、Lassoなどの線形回帰モデルでもうまく機能することができます。 。検討されている10MLアプローチの幅広いスイートの中で、勾配ブースティングが最高のパフォーマンスを発揮し、ディープラーニング（DL）メソッドは慎重なアーキテクチャの選択でいくつかの可能性を示しています。全体として、適切なML手法は、気候学的ベースライン、つまり、特定の場所と時間での30年平均に基づく予測を上回ることができます。さらに、特徴の重要性の研究に基づいて、海洋（特にエルニーニョなどの気候変動に基づく指標）と土地（土壌水分）の共変量は予測的であることがわかりますが、大気の共変量は有用であるとは見なされません。,https://d3i71xaburhd42.cloudfront.net/cac3eda036b01ff0c0c6babab25fb77dd8633afb/3-Figure1-1.png
Learning Light-Weight Translation Models from Deep Transformer,"['Bei Li', 'Ziyang Wang', 'Hui Liu', 'Quan Du', 'Tong Xiao', 'Chunliang Zhang', 'Jingbo Zhu']",https://arxiv.org/abs/2012.13866,"Recently, deep models have shown tremendous improvements in neural machine translation (NMT). However, systems of this kind are computationally expensive and memory intensive. In this paper, we take a natural step towards learning strong but light-weight NMT systems. We proposed a novel group-permutation based knowledge distillation approach to compressing the deep Transformer model into a shallow model. The experimental results on several benchmarks validate the effectiveness of our method. Our compressed model is 8× shallower than the deep model, with almost no loss in BLEU. To further enhance the teacher model, we present a Skipping Sub-Layer method to randomly omit sub-layers to introduce perturbation into training, which achieves a BLEU score of 30.63 on English-German newstest2014. The code is publicly available at https://github.com/libeineu/GPKD.",最近、ディープモデルはニューラル機械翻訳（NMT）の大幅な改善を示しています。ただし、この種のシステムは計算コストが高く、メモリを大量に消費します。このホワイトペーパーでは、強力でありながら軽量のNMTシステムの学習に向けて自然な一歩を踏み出しました。深いTransformerモデルを浅いモデルに圧縮するための新しいグループ順列ベースの知識蒸留アプローチを提案しました。いくつかのベンチマークでの実験結果は、私たちの方法の有効性を検証します。私たちの圧縮モデルは、深いモデルよりも8浅く、BLEUでの損失はほとんどありません。教師モデルをさらに強化するために、サブレイヤーをランダムに省略してトレーニングに摂動を導入するスキップサブレイヤーメソッドを提示します。これにより、英語-ドイツ語のnewstest2014でBLEUスコアが30.63になります。コードはhttps://github.com/libeineu/GPKDで公開されています。,https://d3i71xaburhd42.cloudfront.net/a817d740f64dcc04734ece08e20e136ccff240e7/2-Figure1-1.png
Elastic Consistency: A Practical Consistency Model for Distributed Stochastic Gradient Descent,"['Giorgi Nadiradze', 'Ilia Markov', 'Bapi Chatterjee', 'Vyacheslav Kungurtsev', 'Dan Alistarh']",,,,
Learning Rewards from Linguistic Feedback,"['Theodore R Sumers', 'Mark Ho', 'Robert Hawkins', 'Karthik Narasimhan', 'Tom Griffiths']",https://arxiv.org/abs/2009.14715,"We explore unconstrained natural language feedback as a learning signal for artificial agents. Humans use rich and varied language to teach, yet most prior work on interactive learning from language assumes a particular form of input (e.g. commands). We propose a general framework which does not make this assumption. We decompose linguistic feedback into two components: a grounding to $\textit{features}$ of a Markov decision process and $\textit{sentiment}$ about those features. We then perform an analogue of inverse reinforcement learning, regressing the teacher's sentiment on the features to infer their latent reward function. To evaluate our approach, we first collect a corpus of teaching behavior in a cooperative task where both teacher and learner are human. We use our framework to implement two artificial learners: a simple ""literal"" model and a ""pragmatic"" model with additional inductive biases. We baseline these with a neural network trained end-to-end to predict latent rewards. We then repeat our initial experiment pairing human teachers with our models. We find our ""literal"" and ""pragmatic"" models successfully learn from live human feedback and offer statistically-significant performance gains over the end-to-end baseline, with the ""pragmatic"" model approaching human performance on the task. Inspection reveals the end-to-end network learns representations similar to our models, suggesting they reflect emergent properties of the data. Our work thus provides insight into the information structure of naturalistic linguistic feedback as well as methods to leverage it for reinforcement learning.",人工エージェントの学習信号として、制約のない自然言語フィードバックを調査します。人間は豊かで多様な言語を使って教えますが、言語からのインタラクティブな学習に関するこれまでのほとんどの研究は、特定の形式の入力（コマンドなど）を前提としています。この仮定を行わない一般的なフレームワークを提案します。言語フィードバックを2つの要素に分解します。マルコフ決定過程の特徴への根拠とそれらの特徴に関する感情です。次に、逆強化学習の類似物を実行し、機能に対する教師の感情を回帰して、潜在的な報酬関数を推測します。私たちのアプローチを評価するために、私たちはまず、教師と学習者の両方が人間である協調タスクでの教育行動のコーパスを収集します。フレームワークを使用して、2つの人工学習者を実装します。単純な「リテラル」モデルと、追加の誘導バイアスを使用した「実用的な」モデルです。潜在的な報酬を予測するためにエンドツーエンドでトレーニングされたニューラルネットワークを使用して、これらのベースラインを作成します。次に、人間の教師とモデルを組み合わせた最初の実験を繰り返します。 「リテラル」モデルと「実用的」モデルは、人間のライブフィードバックから正常に学習し、エンドツーエンドのベースラインを超えて統計的に有意なパフォーマンスの向上を提供し、「実用的」モデルはタスクでの人間のパフォーマンスに近づきます。検査により、エンドツーエンドネットワークがモデルと同様の表現を学習していることが明らかになり、データの新たな特性を反映していることが示唆されます。したがって、私たちの仕事は、自然主義的な言語フィードバックの情報構造と、それを強化学習に活用する方法についての洞察を提供します。,https://d3i71xaburhd42.cloudfront.net/2d82567ffdf8877f8fafc1781bc253f07f82c30f/2-Figure1-1.png
FC-GAGA: Fully Connected Gated Graph Architecture for Spatio-Temporal Traffic Forecasting,"['Boris N. Oreshkin', 'Arezou Amini', 'Lucy Coyle', 'Mark Coates']",https://arxiv.org/abs/2007.15531,"Forecasting of multivariate time-series is an important problem that has applications in many domains, including traffic management, cellular network configuration, and quantitative finance. In recent years, researchers have demonstrated the value of applying deep learning architectures for these problems. A special case of the problem arises when there is a graph available that captures the relationships between the time-series. In this paper we propose a novel learning architecture that achieves performance competitive with or better than the best existing algorithms, without requiring knowledge of the graph. The key elements of our proposed architecture are (i) jointly performing backcasting and forecasting with a deep fully-connected architecture; (ii) stacking multiple prediction modules that target successive residuals; and (iii) learning a separate causal relationship graph for each layer of the stack. We can view each layer as predicting a component of the time-series; the differing nature of the causal graphs at different layers can be interpreted as indicating that the multivariate predictive relationships differ for different components. Experimental results for two public traffic network datasets illustrate the value of our approach, and ablation studies confirm the importance of each element of the architecture.",多変量時系列の予測は、トラフィック管理、セルラーネットワーク構成、定量的ファイナンスなど、多くのドメインで適用される重要な問題です。近年、研究者はこれらの問題にディープラーニングアーキテクチャを適用することの価値を実証しています。この問題の特殊なケースは、時系列間の関係をキャプチャする利用可能なグラフがある場合に発生します。この論文では、グラフの知識を必要とせずに、既存の最良のアルゴリズムと同等またはそれ以上のパフォーマンスを実現する新しい学習アーキテクチャを提案します。提案されたアーキテクチャの重要な要素は、（i）完全に接続された深いアーキテクチャと共同でバックキャスティングと予測を実行することです。 （ii）連続する残差を対象とする複数の予測モジュールを積み重ねます。 （iii）スタックの各層について個別の因果関係グラフを学習します。各レイヤーは、時系列のコンポーネントを予測するものと見なすことができます。異なるレイヤーでの因果グラフの異なる性質は、多変量予測関係が異なるコンポーネントで異なることを示していると解釈できます。 2つの公共交通ネットワークデータセットの実験結果は、私たちのアプローチの価値を示しており、アブレーション研究により、アーキテクチャの各要素の重要性が確認されています。,https://d3i71xaburhd42.cloudfront.net/d45be259ca31288b029f90be2fd2461c774b0197/2-Figure1-1.png
"Nearly Linear-Time, Parallelizable Algorithms for Non-Monotone Submodular Maximization",['Alan Kuhnle'],https://arxiv.org/abs/2009.01947,"We study parallelizable algorithms for maximization of a submodular function, not necessarily monotone, with respect to a cardinality constraint $k$. We improve the best approximation factor achieved by an algorithm that has optimal adaptivity and query complexity, up to logarithmic factors in the size $n$ of the ground set, from $0.039 - \epsilon$ to $0.193 - \epsilon$. We provide two algorithms; the first has approximation ratio $1/6 - \epsilon$, adaptivity $O( \log n )$, and query complexity $O( n \log k )$, while the second has approximation ratio $0.193 - \epsilon$, adaptivity $O( \log^2 n )$, and query complexity $O(n \log k)$. Heuristic versions of our algorithms are empirically validated to use a low number of adaptive rounds and total queries while obtaining solutions with high objective value in comparison with highly adaptive approximation algorithms.",カーディナリティ制約kに関して、必ずしも単調ではない劣モジュラ関数を最大化するための並列化可能なアルゴリズムを研究します。最適な適応性とクエリの複雑さを備えたアルゴリズムによって達成される最良の近似係数を、グラウンドセットのサイズnの対数係数（0.039から0.193）まで改善します。 2つのアルゴリズムを提供します。 1つ目は近似比1/6、適応性O（log n）、クエリの複雑さO（nlog k）で、2つ目は近似比0.193、適応性O（log2n）、クエリの複雑さO（nlog k）です。私たちのアルゴリズムのヒューリスティックバージョンは、高度に適応性のある近似アルゴリズムと比較して高い客観的価値を持つソリューションを取得しながら、少数の適応ラウンドと合計クエリを使用することが経験的に検証されています。,https://d3i71xaburhd42.cloudfront.net/f11dd4fc8fecc729edc02b2593fc29447843c16e/10-Figure1-1.png
XL-WSD: An Extra-Large and Cross-Lingual Evaluation Framework for Word Sense Disambiguation,"['Tommaso Pasini', 'Alessandro Raganato', 'Roberto Navigli']",,"Transformer-based architectures brought a breeze of change to Word Sense Disambiguation (WSD), improving models’ performances by a large margin. The fast development of new approaches has been further encouraged by a well-framed evaluation suite for English, which has allowed to keep track and fairly compare their performances. However, other languages have remained largely unexplored, as testing data are available for a few languages only and the evaluation setting is rather matted. In this paper, we untangle this situation by proposing XL-WSD, a cross-lingual evaluation benchmark for the WSD task featuring sense-annotated development and test sets in 18 languages from six different linguistic families, together with language-specific silver training data. We leverage XL-WSD datasets to conduct an extensive evaluation of neural and knowledge-based approaches, including the most recent multilingual language models. Results show that the zero-shot knowledge transfer across languages is a promising research direction within the WSD field, especially when considering low-resourced languages where large pretrained multilingual models still perform poorly. We make the evaluation suite and the code for performing the experiments available at https://sapienzanlp.github.io/xl-wsd/.",Transformerベースのアーキテクチャは、Word Sense Disambiguation（WSD）に簡単な変更をもたらし、モデルのパフォーマンスを大幅に向上させました。新しいアプローチの迅速な開発は、英語の適切に構成された評価スイートによってさらに促進されました。これにより、パフォーマンスを追跡し、公正に比較することができます。ただし、テストデータは一部の言語でのみ利用可能であり、評価設定はかなりマットになっているため、他の言語はほとんど未踏のままです。このホワイトペーパーでは、X-WSDを提案することで、この状況を解決します。XL-WSDは、言語固有のシルバートレーニングデータとともに、6つの異なる言語族からの18言語のセンス注釈付き開発およびテストセットを特徴とするWSDタスクの言語間評価ベンチマークです。 XL-WSDデータセットを活用して、最新の多言語言語モデルを含む、ニューラルおよび知識ベースのアプローチの広範な評価を実施します。結果は、言語間のゼロショットの知識移転がWSD分野内の有望な研究の方向性であることを示しています。特に、事前にトレーニングされた大規模な多言語モデルのパフォーマンスが依然として低い低リソースの言語を検討する場合はそうです。評価スイートと実験を実行するためのコードは、https：//sapienzanlp.github.io/xl-wsd/で入手できます。,https://d3i71xaburhd42.cloudfront.net/b5b7870f1e565eaba21c056e64fcf4a279b4265b/5-Table1-1.png
Knowledge-Aware Leap-LSTM: Integrating Prior Knowledge into Leap-LSTM towards Faster Long Text Classification,"['Jinhua Du', 'Yan Huang', 'Karo Moilanen']",,,,
Meta-Learning Framework with Applications to Zero-Shot Time-Series Forecasting,"['Boris N. Oreshkin', 'Dmitri Carpov', 'Chapados Nicolas', 'Yoshua Bengio']",https://arxiv.org/abs/2002.02887,"Can meta-learning discover generic ways of processing time-series (TS) from a diverse dataset so as to greatly improve generalization on new TS coming from different datasets? This work provides positive evidence to demonstrate this using a broad meta-learning framework which we show subsumes many existing meta-learning algorithms as specific cases. We further identify via theoretical analysis the meta-learning adaptation mechanisms within N-BEATS, a recent neural TS forecasting model. Our meta-learning theory predicts that N-BEATS iteratively generates a subset of its task-specific parameters based on a given TS input, thus gradually expanding the expressive power of the architecture on-the-fly. Our empirical results emphasize the importance of meta-learning for successful zero-shot forecasting to new sources of TS, supporting the claim that it is viable to train a neural network on a source TS dataset and deploy it on a different target TS dataset without retraining, resulting in performance that is at least as good as that of state-of-practice univariate forecasting models.",メタ学習は、さまざまなデータセットからの新しいTSの一般化を大幅に改善するために、さまざまなデータセットから時系列（TS）を処理する一般的な方法を発見できますか？この作業は、特定のケースとして多くの既存のメタ学習アルゴリズムを包含していることを示す幅広いメタ学習フレームワークを使用してこれを実証するための肯定的な証拠を提供します。さらに、理論的分析を介して、最近のニューラルTS予測モデルであるN-BEATS内のメタ学習適応メカニズムを特定します。私たちのメタ学習理論は、N-BEATSが特定のTS入力に基づいてタスク固有のパラメーターのサブセットを繰り返し生成することを予測しているため、アーキテクチャの表現力をオンザフライで徐々に拡張します。私たちの経験的結果は、TSの新しいソースへのゼロショット予測を成功させるためのメタ学習の重要性を強調し、ソースTSデータセットでニューラルネットワークをトレーニングし、再トレーニングせずに別のターゲットTSデータセットにデプロイすることが実行可能であるという主張をサポートします、その結果、少なくとも実際の単変量予測モデルと同等のパフォーマンスが得られます。,https://d3i71xaburhd42.cloudfront.net/ef281cace4094b34c9505ae40b881b28913c2168/8-Figure1-1.png
Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised Learning,"['Paola Cascante-Bonilla', 'Fuwen Tan', 'Yanjun Qi', 'Vicente Ordonez']",https://arxiv.org/abs/2001.06001,"In this paper we revisit the idea of pseudo-labeling in the context of semi-supervised learning where a learning algorithm has access to a small set of labeled samples and a large set of unlabeled samples. Pseudo-labeling works by applying pseudo-labels to samples in the unlabeled set by using a model trained on the combination of the labeled samples and any previously pseudo-labeled samples, and iteratively repeating this process in a self-training cycle. Current methods seem to have abandoned this approach in favor of consistency regularization methods that train models under a combination of different styles of self-supervised losses on the unlabeled samples and standard supervised losses on the labeled samples. We empirically demonstrate that pseudo-labeling can in fact be competitive with the state-of-the-art, while being more resilient to out-of-distribution samples in the unlabeled set. We identify two key factors that allow pseudo-labeling to achieve such remarkable results (1) applying curriculum learning principles and (2) avoiding concept drift by restarting model parameters before each self-training cycle. We obtain 94.91% accuracy on CIFAR-10 using only 4,000 labeled samples, and 68.87% top-1 accuracy on Imagenet-ILSVRC using only 10% of the labeled samples. The code is available at https://github.com/uvavision/Curriculum-Labeling",この論文では、学習アルゴリズムがラベル付きサンプルの小さなセットとラベルなしサンプルの大きなセットにアクセスできる半教師あり学習のコンテキストでの疑似ラベル付けのアイデアを再検討します。疑似ラベル付けは、ラベル付けされたサンプルと以前に疑似ラベル付けされたサンプルの組み合わせでトレーニングされたモデルを使用して、ラベル付けされていないセットのサンプルに疑似ラベルを適用し、このプロセスを自己トレーニングサイクルで繰り返し繰り返すことによって機能します。現在の方法では、このアプローチを放棄して、ラベルのないサンプルでのさまざまなスタイルの自己教師あり損失とラベル付きサンプルの標準的な教師あり損失の組み合わせでモデルをトレーニングする整合性正則化方法を採用しているようです。疑似ラベル付けは、実際には最先端技術と競合する可能性がある一方で、ラベル付けされていないセットの配布外のサンプルに対してより回復力があることを経験的に示しています。疑似ラベリングがそのような驚くべき結果を達成することを可能にする2つの重要な要因を特定します（1）カリキュラム学習の原則を適用することと（2）各自己トレーニングサイクルの前にモデルパラメーターを再開することによって概念のドリフトを回避すること。 94.91を取得します,
HARGAN: Heterogeneous Argument Attention Network for Persuasiveness Prediction,"['Kuo-Yu Huang', 'Hen-Hsen Huang', 'Hsin-Hsi Chen']",,,,
Data-Driven Competitive Algorithms for Online Knapsack and Set Cover,"['Ali Zeynali', 'Bo Sun', 'Mohammad Hajiesmaili', 'Adam Wierman']",https://arxiv.org/abs/2012.05361,"The design of online algorithms has tended to focus on algorithms with worst-case guarantees, e.g., bounds on the competitive ratio. However, it is well-known that such algorithms are often overly pessimistic, performing sub-optimally on non-worst-case inputs. In this paper, we develop an approach for data-driven design of online algorithms that maintain near-optimal worst-case guarantees while also performing learning in order to perform well for typical inputs. Our approach is to identify policy classes that admit global worst-case guarantees, and then perform learning using historical data within the policy classes. We demonstrate the approach in the context of two classical problems, online knapsack and online set cover, proving competitive bounds for rich policy classes in each case. Additionally, we illustrate the practical implications via a case study on electric vehicle charging.",オンラインアルゴリズムの設計は、競争率の限界など、最悪の場合の保証があるアルゴリズムに焦点を合わせる傾向があります。ただし、そのようなアルゴリズムはしばしば過度に悲観的であり、最悪の場合以外の入力に対して最適に実行されないことはよく知られています。このホワイトペーパーでは、典型的な入力に対して適切に実行するために学習を実行しながら、ほぼ最適な最悪の場合の保証を維持するオンラインアルゴリズムのデータ駆動型設計のアプローチを開発します。私たちのアプローチは、グローバルな最悪の場合の保証を認めるポリシークラスを特定し、ポリシークラス内の履歴データを使用して学習を実行することです。オンラインナップザックとオンラインセットカバーという2つの古典的な問題のコンテキストでアプローチを示し、それぞれの場合に豊富なポリシークラスの競争力を証明します。さらに、電気自動車の充電に関するケーススタディを通じて、実際の影響を説明します。,https://d3i71xaburhd42.cloudfront.net/b0a3d2672d5a8f5370703861ea5d49d6436ab512/5-Figure1-1.png
Multi-Dimensional Explanation of Target Variables from Documents,"['Diego Antognini', 'Claudiu Musat', 'Boi Faltings']",https://arxiv.org/abs/1909.11386,"Automated predictions require explanations to be interpretable by humans. Past work used attention and rationale mechanisms to find words that predict the target variable of a document. Often though, they result in a tradeoff between noisy explanations or a drop in accuracy. Furthermore, rationale methods cannot capture the multi-faceted nature of justifications for multiple targets, because of the non-probabilistic nature of the mask. In this paper, we propose the Multi-Target Masker (MTM) to address these shortcomings. The novelty lies in the soft multi-dimensional mask that models a relevance probability distribution over the set of target variables to handle ambiguities. Additionally, two regularizers guide MTM to induce long, meaningful explanations. We evaluate MTM on two datasets and show, using standard metrics and human annotations, that the resulting masks are more accurate and coherent than those generated by the state-of-the-art methods. Moreover, MTM is the first to also achieve the highest F1 scores for all the target variables simultaneously.",自動予測には、人間が解釈できる説明が必要です。過去の研究では、注意と理論的根拠のメカニズムを使用して、ドキュメントのターゲット変数を予測する単語を見つけました。ただし、多くの場合、それらはノイズの多い説明間のトレードオフまたは精度の低下をもたらします。さらに、理論的根拠の方法は、マスクの非確率的性質のために、複数のターゲットの正当化の多面的な性質を捉えることができません。この論文では、これらの欠点に対処するためにマルチターゲットマスカー（MTM）を提案します。目新しさは、あいまいさを処理するために、ターゲット変数のセット全体の関連性確率分布をモデル化するソフト多次元マスクにあります。さらに、2つのレギュラライザーがMTMをガイドして、長く意味のある説明を誘導します。 2つのデータセットでMTMを評価し、標準のメトリックと人間の注釈を使用して、結果のマスクが最先端の方法で生成されたものよりも正確で一貫性があることを示します。さらに、MTMは、すべてのターゲット変数に対して同時に最高のF1スコアを達成した最初の企業です。,https://d3i71xaburhd42.cloudfront.net/01bd82dbb7631fab78790392035bc0d2443e5d1b/1-Figure1-1.png
Fast Training of Provably Robust Neural Networks by SingleProp,"['Akhilan Boopathy', 'Lily Weng', 'Sijia Liu', 'Pin-Yu Chen', 'Gaoyuan Zhang', 'Luca Daniel']",https://arxiv.org/abs/2102.01208,"Recent works have developed several methods of defending neural networks against adversarial attacks with certified guarantees. However, these techniques can be computationally costly due to the use of certification during training. We develop a new regularizer that is both more efficient than existing certified defenses, requiring only one additional forward propagation through a network, and can be used to train networks with similar certified accuracy. Through experiments on MNIST and CIFAR-10 we demonstrate improvements in training speed and comparable certified accuracy compared to state-of-the-art certified defenses.",最近の研究では、認定された保証を使用して、敵対的攻撃からニューラルネットワークを防御するいくつかの方法が開発されています。ただし、これらの手法は、トレーニング中に認定を使用するため、計算コストが高くなる可能性があります。私たちは、既存の認定された防御よりも効率的で、ネットワークを介した追加の順伝播を1つだけ必要とし、同様の認定された精度でネットワークをトレーニングするために使用できる新しい正則化を開発します。 MNISTとCIFAR-10での実験を通じて、最先端の認定防御と比較して、トレーニング速度と同等の認定精度が向上していることを示しています。,https://d3i71xaburhd42.cloudfront.net/3e34b4f2f27f77eb2670958ef6ec8c758173db3b/7-Table1-1.png
Learning Adjustment Sets from Observational and Limited Experimental Data,"['Sofia Triantafillou', 'Greg Cooper']",https://arxiv.org/abs/2005.08749,"Estimating causal effects from observational data is not always possible due to confounding. Identifying a set of appropriate covariates (adjustment set) and adjusting for their influence can remove confounding bias; however, such a set is typically not identifiable from observational data alone. Experimental data do not have confounding bias, but are typically limited in sample size and can therefore yield imprecise estimates. Furthermore, experimental data often include a limited set of covariates, and therefore provide limited insight into the causal structure of the underlying system. In this work we introduce a method that combines large observational and limited experimental data to identify adjustment sets and improve the estimation of causal effects. The method identifies an adjustment set (if possible) by calculating the marginal likelihood for the experimental data given observationally-derived prior probabilities of potential adjustmen sets. In this way, the method can make inferences that are not possible using only the conditional dependencies and independencies in all the observational and experimental data. We show that the method successfully identifies adjustment sets and improves causal effect estimation in simulated data, and it can sometimes make additional inferences when compared to state-of-the-art methods for combining experimental and observational data.",交絡のため、観測データから因果関係を推定できるとは限りません。適切な共変量のセット（調整セット）を特定し、それらの影響を調整することで、交絡バイアスを取り除くことができます。ただし、このようなセットは通常、観測データだけからは識別できません。実験データには交絡バイアスはありませんが、通常はサンプルサイズが制限されているため、不正確な推定値が得られる可能性があります。さらに、実験データには限られた共変量のセットが含まれていることが多いため、基礎となるシステムの因果構造に対する洞察が限られています。この作業では、大規模な観測データと限られた実験データを組み合わせて調整セットを特定し、因果効果の推定を改善する方法を紹介します。この方法は、潜在的な調整セットの観測的に導出された事前確率を前提として、実験データの周辺尤度を計算することにより、調整セットを識別します（可能な場合）。このようにして、この方法では、すべての観測データと実験データの条件付き依存関係と独立性だけでは不可能な推論を行うことができます。この方法は、調整セットを正常に識別し、シミュレーションデータの因果効果の推定を改善し、実験データと観測データを組み合わせるための最先端の方法と比較すると、追加の推論を行うことができることを示します。,https://d3i71xaburhd42.cloudfront.net/f615f645ae62c16e91d7f8e3fa8b690ffe254c6a/2-Figure1-1.png
Online Class-Incremental Continual Learning with Adversarial Shapley Value,"['Dongsub Shim', 'Zheda Mai', 'Jihwan Jeong', 'Scott Sanner', 'Hyunwoo Kim', 'Jongseong Jang']",https://arxiv.org/abs/2009.00093,"As image-based deep learning becomes pervasive on every device, from cell phones to smart watches, there is a growing need to develop methods that continually learn from data while minimizing memory footprint and power consumption. While memory replay techniques have shown exceptional promise for this task of continual learning, the best method for selecting which buffered images to replay is still an open question. In this paper, we specifically focus on the online class-incremental setting where a model needs to learn new classes continually from an online data stream. To this end, we contribute a novel Adversarial Shapley value scoring method that scores memory data samples according to their ability to preserve latent decision boundaries for previously observed classes (to maintain learning stability and avoid forgetting) while interfering with latent decision boundaries of current classes being learned (to encourage plasticity and optimal learning of new class boundaries). Overall, we observe that our proposed ASER method provides competitive or improved performance compared to state-of-the-art replay-based continual learning methods on a variety of datasets.",画像ベースのディープラーニングが携帯電話からスマートウォッチに至るまですべてのデバイスに普及するにつれて、メモリフットプリントと電力消費を最小限に抑えながらデータから継続的に学習する方法を開発する必要性が高まっています。記憶再生技術は、継続的な学習というこのタスクに対して非常に有望であることが示されていますが、再生するバッファリングされた画像を選択するための最良の方法は、依然として未解決の問題です。このホワイトペーパーでは、モデルがオンラインデータストリームから継続的に新しいクラスを学習する必要があるオンラインクラスインクリメンタル設定に特に焦点を当てます。この目的のために、現在のクラスの潜在的な決定境界に干渉しながら、以前に観察されたクラスの潜在的な決定境界を保持する能力（学習の安定性を維持し、忘却を回避する）に従ってメモリデータサンプルをスコアリングする新しい敵対的シャープレイ値スコアリング方法を提供します学習した（可塑性と新しいクラス境界の最適な学習を促進するため）。全体として、提案されたASERメソッドは、さまざまなデータセットでの最先端のリプレイベースの継続的な学習メソッドと比較して、競争力のある、または改善されたパフォーマンスを提供することがわかります。,
Precision-Based Boosting,"['Mohammad Hossein Nikravan', 'Marjan Movahedan', 'Sandra Zilles']",,,,
Computing Ex Ante Coordinated Team-Maxmin Equilibria in Zero-Sum Multiplayer Extensive-Form Games,"['Youzhi Zhang', 'Bo An', 'Jakub Cerny']",,,,
Identity-Aware Graph Neural Networks,"['Jiaxuan You', 'Jonathan M Gomes-Selman', 'Rex Ying', 'Jure Leskovec']",https://arxiv.org/abs/2101.10320,"Message passing Graph Neural Networks (GNNs) provide a powerful modeling framework for relational data. However, the expressive power of existing GNNs is upper-bounded by the 1-Weisfeiler-Lehman (1-WL) graph isomorphism test, which means GNNs that are not able to predict node clustering coefficients and shortest path distances, and cannot differentiate between different d-regular graphs. Here we develop a class of message passing GNNs, named Identity-aware Graph Neural Networks (ID-GNNs), with greater expressive power than the 1-WL test. ID-GNN offers a minimal but powerful solution to limitations of existing GNNs. ID-GNN extends existing GNN architectures by inductively considering nodes’ identities during message passing. To embed a given node, IDGNN first extracts the ego network centered at the node, then conducts rounds of heterogeneous message passing, where different sets of parameters are applied to the center node than to other surrounding nodes in the ego network. We further propose a simplified but faster version of ID-GNN that injects node identity information as augmented node features. Altogether, both versions of ID-GNN represent general extensions of message passing GNNs, where experiments show that transforming existing GNNs to ID-GNNs yields on average 40% accuracy improvement on challenging node, edge, and graph property prediction tasks; 3% accuracy improvement on node and graph classification benchmarks; and 15% ROC AUC improvement on real-world link prediction tasks. Additionally, ID-GNNs demonstrate improved or comparable performance over other task-specific graph networks.",メッセージパッシンググラフニューラルネットワーク（GNN）は、リレーショナルデータの強力なモデリングフレームワークを提供します。ただし、既存のGNNの表現力は、1-Weisfeiler-Lehman（1-WL）グラフ同型テストによって上限が定められています。つまり、ノードのクラスタリング係数と最短経路距離を予測できず、異なるものを区別できないGNNです。 d-正則グラフ。ここでは、1-WLテストよりも優れた表現力を備えたIdentity-aware Graph Neural Networks（ID-GNN）という名前のメッセージパッシングGNNのクラスを開発します。 ID-GNNは、既存のGNNの制限に対する最小限で強力なソリューションを提供します。 ID-GNNは、メッセージパッシング中にノードIDを誘導的に考慮することにより、既存のGNNアーキテクチャを拡張します。特定のノードを埋め込むために、IDGNNは最初にノードを中心とするエゴネットワークを抽出し、次に異種メッセージパッシングのラウンドを実行します。ここで、エゴネットワーク内の他の周囲のノードとは異なるパラメータのセットがセンターノードに適用されます。さらに、ノードID情報を拡張ノード機能として挿入するID-GNNの簡略化された高速バージョンを提案します。全体として、ID-GNNの両方のバージョンは、メッセージパッシングGNNの一般的な拡張を表しており、実験では、既存のGNNをID-GNNに変換すると平均40が得られることが示されています。,https://d3i71xaburhd42.cloudfront.net/a1c5e390a4f1da4f000a160b9ae8f15cfd0244b6/2-Figure1-1.png
Unsupervised Learning of Graph Hierarchical Abstractions with Differentiable Coarsening and Optimal Transport,"['Tengfei Ma', 'Jie Chen']",https://arxiv.org/abs/1912.11176,"Hierarchical abstractions are a methodology for solving large-scale graph problems in various disciplines. Coarsening is one such approach: it generates a pyramid of graphs whereby the one in the next level is a structural summary of the prior one. With a long history in scientific computing, many coarsening strategies were developed based on mathematically driven heuristics. Recently, resurgent interests exist in deep learning to design hierarchical methods learnable through differentiable parameterization. These approaches are paired with downstream tasks for supervised learning. In practice, however, supervised signals (e.g., labels) are scarce and are often laborious to obtain. In this work, we propose an unsupervised approach, coined OTCoarsening, with the use of optimal transport. Both the coarsening matrix and the transport cost matrix are parameterized, so that an optimal coarsening strategy can be learned and tailored for a given set of graphs. We demonstrate that the proposed approach produces meaningful coarse graphs and yields competitive performance compared with supervised methods for graph classification and regression.",階層的抽象化は、さまざまな分野の大規模なグラフの問題を解決するための方法論です。粗大化はそのようなアプローチの1つです。グラフのピラミッドを生成し、次のレベルのグラフは前のグラフの構造の要約になります。科学計算の長い歴史により、数学的に駆動されるヒューリスティックに基づいて多くの粗大化戦略が開発されました。最近、微分可能なパラメーター化を通じて学習可能な階層的手法を設計するための深層学習に復活の関心が集まっています。これらのアプローチは、教師あり学習のためのダウンストリームタスクとペアになっています。ただし、実際には、監視対象の信号（ラベルなど）は不足しており、取得するのに手間がかかることがよくあります。この作業では、最適なトランスポートを使用して、教師なしアプローチ、造語OTCoarseningを提案します。粗大化マトリックスと輸送コストマトリックスの両方がパラメーター化されているため、最適な粗大化戦略を学習し、特定のグラフのセットに合わせて調整できます。提案されたアプローチは、意味のある粗いグラフを生成し、グラフの分類と回帰の教師あり手法と比較して競争力のあるパフォーマンスをもたらすことを示します。,https://d3i71xaburhd42.cloudfront.net/40484fb2739a5169950a4b59e33f03297525b668/4-Figure1-1.png
Inverse Reinforcement Learning with Natural Language Goals,"['Li Zhou', 'Kevin Small']",https://arxiv.org/abs/2008.06924,"Humans generally use natural language to communicate task requirements amongst each other. It is desirable that this would be similar for autonomous machines (e.g. robots) such that humans can convey goals or assign tasks more easily. However, understanding natural language goals and mapping them to sequences of states and actions is challenging. Previous research has encountered difficulty generalizing learned policies to new natural language goals and environments. In this paper, we propose an adversarial inverse reinforcement learning algorithm that learns a language-conditioned policy and reward function. To improve the generalization of the learned policy and reward function, we use a variational goal generator that relabels trajectories and samples diverse goals during training. Our algorithm outperforms baselines by a large margin on a vision-based natural language instruction following dataset, demonstrating a promising advance in providing natural language instructions to agents without reliance on instruction templates.",人間は通常、自然言語を使用してタスク要件を相互に伝達します。人間が目標を伝えたり、タスクをより簡単に割り当てたりできるように、これは自律型マシン（ロボットなど）でも同様であることが望ましい。ただし、自然言語の目標を理解し、それらを一連の状態やアクションにマッピングすることは困難です。以前の研究では、学習したポリシーを新しい自然言語の目標と環境に一般化するのが困難でした。本論文では、言語条件付きポリシーと報酬関数を学習する敵対的逆強化学習アルゴリズムを提案します。学習したポリシーと報酬関数の一般化を改善するために、トレーニング中に軌道にラベルを付け直し、さまざまな目標をサンプリングする変分目標ジェネレーターを使用します。私たちのアルゴリズムは、データセットに続くビジョンベースの自然言語命令でベースラインを大幅に上回っており、命令テンプレートに依存せずにエージェントに自然言語命令を提供する上で有望な進歩を示しています。,https://d3i71xaburhd42.cloudfront.net/b54b4de7371351037857a6dc8cd276125bee8818/7-Figure1-1.png
Towards Feature Space Adversarial Attack by Style Perturbation,"['Qiuling Xu', 'Guanhong Tao', 'Siyuan Cheng', 'Xiangyu Zhang']",,,,
Data Augmentation for Graph Neural Networks,"['Tong Zhao', 'Yozen Liu', 'Leonardo Neves', 'Oliver J Woodford', 'Meng Jiang', 'Neil Shah']",https://arxiv.org/abs/2006.06830,"Data augmentation has been widely used to improve generalizability of machine learning models. However, comparatively little work studies data augmentation for graphs. This is largely due to the complex, non-Euclidean structure of graphs, which limits possible manipulation operations. Augmentation operations commonly used in vision and language have no analogs for graphs. Our work studies graph data augmentation for graph neural networks (GNNs) in the context of improving semi-supervised node-classification. We discuss practical and theoretical motivations, considerations and strategies for graph data augmentation. Our work shows that neural edge predictors can effectively encode class-homophilic structure to promote intra-class edges and demote inter-class edges in given graph structure, and our main contribution introduces the GAug graph data augmentation framework, which leverages these insights to improve performance in GNN-based node classification via edge prediction. Extensive experiments on multiple benchmarks show that augmentation via GAug improves performance across GNN architectures and datasets.",データ拡張は、機械学習モデルの一般化可能性を向上させるために広く使用されています。ただし、グラフのデータ拡張を研究する作業は比較的少ないです。これは主に、グラフの複雑な非ユークリッド構造が原因であり、可能な操作操作が制限されます。視覚と言語で一般的に使用される拡張操作には、グラフの類似物がありません。私たちの仕事は、半教師ありノード分類を改善するという文脈で、グラフニューラルネットワーク（GNN）のグラフデータ拡張を研究しています。グラフデータ拡張の実際的および理論的な動機、考慮事項、および戦略について説明します。私たちの仕事は、ニューラルエッジ予測子がクラス同好性構造を効果的にエンコードして、クラス内エッジを促進し、特定のグラフ構造のクラス間エッジを降格できることを示しています。主な貢献は、これらの洞察を活用してパフォーマンスを向上させるGAugグラフデータ拡張フレームワークを紹介します。エッジ予測によるGNNベースのノード分類。複数のベンチマークでの広範な実験により、GAugを介した拡張により、GNNアーキテクチャとデータセット全体のパフォーマンスが向上することが示されています。,https://d3i71xaburhd42.cloudfront.net/7ed782385594c5233452cba9be211c2298f465eb/2-Figure1-1.png
Estimating alpha-Rank by Maximizing Information Gain,"['Tabish Rashid', 'Cheng Zhang', 'Kamil Ciosek']",https://arxiv.org/abs/2101.09178,"Game theory has been increasingly applied in settings where the game is not known outright, but has to be estimated by sampling. For example, meta-games that arise in multi-agent evaluation can only be accessed by running a succession of expensive experiments that may involve simultaneous deployment of several agents. In this paper, we focus on α-rank, a popular game-theoretic solution concept designed to perform well in such scenarios. We aim to estimate the α-rank of the game using as few samples as possible. Our algorithm maximizes information gain between an epistemic belief over the α-ranks and the observed payoff. This approach has two main benefits. First, it allows us to focus our sampling on the entries that matter the most for identifying the α-rank. Second, the Bayesian formulation provides a facility to build in modeling assumptions by using a prior over game payoffs. We show the benefits of using information gain as compared to the confidence interval criterion of ResponseGraphUCB (Rowland et al. 2019), and provide theoretical results justifying our method.",ゲーム理論は、ゲームが完全に知られていないが、サンプリングによって推定されなければならない設定でますます適用されています。たとえば、マルチエージェント評価で発生するメタゲームにアクセスするには、複数のエージェントの同時展開を伴う可能性のある一連の高価な実験を実行する必要があります。このホワイトペーパーでは、このようなシナリオで適切に機能するように設計された、人気のあるゲーム理論ソリューションの概念であるランクに焦点を当てます。できるだけ少ないサンプルを使用して、ゲームのランクを推定することを目指しています。私たちのアルゴリズムは、ランクに対する認識論的信念と観察されたペイオフの間の情報ゲインを最大化します。このアプローチには2つの主な利点があります。まず、-rankを識別するために最も重要なエントリにサンプリングを集中させることができます。第2に、ベイジアン定式化は、事​​前のゲームオーバーペイオフを使用してモデリングの仮定を組み込む機能を提供します。 ResponseGraphUCBの信頼区間基準（Rowland etal。2019）と比較して、情報ゲインを使用することの利点を示し、私たちの方法を正当化する理論的結果を提供します。,https://d3i71xaburhd42.cloudfront.net/4850e41f26659780136a28af72ddb3f7ecd8ae55/3-Figure1-1.png
Decentralized Policy Gradient Descent Ascent for Safe Multi-Agent Reinforcement Learning,"['Songtao Lu', 'Kaiqing Zhang', 'Tianyi Chen', 'Tamer Basar', 'Lior Horesh']",,"This paper deals with distributed reinforcement learning problems with safety constraints. In particular, we consider that a team of agents cooperate in a shared environment, where each agent has its individual reward function and safety constraints that involve all agents’ joint actions. As such, the agents aim to maximize the team-average long-term return, subject to all the safety constraints. More intriguingly, no central controller is assumed to coordinate the agents, and both the rewards and constraints are only known to each agent locally/privately. Instead, the agents are connected by a peer-to-peer communication network to share information with their neighbors. In this work, we first formulate this problem as a distributed constrained Markov decision process (D-CMDP) with networked agents. Then, we propose a decentralized policy gradient (PG) method, Safe Dec-PG, to perform policy optimization based on this D-CMDP model over a network. Convergence guarantees, together with numerical results, showcase the superiority of the proposed algorithm. To the best of our knowledge, this is the first decentralized PG algorithm that accounts for the coupled safety constraints with a quantifiable convergence rate in the multi-agent reinforcement learning. Finally, we emphasize that our algorithm is also novel in solving general decentralized stochastic nonconvex-concave minimax optimization problems, where both the algorithm design and corresponding theoretical analysis are of independent interest. Introduction Reinforcement learning (RL) has achieved tremendous success in many sequential decision-making problems in (Mnih et al. 2015; Sutton and Barto 2018), such as operations research, optimal control, bounded rationality, machine learning, etc., where an agent explores the interactions with an environment so that it is able to maximize a cumulative reward through this learning process. Beyond applying the classical RL techniques in control systems, physical con∗The research of K.Z. and T.B. was supported in part by the US Army Research Laboratory (ARL) Cooperative Agreement W911NF-17-2-0196, in part by the Office of Naval Research (ONR) MURI Grant N00014-16-1-2710, and in part by the Air Force Office of Scientific Research (AFOSR) Grant FA9550-19-1-0353. †The work of T. Chen was supported by the RPI-IBM Artificial Intelligence Research Collaboration (AIRC). Copyright c ⃝ 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. straints or safety considerations will also be the key components of determining the performance of an RL system. Especially, this is more important in multi-agent RL (MARL) that models the sequential decision-making of multiple agents in a shared environment, while each agent’s objective and the system evolution are both affected by the decisions made by all agents (Nguyen et al. 2014). Background of multi-agent RL The studies of MARL can be traced back to Q-learning in (Claus and Boutilier 1998) and (Wolpert, Wheeler, and Tumer 1999), with applications to network routing (Boyan and Littman 1994) and power network control (Schneider et al. 1999). However, all the algorithms involved in these works are heuristic without performance guarantees. Recent empirical results of deep multi-agent collaborative RL algorithms can also be found in (Gupta, Egorov, and Kochenderfer 2017; Lowe et al. 2017; Omidshafiei et al. 2017). One of the earliest distributed RL algorithm with convergence guarantees was reported in (Lauer and Riedmiller 2000), which is tailored to the tabular multi-agent Markov decision process (MDP) setting, and another one (Nguyen et al. 2014). Then, a distributed Q-learning algorithm was developed with being provably able to learn the desired value function and the optimal stationary control policy at each network agent through a consensus network, where each agent can only communicate with their neighbors (Kar, Moura, and Poor 2013). In the same setup, fully decentralized actor-critic algorithms with function approximation were developed in (Zhang et al. 2018) to handle large or even continuous state-action spaces. However, the convergence in (Zhang et al. 2018) was again established in an asymptotic sense. For a fixed policy, decentralized policy evaluation (value function approximations) approaches for MARL have been studied in (Wai et al. 2018; Doan, Maguluri, and Romberg 2019; Qu et al. 2019). (Please see also the recent surveys (Zhang, Yang, and Başar 2019; Lee et al. 2019) and references therein.) Related work Decentralized and distributed algorithms with quantifiable convergence rate guarantees in the optimization community have been developed for many decades (Nedic, Ozdaglar, and Parrilo 2010) in various scenarios, inTable 1: A comparison of stochastic non-convex concave minmax algorithms with convergence to (a neighborhood of) firstorder stationary points (FOSPs). Algorithm Rate Decentralized Stochastic Implementation PGSMD (Rafique et al. 2018) O ( ε−6 ) 7 3 double-loop Multi-GDA (Nouiehed et al. 2019) N/A 7 7 double-loop HiBSA (Lu et al. 2020) N/A 7 7 single-loop GDA (Lin, Jin, and Jordan 2019) O ( ε−8 ) 7 3 single-loop Safe Dec-PG (this work) O ( ε−4 ) 3 3 single-loop cluding (strongly) convex and non-convex cases. Recent advances in distributed non-convex optimization show that decentralized stochastic gradient descent or tracking (DSGD/DSGT) is able to train neural networks much faster than the centralized algorithms in terms of running time numerically (Lian et al. 2017; Lu et al. 2019). Also, it has been indicated in theory that there is a linear speed-up of performing decentralized optimization compared with the centralized one in terms of the number of nodes (Lian et al. 2017; Tang et al. 2018; Lu and Wu 2020). Moreover, in practice, the data would be collected through the sensors over a network, so the distributed learning becomes one of the most signal, data, and information processing tools. (Please see a survey (Chang et al. 2020) of recent distributed non-convex optimization algorithms and their applications.) However, the safe RL problem is not only maximizing rewards but also takes practical issues into account or introduces some prior knowledge of the model in advance, where there would be multiple cumulative long-term reward functions incorporated as the constraints (Paternain et al. 2019a; Wachi and Sui 2020). Unfortunately, none of the existing works deal with the safety constraints that are also non-convex, no need to mention their distributed implementation over a network. By the primal-dual optimization framework, the safe RL problem can be formulated as a min-max saddle point form by the method of Lagrange multipliers or dualizing the constraints (Boyd and Vandenberghe 2004). However, different from the classical supervised learning, e.g., support vector machine and least squares regression, the policy in RL is mostly parametrized by a (deep) neural network so that the cumulative reward functions are non-convex. Hence, the duality gap in this case is not zero in general, which makes the optimization process much more difficult than the traditional convex-concave min-max problem even in the centralized setting. Interestingly, some recent exciting results illustrate that the duality gap in safe RL problems could be zero (Paternain et al. 2019b) by assuming some oracle that can find the global optimal solution of the Lagrangian with respect to policy. It is inspiring that safe RL might be solved efficiently to high-quality solutions by the non-convex minmax solvers. During the last few years, solving non-convex min-max saddle-point problems has gained huge popularity and indicated significant power of optimizing the interest of parameters in many machine learning and/or artificial intelligence problems, including adversarial learning, robust neural nets or generative adversarial nets (GANs) training, fair resource allocation (Razaviyayn et al. 2020). The main idea of designing these algorithms is to perform gradient descent and ascent with respect to the objective functions, such as gradient descent ascent (GDA) algorithm (Lin, Jin, and Jordan 2019), multi-GDA (Nouiehed et al. 2019), proximally guided stochastic mirror descent method (PGSMD) (Rafique et al. 2018), and hybrid block successive approximation (HiBSA) (Lu et al. 2020). The difference between GDA and multiGDA is that the latter performs multiple steps of gradient ascent updates instead of one. Among these algorithms, HiBSA achieves the fastest convergence rate with only a single loop update rule to optimization variables for the deterministic non-convex case. However, there is no theoretical guarantee that HiBSA is amenable to handle the stochasticity of the samples in the non-convex (strongly) concave min-max problems. Further, all these algorithms are centralized, so it is not clear whether they can be used for a multi-agent system. Recently, there are some interesting works regarding the distributed training for a class of GANs (Liu et al. 2019b, 2020), where the problem is formulated as a decentralized non-convex saddle-point problem. But both of them require that the objective function satisfy the Minty variational inequality (MVI), otherwise, these methods cannot converge to an ε-first-order stationary point (FOSP) of the considered problem even the number of iterations is infinite. While in RL/MARL there is no evidence which can indicate that discounted cumulative reward function satisfies MVI again due to the nonconvexity of the loss function when the policy at each node is parametrized by a neural net. Main contributions In this work, by leveraging the min-max saddle-point formulation, we propose the first safe decentralized policy gradient (PG) descent and ascent algorithm, i.e., Safe Dec-PG, which is able to deal with a class of multi-agent safe RL problems over a graph. Importantly, we provide theoretical results that quantify the",この論文は、安全制約を伴う分散強化学習問題を扱っています。特に、エージェントのチームは共有環境で協力していると考えています。共有環境では、各エージェントに個別の報酬機能と、すべてのエージェントの共同アクションを伴う安全上の制約があります。そのため、エージェントは、すべての安全上の制約を条件として、チーム平均の長期的な利益を最大化することを目指しています。さらに興味深いことに、エージェントを調整する中央コントローラーは想定されておらず、報酬と制約の両方が各エージェントにローカル/プライベートでのみ知られています。代わりに、エージェントはピアツーピア通信ネットワークによって接続され、ネイバーと情報を共有します。この作業では、最初に、ネットワーク化されたエージェントを使用した分散制約付きマルコフ決定過程（D-CMDP）としてこの問題を定式化します。次に、分散型ポリシー勾配（PG）メソッドであるSafe Dec-PGを提案し、ネットワーク上でこのD-CMDPモデルに基づいてポリシーの最適化を実行します。収束保証は、数値結果とともに、提案されたアルゴリズムの優位性を示しています。私たちの知る限り、これは、マルチエージェント強化学習における定量化可能な収束率と結合された安全制約を説明する最初の分散型PGアルゴリズムです。最後に、アルゴリズムの設計と対応する理論的分析の両方が独立した関心事である、一般的な分散型確率的非凸凹ミニマックス最適化問題を解く上で、私たちのアルゴリズムも斬新であることを強調します。はじめに強化学習（RL）は、オペレーションズリサーチ、最適制御、限定合理性、機械学習など、（Mnihetal。2015; Sutton and Barto 2018）の多くの連続した意思決定問題で大きな成功を収めています。エージェントは、この学習プロセスを通じて累積報酬を最大化できるように、環境との相互作用を調査します。制御システムに古典的なRL技術を適用するだけでなく、物理的制御KZとTBの研究は、米国陸軍研究所（ARL）の協力協定W911NF-17-2-0196によって部分的にサポートされ、海軍研究局（ONR ）MURI Grant N00014-16-1-2710、および一部は空軍科学研究局（AFOSR）GrantFA9550-19-1-0353による。 T. Chenの作業は、RPI-IBM人工知能研究コラボレーション（AIRC）によってサポートされました。 Copyright c 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org）。全著作権所有。ひずみや安全性の考慮事項も、RLシステムのパフォーマンスを決定する重要な要素になります。特に、これは、共有環境での複数のエージェントの順次意思決定をモデル化するマルチエージェントRL（MARL）でより重要ですが、各エージェントの目的とシステムの進化は、すべてのエージェントによる決定の影響を受けます（Nguyen et al.2014）。マルチエージェントRLの背景MARLの研究は、ネットワークルーティング（Boyan and Littman 1994）および電力ネットワークへの適用を伴う（Claus and Boutilier 1998）および（Wolpert、Wheeler、and Tumer 1999）のQ学習にまでさかのぼることができます。コントロール（Schneider et al.1999）。ただし、これらの作業に関連するすべてのアルゴリズムは、パフォーマンスが保証されていないヒューリスティックです。ディープマルチエージェントコラボレーティブRLアルゴリズムの最近の経験的結果は、（Gupta、Egorov、およびKochenderfer 2017; Loweetal。2017; Omidshafiei etal。2017）にもあります。収束が保証された最も初期の分散RLアルゴリズムの1つが（Lauer and Riedmiller 2000）で報告されました。これは、表形式のマルチエージェントマルコフ決定過程（MDP）設定に合わせて調整され、もう1つ（Nguyen et al.2014）です。次に、分散型Q学習アルゴリズムが開発され、コンセンサスネットワークを介して各ネットワークエージェントで目的の値関数と最適な定常制御ポリシーを学習できることが証明されました。各エージェントは、隣接するエージェント（Kar、Moura、および悪い2013）。同じ設定で、関数近似を使用した完全に分散化されたアクター批評アルゴリズムが（Zhang etal。2018）で開発され、大規模または連続的な状態アクション空間を処理しました。ただし、（Zhang etal。2018）の収束は、漸近的な意味で再び確立されました。固定政策については、MARLの分散型政策評価（価値関数近似）アプローチが研究されています（Wai et al.2018; Doan、Magluri、and Romberg 2019; Qu et al.2019）。 （最近の調査（Zhang、Yang、およびBasar 2019; Lee etal。2019）およびその中の参考文献も参照してください。）関連作業最適化コミュニティで定量化可能な収束率が保証された分散型および分散型アルゴリズムは、何十年にもわたって開発されてきました（Nedic 、Ozdaglar、およびParrilo 2010）、さまざまなシナリオで、表1：1次停留点（FOSP）（の近傍）への収束を伴う確率的非凸凹型ミニマックスアルゴリズムの比較。アルゴリズムレート分散型確率的実装PGSMD（Rafique etal。2018）O（6）7 3ダブルループマルチGDA（Nouiehed etal。2019）N / A 7 7ダブルループHiBSA（Lu etal。2020）N / A 7 7シングルループGDA（Lin、Jin、およびJordan 2019）O（8）7 3シングルループSafeDec-PG（この作業）O（4）3 3シングルループ（強く）凸状および非凸型を含む凸型の場合。分散型非凸最適化の最近の進歩は、分散型確率的勾配降下法または追跡法（DSGD / DSGT）が、実行時間の数値に関して、集中型アルゴリズムよりもはるかに高速にニューラルネットワークをトレーニングできることを示しています（Lian et al.2017; Lu etal。 2019）。また、理論的には、ノード数の点で、集中型最適化と比較して分散型最適化の実行が直線的に高速化されることが示されています（Lian et al.2017; Tang et al.2018; Lu and Wu 2020） 。さらに、実際には、データはネットワーク上のセンサーを介して収集されるため、分散学習は最も信号、データ、および情報処理ツールの1つになります。 （最近の分散非凸最適化アルゴリズムとそのアプリケーションの調査（Chang etal。2020）を参照してください。）ただし、安全なRL問題は、報酬を最大化するだけでなく、実用的な問題を考慮に入れるか、事前にモデル化し、制約として複数の累積的な長期報酬関数が組み込まれる場合（Paternainetal。2019a; Wachi and Sui 2020）。残念ながら、既存の作業はいずれも、凸面ではない安全上の制約を扱っておらず、ネットワークを介した分散実装について言及する必要はありません。 primal-dual最適化フレームワークにより、安全なRL問題は、ラグランジュ乗数法または制約の二重化によって、最小-最大鞍点形式として定式化できます（Boyd and Vandenberghe2004）。ただし、サポートベクターマシンや最小二乗回帰などの従来の教師あり学習とは異なり、RLのポリシーは、ほとんどの場合（ディープ）ニューラルネットワークによってパラメーター化されるため、累積報酬関数は非凸関数になります。したがって、この場合の双対性ギャップは一般にゼロではなく、集中化された設定であっても、最適化プロセスは従来の凸凹ミニマックス問題よりもはるかに困難になります。興味深いことに、最近のいくつかのエキサイティングな結果は、ポリシーに関してラグランジアンのグローバルな最適解を見つけることができるオラクルを仮定することにより、安全なRL問題の双対性ギャップがゼロになる可能性があることを示しています（Paternain et al.2019b）。安全なRLが、非凸ミニマックスソルバーによって高品質のソリューションに効率的に解決される可能性があることは刺激的です。過去数年の間に、非凸の最小-最大鞍点問題の解決は非常に人気があり、敵対的学習、堅牢なニューラルネット、または生成的敵対的ネット（GAN）トレーニング、公正なリソース割り当て（Razaviyayn et al.2020）。これらのアルゴリズムを設計する主なアイデアは、勾配降下上昇（GDA）アルゴリズム（Lin、Jin、およびJordan 2019）、マルチGDA（Nouiehed etal。2019）などの目的関数に関して勾配降下および上昇を実行することです。 、近位誘導確率的ミラー降下法（PGSMD）（Rafique etal。2018）、およびハイブリッドブロック逐次近似（HiBSA）（Lu et al.2020）。 GDAとmultiGDAの違いは、後者が1つではなく複数の勾配上昇更新ステップを実行することです。これらのアルゴリズムの中で、HiBSAは、決定論的な非凸の場合の最適化変数への単一のループ更新ルールのみで、最速の収束率を達成します。ただし、HiBSAが非凸（強く）凹のミニマックス問題でサンプルの確率論を処理できるという理論上の保証はありません。さらに、これらのアルゴリズムはすべて一元化されているため、マルチエージェントシステムに使用できるかどうかは明確ではありません。最近、GANのクラスの分散トレーニングに関する興味深い研究がいくつかあり（Liu etal。2019b、2020）、問題は分散型の非凸鞍点問題として定式化されています。ただし、どちらも目的関数がミンティ変分不等式（MVI）を満たす必要があります。そうでない場合、反復回数が無限であっても、これらの方法は考慮される問題の1次停留点（FOSP）に収束できません。 RL / MARLでは、各ノードのポリシーがニューラルネットによってパラメーター化されている場合、損失関数の非凸性のために、割引された累積報酬関数が再びMVIを満たすことを示す証拠はありません。主な貢献この作業では、最小-最大鞍点定式化を活用することにより、最初の安全な分散型ポリシー勾配（PG）の下降および上昇アルゴリズム、つまり、マルチのクラスを処理できるSafeDec-PGを提案します。 -グラフ上のエージェントセーフRL問題。重要なのは、,https://d3i71xaburhd42.cloudfront.net/d59d3eb12f58ddf10eed0a6bf4a46a8ee6d8c548/7-Figure1-1.png
Differentially Private Decomposable Submodular Maximization,"['Anamay Chaturvedi', 'Huy Nguyen', 'Lydia Zakynthinou']",https://arxiv.org/abs/2005.14717,"We study the problem of differentially private constrained maximization of decomposable submodular functions. A submodular function is decomposable if it takes the form of a sum of submodular functions. The special case of maximizing a monotone, decomposable submodular function under cardinality constraints is known as the Combinatorial Public Projects (CPP) problem [Papadimitriou et al., 2008]. Previous work by Gupta et al. [2010] gave a differentially private algorithm for the CPP problem. We extend this work by designing differentially private algorithms for both monotone and non-monotone decomposable submodular maximization under general matroid constraints, with competitive utility guarantees. We complement our theoretical bounds with experiments demonstrating empirical performance, which improves over the differentially private algorithms for the general case of submodular maximization and is close to the performance of non-private algorithms.",分解可能な劣モジュラ関数の差分プライベート制約付き最大化の問題を研究します。劣モジュラ関数は、劣モジュラ関数の和の形をとる場合、分解可能です。カーディナリティ制約の下で単調で分解可能な劣モジュラ関数を最大化する特殊なケースは、Combinatorial Public Projects（CPP）問題として知られています[Papadimitriou et al。、2008]。グプタらによる前の仕事。 [2010]は、CPP問題に対して差分プライベートアルゴリズムを提供しました。一般的なマトロイド制約の下で、単調および非単調の分解可能な劣モジュラ最大化の差分プライベートアルゴリズムを設計し、競争力のあるユーティリティを保証することで、この作業を拡張します。理論的限界を、劣モジュラ最大化の一般的なケースの差分プライベートアルゴリズムよりも改善され、非プライベートアルゴリズムのパフォーマンスに近い経験的パフォーマンスを実証する実験で補完します。,https://d3i71xaburhd42.cloudfront.net/ffeaf679ecfbb70b9a22dfd640990d10bcc5cdc5/30-Figure1-1.png
Localization in the Crowd with Topological Constraints,"['Shahira Abousamra', 'Minh Hoai Nguyen', 'Dimitris Samaras', 'Chao Chen']",,,,
Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks,"['Russell Tsuchida', 'Tim D Pearce', 'Chris van der Heide', 'Fred Roosta', 'Marcus Gallagher']",https://arxiv.org/abs/2002.08517,"Analysing and computing with Gaussian processes arising from infinitely wide neural networks has recently seen a resurgence in popularity. Despite this, many explicit covariance functions of networks with activation functions used in modern networks remain unknown. Furthermore, while the kernels of deep networks can be computed iteratively, theoretical understanding of deep kernels is lacking, particularly with respect to fixed-point dynamics. Firstly, we derive the covariance functions of MLPs with exponential linear units and Gaussian error linear units and evaluate the performance of the limiting Gaussian processes on some benchmarks. Secondly, and more generally, we introduce a framework for analysing the fixed-point dynamics of iterated kernels corresponding to a broad range of activation functions. We find that unlike some previously studied neural network kernels, these new kernels exhibit non-trivial fixed-point dynamics which are mirrored in finite-width neural networks.",無限に広いニューラルネットワークから生じるガウス過程を使用した分析と計算は、最近人気が復活しています。これにもかかわらず、現代のネットワークで使用されている活性化関数を使用したネットワークの多くの明示的な共分散関数は不明なままです。さらに、ディープネットワークのカーネルは繰り返し計算できますが、特に固定小数点ダイナミクスに関して、ディープカーネルの理論的理解が不足しています。まず、指数線形単位とガウス誤差線形単位を使用してMLPの共分散関数を導出し、いくつかのベンチマークで制限ガウス過程のパフォーマンスを評価します。次に、より一般的には、広範囲の活性化関数に対応する反復カーネルの固定小数点ダイナミクスを分析するためのフレームワークを紹介します。以前に研究されたいくつかのニューラルネットワークカーネルとは異なり、これらの新しいカーネルは、有限幅のニューラルネットワークに反映される自明ではない固定小数点ダイナミクスを示すことがわかります。,https://d3i71xaburhd42.cloudfront.net/e61d43d341b33b6d03bb8cd1c6fd75cb37b43414/3-Figure1-1.png
Learning Branching Heuristics for Propositional Model Counting,"['Pashootan Vaezipoor', 'Gil Lederman', 'Yuhuai Wu', 'Chris Maddison', 'Roger B Grosse', 'Sanjit A. Seshia', 'Fahiem Bacchus']",https://arxiv.org/abs/2007.03204,"Author(s): Vaezipoor, Pashootan; Lederman, Gil; Wu, Yuhuai; Maddison, Chris J; Grosse, Roger; Lee, Edward; Seshia, Sanjit A; Bacchus, Fahiem | Abstract: Propositional model counting or #SAT is the problem of computing the number of satisfying assignments of a Boolean formula and many discrete probabilistic inference problems can be translated into a model counting problem to be solved by #SAT solvers. Generic ``exact'' #SAT solvers, however, are often not scalable to industrial-level instances. In this paper, we present Neuro#, an approach for learning branching heuristics for exact #SAT solvers via evolution strategies (ES) to reduce the number of branching steps the solver takes to solve an instance. We experimentally show that our approach not only reduces the step count on similarly distributed held-out instances but it also generalizes to much larger instances from the same problem family. The gap between the learned and the vanilla solver on larger instances is sometimes so wide that the learned solver can even overcome the run time overhead of querying the model and beat the vanilla in wall-clock time by orders of magnitude.",著者：Vaezipoor、Pashootan;レダーマン、ギル;ウー、ユフアイ;マディソン、クリスJ;グロス、ロジャー;リー、エドワード; Seshia、Sanjit A;バッカス、ファヒーム|要約：命題モデルカウントまたは#SATは、ブール式の満足のいく割り当ての数を計算する問題であり、多くの離散確率的推論問題は、＃SATソルバーによって解決されるモデルカウント問題に変換できます。ただし、一般的な正確な#SATソルバーは、多くの場合、産業レベルのインスタンスに拡張できません。このホワイトペーパーでは、進化戦略（ES）を介して正確な#SATソルバーの分岐ヒューリスティックを学習し、ソルバーがインスタンスを解決するために実行する分岐ステップの数を減らすアプローチであるNeuro＃を紹介します。私たちのアプローチは、同様に分散されたホールドアウトインスタンスのステップ数を減らすだけでなく、同じ問題ファミリからのはるかに大きなインスタンスに一般化することも実験的に示しています。大規模なインスタンスでの学習済みソルバーとバニラソルバーの間のギャップが非常に大きいため、学習済みソルバーはモデルのクエリの実行時オーバーヘッドを克服し、実時間でバニラを桁違いに打ち負かすことができます。,https://d3i71xaburhd42.cloudfront.net/01b60eb66d67b70b52040ebb99b7c5343e2e9003/1-Figure1-1.png
Towards Topic-Aware Slide Generation for Academic Papers with Unsupervised Mutual Learning,"['Da-Wei Li', 'Danqing Huang', 'Tingting Ma', 'Chin-Yew Lin']",,,,
GTA: Graph Truncated Attention for Retrosynthesis,"['Seung-Woo Seo', 'You Young Song', 'June Yong Yang', 'Seohui Bae', 'Hankook Lee', 'Jinwoo Shin', 'Sung Ju Hwang', 'Eunho Yang']",,,,
The Sample Complexity of Teaching by Reinforcement on Q-Learning,"['Xuezhou Zhang', 'Shubham Bharti', 'Yuzhe Ma', 'Adish Singla', 'Xiaojin Zhu']",,,,
Geodesic-HOF: 3D Reconstruction without Cutting Corners,"['Ziyun Wang', 'Eric Mitchell', 'Volkan Isler', 'Daniel D Lee']",https://arxiv.org/abs/2006.07981,"Single-view 3D object reconstruction is a challenging fundamental problem in computer vision, largely due to the morphological diversity of objects in the natural world. In particular, high curvature regions are not always captured effectively by methods trained using only set-based loss functions, resulting in reconstructions short-circuiting the surface or cutting corners. In particular, high curvature regions are not always captured effectively by methods trained using only set-based loss functions, resulting in reconstructions short-circuiting the surface or cutting corners. To address this issue, we propose learning an image-conditioned mapping function from a canonical sampling domain to a high dimensional space where the Euclidean distance is equal to the geodesic distance on the object. The first three dimensions of a mapped sample correspond to its 3D coordinates. The additional lifted components contain information about the underlying geodesic structure. Our results show that taking advantage of these learned lifted coordinates yields better performance for estimating surface normals and generating surfaces than using point cloud reconstructions alone. Further, we find that this learned geodesic embedding space provides useful information for applications such as unsupervised object decomposition.",シングルビュー3Dオブジェクトの再構築は、主に自然界のオブジェクトの形態学的多様性のために、コンピュータビジョンにおける挑戦的な根本的な問題です。特に、曲率の高い領域は、セットベースの損失関数のみを使用してトレーニングされた方法では必ずしも効果的にキャプチャされないため、再構成によって表面が短絡したり、コーナーが切断されたりします。特に、曲率の高い領域は、セットベースの損失関数のみを使用してトレーニングされた方法では必ずしも効果的にキャプチャされないため、再構成によって表面が短絡したり、コーナーが切断されたりします。この問題に対処するために、正規のサンプリング領域から、ユークリッド距離がオブジェクトの測地線距離に等しい高次元空間への画像条件付きマッピング関数の学習を提案します。マップされたサンプルの最初の3次元は、その3D座標に対応します。追加の持ち上げられたコンポーネントには、基礎となる測地線構造に関する情報が含まれています。私たちの結果は、これらの学習されたリフト座標を利用すると、点群再構成のみを使用するよりも、表面法線の推定と表面の生成に優れたパフォーマンスが得られることを示しています。さらに、この学習された測地線埋め込みスペースは、教師なしオブジェクト分解などのアプリケーションに役立つ情報を提供することがわかりました。,https://d3i71xaburhd42.cloudfront.net/e7f5a2793ff1eb1581fad2c6b1b28c7cc57bec1a/2-Figure1-1.png
Visual Transfer for Reinforcement Learning via Wasserstein Domain Confusion,"['Josh Roy', 'George Konidaris']",https://arxiv.org/abs/2006.03465,"We introduce Wasserstein Adversarial Proximal Policy Optimization (WAPPO), a novel algorithm for visual transfer in Reinforcement Learning that explicitly learns to align the distributions of extracted features between a source and target task. WAPPO approximates and minimizes the Wasserstein-1 distance between the distributions of features from source and target domains via a novel Wasserstein Confusion objective. WAPPO outperforms the prior state-of-the-art in visual transfer and successfully transfers policies across Visual Cartpole and two instantiations of 16 OpenAI Procgen environments.",Wasserstein Adversarial Proximal Policy Optimization（WAPPO）を紹介します。これは、強化学習における視覚転送の新しいアルゴリズムであり、抽出された特徴の分布をソースタスクとターゲットタスクの間で調整することを明示的に学習します。 WAPPOは、新しいWasserstein Confusion目標を介して、ソースドメインとターゲットドメインからの特徴の分布間のWasserstein-1距離を概算して最小化します。 WAPPOは、ビジュアル転送において以前の最先端技術を上回り、VisualCartpoleと16のOpenAIProcgen環境の2つのインスタンス化間でポリシーを正常に転送します。,https://d3i71xaburhd42.cloudfront.net/ca96857a584bab75c5bf8225357a6197fb5892b3/4-Figure1-1.png
Class-Attentive Diffusion Network for Semi-Supervised Classification,"['Jongin Lim', 'Daeho Um', 'Hyung Jin Chang', 'Dae Ung Jo', 'Jin Young Choi']",https://arxiv.org/abs/2006.10222,"We propose Aggregation with Class-Attentive Diffusion (AggCAD), a novel aggregation scheme for semi-supervised classification on graphs, which enables the model to embed more favorable node representations for better class separation. To this end, we propose a novel Class-Attentive Diffusion (CAD) which strengthens attention to intra-class nodes and attenuates attention to inter-class nodes. In contrast to the existing diffusion methods with a transition matrix determined solely by the graph structure, CAD considers both the node features and the graph structure with the design of the class-attentive transition matrix which utilizes the classifier. In addition, we further propose an adaptive scheme for AggCAD that leverages different reflection ratios of the diffusion result for each node depending on the local class-context. As the main advantage, AggCAD alleviates the problem of undesired mixing of inter-class features caused by discrepancies between node labels and the graph structure. Built on AggCAD, we construct Class-Attentive Diffusion Network for semi-supervised classification. Comprehensive experiments demonstrate the validity of AggCAD and the results show that the proposed method significantly outperforms the state-of-the-art methods on three benchmark datasets.",グラフ上の半教師あり分類のための新しい集約スキームであるClass-AttentiveDiffusion（AggCAD）を使用した集約を提案します。これにより、モデルはより好ましいノード表現を埋め込んで、より良いクラス分離を実現できます。この目的のために、クラス内ノードへの注意を強化し、クラス間ノードへの注意を弱める新しいクラス注意拡散（CAD）を提案します。グラフ構造のみによって決定される遷移行列を使用する既存の拡散方法とは対照的に、CADは、分類器を利用するクラス注意遷移行列の設計で、ノードの特徴とグラフ構造の両方を考慮します。さらに、ローカルクラスコンテキストに応じて、各ノードの拡散結果の異なる反射率を活用するAggCADの適応スキームをさらに提案します。主な利点として、AggCADは、ノードラベルとグラフ構造の間の不一致によって引き起こされるクラス間機能の望ましくない混合の問題を軽減します。 AggCAD上に構築され、半教師あり分類のためのクラス注意拡散ネットワークを構築します。包括的な実験は、AggCADの有効性を示し、結果は、提案された方法が3つのベンチマークデータセットで最先端の方法を大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/b2185c44d9d2c147e8bf2585a09fdb9a9ee65991/6-Figure1-1.png
Semi-Supervised Learning with Variational Bayesian Inference and Maximum Uncertainty Regularization,"['Kien Duc Do', 'Truyen Tran', 'Svetha Venkatesh']",,,,
Variance Penalized On-Policy and Off-Policy Actor-Critic,"['Arushi Jain', 'Gandharv Patil', 'Ayush Jain', 'Khimya Khetarpal', 'Doina Precup']",https://arxiv.org/abs/2102.01985,"Reinforcement learning algorithms are typically geared towards optimizing the expected return of an agent. However, in many practical applications, low variance in the return is desired to ensure the reliability of an algorithm. In this paper, we propose on-policy and off-policy actor-critic algorithms that optimize a performance criterion involving both mean and variance in the return. Previous work uses the second moment of return to estimate the variance indirectly. Instead, we use a much simpler recently proposed direct variance estimator which updates the estimates incrementally using temporal difference methods. Using the variance-penalized criterion, we guarantee the convergence of our algorithm to locally optimal policies for finite state action Markov decision processes. We demonstrate the utility of our algorithm in tabular and continuous MuJoCo domains. Our approach not only performs on par with actor-critic and prior variance-penalization baselines in terms of expected return, but also generates trajectories which have lower variance in the return. Introduction Reinforcement learning (RL) agents learn to solve a task by optimizing the expected accumulated discounted rewards (return) in a conventional setting. However, in risk-sensitive applications like industrial automation, finance, medicine, or robotics, the standard objective of RL may not suffice, because it does not account for the variability induced by the return distribution. In this paper, we propose a technique that promotes learning of policies with less variability. Variability in sequential decision-making problems can arise from two sources – the inherent stochasticity in the environment (transition and reward), and imperfect knowledge about the model. The former source of variability is addressed by the risk-sensitive Markov decision processes (MDPs) (Howard and Matheson 1972; Heger 1994; Borkar 2001, 2002), whereas the latter is covered by robust MDPs (Iyengar 2005; Nilim and El Ghaoui 2005). In this work, we address the former source of variability in an RL setup via mean-variance optimization. One could account for meanvariance tradeoffs via maximization of the mean subject to variance constraints (solved using constrained MDPs (Altman 1999)), maximization of the Sharpe ratio (Sharpe Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 1994), or incorporation of the variance as a penalty in the objective function (Filar, Kallenberg, and Lee 1989; White 1994). Here, we use a variance-penalized method to solve the optimization problem by adding a penalty term to the objective. There are two ways to compute the variance in the return Var(G). The indirect approach estimates Var(G) using the Bellman equation for both the first moment (i.e. value function) and the second moment as Var(G) = E[G] − E[G] (Sobel 1982). The direct approach forms a Bellman equation for the variance itself, as Var(G) = E[(G − E[G])] (Sherstan et al. 2018), skipping the calculation of the second moment. Sherstan et al. (2018) empirically established that in the policy evaluation setting, the direct variance estimation approach is better behaved compared to the indirect approach, in several scenarios: (a) when the value estimates are noisy, (b) when eligibility traces are used in the value estimation, and (c) when the variance in return is estimated from off-policy samples. Due to the above benefits and the simplicity of the direct approach, we build upon the approach proposed by Sherstan et al. (2018) only for policy evaluation setting, and, develop actor-critic algorithms for both onand off-policy settings (control). Contributions: (1) We modify the standard policy gradient objective to include a direct variance estimator for learning policies that maximize the variance-penalized return. (2) We develop a multi-timescale actor-critic algorithm, by deriving the gradient of the variance estimator in both the onpolicy and the off-policy case. (3) We prove convergence to locally optimal policies in the on-policy tabular setting. (4) We compare our proposed variance-penalized actor-critic (VPAC) algorithm with two baselines: actor-critic (AC) (Sutton et al. 2000; Konda and Tsitsiklis 2000), and an existing indirect variance penalized approach called varianceadjusted actor-critic (VAAC) (Tamar and Mannor 2013). We evaluate our onand off-policy VPAC algorithms in both discrete and continuous domains. The empirical findings demonstrate that VPAC compares favorably to both baselines in terms of the mean return, but generates trajectories with significantly lower variance in the return. Preliminaries Notation We consider an infinite-horizon discrete MDP 〈S,A,R, P, γ〉 with finite state space S and finite action ar X iv :2 10 2. 01 98 5v 1 [ cs .L G ] 3 F eb 2 02 1 space A. R ∈ R denotes the reward function (with Rt+1 denoting the reward at time t). A policy π : S → A governs the behavior of the agent in state s, the agent chooses an action a ∼ π(·|s), then transitions to next state s′ according to transition probability P (s′|s, a). γ ∈ [0, 1] is the discount factor. Let Gt = ∑∞ l=0 γ Rt+1+l denote the accumulated discounted reward (also known as return) along a trajectory. The state value function for π is defined as: Vπ(s) = Eπ[Gt|St = s] and state-action value function is: Qπ(s, a) = Eπ[Gt|St = s,At = a]. In this paper, Eπ[.] denotes expectation over transition function of MDP and probability distribution under π policy. Actor-Critic (AC) The policy gradient (PG) method (Sutton et al. 2000) is a policy optimization algorithm that performs gradient ascent in the direction maximizing the expected return. Given a parameterized policy πθ(a|s), where θ is the policy parameter, an initial state distribution d0 and the discounted weighting of states dπ(s) = ∑∞ t=0 γ P (St = s|s0 ∼ d0, π) encountered starting at some state s0, the gradient of the objective function Jd0(θ) = ∑ s0 d0(s0)Vπθ (s0) (Sutton and Barto 2018) is given by: ∇θJd0(θ) = Es0∼d0 [∑",強化学習アルゴリズムは通常、エージェントの期待収益を最適化することを目的としています。ただし、多くの実際のアプリケーションでは、アルゴリズムの信頼性を確保するために、リターンの分散を小さくすることが望まれます。この論文では、リターンの平均と分散の両方を含むパフォーマンス基準を最適化する、オンポリシーおよびオフポリシーのアクタークリティカルアルゴリズムを提案します。前の作業では、断面二次モーメントを使用して分散を間接的に推定します。代わりに、時間差法を使用して推定値を段階的に更新する、はるかに単純な最近提案された直接分散推定量を使用します。分散ペナルティ基準を使用して、有限状態アクションマルコフ決定過程の局所的に最適なポリシーへのアルゴリズムの収束を保証します。表形式および連続MuJoCoドメインでのアルゴリズムの有用性を示します。私たちのアプローチは、期待収益の点でアクター批評家および以前の分散ペナルティベースラインと同等に機能するだけでなく、収益の分散が小さい軌道を生成します。はじめに強化学習（RL）エージェントは、従来の設定で予想される累積割引報酬（リターン）を最適化することにより、タスクを解決することを学習します。ただし、産業オートメーション、金融、医療、ロボット工学などのリスクに敏感なアプリケーションでは、RLの標準的な目的は、リターン分布によって引き起こされる変動性を考慮していないため、十分でない場合があります。本論文では、変動性の少ない政策の学習を促進する手法を提案する。順次意思決定問題の変動性は、環境に固有の確率論（遷移と報酬）とモデルに関する不完全な知識の2つの原因から生じる可能性があります。前者の変動の原因は、リスクに敏感なマルコフ決定過程（MDP）によって対処されます（Howard and Matheson 1972; Heger 1994; Borkar 2001、2002）が、後者は堅牢なMDPによってカバーされます（Iyengar 2005; Nilim and El Ghaoui 2005 ）。この作業では、平均分散の最適化を介して、RLセットアップの変動の以前の原因に対処します。分散制約の対象となる平均の最大化（制約付きMDP（Altman 1999）を使用して解決）、シャープレシオの最大化（Sharpe Copyright 2021、Association for the Advancement of Artificial Intelligence（www.aaai.org））を介して、平均分散のトレードオフを説明できます。 。Allrightsreserved。1994）、または目的関数へのペナルティとしての分散の組み込み（Filar、Kallenberg、およびLee 1989; White 1994）。ここでは、分散ペナルティ法を使用して、目的にペナルティ項を追加することで最適化問題を解決します。戻り値Var（G）の分散を計算する方法は2つあります。間接アプローチは、Var（G）= E [G] E [G]（Sobel 1982）として、最初のモーメント（つまり値関数）と2番目のモーメントの両方のベルマン方程式を使用してVar（G）を推定します。直接アプローチは、Var（G）= E [（GE [G]）]（Sherstan etal。2018）のように、分散自体のベルマン方程式を形成し、2次モーメントの計算をスキップします。 Sherstan etal。 （2018）いくつかのシナリオで、ポリシー評価設定では、直接分散推定アプローチが間接アプローチよりも適切に動作することを経験的に確立しました：（a）値の推定にノイズが多い場合、（b）適格性トレースが価値の推定、および（c）リターンの分散がポリシー外のサンプルから推定される場合。上記の利点と直接アプローチの単純さのために、Sherstanらによって提案されたアプローチに基づいています。 （2018）ポリシー評価設定のみ、およびオンポリシー設定とオフポリシー設定（制御）の両方のアクタークリティカルアルゴリズムを開発します。貢献：（1）標準のポリシー勾配目標を変更して、分散ペナルティのリターンを最大化するポリシーを学習するための直接分散推定量を含めます。 （2）オンポリシーとオフポリシーの両方の場合の分散推定量の勾配を導出することにより、マルチタイムスケールのアクター批評アルゴリズムを開発します。 （3）ポリシー上の表形式の設定で、ローカルに最適なポリシーへの収束を証明します。 （4）提案された分散ペナルティアクタークリティカル（VPAC）アルゴリズムを2つのベースラインと比較します：アクタークリティカル（AC）（Suttonetal。2000; Konda and Tsitsiklis 2000）、および分散調整アクターと呼ばれる既存の間接分散ペナルティアプローチ-評論家（VAAC）（Tamar and Mannor 2013）。離散ドメインと連続ドメインの両方で、オンポリシーとオフポリシーのVPACアルゴリズムを評価します。経験的調査結果は、VPACが平均リターンの点で両方のベースラインと比較して有利であることを示していますが、リターンの分散が大幅に低い軌道を生成します。予備表記法有限状態空間Sと有限作用arX iv：2 10 2. 01 98 5v 1 [cs .LG] 3 F eb 2 021空間を持つ無限地平離散MDPS、A、R、Pを検討します。 A. RRは報酬関数を示します（Rt + 1は時間tでの報酬を示します）。ポリシー：SAは状態sでのエージェントの動作を管理し、エージェントはアクションa（| s）を選択し、遷移確率P（s | s、a）に従って次の状態sに遷移します。 [0、1]は割引係数です。 Gt = l = 0 Rt + 1 + lは、軌道に沿った累積割引報酬（リターンとも呼ばれます）を示します。の状態値関数は、V（s）= E [Gt | St = s]として定義され、状態アクション値関数は、Q（s、a）= E [Gt | St = s、At = a]です。この論文では、E [。]は、MDPの遷移関数に対する期待値とポリシーの下での確率分布を示します。 Actor-Critic（AC）ポリシー勾配（PG）メソッド（Sutton etal。2000）は、期待収益を最大化する方向に勾配上昇を実行するポリシー最適化アルゴリズムです。パラメータ化されたポリシー（a | s）が与えられます。ここで、はポリシーパラメータ、初期状態分布d0、および状態の割引された重み付けd（s）= t = 0 P（St = s | s0 d0、）は、ある状態で開始されます。 s0、目的関数Jd0（）= s0 d0（s0）V（s0）（Sutton and Barto 2018）の勾配は次の式で与えられます。Jd0（）= Es0d0 [,https://d3i71xaburhd42.cloudfront.net/08e7fda8b3077db9dbf7630ff5424582909a002a/4-Figure1-1.png
Predicting Livelihood Indicators from Community-Generated Street-Level Imagery,"['Jihyeon Lee', 'Dylan J Grosz', 'Burak Uzkent', 'Sicheng Zeng', 'Marshall Burke', 'David Lobell', 'Stefano Ermon']",,,,
Inference-Based Deterministic Messaging for Multi-Agent Communication,"['Varun Bhatt', 'Michael Buro']",,,,
Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act Recognition and Sentiment Classification,"['Libo Qin', 'Zhouyang Li', 'Wanxiang Che', 'Minheng Ni', 'Ting Liu']",https://arxiv.org/abs/2012.13260,"In a dialog system, dialog act recognition and sentiment classification are two correlative tasks to capture speakers’ intentions, where dialog act and sentiment can indicate the explicit and the implicit intentions separately. The dialog context information (contextual information) and the mutual interaction information are two key factors that contribute to the two related tasks. Unfortunately, none of the existing approaches consider the two important sources of information simultaneously. In this paper, we propose a Co-Interactive Graph Attention Network (Co-GAT) to jointly perform the two tasks. The core module is a proposed co-interactive graph interaction layer where a cross-utterances connection and a cross-tasks connection are constructed and iteratively updated with each other, achieving to consider the two types of information simultaneously. Experimental results on two public datasets show that our model successfully captures the two sources of information and achieve the state-of-the-art performance. In addition, we find that the contributions from the contextual and mutual interaction information do not fully overlap with contextualized word representations (BERT, Roberta, XLNet).",対話システムでは、対話行為の認識と感情の分類は、話者の意図を捉えるための2つの相関タスクであり、対話行為と感情は、明示的な意図と暗黙的な意図を別々に示すことができます。ダイアログコンテキスト情報（コンテキスト情報）と相互作用情報は、2つの関連するタスクに寄与する2つの重要な要素です。残念ながら、既存のアプローチはいずれも、2つの重要な情報源を同時に考慮していません。この論文では、2つのタスクを共同で実行するためのCo-Interactive Graph Attention Network（Co-GAT）を提案します。コアモジュールは、提案された共同対話型グラフインタラクションレイヤーであり、クロス発話接続とクロスタスク接続が構築され、相互に繰り返し更新され、2つのタイプの情報を同時に考慮することができます。 2つの公開データセットでの実験結果は、モデルが2つの情報ソースを正常にキャプチャし、最先端のパフォーマンスを達成していることを示しています。さらに、文脈的および相互作用情報からの寄与は、文脈化された単語表現（BERT、Roberta、XLNet）と完全には重複していないことがわかります。,https://d3i71xaburhd42.cloudfront.net/af574bff0e9ffd71b0708a22b135012442e33b8d/1-Figure1-1.png
MTAAL: Multi-Task Adversarial Active Learning for Medical Named Entity Recognition and Normalization,"['Baohang Zhou', 'Xiangrui Cai', 'Ying ZHANG', 'Wenya Guo', 'Xiaojie Yuan']",,,,
Adressing Class Imbalance in Federated Learning,"['Lixu Wang', 'Shichao Xu', 'Xiao Wang', 'Zhu Qi']",,,,
A Neural Group-Wise Sentiment Analysis Model with Data Sparsity Awareness,"['Deyu Zhou', 'Meng Zhang', 'Linhai Zhang', 'Yulan He']",,,,
DialogBERT: Discourse-Aware Response Generation via Learning to Recover and Rank Utterances,"['Xiaodong Gu', 'Kang Min Yoo', 'Jung-Woo Ha']",https://arxiv.org/abs/2012.01775,"Recent advances in pre-trained language models have significantly improved neural response generation. However, existing methods usually view the dialogue context as a linear sequence of tokens and learn to generate the next word through token-level self-attention. Such token-level encoding hinders the exploration of discourse-level coherence among utterances. This paper presents DialogBERT, a novel conversational response generation model that enhances previous PLM-based dialogue models. DialogBERT employs a hierarchical Transformer architecture. To efficiently capture the discourse-level coherence among utterances, we propose two training objectives, including masked utterance regression and distributed utterance order ranking in analogy to the original BERT training. Experiments on three multi-turn conversation datasets show that our approach remarkably outperforms the baselines, such as BART and DialoGPT, in terms of quantitative evaluation. The human evaluation suggests that DialogBERT generates more coherent, informative, and human-like responses than the baselines with significant margins.",事前に訓練された言語モデルの最近の進歩により、神経応答の生成が大幅に改善されました。ただし、既存のメソッドは通常、ダイアログコンテキストをトークンの線形シーケンスと見なし、トークンレベルの自己注意によって次の単語を生成することを学習します。このようなトークンレベルのエンコーディングは、発話間の談話レベルの一貫性の調査を妨げます。このホワイトペーパーでは、以前のPLMベースの対話モデルを強化する新しい会話応答生成モデルであるDialogBERTを紹介します。 DialogBERTは、階層的なTransformerアーキテクチャを採用しています。発話間の談話レベルの一貫性を効率的にキャプチャするために、元のBERTトレーニングと同様に、マスクされた発話回帰と分散発話順序ランキングを含む2つのトレーニング目標を提案します。 3つのマルチターン会話データセットでの実験は、定量的評価の点で、私たちのアプローチがBARTやDialoGPTなどのベースラインを著しく上回っていることを示しています。人間による評価は、DialogBERTがベースラインよりも一貫性があり、有益で、人間に似た応答を生成することを示唆しています。,https://d3i71xaburhd42.cloudfront.net/76dc470d7cf70da860735a000547ee460c505f0c/2-Figure1-1.png
Iterative Utterance Segmentation for Neural Semantic Parsing,"['Yinuo Guo', 'Zeqi Lin', 'Jian-Guang Lou', 'Dongmei Zhang']",https://arxiv.org/abs/2012.07019,"Neural semantic parsers usually fail to parse long and complex utterances into correct meaning representations, due to the lack of exploiting the principle of compositionality. To address this issue, we present a novel framework for boosting neural semantic parsers via iterative utterance segmentation. Given an input utterance, our framework iterates between two neural modules: a segmenter for segmenting a span from the utterance, and a parser for mapping the span into a partial meaning representation. Then, these intermediate parsing results are composed into the final meaning representation. One key advantage is that this framework does not require any handcraft templates or additional labeled data for utterance segmentation: we achieve this through proposing a novel training method, in which the parser provides pseudo supervision for the segmenter. Experiments on Geo, ComplexWebQuestions, and Formulas show that our framework can consistently improve performances of neural semantic parsers in different domains. On data splits that require compositional generalization, our framework brings significant accuracy gains: Geo 63.1 to 81.2, Formulas 59.7 to 72.7, ComplexWebQuestions 27.1 to 56.3.",ニューラルセマンティックパーサーは通常、構成性の原則を活用していないため、長くて複雑な発話を正しい意味表現に解析できません。この問題に対処するために、反復発話セグメンテーションを介してニューラルセマンティックパーサーをブーストするための新しいフレームワークを提示します。入力発話が与えられると、フレームワークは2つのニューラルモジュール間で反復します。発話からスパンをセグメント化するためのセグメンテーションと、スパンを部分的な意味表現にマッピングするためのパーサーです。次に、これらの中間解析結果は、最終的な意味表現に構成されます。重要な利点の1つは、このフレームワークが発話セグメンテーションに手作りのテンプレートや追加のラベル付きデータを必要としないことです。これは、パーサーがセグメンテーションに疑似監視を提供する新しいトレーニング方法を提案することで実現します。 Geo、ComplexWebQuestions、およびFormulasの実験は、私たちのフレームワークがさまざまなドメインのニューラルセマンティックパーサーのパフォーマンスを一貫して改善できることを示しています。構成の一般化を必要とするデータ分割では、フレームワークによって精度が大幅に向上します。Geo63.1から81.2、Formula 59.7から72.7、ComplexWebQuestions27.1から56.3です。,https://d3i71xaburhd42.cloudfront.net/7344ed64d1717780422fd1d58fae85edc544d180/3-Figure1-1.png
Extending Multi-Sense Word Embedding to Phrases and Sentences for Unsupervised Semantic Applications,"['Haw-shiuan Chang', 'Amol Agrawal', 'Andrew McCallum']",,,,
Beyond Low-Frequency Information in Graph Convolutional Networks,"['Deyu Bo', 'Xiao Wang', 'Chuan Shi', 'Huawei Shen']",https://arxiv.org/abs/2101.00797,"Graph neural networks (GNNs) have been proven to be effective in various network-related tasks. Most existing GNNs usually exploit the low-frequency signals of node features, which gives rise to one fundamental question: is the low-frequency information all we need in the real world applications? In this paper, we first present an experimental investigation assessing the roles of low-frequency and high-frequency signals, where the results clearly show that exploring low-frequency signal only is distant from learning an effective node representation in different scenarios. How can we adaptively learn more information beyond low-frequency information in GNNs? A well-informed answer can help GNNs enhance the adaptability. We tackle this challenge and propose a novel Frequency Adaptation Graph Convolutional Networks (FAGCN) with a selfgating mechanism, which can adaptively integrate different signals in the process of message passing. For a deeper understanding, we theoretically analyze the roles of low-frequency signals and high-frequency signals on learning node representations, which further explains why FAGCN can perform well on different types of networks. Extensive experiments on six real-world networks validate that FAGCN not only alleviates the over-smoothing problem, but also has advantages over the state-of-the-arts.",グラフニューラルネットワーク（GNN）は、さまざまなネットワーク関連のタスクで効果的であることが証明されています。ほとんどの既存のGNNは通常、ノード機能の低周波信号を利用します。これにより、1つの基本的な問題が発生します。それは、実際のアプリケーションで必要なのは低周波情報だけですか。この論文では、最初に低周波信号と高周波信号の役割を評価する実験的調査を提示します。結果は、低周波信号のみを探索することは、さまざまなシナリオで効果的なノード表現を学習することから遠いことを明確に示しています。 GNNの低周波情報を超えて、より多くの情報を適応的に学習するにはどうすればよいでしょうか。十分な情報に基づいた回答は、GNNが適応性を高めるのに役立ちます。この課題に取り組み、メッセージパッシングの過程でさまざまな信号を適応的に統合できるセルフゲーティングメカニズムを備えた新しい周波数適応グラフ畳み込みネットワーク（FAGCN）を提案します。より深く理解するために、ノード表現の学習における低周波信号と高周波信号の役割を理論的に分析します。これにより、FAGCNがさまざまなタイプのネットワークでうまく機能する理由がさらに説明されます。 6つの実際のネットワークでの広範な実験により、FAGCNは過度の平滑化の問題を軽減するだけでなく、最先端のネットワークよりも優れていることが検証されています。,https://d3i71xaburhd42.cloudfront.net/fbc136c8c81cd89206dc0fcb54e16bd98df83b62/2-Figure1-1.png
Neural-Symbolic Integration: A Compositional Perspective,"['Efthymia Tsamoura', 'Timothy Hospedales', 'Loizos Michael']",https://arxiv.org/abs/2010.11926,"Despite significant progress in the development of neural-symbolic frameworks, the question of how to integrate a neural and a symbolic system in a \emph{compositional} manner remains open. Our work seeks to fill this gap by treating these two systems as black boxes to be integrated as modules into a single architecture, without making assumptions on their internal structure and semantics. Instead, we expect only that each module exposes certain methods for accessing the functions that the module implements: the symbolic module exposes a deduction method for computing the function's output on a given input, and an abduction method for computing the function's inputs for a given output; the neural module exposes a deduction method for computing the function's output on a given input, and an induction method for updating the function given input-output training instances. We are, then, able to show that a symbolic module -- with any choice for syntax and semantics, as long as the deduction and abduction methods are exposed -- can be cleanly integrated with a neural module, and facilitate the latter's efficient training, achieving empirical performance that exceeds that of previous work.",神経シンボリックフレームワークの開発が大幅に進歩したにもかかわらず、神経システムとシンボリックシステムを構成的に統合する方法の問題は未解決のままです。私たちの仕事は、これら2つのシステムをブラックボックスとして扱い、内部構造やセマンティクスを前提とせずに、モジュールとして単一のアーキテクチャに統合することで、このギャップを埋めることを目指しています。代わりに、各モジュールが、モジュールが実装する関数にアクセスするための特定のメソッドを公開することだけを期待します。シンボリックモジュールは、特定の入力の関数出力を計算するための演繹メソッドと、特定の出力の関数入力を計算するための外転メソッドを公開します。 ;ニューラルモジュールは、特定の入力で出力された関数を計算するための演繹法と、入出力トレーニングインスタンスで与えられた関数を更新するための誘導法を公開します。したがって、推論と外転の方法が公開されている限り、構文とセマンティクスを任意に選択できるシンボリックモジュールをニューラルモジュールとクリーンに統合し、ニューラルモジュールを効率的にトレーニングして、経験的なパフォーマンスを実現できることを示すことができます。前作を上回っています。,https://d3i71xaburhd42.cloudfront.net/0d6e349e385ed1765e4063bd820e2f541ee93b89/2-Figure1-1.png
Policy Optimization as Online Learning with Mediator Feedback,"['Alberto Maria Metelli', 'Matteo Papini', ""Pierluca D'Oro"", 'Marcello Restelli']",https://arxiv.org/abs/2012.08225,"Policy Optimization (PO) is a widely used approach to address continuous control tasks. In this paper, we introduce the notion of mediator feedback that frames PO as an online learning problem over the policy space. The additional available information, compared to the standard bandit feedback, allows reusing samples generated by one policy to estimate the performance of other policies. Based on this observation, we propose an algorithm, RANDomized-exploration policy Optimization via Multiple Importance Sampling with Truncation (RANDOMIST), for regret minimization in PO, that employs a randomized exploration strategy, differently from the existing optimistic approaches. When the policy space is finite, we show that under certain circumstances, it is possible to achieve constant regret, while always enjoying logarithmic regret. We also derive problem-dependent regret lower bounds. Then, we extend RANDOMIST to compact policy spaces. Finally, we provide numerical simulations on finite and compact policy spaces, in comparison with PO and bandit baselines.",ポリシー最適化（PO）は、継続的な制御タスクに対処するために広く使用されているアプローチです。この論文では、POをポリシー空間でのオンライン学習問題として組み立てるメディエーターフィードバックの概念を紹介します。標準の盗賊フィードバックと比較して、追加の利用可能な情報により、1つのポリシーによって生成されたサンプルを再利用して、他のポリシーのパフォーマンスを推定できます。この観察に基づいて、POでの後悔を最小化するために、既存の楽観的アプローチとは異なり、ランダム化された探索戦略を採用するアルゴリズム、切り捨てによる複数の重要度サンプリングによるランダム化された探索ポリシーの最適化（RANDOMIST）を提案します。政策空間が有限である場合、特定の状況下では、常に対数的な後悔を楽しみながら、一定の後悔を達成することが可能であることを示します。また、問題に依存する後悔の下限を導き出します。次に、RANDOMISTを拡張してポリシースペースをコンパクトにします。最後に、POおよび盗賊のベースラインと比較して、有限でコンパクトなポリシースペースの数値シミュレーションを提供します。,https://d3i71xaburhd42.cloudfront.net/ac6b3d3d85d0cdfdff34c522ad8c3e1677d2f5a1/3-Figure1-1.png
Adversarial Language Games for Advanced Natural Language Intelligence,"['Yuan Yao', 'Haoxi Zhong', 'Zhengyan Zhang', 'Xu Han', 'Xiaozhi Wang', 'Kai Zhang', 'Chaojun Xiao', 'Guoyang Zeng', 'Zhiyuan Liu', 'Maosong Sun']",https://arxiv.org/abs/1911.01622,"We study the problem of adversarial language games, in which multiple agents with conflicting goals compete with each other via natural language interactions. While adversarial language games are ubiquitous in human activities, little attention has been devoted to this field in natural language processing. In this work, we propose a challenging adversarial language game called Adversarial Taboo as an example, in which an attacker and a defender compete around a target word. The attacker is tasked with inducing the defender to utter the target word invisible to the defender, while the defender is tasked with detecting the target word before being induced by the attacker. In Adversarial Taboo, a successful attacker must hide its intention and subtly induce the defender, while a competitive defender must be cautious with its utterances and infer the intention of the attacker. Such language abilities can facilitate many important downstream NLP tasks. To instantiate the game, we create a game environment and a competition platform. Comprehensive experiments and empirical studies on several baseline attack and defense strategies show promising and interesting results. Based on the analysis on the game and experiments, we discuss multiple promising directions for future research.",対立する目標を持つ複数のエージェントが自然言語の相互作用を介して互いに競合する、敵対的な言語ゲームの問題を研究します。敵対的な言語ゲームは人間の活動に遍在していますが、自然言語処理ではこの分野にほとんど注意が向けられていません。この作品では、例として、攻撃者と防御者がターゲット単語をめぐって競争する、敵対的タブーと呼ばれる挑戦的な敵対的言語ゲームを提案します。攻撃者は、防御者に見えないターゲット単語を発声するように防御者を誘導する任務を負い、一方、防御者は、攻撃者によって誘導される前に標的単語を検出する任務を負います。敵対的タブーでは、成功した攻撃者はその意図を隠し、防御者を微妙に誘導する必要がありますが、競争力のある防御者はその発話に注意し、攻撃者の意図を推測する必要があります。このような言語能力は、多くの重要なダウンストリームNLPタスクを容易にすることができます。ゲームをインスタンス化するために、ゲーム環境と競争プラットフォームを作成します。いくつかのベースライン攻撃および防御戦略に関する包括的な実験と実証的研究は、有望で興味深い結果を示しています。ゲームと実験の分析に基づいて、将来の研究のための複数の有望な方向性について説明します。,https://d3i71xaburhd42.cloudfront.net/8a9a798c56fc83858d7ace0352606d73aeaa204d/1-Figure1-1.png
Estimating the Number of Induced Subgraphs from Incomplete Data and Neighborhood Queries,"['Dimitris Fotakis', 'Thanasis Pittas', 'Stratis Skoulakis']",,,,
MLE-Guided Parameter Search for Task Loss Minimization in Neural Sequence Modeling,"['Sean Welleck', 'Kyunghyun Cho']",https://arxiv.org/abs/2006.03158,"Neural autoregressive sequence models are used to generate sequences in a variety of natural language processing (NLP) tasks, where they are evaluated according to sequence-level task losses. These models are typically trained with maximum likelihood estimation, which ignores the task loss, yet empirically performs well as a surrogate objective. Typical approaches to directly optimizing the task loss such as policy gradient and minimum risk training are based around sampling in the sequence space to obtain candidate update directions that are scored based on the loss of a single sequence. In this paper, we develop an alternative method based on random search in the parameter space that leverages access to the maximum likelihood gradient. We propose maximum likelihood guided parameter search (MGS), which samples from a distribution over update directions that is a mixture of random search around the current parameters and around the maximum likelihood gradient, with each direction weighted by its improvement in the task loss. MGS shifts sampling to the parameter space, and scores candidates using losses that are pooled from multiple sequences. Our experiments show that MGS is capable of optimizing sequence-level losses, with substantial reductions in repetition and non-termination in sequence completion, and similar improvements to those of minimum risk training in machine translation.",ニューラル自己回帰シーケンスモデルは、さまざまな自然言語処理（NLP）タスクでシーケンスを生成するために使用され、シーケンスレベルのタスク損失に従って評価されます。これらのモデルは通常、最尤推定でトレーニングされます。これは、タスクの損失を無視しますが、経験的に代理目的として適切に機能します。ポリシー勾配や最小リスクトレーニングなどのタスク損失を直接最適化するための一般的なアプローチは、単一のシーケンスの損失に基づいてスコアリングされる候補更新方向を取得するためのシーケンス空間でのサンプリングに基づいています。この論文では、最尤勾配へのアクセスを活用するパラメータ空間でのランダム検索に基づく代替方法を開発します。最尤ガイド付きパラメーター検索（MGS）を提案します。これは、現在のパラメーターと最尤勾配の周りのランダム検索の混合である更新方向の分布からサンプリングし、各方向はタスク損失の改善によって重み付けされます。 MGSはサンプリングをパラメーター空間にシフトし、複数のシーケンスからプールされた損失を使用して候補をスコアリングします。私たちの実験は、MGSがシーケンスレベルの損失を最適化できることを示しており、シーケンス完了の繰り返しと非終了が大幅に削減され、機械翻訳の最小リスクトレーニングと同様の改善が見られます。,https://d3i71xaburhd42.cloudfront.net/619db8ab81af19edae005324758c89547adb989e/6-Figure1-1.png
Rethinking Graph Regularization for Graph Neural Networks,"['Han Yang', 'Kaili Ma', 'James Cheng']",https://arxiv.org/abs/2009.02027,"The graph Laplacian regularization term is usually used in semi-supervised node classification to provide graph structure information for a model $f(X)$. However, with the recent popularity of graph neural networks (GNNs), directly encoding graph structure $A$ into a model, i.e., $f(A, X)$, has become the more common approach. While we show that graph Laplacian regularization $f(X)^\top \Delta f(X)$ brings little-to-no benefit to existing GNNs, we propose a simple but non-trivial variant of graph Laplacian regularization, called Propagation-regularization (P-reg), to boost the performance of existing GNN models. We provide formal analyses to show that P-reg not only infuses extra information (that is not captured by the traditional graph Laplacian regularization) into GNNs, but also has the capacity equivalent to an infinite-depth graph convolutional network. The code is available at this https URL.",グラフラプラシアン正則化項は、通常、半教師ありノード分類で使用され、モデルf（X）のグラフ構造情報を提供します。ただし、最近のグラフニューラルネットワーク（GNN）の人気により、グラフ構造Aをモデルに直接エンコードする、つまりf（A、X）がより一般的なアプローチになっています。グラフラプラシアン正則化f（X）^（）f（X）が既存のGNNにほとんどまたはまったく利益をもたらさないことを示しますが、伝播-正則化（P- reg）、既存のGNNモデルのパフォーマンスを向上させます。 P-regが追加情報（従来のグラフラプラシアン正則化では取得されない）をGNNに注入するだけでなく、無限深度のグラフ畳み込みネットワークと同等の容量を備えていることを示す正式な分析を提供します。コードはこのhttpsURLで入手できます。,https://d3i71xaburhd42.cloudfront.net/85d1efae8697a0ff6fb29bba4874dfe50e75ee8d/3-Figure1-1.png
A Flexible Framework for Communication-Efficient Machine Learning,"['Sarit Khirirat', 'Sindri Magnusson', 'Arda Aytekin', 'Mikael Johansson']",,,,
Dynamic Knowledge Graph Alignment,"['Yuchen Yan', 'Lihui Liu', 'Yikun Ban', 'Baoyu Jing', 'Hanghang Tong']",,,,
Learning Set Functions that are Sparse in Non-Orthogonal Fourier Bases,"['Chris Wendler', 'Andisheh Amrollahi', 'Bastian Seifert', 'Andreas Krause', 'Markus Püschel']",https://arxiv.org/abs/2010.00439,"Many applications of machine learning on discrete domains, such as learning preference functions in recommender systems or auctions, can be reduced to estimating a set function that is sparse in the Fourier domain. In this work, we present a new family of algorithms for learning Fourier-sparse set functions. They require at most $nk - k \log_2 k + k$ queries (set function evaluations), under mild conditions on the Fourier coefficients, where $n$ is the size of the ground set and $k$ the number of non-zero Fourier coefficients. In contrast to other work that focused on the orthogonal Walsh-Hadamard transform, our novel algorithms operate with recently introduced non-orthogonal Fourier transforms that offer different notions of Fourier-sparsity. These naturally arise when modeling, e.g., sets of items forming substitutes and complements. We demonstrate effectiveness on several real-world applications.",レコメンダーシステムやオークションでの優先関数の学習など、離散ドメインでの機械学習の多くのアプリケーションは、フーリエドメインでまばらな集合関数を推定することに還元できます。この作業では、フーリエスパース集合関数を学習するためのアルゴリズムの新しいファミリを紹介します。フーリエ係数の穏やかな条件下で、最大でnk klog2k + kクエリ（集合関数の評価）が必要です。ここで、nは基底集合のサイズ、kは非ゼロフーリエ係数の数です。直交ウォルシュ-アダマール変換に焦点を当てた他の研究とは対照的に、私たちの新しいアルゴリズムは、フーリエスパース性のさまざまな概念を提供する最近導入された非直交フーリエ変換で動作します。これらは、たとえば、代替物や補完物を形成するアイテムのセットをモデル化するときに自然に発生します。いくつかの実際のアプリケーションでの有効性を示します。,https://d3i71xaburhd42.cloudfront.net/ae66ca3be1d3ce8d065a23166f2f7f727ba11085/3-Figure1-1.png
Maximum Roaming Multi-Task Learning,"['Lucas Pascal', 'Pietro Michiardi', 'Xavier Bost', 'Benoit Huet', 'Maria A. Zuluaga']",,,,
Differentially Private Clustering via Maximum Coverage,"['Matthew Jones', 'Huy Nguyen', 'Thy D Nguyen']",,,,
The Causal Learning of Retail Delinquency,"['Yiyan Huang', 'Cheuk Hang Leung', 'Xing Yan', 'Qi Wu', 'Nanbo Peng', 'Dongdong Wang', 'Zhixiang Huang']",,,,
Frugal Optimization for Cost-Related Hyperparameters,"['Qingyun Wu', 'Chi Wang', 'Silu Huang']",,,,
Content Learning with Structure-Aware Writing: A Graph-Infused Dual Conditional Variational Autoencoder for Automatic Storytelling,"['Meng Hsuan Yu', 'Juntao Li ', 'Zhangming Chan', 'Dongyan Zhao', 'Rui Yan']",,,,
Unsupervised Opinion Summarization with Content Planning,"['Reinald Kim Amplayo', 'Stefanos Angelidis', 'Mirella Lapata']",,,,
A Theory of Independent Mechanisms for Extrapolation in Generative Models,"['Michel Besserve', 'Remy Sun', 'Dominik Janzing', 'Bernhard Schölkopf']",,,,
Data Augmentation for Abstractive Query-Focused Multi-Document Summarization,"['Ramakanth R Pasunuru', 'Asli Celikyilmaz', 'Michel Galley', 'Chenyan Xiong', 'Yizhe Zhang', 'Mohit Bansal', 'Jianfeng Gao']",,,,
Open Domain Dialogue Generation with Latent Images,"['Ze Yang', 'Wei Wu', 'Huang Hu', 'Can Xu', 'Wei Wang', 'Zhoujun Li']",https://arxiv.org/abs/2004.01981,"We consider grounding open domain dialogues with images. Existing work assumes that both an image and a textual context are available, but image-grounded dialogues by nature are more difficult to obtain than textual dialogues. Thus, we propose learning a response generation model with both image-grounded dialogues and textual dialogues by assuming that there is a latent variable in a textual dialogue that represents the image, and trying to recover the latent image through text-to-image generation techniques. The likelihood of the two types of dialogues is then formulated by a response generator and an image reconstructor that are learned within a conditional variational auto-encoding framework. Empirical studies are conducted in both image-grounded conversation and text-based conversation. In the first scenario, image-grounded dialogues, especially under a low-resource setting, can be effectively augmented by textual dialogues with latent images; while in the second scenario, latent images can enrich the content of responses and at the same time keep them relevant to contexts.",オープンドメインの対話を画像で接地することを検討します。既存の作業では、画像とテキストのコンテキストの両方が利用可能であると想定していますが、画像に基づいた対話は、本質的にテキストの対話よりも取得が困難です。したがって、画像を表すテキスト対話に潜在変数があると仮定し、テキストから画像への生成手法を通じて潜在画像を復元しようとすることにより、画像ベースの対話とテキスト対話の両方で応答生成モデルを学習することを提案します。 。次に、2種類の対話の可能性は、条件付き変分自動エンコードフレームワーク内で学習される応答ジェネレーターと画像再構成子によって定式化されます。実証研究は、画像ベースの会話とテキストベースの会話の両方で実施さ​​れます。最初のシナリオでは、特にリソースが少ない設定での画像ベースの対話は、潜像を使用したテキスト対話によって効果的に強化できます。 2番目のシナリオでは、潜像は応答の内容を充実させると同時に、コンテキストとの関連性を保つことができます。,https://d3i71xaburhd42.cloudfront.net/69f8985cbbea69273d8003876d196adc9103d300/1-Figure1-1.png
AutoDrop: Learning Dropping Patterns to Regularize Deep Networks,"['Hieu Pham', 'Quoc Le']",https://arxiv.org/abs/2101.01761,"Neural networks are often over-parameterized and hence benefit from aggressive regularization. Conventional regularization methods, such as Dropout (Srivastava et al. 2014) or weight decay, do not leverage the structures of the network’s inputs and hidden states. As a result, these methods are less effective than recent methods that leverage the structures, such as SpatialDropout (Tompson et al. 2020) and DropBlock (Ghiasi, Lin, and Le 2018), which randomly drop the values at certain contiguous areas in the hidden states and setting them to zero. Although the locations of dropout areas are random, the patterns of SpatialDropout and DropBlock are manually designed and fixed. Here we propose AutoDropout, which automates the process of designing dropout patterns. In our method, a controller learns to generate a dropout pattern at every channel and layer of a target network, such as a ConvNet or a Transformer. The target network is then trained with the dropout pattern, and its resulting validation performance is used as a signal for the controller to learn from. We show that this method works well for both image recognition on CIFAR-10 and ImageNet, as well as language modeling on Penn Treebank and WikiText-2. The learned dropout patterns also transfers to different tasks and datasets, such as from language model on Penn Treebank to Engligh-French translation on WMT 2014. Our code will be available.",ニューラルネットワークはパラメータが多すぎることが多いため、積極的な正則化の恩恵を受けます。ドロップアウト（Srivastava etal。2014）や重みの減衰などの従来の正則化方法は、ネットワーク入力と隠れた状態の構造を利用しません。その結果、これらの方法は、SpatialDropout（Tompson etal。2020）やDropBlock（Ghiasi、Lin、Le 2018）などの構造を活用する最近の方法よりも効果が低く、これらの方法では、の特定の隣接領域で値がランダムにドロップされます。非表示の状態とそれらをゼロに設定します。ドロップアウトエリアの場所はランダムですが、SpatialDropoutとDropBlockのパターンは手動で設計および修正されています。ここでは、ドロップアウトパターンの設計プロセスを自動化するAutoDropoutを提案します。私たちの方法では、コントローラーは、ConvNetやTransformerなどのターゲットネットワークのすべてのチャネルとレイヤーでドロップアウトパターンを生成することを学習します。次に、ターゲットネットワークはドロップアウトパターンでトレーニングされ、その結果の検証パフォーマンスは、コントローラーが学習するための信号として使用されます。この方法が、CIFAR-10とImageNetでの画像認識、およびPennTreebankとWikiText-2での言語モデリングの両方でうまく機能することを示します。学習したドロップアウトパターンは、PennTreebankの言語モデルからWMT2014の英語-フランス語翻訳など、さまざまなタスクやデータセットにも転送されます。コードが利用可能になります。,https://d3i71xaburhd42.cloudfront.net/ef8854a62e05c8e741894166689a9cd8352a1df0/3-Figure1-1.png
ACMo: Angle-Calibrated Moment Methods for Stochastic Optimization,"['Xunpeng Huang', 'Runxin Xu', 'Hao Zhou', 'Zhe Wang', 'Zhengyang Liu', 'Lei Li']",https://arxiv.org/abs/2006.07065,"Due to its simplicity and outstanding ability to generalize, stochastic gradient descent (SGD) is still the most widely used optimization method despite its slow convergence. Meanwhile, adaptive methods have attracted rising attention of optimization and machine learning communities, both for the leverage of life-long information and for the profound and fundamental mathematical theory. Taking the best of both worlds is the most exciting and challenging question in the field of optimization for machine learning. Along this line, we revisited existing adaptive gradient methods from a novel perspective, refreshing understanding of second moments. Our new perspective empowers us to attach the properties of second moments to the first moment iteration, and to propose a novel first moment optimizer, \emph{Angle-Calibrated Moment method} (\method). Our theoretical results show that \method is able to achieve the same convergence rate as mainstream adaptive methods. Furthermore, extensive experiments on CV and NLP tasks demonstrate that \method has a comparable convergence to SOTA Adam-type optimizers, and gains a better generalization performance in most cases.",その単純さと一般化する卓越した能力により、確率的勾配降下法（SGD）は、収束が遅いにもかかわらず、依然として最も広く使用されている最適化手法です。一方、適応手法は、生涯情報の活用と深遠で基本的な数学的理論の両方で、最適化と機械学習のコミュニティの注目を集めています。両方の世界を最大限に活用することは、機械学習の最適化の分野で最もエキサイティングで挑戦的な質問です。この方針に沿って、既存の適応勾配法を新しい視点から再検討し、2次モーメントの理解を新たにしました。私たちの新しい視点は、2次モーメントの特性を1次モーメントの反復に結び付け、新しい1次モーメントオプティマイザーである角度較正モーメント法を提案することを可能にします（）。私たちの理論的結果は、主流の適応法と同じ収束率を達成できることを示しています。さらに、CVおよびNLPタスクに関する広範な実験により、SOTA Adamタイプのオプティマイザーに匹敵する収束性があり、ほとんどの場合、より優れた一般化パフォーマンスが得られることが示されています。,https://d3i71xaburhd42.cloudfront.net/efe0af196c18abea1db1e28b7c78dd30c4437585/4-Figure1-1.png
Online Non-Monotone DR-Submodular Maximization,"['Kim Thang Nguyen', 'Abhinav Srivastav']",,,,
Minimum Robust Multi-Submodular Cover for Fairness,"['Lan N Nguyen', 'My T. Thai']",https://arxiv.org/abs/2012.07936,"In this paper, we study a novel problem, Minimum Robust Multi-Submodular Cover for Fairness (MinRF), as follows: given a ground set $V$; $m$ monotone submodular functions $f_1,...,f_m$; $m$ thresholds $T_1,...,T_m$ and a non-negative integer $r$, MinRF asks for the smallest set $S$ such that for all $i \in [m]$, $\min_{|X| \leq r} f_i(S \setminus X) \geq T_i$. We prove that MinRF is inapproximable within $(1-\epsilon)\ln m$; and no algorithm, taking fewer than exponential number of queries in term of $r$, is able to output a feasible set to MinRF with high certainty. Three bicriteria approximation algorithms with performance guarantees are proposed: one for $r=0$, one for $r=1$, and one for general $r$. We further investigate our algorithms' performance in two applications of MinRF, Information Propagation for Multiple Groups and Movie Recommendation for Multiple Users. Our algorithms have shown to outperform baseline heuristics in both solution quality and the number of queries in most cases.",この論文では、次のように、新しい問題である公平性のための最小ロバストマルチ劣モジュラカバー（MinRF）を研究します。 m単調劣モジュラ関数f1、...、f（m）; m個のしきい値T1、...、T（m）および負でない整数rの場合、MinRFは、すべてのi [m]、min（| X | r）f（i）（S \ X）T（i）。 MinRFが（1）lnm以内で近似できないことを証明します。また、rに関して指数関数的な数より少ないクエリを使用するアルゴリズムでは、実行可能セットをMinRFに高い確実性で出力できません。パフォーマンスが保証された3つの二基準近似アルゴリズムが提案されています。1つはr = 0用、1つはr = 1用、もう1つは一般的なr用です。さらに、MinRFの2つのアプリケーション、複数のグループの情報伝播と複数のユーザーの映画の推奨におけるアルゴリズムのパフォーマンスを調査します。私たちのアルゴリズムは、ほとんどの場合、ソリューションの品質とクエリの数の両方でベースラインヒューリスティックを上回ることが示されています。,https://d3i71xaburhd42.cloudfront.net/6ec2c2700ad7f3065899ae98028f7b35a9607fe3/6-Figure1-1.png
C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot Filling,"['Yutai Hou', 'Sanyuan Chen', 'Wanxiang Che', 'Cheng Chen', 'Ting Liu']",https://arxiv.org/abs/2012.07004,"Slot filling, a fundamental module of spoken language understanding, often suffers from insufficient quantity and diversity of training data. To remedy this, we propose a novel Cluster-to-Cluster generation framework for Data Augmentation (DA), named C2C-GenDA. It enlarges the training set by reconstructing existing utterances into alternative expressions while keeping semantic. Different from previous DA works that reconstruct utterances one by one independently, C2C-GenDA jointly encodes multiple existing utterances of the same semantics and simultaneously decodes multiple unseen expressions. Jointly generating multiple new utterances allows to consider the relations between generated instances and encourages diversity. Besides, encoding multiple existing utterances endows C2C with a wider view of existing expressions, helping to reduce generation that duplicates existing data. Experiments on ATIS and Snips datasets show that instances augmented by C2C-GenDA improve slot filling by 7.99 (11.9%) and 5.76 (13.6%) F-scores respectively, when there are only hundreds of training utterances.",口頭言語理解の基本モジュールであるスロット充填は、トレーニングデータの量と多様性が不十分であることがよくあります。これを改善するために、C2C-GenDAという名前のデータ拡張（DA）用の新しいクラスター間生成フレームワークを提案します。セマンティックを維持しながら、既存の発話を代替表現に再構築することにより、トレーニングセットを拡大します。 C2C-GenDAは、発話を1つずつ独立して再構築する以前のDA作業とは異なり、同じセマンティクスの複数の既存の発話を共同でエンコードし、同時に複数の見えない表現をデコードします。複数の新しい発話を共同で生成することで、生成されたインスタンス間の関係を検討し、多様性を促進できます。さらに、複数の既存の発話をエンコードすると、C2Cに既存の表現のより広い視野が与えられ、既存のデータを複製する生成を減らすのに役立ちます。 ATISおよびSnipsデータセットでの実験では、C2C-GenDAによって拡張されたインスタンスにより、スロットの充填が7.99（11.9,https://d3i71xaburhd42.cloudfront.net/c326c1d6f154bbc9822f900ddcf42f482ec9c611/1-Figure1-1.png
Self-Attention Attribution: Interpreting Information Interactions Inside Transformer,"['Yaru Hao', 'Li Dong', 'Furu Wei', 'Ke Xu']",https://arxiv.org/abs/2004.11207,"The great success of Transformer-based models benefits from the powerful multi-head self-attention mechanism, which learns token dependencies and encodes contextual information from the input. Prior work strives to attribute model decisions to individual input features with different saliency measures, but they fail to explain how these input features interact with each other to reach predictions. In this paper, we propose a self-attention attribution algorithm to interpret the information interactions inside Transformer. We take BERT as an example to conduct extensive studies. Firstly, we extract the most salient dependencies in each layer to construct an attribution graph, which reveals the hierarchical interactions inside Transformer. Furthermore, we apply self-attention attribution to identify the important attention heads, while others can be pruned with only marginal performance degradation. Finally, we show that the attribution results can be used as adversarial patterns to implement non-targeted attacks towards BERT.",Transformerベースのモデルの大成功は、トークンの依存関係を学習し、入力からコンテキスト情報をエンコードする強力なマルチヘッド自己注意メカニズムの恩恵を受けています。以前の作業では、モデルの決定を異なる顕著性測定値を持つ個々の入力特徴に帰するように努めていますが、これらの入力特徴が相互作用して予測に到達する方法を説明できていません。この論文では、Transformer内の情報の相互作用を解釈するための自己注意帰属アルゴリズムを提案します。広範な調査を実施するための例としてBERTを取り上げます。まず、各レイヤーで最も顕著な依存関係を抽出して、Transformer内の階層的な相互作用を明らかにするアトリビューショングラフを作成します。さらに、重要な注意の頭を特定するために自己注意の帰属を適用しますが、他の人はわずかなパフォーマンスの低下だけで剪定することができます。最後に、帰属結果を敵対的なパターンとして使用して、BERTに対する非標的型攻撃を実装できることを示します。,https://d3i71xaburhd42.cloudfront.net/1686203adc5f2dbc18627ce64f66d33eb81432a5/3-Figure1-1.png
Few-Shot Learning for Multi-Label Intent Detection,"['Yutai Hou', 'Yongkui Lai', 'YuShan Wu', 'Wanxiang Che', 'Ting Liu']",https://arxiv.org/abs/2010.05256,"In this paper, we study the few-shot multi-label classification for user intent detection. For multi-label intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels. To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a calibration based on nonparametric learning. For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refines representations of different classes to be well-separated from each other. Experiments on two datasets show that the proposed model significantly outperforms strong baselines in both one-shot and five-shot settings.",この論文では、ユーザーの意図を検出するための数ショットのマルチラベル分類を研究します。マルチラベルインテント検出の場合、最先端の作業により、ラベルインスタンスの関連性スコアが推定され、しきい値を使用して複数の関連するインテントラベルが選択されます。ほんの数例で適切なしきい値を決定するために、最初にデータが豊富なドメインでのユニバーサルしきい値処理の経験を学習し、次にノンパラメトリック学習に基づくキャリブレーションを使用してしきい値を特定の数ショットドメインに適応させます。ラベルインスタンスの関連性スコアをより適切に計算するために、表現空間のアンカーポイントとしてラベル名の埋め込みを導入します。これにより、さまざまなクラスの表現が互いに十分に分離されるように調整されます。 2つのデータセットでの実験は、提案されたモデルがワンショットと5ショットの両方の設定で強力なベースラインを大幅に上回っていることを示しています。,https://d3i71xaburhd42.cloudfront.net/6c6dc8cfda89fb6f90073cbee1ea82e744477460/1-Figure1-1.png
Enhanced Regularizers for Attributional Robustness,"['Anindya Sarkar', 'Anirban Sarkar', 'Vineeth N Balasubramanian']",https://arxiv.org/abs/2012.14395,"Deep neural networks are the default choice of learning models for computer vision tasks. Extensive work has been carried out in recent years on explaining deep models for vision tasks such as classification. However, recent work has shown that it is possible for these models to produce substantially different attribution maps even when two very similar images are given to the network, raising serious questions about trustworthiness. To address this issue, we propose a robust attribution training strategy to improve attributional robustness of deep neural networks. Our method carefully analyzes the requirements for attributional robustness and introduces two new regularizers that preserve a model’s attribution map during attacks. Our method surpasses state-of-the-art attributional robustness methods by a margin of approximately 3% to 9% in terms of attribution robustness measures on several datasets including MNIST, FMNIST, Flower and GTSRB.",ディープニューラルネットワークは、コンピュータービジョンタスクの学習モデルのデフォルトの選択肢です。近年、分類などの視覚課題の深いモデルを説明するための広範な作業が行われています。ただし、最近の研究では、2つの非常に類似した画像がネットワークに与えられた場合でも、これらのモデルが大幅に異なるアトリビューションマップを生成する可能性があり、信頼性について深刻な疑問が生じています。この問題に対処するために、ディープニューラルネットワークの帰属の堅牢性を向上させるための堅牢な帰属トレーニング戦略を提案します。私たちの方法は、帰属の堅牢性の要件を注意深く分析し、攻撃中にモデルの帰属マップを保持する2つの新しいレギュラライザーを導入します。私たちの方法は、最先端の帰属ロバスト性の方法を約3のマージンで上回っています。,https://d3i71xaburhd42.cloudfront.net/99e6269625fd83090cdcbebf85f9632f8573be40/2-Figure1-1.png
Deep Innovation Protection: Confronting the Credit Assignment Problem in Training Heterogeneous Neural Architectures,"['Sebastian Risi', 'Kenneth O Stanley']",,,,
Does Explainable Artificial Intelligence Improve Human Decision-Making?,"['Yasmeen Alufaisan', 'Laura Marusich', 'Jonathan Bakdash', 'Yan Zhou', 'Murat Kantarcioglu']",https://arxiv.org/abs/2006.11194,"Explainable AI provides insight into the ""why"" for model predictions, offering potential for users to better understand and trust a model, and to recognize and correct AI predictions that are incorrect. Prior research on human and explainable AI interactions has focused on measures such as interpretability, trust, and usability of the explanation. Whether explainable AI can improve actual human decision-making and the ability to identify the problems with the underlying model are open questions. Using real datasets, we compare and evaluate objective human decision accuracy without AI (control), with an AI prediction (no explanation), and AI prediction with explanation. We find providing any kind of AI prediction tends to improve user decision accuracy, but no conclusive evidence that explainable AI has a meaningful impact. Moreover, we observed the strongest predictor for human decision accuracy was AI accuracy and that users were somewhat able to detect when the AI was correct versus incorrect, but this was not significantly affected by including an explanation. Our results indicate that, at least in some situations, the ""why"" information provided in explainable AI may not enhance user decision-making, and further research may be needed to understand how to integrate explainable AI into real systems.",説明可能なAIは、モデル予測の「理由」についての洞察を提供し、ユーザーがモデルをよりよく理解して信頼し、誤ったAI予測を認識して修正する可能性を提供します。人間と説明可能なAIの相互作用に関するこれまでの研究は、説明の解釈可能性、信頼性、使いやすさなどの指標に焦点を当ててきました。説明可能なAIが実際の人間の意思決定を改善できるかどうか、および基礎となるモデルの問題を特定する能力は未解決の問題です。実際のデータセットを使用して、AIなし（コントロール）、AI予測あり（説明なし）、および説明付きのAI予測を使用して、客観的な人間の意思決定の精度を比較および評価します。あらゆる種類のAI予測を提供すると、ユーザーの意思決定の精度が向上する傾向がありますが、説明可能なAIが意味のある影響を与えるという決定的な証拠はありません。さらに、人間の意思決定の正確さの最も強力な予測因子はAIの正確さであり、ユーザーはAIが正しいか間違っているかをある程度検出できましたが、説明を含めても大きな影響はありませんでした。私たちの結果は、少なくともいくつかの状況では、説明可能なAIで提供される「理由」情報がユーザーの意思決定を強化しない可能性があり、説明可能なAIを実際のシステムに統合する方法を理解するためにさらなる調査が必要になる可能性があることを示しています。,https://d3i71xaburhd42.cloudfront.net/e7411483b88a977ff046f444800d808135535f65/5-Figure1-1.png
Necessarily Optimal One-Sided Matchings,"['Hadi Hosseini', 'Vijay Menon', 'Nisarg Shah', 'Sujoy Sikdar']",,,,
Evolutionary Game Theory Squared: Evolving Agents in Endogenously Evolving Zero-Sum Games,"['Stratis Skoulakis', 'Tanner Fiez', 'Ryann Sim', 'Georgios Piliouras', 'Lillian Ratliff']",,,,
Query Training: Learning a Worse Model to Infer Better Marginals in Undirected Graphical Models with Hidden Variables,"['Miguel Lázaro-Gredilla', 'Wolfgang Lehrach', 'Nishad Gothoskar', 'Guangyao Zhou', 'Antoine Dedieu', 'Dileep George']",,,,
Multilingual Transfer Learning for QA Using Translation as Data Augmentation,"['Mihaela Bornea', 'Lin Pan', 'Sara Rosenthal', 'Radu Florian', 'Avi Sil']",,,,
Top-k Ranking Bayesian Optimization,"['Quoc Phong Nguyen', 'Sebastian Tay', 'Bryan Kian Hsiang Low', 'Patrick Jaillet']",,,,
Improved Mutual Information Estimation,"['Youssef Mroueh', 'Igor Melnyk', 'Pierre Dognin', 'Jarret Ross', 'Tom Sercu']",,,,
Meta Label Correction for Noisy Label Learning,"['Guoqing Zheng', 'Ahmed Awadallah', 'Susan Dumais']",,"Leveraging weak or noisy supervision for building effective machine learning models has long been an important research problem. Its importance has further increased recently due to the growing need for large-scale datasets to train deep learning models. Weak or noisy supervision could originate from multiple sources including non-expert annotators or automatic labeling based on heuristics or user interaction signals. There is an extensive amount of previous work focusing on leveraging noisy labels. Most notably, recent work has shown impressive gains by using a meta-learned instance re-weighting approach where a meta-learning framework is used to assign instance weights to noisy labels. In this paper, we extend this approach via posing the problem as label correction problem within a meta-learning framework. We view the label correction procedure as a meta-process and propose a new meta-learning based framework termed MLC (Meta Label Correction) for learning with noisy labels. Specifically, a label correction network is adopted as a meta-model to produce corrected labels for noisy labels while the main model is trained to leverage the corrected labeled. Both models are jointly trained by solving a bi-level optimization problem. We run extensive experiments with different label noise levels and types on both image recognition and text classification tasks. We compare the reweighing and correction approaches showing that the correction framing addresses some of the limitation of reweighting. We also show that the proposed MLC approach achieves large improvements over previous methods in many settings.",効果的な機械学習モデルを構築するために弱いまたはノイズの多い監視を活用することは、長い間重要な研究課題でした。ディープラーニングモデルをトレーニングするための大規模なデータセットの必要性が高まっているため、その重要性は最近さらに高まっています。弱いまたはノイズの多い監視は、専門家ではないアノテーターや、ヒューリスティックまたはユーザーインタラクション信号に基づく自動ラベル付けなど、複数のソースから発生する可能性があります。ノイズの多いラベルの活用に焦点を当てたこれまでの作業は大量にあります。最も注目すべきことに、最近の研究では、メタ学習フレームワークを使用してノイズの多いラベルにインスタンスの重みを割り当てる、メタ学習されたインスタンスの再重み付けアプローチを使用することで、目覚ましい進歩が見られました。この論文では、メタ学習フレームワーク内のラベル修正問題として問題を提起することにより、このアプローチを拡張します。ラベル修正手順をメタプロセスと見なし、ノイズの多いラベルで学習するためのMLC（メタラベル修正）と呼ばれる新しいメタ学習ベースのフレームワークを提案します。具体的には、ラベル修正ネットワークがメタモデルとして採用され、ノイズの多いラベルの修正ラベルを生成し、メインモデルは修正されたラベルを活用するようにトレーニングされます。両方のモデルは、2レベルの最適化問題を解くことによって共同でトレーニングされます。画像認識とテキスト分類の両方のタスクで、さまざまなラベルノイズレベルとタイプを使用して広範な実験を実行します。再計量と修正のアプローチを比較して、修正フレーミングが再重み付けの制限のいくつかに対処していることを示します。また、提案されたMLCアプローチが、多くの設定で以前の方法に比べて大幅な改善を達成することも示しています。,
Towards Trustworthy Predictions from Deep Neural Networks with Fast Adversarial Calibration,"['Christian Tomani', 'Florian Buettner']",https://arxiv.org/abs/2012.10923,"To facilitate a wide-spread acceptance of AI systems guiding decision making in real-world applications, trustworthiness of deployed models is key. That is, it is crucial for predictive models to be uncertainty-aware and yield well-calibrated (and thus trustworthy) predictions for both in-domain samples as well as under domain shift. Recent efforts to account for predictive uncertainty include post-processing steps for trained neural networks, Bayesian neural networks as well as alternative non-Bayesian approaches such as ensemble approaches and evidential deep learning. Here, we propose an efficient yet general modelling approach for obtaining wellcalibrated, trustworthy probabilities for samples obtained after a domain shift. We introduce a new training strategy combining an entropy-encouraging loss term with an adversarial calibration loss term and demonstrate that this results in well-calibrated and technically trustworthy predictions for a wide range of domain drifts. We comprehensively evaluate previously proposed approaches on different data modalities, a large range of data sets including sequence data, network architectures and perturbation strategies. We observe that our modelling approach substantially outperforms existing state-of-the-art approaches, yielding well-calibrated predictions under domain drift.",実世界のアプリケーションで意思決定を導くAIシステムの普及を促進するには、展開されたモデルの信頼性が重要です。つまり、予測モデルが不確実性を認識し、ドメイン内サンプルとドメインシフト下の両方で適切に調整された（したがって信頼できる）予測を生成することが重要です。予測の不確実性を説明する最近の取り組みには、トレーニングされたニューラルネットワーク、ベイズニューラルネットワークのほか、アンサンブルアプローチや証拠深層学習などの代替の非ベイズアプローチの後処理ステップが含まれます。ここでは、ドメインシフト後に取得されたサンプルの十分に調整された信頼できる確率を取得するための効率的でありながら一般的なモデリングアプローチを提案します。エントロピーを促進する損失項と敵対的な較正損失項を組み合わせた新しいトレーニング戦略を紹介し、これにより、広範囲のドメインドリフトに対して十分に較正された技術的に信頼できる予測が得られることを示します。さまざまなデータモダリティ、シーケンスデータ、ネットワークアーキテクチャ、摂動戦略などの幅広いデータセットについて、以前に提案されたアプローチを包括的に評価します。私たちのモデリングアプローチは、既存の最先端のアプローチを大幅に上回り、ドメインドリフトの下で十分に調整された予測をもたらすことがわかります。,https://d3i71xaburhd42.cloudfront.net/d3b1cfec88ff61e495a5aeec3e8126651c2472cb/3-Figure1-1.png
Invertible Concept-Based Explanations for CNN Models with Non-Negative Concept Activation Vectors,"['Ruihan Zhang', 'Prashan M Madumal', 'Tim Miller', 'Krista A. Ehinger', 'Benjamin Rubinstein']",,,,
MELINDA: A Multimodal Dataset for Biomedical Experiment Method Classification,"['Te-Lin Wu', 'Shikhar Singh', 'Sayan Paul', 'Gully A Burns', 'Nanyun Peng']",https://arxiv.org/abs/2012.09216,"We introduce a new dataset, MELINDA, for Multimodal biomEdicaL experImeNt methoD clAssification. The dataset is collected in a fully automated distant supervision manner, where the labels are obtained from an existing curated database, and the actual contents are extracted from papers associated with each of the records in the database. We benchmark various state-of-the-art NLP and computer vision models, including unimodal models which only take either caption texts or images as inputs, and multimodal models. Extensive experiments and analysis show that multimodal models, despite outperforming unimodal ones, still need improvements especially on a less-supervised way of grounding visual concepts with languages, and better transferability to low resource domains. We release our dataset and the benchmarks to facilitate future research in multimodal learning, especially to motivate targeted improvements for applications in scientific domains.",マルチモーダル生物工学実験法の分類のための新しいデータセット、MELINDAを紹介します。データセットは完全に自動化された遠隔監視方式で収集され、ラベルは既存のキュレーションされたデータベースから取得され、実際のコンテンツはデータベース内の各レコードに関連付けられた論文から抽出されます。キャプションテキストまたは画像のいずれかのみを入力として受け取るユニモーダルモデルやマルチモーダルモデルなど、さまざまな最先端のNLPおよびコンピュータービジョンモデルのベンチマークを行います。広範な実験と分析により、マルチモーダルモデルは、ユニモーダルモデルを上回っていますが、特に監視されていない方法で視覚的概念を言語に基づいて構築し、低リソースドメインへの転送性を向上させる必要があることが示されています。データセットとベンチマークをリリースして、マルチモーダル学習の将来の研究を促進し、特に科学分野のアプリケーションの対象を絞った改善を動機付けます。,https://d3i71xaburhd42.cloudfront.net/c9074d9719c5ce0dd3a7369dd0749cd08d7f67ed/1-Figure1-1.png
Sublinear Classical and Quantum Algorithms for General Matrix Games,"['Tongyang Li', 'Chunhao Wang', 'Shouvanik Chakrabarti', 'Xiaodi Wu']",https://arxiv.org/abs/2012.06519,"We investigate sublinear classical and quantum algorithms for matrix games, a fundamental problem in optimization and machine learning, with provable guarantees. Given a matrix $A\in\mathbb{R}^{n\times d}$, sublinear algorithms for the matrix game $\min_{x\in\mathcal{X}}\max_{y\in\mathcal{Y}} y^{\top} Ax$ were previously known only for two special cases: (1) $\mathcal{Y}$ being the $\ell_{1}$-norm unit ball, and (2) $\mathcal{X}$ being either the $\ell_{1}$- or the $\ell_{2}$-norm unit ball. We give a sublinear classical algorithm that can interpolate smoothly between these two cases: for any fixed $q\in (1,2]$, we solve the matrix game where $\mathcal{X}$ is a $\ell_{q}$-norm unit ball within additive error $\epsilon$ in time $\tilde{O}((n+d)/{\epsilon^{2}})$. We also provide a corresponding sublinear quantum algorithm that solves the same task in time $\tilde{O}((\sqrt{n}+\sqrt{d})\textrm{poly}(1/\epsilon))$ with a quadratic improvement in both $n$ and $d$. Both our classical and quantum algorithms are optimal in the dimension parameters $n$ and $d$ up to poly-logarithmic factors. Finally, we propose sublinear classical and quantum algorithms for the approximate Caratheodory problem and the $\ell_{q}$-margin support vector machines as applications.",マトリックスゲームの劣線形古典アルゴリズムと量子アルゴリズム、最適化と機械学習の基本的な問題を、証明可能な保証付きで調査します。行列AR ^（nd）が与えられた場合、行列ゲームmin（x X）max（y Y）y ^（）Axの劣線形アルゴリズムは、以前は2つの特殊なケースでのみ知られていました。（1）Yはl1ノルム単位球です。 、および（2）Xはl1-またはl2-ノルム単位球のいずれかです。これら2つのケース間をスムーズに補間できる劣線形古典アルゴリズムを与えます。任意の固定q（1、2]に対して、Xが時間O（（n）の加法誤差内でal（q）-ノルム単位球である行列ゲームを解きます。 + d）/ 2）また、同じタスクを時間内に解決する対応する劣線形量子アルゴリズムを提供します$ \ tilde {O}（（\ sqrt {n} + \ sqrt {d}）\ textrm {poly}（1 / \ epsilon））$ nとdの両方が2次的に改善されています。古典的アルゴリズムと量子アルゴリズムの両方が、多対数因子までの次元パラメーターnとdで最適です。最後に、近似カラセオドリーの劣線形古典的アルゴリズムと量子アルゴリズムを提案します。問題とl（q）マージンはアプリケーションとしてベクトルマシンをサポートします。,https://d3i71xaburhd42.cloudfront.net/3a69cf4992a77daf4d4e6dba6544e4f6a090a401/14-Figure1-1.png
Segatron: Segment-Aware Transformer for Language Modeling and Understanding,"['He Bai', 'Peng Shi', 'Jimmy Lin', 'Yuqing Xie', 'Luchen Tan', 'Kun Xiong', 'Wen Gao', 'Ming Li']",https://arxiv.org/abs/2004.14996,"Transformers are powerful for sequence modeling. Nearly all state-of-the-art language models and pre-trained language models are based on the Transformer architecture. However, it distinguishes sequential tokens only with the token position index. We hypothesize that better contextual representations can be generated from the Transformer with richer positional information. To verify this, we propose a segment-aware Transformer (Segatron), by replacing the original token position encoding with a combined position encoding of paragraph, sentence, and token. We first introduce the segment-aware mechanism to Transformer-XL, which is a popular Transformer-based language model with memory extension and relative position encoding. We find that our method can further improve the Transformer-XL base model and large model, achieving 17.1 perplexity on the WikiText-103 dataset. We further investigate the pre-training masked language modeling task with Segatron. Experimental results show that BERT pre-trained with Segatron (SegaBERT) can outperform BERT with vanilla Transformer on various NLP tasks, and outperforms RoBERTa on zero-shot sentence representation learning.",トランスフォーマーは、シーケンスモデリングに強力です。ほぼすべての最先端の言語モデルと事前にトレーニングされた言語モデルは、Transformerアーキテクチャに基づいています。ただし、シーケンシャルトークンはトークン位置インデックスでのみ区別されます。より豊富な位置情報を使用して、Transformerからより適切なコンテキスト表現を生成できると仮定します。これを検証するために、元のトークン位置エンコーディングを段落、文、およびトークンの組み合わせ位置エンコーディングに置き換えることにより、セグメント対応トランスフォーマー（Segatron）を提案します。最初に、セグメント対応メカニズムをTransformer-XLに導入します。これは、メモリ拡張と相対位置エンコーディングを備えた、人気のあるTransformerベースの言語モデルです。私たちの方法は、Transformer-XLベースモデルとラージモデルをさらに改善し、WikiText-103データセットで17.1の複雑さを実現できることがわかりました。 Segatronを使用して、トレーニング前のマスクされた言語モデリングタスクをさらに調査します。実験結果は、Segatron（SegaBERT）で事前トレーニングされたBERTが、さまざまなNLPタスクでバニラトランスフォーマーを使用したBERTを上回り、ゼロショット文表現学習でRoBERTaを上回っていることを示しています。,
Learning from Crowds by Modeling Common Confusions,"['Zhendong Chu', 'Jing Ma', 'Hongning Wang']",https://arxiv.org/abs/2012.13052,"Crowdsourcing provides a practical way to obtain large amounts of labeled data at a low cost. However, the annotation quality of annotators varies considerably, which imposes new challenges in learning a high-quality model from the crowdsourced annotations. In this work, we provide a new perspective to decompose annotation noise into common noise and individual noise and differentiate the source of confusion based on instance difficulty and annotator expertise on a per-instance-annotator basis. We realize this new crowdsourcing model by an end-to-end learning solution with two types of noise adaptation layers: one is shared across annotators to capture their commonly shared confusions, and the other one is pertaining to each annotator to realize individual confusion. To recognize the source of noise in each annotation, we use an auxiliary network to choose the two noise adaptation layers with respect to both instances and annotators. Extensive experiments on both synthesized and realworld benchmarks demonstrate the effectiveness of our proposed common noise adaptation solution.",クラウドソーシングは、大量のラベル付きデータを低コストで取得するための実用的な方法を提供します。ただし、アノテーターの注釈の品質は大幅に異なるため、クラウドソーシングされた注釈から高品質のモデルを学習する際に新たな課題が発生します。この作業では、注釈ノイズを一般的なノイズと個々のノイズに分解し、インスタンスの難易度とインスタンスごとのアノテーターごとのアノテーターの専門知識に基づいて混乱の原因を区別するための新しい視点を提供します。この新しいクラウドソーシングモデルは、2種類のノイズ適応層を備えたエンドツーエンドの学習ソリューションによって実現されます。1つはアノテーター間で共有されて共通の混乱を捉え、もう1つは各アノテーターに関係して個々の混乱を実現します。各アノテーションのノイズの原因を認識するために、補助ネットワークを使用して、インスタンスとアノテーターの両方に関して2つのノイズ適応層を選択します。合成ベンチマークと実世界ベンチマークの両方での広範な実験は、提案された一般的なノイズ適応ソリューションの有効性を示しています。,https://d3i71xaburhd42.cloudfront.net/6a07ffe4d2a09bace25e8fb8992711b1ddf6b675/2-Figure1-1.png
GATE: Graph Attention Transformer Encoder for Cross-Lingual Relation and Event Extraction,"['Wasi U Ahmad', 'Nanyun Peng', 'Kai-Wei Chang']",https://arxiv.org/abs/2010.03009,"Prevalent approaches in cross-lingual relation and event extraction use graph convolutional networks (GCNs) with universal dependency parses to learn language-agnostic representations such that models trained on one language can be applied to other languages. However, GCNs lack in modeling long-range dependencies or disconnected words in the dependency tree. To address this challenge, we propose to utilize the self-attention mechanism where we explicitly fuse structural information to learn the dependencies between words at different syntactic distances. We introduce GATE, a {\bf G}raph {\bf A}ttention {\bf T}ransformer {\bf E}ncoder, and test its cross-lingual transferability on relation and event extraction tasks. We perform rigorous experiments on the widely used ACE05 dataset that includes three typologically different languages: English, Chinese, and Arabic. The evaluation results show that GATE outperforms three recently proposed methods by a large margin. Our detailed analysis reveals that due to the reliance on syntactic dependencies, GATE produces robust representations that facilitate transfer across languages.",言語間関係とイベント抽出の一般的なアプローチでは、ユニバーサル依存関係解析を使用したグラフ畳み込みネットワーク（GCN）を使用して、ある言語でトレーニングされたモデルを他の言語に適用できるように、言語に依存しない表現を学習します。ただし、GCNには、依存関係ツリー内の長距離の依存関係または切断された単語のモデリングがありません。この課題に対処するために、構造情報を明示的に融合して、異なる構文距離にある単語間の依存関係を学習する自己注意メカニズムを利用することを提案します。 Graph Attention Transformer EncoderであるGATEを紹介し、関係およびイベント抽出タスクでの言語間の転送可能性をテストします。英語、中国語、アラビア語の3つの類型的に異なる言語を含む、広く使用されているACE05データセットに対して厳密な実験を行います。評価結果は、GATEが最近提案された3つの方法を大幅に上回っていることを示しています。詳細な分析により、構文の依存関係に依存しているため、GATEは言語間の転送を容易にする堅牢な表現を生成することが明らかになりました。,https://d3i71xaburhd42.cloudfront.net/ec7bac39655b5ea177e76f7a80afd02658154027/1-Figure1-1.png
MultiTalk: A Highly-Branching Dialog Testbed for Diverse Conversations,"['Yao Dou', 'Maxwell Forbes', 'Ari Holtzman', 'Yejin Choi']",https://arxiv.org/abs/2102.01263,"We study conversational dialog in which there are many possible responses to a given history. We present the MultiTalk Dataset, a corpus of over 320,000 sentences of written conversational dialog that balances a high branching factor (10) with several conversation turns (6) through selective branch continuation. We make multiple contributions to study dialog generation in the highly branching setting. In order to evaluate a diverse set of generations, we propose a simple scoring algorithm, based on bipartite graph matching, to optimally incorporate a set of diverse references. We study multiple language generation tasks at different levels of predictive conversation depth, using textual attributes induced automatically from pretrained classifiers. Our culminating task is a challenging theory of mind problem, a controllable generation task which requires reasoning about the expected reaction of the listener.",私たちは、与えられた歴史に対して多くの可能な反応がある会話対話を研究します。 MultiTalk Datasetを紹介します。これは、選択的な分岐の継続を通じて、高い分岐係数（10）といくつかの会話ターン（6）のバランスをとる、32万文を超える会話ダイアログのコーパスです。高度に分岐した設定でのダイアログ生成の研究に複数の貢献をしています。世代の多様なセットを評価するために、2部グラフマッチングに基づいて、多様な参照のセットを最適に組み込むための単純なスコアリングアルゴリズムを提案します。事前にトレーニングされた分類子から自動的に誘導されたテキスト属性を使用して、予測会話の深さのさまざまなレベルで複数の言語生成タスクを研究します。私たちの最高のタスクは、心の問題の挑戦的な理論であり、リスナーの予想される反応についての推論を必要とする制御可能な生成タスクです。,https://d3i71xaburhd42.cloudfront.net/b00674d4e14ef655a16e74a24dfef32664064587/1-Figure1-1.png
It Takes Two to Empathize: One to Seek and One to Provide,"['Mahshid Hosseini', 'Cornelia Caragea']",,,,
Submodel Decomposition Bounds for Influence Diagrams,"['Junkyu Lee', 'Radu Marinescu', 'Rina Dechter']",,,,
Paragraph-Level Commonsense Transformers with Recurrent Memory,"['Saadia Gabriel', 'Chandra Bhagavatula', 'Vered Shwartz', 'Ronan Le Bras', 'Maxwell Forbes', 'Yejin Choi']",https://arxiv.org/abs/2010.01486,"Human understanding of narrative texts requires making commonsense inferences beyond what is stated in the text explicitly. A recent model, COMeT, can generate such inferences along several dimensions such as pre- and post-conditions, motivations, and mental-states of the participants. However, COMeT was trained on short phrases, and is therefore discourse-agnostic. When presented with each sentence of a multi-sentence narrative, it might generate inferences that are inconsistent with the rest of the narrative. 
We present the task of discourse-aware commonsense inference. Given a sentence within a narrative, the goal is to generate commonsense inferences along predefined dimensions, while maintaining coherence with the rest of the narrative. Such large-scale paragraph-level annotation is hard to get and costly, so we use available sentence-level annotations to efficiently and automatically construct a distantly supervised corpus. 
Using this corpus, we train PARA-COMeT, a discourse-aware model that incorporates paragraph-level information to generate coherent commonsense inferences from narratives. PARA-COMeT captures both semantic knowledge pertaining to prior world knowledge, and episodic knowledge involving how current events relate to prior and future events in a narrative. Our results confirm that PARA-COMeT outperforms the sentence-level baselines, particularly in generating inferences that are both coherent and novel.",物語のテキストを人間が理解するには、テキストに明示的に記載されている以上の常識的な推論を行う必要があります。最近のモデルであるCOMeTは、参加者の事前条件と事後条件、動機、精神状態など、いくつかの側面に沿ってそのような推論を生成できます。ただし、COMeTは短いフレーズでトレーニングされているため、談話に依存しません。複数文の物語の各文が提示されると、それは物語の残りの部分と矛盾する推論を生成する可能性があります。談話を意識した常識的推論のタスクを提示します。物語内の文が与えられた場合、目標は、物語の残りの部分との一貫性を維持しながら、事前定義された次元に沿って常識的な推論を生成することです。このような大規模な段落レベルの注釈は取得が難しく、コストがかかるため、利用可能な文レベルの注釈を使用して、遠隔監視されたコーパスを効率的かつ自動的に構築します。このコーパスを使用して、パラグラフレベルの情報を組み込んだ談話認識モデルであるPARA-COMeTをトレーニングし、物語から一貫した常識的な推論を生成します。 PARA-COMeTは、過去の世界の知識に関連する意味論的知識と、現在の出来事が物語の過去および将来の出来事にどのように関連するかを含むエピソード的知識の両方をキャプチャします。私たちの結果は、PARA-COMeTが、特に一貫性があり斬新な推論を生成する際に、文レベルのベースラインを上回っていることを確認しています。,https://d3i71xaburhd42.cloudfront.net/5dfc43bb697acf5eacf8b8a05d78dba8beb0dd42/1-Figure1-1.png
Fair Influence Maximization: a Welfare Optimization Approach,"['Aida Rahmattalabi', 'Shahin Jabbari', 'Himabindu Lakkaraju', 'Phebe Vayanos', 'Max Izenberg', 'Ryan Brown ', 'Eric Rice', 'Milind Tambe']",https://arxiv.org/abs/2006.07906,"Several social interventions (e.g., suicide and HIV prevention) leverage social network information to maximize outreach. Algorithmic influence maximization techniques have been proposed to aid with the choice of influencers (or peer leaders) in such interventions. Traditional algorithms for influence maximization have not been designed with social interventions in mind. As a result, they may disproportionately exclude minority communities from the benefits of the intervention. This has motivated research on fair influence maximization. Existing techniques require committing to a single domain-specific fairness measure. This makes it hard for a decision maker to meaningfully compare these notions and their resulting trade-offs across different applications. 
We address these shortcomings by extending the principles of cardinal welfare to the influence maximization setting, which is underlain by complex connections between members of different communities. We generalize the theory regarding these principles and show under what circumstances these principles can be satisfied by a welfare function. We then propose a family of welfare functions that are governed by a single inequity aversion parameter which allows a decision maker to study task-dependent trade-offs between fairness and total influence and effectively trade off quantities like influence gap by varying this parameter. We use these welfare functions as a fairness notion to rule out undesirable allocations. We show that the resulting optimization problem is monotone and submodular and can be solved with optimality guarantees. Finally, we carry out a detailed experimental analysis on synthetic and real social networks and should that high welfare can be achieved without sacrificing the total influence significantly. Interestingly we can show there exists welfare functions that empirically satisfy all of the principles.",いくつかの社会的介入（自殺やHIV予防など）は、ソーシャルネットワーク情報を活用してアウトリーチを最大化します。このような介入におけるインフルエンサー（またはピアリーダー）の選択を支援するために、アルゴリズムによる影響最大化手法が提案されています。影響を最大化するための従来のアルゴリズムは、社会的介入を念頭に置いて設計されていません。その結果、彼らは介入の利益からマイノリティコミュニティを不釣り合いに排除するかもしれません。これは、公正な影響の最大化に関する研究の動機となっています。既存の手法では、単一のドメイン固有の公平性測定に取り組む必要があります。これにより、意思決定者がこれらの概念とその結果として生じるトレードオフをさまざまなアプリケーション間で有意義に比較することが困難になります。私たちは、枢機卿福祉の原則を影響最大化の設定に拡張することによってこれらの欠点に対処します。これは、異なるコミュニティのメンバー間の複雑なつながりによって裏付けられています。これらの原則に関する理論を一般化し、どのような状況下でこれらの原則が福祉機能によって満たされるかを示します。次に、意思決定者が公平性と全体的な影響力の間のタスク依存のトレードオフを研究し、このパラメーターを変更することによって影響力のギャップなどの量を効果的にトレードオフできるようにする、単一の不公平回避パラメーターによって管理される福祉関数のファミリーを提案します。これらの福祉機能を公平性の概念として使用して、望ましくない割り当てを除外します。結果として生じる最適化問題は単調で劣モジュラであり、最適性の保証で解決できることを示します。最後に、総合的および実際のソーシャルネットワークについて詳細な実験的分析を行い、全体的な影響を大幅に犠牲にすることなく高い福祉を達成できるかどうかを確認します。興味深いことに、すべての原則を経験的に満たす福祉機能が存在することを示すことができます。,https://d3i71xaburhd42.cloudfront.net/06fe543ad9ef9d0c91db0dfa0e6f98904a6bb40a/8-Figure1-1.png
Bringing UMAP Closer to the Speed of Light with GPU Acceleration,"['Corey J Nolet', 'Victor Lafargue', 'Edward Raff', 'Thejaswi Nanditalte', 'Tim Oates', 'John Zedlewski', 'Joshua Patterson']",https://arxiv.org/abs/2008.00325,"The Uniform Manifold Approximation and Projection (UMAP) algorithm has become widely popular for its ease of use, quality of results, and support for exploratory, unsupervised, supervised, and semi-supervised learning. While many algorithms can be ported to a GPU in a simple and direct fashion, such efforts have resulted in inefficent and inaccurate versions of UMAP. We show a number of techniques that can be used to make a faster and more faithful GPU version of UMAP, and obtain speedups of up to 100x in practice. Many of these design choices/lessons are general purpose and may inform the conversion of other graph and manifold learning algorithms to use GPUs. Our implementation has been made publicly available as part of the open source RAPIDS cuML library(this https URL).",均一マニホールド近似および射影（UMAP）アルゴリズムは、その使いやすさ、結果の品質、および探索的、教師なし、教師あり、および半教師あり学習のサポートで広く普及しています。多くのアルゴリズムは単純で直接的な方法でGPUに移植できますが、そのような努力はUMAPの非効率的で不正確なバージョンをもたらしました。 UMAPのより高速で忠実なGPUバージョンを作成し、実際に最大100倍のスピードアップを実現するために使用できるいくつかの手法を示します。これらの設計の選択/レッスンの多くは汎用であり、GPUを使用するための他のグラフおよび多様体学習アルゴリズムの変換に情報を提供する場合があります。私たちの実装は、オープンソースのRAPIDS cuMLライブラリ（このhttps URL）の一部として公開されています。,https://d3i71xaburhd42.cloudfront.net/5b17bfb51597d158100ba3f53148f37ac6aaf7c0/5-Figure1-1.png
Scalable Equilibrium Computation in Multi-Agent Influence Games on Networks,"['Fotini Christia', 'Michael J Curry', 'Constantinos Daskalakis', 'Erik Demaine', 'John P Dickerson', 'MohammadTaghi Hajiaghayi', 'Adam Hesterberg', 'Marina L Knittel', 'Aidan Milliff']",,,,
"Circles Are Like Ellipses, or Ellipses Are Like Circles? Measuring the Degree of Asymmetry of Static and Contextual Word Embeddings and the Implications to Representation Learning","['Wei Zhang', 'Murray Campbell', 'Yang Yu', 'Sadhana Kumaravel']",https://arxiv.org/abs/2012.01631,"Human judgments of word similarity have been a popular method of evaluating the quality of word embedding. But it fails to measure the geometry properties such as asymmetry. For example, it is more natural to say ""Ellipses are like Circles"" than ""Circles are like Ellipses"". Such asymmetry has been observed from a psychoanalysis test called word evocation experiment, where one word is used to recall another. Although useful, such experimental data have been significantly understudied for measuring embedding quality. In this paper, we use three well-known evocation datasets to gain insights into asymmetry encoding of embedding. We study both static embedding as well as contextual embedding, such as BERT. Evaluating asymmetry for BERT is generally hard due to the dynamic nature of embedding. Thus, we probe BERT's conditional probabilities (as a language model) using a large number of Wikipedia contexts to derive a theoretically justifiable Bayesian asymmetry score. The result shows that contextual embedding shows randomness than static embedding on similarity judgments while performing well on asymmetry judgment, which aligns with its strong performance on ""extrinsic evaluations"" such as text classification. The asymmetry judgment and the Bayesian approach provides a new perspective to evaluate contextual embedding on intrinsic evaluation, and its comparison to similarity evaluation concludes our work with a discussion on the current state and the future of representation learning.",単語の類似性を人間が判断することは、単語の埋め込みの品質を評価するための一般的な方法です。ただし、非対称性などのジオメトリプロパティの測定には失敗します。たとえば、「円は楕円のようです」よりも「楕円は円のようです」と言う方が自然です。このような非対称性は、ある単語が別の単語を思い出すために使用される単語誘発実験と呼ばれる精神分析テストから観察されています。有用ではありますが、そのような実験データは、埋め込み品質を測定するために大幅に研究されてきました。このホワイトペーパーでは、3つのよく知られた呼び出しデータセットを使用して、埋め込みの非対称エンコーディングに関する洞察を得ます。静的埋め込みとBERTなどのコンテキスト埋め込みの両方を研究しています。 BERTの非対称性の評価は、埋め込みの動的な性質のため、一般的に困難です。したがって、多数のWikipediaコンテキストを使用して、BERTの条件付き確率（言語モデルとして）を精査し、理論的に正当なベイズ非対称スコアを導き出します。結果は、コンテキスト埋め込みが類似性判断で静的埋め込みよりもランダム性を示し、非対称性判断で優れたパフォーマンスを発揮することを示しています。これは、テキスト分類などの「外部評価」での強力なパフォーマンスと一致しています。非対称性の判断とベイズアプローチは、本質的な評価への文脈埋め込みを評価するための新しい視点を提供し、類似性評価との比較は、表現学習の現状と将来についての議論で私たちの仕事を締めくくります。,https://d3i71xaburhd42.cloudfront.net/3e4c16b56dccb1685e8cb0c973242792ce8f8fe3/6-Figure1-1.png
Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse Reward Learning with Iterative Reasoning and Cumulative Prospect Theory,"['Ran Tian', 'Liting Sun', 'Masayoshi TOMIZUKA']",,,,
Benchmarking Knowledge-Enhanced Commonsense Question Answering via Knowledge-to-Text Transformation,"['Ning Bian', 'Xianpei Han', 'Bo Chen', 'Le Sun']",https://arxiv.org/abs/2101.00760,"A fundamental ability of humans is to utilize commonsense knowledge in language understanding and question answering. In recent years, many knowledge-enhanced Commonsense Question Answering (CQA) approaches have been proposed. However, it remains unclear: (1) How far can we get by exploiting external knowledge for CQA? (2) How much potential of knowledge has been exploited in current CQA models? (3) Which are the most promising directions for future CQA? To answer these questions, we benchmark knowledge-enhanced CQA by conducting extensive experiments on multiple standard CQA datasets using a simple and effective knowledgeto-text transformation framework. Experiments show that: (1) Our knowledge-to-text framework is effective and achieves state-of-the-art performance on CommonsenseQA dataset, providing a simple and strong knowledge-enhanced baseline for CQA; (2) The potential of knowledge is still far from being fully exploited in CQA — there is a significant performance gap from current models to our models with golden knowledge; and (3) Context-sensitive knowledge selection, heterogeneous knowledge exploitation, and commonsense-rich language models are promising CQA directions.",人間の基本的な能力は、言語理解と質問応答に常識的な知識を利用することです。近年、多くの知識が強化された常識的な質問応答（CQA）アプローチが提案されています。ただし、不明な点が残っています。（1）CQAの外部知識を活用することで、どこまで到達できるでしょうか。 （2）現在のCQAモデルでは、知識の可能性がどの程度活用されていますか？ （3）将来のCQAの最も有望な方向性はどれですか？これらの質問に答えるために、シンプルで効果的な知識からテキストへの変換フレームワークを使用して、複数の標準CQAデータセットで広範な実験を行うことにより、知識が強化されたCQAのベンチマークを行います。実験は次のことを示しています。（1）知識からテキストへのフレームワークは効果的であり、CommonsenseQAデータセットで最先端のパフォーマンスを実現し、CQAのシンプルで強力な知識強化ベースラインを提供します。 （2）知識の可能性がCQAで十分に活用されるにはまだほど遠いため、現在のモデルから黄金の知識を持つモデルまで、パフォーマンスに大きなギャップがあります。 （3）状況依存の知識の選択、異種の知識の活用、および常識に富んだ言語モデルは、CQAの有望な方向性です。,https://d3i71xaburhd42.cloudfront.net/cc1adf2d74d1392cdba5ffa2841bdf9c6bc52bac/1-Figure1-1.png
"Converse, Focus and Guess - Towards Multi-Document Driven Dialogue","['Han Liu', 'Caixia Yuan', 'Xiaojie Wang', 'Yushu Yang', 'Huixing Jiang', 'Zhongyuan Wang']",https://arxiv.org/abs/2102.02435,"We propose a novel task, Multi-Document Driven Dialogue (MD3), in which an agent can guess the target document that the user is interested in by leading a dialogue. To benchmark progress, we introduce a new dataset of GuessMovie, which contains 16,881 documents, each describing a movie, and associated 13,434 dialogues. Further, we propose the MD3 model. Keeping guessing the target document in mind, it converses with the user conditioned on both document engagement and user feedback. In order to incorporate large-scale external documents into the dialogue, it pretrains a document representation which is sensitive to attributes it talks about an object. Then it tracks dialogue state by detecting evolvement of document belief and attribute belief, and finally optimizes dialogue policy in principle of entropy decreasing and reward increasing, which is expected to successfully guess the user’s target in a minimum number of turns. Experiments show that our method significantly outperforms several strong baseline methods and is very close to human’s performance. 1","新しいタスクであるマルチドキュメントドリブンダイアログ（MD3）を提案します。このタスクでは、エージェントは、ダイアログをリードすることで、ユーザーが関心のあるターゲットドキュメントを推測できます。進捗状況をベンチマークするために、GuessMovieの新しいデータセットを紹介します。このデータセットには、それぞれが映画を説明する16,881のドキュメントと、関連する13,434のダイアログが含まれています。さらに、MD3モデルを提案します。ターゲットドキュメントを推測することを念頭に置いて、ドキュメントエンゲージメントとユーザーフィードバックの両方を条件とするユーザーと会話します。大規模な外部ドキュメントをダイアログに組み込むために、オブジェクトについて話す属性に敏感なドキュメント表現を事前にトレーニングします。次に、ドキュメントの信念と属性の信念の進化を検出することによって対話の状態を追跡し、最後にエントロピーの減少と報酬の増加の原則で対話ポリシーを最適化します。実験は、私たちの方法がいくつかの強力なベースライン方法を大幅に上回り、人間のパフォーマンスに非常に近いことを示しています。 1",https://d3i71xaburhd42.cloudfront.net/76cb4a8e7d5340213297945793367a543d6e55b5/2-Figure1-1.png
Bandit Linear Optimization for Sequential Decision Making and Extensive-Form Games,"['Gabriele Farina', 'Robin Schmucker', 'Tuomas Sandholm']",,,,
Interpretable Sequence Classification via Discrete Optimization,"['Maayan Shvo', 'Andrew C Li', 'Rodrigo A Toro Icarte', 'Sheila A. McIlraith']",https://arxiv.org/abs/2010.02819,"Sequence classification is the task of predicting a class label given a sequence of observations. In many applications such as healthcare monitoring or intrusion detection, early classification is crucial to prompt intervention. In this work, we learn sequence classifiers that favour early classification from an evolving observation trace. While many state-of-the-art sequence classifiers are neural networks, and in particular LSTMs, our classifiers take the form of finite state automata and are learned via discrete optimization. Our automata-based classifiers are interpretable---supporting explanation, counterfactual reasoning, and human-in-the-loop modification---and have strong empirical performance. Experiments over a suite of goal recognition and behaviour classification datasets show our learned automata-based classifiers to have comparable test performance to LSTM-based classifiers, with the added advantage of being interpretable.",シーケンス分類は、一連の観測値が与えられた場合にクラスラベルを予測するタスクです。ヘルスケアの監視や侵入検知などの多くのアプリケーションでは、介入を促すために早期の分類が不可欠です。この作業では、進化する観測トレースから早期分類を支持するシーケンス分類子を学習します。多くの最先端のシーケンス分類器はニューラルネットワーク、特にLSTMですが、私たちの分類器は有限状態オートマトンの形式を取り、離散最適化によって学習されます。私たちのオートマトンベースの分類器は、説明、反事実的推論、およびヒューマンインザループ修正をサポートする解釈可能であり、強力な経験的パフォーマンスを備えています。一連の目標認識および行動分類データセットでの実験は、学習したオートマトンベースの分類器がLSTMベースの分類器と同等のテストパフォーマンスを持ち、解釈可能であるという追加の利点があることを示しています。,https://d3i71xaburhd42.cloudfront.net/dbcb1a868328b1c2d60627b8e3ebf52932972d2b/2-Figure1-1.png
Defending against Backdoors in Federated Learning with Robust Learning Rate,"['Mustafa S Ozdayi', 'Murat Kantarcioglu', 'Yulia R. Gel']",https://arxiv.org/abs/2007.03767,"Federated Learning (FL) allows a set of agents to collaboratively train a model in a decentralized fashion without sharing their potentially sensitive data. This makes FL suitable for privacy-preserving applications. At the same time, FL is susceptible to adversarial attacks due to decentralized and unvetted data. One important line of attacks against FL is the backdoor attacks. In a backdoor attack, an adversary tries to embed a backdoor trigger functionality to the model during training which can later be activated to cause a desired misclassification. To prevent such backdoor attacks, we propose a lightweight defense that requires no change to the FL structure. At a high level, our defense is based on carefully adjusting the server's learning rate, per dimension, at each round based on the sign information of agent's updates. We first conjecture the necessary steps to carry a successful backdoor attack in FL setting, and then, explicitly formulate the defense based on our conjecture. Through experiments, we provide empirical evidence to the support of our conjecture. We test our defense against backdoor attacks under different settings, and, observe that either backdoor is completely eliminated, or its accuracy is significantly reduced. Overall, our experiments suggests that our approach significantly outperforms some of the recently proposed defenses in the literature. We achieve this by having minimal influence over the accuracy of the trained models.",Federated Learning（FL）を使用すると、一連のエージェントは、潜在的に機密性の高いデータを共有することなく、分散型の方法でモデルを共同でトレーニングできます。これにより、FLはプライバシー保護アプリケーションに適しています。同時に、FLは、データが分散化され、検証されていないため、敵対的攻撃を受けやすくなっています。 FLに対する重要な攻撃ラインの1つは、バックドア攻撃です。バックドア攻撃では、攻撃者はトレーニング中にバックドアトリガー機能をモデルに埋め込もうとしますが、これを後でアクティブにして、目的の誤分類を引き起こす可能性があります。このようなバックドア攻撃を防ぐために、FL構造を変更する必要のない軽量の防御策を提案します。大まかに言えば、私たちの防御は、エージェントの更新のサイン情報に基づいて、各ラウンドでディメンションごとにサーバーの学習率を注意深く調整することに基づいています。まず、FL設定でバックドア攻撃を成功させるために必要な手順を推測し、次にその推測に基づいて防御を明示的に策定します。実験を通して、私たちは私たちの推測を裏付ける経験的証拠を提供します。さまざまな設定でバックドア攻撃に対する防御をテストし、バックドアが完全に排除されているか、精度が大幅に低下していることを確認します。全体として、私たちの実験は、私たちのアプローチが、最近提案された文献の防御のいくつかを大幅に上回っていることを示唆しています。これは、トレーニング済みモデルの精度への影響を最小限に抑えることで実現します。,https://d3i71xaburhd42.cloudfront.net/23e3cad5f7cd3ac48e9734fc7c6c6d63b5464840/5-Figure1-1.png
BERT & Family Eat Word Salad: Experiments with Text Understanding,"['Ashim Gupta', 'Giorgi Kvernadze', 'Vivek Srikumar']",https://arxiv.org/abs/2101.03453,"In this paper, we study the response of large models from the BERT family to incoherent inputs that should confuse any model that claims to understand natural language. We define simple heuristics to construct such examples. Our experiments show that state-of-the-art models consistently fail to recognize them as ill-formed, and instead produce high confidence predictions on them. Finally, we show that if models are explicitly trained to recognize invalid inputs, they can be robust to such attacks without a drop in performance.",この論文では、自然言語を理解すると主張するモデルを混乱させるはずの一貫性のない入力に対するBERTファミリーの大規模モデルの応答を研究します。このような例を作成するために、単純なヒューリスティックを定義します。私たちの実験は、最先端のモデルが一貫してそれらを不正な形式として認識できず、代わりにそれらに対して高い信頼性の予測を生成することを示しています。最後に、モデルが無効な入力を認識するように明示的にトレーニングされている場合、パフォーマンスを低下させることなく、そのような攻撃に対して堅牢にできることを示します。,https://d3i71xaburhd42.cloudfront.net/7defc117a11c16fb70bea6cbc0b58e48244992c8/1-Figure1-1.png
LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short Text Matching,"['Boer Lyu', 'Lu Chen', 'Su Zhu', 'Kai Yu']",,,,
Model-Free Online Learning in Unknown Sequential Decision Making Problems and Games,['Gabriele Farina'],,,,
Visual Boundary Knowledge Translation for Foreground Segmentation,"['Zunlei Feng', 'Lechao Cheng', 'Xinchao Wang', 'Xiang Wang', 'Ya Jie Liu', 'Xiangtong Du', 'Mingli Song']",,,,
Distribution Matching for Rationalization,"['Yongfeng Huang', 'Yujun Chen', 'Yulun Du', 'Zhilin Yang']",,,,
Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-Shot Commonsense Question Answering,"['Antoine Bosselut', 'Ronan Le Bras', 'Yejin Choi']",https://arxiv.org/abs/1911.03876,"Understanding narratives requires reasoning about implicit world knowledge related to the causes, effects, and states of situations described in text. At the core of this challenge is how to access contextually relevant knowledge on demand and reason over it. In this paper, we present initial studies toward zero-shot commonsense question answering by formulating the task as inference over dynamically generated commonsense knowledge graphs. In contrast to previous studies for knowledge integration that rely on retrieval of existing knowledge from static knowledge graphs, our study requires commonsense knowledge integration where contextually relevant knowledge is often not present in existing knowledge bases. Therefore, we present a novel approach that generates contextually-relevant symbolic knowledge structures on demand using generative neural commonsense knowledge models. Empirical results on two datasets demonstrate the efficacy of our neuro-symbolic approach for dynamically constructing knowledge graphs for reasoning. Our approach achieves significant performance boosts over pretrained language models and vanilla knowledge models, all while providing interpretable reasoning paths for its predictions.",物語を理解するには、テキストで説明されている状況の原因、影響、および状態に関連する暗黙の世界知識について推論する必要があります。この課題の中核となるのは、状況に応じて関連する知識にオンデマンドでアクセスする方法と、それに対する理由です。この論文では、動的に生成された常識知識グラフに対する推論としてタスクを定式化することにより、ゼロショット常識質問応答に向けた初期研究を提示します。静的知識グラフからの既存の知識の検索に依存する知識統合に関する以前の研究とは対照的に、私たちの研究では、文脈に関連する知識が既存の知識ベースに存在しないことが多い常識的な知識統合が必要です。したがって、生成的な神経常識知識モデルを使用して、オンデマンドでコンテキストに関連するシンボリック知識構造を生成する新しいアプローチを提示します。 2つのデータセットでの経験的結果は、推論のための知識グラフを動的に構築するためのニューロシンボリックアプローチの有効性を示しています。私たちのアプローチは、事前にトレーニングされた言語モデルやバニラ知識モデルよりもパフォーマンスが大幅に向上すると同時に、予測のための解釈可能な推論パスを提供します。,
Stochastic Precision Ensemble: Self-Knowledge Distillation for Quantized Deep Neural Networks,"['Yoonho Boo', 'Sungho Shin', 'Jungwook Choi', 'Wonyong Sung']",https://arxiv.org/abs/2009.14502,"The quantization of deep neural networks (QDNNs) has been actively studied for deployment in edge devices. Recent studies employ the knowledge distillation (KD) method to improve the performance of quantized networks. In this study, we propose stochastic precision ensemble training for QDNNs (SPEQ). SPEQ is a knowledge distillation training scheme; however, the teacher is formed by sharing the model parameters of the student network. We obtain the soft labels of the teacher by changing the bit precision of the activation stochastically at each layer of the forward-pass computation. The student model is trained with these soft labels to reduce the activation quantization noise. The cosine similarity loss is employed, instead of the KL-divergence, for KD training. As the teacher model changes continuously by random bit-precision assignment, it exploits the effect of stochastic ensemble KD. SPEQ outperforms the existing quantization training methods in various tasks, such as image classification, question-answering, and transfer learning without the need for cumbersome teacher networks.",ディープニューラルネットワーク（QDNN）の量子化は、エッジデバイスでの展開のために活発に研究されてきました。最近の研究では、量子化ネットワークのパフォーマンスを向上させるために知識蒸留（KD）法が採用されています。この研究では、QDNN（SPEQ）の確率的精密アンサンブルトレーニングを提案します。 SPEQは知識蒸留トレーニングスキームです。ただし、教師は学生ネットワークのモデルパラメータを共有することによって形成されます。フォワードパス計算の各レイヤーでアクティベーションのビット精度を確率的に変更することにより、教師のソフトラベルを取得します。学生モデルは、アクティベーション量子化ノイズを低減するために、これらのソフトラベルでトレーニングされています。 KDトレーニングでは、KLダイバージェンスの代わりにコサイン類似度損失が使用されます。教師モデルはランダムなビット精度の割り当てによって継続的に変化するため、確率的アンサンブルKDの効果を利用します。 SPEQは、面倒な教師ネットワークを必要とせずに、画像分類、質問応答、転移学習などのさまざまなタスクで既存の量子化トレーニング方法よりも優れています。,https://d3i71xaburhd42.cloudfront.net/261aa442c219e6a388642d51834740bdb863a30a/3-Figure1-1.png
Reinforced Multi-Teacher Selection for Knowledge Distillation,"['Fei Yuan', 'Linjun Shou', 'Jian Pei', 'Wutao Lin', 'Ming Gong', 'Yan Fu', 'Daxin Jiang']",https://arxiv.org/abs/2012.06048,"In natural language processing (NLP) tasks, slow inference speed and huge footprints in GPU usage remain the bottleneck of applying pre-trained deep models in production. As a popular method for model compression, knowledge distillation transfers knowledge from one or multiple large (teacher) models to a small (student) model. When multiple teacher models are available in distillation, the state-of-the-art methods assign a fixed weight to a teacher model in the whole distillation. Furthermore, most of the existing methods allocate an equal weight to every teacher model. In this paper, we observe that, due to the complexity of training examples and the differences in student model capability, learning differentially from teacher models can lead to better performance of student models distilled. We systematically develop a reinforced method to dynamically assign weights to teacher models for different training instances and optimize the performance of student model. Our extensive experimental results on several NLP tasks clearly verify the feasibility and effectiveness of our approach.",自然言語処理（NLP）タスクでは、推論速度が遅く、GPU使用量が非常に多いため、事前にトレーニングされたディープモデルを本番環境に適用する際のボトルネックが残っています。モデル圧縮の一般的な方法として、知識蒸留は1つまたは複数の大きな（教師）モデルから小さな（学生）モデルに知識を転送します。蒸留で複数の教師モデルが利用できる場合、最先端の方法では、蒸留全体で教師モデルに固定の重みが割り当てられます。さらに、既存の方法のほとんどは、すべての教師モデルに等しい重みを割り当てます。この論文では、トレーニング例の複雑さと生徒モデルの能力の違いにより、教師モデルとは異なる方法で学習することで、蒸留された生徒モデルのパフォーマンスが向上する可能性があることを確認します。さまざまなトレーニングインスタンスの教師モデルに動的に重みを割り当て、学生モデルのパフォーマンスを最適化するための強化された方法を体系的に開発します。いくつかのNLPタスクに関する広範な実験結果は、私たちのアプローチの実現可能性と有効性を明確に検証しています。,https://d3i71xaburhd42.cloudfront.net/63c966e28b471551f2d9c7a5b4c639de6c8953b0/3-Figure1-1.png
Efficient Poverty Mapping from High Resolution Remote Sensing Images,"['Kumar Ayush', 'Burak Uzkent', 'Kumar Tanmay', 'Marshall Burke', 'David Lobell', 'Stefano Ermon']",,,,
Sketch and Customize: A Counterfactual Story Generator,"['Changying Hao', 'Liang Pang', 'Yanyan Lan', 'Yan Wang', 'Jiafeng Guo', 'Xueqi Cheng']",,,,
Deep Contextual Clinical Prediction with Reverse Distillation,"['Rohan S Kodialam', 'Rebecca Boiarsky', 'Justin K Lim', 'Aditya Sai', 'Neil Dixit', 'David Sontag']",https://arxiv.org/abs/2007.05611,"Healthcare providers are increasingly using learned methods to predict and understand long-term patient outcomes in order to make meaningful interventions. However, despite innovations in this area, deep learning models often struggle to match performance of shallow linear models in predicting these outcomes, making it difficult to leverage such techniques in practice. In this work, motivated by the task of clinical prediction from insurance claims, we present a new technique called reverse distillation which pretrains deep models by using high-performing linear models for initialization. We make use of the longitudinal structure of insurance claims datasets to develop Self Attention with Reverse Distillation, or SARD, an architecture that utilizes a combination of contextual embedding, temporal embedding and self-attention mechanisms and most critically is trained via reverse distillation. SARD outperforms state-of-the-art methods on multiple clinical prediction outcomes, with ablation studies revealing that reverse distillation is a primary driver of these improvements.",医療提供者は、有意義な介入を行うために、学習した方法を使用して長期的な患者の転帰を予測および理解することがますます増えています。ただし、この分野での革新にもかかわらず、深層学習モデルは、これらの結果を予測する際に浅い線形モデルのパフォーマンスと一致させるのに苦労することが多く、実際にそのような手法を活用することは困難です。この作業では、保険金請求からの臨床予測のタスクに動機付けられて、初期化に高性能線形モデルを使用して深層モデルを事前トレーニングする逆蒸留と呼ばれる新しい手法を紹介します。保険金請求データセットの縦方向の構造を利用して、逆蒸留による自己注意（SARD）を開発します。これは、コンテキスト埋め込み、時間埋め込み、および自己注意メカニズムの組み合わせを利用するアーキテクチャであり、最も重要なのは逆蒸留によってトレーニングされます。 SARDは、複数の臨床予測結果に関して最先端の方法よりも優れており、アブレーション研究により、逆蒸留がこれらの改善の主な推進力であることが明らかになっています。,https://d3i71xaburhd42.cloudfront.net/885015a0faa0903f170b9b588a5d1b14660dc20f/3-Figure1-1.png
Exploiting Behavioral Consistence for Universal User Representation,"['Jie Gu', 'Feng Wang', 'Qinghui Sun', 'Zhiquan Ye', 'Xiaoxiao Xu', 'Jingmin Chen', 'Jun Zhang']",https://arxiv.org/abs/2012.06146,"User modeling is critical for developing personalized services in industry. A common way for user modeling is to learn user representations that can be distinguished by their interests or preferences. In this work, we focus on developing universal user representation model. The obtained universal representations are expected to contain rich information, and be applicable to various downstream applications without further modifications (e.g., user preference prediction and user profiling). Accordingly, we can be free from the heavy work of training task-specific models for every downstream task as in previous works. In specific, we propose Self-supervised User Modeling Network (SUMN) to encode behavior data into the universal representation. It includes two key components. The first one is a new learning objective, which guides the model to fully identify and preserve valuable user information under a self-supervised learning framework. The other one is a multi-hop aggregation layer, which benefits the model capacity in aggregating diverse behaviors. Extensive experiments on benchmark datasets show that our approach can outperform state-of-the-art unsupervised representation methods, and even compete with supervised ones.",ユーザーモデリングは、業界でパーソナライズされたサービスを開発するために重要です。ユーザーモデリングの一般的な方法は、興味や好みによって区別できるユーザー表現を学習することです。この作業では、ユニバーサルユーザー表現モデルの開発に焦点を当てます。得られたユニバーサル表現は、豊富な情報を含み、さらに変更することなくさまざまなダウンストリームアプリケーションに適用できることが期待されます（たとえば、ユーザーの好みの予測やユーザーのプロファイリング）。したがって、以前の作業のように、すべてのダウンストリームタスクに対してタスク固有のモデルをトレーニングするという重い作業から解放されます。具体的には、行動データを普遍的な表現にエンコードするための自己監視ユーザーモデリングネットワーク（SUMN）を提案します。これには2つの主要なコンポーネントが含まれています。 1つ目は、新しい学習目標です。これは、自己監視学習フレームワークの下で貴重なユーザー情報を完全に識別して保存するようにモデルをガイドします。もう1つはマルチホップ集約レイヤーであり、多様な動作を集約する際のモデル容量にメリットがあります。ベンチマークデータセットでの広範な実験は、私たちのアプローチが最先端の教師なし表現方法よりも優れており、監視されたものとさえ競合できることを示しています。,https://d3i71xaburhd42.cloudfront.net/cff8fc77bd7d860a1f9c910ef85e471b00c8b2fb/3-Figure1-1.png
Generating CCG Categories,"['Yufang Liu', 'Tao Ji', 'Yuanbin Wu', 'Man Lan']",,,,
Hierarchical Relational Inference,"['Aleksandar Stanic', 'Sjoerd van Steenkiste', 'Jürgen Schmidhuber']",https://arxiv.org/abs/2010.03635,"Common-sense physical reasoning in the real world requires learning about the interactions of objects and their dynamics. The notion of an abstract object, however, encompasses a wide variety of physical objects that differ greatly in terms of the complex behaviors they support. To address this, we propose a novel approach to physical reasoning that models objects as hierarchies of parts that may locally behave separately, but also act more globally as a single whole. Unlike prior approaches, our method learns in an unsupervised fashion directly from raw visual images to discover objects, parts, and their relations. It explicitly distinguishes multiple levels of abstraction and improves over a strong baseline at modeling synthetic and real-world videos.",現実の世界での常識的な物理的推論には、オブジェクトの相互作用とそのダイナミクスについて学ぶ必要があります。ただし、抽象オブジェクトの概念には、サポートする複雑な動作の点で大きく異なるさまざまな物理オブジェクトが含まれます。これに対処するために、ローカルで個別に動作するだけでなく、単一の全体としてよりグローバルに動作するパーツの階層としてオブジェクトをモデル化する、物理的推論への新しいアプローチを提案します。以前のアプローチとは異なり、私たちの方法は、教師なしの方法で生の視覚画像から直接学習し、オブジェクト、パーツ、およびそれらの関係を発見します。抽象化の複数のレベルを明確に区別し、合成ビデオと実世界のビデオのモデリングにおける強力なベースラインを上回ります。,https://d3i71xaburhd42.cloudfront.net/95bf60a6e8cf2f71ce8a44a0dacb390afcf14c34/1-Figure1-1.png
Agent Incentives: A Causal Perspective,"['Tom Everitt', 'Ryan Carey', 'Eric D Langlois', 'Pedro Ortega', 'Shane Legg']",https://arxiv.org/abs/2102.01685,"We present a framework for analysing agent incentives using causal influence diagrams. We establish that a well-known criterion for value of information is complete. We propose a new graphical criterion for value of control, establishing its soundness and completeness. We also introduce two new concepts for incentive analysis: response incentives indicate which changes in the environment affect an optimal decision, while instrumental control incentives establish whether an agent can influence its utility via a variable X. For both new concepts, we provide sound and complete graphical criteria. We show by example how these results can help with evaluating the safety and fairness of an AI system.",因果関係図を使用してエージェントのインセンティブを分析するためのフレームワークを提示します。情報の価値に関するよく知られた基準が完全であることを確立します。制御の価値に関する新しいグラフィカルな基準を提案し、その健全性と完全性を確立します。また、インセンティブ分析の2つの新しい概念を紹介します。応答インセンティブは環境のどの変化が最適な決定に影響を与えるかを示し、機器制御インセンティブはエージェントが変数Xを介してその効用に影響を与えることができるかどうかを確立します。両方の新しい概念について、健全で完全なものを提供しますグラフィカルな基準。これらの結果がAIシステムの安全性と公平性の評価にどのように役立つかを例で示します。,https://d3i71xaburhd42.cloudfront.net/67a5303464a764453a2435bec453bed1c5ac9c43/2-Figure1-1.png
Near-Optimal Regret Bounds for Contextual Combinatorial Semi-Bandits with Linear Payoff Functions,"['Kei Takemura', 'Shinji Ito', 'Daisuke Hatano', 'Hanna Sumita', 'Takuro Fukunaga', 'Naonori Kakimura', 'Ken-ichi Kawarabayashi']",https://arxiv.org/abs/2101.07957,"Kei Takemura,1 Shinji Ito,1 Daisuke Hatano,2 Hanna Sumita,3 Takuro Fukunaga,4,2,5 Naonori Kakimura,6 Ken-ichi Kawarabayashi 7 1 NEC Corporation 2 RIKEN AIP 3 Tokyo Institute of Technology 4 Chuo University 5 JST PRESTO 6 Keio University 7 National Institute of Informatics {kei takemura, i-shinji}@nec.com, daisuke.hatano@riken.jp, sumita@c.titech.ac.jp, fukunaga.07s@chuo-u.ac.jp, kakimura@math.keio.ac.jp, k-keniti@nii.ac.jp","Kei Takemura,1 Shinji Ito,1 Daisuke Hatano,2 Hanna Sumita,3 Takuro Fukunaga,4,2,5 Naonori Kakimura,6 Ken-ichi Kawarabayashi 7 1 NEC Corporation 2 RIKEN AIP 3 Tokyo Institute of Technology 4 Chuo University 5 JST PRESTO 6 Keio University 7 National Institute of Informatics kei takemura, i-shinji@nec.com, daisuke.hatano@riken.jp, sumita@c.titech.ac.jp, fukunaga.07s@chuo-u.ac.jp, kakimura@math.keio.ac.jp, k-keniti@nii.ac.jp",https://d3i71xaburhd42.cloudfront.net/2b7f6ace2f62bbe4ce5452e6c56db4f13379d38d/7-Figure1-1.png
Tune-In: Training under Negative Environments with Interference for Attention Networks Simulating Cocktail Party Effect,"['Jun Wang', 'Max W. Y. Lam', 'Dan Su', 'Dong Yu']",,,,
OpEvo: An Evolutionary Method for Tensor Operator Optimization,"['Xiaotian Gao', 'Wei Cui', 'lintao Zhang', 'Mao Yang']",https://arxiv.org/abs/2006.05664,"Training and inference efficiency of deep neural networks highly rely on the performance of tensor operators on hardware platforms. Manually optimized tensor operators have limitations in terms of supporting new operators or supporting new hardware platforms. Therefore, automatically optimizing device code configurations of tensor operators is getting increasingly attractive. However, current methods for tensor operator optimization usually suffer from poor sample-efficiency due to the combinatorial search space. In this work, we propose a novel evolutionary method, OpEvo, which efficiently explores the search spaces of tensor operators by introducing a topology-aware mutation operation based on q-random walk distribution to leverage the topological structures over the search spaces. Our comprehensive experiment results show that OpEvo can find the best configuration with the least number of trials and the lowest variance compared with state-of-the-art methods. All code of this work is available online.",ディープニューラルネットワークのトレーニングと推論の効率は、ハードウェアプラットフォームでのテンソル演算子のパフォーマンスに大きく依存しています。手動で最適化されたテンソル演算子には、新しい演算子のサポートまたは新しいハードウェアプラットフォームのサポートに関して制限があります。したがって、テンソル演算子のデバイスコード構成を自動的に最適化することはますます魅力的になっています。ただし、テンソル演算子の最適化の現在の方法は、通常、組み合わせ検索スペースのためにサンプル効率が低いという問題があります。この作業では、q-ランダムウォーク分布に基づくトポロジー認識突然変異操作を導入して、探索空間全体のトポロジー構造を活用することにより、テンソル演算子の探索空間を効率的に探索する新しい進化的手法OpEvoを提案します。私たちの包括的な実験結果は、OpEvoが、最先端の方法と比較して、最小の試行回数と最小の分散で最適な構成を見つけることができることを示しています。この作品のすべてのコードはオンラインで入手できます。,https://d3i71xaburhd42.cloudfront.net/6080199a7e1e4560b86ea9a7aed415f5c2c624ce/5-Figure1-1.png
Faster Depth-Adaptive Transformers,"['Yijin Liu', 'Fandong Meng', 'Jie Zhou', 'Yufeng Chen', 'Jinan Xu']",https://arxiv.org/abs/2004.13542,"Depth-adaptive neural networks can dynamically adjust depths according to the hardness of input words, and thus improve efficiency. The main challenge is how to measure such hardness and decide the required depths (i.e., layers) to conduct. Previous works generally build a halting unit to decide whether the computation should continue or stop at each layer. As there is no specific supervision of depth selection, the halting unit may be under-optimized and inaccurate, which results in suboptimal and unstable performance when modeling sentences. In this paper, we get rid of the halting unit and estimate the required depths in advance, which yields a faster depth-adaptive model. Specifically, two approaches are proposed to explicitly measure the hardness of input words and estimate corresponding adaptive depth, namely 1) mutual information (MI) based estimation and 2) reconstruction loss based estimation. We conduct experiments on the text classification task with 24 datasets in various sizes and domains. Results confirm that our approaches can speed up the vanilla Transformer (up to 7x) while preserving high accuracy. Moreover, efficiency and robustness are significantly improved when compared with other depth-adaptive approaches.",深度適応型ニューラルネットワークは、入力された単語の硬さに応じて深度を動的に調整できるため、効率が向上します。主な課題は、そのような硬度をどのように測定し、実施するために必要な深さ（つまり、層）を決定するかです。以前の作業では、通常、停止ユニットを構築して、計算を続行するか、各レイヤーで停止するかを決定します。深度選択の特定の監視がないため、停止ユニットが最適化されておらず、不正確である可能性があり、その結果、文をモデル化するときに最適ではなく不安定なパフォーマンスが発生します。この論文では、停止ユニットを取り除き、必要な深度を事前に推定します。これにより、より高速な深度適応モデルが得られます。具体的には、入力単語の硬さを明示的に測定し、対応する適応深度を推定するために、1）相互情報量（MI）ベースの推定と2）再構成損失ベースの推定の2つのアプローチが提案されています。さまざまなサイズとドメインの24のデータセットを使用して、テキスト分類タスクの実験を行います。結果は、私たちのアプローチが高精度を維持しながらバニラトランスフォーマー（最大7倍）を高速化できることを確認しています。さらに、他の深度適応アプローチと比較すると、効率と堅牢性が大幅に向上しています。,
DocParser: Hierarchical Document Structure Parsing from Renderings,"['Johannes Rausch', 'Jesus Octavio Martinez Bermudez', 'Fabian Bissig', 'Ce Zhang', 'Stefan Feuerriegel']",,,,
Adversarial Turing Patterns from Cellular Automata,"['Nurislam Tursynbek', 'Ilya Vilkoviskiy', 'Maria Sindeeva', 'Ivan Oseledets']",https://arxiv.org/abs/2011.09393,"State-of-the-art deep classifiers are intriguingly vulnerable to universal adversarial perturbations: single disturbances of small magnitude that lead to misclassification of most inputs. This phenomena may potentially result in a serious security problem. Despite the extensive research in this area, there is a lack of theoretical understanding of the structure of these perturbations. In image domain, there is a certain visual similarity between patterns, that represent these perturbations, and classical Turing patterns, which appear as a solution of non-linear partial differential equations and are underlying concept of many processes in nature. In this paper, we provide a theoretical bridge between these two different theories, by mapping a simplified algorithm for crafting universal perturbations to (inhomogeneous) cellular automata, the latter is known to generate Turing patterns. Furthermore, we propose to use Turing patterns, generated by cellular automata, as universal perturbations, and experimentally show that they significantly degrade the performance of deep learning models. We found this method to be a fast and efficient way to create a data-agnostic quasi-imperceptible perturbation in the black-box scenario.",最先端の深い分類器は、普遍的な敵対的摂動に対して興味をそそるほど脆弱です。ほとんどの入力の誤分類につながる小さな大きさの単一の外乱です。この現象は、深刻なセキュリティ問題を引き起こす可能性があります。この分野での広範な研究にもかかわらず、これらの摂動の構造の理論的理解が不足しています。画像領域では、これらの摂動を表すパターンと、非線形偏微分方程式の解として現れ、自然界の多くのプロセスの基礎となる概念である古典的なチューリングパターンとの間に特定の視覚的類似性があります。この論文では、普遍的な摂動を作成するための単純化されたアルゴリズムを（不均一な）セルオートマトンにマッピングすることにより、これら2つの異なる理論間の理論的な架け橋を提供します。後者はチューリングパターンを生成することが知られています。さらに、セルオートマトンによって生成されたチューリングパターンを普遍的な摂動として使用することを提案し、それらが深層学習モデルのパフォーマンスを大幅に低下させることを実験的に示します。この方法は、ブラックボックスシナリオでデータに依存しない準知覚不可能な摂動を作成するための高速で効率的な方法であることがわかりました。,
Expected Eligibility Traces,"['Hado van Hasselt', 'Sephora Madjiheurem', 'Matteo Hessel', 'Andre Barreto', 'David Silver', 'Diana Borsa']",,,,
Bidirectional Machine Reading Comprehension for Aspect Sentiment Triplet Extraction,"['Shaowei Chen', 'Yu Wang', 'Jie Liu', 'Yuelin Wang']",,,,
"""Listen, Understand and Translate"": Triple Supervision Decouples End-to-End Speech-to-Text Translation","['Qianqian Q Dong', 'Rong Ye', 'Mingxuan Wang', 'Hao Zhou', 'Shuang Xu', 'Bo Xu', 'Lei Li']",https://arxiv.org/abs/2009.09704,"An end-to-end speech-to-text translation (ST) takes audio in a source language and outputs the text in a target language. Inspired by neuroscience, humans have perception systems and cognitive systems to process different information, we propose LUT, Listen-Understand-Translate, a unified framework with triple supervision to decouple the end-to-end speech-to-text translation task. In addition to the target language sentence translation loss, LUT includes two auxiliary supervising signals to guide the acoustic encoder to extracts acoustic features from the input, and the semantic encoder to extract semantic features relevant to the source transcription text. We do experiments on English-French, English-German and English-Chinese speech translation benchmarks and the results demonstrate the reasonability of LUT. Our code is available at https://github.com/dqqcasia/st.",エンドツーエンドの音声からテキストへの翻訳（ST）は、音声をソース言語で受け取り、テキストをターゲット言語で出力します。神経科学に触発されて、人間はさまざまな情報を処理するための知覚システムと認知システムを持っています。私たちは、エンドツーエンドの音声からテキストへの翻訳タスクを分離するためのトリプル監視を備えた統合フレームワークであるLUT、Listen-Understand-Translateを提案します。ターゲット言語の文の翻訳損失に加えて、LUTには、入力から音響特徴を抽出するための音響エンコーダーと、ソース転写テキストに関連する意味特徴を抽出するためのセマンティックエンコーダーをガイドする2つの補助監視信号が含まれています。英語-フランス語、英語-ドイツ語、英語-中国語の音声翻訳ベンチマークで実験を行い、その結果はLUTの合理性を示しています。私たちのコードはhttps://github.com/dqqcasia/stで入手できます。,
DirectQE: Direct Pretraining for Machine Translation Quality Estimation,"['Qu Cui', 'Shujian Huang', 'Jiahuan Li', 'Xiang Geng', 'Zaixiang Zheng', 'Guoping Huang', 'Jiajun Chen']",,,,
Deep Bayesian Quadrature Policy Optimization,"['Ravi Tej Akella', 'Kamyar Azizzadenesheli', 'Mohammad Ghavamzadeh', 'Animashree Anandkumar', 'Yisong Yue Special Track on AI for Social Impact']",,,,
Abusive Language Detection in Heterogeneous Contexts: Dataset Collection and the Role of Supervised Attention,"['Hongyu Gong', 'Alberto Valido', 'Katherine M Ingram', 'Giulia Fanti', 'Suma Bhat', 'Dorothy L Espelage']",,,,
Learning Augmented Methods for Matching: Improving Invasive Species Management and Urban Mobility,"['Johan Björck', 'Qinru Shi', 'Carrie Brown-Lima', 'Jennifer Dean', 'Angela Fuller', 'Carla P Gomes']",,,,
Project RISE: Recognizing Industrial Smoke Emissions,"['Yen-Chia Hsu', 'Ting-Hao K Huang', 'Ting-Yao Hu', 'Paul Dille', 'Sean Prendi', 'Ryan Hoffman', 'Anastasia Tsuhlares', 'Jessica Pachuta', 'Randy Sargent', 'Illah Nourbakhsh']",https://arxiv.org/abs/2005.06111,"Industrial smoke emissions pose a significant concern to human health. Prior works have shown that using Computer Vision (CV) techniques to identify smoke as visual evidence can influence the attitude of regulators and empower citizens in pursuing environmental justice. However, existing datasets do not have sufficient quality nor quantity for training robust CV models to support air quality advocacy. We introduce RISE, the first large-scale video dataset for Recognizing Industrial Smoke Emissions. We adopt the citizen science approach to collaborate with local community members in annotating whether a video clip has smoke emissions. Our dataset contains 12,567 clips with 19 distinct views from cameras on three sites that monitored three different industrial facilities. The clips are from 30 days that spans four seasons in two years in the daytime. We run experiments using deep neural networks developed for video action recognition to establish a performance baseline and reveal the challenges for smoke recognition. Our data analysis also shows opportunities for integrating citizen scientists and crowd workers into the application of Artificial Intelligence for social good.","産業用煙の排出は、人間の健康に重大な懸念をもたらします。以前の研究では、コンピュータービジョン（CV）技術を使用して煙を視覚的な証拠として特定することで、規制当局の態度に影響を与え、市民が環境正義を追求できるようになることが示されています。ただし、既存のデータセットには、大気質の擁護をサポートするための堅牢なCVモデルをトレーニングするための十分な質も量もありません。産業用煙の排出を認識するための最初の大規模ビデオデータセットであるRISEを紹介します。市民科学のアプローチを採用して、ビデオクリップに煙が放出されているかどうかに注釈を付ける際に地域コミュニティのメンバーと協力しています。私たちのデータセットには、3つの異なる産業施設を監視した3つのサイトのカメラからの19の異なるビューを含む12,567のクリップが含まれています。クリップは、昼間の2年間で4シーズンにわたる30日からのものです。ビデオアクション認識用に開発されたディープニューラルネットワークを使用して実験を実行し、パフォーマンスベースラインを確立し、煙認識の課題を明らかにします。私たちのデータ分析は、市民科学者と群衆労働者を社会的利益のための人工知能のアプリケーションに統合する機会も示しています。",https://d3i71xaburhd42.cloudfront.net/3766010a35b55113cac6e79eabae7fb6e7913455/1-Figure1-1.png
Fair and Interpretable Algorithmic Hiring Using Evolutionary Many Objective Optimization,"['Michael Geden', 'Joshua Andrews']",,,,
Accelerating Ecological Sciences from Above: Spatial Contrastive Learning for Remote Sensing,"['Johan Björck', 'Brendan Rapazzo', 'Qinru Shi', 'Carrie Brown-Lima', 'Jennifer Dean', 'Angela Fuller', 'Carla P Gomes']",,,,
We Don't Speak the Same Language: Interpreting Polarization through Machine Translation,"['Ashiqur KhudaBukhsh', 'Rupak Sarkar', 'Mark Kamlet', 'Tom Mitchell']",https://arxiv.org/abs/2010.02339,"Polarization among US political parties, media and elites is a widely studied topic. Prominent lines of prior research across multiple disciplines have observed and analyzed growing polarization in social media. In this paper, we present a new methodology that offers a fresh perspective on interpreting polarization through the lens of machine translation. With a novel proposition that two sub-communities are speaking in two different \emph{languages}, we demonstrate that modern machine translation methods can provide a simple yet powerful and interpretable framework to understand the differences between two (or more) large-scale social media discussion data sets at the granularity of words. Via a substantial corpus of 86.6 million comments by 6.5 million users on over 200,000 news videos hosted by YouTube channels of four prominent US news networks, we demonstrate that simple word-level and phrase-level translation pairs can reveal deep insights into the current political divide -- what is \emph{black lives matter} to one can be \emph{all lives matter} to the other.","米国の政党、メディア、エリートの間の二極化は、広く研究されているトピックです。複数の分野にわたる先行研究の著名なラインは、ソーシャルメディアにおける二極化の進展を観察および分析してきました。この論文では、機械翻訳のレンズを通して偏光を解釈する上で新鮮な視点を提供する新しい方法論を提示します。 2つのサブコミュニティが2つの異なる言語で話しているという斬新な提案により、最新の機械翻訳手法が、2つ（またはそれ以上）の大規模なソーシャルメディアディスカッションデータセットの違いを理解するための、シンプルでありながら強力で解釈可能なフレームワークを提供できることを示します。言葉の粒度で。米国の4つの著名なニュースネットワークのYouTubeチャンネルがホストする200,000を超えるニュースビデオに対する650万人のユーザーによる8,660万のコメントの実質的なコーパスを介して、単純な単語レベルとフレーズレベルの翻訳ペアが現在の政治的分裂に対する深い洞察を明らかにできることを示します黒人の生命が一方にとって重要であるのは、すべての生命が他方にとって重要である可能性があります。",https://d3i71xaburhd42.cloudfront.net/8457838206e58192d0f8edebd7512233ead13087/2-Figure1-1.png
Early Safety Warnings for Long-Distance Pipelines: A Distributed Optical Fiber Sensor Machine Learning Approach,"['Yiyuan Yang', 'Yi Li', 'Taojia Zhang', 'Yan Zhou', 'Haifeng Zhang']",,,,
Forecasting Reservoir Inflow via Recurrent Neural ODEs,"['Fan Zhou', 'Liang Li']",,,,
Retrieve and Revise: Improving Peptide Identification with Similar Mass Spectra,['Zhengcong Fei'],,,,
Land Deformation Prediction via Slope-Aware Graph Neural Networks,"['Fan Zhou', 'Rongfan Li', 'Goce Trajcevski', 'Kunpeng Zhang']",,,,
Combining Machine Learning & Reasoning for Biodiversity Data Intelligence,"['Atriya Sen', 'Beckett Sterner', 'Nico Franz', 'Caleb Powel', 'Nathan Upham']",,,,
Harnessing Social Media to Identify Homeless Youth At-Risk of Substance Use,"['Zi-Yi Dou', 'Anamika Barman-Adhikari', 'Fei Fang', 'Amulya Yadav']",,,,
Intelligent Recommendations for Citizen Science,"['Kobi Gal', 'Guy Shani', 'Avi Segal', 'Darlene Cavalier', 'Daniel Ben Zaken']",,,,
Graph Learning for Inverse Landscape Genetics,"['Prathamesh Dharangutte', 'Christopher Musco']",https://arxiv.org/abs/2006.12334,"The problem of inferring unknown graph edges from numerical data at a graph's nodes appears in many forms across machine learning. We study a version of this problem that arises in the field of landscape genetics, where genetic similarity between populations of organisms living in a heterogeneous landscape is explained by a weighted graph that encodes the ease of dispersal through that landscape. Our main contribution is an efficient algorithm for inverse landscape genetics, which is the task of inferring this graph from measurements of genetic similarity at different locations (graph nodes). We reduced the problem to that of inferring graph edges from noisy measurements of effective resistances between graph nodes, which have been observed to correlate well with genetic similarity. Building on Hoskins et. al., we develop an efficient first-order optimization method for solving this problem. Despite its non-convex nature, extensive experiments on synthetic and real genetic data establish that our method provides fast and reliable convergence, significantly outperforming existing heuristics used in the field.",グラフノードの数値データから未知のグラフエッジを推測する問題は、機械学習全体でさまざまな形で現れます。ランドスケープ遺伝学の分野で発生するこの問題のバージョンを研究します。ここでは、不均一なランドスケープに住む生物の集団間の遺伝的類似性が、そのランドスケープ全体の分散のしやすさをエンコードする加重グラフによって説明されます。私たちの主な貢献は、逆ランドスケープ遺伝学の効率的なアルゴリズムです。これは、さまざまな場所（グラフノード）での遺伝的類似性の測定値からこのグラフを推測するタスクです。問題を、遺伝的類似性とよく相関することが観察されているグラフノード間の有効抵抗のノイズの多い測定からグラフエッジを推測する問題に減らしました。 Hoskinsらに基づいて構築また、この問題を解決するための効率的な一次最適化手法を開発しています。その非凸性にもかかわらず、合成および実際の遺伝子データに関する広範な実験により、私たちの方法が高速で信頼性の高い収束を提供し、フィールドで使用されている既存のヒューリスティックを大幅に上回っていることを確認します。,https://d3i71xaburhd42.cloudfront.net/238fc74548666e241d427a703dd1c150f0c178b9/2-Figure1-1.png
Predicting Forest Fire Using Remote Sensing Data and Machine Learning,"['Suwei Yang', 'Massimo Lupascu', 'Kuldeep S Meel']",,,,
Dual-Mandate Patrols: Multi-Armed Bandits for Green Security,"['Lily Xu', 'Elizabeth Bondi', 'Fei Fang', 'Andrew Perrault', 'Kai Wang', 'Milind Tambe']",https://arxiv.org/abs/2009.06560,"Conservation efforts in green security domains to protect wildlife and forests are constrained by the limited availability of defenders (i.e., patrollers), who must patrol vast areas to protect from attackers (e.g., poachers or illegal loggers). Defenders must choose how much time to spend in each region of the protected area, balancing exploration of infrequently visited regions and exploitation of known hotspots. We formulate the problem as a stochastic multi-armed bandit, where each action represents a patrol strategy, enabling us to guarantee the rate of convergence of the patrolling policy. However, a naive bandit approach would compromise short-term performance for long-term optimality, resulting in animals poached and forests destroyed. To speed up performance, we leverage smoothness in the reward function and decomposability of actions. We show a synergy between Lipschitz-continuity and decomposition as each aids the convergence of the other. In doing so, we bridge the gap between combinatorial and Lipschitz bandits, presenting a no-regret approach that tightens existing guarantees while optimizing for short-term performance. We demonstrate that our algorithm, LIZARD, improves performance on real-world poaching data from Cambodia.",野生生物や森林を保護するためのグリーンセキュリティドメインでの保護活動は、攻撃者（密猟者や違法伐採者など）から保護するために広大な地域をパトロールしなければならない防御者（つまり、パトローラー）の限られた可用性によって制約されます。防御側は、保護地域の各地域で過ごす時間を選択し、訪問頻度の低い地域の探索と既知のホットスポットの活用のバランスをとる必要があります。問題を確率的多腕バンディットとして定式化します。各アクションはパトロール戦略を表し、パトロールポリシーの収束率を保証できます。しかし、ナイーブな盗賊のアプローチは、長期的な最適性のために短期的なパフォーマンスを損ない、動物が密猟され、森林が破壊される結果になります。パフォーマンスを高速化するために、報酬関数の滑らかさとアクションの分解性を活用します。リプシッツ連続性と分解の相乗効果を示します。それぞれが他方の収束を支援します。そうすることで、コンビナトリアルとリプシッツの盗賊の間のギャップを埋め、短期的なパフォーマンスを最適化しながら既存の保証を強化する後悔のないアプローチを提示します。私たちのアルゴリズムであるLIZARDが、カンボジアからの実際の密猟データのパフォーマンスを向上させることを示します。,https://d3i71xaburhd42.cloudfront.net/a472e5308f86f484e66ffe45578b05b3708723c0/1-Figure1-1.png
Goten: GPU-Outsourcing Trusted Execution of Neural Network Training and Prediction,"['Lucien K.L. Ng', 'Sherman S. M. Chow', 'Pui Yung Anna Woo', 'Yongjun Zhao']",,,,
Detection and Prediction of Nutrient Deficiency Stress Using Longitudinal Aerial Imagery,"['Saba Dadsetan', 'Gisele Rose', 'Naira Hovakimyan', 'Jennifer Hobbs']",https://arxiv.org/abs/2012.09654,"Early, precise detection of nutrient deficiency stress (NDS) has key economic as well as environmental impact; precision application of chemicals in place of blanket application reduces operational costs for the growers while reducing the amount of chemicals which may enter the environment unnecessarily. Furthermore, earlier treatment reduces the amount of loss and therefore boosts crop production during a given season. With this in mind, we collect sequences of high-resolution aerial imagery and construct semantic segmentation models to detect and predict NDS across the field. Our work sits at the intersection of agriculture, remote sensing, and modern computer vision and deep learning. First, we establish a baseline for full-field detection of NDS and quantify the impact of pretraining, backbone architecture, input representation, and sampling strategy. We then quantify the amount of information available at different points in the season by building a single-timestamp model based on a UNet. Next, we construct our proposed spatiotemporal architecture, which combines a UNet with a convolutional LSTM layer, to accurately detect regions of the field showing NDS; this approach has an impressive IOU score of 0.53. Finally, we show that this architecture can be trained to predict regions of the field which are expected to show NDS in a later flight -- potentially more than three weeks in the future -- maintaining an IOU score of 0.47-0.51 depending on how far in advance the prediction is made. We will also release a dataset which we believe will benefit the computer vision, remote sensing, as well as agriculture fields. This work contributes to the recent developments in deep learning for remote sensing and agriculture, while addressing a key social challenge with implications for economics and sustainability.",栄養素欠乏ストレス（NDS）の早期の正確な検出は、環境だけでなく経済にも重要な影響を及ぼします。ブランケット散布の代わりに化学薬品を正確に散布することで、栽培者の運用コストを削減すると同時に、環境に不必要に侵入する可能性のある化学物質の量を削減します。さらに、早期の処理は損失の量を減らし、したがって与えられた季節の間の作物生産を後押しします。これを念頭に置いて、高解像度の航空画像のシーケンスを収集し、セマンティックセグメンテーションモデルを構築して、フィールド全体のNDSを検出および予測します。私たちの仕事は、農業、リモートセンシング、最新のコンピュータービジョンとディープラーニングの交差点に位置しています。まず、NDSのフルフィールド検出のベースラインを確立し、事前トレーニング、バックボーンアーキテクチャ、入力表現、およびサンプリング戦略の影響を定量化します。次に、UNetに基づいて単一のタイムスタンプモデルを構築することにより、シーズンのさまざまな時点で利用可能な情報の量を定量化します。次に、UNetと畳み込みLSTM層を組み合わせて、NDSを示すフィールドの領域を正確に検出する、提案された時空間アーキテクチャを構築します。このアプローチのIOUスコアは0.53です。最後に、このアーキテクチャをトレーニングして、予測のどれだけ前にあるかに応じて、0.47〜0.51のIOUスコアを維持しながら、将来3週間以上後のフライトでNDSを示すと予想されるフィールドの領域を予測できることを示します。作られています。また、コンピュータービジョン、リモートセンシング、および農業分野に役立つと思われるデータセットもリリースします。この作業は、経済学と持続可能性に影響を与える重要な社会的課題に対処しながら、リモートセンシングと農業の深層学習の最近の発展に貢献しています。,https://d3i71xaburhd42.cloudfront.net/ed246c0456853b27453de0cb6cdcd0938822044a/13-Figure1-1.png
HOT-VAE: Learning High-Order Label Correlation for Multi-LabelClassification via Attention-Based Variational Autoencoders,"['Wenting Zhao', 'Shufeng Kong', 'Junwen Bai', 'Daniel Fink', 'Carla P Gomes']",,,,
Clinical Trial of an AI-Augmented Intervention for HIV Prevention in Youth Experiencing Homelessness,"['Bryan Wilder', 'Laura Onasch-Vera', 'Graham Diguiseppi', 'Robin Petering', 'Chyna Hill', 'Amulya Yadav', 'Eric Rice', 'Milind Tambe']",https://arxiv.org/abs/2009.09559,"Youth experiencing homelessness (YEH) are subject to substantially greater risk of HIV infection, compounded both by their lack of access to stable housing and the disproportionate representation of youth of marginalized racial, ethnic, and gender identity groups among YEH. A key goal for health equity is to improve adoption of protective behaviors in this population. One promising strategy for intervention is to recruit peer leaders from the population of YEH to promote behaviors such as condom usage and regular HIV testing to their social contacts. This raises a computational question: which youth should be selected as peer leaders to maximize the overall impact of the intervention? We developed an artificial intelligence system to optimize such social network interventions in a community health setting. We conducted a clinical trial enrolling 713 YEH at drop-in centers in a large US city. The clinical trial compared interventions planned with the algorithm to those where the highest-degree nodes in the youths' social network were recruited as peer leaders (the standard method in public health) and to an observation-only control group. Results from the clinical trial show that youth in the AI group experience statistically significant reductions in key risk behaviors for HIV transmission, while those in the other groups do not. This provides, to our knowledge, the first empirical validation of the usage of AI methods to optimize social network interventions for health. We conclude by discussing lessons learned over the course of the project which may inform future attempts to use AI in community-level interventions.",ホームレス（YEH）を経験している若者は、安定した住居へのアクセスの欠如と、YEHの間で疎外された人種、民族、性同一性グループの若者の不均衡な表現の両方によって、HIV感染のリスクが大幅に高くなります。健康格差の主要な目標は、この集団における保護行動の採用を改善することです。介入の有望な戦略の1つは、YEHの人口から仲間のリーダーを募集して、コンドームの使用や定期的なHIV検査などの行動を社会的接触者に宣伝することです。これは計算上の問題を提起します：介入の全体的な影響を最大化するためにどの若者がピアリーダーとして選ばれるべきですか？私たちは、コミュニティの健康環境におけるそのようなソーシャルネットワーク介入を最適化するための人工知能システムを開発しました。米国の大都市にあるドロップインセンターで、713YEHを登録する臨床試験を実施しました。臨床試験では、アルゴリズムを使用して計画された介入を、若者のソーシャルネットワークの最高度のノードがピアリーダーとして採用された介入（公衆衛生の標準的な方法）および観察のみの対照グループと比較しました。臨床試験の結果は、AIグループの若者がHIV感染の主要なリスク行動の統計的に有意な減少を経験しているのに対し、他のグループの若者はそうではないことを示しています。これは、私たちの知る限り、健康のためのソーシャルネットワーク介入を最適化するためのAIメソッドの使用法の最初の経験的検証を提供します。最後に、プロジェクトの過程で学んだ教訓について説明します。これは、コミュニティレベルの介入でAIを使用する将来の試みに役立つ可能性があります。,https://d3i71xaburhd42.cloudfront.net/1935d59e3501cd0b07016bfdd4dd369d3412eece/4-Figure1-1.png
Joint Incentive Optimization of Customer and Merchant in Mobile Payment Marketing,"['Li Yu', 'Zhengwei Wu', 'Ziqi Liu', 'Zhiqiang Zhang', 'Jinjie Gu', 'Xiaodong Zeng', 'Lihong Gu', 'Tianchi Cai']",,,,
Subverting Privacy-Preserving GANs: Hiding Secrets in Sanitized Images,"['Kang Liu', 'Benjamin Tan', 'Siddharth Garg']",https://arxiv.org/abs/2009.09283,"Unprecedented data collection and sharing have exacerbated privacy concerns and led to increasing interest in privacy-preserving tools that remove sensitive attributes from images while maintaining useful information for other tasks. Currently, state-of-the-art approaches use privacy-preserving generative adversarial networks (PP-GANs) for this purpose, for instance, to enable reliable facial expression recognition without leaking users' identity. However, PP-GANs do not offer formal proofs of privacy and instead rely on experimentally measuring information leakage using classification accuracy on the sensitive attributes of deep learning (DL)-based discriminators. In this work, we question the rigor of such checks by subverting existing privacy-preserving GANs for facial expression recognition. We show that it is possible to hide the sensitive identification data in the sanitized output images of such PP-GANs for later extraction, which can even allow for reconstruction of the entire input images, while satisfying privacy checks. We demonstrate our approach via a PP-GAN-based architecture and provide qualitative and quantitative evaluations using two public datasets. Our experimental results raise fundamental questions about the need for more rigorous privacy checks of PP-GANs, and we provide insights into the social impact of these.",前例のないデータ収集と共有はプライバシーの懸念を悪化させ、他のタスクに役立つ情報を維持しながら画像から機密属性を削除するプライバシー保護ツールへの関心を高めています。現在、最先端のアプローチでは、プライバシーを保護する生成的敵対的ネットワーク（PP-GAN）をこの目的で使用しており、たとえば、ユーザーのIDを漏らすことなく信頼性の高い表情認識を実現しています。ただし、PP-GANはプライバシーの正式な証明を提供せず、代わりに、深層学習（DL）ベースの弁別子の機密属性の分類精度を使用して情報漏えいを実験的に測定することに依存しています。この作業では、顔の表情の認識のために既存のプライバシー保護GANを破壊することにより、このようなチェックの厳密さに疑問を投げかけます。このようなPP-GANのサニタイズされた出力画像の機密識別データを非表示にして後で抽出できることを示します。これにより、プライバシーチェックを満たしながら、入力画像全体を再構築することもできます。 PP-GANベースのアーキテクチャを介してアプローチを示し、2つの公開データセットを使用して定性的および定量的評価を提供します。私たちの実験結果は、PP-GANのより厳密なプライバシーチェックの必要性についての基本的な質問を提起し、これらの社会的影響への洞察を提供します。,https://d3i71xaburhd42.cloudfront.net/cde71cbb955a3a3eb8de3ff8aa5da713ea3cbbf0/1-Figure1-1.png
Evidence Aware Neural Pornographic Text Identification for Child Protection,"['Kaisong Song', 'Yangyang Kang', 'Wei Gao', 'Zhe Gao', 'Changlong Sun', 'Xiaozhong Liu']",,,,
A Universal 2-State n-Action Adaptive Management Solver,"['Luz V Pascal', 'Marianne Akian', 'Sam Nicol', 'Iadine Chades']",,,,
Fairness in Influence Maximization through Randomization,"['Ruben Becker', ""Gianlorenzo D'Angelo"", 'Sajjad Ghobadi', 'Hugo Gilbert']",https://arxiv.org/abs/2010.03438,"The influence maximization paradigm has been used by researchers in various fields in order to study how information spreads in social networks. While previously the attention was mostly on efficiency, more recently fairness issues have been taken into account in this scope. In this paper, we propose to use randomization as a mean for achieving fairness. Similar to previous works like Fish et al. (WWW '19) and Tsang et al. (IJCAI '19), we study the maximin criterion for (group) fairness. In contrast to their work however, we model the problem in such a way that, when choosing the seed sets, probabilistic strategies are possible rather than only deterministic ones. We introduce two different variants of this probabilistic problem, one that entails probabilistic strategies over nodes (node-based problem) and a second one that entails probabilistic strategies over sets of nodes (set-based problem). While the original deterministic problem involving the maximin criterion has been shown to be inapproximable, interestingly, we show that both probabilistic variants permit approximation algorithms that achieve a constant multiplicative factor of 1-1/e plus an additive arbitrarily small error that is due to the simulation of the information spread. For an experimental study, we provide implementations of multiplicative-weight routines for both problems and compare the achieved fairness values to existing methods. Maybe non-surprisingly, we show that the ex-ante values of the computed probabilistic strategies are significantly larger than the (ex-post) fairness values of previous methods. This indicates that studying fairness via randomization is a worthwhile path to follow. Interestingly and maybe more surprisingly, we observe that even the ex-post fairness values computed by our routines, dominate over the fairness achieved by previous methods on most of the instances tested.",影響最大化パラダイムは、情報がソーシャルネットワークでどのように広がるかを研究するために、さまざまな分野の研究者によって使用されてきました。以前は主に効率性に注目が集まっていましたが、最近ではこの範囲で公平性の問題が考慮されています。この論文では、公平性を達成するための手段としてランダム化を使用することを提案します。 Fishらのような以前の作品と同様。 （WWW 19）およびTsang etal。 （IJCAI 19）、（グループ）公平性の最大基準を研究します。しかし、彼らの研究とは対照的に、シードセットを選択するときに、決定論的戦略だけでなく確率論的戦略が可能になるように問題をモデル化します。この確率論的問題の2つの異なる変形を紹介します。1つはノードの確率論的戦略を伴う（ノードベースの問題）、もう1つはノードのセットに対する確率論的戦略を伴う（セットベースの問題）。マキシミン基準を含む元の決定論的問題は近似できないことが示されていますが、興味深いことに、両方の確率的バリアントが、1-1 / eの一定の乗法係数と追加の任意の小さな誤差を達成する近似アルゴリズムを許可することを示します。情報拡散のシミュレーション。実験的研究のために、両方の問題に対して乗法重みルーチンの実装を提供し、達成された公平性の値を既存の方法と比較します。おそらく当然のことながら、計算された確率的戦略の事前値が、以前の方法の（事後）公平性値よりも大幅に大きいことを示します。これは、ランダム化を介して公平性を研究することは、従う価値のある道であることを示しています。興味深いことに、おそらくもっと驚くべきことに、ルーチンによって計算された事後の公平性の値でさえ、テストされたほとんどのインスタンスで以前の方法によって達成された公平性よりも支配的であることがわかります。,https://d3i71xaburhd42.cloudfront.net/173bc2bc007a887e660ad3530746e024413f512f/7-Figure1-1.png
K-N-MOMDPs: Towards Interpretable Solutions for Adaptive Management,"['Jonathan Ferrer Mestres', 'Thomas Dietterich', 'Olivier Buffet', 'Iadine Chades']",,,,
Computational Visual Ceramicology: Matching Image Outlines to Catalog Sketches,"['Barak Itkin', 'Lior Wolf', 'Nachum Dershowitz']",,,,
"Prediction of Landfall Intensity, Location, and Time of a Tropical Cyclone","['Sandeep Kumar', 'Koushik Biswas', 'Ashish Kumar Pandey']",,,,
Mitigating Political Bias in Language Models through Reinforced Calibration,"['Ruibo Liu', 'Chenyan Jia', 'Jason W Wei', 'Guangxuan Xu', 'Lili Wang', 'Soroush Vosoughi']",,,,
RainBench: Towards Data-Driven Global Precipitation Forecasting from Satellite Imagery,"['Christian A Schroeder de Witt', 'Catherine Tong', 'Valentina Zantedeschi', 'Daniele De Martini', 'Alfredo Kalaitzis', 'Matthew Chantry', 'Duncan Watson-Parris', 'Piotr Bilinski']",,,,
Predicting Flashover Occurrence Using Surrogate Temperature Data,"['Eugene Yujun Fu', 'Wai Cheong Tam', 'Jun Wang', 'Richard Peacock', 'Paul A Reneke', 'Grace Ngai', 'Hong Va Leong', 'Thomas Cleary']",,,,
Using Radio Archives for Low-Resource Speech Recognition: Towards an Intelligent Virtual Assistant for Illiterate Users,"['Moussa Doumbouya', 'Lisa Einstein', 'Chris Piech']",,,,
Degree Planning with PLAN-BERT: Multi-Semester Recommendation Using Future Courses of Interest,"['Erzhuo Shao', 'Shiyuan Guo', 'Zachary A Pardos']",,"Planning scenarios involving user pre-specified items present themselves frequently in recommender system domains. Although next-item and next-basket recommendation has been a focus of prior research, multiple consecutive item or basket approaches are needed for planning. No prior work has leveraged pre-specified future reference items to improve this type of challenging consecutive prediction task at inference time. PLAN-BERT is the first to accommodate this general planning scenario. It does so by contributing novel modifications that take inspiration from the masked training and contextual embedding of self-attention models. To test the model, we use the domain of student academic degree planning, in which students’ past course histories and future pre-specified courses of interest are used to fill in the remainder of their curriculum. Our offline analyses consist of 15 million historic course enrollments at 20 institutions and an online evaluation conducted at one of the institutions. Our results show that PLAN-BERT outperforms existing models including BERT, BiLSTM, and a UserKNN baseline, with small numbers of future reference items substantially improving accuracy. Significant results from our online evaluation show PLAN-BERT to be strongest in students’ perceptions of personalization.",ユーザーが事前に指定したアイテムを含む計画シナリオは、レコメンダーシステムドメインに頻繁に現れます。次のアイテムと次のバスケットの推奨は以前の調査の焦点でしたが、計画には複数の連続したアイテムまたはバスケットのアプローチが必要です。推論時にこのタイプの挑戦的な連続予測タスクを改善するために、事前に指定された将来の参照項目を活用した先行研究はありません。 PLAN-BERTは、この一般的な計画シナリオに対応する最初の企業です。これは、マスクされたトレーニングと自己注意モデルのコンテキスト埋め込みからインスピレーションを得た新しい変更を提供することによって行われます。モデルをテストするために、学生の学位計画のドメインを使用します。このドメインでは、過去のコース履歴と将来の事前に指定された関心のあるコースを使用して、残りのカリキュラムを埋めます。オフライン分析は、20の教育機関での1500万の歴史的なコース登録と、いずれかの教育機関で実施されたオンライン評価で構成されています。私たちの結果は、PLAN-BERTがBERT、BiLSTM、UserKNNベースラインなどの既存のモデルよりも優れており、将来の参照項目の数が少ないため、精度が大幅に向上することを示しています。私たちのオンライン評価からの重要な結果は、PLAN-BERTが学生の個人化の認識において最も強いことを示しています。,https://d3i71xaburhd42.cloudfront.net/6ba14b9864bb34c658695096c86080a90ef73425/4-Figure1-1.png
Modeling the Field Value Variations and Field Interactions Simultaneously for Fraud Detection,"['Dongbo Xi', 'Bowen Song', 'Fuzhen Zhuang', 'Yongchun Zhu', 'Shuai Chen', 'Tianyi Zhang', 'Yuan Qi', 'Qing He']",https://arxiv.org/abs/2008.05600,"With the explosive growth of e-commerce, online transaction fraud has become one of the biggest challenges for e-commerce platforms. The historical behaviors of users provide rich information for digging into the users' fraud risk. While considerable efforts have been made in this direction, a long-standing challenge is how to effectively exploit internal user information and provide explainable prediction results. In fact, the value variations of same field from different events and the interactions of different fields inside one event have proven to be strong indicators for fraudulent behaviors. In this paper, we propose the Dual Importance-aware Factorization Machines (DIFM), which exploits the internal field information among users' behavior sequence from dual perspectives, i.e., field value variations and field interactions simultaneously for fraud detection. The proposed model is deployed in the risk management system of one of the world's largest e-commerce platforms, which utilize it to provide real-time transaction fraud detection. Experimental results on real industrial data from different regions in the platform clearly demonstrate that our model achieves significant improvements compared with various state-of-the-art baseline models. Moreover, the DIFM could also give an insight into the explanation of the prediction results from dual perspectives.",電子商取引の爆発的な成長に伴い、オンライン取引詐欺は電子商取引プラットフォームの最大の課題の1つになっています。ユーザーの過去の行動は、ユーザーの不正リスクを掘り下げるための豊富な情報を提供します。この方向でかなりの努力が払われてきましたが、長年の課題は、内部ユーザー情報を効果的に活用し、説明可能な予測結果を提供する方法です。実際、異なるイベントからの同じフィールドの値の変動と、1つのイベント内の異なるフィールドの相互作用は、不正行為の強力な指標であることが証明されています。本論文では、ユーザーの行動シーケンス間の内部フィールド情報を、フィールド値の変動とフィールドの相互作用を同時に活用して不正を検出する、デュアル重要度認識因数分解マシン（DIFM）を提案します。提案されたモデルは、世界最大の電子商取引プラットフォームの1つであるリスク管理システムに導入され、リアルタイムのトランザクション不正検出を提供します。プラットフォーム内のさまざまな地域からの実際の産業データに関する実験結果は、私たちのモデルがさまざまな最先端のベースラインモデルと比較して大幅な改善を達成していることを明確に示しています。さらに、DIFMは、二重の観点から予測結果の説明への洞察を与えることもできます。,https://d3i71xaburhd42.cloudfront.net/28aa5e35e13c8baac8f202f1b2f68dbac8c80f6f/2-Figure1-1.png
Multi-Layer Networks for Ensemble Precipitation Forecasts Postprocessing,"['Fengyang Xu', 'Guanbin Li', 'Yunfei Du', 'Zhiguang Chen', 'Yutong Lu']",,,,
Minimizing Energy Use of Mixed-Fleet Public Transit for Fixed-Route Service,"['Amutheezan Sivagnanam', 'Afiya Ayman', 'Michael Wilbur', 'Philip Pugliese', 'Abhishek Dubey', 'Aron Laszka']",https://arxiv.org/abs/2004.05146,"Public transit can have significantly lower environmental impact than personal vehicles; however, it still uses a substantial amount of energy, causing air pollution and greenhouse gas emission. While electric vehicles (EVs) can reduce energy use, most public transit agencies have to employ them in combination with conventional, internal-combustion engine vehicles due to the high upfront costs of EVs. To make the best use of such a mixed fleet of vehicles, transit agencies need to optimize route assignments and charging schedules, which presents a challenging problem for large public transit networks. We introduce a novel problem formulation to minimize fuel and electricity use by assigning vehicles to transit trips and scheduling them for charging while serving an existing fixed-route transit schedule. We present an integer program for optimal discrete-time scheduling, and we propose polynomial-time heuristic algorithms and a genetic algorithm for finding solutions for larger networks. We evaluate our algorithms on the transit service of a mid-size U.S. city using operational data collected from public transit vehicles. Our results show that the proposed algorithms are scalable and achieve near-minimum energy use.",公共交通機関は、自家用車よりも環境への影響が大幅に少ない可能性があります。しかし、それでもかなりの量のエネルギーを使用し、大気汚染と温室効果ガスの排出を引き起こします。電気自動車（EV）はエネルギー使用量を削減できますが、EVの初期費用が高いため、ほとんどの公共交通機関は従来の内燃エンジン車と組み合わせて使用​​する必要があります。このような混合車両を最大限に活用するには、交通機関はルートの割り当てと課金スケジュールを最適化する必要があります。これは、大規模な公共交通ネットワークにとって困難な問題です。車両をトランジットトリップに割り当て、既存の固定ルートトランジットスケジュールを提供しながら充電をスケジュールすることにより、燃料と電力の使用を最小限に抑えるための新しい問題の定式化を紹介します。最適な離散時間スケジューリングのための整数計画法を提示し、より大きなネットワークの解を見つけるための多項式時間ヒューリスティックアルゴリズムと遺伝的アルゴリズムを提案します。公共交通機関から収集した運用データを使用して、米国の中規模都市の交通サービスに関するアルゴリズムを評価します。私たちの結果は、提案されたアルゴリズムがスケーラブルであり、ほぼ最小のエネルギー使用を達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/bf6b9fe0ea3ebf01e112e21be133d1bc23a234f2/5-Figure1-1.png
Traffic Flow Forecasting with Spatial-Temporal Graph Diffusion Network,"['Xiyue Zhang', 'Chao Huang', 'Yong Xu', 'Lianghao Xia', 'Peng Dai', 'Liefeng Bo', 'Junbo Zhang', 'Yu Zheng']",,,,
Real-Time Tropical Cyclone Intensity Estimation by Handling Temporally Heterogeneous Satellite Data,"['Boyo Chen', 'Buo-Fu Chen', 'Yun-Nung Chen']",https://arxiv.org/abs/2010.14977,"Analyzing big geophysical observational data collected by multiple advanced sensors on various satellite platforms promotes our understanding of the geophysical system. For instance, convolutional neural networks (CNN) have achieved great success in estimating tropical cyclone (TC) intensity based on satellite data with fixed temporal frequency (e.g., 3 h). However, to achieve more timely (under 30 min) and accurate TC intensity estimates, a deep learning model is demanded to handle temporally-heterogeneous satellite observations. Specifically, infrared (IR1) and water vapor (WV) images are available under every 15 minutes, while passive microwave rain rate (PMW) is available for about every 3 hours. Meanwhile, the visible (VIS) channel is severely affected by noise and sunlight intensity, making it difficult to be utilized. Therefore, we propose a novel framework that combines generative adversarial network (GAN) with CNN. The model utilizes all data, including VIS and PMW information, during the training phase and eventually uses only the high-frequent IR1 and WV data for providing intensity estimates during the predicting phase. Experimental results demonstrate that the hybrid GAN-CNN framework achieves comparable precision to the state-of-the-art models, while possessing the capability of increasing the maximum estimation frequency from 3 hours to less than 15 minutes.",さまざまな衛星プラットフォーム上の複数の高度なセンサーによって収集された大きな地球物理学的観測データを分析することで、地球物理学的システムの理解が促進されます。たとえば、畳み込みニューラルネットワーク（CNN）は、固定された時間周波数（たとえば、3時間）の衛星データに基づいて熱帯低気圧（TC）の強度を推定することに大きな成功を収めています。ただし、よりタイムリー（30分未満）で正確なTC強度推定を達成するには、時間的に不均一な衛星観測を処理するための深層学習モデルが必要です。具体的には、赤外線（IR1）と水蒸気（WV）の画像は15分ごとに利用でき、パッシブマイクロ波降雨量（PMW）は約3時間ごとに利用できます。一方、可視（VIS）チャンネルは、ノイズや太陽光の強さの影響を強く受け、利用が困難です。したがって、生成的敵対的ネットワーク（GAN）とCNNを組み合わせた新しいフレームワークを提案します。モデルは、トレーニングフェーズ中にVISおよびPMW情報を含むすべてのデータを利用し、最終的には、予測フェーズ中に強度推定値を提供するために高頻度のIR1およびWVデータのみを使用します。実験結果は、ハイブリッドGAN-CNNフレームワークが、最大推定頻度を3時間から15分未満に増やす機能を備えながら、最先端のモデルと同等の精度を達成することを示しています。,https://d3i71xaburhd42.cloudfront.net/588353f6daf232bb87ceaa2ade7c0ba50333c685/2-Figure1-1.png
Court Opinion Generation from Case Fact Description with Legal Basis,"['Quanzhi Li', 'Qiong Zhang']",,,,
HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection,"['Binny Mathew', 'Punyajoy Saha', 'Seid Muhie Yimam', 'Chris Biemann', 'Pawan Goyal', 'Animesh Mukherjee']",https://arxiv.org/abs/2012.10289,"Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. We also observe that models, which utilize the human rationales for training, perform better in reducing unintended bias towards target communities. We have made our code and dataset public for other researchers. Disclaimer: The article contains material that many will find offensive or hateful; however this cannot be avoided owing to the nature of the work.",ヘイトスピーチは、オンラインソーシャルメディアを悩ませている挑戦的な問題です。ヘイトスピーチ検出のより良いモデルが継続的に開発されていますが、ヘイトスピーチのバイアスと解釈可能性の側面に関する研究はほとんどありません。このホワイトペーパーでは、問題の複数の側面をカバーする最初のベンチマークヘイトスピーチデータセットであるHateXplainを紹介します。データセット内の各投稿には、3つの異なる観点から注釈が付けられています。基本的な、一般的に使用される3クラスの分類（つまり、ヘイト、攻撃的、または通常）、ターゲットコミュニティ（つまり、ヘイトスピーチ/攻撃的スピーチの犠牲になったコミュニティ）です。投稿内）、および理論的根拠、つまり、ラベル付けの決定（憎悪、攻撃的、または通常）の基礎となる投稿の部分。既存の最先端モデルを利用し、分類で非常に優れたパフォーマンスを発揮するモデルでさえ、モデルの妥当性や忠実度などの説明可能性の指標で高いスコアを獲得しないことを確認しています。また、トレーニングに人間の論理的根拠を利用するモデルは、ターゲットコミュニティに対する意図しないバイアスを減らすのに優れていることも確認しています。コードとデータセットを他の研究者に公開しました。免責事項：この記事には、多くの人が不快または不快に感じる資料が含まれています。ただし、作業の性質上、これは避けられません。,https://d3i71xaburhd42.cloudfront.net/2a075155e72eb22f95b92efeef38a0b8e5708f5d/4-Figure1-1.png
