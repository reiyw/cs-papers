title,authors,arxiv_url,abstract,abstract_ja,figure1_url
A Bilingual Generative Transformer for Semantic Sentence Embedding,"['John Wieting', 'Graham Neubig', 'Taylor Berg-Kirkpatrick']",http://arxiv.org/abs/1911.03895v1,"Semantic sentence embedding models encode natural language sentences into vectors, such that closeness in embedding space indicates closeness in the semantics between the sentences. Bilingual data offers a useful signal for learning such embeddings: properties shared by both sentences in a translation pair are likely semantic, while divergent properties are likely stylistic or language-specific. We propose a deep latent variable model that attempts to perform source separation on parallel sentences, isolating what they have in common in a latent semantic vector, and explaining what is left over with language-specific latent vectors. Our proposed approach differs from past work on semantic sentence encoding in two ways. First, by using a variational probabilistic framework, we introduce priors that encourage source separation, and can use our model's posterior to predict sentence embeddings for monolingual data at test time. Second, we use high-capacity transformers as both data generating distributions and inference networks -- contrasting with most past work on sentence embeddings. In experiments, our approach substantially outperforms the state-of-the-art on a standard suite of unsupervised semantic similarity evaluations. Further, we demonstrate that our approach yields the largest gains on more difficult subsets of these evaluations where simple word overlap is not a good indicator of similarity.",意味的文埋め込みモデルは、自然言語の文をベクトルにエンコードし、埋め込み空間が近いと文間の意味論が近いことを示します。二ヶ国語データは、このような埋め込みを学習するために有用な信号を提供する。すなわち、翻訳ペアの中の両方の文が共有する特性は意味論的である可能性が高く、一方で発散する特性は文体や言語固有の特性である可能性が高い。我々は、並列文のソース分離を実行しようとする深層潜在変数モデルを提案し、それらが潜在的な意味的ベクトルで共通するものを分離し、言語固有の潜在ベクトルで残されたものを説明する。我々の提案するアプローチは、意味的文の符号化に関する過去の研究とは2つの点で異なる。第一に、変分確率的枠組みを用いることで、ソース分離を促進するプリオールを導入し、テスト時に単言語データの文の埋め込みを予測するために我々のモデルの事後予測を用いることができる。第二に、データ生成分布と推論ネットワークの両方に大容量変換器を用いており、これまでの文のエンベッディングに関する研究とは対照的である。実験では、我々のアプローチは、教師なしの意味的類似度評価の標準的なスイートにおいて、最先端の手法を大幅に凌駕している。さらに、単純な単語の重複が類似性の良い指標とはならないような、より困難な評価のサブセットにおいて、我々のアプローチが最大の利益をもたらすことを実証した。,https://d3i71xaburhd42.cloudfront.net/1941f5b053ccc80fa44980d38ac074145591b4ec/3-Figure1-1.png
A Centering Approach for Discourse Structure-aware Coherence Modeling,"['Sungho Jeon', 'Michael Strube']",,,なし,
A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support,"['Ashish Sharma', 'Adam Miner', 'David Atkins', 'Tim Althoff']",http://arxiv.org/abs/2009.08441v1,"Empathy is critical to successful mental health support. Empathy measurement has predominantly occurred in synchronous, face-to-face settings, and may not translate to asynchronous, text-based contexts. Because millions of people use text-based platforms for mental health support, understanding empathy in these contexts is crucial. In this work, we present a computational approach to understanding how empathy is expressed in online mental health platforms. We develop a novel unifying theoretically-grounded framework for characterizing the communication of empathy in text-based conversations. We collect and share a corpus of 10k (post, response) pairs annotated using this empathy framework with supporting evidence for annotations (rationales). We develop a multi-task RoBERTa-based bi-encoder model for identifying empathy in conversations and extracting rationales underlying its predictions. Experiments demonstrate that our approach can effectively identify empathic conversations. We further apply this model to analyze 235k mental health interactions and show that users do not self-learn empathy over time, revealing opportunities for empathy training and feedback.","共感性は、メンタルヘルス支援を成功させるために不可欠である。共感性の測定は、主に同期的な、対面式の設定で行われてきましたが、非同期的な、テキストベースの文脈には当てはまらない場合があります。何百万人もの人がテキストベースのプラットフォームを使ってメンタルヘルス支援を行っているため、これらの文脈における共感性を理解することは非常に重要である。本研究では、オンライン・メンタルヘルス・プラットフォームにおいて共感がどのように表現されるかを理解するための計算科学的アプローチを提示する。本研究では、テキストベースの会話における共感のコミュニケーションを特徴づけるために、理論的に統一された新しい枠組みを開発する。この共感フレームワークを用いて注釈を付けた10,000組のペア（ポスト、レスポンス）のコーパスを収集し、注釈の根拠（根拠）を添えて共有する。我々は、会話の共感を識別し、その予測の基礎となる根拠を抽出するためのマルチタスクRoBERTaベースのバイエンコーダーモデルを開発する。実験により、我々のアプローチが効果的に共感的な会話を識別できることが実証された。我々はさらに、このモデルを23万5千人のメンタルヘルスの相互作用を分析するために適用し、ユーザーが時間の経過とともに共感を自己学習しないことを示し、共感トレーニングとフィードバックの機会を明らかにした。",https://d3i71xaburhd42.cloudfront.net/15c9bbc6de95fbff176b6cb76530785146da81eb/1-Figure1-1.png
A Dataset for Tracking Entities in Open Domain Procedural Text,"['Niket Tandon', 'Keisuke Sakaguchi', 'Bhavana Dalvi', 'Dheeraj Rajagopal', 'Peter Clark', 'Michal Guerquin', 'Kyle Richardson', 'Eduard Hovy']",,,なし,
A Diagnostic Study of Explainability Techniques for Text Classification,"['Pepa Atanasova', 'Jakob Grue Simonsen', 'Christina Lioma', 'Isabelle Augenstein']",http://arxiv.org/abs/2009.13295v1,"Recent developments in machine learning have introduced models that approach human performance at the cost of increased architectural complexity. Efforts to make the rationales behind the models' predictions transparent have inspired an abundance of new explainability techniques. Provided with an already trained model, they compute saliency scores for the words of an input instance. However, there exists no definitive guide on (i) how to choose such a technique given a particular application task and model architecture, and (ii) the benefits and drawbacks of using each such technique. In this paper, we develop a comprehensive list of diagnostic properties for evaluating existing explainability techniques. We then employ the proposed list to compare a set of diverse explainability techniques on downstream text classification tasks and neural network architectures. We also compare the saliency scores assigned by the explainability techniques with human annotations of salient input regions to find relations between a model's performance and the agreement of its rationales with human ones. Overall, we find that the gradient-based explanations perform best across tasks and model architectures, and we present further insights into the properties of the reviewed explainability techniques.",最近の機械学習の発展は、アーキテクチャの複雑さを増した代償として、人間のパフォーマンスに近づけるモデルを導入しました。モデルの予測の背後にある理論的根拠を透明にする努力は、新しい説明可能性の技術を大量に生み出しました。すでに訓練されたモデルを与えられたモデルは、入力インスタンスの単語の意味度スコアを計算します。しかし、(i)特定のアプリケーションタスクとモデルアーキテクチャに応じてどのようにそのような手法を選択するか、(ii)そのような手法を使用することの利点と欠点についての決定的なガイドは存在しない。本論文では、既存の説明可能性技術を評価するための診断特性の包括的なリストを作成する。そして、提案したリストを用いて、下流のテキスト分類タスクとニューラルネットワークアーキテクチャ上の多様な説明可能性技術を比較する。また、説明可能性技術によって割り当てられた重要度スコアを、人間による顕著な入力領域のアノテーションと比較し、モデルの性能と人間のアノテーションとの間の関係を明らかにする。全体的に、勾配に基づいた説明がタスクとモデルアーキテクチャにおいて最も優れた性能を発揮することがわかり、レビューされた説明可能性技術の特性についての更なる洞察を提示する。,https://d3i71xaburhd42.cloudfront.net/ae06bc1e8e67c27b89329ebcfe61b71625d853f6/1-Figure1-1.png
A Joint Multiple Criteria Model in Transfer Learning for Cross-domain Chinese Word Segmentation,"['Kaiyu Huang', 'Degen Huang', 'Zhuang Liu', 'Fengran Mo']",,,なし,
A Knowledge-Aware Sequence-to-Tree Network for Math Word Problem Solving,"['Qinzhuo Wu', 'Qi Zhang', 'Jinlan Fu', 'Xuanjing Huang']",,,なし,
A Knowledge-driven Generative Model for Multi-implication Chinese Medical Procedure Entity Normalization,"['Jinghui Yan', 'Yining Wang', 'Lu Xiang', 'Yu Zhou', 'Chengqing Zong']",,,なし,
A Massive Collection of Cross-Lingual Web-Document Pairs,"['Ahmed El-Kishky', 'Vishrav Chaudhary', 'Francisco Guzmán', 'Philipp Koehn']",http://arxiv.org/abs/1911.06154v2,"Cross-lingual document alignment aims to identify pairs of documents in two distinct languages that are of comparable content or translations of each other. In this paper, we exploit the signals embedded in URLs to label web documents at scale with an average precision of 94.5% across different language pairs. We mine sixty-eight snapshots of the Common Crawl corpus and identify web document pairs that are translations of each other. We release a new web dataset consisting of over 392 million URL pairs from Common Crawl covering documents in 8144 language pairs of which 137 pairs include English. In addition to curating this massive dataset, we introduce baseline methods that leverage cross-lingual representations to identify aligned documents based on their textual content. Finally, we demonstrate the value of this parallel documents dataset through a downstream task of mining parallel sentences and measuring the quality of machine translations from models trained on this mined data. Our objective in releasing this dataset is to foster new research in cross-lingual NLP across a variety of low, medium, and high-resource languages.","言語間のドキュメントアライメントは、2つの異なる言語で書かれたドキュメントのペアを識別することを目的としており、それらは互いに同等の内容または翻訳である。この論文では、URLに埋め込まれた信号を利用して、異なる言語ペア間で平均94.5%の精度でウェブ文書のラベル付けを行う。我々は、Common Crawlコーパスの68スナップショットを採掘し、お互いの翻訳であるウェブドキュメントのペアを識別します。我々は、8144言語ペアのドキュメントをカバーするCommon Crawlから3億9,200万以上のURLペアからなる新しいウェブデータセットをリリースしています。この大規模なデータセットのキュレーションに加えて、我々は、テキストの内容に基づいて整合性の取れた文書を識別するために、言語間の表現を活用するベースライン手法を紹介します。最後に、この並列文書データセットの価値を、下流のタスクである並列文のマイニングと、このマイニングされたデータ上で訓練されたモデルからの機械翻訳の品質を測定することによって実証する。このデータセットを公開する目的は、低・中・高リソースの様々な言語を横断する言語横断NLPの新しい研究を促進することです。",https://d3i71xaburhd42.cloudfront.net/cbe846fd673a07a0c959869c483f4a908374d76d/3-Table1-1.png
A Matter of Framing: The Impact of Linguistic Formalism on Probing Results,"['Ilia Kuznetsov', 'Iryna Gurevych']",http://arxiv.org/abs/2004.14999v1,"Deep pre-trained contextualized encoders like BERT (Delvin et al., 2019) demonstrate remarkable performance on a range of downstream tasks. A recent line of research in probing investigates the linguistic knowledge implicitly learned by these models during pre-training. While most work in probing operates on the task level, linguistic tasks are rarely uniform and can be represented in a variety of formalisms. Any linguistics-based probing study thereby inevitably commits to the formalism used to annotate the underlying data. Can the choice of formalism affect probing results? To investigate, we conduct an in-depth cross-formalism layer probing study in role semantics. We find linguistically meaningful differences in the encoding of semantic role- and proto-role information by BERT depending on the formalism and demonstrate that layer probing can detect subtle differences between the implementations of the same linguistic formalism. Our results suggest that linguistic formalism is an important dimension in probing studies, along with the commonly used cross-task and cross-lingual experimental settings.","BERT(Delvin et al., 2019)のようなディープな事前学習された文脈化エンコーダーは、下流のタスクの範囲で顕著な性能を示している。プロービングにおける最近の研究では、事前訓練中にこれらのモデルによって暗黙的に学習された言語知識を調査している。プロービングのほとんどの研究はタスクレベルで行われているが、言語タスクは一様ではなく、様々な形式論で表現されることがある。言語学をベースにしたプロービング研究では、必然的に基礎となるデータに注釈を付けるために使用される形式主義にこだわることになります。形式主義の選択は、プロービングの結果に影響を与えることができるのでしょうか？それを調べるために、我々はロールセマンティクスにおける形式主義を横断した層の綿密なプロービング研究を行った。形式主義に応じて、BERTによる意味的役割情報および原型的役割情報のエンコーディングに言語学的に意味のある違いがあることを発見し、レイヤープロービングが同じ言語形式主義の実装間の微妙な違いを検出できることを実証した。この結果から、言語形式主義は、一般的に使用されているクロスタスクおよびクロス言語実験環境とともに、プロービング研究において重要な次元であることが示唆された。",https://d3i71xaburhd42.cloudfront.net/a160dbe78b0546679ec8a3140b3cf4614e3cc485/1-Figure1-1.png
A Method for Building a Commonsense Inference Dataset based on Basic Events,"['Kazumasa Omura', 'Daisuke Kawahara', 'Sadao Kurohashi']",,,なし,
A Multi-Task Incremental Learning Framework with Category Name Embedding for Aspect-Category Sentiment Analysis,"['Zehui Dai', 'Cheng Peng', 'Huajie Chen', 'Yadong Ding']",http://arxiv.org/abs/2010.02784v1,"(T)ACSA tasks, including aspect-category sentiment analysis (ACSA) and targeted aspect-category sentiment analysis (TACSA), aims at identifying sentiment polarity on predefined categories. Incremental learning on new categories is necessary for (T)ACSA real applications. Though current multi-task learning models achieve good performance in (T)ACSA tasks, they suffer from catastrophic forgetting problems in (T)ACSA incremental learning tasks. In this paper, to make multi-task learning feasible for incremental learning, we proposed Category Name Embedding network (CNE-net). We set both encoder and decoder shared among all categories to weaken the catastrophic forgetting problem. Besides the origin input sentence, we applied another input feature, i.e., category name, for task discrimination. Our model achieved state-of-the-art on two (T)ACSA benchmark datasets. Furthermore, we proposed a dataset for (T)ACSA incremental learning and achieved the best performance compared with other strong baselines.",(T)ACSAタスクは、アスペクトカテゴリセンチメント分析(ACSA)とターゲットアスペクトカテゴリセンチメント分析(TACSA)を含み、事前に定義されたカテゴリに対するセンチメントの極性を特定することを目的としている。(T)ACSAを実際に適用するためには、新しいカテゴリに対する増分学習が必要である。現在のマルチタスク学習モデルは(T)ACSA課題では良好な性能を発揮するが、(T)ACSA増分学習では壊滅的な忘却問題に悩まされている。本論文では、インクリメンタル学習のためのマルチタスク学習を実現するために、カテゴリ名埋め込みネットワーク(CNE-net)を提案した。本論文では，カテゴリ名埋め込みネットワーク（CNE-net）を提案した．また，タスク識別のために，原点入力文の他に，カテゴリ名を入力特徴量として適用した．我々のモデルは、2つの(T)ACSAベンチマークデータセットにおいて最先端の性能を達成した。さらに、(T)ACSAインクリメンタル学習のためのデータセットを提案し、他の強力なベースラインと比較して最高の性能を達成した。,https://d3i71xaburhd42.cloudfront.net/93594f2e95e5a7473bd90ee5eb04619699cc6ff4/2-Table1-1.png
A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information Expression,"['Mingming Sun', 'Wenyue Hua', 'Zoe Liu', 'Xin Wang', 'kangjie zheng', 'Ping Li']",,,なし,
A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning,"['Yichi Zhang', 'Zhijian Ou', 'Min Hu', 'Junlan Feng']",http://arxiv.org/abs/2009.08115v3,"Structured belief states are crucial for user goal tracking and database query in task-oriented dialog systems. However, training belief trackers often requires expensive turn-level annotations of every user utterance. In this paper we aim at alleviating the reliance on belief state labels in building end-to-end dialog systems, by leveraging unlabeled dialog data towards semi-supervised learning. We propose a probabilistic dialog model, called the LAtent BElief State (LABES) model, where belief states are represented as discrete latent variables and jointly modeled with system responses given user inputs. Such latent variable modeling enables us to develop semi-supervised learning under the principled variational learning framework. Furthermore, we introduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of LABES. In supervised experiments, LABES-S2S obtains strong results on three benchmark datasets of different scales. In utilizing unlabeled dialog data, semi-supervised LABES-S2S significantly outperforms both supervised-only and semi-supervised baselines. Remarkably, we can reduce the annotation demands to 50% without performance loss on MultiWOZ.",構造化された信念状態は、タスク指向の対話システムにおいて、ユーザのゴール追跡やデータベースへの問い合わせに不可欠である。しかし、信念状態トラッカーを訓練するには、ユーザの発話のすべてのターンレベルのアノテーションが必要であり、コストがかかることが多い。この論文では、ラベル付けされていない対話データを半教師付き学習に活用することで、エンドツーエンドの対話システムを構築する際の信念状態ラベルへの依存度を軽減することを目的としている。我々はLAtent BElief State (LABES)モデルと呼ばれる確率論的対話モデルを提案する。このような潜在変数のモデル化により、原理的変分学習の枠組みの下で半教師付き学習を開発することができる。さらに、本研究では、LABESのコピー・オーガメントされたSeq2SeqモデルのインスタンスであるLABES-S2Sを紹介する。教師あり実験では、異なるスケールの3つのベンチマークデータセットにおいて、LABES-S2Sは強い結果を得ることができた。LABES-S2Sは、ラベル付けされていない対話データを利用した場合、半教師付きのLABES-S2Sは、教師付きのみのベースラインと半教師付きのベースラインの両方を有意に上回る結果を得た。驚くべきことに、MultiWOZの性能を損なうことなく、アノテーションの要求を50%まで削減することができた。,https://d3i71xaburhd42.cloudfront.net/a14d3b790ae734feb01bf94602c509fd80768b61/1-Figure1-1.png
A Rigorous Study on Named Entity Recognition: Can Fine-tuning Pretrained Model Lead to the Promised Land?,"['Hongyu Lin', 'Yaojie Lu', 'Jialong Tang', 'Xianpei Han', 'Le Sun', 'Zhicheng Wei', 'Nicholas Jing Yuan']",http://arxiv.org/abs/2004.12126v1,"Fine-tuning pretrained model has achieved promising performance on standard NER benchmarks. Generally, these benchmarks are blessed with strong name regularity, high mention coverage and sufficient context diversity. Unfortunately, when scaling NER to open situations, these advantages may no longer exist, and therefore raise the critical question of whether pretrained supervised models can still work well when facing these issues. As there is no currently available dataset to investigate this problem, this paper proposes to conduct randomization test on standard benchmarks. Specifically, we erase name regularity, mention coverage and context diversity respectively from the benchmarks, in order to explore their impact on the generalization ability of models. Moreover, we also construct a new open NER dataset that focuses on entity types with weak name regularity such as book, song, and movie. From both randomization test and empirical experiments, we draw the conclusions that 1) name regularity is vital for generalization to unseen mentions; 2) high mention coverage may undermine the model generalization ability and 3) context patterns may not require enormous data to capture when using pretrained supervised models.",事前訓練モデルを微調整することで、標準的なNERベンチマークで有望な性能を達成した。一般的に、これらのベンチマークは強い名前の規則性、高い言及カバレッジ、十分な文脈の多様性に恵まれている。しかし、残念ながら、NERをオープンな状況にスケーリングすると、これらの利点はもはや存在しないかもしれず、したがって、これらの問題に直面したときに、事前学習された教師付きモデルがまだ十分に機能するかどうかという重大な疑問が生じる。現在、この問題を調査するためのデータセットがないため、本論文では、標準的なベンチマークを用いて無作為化テストを行うことを提案する。具体的には、名前の規則性、言及範囲、文脈の多様性をそれぞれベンチマークから削除し、それらがモデルの一般化能力に与える影響を調べる。さらに、本、歌、映画のような名前の規則性が弱いエンティティタイプに焦点を当てた新しいオープンNERデータセットを構築した。ランダム化テストと実証実験の両方から、1)名前の規則性は見たことのない言及への一般化に不可欠である、2)高い言及率はモデルの一般化能力を損なう可能性がある、3)事前学習された教師付きモデルを使用する場合、文脈パターンは膨大なデータをキャプチャする必要がないかもしれない、という結論を導き出した。,https://d3i71xaburhd42.cloudfront.net/df3420b28e99f5cf59cccaefc7cb8a719a465087/1-Table1-1.png
A Spectral Method for Unsupervised Multi-Document Summarization,"['Kexiang Wang', 'Baobao Chang', 'Zhifang Sui']",,,なし,
A State-independent and Time-evolving Network with Applications to Early Rumor Detection,"['Rui Xia', 'Kaizhou Xuan', 'Jianfei Yu']",,,なし,
A Supervised Word Alignment Method based on Cross-Language Span Prediction using Multilingual BERT,"['Masaaki Nagata', 'Katsuki Chousa', 'Masaaki Nishino']",http://arxiv.org/abs/2004.14516v1,"We present a novel supervised word alignment method based on cross-language span prediction. We first formalize a word alignment problem as a collection of independent predictions from a token in the source sentence to a span in the target sentence. As this is equivalent to a SQuAD v2.0 style question answering task, we then solve this problem by using multilingual BERT, which is fine-tuned on a manually created gold word alignment data. We greatly improved the word alignment accuracy by adding the context of the token to the question. In the experiments using five word alignment datasets among Chinese, Japanese, German, Romanian, French, and English, we show that the proposed method significantly outperformed previous supervised and unsupervised word alignment methods without using any bitexts for pretraining. For example, we achieved an F1 score of 86.7 for the Chinese-English data, which is 13.3 points higher than the previous state-of-the-art supervised methods.",本研究では、言語間のスパン予測に基づく新しい教師付き単語アライメント法を提案する。我々はまず、単語アライメント問題を、原文中のトークンから対象文中のスパンへの独立した予測の集合として形式化する。これはSQuAD v2.0形式の質問応答タスクに相当するので、我々は、手動で作成された金の単語アライメントデータ上で微調整された多言語BERTを使用して、この問題を解決する。質問にトークンの文脈を加えることで、単語アライメントの精度を大幅に向上させた。中国語、日本語、ドイツ語、ルーマニア語、フランス語、英語の5つの単語アライメントデータを用いた実験では、事前学習にビットテキストを用いることなく、提案手法が従来の教師あり・教師なし単語アライメント手法を大幅に上回ることを示した。例えば、中国語-英語データのF1スコアは86.7であり、これは従来の教師あり・教師なしの単語アライメント法と比較して13.3ポイント高い値である。,https://d3i71xaburhd42.cloudfront.net/3645b1b0302be888a02ce8bb79337fe05db0cfe0/4-Table1-1.png
A Synset Relation-enhanced Framework with a Try-again Mechanism for Word Sense Disambiguation,"['Ming Wang', 'Yinglin Wang']",,,なし,
A Time-Aware Transformer based model for Suicide Ideation Detection on Social Media,"['Ramit Sawhney', 'Harshit Joshi', 'Saumya Gandhi', 'Rajiv Ratn Shah']",,,なし,
A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses,"['Hisashi Kamezawa', 'Noriki Nishida', 'Nobuyuki Shimizu', 'Takashi Miyazaki', 'Hideki Nakayama']",,,なし,
Accurate Word Alignment Induction from Neural Machine Translation,"['Yun Chen', 'Yang Liu', 'Guanhua Chen', 'Xin Jiang', 'Qun Liu']",http://arxiv.org/abs/2004.14837v1,"Despite its original goal to jointly learn to align and translate, prior researches suggest that the state-of-the-art neural machine translation model Transformer captures poor word alignment through its attention mechanism. In this paper, we show that attention weights do capture accurate word alignment, which could only be revealed if we choose the correct decoding step and layer to induce word alignment. We propose to induce alignment with the to-be-aligned target token as the decoder input and present two simple but effective interpretation methods for word alignment induction, either through the attention weights or the leave-one-out measures. In contrast to previous studies, we find that attention weights capture better word alignment than the leave-one-out measures under our setting. Using the proposed method with attention weights, we greatly improve over fast-align on word alignment induction. Finally, we present a multi-task learning framework to train the Transformer model and show that by incorporating GIZA++ alignments into our multi-task training, we can induce significantly better alignments than GIZA++.",アラインメントと翻訳を共同学習するという本来の目的にもかかわらず、先行研究では、最先端のニューラル機械翻訳モデルであるTransformerは、その注意メカニズムによって、不十分な単語アライメントを捕捉していることが示唆されている。この論文では、注目度重みが正確な単語アライメントを捉えていることを示す。本論文では、アライメントされるべきターゲットトークンをデコーダ入力として用いてアライメントを誘導することを提案し、注目度を用いた場合と離脱度を用いた場合の2つの単純かつ効果的な解釈方法を提示する。これまでの研究とは対照的に、我々の設定では、注目度重みの方が、離脱判定よりも優れた単語アライメントを捉えていることがわかった。本研究で提案した手法を用いて、注目度重みを用いた場合には、単語アライメントの誘導において、高速アライメントよりも大幅に改善することがわかった。最後に、Transformerモデルを学習するためのマルチタスク学習フレームワークを提示し、GIZA++のアライメントをマルチタスク学習に組み込むことで、GIZA++よりも有意に優れたアライメントを誘導できることを示す。,https://d3i71xaburhd42.cloudfront.net/b761d0afcf976606543007a528ae87034f663d8e/3-Figure1-1.png
Acrostic Poem Generation,"['Rajat Agarwal', 'Katharina Kann']",http://arxiv.org/abs/2010.02239v1,"We propose a new task in the area of computational creativity: acrostic poem generation in English. Acrostic poems are poems that contain a hidden message; typically, the first letter of each line spells out a word or short phrase. We define the task as a generation task with multiple constraints: given an input word, 1) the initial letters of each line should spell out the provided word, 2) the poem's semantics should also relate to it, and 3) the poem should conform to a rhyming scheme. We further provide a baseline model for the task, which consists of a conditional neural language model in combination with a neural rhyming model. Since no dedicated datasets for acrostic poem generation exist, we create training data for our task by first training a separate topic prediction model on a small set of topic-annotated poems and then predicting topics for additional poems. Our experiments show that the acrostic poems generated by our baseline are received well by humans and do not lose much quality due to the additional constraints. Last, we confirm that poems generated by our model are indeed closely related to the provided prompts, and that pretraining on Wikipedia can boost performance.",我々は、計算創造性の分野で新しいタスクを提案します：英語のアクロスティック詩の生成。アクロスティックポエムとは、隠されたメッセージを含む詩のことで、通常、各行の最初の文字が単語や短いフレーズを綴っている。我々は、このタスクを複数の制約条件を持つ生成タスクとして定義する：1)入力単語が与えられた場合、各行の頭文字は与えられた単語を綴るべきであり、2)詩の意味論もまたそれに関連しているべきであり、3)詩は韻を踏むスキームに従うべきである。さらに、条件付きニューラル言語モデルとニューラル韻律モデルを組み合わせたベースラインモデルを提供する。アクロスティックポエム生成のための専用のデータセットが存在しないため、我々はまず、トピック注釈付きの小さなセットのポエムに対して別のトピック予測モデルを訓練し、その後、追加のポエムに対してトピックを予測することによって、我々のタスクのための訓練データを作成した。実験の結果、我々のベースラインで生成されたアクロスティックな詩は、人間によく受け取られ、追加の制約により品質が低下しないことがわかった。最後に、我々のモデルで生成された詩は、実際に提供されたプロンプトと密接に関連しており、ウィキペディアでの事前学習がパフォーマンスを向上させることができることを確認した。,https://d3i71xaburhd42.cloudfront.net/842247800285f6866c5bca69cba9e45237d19cab/1-Figure1-1.png
Active Learning for BERT: An Empirical Study,"['Liat Ein-Dor', 'Alon Halfon', 'Ariel Gera', 'Eyal Shnarch', 'Lena Dankin', 'Leshem Choshen', 'Marina Danilevsky', 'Ranit Aharonov', 'Yoav Katz', 'Noam Slonim']",,,なし,
Adaptive Attentional Network for Few-Shot Knowledge Graph Completion,"['Jiawei Sheng', 'Shu Guo', 'Zhenyu Chen', 'Juwei Yue', 'Lihong Wang', 'Tingwen Liu', 'Hongbo Xu']",http://arxiv.org/abs/2010.09638v1,"Few-shot Knowledge Graph (KG) completion is a focus of current research, where each task aims at querying unseen facts of a relation given its few-shot reference entity pairs. Recent attempts solve this problem by learning static representations of entities and references, ignoring their dynamic properties, i.e., entities may exhibit diverse roles within task relations, and references may make different contributions to queries. This work proposes an adaptive attentional network for few-shot KG completion by learning adaptive entity and reference representations. Specifically, entities are modeled by an adaptive neighbor encoder to discern their task-oriented roles, while references are modeled by an adaptive query-aware aggregator to differentiate their contributions. Through the attention mechanism, both entities and references can capture their fine-grained semantic meanings, and thus render more expressive representations. This will be more predictive for knowledge acquisition in the few-shot scenario. Evaluation in link prediction on two public datasets shows that our approach achieves new state-of-the-art results with different few-shot sizes.",現在の研究では、フューショット知識グラフ（KG）補完が注目されており、各タスクは、フューショット参照エンティティのペアを与えられた関係の見たことのない事実を問い合わせることを目的としている。最近の試みでは、エンティティと参照の静的な表現を学習することでこの問題を解決しているが、動的な特性は無視されている（すなわち、エンティティはタスクの関係の中で多様な役割を果たし、参照はクエリに対して異なる貢献をするかもしれない）。本研究では、適応的な実体表現と参照表現を学習することで、数ショットのKG補完のための適応的な注意喚起ネットワークを提案する。具体的には、エンティティは適応的な近傍エンコーダーによってモデル化され、タスク指向の役割を識別し、参照は適応的な問い合わせ対応アグリゲータによってモデル化され、それぞれの貢献度を区別する。注意メカニズムにより、エンティティと参照の両方が、より細かい意味を捉えることができるため、より表現力の高い表現が可能になります。これは、数ショットのシナリオでの知識獲得をより予測できるようになるだろう。2つの公開データセットを用いたリンク予測の評価では、我々のアプローチが、異なる数ショットサイズで新たな最先端の結果を達成していることが示された。,https://d3i71xaburhd42.cloudfront.net/b32f5c3d2b0717fd6436068052c33dba2f59fcf2/1-Figure1-1.png
Adversarial Attack and Defense of Structured Prediction Models,"['Wenjuan Han', 'Liwen Zhang', 'Yong Jiang', 'Kewei Tu']",http://arxiv.org/abs/2010.01610v2,"Building an effective adversarial attacker and elaborating on countermeasures for adversarial attacks for natural language processing (NLP) have attracted a lot of research in recent years. However, most of the existing approaches focus on classification problems. In this paper, we investigate attacks and defenses for structured prediction tasks in NLP. Besides the difficulty of perturbing discrete words and the sentence fluency problem faced by attackers in any NLP tasks, there is a specific challenge to attackers of structured prediction models: the structured output of structured prediction models is sensitive to small perturbations in the input. To address these problems, we propose a novel and unified framework that learns to attack a structured prediction model using a sequence-to-sequence model with feedbacks from multiple reference models of the same structured prediction task. Based on the proposed attack, we further reinforce the victim model with adversarial training, making its prediction more robust and accurate. We evaluate the proposed framework in dependency parsing and part-of-speech tagging. Automatic and human evaluations show that our proposed framework succeeds in both attacking state-of-the-art structured prediction models and boosting them with adversarial training.",自然言語処理(NLP)における効果的な敵対攻撃者の構築や敵対攻撃への対策の検討は、近年多くの研究が注目されている。しかし、既存のアプローチの多くは分類問題に焦点を当てたものである。本論文では、NLPにおける構造化予測タスクに対する攻撃と防御策を検討する。離散語の摂動の難しさと、任意のNLPタスクで攻撃者が直面する文の流暢性の問題に加えて、構造化予測モデルの攻撃者には、構造化予測モデルの構造化出力が入力の小さな摂動に敏感であるという特定の課題がある。これらの問題に対処するために、我々は、同じ構造化予測タスクの複数の参照モデルからのフィードバックを持つ順序対順序モデルを用いて構造化予測モデルを攻撃するための学習を行う新規かつ統一的なフレームワークを提案する。提案した攻撃に基づいて、被害者モデルをさらに敵対的な学習で強化し、その予測をよりロバストで正確なものにする。提案フレームワークを依存性解析と品詞タグ付けで評価した。自動評価と人間による評価の結果、提案フレームワークは最先端の構造化予測モデルを攻撃することと、逆説的訓練によって予測モデルを強化することの両方に成功していることが示された。,https://d3i71xaburhd42.cloudfront.net/4f34b9a6cf0e375a35d892d90c4d599ed2cde1bd/1-Figure1-1.png
Adversarial Self-Supervised Data Free Distillation for Text Classification,"['Xinyin Ma', 'Yongliang Shen', 'Gongfan Fang', 'Chen Chen', 'Chenghao Jia', 'Weiming Lu']",http://arxiv.org/abs/2010.04883v1,"Large pre-trained transformer-based language models have achieved impressive results on a wide range of NLP tasks. In the past few years, Knowledge Distillation(KD) has become a popular paradigm to compress a computationally expensive model to a resource-efficient lightweight model. However, most KD algorithms, especially in NLP, rely on the accessibility of the original training dataset, which may be unavailable due to privacy issues. To tackle this problem, we propose a novel two-stage data-free distillation method, named Adversarial self-Supervised Data-Free Distillation (AS-DFD), which is designed for compressing large-scale transformer-based models (e.g., BERT). To avoid text generation in discrete space, we introduce a Plug & Play Embedding Guessing method to craft pseudo embeddings from the teacher's hidden knowledge. Meanwhile, with a self-supervised module to quantify the student's ability, we adapt the difficulty of pseudo embeddings in an adversarial training manner. To the best of our knowledge, our framework is the first data-free distillation framework designed for NLP tasks. We verify the effectiveness of our method on several text classification datasets.",大規模な事前学習されたトランスフォーマーベースの言語モデルは、広範囲のNLPタスクで印象的な結果を達成してきました。過去数年の間に、知識蒸留(KD)は、計算量の多いモデルをリソース効率の高い軽量モデルに圧縮するための人気のあるパラダイムとなっています。しかし、ほとんどのKDアルゴリズム、特にNLPにおいては、元の学習データセットがプライバシーの問題から利用できない可能性があるため、その利用可能性に依存している。この問題に取り組むために、我々は、大規模なトランスフォーマーベースのモデル（例えば、BERT）を圧縮するために設計された、Adversarial self-Supervised Data-Free Distillation (AS-DFD)と名付けられた新しい2段階のデータフリー蒸留法を提案する。離散空間でのテキスト生成を回避するために、教師の隠れた知識から擬似的な埋め込みを作成するPlug & Play Embedding Guessing法を導入した。一方、生徒の能力を定量化するための自己監視モジュールを用いて、疑似埋め込みの難易度を敵対的な訓練方法で適応させる。我々の知る限りでは、我々のフレームワークは、NLPタスクのために設計された最初のデータフリー蒸留フレームワークである。我々は、いくつかのテキスト分類データセットで我々の手法の有効性を検証している。,https://d3i71xaburhd42.cloudfront.net/71b769812974c2e04bcd2ffd9554015052f7cfd5/3-Figure1-1.png
Adversarial Semantic Collisions,"['Congzheng Song', 'Alexander Rush', 'Vitaly Shmatikov']",,,なし,
Affective Event Classification with Discourse-enhanced Self-training,"['Yuan Zhuang', 'Tianyu Jiang', 'Ellen Riloff']",,,なし,
ALICE: Active Learning with Contrastive Natural Language Explanations,"['Weixin Liang', 'James Zou', 'Zhou Yu']",http://arxiv.org/abs/2009.10259v1,"Training a supervised neural network classifier typically requires many annotated training samples. Collecting and annotating a large number of data points are costly and sometimes even infeasible. Traditional annotation process uses a low-bandwidth human-machine communication interface: classification labels, each of which only provides several bits of information. We propose Active Learning with Contrastive Explanations (ALICE), an expert-in-the-loop training framework that utilizes contrastive natural language explanations to improve data efficiency in learning. ALICE learns to first use active learning to select the most informative pairs of label classes to elicit contrastive natural language explanations from experts. Then it extracts knowledge from these explanations using a semantic parser. Finally, it incorporates the extracted knowledge through dynamically changing the learning model's structure. We applied ALICE in two visual recognition tasks, bird species classification and social relationship classification. We found by incorporating contrastive explanations, our models outperform baseline models that are trained with 40-100% more training data. We found that adding 1 explanation leads to similar performance gain as adding 13-30 labeled training data points.",教師付きニューラルネットワーク分類器を訓練するには、通常、多くの注釈付き訓練サンプルが必要です。多数のデータ・ポイントを収集してアノテーションを行うにはコストがかかり、時には実行不可能な場合もあります。従来のアノテーションプロセスは、低帯域幅のヒューマン・マシン・コミュニケーション・インターフェースである分類ラベルを使用しています。我々は、対照的な自然言語の説明を利用して学習効率を向上させるエキスパートインザループ学習フレームワークであるActive Learning with Contrastive Explanations (ALICE)を提案する。ALICEは、まず能動学習を用いて、最も情報量の多いラベルクラスのペアを選択し、専門家から対照的な自然言語の説明を引き出すように学習する。次に、これらの説明からセマンティックパーサを用いて知識を抽出します。最後に、学習モデルの構造を動的に変化させることで、抽出した知識を組み込みます。本研究では、鳥類の種類分類と社会関係分類の2つの視覚認識タスクにALICEを適用した。対照的な説明を組み込むことで、我々のモデルは40～100%多い学習データで学習されたベースラインモデルよりも優れた性能を発揮することがわかりました。1つの説明を追加することで、13～30個のラベル付き訓練データポイントを追加した場合と同等の性能向上が得られることがわかりました。,https://d3i71xaburhd42.cloudfront.net/b5153bde87b9939be95ec26d5d0f4b1c9071ffa4/1-Figure1-1.png
Alignment-free Cross-lingual Semantic Role Labeling,"['Rui Cai', 'Mirella Lapata']",,,なし,
Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training,"['Wanwei He', 'Min Yang', 'Rui Yan', 'Chengming Li', 'Ying Shen', 'Ruifeng Xu']",,,なし,
AmbigQA: Answering Ambiguous Open-domain Questions,"['Sewon Min', 'Julian Michael', 'Hannaneh Hajishirzi', 'Luke Zettlemoyer']",http://arxiv.org/abs/2004.10645v2,"Ambiguity is inherent to open-domain question answering; especially when exploring new topics, it can be difficult to ask questions that have a single, unambiguous answer. In this paper, we introduce AmbigQA, a new open-domain question answering task which involves finding every plausible answer, and then rewriting the question for each one to resolve the ambiguity. To study this task, we construct AmbigNQ, a dataset covering 14,042 questions from NQ-open, an existing open-domain QA benchmark. We find that over half of the questions in NQ-open are ambiguous, with diverse sources of ambiguity such as event and entity references. We also present strong baseline models for AmbigQA which we show benefit from weakly supervised learning that incorporates NQ-open, strongly suggesting our new task and data will support significant future research effort. Our data and baselines are available at https://nlp.cs.washington.edu/ambigqa.","曖昧さはオープンドメインの質問応答に固有のものであり、特に新しいトピックを探索する際には、単一の曖昧さのない答えを持つ質問をすることは困難な場合がある。この論文では、AmbigQAと呼ばれる新しいオープンドメインの質問応答タスクを紹介する。このタスクを研究するために、既存のオープンドメインQAベンチマークであるNQ-openの14,042問の問題を収録したデータセットAmbigNQを構築した。その結果、NQ-openの問題の半数以上が曖昧であり、イベントや実体参照などの多様な曖昧性の原因があることがわかった。また、NQ-openを組み込んだ弱教師付き学習の利点を示すAmbigQAの強力なベースラインモデルを提示し、今後の重要な研究努力を支援することを強く示唆した。我々のデータとベースラインは、https:/nlp.cs.washington.eduambigqaから入手可能です。",https://d3i71xaburhd42.cloudfront.net/32151ca81fa9e943ebe3028c5c2a7e76434da1bc/1-Figure1-1.png
An Analysis of Natural Language Inference Benchmarks through the Lens of Negation,"['Md Mosharaf Hossain', 'Venelin Kovatchev', 'Pranoy Dutta', 'Tiffany Kao', 'Elizabeth Wei', 'Eduardo Blanco']",,,なし,
An Effective Data Augmentation Method for Low-resource Tagging Tasks,"['BOSHENG DING', 'Linlin Liu', 'Lidong Bing', 'Canasai Kruengkrai', 'Thien Hai Nguyen', 'Shafiq Joty', 'Luo Si', 'Chunyan Miao']",,,なし,
An Embedding Model for Estimating Legislative Preferences from the Frequency and Sentiment of Tweets,"['Gregory Spell', 'Brian Guay', 'Sunshine Hillygus', 'Lawrence Carin']",,,なし,
An Empirical Investigation of Contextualized Number Prediction,"['Taylor Berg-Kirkpatrick', 'Daniel Spokoyny']",,,なし,
An Empirical Investigation Towards Efficient Multi-Domain Language Model Pre-training,"['Kristjan Arumae', 'Qing Sun', 'Parminder Bhatia']",http://arxiv.org/abs/2010.00784v1,"Pre-training large language models has become a standard in the natural language processing community. Such models are pre-trained on generic data (e.g. BookCorpus and English Wikipedia) and often fine-tuned on tasks in the same domain. However, in order to achieve state-of-the-art performance on out of domain tasks such as clinical named entity recognition and relation extraction, additional in domain pre-training is required. In practice, staged multi-domain pre-training presents performance deterioration in the form of catastrophic forgetting (CF) when evaluated on a generic benchmark such as GLUE. In this paper we conduct an empirical investigation into known methods to mitigate CF. We find that elastic weight consolidation provides best overall scores yielding only a 0.33% drop in performance across seven generic tasks while remaining competitive in bio-medical tasks. Furthermore, we explore gradient and latent clustering based data selection techniques to improve coverage when using elastic weight consolidation and experience replay methods.",大規模な言語モデルの事前学習は、自然言語処理のコミュニティでは標準となっている。このようなモデルは、一般的なデータ（例えば、BookCorpusや英語版Wikipediaなど）で事前学習され、同じドメインのタスクで微調整されることが多い。しかし、臨床的な名前付き実体認識や関係性抽出のようなアウトオブドメインのタスクで最先端の性能を達成するためには、ドメイン内での追加の事前学習が必要となる。実際には、段階的なマルチドメイン事前訓練は、GLUEのような汎用的なベンチマークで評価すると、破局的忘却（CF）という形で性能が低下する。本論文では、CFを軽減するための既知の方法を実証的に調査した。その結果、弾性的な重量連結は、7つの一般的な課題では0.33%のパフォーマンス低下しかもたらさず、生物医学的課題では競争力を維持したまま、総合的に最も良いスコアを提供することがわかった。さらに、弾性的重量連結と経験的リプレイ法を使用した場合のカバレッジを向上させるために、勾配と潜在的クラスタリングに基づいたデータ選択技術を探求している。,https://d3i71xaburhd42.cloudfront.net/23849edbce90489b29264367c855b7eb3e2275b5/1-Figure1-1.png
An Empirical Study of Generation Order for Machine Translation,"['William Chan', 'Mitchell Stern', 'Jamie Kiros', 'Jakob Uszkoreit']",http://arxiv.org/abs/1910.13437v1,"In this work, we present an empirical study of generation order for machine translation. Building on recent advances in insertion-based modeling, we first introduce a soft order-reward framework that enables us to train models to follow arbitrary oracle generation policies. We then make use of this framework to explore a large variety of generation orders, including uninformed orders, location-based orders, frequency-based orders, content-based orders, and model-based orders. Curiously, we find that for the WMT'14 English $\to$ German translation task, order does not have a substantial impact on output quality, with unintuitive orderings such as alphabetical and shortest-first matching the performance of a standard Transformer. This demonstrates that traditional left-to-right generation is not strictly necessary to achieve high performance. On the other hand, results on the WMT'18 English $\to$ Chinese task tend to vary more widely, suggesting that translation for less well-aligned language pairs may be more sensitive to generation order.",本研究では、機械翻訳における生成順序の実証的研究を行う。挿入ベースのモデリングにおける最近の進歩に基づいて、我々はまず、任意のオラクル生成ポリシーに従うようにモデルを訓練することを可能にするソフトオーダー報酬フレームワークを導入する。次に、このフレームワークを利用して、非通知オーダー、位置ベースのオーダー、周波数ベースのオーダー、コンテンツベースのオーダー、モデルベースのオーダーを含む、非常に多様な生成オーダーを探索する。不思議なことに、WMT'14の英語 $\to$ ドイツ語翻訳タスクでは、順序は出力品質に大きな影響を与えず、アルファベット順や最短順などの直感的でない順序は、標準的なトランスフォーマーの性能と一致することがわかりました。このことから、伝統的な左から右への生成は、高い性能を達成するために厳密に必要ではないことがわかります。一方、WMT'18 English $\to$ Chineseタスクの結果は、より大きく変化する傾向があり、あまり整列していない言語ペアの翻訳は、生成順序により敏感である可能性があることを示唆しています。,https://d3i71xaburhd42.cloudfront.net/3c27a725998bc8c13ae38a77c50879610120de2f/2-Figure1-1.png
An Empirical Study of Hyperbole,"['Li Kong', 'Chuanyi Li', 'Jidong Ge', 'Bin Luo', 'Vincent Ng']",,,なし,
An Empirical Study on Large-Scale Multi-Label Text Classification including Few and Zero-Shot Labels,"['Ilias Chalkidis', 'Manos Fergadiotis', 'Sotiris Kotitsas', 'Prodromos Malakasiotis', 'Nikolaos Aletras', 'Ion Androutsopoulos']",http://arxiv.org/abs/2010.01653v1,"Large-scale Multi-label Text Classification (LMTC) has a wide range of Natural Language Processing (NLP) applications and presents interesting challenges. First, not all labels are well represented in the training set, due to the very large label set and the skewed label distributions of LMTC datasets. Also, label hierarchies and differences in human labelling guidelines may affect graph-aware annotation proximity. Finally, the label hierarchies are periodically updated, requiring LMTC models capable of zero-shot generalization. Current state-of-the-art LMTC models employ Label-Wise Attention Networks (LWANs), which (1) typically treat LMTC as flat multi-label classification; (2) may use the label hierarchy to improve zero-shot learning, although this practice is vastly understudied; and (3) have not been combined with pre-trained Transformers (e.g. BERT), which have led to state-of-the-art results in several NLP benchmarks. Here, for the first time, we empirically evaluate a battery of LMTC methods from vanilla LWANs to hierarchical classification approaches and transfer learning, on frequent, few, and zero-shot learning on three datasets from different domains. We show that hierarchical methods based on Probabilistic Label Trees (PLTs) outperform LWANs. Furthermore, we show that Transformer-based approaches outperform the state-of-the-art in two of the datasets, and we propose a new state-of-the-art method which combines BERT with LWANs. Finally, we propose new models that leverage the label hierarchy to improve few and zero-shot learning, considering on each dataset a graph-aware annotation proximity measure that we introduce.",大規模マルチラベルテキスト分類(LMTC)は、自然言語処理(NLP)の応用範囲が広く、興味深い課題を提示している。まず、非常に大規模なラベルセットとLMTCデータセットのラベル分布が歪んでいるため、すべてのラベルが学習セットに十分に表現されているわけではありません。また、ラベル階層や人間のラベリングガイドラインの違いが、グラフを意識したアノテーションの近接性に影響を与える可能性がある。最後に、ラベル階層は定期的に更新されるため、ゼロショット一般化が可能なLMTCモデルが必要となる。現在の最先端のLMTCモデルは、ラベルワイズ・アテンション・ネットワーク（LWAN）を採用しており、(1)LMTCをフラットなマルチラベル分類として扱う、(2)ゼロショット学習を改善するためにラベル階層を使用することがあるが、この方法はほとんど研究されていない、(3)いくつかのNLPベンチマークで最先端の結果をもたらしている事前学習済みのトランスフォーマー（例：BERT）と組み合わせていない。ここで初めて、バニラLWANから階層的分類アプローチと伝達学習に至るまでのLMTC手法を、異なるドメインからの3つのデータセットについて、頻出、少数、ゼロショット学習で実証的に評価した。確率的ラベル木(PLT)に基づく階層的手法がLWANを凌駕することを示す。さらに、トランスフォーマーに基づくアプローチが、2つのデータセットにおいて最先端の手法を上回ることを示し、BERTとLWANを組み合わせた新しい最先端の手法を提案する。最後に、ラベル階層を活用して、我々が導入したグラフを意識したアノテーション近接度測定を各データセット上で考慮し、少数およびゼロショット学習を改善する新しいモデルを提案する。,https://d3i71xaburhd42.cloudfront.net/3186deef8c2aa3839b40c7f56b05807592cbe918/1-Figure1-1.png
An Exploration of Arbitrary-Order Sequence Labeling via Energy-Based Inference Networks,"['Lifu Tu', 'Tianyu Liu', 'Kevin Gimpel']",http://arxiv.org/abs/2010.02789v1,"Many tasks in natural language processing involve predicting structured outputs, e.g., sequence labeling, semantic role labeling, parsing, and machine translation. Researchers are increasingly applying deep representation learning to these problems, but the structured component of these approaches is usually quite simplistic. In this work, we propose several high-order energy terms to capture complex dependencies among labels in sequence labeling, including several that consider the entire label sequence. We use neural parameterizations for these energy terms, drawing from convolutional, recurrent, and self-attention networks. We use the framework of learning energy-based inference networks (Tu and Gimpel, 2018) for dealing with the difficulties of training and inference with such models. We empirically demonstrate that this approach achieves substantial improvement using a variety of high-order energy terms on four sequence labeling tasks, while having the same decoding speed as simple, local classifiers. We also find high-order energies to help in noisy data conditions.","自然言語処理の多くのタスクでは、シーケンスラベリング、意味的役割ラベリング、構文解析、機械翻訳など、構造化された出力の予測が行われています。これらの問題に深層表現学習を適用する研究者が増えているが、これらのアプローチの構造化要素は通常非常に単純である。本研究では、シーケンスラベリングにおけるラベル間の複雑な依存関係を捉えるために、ラベルシーケンス全体を考慮したいくつかの高次エネルギー項を提案する。これらのエネルギー項には、畳み込みネットワーク、リカレントネットワーク、自己注意ネットワークからのニューラルパラメタリゼーションを用いる。我々は、このようなモデルでの学習と推論の困難さに対処するために、学習エネルギーベースの推論ネットワーク（Tu and Gimpel, 2018）のフレームワークを使用する。我々は、このアプローチが、単純な局所的な分類器と同じ解読速度を持ちながら、4つのシーケンスラベリングタスク上で様々な高次エネルギー項を用いて実質的な改善を達成していることを経験的に実証している。また、高次エネルギーがノイズの多いデータ条件でも有効であることも明らかにした。",https://d3i71xaburhd42.cloudfront.net/fa131ed1529c2d4d49ab1c6a8c0c964e079b376a/4-Table1-1.png
An Imitation Game for Learning Semantic Parsers from User Interaction,"['Ziyu Yao', 'Yiqi Tang', 'Wen-tau Yih', 'Huan Sun', 'Yu Su']",http://arxiv.org/abs/2005.00689v3,"Despite the widely successful applications, bootstrapping and fine-tuning semantic parsers are still a tedious process with challenges such as costly data annotation and privacy risks. In this paper, we suggest an alternative, human-in-the-loop methodology for learning semantic parsers directly from users. A semantic parser should be introspective of its uncertainties and prompt for user demonstration when uncertain. In doing so it also gets to imitate the user behavior and continue improving itself autonomously with the hope that eventually it may become as good as the user in interpreting their questions. To combat the sparsity of demonstration, we propose a novel annotation-efficient imitation learning algorithm, which iteratively collects new datasets by mixing demonstrated states and confident predictions and re-trains the semantic parser in a Dataset Aggregation fashion (Ross et al., 2011). We provide a theoretical analysis of its cost bound and also empirically demonstrate its promising performance on the text-to-SQL problem. Code will be available at https://github.com/sunlab-osu/MISP.","広く応用されているにもかかわらず、ブートストラップと意味パーサーの微調整は、コストのかかるデータアノテーションやプライバシーリスクなどの課題があり、いまだに面倒なプロセスである。この論文では、ユーザーから直接セマンティックパーサーを学習するための代替的なヒューマンインザループの方法論を提案する。意味パーサーは、その不確実性を内省的に捉え、不確実性がある場合には、ユーザーのデモを促すべきである。そうすることで、ユーザーの行動を真似し、最終的にはユーザーの質問を解釈するのが上手になることを期待して、自律的に自分自身を改善し続けることができます。これは、実証された状態と自信を持った予測を混合して新しいデータセットを反復的に収集し、Dataset Aggregationの方法で意味解析器を再訓練するものである(Ross et al., 2011)。本研究では、そのコスト境界の理論的な分析を行い、テキストからSQLへの変換問題において有望な性能を実証的に示します。コードは https:/github.comsunlab-osuMISP で公開されます。",https://d3i71xaburhd42.cloudfront.net/65dd4ff4074812ef4123ecfca9609ef3db87f9de/1-Figure1-1.png
An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction,"['Bhargavi Paranjape', 'Mandar Joshi', 'John Thickstun', 'Hannaneh Hajishirzi', 'Luke Zettlemoyer']",http://arxiv.org/abs/2005.00652v2,"Decisions of complex language understanding models can be rationalized by limiting their inputs to a relevant subsequence of the original text. A rationale should be as concise as possible without significantly degrading task performance, but this balance can be difficult to achieve in practice. In this paper, we show that it is possible to better manage this trade-off by optimizing a bound on the Information Bottleneck (IB) objective. Our fully unsupervised approach jointly learns an explainer that predicts sparse binary masks over sentences, and an end-task predictor that considers only the extracted rationale. Using IB, we derive a learning objective that allows direct control of mask sparsity levels through a tunable sparse prior. Experiments on ERASER benchmark tasks demonstrate significant gains over norm-minimization techniques for both task performance and agreement with human rationales. Furthermore, we find that in the semi-supervised setting, a modest amount of gold rationales (25% of training examples) closes the gap with a model that uses the full input.",複雑な言語理解モデルの決定は、その入力を原文の関連する部分的な文章に限定することで合理化することができる。合理化は、タスクのパフォーマンスを著しく低下させることなく、可能な限り簡潔でなければならないが、このバランスをとることは実際には難しい。本稿では、情報ボトルネック(IB)目標の境界を最適化することで、このトレードオフをより良く管理できることを示す。我々の完全教師なしアプローチは、文上の疎なバイナリマスクを予測する説明器と、抽出された理由付けのみを考慮するエンドタスク予測器を共同で学習する。IBを用いて、我々は、調整可能な疎な事前処理によってマスクの疎さレベルを直接制御できる学習目的を導出した。ERASERベンチマークタスクでの実験では、タスク性能と人間の論理的根拠との一致の両方において、ノルム最小化手法に比べて有意に向上することが示された。さらに、半教師付きの設定では、適度な量の金の理論的根拠（訓練例の25％）が、完全な入力を使用するモデルとのギャップを埋めることがわかった。,https://d3i71xaburhd42.cloudfront.net/c9aeb7e31b16b7273a80ae748b3ff48105928147/1-Figure1-1.png
An Unsupervised Joint System for Text Generation from Knowledge Graphs and Semantic Parsing,"['Martin Schmitt', 'Sahand Sharifzadeh', 'Volker Tresp', 'Hinrich Schütze']",http://arxiv.org/abs/1904.09447v3,"Knowledge graph (KG) schemas can vary greatly from one domain to another. Therefore supervised approaches to graph-to-text generation and text-to-graph knowledge extraction (semantic parsing) will always suffer from a shortage of domain-specific parallel graph-text data, while adapting a model trained on a different domain is often impossible due to little or no overlap in entities and relations. This situation calls for an approach that (1) does not need large amounts of annotated data and (2) is easy to adapt to new KG schemas. To this end, we present the first approach to fully unsupervised text generation from KGs and KG generation from text. Inspired by recent work on unsupervised machine translation, we serialize a KG as a sequence of facts and frame both tasks as sequence translation. By means of a shared sequence encoder and decoder, our model learns to map both graphs and texts into a joint semantic space and thus generalizes over different surface representations with the same meaning. We evaluate our approach on WebNLG v2.1 and a new benchmark leveraging scene graphs from Visual Genome. Our system outperforms strong baselines for both text$\leftrightarrow$graph tasks without any manual adaptation from one dataset to the other. In additional experiments, we investigate the impact of using different unsupervised objectives.",知識グラフ（KG）スキーマは、あるドメインによって大きく異なる可能性があります。そのため、グラフからテキストへの生成やテキストからグラフへの知識抽出（意味解析）に対する教師付きアプローチは、常にドメイン固有の並列グラフ-テキストデータの不足に悩まされることになります。このような状況では、(1)大量のアノテーションデータを必要とせず、(2)新しいKGスキーマへの適応が容易なアプローチが必要となる。そこで、本研究では、KGからの完全教師なしテキスト生成とテキストからのKG生成を実現する初のアプローチを提案する。教師なし機械翻訳の最近の研究に触発されて、我々はKGを事実のシーケンスとして直列化し、両方のタスクをシーケンス翻訳としてフレーム化する。シーケンスエンコーダーとデコーダーを共有することで、我々のモデルは、グラフとテキストの両方を共同意味空間にマッピングすることを学習し、同じ意味を持つ異なる表面表現の上で一般化する。我々はWebNLG v2.1とVisual Genomeのシーングラフを利用した新しいベンチマークで我々のアプローチを評価している。我々のシステムは、一方のデータセットから他方のデータセットへの手動適応なしに、両方のtext$\leftrightarrow$graphタスクのための強力なベースラインを上回りました。追加の実験では、異なる教師なし目的語を使用することの影響を調査しています。,https://d3i71xaburhd42.cloudfront.net/26e8b54c0e9f3c25e78a56b738deb52a1333e9d1/1-Figure1-1.png
An Unsupervised Sentence Embedding Method by Mutual Information Maximization,"['Yan Zhang', 'Ruidan He', 'ZUOZHU LIU', 'Kwan Hui Lim', 'Lidong Bing']",http://arxiv.org/abs/2009.12061v1,"BERT is inefficient for sentence-pair tasks such as clustering or semantic search as it needs to evaluate combinatorially many sentence pairs which is very time-consuming. Sentence BERT (SBERT) attempted to solve this challenge by learning semantically meaningful representations of single sentences, such that similarity comparison can be easily accessed. However, SBERT is trained on corpus with high-quality labeled sentence pairs, which limits its application to tasks where labeled data is extremely scarce. In this paper, we propose a lightweight extension on top of BERT and a novel self-supervised learning objective based on mutual information maximization strategies to derive meaningful sentence embeddings in an unsupervised manner. Unlike SBERT, our method is not restricted by the availability of labeled data, such that it can be applied on different domain-specific corpus. Experimental results show that the proposed method significantly outperforms other unsupervised sentence embedding baselines on common semantic textual similarity (STS) tasks and downstream supervised tasks. It also outperforms SBERT in a setting where in-domain labeled data is not available, and achieves performance competitive with supervised methods on various tasks.",BERT は、クラスタリングや意味検索のような文対のタスクでは、多くの文対を組み合わせて評価する必要があり、非常に時間がかかるため、非効率的である。Sentence BERT (SBERT) は、類似性比較が容易に行えるように、意味的に意味のある単一文の表現を学習することで、この課題を解決しようとした。しかし、SBERTは高品質のラベル付き文対を持つコーパスで学習されるため、ラベル付きデータが非常に少ないタスクへの応用に限界がある。本論文では、教師なしで意味のある文の埋め込みを導出するために、BERTの上に軽量な拡張機能と、相互情報最大化戦略に基づく新しい自己教師付き学習目的を提案する。SBERTとは異なり、我々の手法はラベル付きデータの利用可能性に制限されないため、異なるドメイン固有のコーパスに適用することができる。実験結果は、提案手法が、共通の意味的テキスト類似性（STS）タスクと下流の教師付きタスクにおいて、他の教師なし文埋め込みベースラインよりも有意に優れていることを示している。また、領域内ラベル付きデータが利用できない環境では、SBERTよりも優れた性能を発揮し、様々なタスクにおいて教師付き手法と競合する性能を達成した。,https://d3i71xaburhd42.cloudfront.net/c9e6a3898f6b2fd773e53dfce17adc8f8c6c1828/4-Figure1-1.png
Analogous Process Structure Induction for Sub-event Sequence Prediction,"['Hongming Zhang', 'Muhao Chen', 'Haoyu Wang', 'Yangqiu Song', 'Dan Roth']",http://arxiv.org/abs/2010.08525v1,"Computational and cognitive studies of event understanding suggest that identifying, comprehending, and predicting events depend on having structured representations of a sequence of events and on conceptualizing (abstracting) its components into (soft) event categories. Thus, knowledge about a known process such as ""buying a car"" can be used in the context of a new but analogous process such as ""buying a house"". Nevertheless, most event understanding work in NLP is still at the ground level and does not consider abstraction. In this paper, we propose an Analogous Process Structure Induction APSI framework, which leverages analogies among processes and conceptualization of sub-event instances to predict the whole sub-event sequence of previously unseen open-domain processes. As our experiments and analysis indicate, APSI supports the generation of meaningful sub-event sequences for unseen processes and can help predict missing events.",イベント理解に関する計算上および認知上の研究では、イベントの識別、理解、予測は、一連のイベントの構造化された表現を持つこと、およびその構成要素を（ソフトな）イベント・カテゴリーに概念化（抽象化）することに依存していることが示唆されている。このように、「車を買う」というような既知のプロセスに関する知識は、「家を買う」というような新しい、しかし類似したプロセスの文脈で使用することができる。それにもかかわらず、NLPにおけるイベント理解のほとんどの作業は、まだ地上レベルのものであり、抽象化を考慮していない。本論文では、プロセス間の類似性とサブイベントインスタンスの概念化を利用して、これまで見えていなかったオープンドメインプロセスのサブイベントシーケンス全体を予測するAPSIフレームワークを提案する。我々の実験と分析から明らかなように、APSIは未見プロセスのための意味のあるサブイベントシーケンスの生成を支援し、欠落イベントの予測を支援することができる。,https://d3i71xaburhd42.cloudfront.net/88119224c18e891c9dd550b2ced8ff5049be3849/1-Figure1-1.png
Analyzing Individual Neurons in Pre-trained Language Models,"['Nadir Durrani', 'Hassan Sajjad', 'Fahim Dalvi', 'Yonatan Belinkov']",http://arxiv.org/abs/2010.02695v1,"While a lot of analysis has been carried to demonstrate linguistic knowledge captured by the representations learned within deep NLP models, very little attention has been paid towards individual neurons.We carry outa neuron-level analysis using core linguistic tasks of predicting morphology, syntax and semantics, on pre-trained language models, with questions like: i) do individual neurons in pre-trained models capture linguistic information? ii) which parts of the network learn more about certain linguistic phenomena? iii) how distributed or focused is the information? and iv) how do various architectures differ in learning these properties? We found small subsets of neurons to predict linguistic tasks, with lower level tasks (such as morphology) localized in fewer neurons, compared to higher level task of predicting syntax. Our study also reveals interesting cross architectural comparisons. For example, we found neurons in XLNet to be more localized and disjoint when predicting properties compared to BERT and others, where they are more distributed and coupled.",これまで、ディープNLPモデルの中で学習された表現によって捕捉された言語知識を実証するために多くの分析が行われてきたが、個々のニューロンについてはほとんど注目されてこなかった。 本研究では、事前に学習した言語モデルを用いて、形態論、構文、意味論の予測という主要な言語タスクを用いて、ニューロンレベルでの解析を行った。 i) 事前に学習したモデルの中の個々のニューロンは言語情報を獲得しているのか、ii) ネットワークのどの部分が特定の言語現象についてより多くのことを学習しているのか、iii) 情報はどの程度分散しているのか、あるいは集中しているのか、iv) これらの特性を学習する際に、様々なアーキテクチャはどのように異なっているのか、という疑問を持つ。その結果、言語タスクを予測するためのニューロンのサブセットが少ないことがわかりました。また、本研究では、興味深いアーキテクチャ間の比較も明らかにしています。例えば、XLNetのニューロンは、BERTやその他のニューロンと比較して、特性を予測する際に、より局在化され、不連続であることがわかりました。,https://d3i71xaburhd42.cloudfront.net/9f0272bb258506fdc0ee7d8951593914d4f9c39d/4-Table1-1.png
Analyzing Redundancy in Pretrained Transformer Models,"['Fahim Dalvi', 'Hassan Sajjad', 'Nadir Durrani', 'Yonatan Belinkov']",http://arxiv.org/abs/2004.04010v2,"Transformer-based deep NLP models are trained using hundreds of millions of parameters, limiting their applicability in computationally constrained environments. In this paper, we study the cause of these limitations by defining a notion of Redundancy, which we categorize into two classes: General Redundancy and Task-specific Redundancy. We dissect two popular pretrained models, BERT and XLNet, studying how much redundancy they exhibit at a representation-level and at a more fine-grained neuron-level. Our analysis reveals interesting insights, such as: i) 85% of the neurons across the network are redundant and ii) at least 92% of them can be removed when optimizing towards a downstream task. Based on our analysis, we present an efficient feature-based transfer learning procedure, which maintains 97% performance while using at-most 10% of the original neurons.",変圧器ベースのディープNLPモデルは、何億ものパラメータを使って学習されるため、計算量に制約のある環境での適用が制限されている。この論文では、冗長性の概念を定義することで、これらの制限の原因を研究しています。一般的な冗長性とタスク固有の冗長性の2つのクラスに分類する。我々は、2つの一般的な事前学習モデルであるBERTとXLNetを解剖し、表現レベルとより細かいニューロンレベルでどの程度の冗長性を示しているかを研究する。我々の分析により、次のような興味深い洞察が得られた：i)ネットワーク全体のニューロンの85％が冗長であること、ii)下流のタスクに向けて最適化する際に、少なくとも92％のニューロンが除去できること、などである。我々の分析に基づいて、我々は効率的な特徴ベースの伝達学習手順を提示し、元のニューロンの少なくとも10%を使用しながら97%の性能を維持する。,
Annotating Temporal Dependency Graphs via Crowdsourcing,"['Jiarui Yao', 'Haoling Qiu', 'Bonan Min', 'Nianwen Xue']",,,なし,
AnswerFact: Fact Checking in Product Question Answering,"['Wenxuan Zhang', 'Yang Deng', 'Jing Ma', 'Wai Lam']",,,なし,
Are All Good Word Vector Spaces Isomorphic?,"['Ivan Vulić', 'Sebastian Ruder', 'Anders Søgaard']",http://arxiv.org/abs/2004.04070v1,"Existing algorithms for aligning cross-lingual word vector spaces assume that vector spaces are approximately isomorphic. As a result, they perform poorly or fail completely on non-isomorphic spaces. Such non-isomorphism has been hypothesised to result almost exclusively from typological differences between languages. In this work, we ask whether non-isomorphism is also crucially a sign of degenerate word vector spaces. We present a series of experiments across diverse languages which show that, besides inherent typological differences, variance in performance across language pairs can largely be attributed to the size of the monolingual resources available, and to the properties and duration of monolingual training (e.g. ""under-training"").",言語横断的な単語ベクトル空間を整列させるための既存のアルゴリズムは、ベクトル空間がほぼ同型であることを前提としています。その結果、非同型空間では性能が劣るか、完全に失敗してしまいます。このような非同型性は、ほとんどの場合、言語間の類型論的な違いに起因すると考えられてきた。この研究では、非同型性が退化した単語ベクトル空間の兆候であるかどうかを問う。我々は、多様な言語を対象とした一連の実験を行い、固有の類型論的差異の他に、言語ペア間でのパフォーマンスのばらつきが、利用可能な単言語資源の大きさや、単言語トレーニングの特性や期間（例えば、「アンダートレーニング」）に大きく起因することを示した。,https://d3i71xaburhd42.cloudfront.net/5d2165fbf395d2456b5f13a7e35b6ade08c4db01/1-Figure1-1.png
Argument Pair Extraction from Peer Review and Rebuttal via Multi-task Learning,"['Liying Cheng', 'Lidong Bing', 'Qian Yu', 'Wei Lu', 'Luo Si']",,,なし,
Asking without Telling: Exploring Latent Ontologies in Contextual Representations,"['Julian Michael', 'Jan A. Botha', 'Ian Tenney']",http://arxiv.org/abs/2004.14513v2,"The success of pretrained contextual encoders, such as ELMo and BERT, has brought a great deal of interest in what these models learn: do they, without explicit supervision, learn to encode meaningful notions of linguistic structure? If so, how is this structure encoded? To investigate this, we introduce latent subclass learning (LSL): a modification to existing classifier-based probing methods that induces a latent categorization (or ontology) of the probe's inputs. Without access to fine-grained gold labels, LSL extracts emergent structure from input representations in an interpretable and quantifiable form. In experiments, we find strong evidence of familiar categories, such as a notion of personhood in ELMo, as well as novel ontological distinctions, such as a preference for fine-grained semantic roles on core arguments. Our results provide unique new evidence of emergent structure in pretrained encoders, including departures from existing annotations which are inaccessible to earlier methods.",ELMo や BERT などの事前学習型文脈エンコーダーの成功により、これらのモデルが何を学習するのかという点に大きな関心が寄せられている。もしそうだとしたら、この構造はどのように符号化されているのだろうか？この研究のために、我々は潜在サブクラス学習（LSL）を導入した。これは、既存の分類器ベースのプロービング手法を改良したもので、プローブの入力の潜在分類（またはオントロジー）を誘導するものである。LSLは、細かい粒度のゴールドラベルにアクセスすることなく、解釈可能で定量化可能な形で入力表現から創発的な構造を抽出する。実験では、ELMoにおける人称の概念のようななじみのあるカテゴリの強い証拠と、核心的な議論における細かい意味的役割の優先などの新しい存在論的な区別が見出された。本研究の結果は、従来の方法ではアクセスできなかった既存のアノテーションからの逸脱を含む、事前に学習されたエンコーダの創発的な構造を示すユニークな新しい証拠を提供するものである。,https://d3i71xaburhd42.cloudfront.net/196c558ce126f5f7d66df4ea52e2442848fc65be/1-Figure1-1.png
Aspect-Based Sentiment Analysis by Aspect-Sentiment Joint Embedding,"['Jiaxin Huang', 'Yu Meng', 'Fang Guo', 'Heng Ji', 'Jiawei Han']",,,なし,
Assessing Phrasal Representation and Composition in Transformers,"['Lang Yu', 'Allyson Ettinger']",http://arxiv.org/abs/2010.03763v2,"Deep transformer models have pushed performance on NLP tasks to new limits, suggesting sophisticated treatment of complex linguistic inputs, such as phrases. However, we have limited understanding of how these models handle representation of phrases, and whether this reflects sophisticated composition of phrase meaning like that done by humans. In this paper, we present systematic analysis of phrasal representations in state-of-the-art pre-trained transformers. We use tests leveraging human judgments of phrase similarity and meaning shift, and compare results before and after control of word overlap, to tease apart lexical effects versus composition effects. We find that phrase representation in these models relies heavily on word content, with little evidence of nuanced composition. We also identify variations in phrase representation quality across models, layers, and representation types, and make corresponding recommendations for usage of representations from these models.",ディープトランスフォーマーモデルは、NLPタスクのパフォーマンスを新たな限界に押し上げ、フレーズのような複雑な言語入力を高度に処理することを示唆している。しかし、これらのモデルがどのようにフレーズ表現を扱うのか、また、それが人間が行うような高度なフレーズの意味構成を反映しているのかについては、ほとんど理解されていない。本論文では、最新の事前学習型変換器におけるフレーズ表現の系統的な解析を行う。このような場合には、「フレーズの類似性」と「意味のシフト」の人間の判断を利用したテストを行い、単語の重複を制御する前と後の結果を比較することで、語彙的効果と構成効果を区別しています。その結果、これらのモデルにおけるフレーズ表現は、単語の内容に大きく依存しており、微妙な構成の証拠はほとんどないことがわかりました。また、モデル、レイヤー、表現タイプ間でのフレーズ表現の品質のばらつきを明らかにし、これらのモデルからの表現の使用について対応する推奨を行う。,https://d3i71xaburhd42.cloudfront.net/a129bed0b735918da1c797a27ebb43a541971c64/3-Table1-1.png
Assessing the Helpfulness of Learning Materials with Inference-Based Learner-Like Agent,"['Yun-Hsuan Jen', 'Chieh-Yang Huang', 'MeiHua Chen', 'Ting-Hao Huang', 'Lun-Wei Ku']",http://arxiv.org/abs/2010.02179v1,"Many English-as-a-second language learners have trouble using near-synonym words (e.g., small vs.little; briefly vs.shortly) correctly, and often look for example sentences to learn how two nearly synonymous terms differ. Prior work uses hand-crafted scores to recommend sentences but has difficulty in adopting such scores to all the near-synonyms as near-synonyms differ in various ways. We notice that the helpfulness of the learning material would reflect on the learners' performance. Thus, we propose the inference-based learner-like agent to mimic learner behavior and identify good learning materials by examining the agent's performance. To enable the agent to behave like a learner, we leverage entailment modeling's capability of inferring answers from the provided materials. Experimental results show that the proposed agent is equipped with good learner-like behavior to achieve the best performance in both fill-in-the-blank (FITB) and good example sentence selection tasks. We further conduct a classroom user study with college ESL learners. The results of the user study show that the proposed agent can find out example sentences that help students learn more easily and efficiently. Compared to other models, the proposed agent improves the score of more than 17% of students after learning.",多くの英語学習者は、同義語に近い単語（例：small vs.little、bliefly vs.shortly）を正しく使うことができず、2つのほぼ同義語がどのように違うのかを学ぶために例文を探すことがよくあります。これまでの研究では、文を推薦するために手作りのスコアを使用していましたが、同義語は様々な方法で異なるため、すべての同義語にそのようなスコアを採用することは困難でした。また，学習教材の有用性が学習者のパフォーマンスに反映されることがわかった．そこで、本研究では、学習者の行動を模倣し、学習者のパフォーマンスを調べることで、良い教材を特定する推論ベースの学習者ライクエージェントを提案する。学習者の行動を模倣するために、提供された教材から答えを推論するエンテラインメントモデルの機能を利用する。実験の結果、本研究で提案したエージェントは、FITB課題と例文選択課題の両方において、学習者のような振る舞いをすることで最高のパフォーマンスを発揮することがわかった。さらに、大学のESL学習者を対象とした教室でのユーザー研究を実施した。その結果、提案エージェントは学習者がより簡単に効率よく学習するための例文を見つけることができた。他のモデルと比較して、提案エージェントは学習後の学生のスコアを17%以上改善することがわかった。,
Attention Is All You Need for Chinese Word Segmentation,"['Sufeng Duan', 'Hai Zhao']",http://arxiv.org/abs/1910.14537v3,"Taking greedy decoding algorithm as it should be, this work focuses on further strengthening the model itself for Chinese word segmentation (CWS), which results in an even more fast and more accurate CWS model. Our model consists of an attention only stacked encoder and a light enough decoder for the greedy segmentation plus two highway connections for smoother training, in which the encoder is composed of a newly proposed Transformer variant, Gaussian-masked Directional (GD) Transformer, and a biaffine attention scorer. With the effective encoder design, our model only needs to take unigram features for scoring. Our model is evaluated on SIGHAN Bakeoff benchmark datasets. The experimental results show that with the highest segmentation speed, the proposed model achieves new state-of-the-art or comparable performance against strong baselines in terms of strict closed test setting.",本研究では、貪欲な復号化アルゴリズムをそのままに、中国語単語分割(CWS)のためのモデル自体をさらに強化し、より高速で正確なCWSモデルを実現することに焦点を当てています。我々のモデルは、注目のみのスタック型エンコーダと、貪欲なセグメンテーションのための十分に軽いデコーダ、さらに滑らかなトレーニングのための2つのハイウェイ接続で構成されており、エンコーダは、新たに提案されたトランスのバリアント、ガウシアンマスクされた方向性（GD）トランス、およびバイアフィン注目スコアラーで構成されています。効果的なエンコーダの設計により、我々のモデルはスコアリングのために一グラムの特徴を取るだけで済むようになった。我々のモデルをSIGHAN Bakeoffベンチマークデータセットで評価した。実験結果は、最高のセグメンテーション速度で、提案モデルは厳密なクローズドテスト設定の観点から、強力なベースラインと比較して、新しい最先端の性能を達成するか、同等の性能を達成することを示している。,https://d3i71xaburhd42.cloudfront.net/d4f68b2c033a79fc02f30d8cffb6cbc532cdbd51/2-Table1-1.png
Attention is Not Only a Weight: Analyzing Transformers with Vector Norms,"['Goro Kobayashi', 'Tatsuki Kuribayashi', 'Sho Yokoi', 'Kentaro Inui']",http://arxiv.org/abs/2004.10102v2,"Attention is a key component of Transformers, which have recently achieved considerable success in natural language processing. Hence, attention is being extensively studied to investigate various linguistic capabilities of Transformers, focusing on analyzing the parallels between attention weights and specific linguistic phenomena. This paper shows that attention weights alone are only one of the two factors that determine the output of attention and proposes a norm-based analysis that incorporates the second factor, the norm of the transformed input vectors. The findings of our norm-based analyses of BERT and a Transformer-based neural machine translation system include the following: (i) contrary to previous studies, BERT pays poor attention to special tokens, and (ii) reasonable word alignment can be extracted from attention mechanisms of Transformer. These findings provide insights into the inner workings of Transformers.",注意はトランスフォーマーの重要な構成要素であり、最近では自然言語処理の分野で大きな成功を収めている。そのため、トランスフォーマーの様々な言語能力を調べるために、注目度と特定の言語現象との類似性を分析することに焦点を当てて、注目度の研究が盛んに行われている。本論文では、注目度の重みだけでは注目度の出力を決定する2つの要因のうちの1つに過ぎないことを示し、2つ目の要因である変換された入力ベクトルのノルムを組み込んだノルムベースの分析を提案する。BERTとトランスフォーマーベースの神経機械翻訳システムのノルムベース分析の結果には、以下のようなものがある。(i)先行研究とは異なり、BERTは特殊なトークンにはあまり注意を払っていないこと、(ii)Transformerの注意メカニズムから合理的な単語アライメントが抽出できること、などである。これらの知見は、トランスフォーマーの内部の仕組みについての洞察を提供するものである。,
AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue,"['Jaehun Jung', 'Bokyung Son', 'Sungwon Lyu']",,,なし,
Augmented Natural Language for Generative Sequence Labeling,"['Ben Athiwaratkun', 'Cícero Nogueira dos Santos', 'Jason Krone', 'Bing Xiang']",http://arxiv.org/abs/2009.13272v1,"We propose a generative framework for joint sequence labeling and sentence-level classification. Our model performs multiple sequence labeling tasks at once using a single, shared natural language output space. Unlike prior discriminative methods, our model naturally incorporates label semantics and shares knowledge across tasks. Our framework is general purpose, performing well on few-shot, low-resource, and high-resource tasks. We demonstrate these advantages on popular named entity recognition, slot labeling, and intent classification benchmarks. We set a new state-of-the-art for few-shot slot labeling, improving substantially upon the previous 5-shot ($75.0\% \rightarrow 90.9\%$) and 1-shot ($70.4\% \rightarrow 81.0\%$) state-of-the-art results. Furthermore, our model generates large improvements ($46.27\% \rightarrow 63.83\%$) in low-resource slot labeling over a BERT baseline by incorporating label semantics. We also maintain competitive results on high-resource tasks, performing within two points of the state-of-the-art on all tasks and setting a new state-of-the-art on the SNIPS dataset.",我々は、シーケンスラベリングと文レベル分類を共同で行うための生成的フレームワークを提案する。我々のモデルは、共有された単一の自然言語出力空間を用いて、複数のシーケンスラベリングタスクを一度に実行する。先行する識別的手法とは異なり、我々のモデルはラベルの意味論を自然に取り入れ、タスク間で知識を共有する。我々のフレームワークは汎用的であり、少ないショット、低リソース、高リソースのタスクで良好なパフォーマンスを発揮する。これらの利点を、一般的な名前付き実体認識、スロットラベリング、インテント分類のベンチマークで実証する。我々は、少数ショットのスロットラベリングのための新しい最先端を設定し、以前の5ショット($75.0% \rightarrow 90.9%$)と1ショット($70.4% \rightarrow 81.0%$)の最先端の結果を大幅に改善した。さらに、我々のモデルは、ラベル・セマンティクスを組み込むことにより、BERT ベースライン上の低リソース・スロット・ ラベリングにおいて大きな改善（$46.27\% \rightarrow 63.83\%$）を生成する。また、高リソースのタスクにおいても競争力のある結果を維持し、すべてのタスクにおいて最新技術の2ポイント以内の性能を発揮し、SNIPSデータセットにおいて新たな最新技術を設定した。,https://d3i71xaburhd42.cloudfront.net/15f002dde348b82817fa2a59e7ed56e6e3ec6972/2-Figure1-1.png
Authorship Attribution for Neural Text Generation,"['Adaku Uchendu', 'Thai Le', 'Kai Shu', 'Dongwon Lee']",,,なし,
Automatic Extraction of Rules Governing Morphological Agreement,"['Aditi Chaudhary', 'Antonios Anastasopoulos', 'Adithya Pratapa', 'David R. Mortensen', 'Zaid Sheikh', 'Yulia Tsvetkov', 'Graham Neubig']",http://arxiv.org/abs/2010.01160v2,"Creating a descriptive grammar of a language is an indispensable step for language documentation and preservation. However, at the same time it is a tedious, time-consuming task. In this paper, we take steps towards automating this process by devising an automated framework for extracting a first-pass grammatical specification from raw text in a concise, human- and machine-readable format. We focus on extracting rules describing agreement, a morphosyntactic phenomenon at the core of the grammars of many of the world's languages. We apply our framework to all languages included in the Universal Dependencies project, with promising results. Using cross-lingual transfer, even with no expert annotations in the language of interest, our framework extracts a grammatical specification which is nearly equivalent to those created with large amounts of gold-standard annotated data. We confirm this finding with human expert evaluations of the rules that our framework produces, which have an average accuracy of 78%. We release an interface demonstrating the extracted rules at https://neulab.github.io/lase/.",言語の記述文法を作成することは、言語の文書化や保存に不可欠なステップです。しかし、その一方で、面倒で時間のかかる作業でもある。本論文では、このプロセスの自動化に向けて、生のテキストから簡潔で、人間が読みやすく、機械でも読める形式で第一段階の文法仕様を抽出するための自動フレームワークを考案する。我々は、世界の多くの言語の文法の中核をなす形態統語現象である一致を記述する規則を抽出することに焦点を当てている。我々のフレームワークをUniversal Dependenciesプロジェクトに含まれる全ての言語に適用し、有望な結果を得た。言語間の移動を利用して、興味のある言語に専門家のアノテーションがなくても、私たちのフレームワークは、大量のゴールドスタンダードのアノテーションデータで作成されたものとほぼ同等の文法仕様を抽出します。我々は、我々のフレームワークが生成するルールの人間の専門家による評価でこの発見を確認しています。私たちは、抽出されたルールを示すインターフェイスを https:/neulab.github.iolase で公開しています。,https://d3i71xaburhd42.cloudfront.net/de7d0c87794c3de6f8ab2c753ecc398c18c26631/2-Figure1-1.png
Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing,"['Brian Thompson', 'Matt Post']",http://arxiv.org/abs/2004.14564v1,"We propose the use of a sequence-to-sequence paraphraser for automatic machine translation evaluation. The paraphraser takes a human reference as input and then force-decodes and scores an MT system output. We propose training the aforementioned paraphraser as a multilingual NMT system, treating paraphrasing as a zero-shot ""language pair"" (e.g., Russian to Russian). We denote our paraphraser ""unbiased"" because the mode of our model's output probability is centered around a copy of the input sequence, which in our case represent the best case scenario where the MT system output matches a human reference. Our method is simple and intuitive, and our single model (trained in 39 languages) outperforms or statistically ties with all prior metrics on the WMT19 segment-level shared metrics task in all languages, excluding Gujarati where the model had no training data. We also explore using our model conditioned on the source instead of the reference, and find that it outperforms every quality estimation as a metric system from the WMT19 shared task on quality estimation by a statistically significant margin in every language pair.","本研究では、機械翻訳の自動評価のために、シーケンス間の言い換え機能を利用することを提案する。この言い換え機能は、人間のリファレンスを入力とし、MTシステムの出力を強制的に復号化してスコア化するものである。我々は、前述の言い換え器を多言語NMTシステムとして学習することを提案し、言い換えをゼロショットの「言語ペア」(例えば、ロシア語からロシア語)として扱う。我々は、我々のモデルの出力確率のモードが入力シーケンスのコピーを中心にしているので、我々の場合、MTシステムの出力が人間の参照と一致する最良のケースのシナリオを表しているので、我々は我々の言い換え器を ""不偏 ""と呼ぶ。我々の方法は単純で直感的であり、我々の単一モデル（39言語で訓練された）は、モデルが訓練データを持たないグジャラート語を除いて、すべての言語でWMT19セグメントレベルの共有メトリクスタスクにおいて、すべての先行メトリクスよりも優れているか、または統計的に一致していた。また、参照ではなくソースに条件を付けて我々のモデルを使用することを検討した結果、すべての言語ペアにおいて、WMT19共有タスクのメトリックシステムとしてのすべての品質推定を統計的に有意なマージンで上回ることがわかった。",https://d3i71xaburhd42.cloudfront.net/01508f386eb2ca5181fde7bb6da4920e250d7498/1-Figure1-1.png
AutoQA: From Databases To Q&A Semantic Parsers With Only Synthetic Training Data,"['Silei Xu', 'Sina Semnani', 'Giovanni Campagna', 'Monica Lam']",http://arxiv.org/abs/2010.04806v1,"We propose AutoQA, a methodology and toolkit to generate semantic parsers that answer questions on databases, with no manual effort. Given a database schema and its data, AutoQA automatically generates a large set of high-quality questions for training that covers different database operations. It uses automatic paraphrasing combined with template-based parsing to find alternative expressions of an attribute in different parts of speech. It also uses a novel filtered auto-paraphraser to generate correct paraphrases of entire sentences. We apply AutoQA to the Schema2QA dataset and obtain an average logical form accuracy of 62.9% when tested on natural questions, which is only 6.4% lower than a model trained with expert natural language annotations and paraphrase data collected from crowdworkers. To demonstrate the generality of AutoQA, we also apply it to the Overnight dataset. AutoQA achieves 69.8% answer accuracy, 16.4% higher than the state-of-the-art zero-shot models and only 5.2% lower than the same model trained with human data.",我々は、データベース上の質問に答えるセマンティックパーサーを生成するための方法論とツールキットであるAutoQAを提案する。データベーススキーマとそのデータが与えられると、AutoQAは、さまざまなデータベース操作をカバーするトレーニング用の高品質な質問の大規模なセットを自動的に生成する。AutoQAは、テンプレートベースの構文解析と組み合わせた自動パラフレーズを使用して、音声のさまざまな部分で属性の代替表現を見つけます。また、文全体の正しい言い換えを生成するために、新しいフィルタリングされた自動言い換え機能を使用している。AutoQAをSchema2QAデータセットに適用したところ、自然な質問でテストした場合の平均論理形精度は62.9%で、エキスパートの自然言語アノテーションとクラウドワーカーから収集した言い換えデータを用いて学習したモデルよりも6.4%低いだけであった。AutoQAの一般性を実証するために、Overnightデータセットにも適用しています。AutoQAは69.8%の解答精度を達成し、最先端のゼロショットモデルよりも16.4%高く、人間のデータで訓練した同じモデルよりも5.2%低いだけである。,https://d3i71xaburhd42.cloudfront.net/2a0417e641233cd9aa77c58f00f944d3c5e84d62/1-Figure1-1.png
Autoregressive Knowledge Distillation through Imitation Learning,"['Alexander Lin', 'Jeremy Wohlwend', 'Howard Chen', 'Tao Lei']",http://arxiv.org/abs/2009.07253v1,"The performance of autoregressive models on natural language generation tasks has dramatically improved due to the adoption of deep, self-attentive architectures. However, these gains have come at the cost of hindering inference speed, making state-of-the-art models cumbersome to deploy in real-world, time-sensitive settings. We develop a compression technique for autoregressive models that is driven by an imitation learning perspective on knowledge distillation. The algorithm is designed to address the exposure bias problem. On prototypical language generation tasks such as translation and summarization, our method consistently outperforms other distillation algorithms, such as sequence-level knowledge distillation. Student models trained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those trained from scratch, while increasing inference speed by up to 14 times in comparison to the teacher model.",自然言語生成タスクにおける自己回帰モデルの性能は、深い自己注意型アーキテクチャの採用により劇的に向上した。しかし、これらの向上は推論速度を阻害するという代償を払っており、最新のモデルを実世界の時間に敏感な環境で展開するのは煩雑である。本研究では、知識の蒸留に関する模倣学習の観点から、自己回帰モデルの圧縮技術を開発する。このアルゴリズムは、暴露バイアス問題に対処するように設計されている。翻訳や要約のようなプロトタイプの言語生成タスクにおいて、本手法はシーケンスレベルの知識蒸留のような他の蒸留アルゴリズムよりも一貫して優れた性能を示した。本手法を用いて学習した学生モデルは、スクラッチから学習したモデルよりも1.4～4.8ポイント高いBLEUROUGEポイントを獲得し、教師モデルと比較して推論速度を最大14倍に向上させることができました。,https://d3i71xaburhd42.cloudfront.net/f275a996851e48c6a5dc366969d279f96679cec1/4-Table1-1.png
AxCell: Automatic Extraction of Results from Machine Learning Papers,"['Marcin Kardas', 'Piotr Czapla', 'Pontus Stenetorp', 'Sebastian Ruder', 'Sebastian Riedel', 'Ross Taylor', 'Robert Stojnic']",,,なし,
Backpropagation-based Decoding for Unsupervised Counterfactual and Abductive Reasoning,"['Lianhui Qin', 'Vered Shwartz', 'Peter West', 'Chandra Bhagavatula', 'Jena D. Hwang', 'Ronan Le Bras', 'Antoine Bosselut', 'Yejin Choi']",,,なし,
Be More with Less: Hypergraph Attention Networks for Inductive Text Classification,"['Kaize Ding', 'Jianling Wang', 'Jundong Li', 'Dingcheng Li', 'Huan Liu']",,,なし,
Benchmarking Meaning Representations in Neural Semantic Parsing,"['Jiaqi Guo', 'Qian Liu', 'Jian-Guang LOU', 'Zhenwen Li', 'Xueqing Liu', 'Tao Xie', 'Ting Liu']",,,なし,
"BERT Knows Punta Cana is not just beautiful, it's gorgeous: Ranking Scalar Adjectives with Contextualised Representations","['Aina Garí Soler', 'Marianna Apidianaki']",http://arxiv.org/abs/2010.02686v1,"Adjectives like pretty, beautiful and gorgeous describe positive properties of the nouns they modify but with different intensity. These differences are important for natural language understanding and reasoning. We propose a novel BERT-based approach to intensity detection for scalar adjectives. We model intensity by vectors directly derived from contextualised representations and show they can successfully rank scalar adjectives. We evaluate our models both intrinsically, on gold standard datasets, and on an Indirect Question Answering task. Our results demonstrate that BERT encodes rich knowledge about the semantics of scalar adjectives, and is able to provide better quality intensity rankings than static embeddings and previous models with access to dedicated resources.",pretty、beautiful、gorgeousなどの形容詞は、修飾する名詞の肯定的な性質を表現しますが、強さは異なります。このような違いは、自然言語の理解や推論に重要である。我々は、スカラー形容詞の強度検出に対する新しいBERTベースのアプローチを提案する。我々は、文脈化された表現から直接導出されたベクトルによって強度をモデル化し、スカラー形容詞のランク付けに成功することを示す。我々は、ゴールドスタンダードのデータセットと間接的な質問応答タスクの両方で、我々のモデルを本質的に評価する。我々の結果は、BERTがスカラー形容詞の意味論に関する豊富な知識をエンコードし、静的な埋め込みや専用のリソースにアクセスする以前のモデルよりも質の高い強度ランキングを提供できることを実証している。,https://d3i71xaburhd42.cloudfront.net/5b71bcf769e7efab90ceba56b9e4f898899538fe/1-Figure1-1.png
BERT-ATTACK: Adversarial Attack Against BERT Using BERT,"['linyang li', 'Ruotian Ma', 'Qipeng Guo', 'Xiangyang Xue', 'Xipeng Qiu']",http://arxiv.org/abs/2004.09984v3,"Adversarial attacks for discrete data (such as texts) have been proved significantly more challenging than continuous data (such as images) since it is difficult to generate adversarial samples with gradient-based methods. Current successful attack methods for texts usually adopt heuristic replacement strategies on the character or word level, which remains challenging to find the optimal solution in the massive space of possible combinations of replacements while preserving semantic consistency and language fluency. In this paper, we propose \textbf{BERT-Attack}, a high-quality and effective method to generate adversarial samples using pre-trained masked language models exemplified by BERT. We turn BERT against its fine-tuned models and other deep neural models in downstream tasks so that we can successfully mislead the target models to predict incorrectly. Our method outperforms state-of-the-art attack strategies in both success rate and perturb percentage, while the generated adversarial samples are fluent and semantically preserved. Also, the cost of calculation is low, thus possible for large-scale generations. The code is available at https://github.com/LinyangLee/BERT-Attack.",離散データ（テキストなど）に対する逆襲攻撃は、連続データ（画像など）に比べて、勾配ベースの手法では逆襲サンプルを生成することが困難であるため、非常に困難であることが証明されています。現在成功しているテキストに対する攻撃手法は，通常，文字や単語レベルでのヒューリスティックな置換戦略を採用しているが，意味的な一貫性や言語の流暢性を維持しつつ，置換の可能な組み合わせの膨大な空間の中で最適解を見つけることは困難である．この論文では、BERTによって例示される事前に訓練された仮面言語モデルを用いて敵対的サンプルを生成するための高品質で効果的な方法である\textbf{BERT-Attack}を提案する。我々は、下流のタスクにおいて、BERTをその微調整されたモデルや他のディープニューラルモデルと対戦させることで、ターゲットモデルに誤った予測をさせることに成功する。我々の方法は、成功率と摂動率の両方において最先端の攻撃戦略を上回り、生成された敵対的サンプルは流暢で意味的に保存されている。また、計算コストが低いため、大規模な生成が可能である。コードはhttps:/github.comLinyangLeeBERT-Atackにあります。,https://d3i71xaburhd42.cloudfront.net/f5bf1d83a4d3e55e75dcc28a7bda4e99cce85836/3-Figure1-1.png
BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth Mover's Distance,"['jianquan li', 'Xiaokang Liu', 'Honghong Zhao', 'Ruifeng Xu', 'Min Yang', 'yaohong jin']",http://arxiv.org/abs/2010.06133v1,"Pre-trained language models (e.g., BERT) have achieved significant success in various natural language processing (NLP) tasks. However, high storage and computational costs obstruct pre-trained language models to be effectively deployed on resource-constrained devices. In this paper, we propose a novel BERT distillation method based on many-to-many layer mapping, which allows each intermediate student layer to learn from any intermediate teacher layers. In this way, our model can learn from different teacher layers adaptively for various NLP tasks. %motivated by the intuition that different NLP tasks require different levels of linguistic knowledge contained in the intermediate layers of BERT. In addition, we leverage Earth Mover's Distance (EMD) to compute the minimum cumulative cost that must be paid to transform knowledge from teacher network to student network. EMD enables the effective matching for many-to-many layer mapping. %EMD can be applied to network layers with different sizes and effectively measures semantic distance between the teacher network and student network. Furthermore, we propose a cost attention mechanism to learn the layer weights used in EMD automatically, which is supposed to further improve the model's performance and accelerate convergence time. Extensive experiments on GLUE benchmark demonstrate that our model achieves competitive performance compared to strong competitors in terms of both accuracy and model compression.",事前学習された言語モデル（例：BERT）は、様々な自然言語処理（NLP）タスクにおいて大きな成功を収めてきました。しかし、高いストレージと計算コストは、事前学習された言語モデルを資源に制約のある装置に効果的に配置することを妨げている。本論文では、多対多の層のマッピングに基づいた新しいBERT蒸留法を提案する。このようにして、我々のモデルは、様々なNLPタスクに対して、異なる教師層から適応的に学習することができる。これは、異なる NLP タスクが BERT の中間層に含まれる異なるレベルの言語知識を必要とするという直感に基づいています。さらに、Earth Mover's Distance（EMD）を利用して、教師ネットワークから学生ネットワークへ知識を変換するために支払わなければならない最小の累積コストを計算する。EMD は、多対多層のマッピングのための効果的なマッチングを可能にします。EMDは、異なるサイズのネットワーク層にも適用でき、教師ネットワークと学生ネットワークの間の意味的距離を効果的に測定することができる。さらに、EMDで使用される層の重みを自動的に学習するコスト注目メカニズムを提案し、モデルの性能をさらに向上させ、収束時間を加速させることが期待される。GLUEベンチマークを用いた広範な実験により、本モデルは精度とモデル圧縮の両面で強力な競合他社と比較して競争力のある性能を達成していることが示された。,https://d3i71xaburhd42.cloudfront.net/8fd0b70cfd6bbdaef9fbe1073afb3920cb61f80b/4-Figure1-1.png
BERT-enhanced Relational Sentence Ordering Network,"['Baiyun Cui', 'Yingming Li', 'Zhongfei Zhang']",,,なし,
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing,"['Canwen Xu', 'Wangchunshu Zhou', 'Tao Ge', 'Furu Wei', 'Ming Zhou']",http://arxiv.org/abs/2002.02925v4,"In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models. Compared to the previous knowledge distillation approaches for BERT compression, our approach does not introduce any additional loss function. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.",本論文では、プログレッシブモジュール置換によりBERTを効果的に圧縮するための新しいモデル圧縮アプローチを提案する。このアプローチでは、まず、元のBERTをいくつかのモジュールに分割し、それらのコンパクトな代替モジュールを構築する。次に、元のモジュールをその代替モジュールでランダムに置き換え、コンパクトモジュールが元のモジュールの挙動を模倣するように訓練する。訓練を通じて、置き換えの確率を段階的に増加させていく。このようにして、我々のアプローチは、オリジナルモデルとコンパクトモデルの間の相互作用の深化をもたらす。BERT圧縮のための以前の知識蒸留アプローチと比較して、我々のアプローチは追加の損失関数を導入しない。我々のアプローチは、GLUEベンチマークにおいて既存の知識蒸留アプローチを凌駕し、モデル圧縮の新しい視点を示している。,https://d3i71xaburhd42.cloudfront.net/e89ebd73ebf4151356e37b2f1ed516fc6789f6f7/2-Figure1-1.png
Better Highlighting: Creating Sub-Sentence Summary Highlights,"['Sangwoo Cho', 'Kaiqiang Song', 'Chen Li', 'Dong Yu', 'Hassan Foroosh', 'Fei Liu']",,,なし,
Beyond Geolocation: Micro-Dialect Identification in Diaglossic and Code-Switched Environments,"['Muhammad Abdul-Mageed', 'Chiyu Zhang', 'AbdelRahim Elmadany', 'Lyle Ungar']",,,なし,
Biomedical Event Extraction as Sequence Labeling,"['Alan Ramponi', 'Rob van der Goot', 'Rosario Lombardo', 'Barbara Plank']",,,なし,
BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues,"['Hung Le', 'Doyen Sahoo', 'Nancy Chen', 'Steven C.H. Hoi']",,,なし,
Blank Language Models,"['Tianxiao Shen', 'Victor Quach', 'Regina Barzilay', 'Tommi Jaakkola']",http://arxiv.org/abs/2002.03079v1,"We propose Blank Language Model (BLM), a model that generates sequences by dynamically creating and filling in blanks. Unlike previous masked language models or the Insertion Transformer, BLM uses blanks to control which part of the sequence to expand. This fine-grained control of generation is ideal for a variety of text editing and rewriting tasks. The model can start from a single blank or partially completed text with blanks at specified locations. It iteratively determines which word to place in a blank and whether to insert new blanks, and stops generating when no blanks are left to fill. BLM can be efficiently trained using a lower bound of the marginal data likelihood, and achieves perplexity comparable to traditional left-to-right language models on the Penn Treebank and WikiText datasets. On the task of filling missing text snippets, BLM significantly outperforms all other baselines in terms of both accuracy and fluency. Experiments on style transfer and damaged ancient text restoration demonstrate the potential of this framework for a wide range of applications.",我々は、ブランクを動的に生成し、それを埋めることでシーケンスを生成するモデルであるBlank Language Model (BLM)を提案する。従来のマスク付き言語モデルや挿入変換器とは異なり、BLMは空白を用いてシーケンスのどの部分を展開するかを制御する。このようなきめ細かな生成制御は、さまざまなテキスト編集や書き換え作業に最適です。このモデルは、指定された位置にブランクがある単一のブランクまたは部分的に完成したテキストから開始することができます。どの単語をブランクに配置するか、新しいブランクを挿入するかどうかを反復的に決定し、ブランクがなくなると生成を停止します。BLMは、データの限界尤度の下限を用いて効率的に学習することができ、Penn TreebankとWikiTextのデータセットにおいて、従来の左から右への言語モデルに匹敵する複雑さを達成しています。欠落したテキストのスニペットを埋める作業において、BLMは精度と流暢さの両方の点で他のすべてのベースラインを有意に凌駕する。スタイル転送と損傷した古代テキストの復元に関する実験では、このフレームワークが幅広い用途で利用できる可能性が示されています。,https://d3i71xaburhd42.cloudfront.net/ebaa5f5da3e1832a97597ae2c2c0e3e6388c4439/4-Table1-1.png
BLEU might be Guilty but References are not Innocent,"['Markus Freitag', 'David Grangier', 'Isaac Caswell']",http://arxiv.org/abs/2004.06063v1,"The quality of automatic metrics for machine translation has been increasingly called into question, especially for high-quality systems. This paper demonstrates that, while choice of metric is important, the nature of the references is also critical. We study different methods to collect references and compare their value in automated evaluation by reporting correlation with human evaluation for a variety of systems and metrics. Motivated by the finding that typical references exhibit poor diversity, concentrating around translationese language, we develop a paraphrasing task for linguists to perform on existing reference translations, which counteracts this bias. Our method yields higher correlation with human judgment not only for the submissions of WMT 2019 English to German, but also for Back-translation and APE augmented MT output, which have been shown to have low correlation with automatic metrics using standard references. We demonstrate that our methodology improves correlation with all modern evaluation metrics we look at, including embedding-based methods. To complete this picture, we reveal that multi-reference BLEU does not improve the correlation for high quality output, and present an alternative multi-reference formulation that is more effective.",機械翻訳のための自動メトリクスの品質は、特に高品質なシステムの場合、ますます疑問視されています。本論文では、メトリクスの選択が重要である一方で、参照文献の性質も重要であることを示している。我々は、様々なシステムやメトリクスについて、人間の評価との相関関係を報告することで、参考文献を収集するための様々な方法を研究し、自動評価における参考文献の価値を比較している。典型的な参考文献は翻訳言語に集中しており、多様性に乏しいことを発見したことをきっかけに、言語学者が既存の参考文献の翻訳に対して実行するための言い換えタスクを開発し、このバイアスを打ち消す。我々の方法は、WMT 2019英語→ドイツ語の提出物だけでなく、標準的な参考文献を使用した自動メトリクスとの相関性が低いことが示されているBack-translationおよびAPE拡張MT出力についても、人間の判断とのより高い相関性をもたらす。我々は、我々の方法論が、エンベッディングベースの方法を含む、我々が見るすべての近代的な評価指標との相関性を改善することを実証しています。この図を完成させるために、多参照BLEUは高品質な出力の相関を改善しないことを明らかにし、より効果的な代替的な多参照定式化を提示します。,https://d3i71xaburhd42.cloudfront.net/5ef298f3c7792a95825981e2268fce95509fe43a/5-Figure1-1.png
Bridging linguistic typology and multilingual machine translation with multi-view language representations,"['Arturo Oncevay', 'Barry Haddow', 'Alexandra Birch']",http://arxiv.org/abs/2004.14923v1,"Sparse language vectors from linguistic typology databases and learned embeddings from tasks like multilingual machine translation have been investigated in isolation, without analysing how they could benefit from each other's language characterisation. We propose to fuse both views using singular vector canonical correlation analysis and study what kind of information is induced from each source. By inferring typological features and language phylogenies, we observe that our representations embed typology and strengthen correlations with language relationships. We then take advantage of our multi-view language vector space for multilingual machine translation, where we achieve competitive overall translation accuracy in tasks that require information about language similarities, such as language clustering and ranking candidates for multilingual transfer. With our method, we can easily project and assess new languages without expensive retraining of massive multilingual or ranking models, which are major disadvantages of related approaches.",言語類型論データベースからの疎な言語ベクトルと、多言語機械翻訳のようなタスクからの学習済みエンベッディングは、これまで分離して研究されてきたが、お互いの言語特徴付けからどのように利益を得ることができるかを分析することはなかった。我々は、特異ベクトル正準相関分析を用いて両者の見解を融合させ、それぞれのソースからどのような情報が誘導されるかを研究することを提案する。類型論的特徴と言語系統を推論することで、我々の表現が類型論を埋め込み、言語関係との相関関係を強化することを観察する。そして、我々の多視点言語ベクトル空間を多言語機械翻訳に活用し、言語クラスタリングや多言語移転候補のランキングなど、言語の類似性に関する情報を必要とする作業において、競争力のある総合的な翻訳精度を達成しています。我々の方法では、関連するアプローチの大きな欠点である大規模な多言語モデルやランキングモデルの再訓練に費用をかけることなく、簡単に新しい言語を投影し、評価することができます。,https://d3i71xaburhd42.cloudfront.net/1d268b9cca810882e631018d4d9d46ba1c9ad47e/3-Table1-1.png
Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation,"['Xiuyi Chen', 'Fandong Meng', 'Peng Li', 'Feilong Chen', 'Shuang Xu', 'Bo Xu', 'Jie Zhou']",,,なし,
Calibrated Fine-Tuning for Pre-trained Language Models via Manifold Smoothing,"['Lingkai Kong', 'Haoming Jiang', 'Yuchen Zhuang', 'Jie Lyu', 'Tuo Zhao', 'Chao Zhang']",,,なし,
Can Automatic Post-Editing Improve NMT?,"['Shamil Chollampatt', 'Raymond Hendy Susanto', 'Liling Tan', 'Ewa Szymanska']",http://arxiv.org/abs/2009.14395v1,"Automatic post-editing (APE) aims to improve machine translations, thereby reducing human post-editing effort. APE has had notable success when used with statistical machine translation (SMT) systems but has not been as successful over neural machine translation (NMT) systems. This has raised questions on the relevance of APE task in the current scenario. However, the training of APE models has been heavily reliant on large-scale artificial corpora combined with only limited human post-edited data. We hypothesize that APE models have been underperforming in improving NMT translations due to the lack of adequate supervision. To ascertain our hypothesis, we compile a larger corpus of human post-edits of English to German NMT. We empirically show that a state-of-art neural APE model trained on this corpus can significantly improve a strong in-domain NMT system, challenging the current understanding in the field. We further investigate the effects of varying training data sizes, using artificial training data, and domain specificity for the APE task. We release this new corpus under CC BY-NC-SA 4.0 license at https://github.com/shamilcm/pedra.",自動ポストエディット（APE）は、機械翻訳を改善し、人間のポストエディットの労力を減らすことを目的としています。APEは統計的機械翻訳(SMT)システムで使用された場合には顕著な成功を収めていますが、ニューラル機械翻訳(NMT)システムでは成功していません。このことは、現在のシナリオにおけるAPEタスクの妥当性に疑問を投げかけています。しかし、APEモデルのトレーニングは、大規模な人工コーパスと限られた人間のポストエディットデータに大きく依存してきた。我々は、APEモデルがNMT翻訳の改善に十分な監督が行われていないために、APEモデルの性能が低下しているのではないかと仮説を立てた。この仮説を確かめるために、我々は英語からドイツ語へのNMTの人間によるポストエディットの大規模コーパスを作成した。その結果、このコーパス上で訓練された最新のニューラルAPEモデルが、領域内の強力なNMTシステムを大幅に改善できることを経験的に示し、この分野における現在の理解に挑戦した。本研究では、このコーパスを用いて学習したニューラルAPEモデルが領域内NMTシステムを大幅に改善することを実証的に示した。この新しいコーパスをCC BY-NC-SA 4.0ライセンスの下、https:/github.comshamilcmpedraで公開しています。,https://d3i71xaburhd42.cloudfront.net/772c74abf9348cb5576caf79c04ef8fa9bf09973/1-Figure1-1.png
Can Emojis Convey Human Emotions? A Study to Understand the Association between Emojis and Emotions,"['Abu Awal Md Shoeb', 'Gerard de Melo']",,,なし,
CancerEmo: A Dataset for Fine-Grained Emotion Detection,"['Tiberiu Sosea', 'Cornelia Caragea']",,,なし,
CapWAP: Captioning with a Purpose,"['Adam Fisch', 'Kenton Lee', 'Ming-Wei Chang', 'Jonathan Clark', 'Regina Barzilay']",,,なし,
Causal Inference of Script Knowledge,"['Noah Weber', 'Rachel Rudinger', 'Benjamin Van Durme']",http://arxiv.org/abs/2004.01174v1,"When does a sequence of events define an everyday scenario and how can this knowledge be induced from text? Prior works in inducing such scripts have relied on, in one form or another, measures of correlation between instances of events in a corpus. We argue from both a conceptual and practical sense that a purely correlation-based approach is insufficient, and instead propose an approach to script induction based on the causal effect between events, formally defined via interventions. Through both human and automatic evaluations, we show that the output of our method based on causal effects better matches the intuition of what a script represents",一連の出来事が日常的なシナリオを定義するのはいつで、この知識はどのようにしてテキストから誘導できるのだろうか。このようなスクリプトを誘導するための先行研究は、コーパス内のイベントのインスタンス間の相関関係の測定に依存してきた。本研究では、純粋な相関関係に基づくアプローチでは不十分であることを概念的にも実用的にも論じ、代わりに、介入を介して正式に定義されたイベント間の因果関係に基づくスクリプト誘導のアプローチを提案する。人間と自動の両方の評価を通じて、因果効果に基づく我々の手法の出力が、スクリプトが何を表すのかという直感とよりよく一致していることを示す。,https://d3i71xaburhd42.cloudfront.net/fc982f5648fb543ea30195709016d2a02a519dde/1-Figure1-1.png
Chapter Captor: Text Segmentation in Novels,"['Charuta Pethe', 'Allen Kim', 'Steve Skiena']",,,なし,
Character-level Representations Still Improve Semantic Parsing in the Age of BERT,"['Rik van Noord', 'Antonio Toral', 'Johan Bos']",,,なし,
CHARM: Inferring Personal Attributes from Conversations,"['Anna Tigunova', 'Andrew Yates', 'Paramita Mirza', 'Gerhard Weikum']",,,なし,
CheXbert: Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using BERT,"['Akshay Smit', 'Saahil Jain', 'Pranav Rajpurkar', 'Anuj Pareek', 'Andrew Ng', 'Matthew Lungren']",http://arxiv.org/abs/2004.09167v3,"The extraction of labels from radiology text reports enables large-scale training of medical imaging models. Existing approaches to report labeling typically rely either on sophisticated feature engineering based on medical domain knowledge or manual annotations by experts. In this work, we introduce a BERT-based approach to medical image report labeling that exploits both the scale of available rule-based systems and the quality of expert annotations. We demonstrate superior performance of a biomedically pretrained BERT model first trained on annotations of a rule-based labeler and then finetuned on a small set of expert annotations augmented with automated backtranslation. We find that our final model, CheXbert, is able to outperform the previous best rules-based labeler with statistical significance, setting a new SOTA for report labeling on one of the largest datasets of chest x-rays.",放射線医学のテキストレポートからラベルを抽出することで、医用画像モデルの大規模なトレーニングが可能になる。報告書のラベル付けに対する既存のアプローチは、一般的に医学領域の知識に基づく高度な特徴工学か、専門家による手動の注釈に依存している。本研究では、利用可能なルールベースのシステムの規模と専門家によるアノテーションの質の両方を利用したBERTベースの医用画像レポートラベリングアプローチを導入する。我々は、生物学的に事前に訓練されたBERTモデルの優れた性能を実証し、最初にルールベースのラベラーのアノテーションで訓練し、その後、自動化された逆翻訳で補強された少数の専門家アノテーションのセットで微調整した。我々の最終モデルであるCheXbertは、統計的有意性をもって以前の最高のルールベースラベラーを上回る性能を発揮し、胸部X線の最大のデータセットの一つである報告書ラベリングのための新しいSOTAを設定することができることを発見した。,https://d3i71xaburhd42.cloudfront.net/eb4bd4290958038889bc73e3f68ce9858cbc653c/1-Figure1-1.png
ChiTeSQL: A Large-Scale and Pragmatic Chinese Text-to-SQL Dataset,"['Lijie Wang', 'Ao Zhang', 'Kun Wu', 'Ke Sun', 'Zhenghua Li', 'Hua Wu', 'Min Zhang', 'Haifeng Wang']",,,なし,
ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization,"['Shiyue Zhang', 'Benjamin Frey', 'Mohit Bansal']",http://arxiv.org/abs/2010.04791v1,"Cherokee is a highly endangered Native American language spoken by the Cherokee people. The Cherokee culture is deeply embedded in its language. However, there are approximately only 2,000 fluent first language Cherokee speakers remaining in the world, and the number is declining every year. To help save this endangered language, we introduce ChrEn, a Cherokee-English parallel dataset, to facilitate machine translation research between Cherokee and English. Compared to some popular machine translation language pairs, ChrEn is extremely low-resource, only containing 14k sentence pairs in total. We split our parallel data in ways that facilitate both in-domain and out-of-domain evaluation. We also collect 5k Cherokee monolingual data to enable semi-supervised learning. Besides these datasets, we propose several Cherokee-English and English-Cherokee machine translation systems. We compare SMT (phrase-based) versus NMT (RNN-based and Transformer-based) systems; supervised versus semi-supervised (via language model, back-translation, and BERT/Multilingual-BERT) methods; as well as transfer learning versus multilingual joint training with 4 other languages. Our best results are 15.8/12.7 BLEU for in-domain and 6.5/5.0 BLEU for out-of-domain Chr-En/EnChr translations, respectively, and we hope that our dataset and systems will encourage future work by the community for Cherokee language revitalization. Our data, code, and demo will be publicly available at https://github.com/ZhangShiyue/ChrEn","チェロキー語は、チェロキー族によって話されている絶滅の危機に瀕したネイティブアメリカンの言語です。チェロキーの文化は、その言語に深く根付いています。しかし、流暢な第一言語であるチェロキー語を話す人は世界に約2,000人しか残っておらず、その数は年々減少しています。この絶滅の危機に瀕しているチェロキー語を救うために、チェロキー語と英語の機械翻訳研究を促進するために、チェロキー語と英語の並列データセットである ChrEn を導入しました。一般的な機械翻訳言語のペアと比較して、 ChrEn は非常に低リソースで、合計 14k の文ペアしか含まれていません。並列データは、領域内と領域外の両方の評価を容易にするように分割しています。また、半教師付き学習を可能にするために、5kのCherokeeの単言語データを収集している。これらのデータセットの他に、いくつかのチェロキー語-英語および英語-チェロキー語の機械翻訳システムを提案する。我々は、SMT(フレーズベース)とNMT(RNNベースとトランスフォーマーベース)システム、教師付きと半教師付き(言語モデル、逆翻訳、BERTMultilingual-BERTを介して)の方法、および他の4つの言語との多言語共同訓練と移乗学習の比較を行った。我々の最良の結果は、領域内翻訳では15.812.7BLEU、領域外翻訳では6.55.0BLEUであり、我々のデータセットとシステムがチェロキー言語の活性化のためのコミュニティによる将来の作業を促進することを期待している。我々のデータ、コード、デモはhttps:/github.comZhangShiyueChrEnEn",
CLIRMatrix: A massively large collection of bilingual and multilingual datasets for Cross-Lingual Information Retrieval,"['Shuo Sun', 'Kevin Duh']",,,なし,
Coarse-to-Fine Pre-training for Named Entity Recognition,"['Xue Mengge', 'Bowen Yu', 'Zhenyu Zhang', 'Tingwen Liu', 'Yue Zhang', 'Bin Wang']",,,なし,
Coarse-to-Fine Query Focused Multi-Document Summarization,"['Yumo Xu', 'Mirella Lapata']",,,なし,
CoDEx: A Comprehensive Knowledge Graph Completion Benchmark,"['Tara Safavi', 'Danai Koutra']",http://arxiv.org/abs/2009.07810v2,"We present CoDEx, a set of knowledge graph completion datasets extracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises three knowledge graphs varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CoDEx, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CoDEx dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CoDEx for five extensively tuned embedding models. Finally, we differentiate CoDEx from the popular FB15K-237 knowledge graph completion dataset by showing that CoDEx covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs.",ウィキデータとウィキペディアから抽出したナレッジグラフ補完データセットCoDExは、既存のナレッジグラフ補完ベンチマークの範囲と難易度を向上させたものです。CoDExは、サイズと構造が異なる3つのナレッジグラフ、実体と関係の多言語記述、もっともらしいが虚偽であると検証された数万個のハードネガティブトリプルから構成されています。本研究では、CoDExを特徴づけるために、徹底した実証分析とベンチマーク実験を行う。まず、各CoDExデータセットを論理的関係パターンの観点から分析します。次に、広範囲に調整された5つのエンベッディングモデルについて、CoDExのベースラインリンク予測と三重分類の結果を報告する。最後に、CoDExがより多様で解釈可能なコンテンツをカバーしており、より困難なリンク予測ベンチマークであることを示すことで、人気のあるFB15K-237ナレッジグラフ補完データセットとCoDExを区別している。データ、コード、事前学習モデルは、https:/bit.ly2EPbrJsから入手可能です。,https://d3i71xaburhd42.cloudfront.net/9699c5ed895ef312ae93655ffb6370c380bddba1/2-Table1-1.png
Coding Textual Inputs Boosts the Accuracy of Neural Networks,"['Abdul Rafae Khan', 'Jia Xu', 'Weiwei Sun']",,,なし,
COGS: A Compositional Generalization Challenge Based on Semantic Interpretation,"['Najoung Kim', 'Tal Linzen']",http://arxiv.org/abs/2010.05465v1,"Natural language is characterized by compositionality: the meaning of a complex expression is constructed from the meanings of its constituent parts. To facilitate the evaluation of the compositional abilities of language processing architectures, we introduce COGS, a semantic parsing dataset based on a fragment of English. The evaluation portion of COGS contains multiple systematic gaps that can only be addressed by compositional generalization; these include new combinations of familiar syntactic structures, or new combinations of familiar words and familiar structures. In experiments with Transformers and LSTMs, we found that in-distribution accuracy on the COGS test set was near-perfect (96--99%), but generalization accuracy was substantially lower (16--35%) and showed high sensitivity to random seed ($\pm$6--8%). These findings indicate that contemporary standard NLP models are limited in their compositional generalization capacity, and position COGS as a good way to measure progress.",自然言語は構成性を特徴としており、複雑な表現の意味は、その構成部分の意味から構成されている。言語処理アーキテクチャの構成能力の評価を容易にするために、英語の断片に基づいた意味解析データセットであるCOGSを紹介する。COGSの評価部分には、構成の一般化によってのみ対処できる複数の体系的なギャップが含まれており、これらには、見慣れた構文構造の新しい組み合わせや、見慣れた単語と見慣れた構造の新しい組み合わせが含まれる。トランスフォーマーとLSTMを用いた実験では、COGSテストセットにおける分布内精度はほぼ完璧（96〜99％）であったが、一般化精度は大幅に低く（16〜35％）、ランダムシード（$pm$6〜8％）に対して高い感度を示した。これらの結果は、現代の標準的なNLPモデルでは、構成的な一般化能力に限界があることを示しており、COGSは進歩を測定する良い方法として位置づけられています。,https://d3i71xaburhd42.cloudfront.net/b20ddcbd239f3fa9acc603736ac2e4416302d074/1-Figure1-1.png
Cold-start Active Learning through Self-Supervised Language Modeling,"['Michelle Yuan', 'Hsuan-Tien Lin', 'Jordan Boyd-Graber']",http://arxiv.org/abs/2010.09535v1,"Active learning strives to reduce annotation costs by choosing the most critical examples to label. Typically, the active learning strategy is contingent on the classification model. For instance, uncertainty sampling depends on poorly calibrated model confidence scores. In the cold-start setting, active learning is impractical because of model instability and data scarcity. Fortunately, modern NLP provides an additional source of information: pre-trained language models. The pre-training loss can find examples that surprise the model and should be labeled for efficient fine-tuning. Therefore, we treat the language modeling loss as a proxy for classification uncertainty. With BERT, we develop a simple strategy based on the masked language modeling loss that minimizes labeling costs for text classification. Compared to other baselines, our approach reaches higher accuracy within less sampling iterations and computation time.",能動学習は、ラベル付けするために最も重要な例を選択することで、アノテーションのコストを削減しようとします。一般的に、能動学習戦略は分類モデルに依存します。例えば、不確実性のサンプリングは、不十分に校正されたモデルの信頼度スコアに依存します。コールドスタートの設定では、モデルの不安定性とデータの希少性のため、能動学習は非現実的です。幸いなことに、現代のNLPは追加の情報源を提供します：事前に訓練された言語モデルです。事前学習の損失は、モデルを驚かせる例を見つけることができ、効率的な微調整のためにラベル付けされるべきである。したがって、我々は言語モデルの損失を分類の不確実性の代理として扱う。BERT を用いて、テキスト分類のラベリングコストを最小化する、マスクされた言語モデリング損失に基づく単純な戦略を開発する。他のベースラインと比較して、我々のアプローチは、より少ないサンプリング反復と計算時間でより高い精度に到達する。,https://d3i71xaburhd42.cloudfront.net/957e8436a806c253d17521aae6dd5c3e76c1ba02/4-Figure1-1.png
Cold-start and Interpretability: Turning Regular Expressions into Trainable Recurrent Neural Networks,"['Chengyue Jiang', 'Yinggong Zhao', 'Shanbo Chu', 'Libin Shen', 'Kewei Tu']",,,なし,
Collecting Entailment Data for Pretraining: New Protocols and Negative Results,"['Samuel R. Bowman', 'Jennimaria Palomaki', 'Livio Baldini Soares', 'Emily Pitler']",,,なし,
Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection,"['Shaolei Wang', 'Zhongyuan Wang', 'Wanxiang Che', 'Ting Liu']",,,なし,
COMETA: A Corpus for Medical Entity Linking in the Social Media,"['Marco Basaldella', 'Fangyu Liu', 'Ehsan Shareghi', 'Nigel Collier']",http://arxiv.org/abs/2010.03295v2,"Whilst there has been growing progress in Entity Linking (EL) for general language, existing datasets fail to address the complex nature of health terminology in layman's language. Meanwhile, there is a growing need for applications that can understand the public's voice in the health domain. To address this we introduce a new corpus called COMETA, consisting of 20k English biomedical entity mentions from Reddit expert-annotated with links to SNOMED CT, a widely-used medical knowledge graph. Our corpus satisfies a combination of desirable properties, from scale and coverage to diversity and quality, that to the best of our knowledge has not been met by any of the existing resources in the field. Through benchmark experiments on 20 EL baselines from string- to neural-based models we shed light on the ability of these systems to perform complex inference on entities and concepts under 2 challenging evaluation scenarios. Our experimental results on COMETA illustrate that no golden bullet exists and even the best mainstream techniques still have a significant performance gap to fill, while the best solution relies on combining different views of data.",一般的な言語のためのエンティティ・リンキング（EL）が進歩している一方で、既存のデータセットでは、素人の言語で健康用語の複雑な性質に対処することができませんでした。一方で、健康分野における公衆の声を理解できるアプリケーションへのニーズが高まっています。この問題に対処するために、我々はCOMETAと呼ばれる新しいコーパスを導入した。このコーパスは、Redditの専門家による20kの英語の生物医学的実体の言及から構成されており、広く利用されている医療知識グラフであるSNOMED CTへのリンクで注釈が付けられている。我々のコーパスは、我々の知る限りでは、この分野の既存のリソースでは満たされていない、規模、カバレッジ、多様性、品質などの望ましい特性の組み合わせを満たしています。文字列モデルからニューラルベースのモデルまで、20種類のELベースラインを用いたベンチマーク実験を通じて、2つの困難な評価シナリオの下で、これらのシステムが実体と概念の複雑な推論を実行する能力を明らかにした。COMETAでの実験結果から、黄金の弾丸は存在せず、主流の最高の技術であっても性能のギャップが大きく、最良の解決策はデータの異なる見方を組み合わせることに依存していることが明らかになった。,https://d3i71xaburhd42.cloudfront.net/a2cde1da31a61adab24e702999680108ab58e5ff/1-Figure1-1.png
Comparative Evaluation of Label Agnostic Selection Bias in Multilingual Hate Speech Datasets,"['Nedjma Ousidhoum', 'Yangqiu Song', 'Dit-Yan Yeung']",,,なし,
Competence-Level Prediction and Resume-Job_Description Matching Using Context-Aware Transformer Models,"['Changmao Li', 'Elaine Fisher', 'Rebecca Thomas', 'Steve Pittard', 'Vicki Hertzberg', 'Jinho D. Choi']",,,なし,
"Compositional and Lexical Semantics in RoBERTa, BERT and DistilBERT: A Case Study on CoQA","['Ieva Staliūnaitė', 'Ignacio Iacobacci']",http://arxiv.org/abs/2009.08257v1,"Many NLP tasks have benefited from transferring knowledge from contextualized word embeddings, however the picture of what type of knowledge is transferred is incomplete. This paper studies the types of linguistic phenomena accounted for by language models in the context of a Conversational Question Answering (CoQA) task. We identify the problematic areas for the finetuned RoBERTa, BERT and DistilBERT models through systematic error analysis - basic arithmetic (counting phrases), compositional semantics (negation and Semantic Role Labeling), and lexical semantics (surprisal and antonymy). When enhanced with the relevant linguistic knowledge through multitask learning, the models improve in performance. Ensembles of the enhanced models yield a boost between 2.2 and 2.7 points in F1 score overall, and up to 42.1 points in F1 on the hardest question classes. The results show differences in ability to represent compositional and lexical information between RoBERTa, BERT and DistilBERT.",多くのNLPタスクは、文脈化された単語エンベッディングから知識を伝達することで恩恵を受けてきたが、どのような種類の知識が伝達されるのかについては不完全である。本論文では、会話型質問応答（CoQA）タスクの文脈において、言語モデルが説明する言語現象の種類を研究する。基本的な算術（フレーズを数える）、構成的意味論（否定と意味的役割のラベリング）、語彙的意味論（不意打ちと反意打ち）について、系統的なエラー分析を通して、微調整されたRoBERTa、BERT、DistilBERTモデルの問題点を特定する。マルチタスク学習によって関連する言語知識で強化すると、モデルの性能が向上する。強化されたモデルのアンサンブルでは、全体のF1スコアが2.2〜2.7ポイント、最も難しい問題クラスのF1スコアが最大42.1ポイント向上した。結果は、RoBERTa、BERT、DistilBERTの間で、構成情報と語彙情報を表現する能力に違いがあることを示している。,https://d3i71xaburhd42.cloudfront.net/260cce438595c708433719a75c72889fefa5f731/3-Table1-1.png
Compositional Demographic Word Embeddings,"['Charles Welch', 'Jonathan K. Kummerfeld', 'Verónica Pérez-Rosas', 'Rada Mihalcea']",http://arxiv.org/abs/2010.02986v1,"Word embeddings are usually derived from corpora containing text from many individuals, thus leading to general purpose representations rather than individually personalized representations. While personalized embeddings can be useful to improve language model performance and other language processing tasks, they can only be computed for people with a large amount of longitudinal data, which is not the case for new users. We propose a new form of personalized word embeddings that use demographic-specific word representations derived compositionally from full or partial demographic information for a user (i.e., gender, age, location, religion). We show that the resulting demographic-aware word representations outperform generic word representations on two tasks for English: language modeling and word associations. We further explore the trade-off between the number of available attributes and their relative effectiveness and discuss the ethical implications of using them.",単語のエンベッディングは通常，多くの個人のテキストを含むコーパスから得られるため，個別にパーソナライズされた表現ではなく，汎用的な表現になります．パーソナライズされた単語エンベッディングは、言語モデルの性能向上や他の言語処理タスクに有用であるが、大量の縦断的データを持つ人々のためにしか計算できず、新しいユーザのためにはそうではない。我々は、ユーザの完全または部分的な人口統計情報（すなわち、性別、年齢、場所、宗教）から構成的に導き出された人口統計学的に特異的な単語表現を使用する、パーソナライズされた新しい形態の単語エンベッディングを提案する。その結果、人口統計学を意識した単語表現は、英語の2つのタスク（言語モデリングと単語の関連付け）において、一般的な単語表現よりも優れていることを示した。さらに、利用可能な属性の数とその相対的な有効性との間のトレードオフを探り、それらを使用することの倫理的な意味合いについて議論する。,https://d3i71xaburhd42.cloudfront.net/77804b4968bd2745d8fc6f50202c1e18ec29ff6c/1-Table1-1.png
Compositional Phrase Alignment and Beyond,"['Yuki Arase', ""Jun'ichi Tsujii""]",,,なし,
Compressive Summarization with Plausibility and Salience Modeling,"['Shrey Desai', 'Jiacheng Xu', 'Greg Durrett']",http://arxiv.org/abs/2010.07886v1,"Compressive summarization systems typically rely on a crafted set of syntactic rules to determine what spans of possible summary sentences can be deleted, then learn a model of what to actually delete by optimizing for content selection (ROUGE). In this work, we propose to relax the rigid syntactic constraints on candidate spans and instead leave compression decisions to two data-driven criteria: plausibility and salience. Deleting a span is plausible if removing it maintains the grammaticality and factuality of a sentence, and spans are salient if they contain important information from the summary. Each of these is judged by a pre-trained Transformer model, and only deletions that are both plausible and not salient can be applied. When integrated into a simple extraction-compression pipeline, our method achieves strong in-domain results on benchmark summarization datasets, and human evaluation shows that the plausibility model generally selects for grammatical and factual deletions. Furthermore, the flexibility of our approach allows it to generalize cross-domain: our system fine-tuned on only 500 samples from a new domain can match or exceed an in-domain extractive model trained on much more data.",圧縮要約システムは一般的に、削除可能な要約文のどのスパンを削除できるかを決定するための構文規則の細工されたセットに依存しており、その後、コンテンツ選択のための最適化(ROUGE)によって実際に削除すべきもののモデルを学習する。本研究では、候補となるスパンに対する厳格な構文的制約を緩和し、代わりに圧縮の決定を2つのデータ駆動型の基準に委ねることを提案する。スパンを削除しても文の文法性と事実性が維持されるならば妥当であり、要約から重要な情報が含まれているならば妥当である。これらはそれぞれ事前に訓練されたTransformerモデルによって判断され、もっともらしいと思われる削除とそうでない削除の両方が適用されます。単純な抽出圧縮パイプラインに統合された場合、我々の手法は、ベンチマークの要約データセットにおいて強力な領域内結果を達成し、人間による評価では、もっともらしいモデルが一般的に文法的な削除と事実上の削除を選択することが示されている。さらに、我々のアプローチの柔軟性により、領域横断的な一般化が可能である。新しい領域からのわずか500サンプルで微調整された我々のシステムは、より多くのデータで訓練された領域内抽出モデルと一致するか、それ以上の結果を得ることができる。,https://d3i71xaburhd42.cloudfront.net/77d4bd7ffd1aa1e704822a214af3d6e454da0398/2-Figure1-1.png
Conditional Causal Relationships between Emotions and Causes in Texts,"['Xinhong Chen', 'Qing Li', 'Jianping Wang']",,,なし,
Condolences and Empathy in Online Communities,"['Naitian Zhou', 'David Jurgens']",,,なし,
ConjNLI: Natural Language Inference Over Conjunctive Sentences,"['Swarnadeep Saha', 'Yixin Nie', 'Mohit Bansal']",,,なし,
Connecting the Dots: Event Graph Schema Induction with Path Language Modeling,"['Manling Li', 'Qi Zeng', 'Ying Lin', 'Kyunghyun Cho', 'Heng Ji', 'Jonathan May', 'Nathanael Chambers', 'Clare Voss']",,,なし,
Consistency of a Recurrent Language Model With Respect to Incomplete Decoding,"['Sean Welleck', 'Ilia Kulikov', 'Jaedeok Kim', 'Richard Yuanzhe Pang', 'Kyunghyun Cho']",http://arxiv.org/abs/2002.02492v2,"Despite strong performance on a variety of tasks, neural sequence models trained with maximum likelihood have been shown to exhibit issues such as length bias and degenerate repetition. We study the related issue of receiving infinite-length sequences from a recurrent language model when using common decoding algorithms. To analyze this issue, we first define inconsistency of a decoding algorithm, meaning that the algorithm can yield an infinite-length sequence that has zero probability under the model. We prove that commonly used incomplete decoding algorithms - greedy search, beam search, top-k sampling, and nucleus sampling - are inconsistent, despite the fact that recurrent language models are trained to produce sequences of finite length. Based on these insights, we propose two remedies which address inconsistency: consistent variants of top-k and nucleus sampling, and a self-terminating recurrent language model. Empirical results show that inconsistency occurs in practice, and that the proposed methods prevent inconsistency.",最尤で学習されたニューラルシーケンスモデルは、様々なタスクで高い性能を発揮するにもかかわらず、長さの偏りや退化した繰り返しなどの問題があることが示されてきた。我々は、一般的な復号化アルゴリズムを使用した場合に、リカレント言語モデルから無限長のシーケンスを受信することに関連する問題を研究している。この問題を分析するために、まず、復号化アルゴリズムの不整合性を定義する。これは、アルゴリズムがモデルの下でゼロの確率を持つ無限長のシーケンスを得ることができることを意味する。我々は、一般的に使用されている不完全復号化アルゴリズム（貪欲探索、ビーム探索、top-kサンプリング、核サンプリング）が、リカレント言語モデルが有限長のシーケンスを生成するように訓練されているという事実にもかかわらず、不整合であることを証明する。これらの洞察に基づいて、我々は矛盾に対処する2つの解決策を提案する：top-kサンプリングと核サンプリングの一貫したバリエーション、および自己終結型リカレント言語モデルである。実証的な結果は、実際には不整合が発生することを示し、提案する手法は不整合を防止することを示す。,https://d3i71xaburhd42.cloudfront.net/3f1d72105060bebba68b672dd6197c0deddca26f/7-Table1-1.png
Constrained Iterative Labeling for Open Information Extraction,"['Keshav Kolluru', 'Vaibhav Adlakha', 'Samarth Aggarwal', 'Mausam -', 'Soumen Chakrabarti']",,,なし,
Content Planning for Neural Story Generation with Aristotelian Rescoring,"['Seraphina Goldfarb-Tarrant', 'Tuhin Chakrabarty', 'Ralph Weischedel', 'Nanyun Peng']",http://arxiv.org/abs/2009.09870v2,"Long-form narrative text generated from large language models manages a fluent impersonation of human writing, but only at the local sentence level, and lacks structure or global cohesion. We posit that many of the problems of story generation can be addressed via high-quality content planning, and present a system that focuses on how to learn good plot structures to guide story generation. We utilize a plot-generation language model along with an ensemble of rescoring models that each implement an aspect of good story-writing as detailed in Aristotle's Poetics. We find that stories written with our more principled plot-structure are both more relevant to a given prompt and higher quality than baselines that do not content plan, or that plan in an unprincipled way.",大規模な言語モデルから生成された長文の物語文は、人間の文章を流暢に真似ることができるが、局所的な文のレベルでのみ管理されており、構造やグローバルなまとまりに欠けている。我々は、物語生成の問題点の多くは、質の高いコンテンツプランニングによって解決できると考え、物語生成を導くための良いプロット構造をどのように学習するかに焦点を当てたシステムを提案する。我々は、アリストテレスの『詩学』に詳述されているように、それぞれが優れたストーリーライティングの側面を実装した再スコアリングモデルのアンサンブルとともに、プロット生成言語モデルを利用しています。私たちは、より原則的なプロット構造を用いて書かれた物語は、内容を計画しないベースラインや、原則的でない方法で計画するよりも、与えられたプロンプトに関連性が高く、質が高いことを発見しました。,https://d3i71xaburhd42.cloudfront.net/4560660897ca2154c0a303b5802f375c905b332f/2-Table1-1.png
Context-Aware Answer Extraction in Question Answering,"['Yeon Seonwoo', 'Ji-Hoon Kim', 'Jung-Woo Ha', 'Alice Oh']",,,なし,
"Continuity of Topic, Interaction, and Query: Learning to Quote in Online Conversations","['Lingzhi Wang', 'Jing Li', 'Xingshan Zeng', 'Haisong Zhang', 'Kam-Fai Wong']",,,なし,
Contrastive Distillation on Intermediate Representations for Language Model Compression,"['Siqi Sun', 'Zhe Gan', 'Yuwei Fang', 'Yu Cheng', 'Shuohang Wang', 'Jingjing Liu']",http://arxiv.org/abs/2009.14167v1,"Existing language model compression methods mostly use a simple L2 loss to distill knowledge in the intermediate representations of a large BERT model to a smaller one. Although widely used, this objective by design assumes that all the dimensions of hidden representations are independent, failing to capture important structural knowledge in the intermediate layers of the teacher network. To achieve better distillation efficacy, we propose Contrastive Distillation on Intermediate Representations (CoDIR), a principled knowledge distillation framework where the student is trained to distill knowledge through intermediate layers of the teacher via a contrastive objective. By learning to distinguish positive sample from a large set of negative samples, CoDIR facilitates the student's exploitation of rich information in teacher's hidden layers. CoDIR can be readily applied to compress large-scale language models in both pre-training and finetuning stages, and achieves superb performance on the GLUE benchmark, outperforming state-of-the-art compression methods.",既存の言語モデル圧縮方法は、大部分が単純な L2 損失を使用して、大規模な BERT モデルの中間表現の知識をより小さいものに蒸留している。広く使われているが、この目的は設計上、隠された表現のすべての次元が独立していることを前提としており、教師ネットワークの中間層における重要な構造的知識を捕捉することができない。より良い蒸留効果を達成するために、我々は、対照的な目的語を介して教師の中間層を介して知識を蒸留するように学生を訓練する原理的な知識蒸留フレームワークである中間表現上の対照的蒸留（CoDIR）を提案する。ここでは、学生は対照的な目的語を介して教師の中間層を介して知識を蒸留するように訓練されています。CoDIR は大規模な言語モデルの圧縮に容易に適用でき、GLUE ベンチマークでは最先端の圧縮手法を上回る優れた性能を達成しています。,https://d3i71xaburhd42.cloudfront.net/0abb08c4ec5feab4cdd82c471866dd4395c573ce/3-Figure1-1.png
Controllable Meaning Representation to Text Generation: Linearization and Data Augmentation Strategies,"['Chris Kedzie', 'Kathleen McKeown']",,,なし,
Controllable Story Generation with External Knowledge Using Large-Scale Language Models,"['Peng Xu', 'Mostofa Patwary', 'Mohammad Shoeybi', 'Raul Puri', 'Pascale Fung', 'Anima Anandkumar', 'Bryan Catanzaro']",http://arxiv.org/abs/2010.00840v1,"Existing pre-trained large language models have shown unparalleled generative capabilities. However, they are not controllable. In this paper, we propose MEGATRON-CNTRL, a novel framework that uses large-scale language models and adds control to text generation by incorporating an external knowledge base. Our framework consists of a keyword predictor, a knowledge retriever, a contextual knowledge ranker, and a conditional text generator. As we do not have access to ground-truth supervision for the knowledge ranker, we make use of weak supervision from sentence embedding. The empirical results show that our model generates more fluent, consistent, and coherent stories with less repetition and higher diversity compared to prior work on the ROC story dataset. We showcase the controllability of our model by replacing the keywords used to generate stories and re-running the generation process. Human evaluation results show that 77.5% of these stories are successfully controlled by the new keywords. Furthermore, by scaling our model from 124 million to 8.3 billion parameters we demonstrate that larger models improve both the quality of generation (from 74.5% to 93.0% for consistency) and controllability (from 77.5% to 91.5%).","既存の事前学習された大規模言語モデルは、他に類を見ない生成能力を示している。しかし、これらのモデルは制御可能なものではない。本論文では、大規模言語モデルを用い、外部の知識ベースを組み込むことでテキスト生成に制御性を付加する新しいフレームワーク、MEGATRON-CNTRLを提案する。このフレームワークは、キーワード予測器、知識検索器、文脈知識ランカー、条件付きテキスト生成器から構成される。知識ランカーにはグランドトゥルースの監督を利用できないため、文の埋め込みからの弱い監督を利用している。経験的な結果として、我々のモデルは、ROCストーリーデータセットに関する先行研究と比較して、より流暢で一貫性があり、一貫性のあるストーリーを生成し、繰り返しが少なく、より多様性が高いことを示した。また、ストーリー生成に使用したキーワードを入れ替えたり、生成プロセスを再実行したりすることで、本モデルの制御性を示しています。人的評価の結果、77.5%のストーリーが新しいキーワードによって制御されていることがわかりました。さらに、モデルを1億2,400万個のパラメータから83億個のパラメータにスケーリングすることで、より大きなモデルでは、生成の質（一貫性が74.5％から93.0％に）と制御性（77.5％から91.5％に）の両方が向上することを実証しています。",https://d3i71xaburhd42.cloudfront.net/7d884b40ef5892f61e0f6f358b8e29983f64a178/1-Table1-1.png
Conundrums in Entity Reference Resolution,"['Jing Lu', 'Vincent Ng']",,,なし,
Conversational Semantic Parsing,"['Armen Aghajanyan', 'Jean Maillard', 'Akshat Shrivastava', 'Keith Diedrick', 'Michael Haeger', 'Haoran Li', 'Yashar Mehdad', 'Veselin Stoyanov', 'Anuj Kumar', 'Mike Lewis', 'Sonal Gupta']",http://arxiv.org/abs/2009.13655v1,"The structured representation for semantic parsing in task-oriented assistant systems is geared towards simple understanding of one-turn queries. Due to the limitations of the representation, the session-based properties such as co-reference resolution and context carryover are processed downstream in a pipelined system. In this paper, we propose a semantic representation for such task-oriented conversational systems that can represent concepts such as co-reference and context carryover, enabling comprehensive understanding of queries in a session. We release a new session-based, compositional task-oriented parsing dataset of 20k sessions consisting of 60k utterances. Unlike Dialog State Tracking Challenges, the queries in the dataset have compositional forms. We propose a new family of Seq2Seq models for the session-based parsing above, which achieve better or comparable performance to the current state-of-the-art on ATIS, SNIPS, TOP and DSTC2. Notably, we improve the best known results on DSTC2 by up to 5 points for slot-carryover.","タスク指向のアシスタントシステムにおける意味解析のための構造化された表現は、ワンターンクエリの単純な理解に向けられています。この表現には限界があるため、セッションベースの特性である共参照解決やコンテキストキャリーオーバーなどの処理は、パイプライン化されたシステムでは下流で処理される。本論文では、このようなタスク指向の会話システムのためのセマンティック表現を提案し、セッション内のクエリを包括的に理解することを可能にする、共参照やコンテキストキャリーオーバーなどの概念を表現することができる。我々は、60Kの発話からなる20Kのセッションからなる、セッションベースの構成的タスク指向の構文解析データセットをリリースする。ダイアログ状態追跡課題とは異なり、データセットのクエリは構成形式を持っています。我々は、上記のセッションベースの構文解析のための新しいSeq2Seqモデル群を提案し、ATIS, SNIPS, TOP, DSTC2の最新技術と同等の性能を達成した。特に、DSTC2においては、スロットキャリーオーバーに対して最大5ポイントの改善を達成した。",https://d3i71xaburhd42.cloudfront.net/c5ad46ae286e1c8ad3ffa52d7c5481f7dba83e88/3-Figure1-1.png
Conversational Semantic Parsing for Dialog State Tracking,"['Jianpeng Cheng', 'Devang Agrawal', 'Héctor Martínez Alonso', 'Shruti Bhargava', 'Joris Driesen', 'Federico Flego', 'Dain Kaplan', 'Dimitri Kartsaklis', 'Lin Li', 'Dhivya Piraviperumal', 'Jason D Williams', 'Hong Yu', 'Diarmuid Ó Séaghdha', 'Anders Johannsen']",,,なし,
Convolution over Hierarchical Syntactic and Lexical Graphs for Aspect Level Sentiment Analysis,"['Mi Zhang', 'Tieyun Qian']",,,なし,
Coreferential Reasoning Learning for Language Representation,"['Deming Ye', 'Yankai Lin', 'Jiaju Du', 'Zhenghao Liu', 'Peng Li', 'Maosong Sun', 'Zhiyuan Liu']",http://arxiv.org/abs/2004.06870v2,"Language representation models such as BERT could effectively capture contextual semantic information from plain text, and have been proved to achieve promising results in lots of downstream NLP tasks with appropriate fine-tuning. However, most existing language representation models cannot explicitly handle coreference, which is essential to the coherent understanding of the whole discourse. To address this issue, we present CorefBERT, a novel language representation model that can capture the coreferential relations in context. The experimental results show that, compared with existing baseline models, CorefBERT can achieve significant improvements consistently on various downstream NLP tasks that require coreferential reasoning, while maintaining comparable performance to previous models on other common NLP tasks. The source code and experiment details of this paper can be obtained from https://github.com/thunlp/CorefBERT.",BERT のような言語表現モデルは、平文から文脈的意味情報を効果的に取り込むことができ、適切な微調整を行うことで、多くの下流の NLP タスクで有望な結果が得られることが証明されています。しかし、既存の言語表現モデルの多くは、談話全体の一貫性のある理解に不可欠な共参照を明示的に扱うことができない。この問題を解決するために、本研究では、文脈における共参照関係を捉えることができる新しい言語表現モデルであるCorefBERTを提案する。実験結果は、既存のベースラインモデルと比較して、CorefBERTは、他の一般的なNLPタスクにおいて以前のモデルと同等の性能を維持しながら、corefential推論を必要とする様々な下流のNLPタスクにおいて一貫して大幅な改善を達成できることを示している。本論文のソースコードと実験の詳細は、https:/github.comthunlpCorefBERTから入手できる。,https://d3i71xaburhd42.cloudfront.net/5066c41ef26ac9876ba797a7c7f49548cf713f9b/3-Figure1-1.png
Counterfactual Generator: A Weakly-Supervised Method for Named Entity Recognition,"['Xiangji Zeng', 'Yunliang Li', 'Yuchen Zhai', 'Yin Zhang']",,,なし,
Counterfactual Off-Policy Training for Neural Dialogue Generation,"['Qingfu Zhu', 'Wei-Nan Zhang', 'Ting Liu', 'William Yang Wang']",http://arxiv.org/abs/2004.14507v2,"Open-domain dialogue generation suffers from the data insufficiency problem due to the vast size of potential responses. In this paper, we propose to explore potential responses by counterfactual reasoning. Given an observed response, the counterfactual reasoning model automatically infers the outcome of an alternative policy that could have been taken. The resulting counterfactual response synthesized in hindsight is of higher quality than the response synthesized from scratch. Training on the counterfactual responses under the adversarial learning framework helps to explore the high-reward area of the potential response space. An empirical study on the DailyDialog dataset shows that our approach significantly outperforms the HRED model as well as the conventional adversarial learning approaches.",オープンドメインの対話生成では，潜在的な応答が膨大であるため，データの不足が問題となる．本論文では、カウンターファクチュアル推論を用いて潜在的な応答を探索することを提案する。観察された応答が与えられると、カウンターファクト推論モデルは自動的に代替政策の結果を推論する。その結果、後知恵で合成された反事実応答は、ゼロから合成された応答よりも高品質であることがわかった。逆境学習の枠組みの下でカウンターファクタシャル応答の訓練を行うことで、潜在的な応答空間の高報酬領域を探索することができる。DailyDialogのデータセットを用いた実証研究では、我々のアプローチが従来の敵対的学習アプローチと同様に、HREDモデルを有意に上回ることが示された。,https://d3i71xaburhd42.cloudfront.net/80b92e56b71570f8ee7176b9c43f49b5deeb8726/1-Figure1-1.png
Cross Copy Network for Dialogue Generation,"['Changzhen Ji', 'Xin Zhou', 'Yating Zhang', 'Xiaozhong Liu', 'Changlong Sun', 'Conghui Zhu', 'Tiejun Zhao']",,,なし,
Cross-lingual Spoken Language Understanding with Regularized Representation Alignment,"['Zihan Liu', 'Genta Indra Winata', 'Peng Xu', 'Zhaojiang Lin', 'Pascale Fung']",http://arxiv.org/abs/2009.14510v1,"Despite the promising results of current cross-lingual models for spoken language understanding systems, they still suffer from imperfect cross-lingual representation alignments between the source and target languages, which makes the performance sub-optimal. To cope with this issue, we propose a regularization approach to further align word-level and sentence-level representations across languages without any external resource. First, we regularize the representation of user utterances based on their corresponding labels. Second, we regularize the latent variable model (Liu et al., 2019) by leveraging adversarial training to disentangle the latent variables. Experiments on the cross-lingual spoken language understanding task show that our model outperforms current state-of-the-art methods in both few-shot and zero-shot scenarios, and our model, trained on a few-shot setting with only 3\% of the target language training data, achieves comparable performance to the supervised training with all the training data.",現在の音声言語理解システムのための言語横断モデルは有望な結果を得ているにもかかわらず、ソース言語とターゲット言語の間の不完全な言語横断表現の整列に悩まされており、その性能は最適ではないものとなっている。この問題に対処するために、我々は、外部リソースを必要とせずに言語間で単語レベルと文レベルの表現をさらに整列させる正則化アプローチを提案する。まず、ユーザの発話の表現を、対応するラベルに基づいて正則化する。第二に、我々は潜在変数を分離するために敵対的訓練を活用して潜在変数モデルを正則化する（Liu et al. 言語横断型音声言語理解タスクでの実験では、少数ショットとゼロショットの両方のシナリオにおいて、我々のモデルが現在の最先端の手法よりも優れていることが示され、また、目標言語の訓練データの3%だけで少数ショットの設定で訓練された我々のモデルは、すべての訓練データを用いた教師付き訓練と同等の性能を達成しています。,https://d3i71xaburhd42.cloudfront.net/c9a1a3d128f3d7c5d992cbf3361e70c4d4ed19de/1-Figure1-1.png
Cross-Media Keyphrase Prediction: A Unified Framework with Multi-Modality Multi-Head Attention and Image Wordings,"['Yue Wang', 'Jing Li', 'Michael Lyu', 'Irwin King']",,,なし,
Cross-Thought for Sentence Encoder Pre-training,"['Shuohang Wang', 'Yuwei Fang', 'Siqi Sun', 'Zhe Gan', 'Yu Cheng', 'Jingjing Liu', 'Jing Jiang']",http://arxiv.org/abs/2010.03652v1,"In this paper, we propose Cross-Thought, a novel approach to pre-training sequence encoder, which is instrumental in building reusable sequence embeddings for large-scale NLP tasks such as question answering. Instead of using the original signals of full sentences, we train a Transformer-based sequence encoder over a large set of short sequences, which allows the model to automatically select the most useful information for predicting masked words. Experiments on question answering and textual entailment tasks demonstrate that our pre-trained encoder can outperform state-of-the-art encoders trained with continuous sentence signals as well as traditional masked language modeling baselines. Our proposed approach also achieves new state of the art on HotpotQA (full-wiki setting) by improving intermediate information retrieval performance.",この論文では、質問応答などの大規模なNLPタスクのための再利用可能なシーケンスエンベッディングを構築するのに役立つ、シーケンスエンコーダの事前訓練に対する新しいアプローチであるCross-Thoughtを提案する。完全な文の元の信号を使用する代わりに、短いシーケンスの大規模なセットに対してトランスフォーマーベースのシーケンスエンコーダを訓練する。質問に答えるタスクとテキストを含むタスクの実験では、事前に訓練したエンコーダが、従来のマスク付き言語モデリングのベースラインと同様に、連続文信号で訓練した最先端のエンコーダよりも優れた性能を発揮することが実証されている。また、我々の提案するアプローチは、中間情報の検索性能を向上させることで、HotpotQA（完全なwiki設定）上での新しい状態を達成している。,https://d3i71xaburhd42.cloudfront.net/e77c3097d7605b1b8d61c13617b6fdceac59f9d8/5-Table1-1.png
CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models,"['Nikita Nangia', 'Clara Vania', 'Rasika Bhalerao', 'Samuel R. Bowman']",http://arxiv.org/abs/2010.00133v1,"Pretrained language models, especially masked language models (MLMs) have seen success across many NLP tasks. However, there is ample evidence that they use the cultural biases that are undoubtedly present in the corpora they are trained on, implicitly creating harm with biased representations. To measure some forms of social bias in language models against protected demographic groups in the US, we introduce the Crowdsourced Stereotype Pairs benchmark (CrowS-Pairs). CrowS-Pairs has 1508 examples that cover stereotypes dealing with nine types of bias, like race, religion, and age. In CrowS-Pairs a model is presented with two sentences: one that is more stereotyping and another that is less stereotyping. The data focuses on stereotypes about historically disadvantaged groups and contrasts them with advantaged groups. We find that all three of the widely-used MLMs we evaluate substantially favor sentences that express stereotypes in every category in CrowS-Pairs. As work on building less biased models advances, this dataset can be used as a benchmark to evaluate progress.",予習された言語モデル、特にマスクド言語モデル(MLM)は多くのNLPタスクで成功を収めています。しかし、MLMが訓練されたコーパスに間違いなく存在する文化的なバイアスを利用しており、暗黙のうちに偏った表現で害を与えているという十分な証拠があります。米国の保護された人口集団に対する言語モデルにおける社会的バイアスのいくつかの形態を測定するために、Crowdsourced Stereotype Pairsベンチマーク(CrowS-Pairs)を導入する。CrowS-Pairsには、人種、宗教、年齢など9つのタイプのバイアスを扱うステレオタイプをカバーする1508の例がある。CrowS-Pairsでは、モデルは2つの文で提示されます：1つはステレオタイプが多い文、もう1つはステレオタイプが少ない文です。データは、歴史的に不利な立場にあるグループに関するステレオタイプに焦点を当て、有利なグループと対比させています。我々が評価する広く使われているMLMの3つのすべてが、CrowS-Pairsのすべてのカテゴリでステレオタイプを表現する文章を実質的に支持していることがわかりました。より偏りの少ないモデルの構築が進むにつれて、このデータセットは進歩を評価するためのベンチマークとして使用することができる。,https://d3i71xaburhd42.cloudfront.net/645bd6eadc247989abc5e0b0aa0be79ec8b11ea6/2-Table1-1.png
CSP: Code-Switching Pre-training for Neural Machine Translation,"['Zhen Yang', 'Bojie Hu', 'ambyera han', 'shen huang', 'Qi Ju']",,,なし,
DagoBERT: Generating Derivational Morphology with a Pretrained Language Model,"['Valentin Hofmann', 'Janet Pierrehumbert', 'Hinrich Schütze']",http://arxiv.org/abs/2005.00672v2,"Can pretrained language models (PLMs) generate derivationally complex words? We present the first study investigating this question, taking BERT as the example PLM. We examine BERT's derivational capabilities in different settings, ranging from using the unmodified pretrained model to full finetuning. Our best model, DagoBERT (Derivationally and generatively optimized BERT), clearly outperforms the previous state of the art in derivation generation (DG). Furthermore, our experiments show that the input segmentation crucially impacts BERT's derivational knowledge, suggesting that the performance of PLMs could be further improved if a morphologically informed vocabulary of units were used.",事前学習言語モデル（PLM）は、派生的に複雑な単語を生成することができるのだろうか？我々は、PLMの例としてBERTを取り上げ、この疑問を調査した最初の研究を発表する。我々は、修正されていない事前訓練モデルの使用から完全な微調整まで、さまざまな設定でのBERTの派生能力を検証している。我々の最良モデルであるDagoBERT（Derivationally and generatively optimized BERT）は、明らかに導出生成（DG）における以前の技術状態を凌駕している。さらに、我々の実験では、入力セグメンテーションがBERTの派生知識に決定的な影響を与えることが示されており、形態学的に情報を得た単位の語彙が使用される場合、PLMの性能がさらに向上する可能性があることが示唆されている。,
Data and Representation for Turkish Natural Language Inference,"['Emrah Budur', 'Rıza Özçelik', 'Tunga Gungor', 'Christopher Potts']",,,なし,
Data Boost: Text Data Augmentation Through Reinforcement Learning Guided Conditional Generation,"['Ruibo Liu', 'Guangxuan Xu', 'Chenyan Jia', 'Weicheng Ma', 'Lili Wang', 'Soroush Vosoughi']",,,なし,
Data Rejuvenation: Exploiting Inactive Training Examples for Neural Machine Translation,"['Wenxiang Jiao', 'Xing Wang', 'Shilin He', 'Irwin King', 'Michael Lyu', 'Zhaopeng Tu']",http://arxiv.org/abs/2010.02552v1,"Large-scale training datasets lie at the core of the recent success of neural machine translation (NMT) models. However, the complex patterns and potential noises in the large-scale data make training NMT models difficult. In this work, we explore to identify the inactive training examples which contribute less to the model performance, and show that the existence of inactive examples depends on the data distribution. We further introduce data rejuvenation to improve the training of NMT models on large-scale datasets by exploiting inactive examples. The proposed framework consists of three phases. First, we train an identification model on the original training data, and use it to distinguish inactive examples and active examples by their sentence-level output probabilities. Then, we train a rejuvenation model on the active examples, which is used to re-label the inactive examples with forward-translation. Finally, the rejuvenated examples and the active examples are combined to train the final NMT model. Experimental results on WMT14 English-German and English-French datasets show that the proposed data rejuvenation consistently and significantly improves performance for several strong NMT models. Extensive analyses reveal that our approach stabilizes and accelerates the training process of NMT models, resulting in final models with better generalization capability.",近年のニューラル機械翻訳（NMT）モデルの成功の核心は、大規模なトレーニングデータセットにあります。しかし、大規模データには複雑なパターンや潜在的なノイズが含まれているため、NMTモデルの訓練は困難である。本研究では、モデルの性能への貢献度が低い非アクティブな訓練例を特定することを探求し、非アクティブな訓練例の存在がデータの分布に依存することを示す。さらに、不活性例を利用して大規模データセット上でのNMTモデルの学習を改善するためのデータリジュビネーションを導入する。提案するフレームワークは3つのフェーズからなる。まず、元の学習データに対して識別モデルを学習し、文レベルの出力確率によって不活性例と活性例を区別する。次に、アクティブな例に対して若返りモデルを学習し、非アクティブな例を前方変換で再ラベル付けするために用いる。最後に、若返った例と能動的な例を組み合わせて、最終的なNMTモデルを学習する。WMT14英語-ドイツ語と英語-フランス語のデータセットを用いた実験結果から、提案するデータ若返りは、いくつかの強力なNMTモデルの性能を一貫して大幅に向上させることが示された。広範な解析により、我々のアプローチがNMTモデルの学習プロセスを安定化し、加速させ、結果としてより優れた一般化能力を持つ最終モデルをもたらすことが明らかになった。,https://d3i71xaburhd42.cloudfront.net/8bb84249b548e58494ed66efba86621449d49dc1/3-Figure1-1.png
Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics,"['Swabha Swayamdipta', 'Roy Schwartz', 'Nicholas Lourie', 'Yizhong Wang', 'Hannaneh Hajishirzi', 'Noah A. Smith', 'Yejin Choi']",http://arxiv.org/abs/2009.10795v2,"Large datasets have become commonplace in NLP research. However, the increased emphasis on data quantity has made it challenging to assess the quality of data. We introduce Data Maps---a model-based tool to characterize and diagnose datasets. We leverage a largely ignored source of information: the behavior of the model on individual instances during training (training dynamics) for building data maps. This yields two intuitive measures for each example---the model's confidence in the true class, and the variability of this confidence across epochs---obtained in a single run of training. Experiments across four datasets show that these model-dependent measures reveal three distinct regions in the data map, each with pronounced characteristics. First, our data maps show the presence of ""ambiguous"" regions with respect to the model, which contribute the most towards out-of-distribution generalization. Second, the most populous regions in the data are ""easy to learn"" for the model, and play an important role in model optimization. Finally, data maps uncover a region with instances that the model finds ""hard to learn""; these often correspond to labeling errors. Our results indicate that a shift in focus from quantity to quality of data could lead to robust models and improved out-of-distribution generalization.",NLP研究では、大規模なデータセットが当たり前になってきています。しかし、データ量を重視するあまり、データの質を評価することが難しくなってきています。我々は、データセットを特徴づけ、診断するためのモデルベースのツールであるデータマップを紹介します。我々は、ほとんど無視されてきた情報源を活用しています：データマップを構築するために、トレーニング中の個々のインスタンス上でのモデルの振る舞い（トレーニングダイナミクス）です。これにより、各例について2つの直感的な測定値が得られます--真のクラスに対するモデルの信頼度と、エポック間の信頼度の変動--が、1回の訓練で得られます。4つのデータセットでの実験では、これらのモデル依存の測定値がデータマップに3つの異なる領域を明らかにし、それぞれが顕著な特徴を持っていることを示しています。第一に、我々のデータマップは、モデルに関して「曖昧な」領域の存在を示しており、それは分布外の一般化に最も貢献しています。第二に、データの中で最も人口の多い領域は、モデルにとって「学習しやすい」領域であり、モデルの最適化において重要な役割を果たします。最後に、データマップは、モデルが「学習しにくい」と判断するインスタンスを持つ領域を発見します。我々の結果は、データの量から質への焦点のシフトが、ロバストモデルと分布外一般化の改善につながる可能性を示している。,https://d3i71xaburhd42.cloudfront.net/ee5fff85d3ec62698eddba162f054b7e73670b2a/1-Figure1-1.png
De-biased Court’s View Generation with Causality,"['Yiquan Wu', 'Kun Kuang', 'Yating Zhang', 'Xiaozhong Liu', 'Changlong Sun', 'Jun Xiao', 'Yueting Zhuang', 'Luo Si', 'Fei Wu']",,,なし,
Debiasing knowledge graph embeddings,"['Joseph Fisher', 'Arpit Mittal', 'Dave Palfrey', 'Christos Christodoulopoulos']",,,なし,
Deep Attentive Stock Forecasting factoring Social Media Linguistics and Company Correlations,"['Ramit Sawhney', 'Shivam Agarwal', 'Arnav Wadhwa', 'Rajiv Ratn Shah']",,,なし,
Deep Weighted MaxSAT for Aspect-based Opinion Extraction,"['Meixi Wu', 'Wenya Wang', 'Sinno Jialin Pan']",,,なし,
Dense Passage Retrieval for Open-Domain Question Answering,"['Vladimir Karpukhin', 'Barlas Oguz', 'Sewon Min', 'Patrick Lewis', 'Ledell Wu', 'Sergey Edunov', 'Danqi Chen', 'Wen-tau Yih']",http://arxiv.org/abs/2004.04906v3,"Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.",オープンドメインの質問応答は、候補文脈を選択するための効率的な通路検索に依存しており、TF-IDFやBM25のような従来の疎なベクトル空間モデルが事実上の方法である。本研究では、少ない数の質問とパッセージから単純なデュアルエンコーダーフレームワークを用いてエンベッディングを学習し、密な表現のみを用いて検索が実用的に実装できることを示す。広範囲のオープンドメインQAデータセットで評価したところ、我々の密表現検索器は、上位20位以内の通過検索精度において、強力なLucene-BM25システムを9%〜19%の絶対値で大きく上回り、我々のエンドツーエンドQAシステムが複数のオープンドメインQAベンチマークにおいて新たな最先端を確立するのに貢献した。,https://d3i71xaburhd42.cloudfront.net/b26f2037f769d5ffc5f7bdcec2de8da28ec14bee/5-Table1-1.png
Design Challenges in Low-resource Cross-lingual Entity Linking,"['Xingyu Fu', 'Weijia Shi', 'Xiaodong Yu', 'Zian Zhao', 'Dan Roth']",http://arxiv.org/abs/2005.00692v2,"Cross-lingual Entity Linking (XEL), the problem of grounding mentions of entities in a foreign language text into an English knowledge base such as Wikipedia, has seen a lot of research in recent years, with a range of promising techniques. However, current techniques do not rise to the challenges introduced by text in low-resource languages (LRL) and, surprisingly, fail to generalize to text not taken from Wikipedia, on which they are usually trained. This paper provides a thorough analysis of low-resource XEL techniques, focusing on the key step of identifying candidate English Wikipedia titles that correspond to a given foreign language mention. Our analysis indicates that current methods are limited by their reliance on Wikipedia's interlanguage links and thus suffer when the foreign language's Wikipedia is small. We conclude that the LRL setting requires the use of outside-Wikipedia cross-lingual resources and present a simple yet effective zero-shot XEL system, QuEL, that utilizes search engines query logs. With experiments on 25 languages, QuEL~shows an average increase of 25\% in gold candidate recall and of 13\% in end-to-end linking accuracy over state-of-the-art baselines.",Cross-lingual Entity Linking (XEL)は、外国語テキスト中の実体の言及をウィキペディアのような英語の知識ベースに定着させる問題で、近年多くの研究が行われており、様々な有望な技術が開発されています。しかし、現在の技術は、低リソース言語（LRL）のテキストがもたらす課題には対応しておらず、驚くべきことに、これらの技術が通常学習されるウィキペディアから取得されたテキスト以外のテキストには一般化できない。この論文では、与えられた外国語の言及に対応する英語版ウィキペディアのタイトル候補を特定するという重要なステップに焦点を当てて、低リソースXEL技術の徹底的な分析を行う。我々の分析によると、現在の手法はウィキペディアの言語間リンクに依存しているために制限されており、外国語のウィキペディアが少ない場合に苦戦することが示された。我々は、LRLの設定では、外部のウィキペディアのクロスランゲージリソースの使用が必要であると結論付け、検索エンジンのクエリログを利用したシンプルで効果的なゼロショットXELシステム、QuELを提示した。25言語で実験を行った結果、QuELは、ゴールド候補の想起率が平均25%増加し、エンドツーエンドのリンク精度が13%増加することを示した。,https://d3i71xaburhd42.cloudfront.net/2675bca9c9d71324f698744ce29e38186b06ee4d/3-Table1-1.png
Detecting Attackable Sentences in Arguments,"['Yohan Jo', 'Seojin Bang', 'Emaad Manzoor', 'Eduard Hovy', 'Chris Reed']",http://arxiv.org/abs/2010.02660v1,"Finding attackable sentences in an argument is the first step toward successful refutation in argumentation. We present a first large-scale analysis of sentence attackability in online arguments. We analyze driving reasons for attacks in argumentation and identify relevant characteristics of sentences. We demonstrate that a sentence's attackability is associated with many of these characteristics regarding the sentence's content, proposition types, and tone, and that an external knowledge source can provide useful information about attackability. Building on these findings, we demonstrate that machine learning models can automatically detect attackable sentences in arguments, significantly better than several baselines and comparably well to laypeople.",議論の中から攻撃可能な文を見つけることは、議論における反論を成功させるための第一歩である。本研究では、オンライン議論における文章の攻撃性を初めて大規模に分析した。本研究では、議論における攻撃性の原因を分析し、文の特徴を特定する。その結果、文の攻撃性は、文の内容、命題の種類、論調などの多くの特徴と関連しており、外部の知識源が攻撃性に関する有用な情報を提供してくれることを実証した。これらの知見を基に、機械学習モデルが議論の中で攻撃可能な文を自動的に検出できることを実証し、いくつかのベースラインよりも有意に優れており、一般の人でも比較的に良好であることを示す。,https://d3i71xaburhd42.cloudfront.net/33e5e4b079535957d1275497f8870ea57762a03d/1-Figure1-1.png
Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News,"['Reuben Tan', 'Bryan Plummer', 'Kate Saenko']",http://arxiv.org/abs/2009.07698v4,"Large-scale dissemination of disinformation online intended to mislead or deceive the general population is a major societal problem. Rapid progression in image, video, and natural language generative models has only exacerbated this situation and intensified our need for an effective defense mechanism. While existing approaches have been proposed to defend against neural fake news, they are generally constrained to the very limited setting where articles only have text and metadata such as the title and authors. In this paper, we introduce the more realistic and challenging task of defending against machine-generated news that also includes images and captions. To identify the possible weaknesses that adversaries can exploit, we create a NeuralNews dataset composed of 4 different types of generated articles as well as conduct a series of human user study experiments based on this dataset. In addition to the valuable insights gleaned from our user study experiments, we provide a relatively effective approach based on detecting visual-semantic inconsistencies, which will serve as an effective first line of defense and a useful reference for future work in defending against machine-generated disinformation.",一般の人々を誤解させたり欺いたりすることを目的とした、オンライン上での大規模な誤報の流布は、大きな社会問題となっている。画像、ビデオ、自然言語生成モデルの急速な進歩は、この状況を悪化させ、効果的な防御メカニズムの必要性を強めています。既存のアプローチは、ニューラルフェイクニュースを防御するために提案されているが、一般的には、記事にはタイトルや著者などのテキストとメタデータしかないという非常に限られた設定に制約されている。本論文では、画像やキャプションを含む機械生成のニュースを防御するという、より現実的で困難な課題を紹介する。敵が悪用する可能性のある弱点を特定するために、4つの異なるタイプの生成記事からなるNeuralNewsデータセットを作成し、このデータセットに基づいて一連の人間によるユーザー研究実験を行う。この実験から得られた貴重な知見に加えて、視覚的意味的矛盾の検出に基づく比較的効果的なアプローチを提供している。,https://d3i71xaburhd42.cloudfront.net/70c7eb070b151d6e06e2a86107aa6815edb3f1d1/1-Figure1-1.png
Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning To Rank,"['Eleftheria Briakou', 'Marine Carpuat']",http://arxiv.org/abs/2010.03662v1,"Detecting fine-grained differences in content conveyed in different languages matters for cross-lingual NLP and multilingual corpora analysis, but it is a challenging machine learning problem since annotation is expensive and hard to scale. This work improves the prediction and annotation of fine-grained semantic divergences. We introduce a training strategy for multilingual BERT models by learning to rank synthetic divergent examples of varying granularity. We evaluate our models on the Rationalized English-French Semantic Divergences, a new dataset released with this work, consisting of English-French sentence-pairs annotated with semantic divergence classes and token-level rationales. Learning to rank helps detect fine-grained sentence-level divergences more accurately than a strong sentence-level similarity model, while token-level predictions have the potential of further distinguishing between coarse and fine-grained divergences.",異なる言語で伝えられる内容の微細な差異を検出することは、異言語NLPや多言語コーパス解析において重要であるが、アノテーションが高価でスケールアップが困難であるため、機械学習の課題となっている。本研究では、微細な意味的発散の予測とアノテーションを改善する。本研究では、粒度の異なる合成発散例をランク付けして学習することにより、多言語BERTモデルの学習方法を紹介する。本研究では、意味的発散クラスとトークンレベルの合理性が付与された英仏文対からなる新しいデータセットであるRationalized English-French Semantic Divergencesを用いてモデルを評価した。ランク付けを学習することで、強い文レベルの類似性モデルよりも細かい文レベルの発散を正確に検出することができ、トークンレベルの予測は粗い発散と細かい発散をさらに区別することができる可能性がある。,https://d3i71xaburhd42.cloudfront.net/aa6f9d83d44f15618e04dadfa138531542bfeff8/3-Table1-1.png
Dialogue Distillation: Open-domain Dialogue Augmentation Using Unpaired Data,"['Rongsheng Zhang', 'Yinhe Zheng', 'Jianzhi Shao', 'Xiao-Xi Mao', 'Yadong Xi', 'Minlie Huang']",http://arxiv.org/abs/2009.09427v1,"Recent advances in open-domain dialogue systems rely on the success of neural models that are trained on large-scale data. However, collecting large-scale dialogue data is usually time-consuming and labor-intensive. To address this data dilemma, we propose a novel data augmentation method for training open-domain dialogue models by utilizing unpaired data. Specifically, a data-level distillation process is first proposed to construct augmented dialogues where both post and response are retrieved from the unpaired data. A ranking module is employed to filter out low-quality dialogues. Further, a model-level distillation process is employed to distill a teacher model trained on high-quality paired data to augmented dialogue pairs, thereby preventing dialogue models from being affected by the noise in the augmented data. Automatic and manual evaluation indicates that our method can produce high-quality dialogue pairs with diverse contents, and the proposed data-level and model-level dialogue distillation can improve the performance of competitive baselines.",最近のオープンドメイン対話システムの進歩は、大規模データを用いて学習されたニューラルモデルの成功に依存している。しかし、大規模な対話データの収集には時間と労力がかかる。このジレンマを解決するために、本研究では、オープンドメイン対話モデルを学習するために、不対のデータを利用した新しいデータ補強法を提案する。具体的には、まず、データレベルの蒸留プロセスを提案し、不対のデータからポストとレスポンスの両方を取得することで、拡張対話を構築する。低品質の対話をフィルタリングするために、ランキングモジュールを採用する。さらに、モデルレベルの蒸留プロセスを用いて、高品質のペアデータで訓練された教師モデルを拡張対話ペアに蒸留することで、対話モデルが拡張データのノイズの影響を受けないようにする。自動評価および手動評価の結果、本手法は多様な内容の高品質な対話ペアを生成できることが示され、提案されたデータレベルおよびモデルレベルの対話蒸留プロセスは競争力のあるベースラインの性能を向上させることができる。,https://d3i71xaburhd42.cloudfront.net/3c032d7a959c743808d49bfb3e30da13c065c20b/1-Figure1-1.png
Dialogue Response Ranking Training with Large-Scale Human Feedback Data,"['Xiang Gao', 'Yizhe Zhang', 'Michel Galley', 'Chris Brockett', 'Bill Dolan']",http://arxiv.org/abs/2009.06978v1,"Existing open-domain dialog models are generally trained to minimize the perplexity of target human responses. However, some human replies are more engaging than others, spawning more followup interactions. Current conversational models are increasingly capable of producing turns that are context-relevant, but in order to produce compelling agents, these models need to be able to predict and optimize for turns that are genuinely engaging. We leverage social media feedback data (number of replies and upvotes) to build a large-scale training dataset for feedback prediction. To alleviate possible distortion between the feedback and engagingness, we convert the ranking problem to a comparison of response pairs which involve few confounding factors. We trained DialogRPT, a set of GPT-2 based models on 133M pairs of human feedback data and the resulting ranker outperformed several baselines. Particularly, our ranker outperforms the conventional dialog perplexity baseline with a large margin on predicting Reddit feedback. We finally combine the feedback prediction models and a human-like scoring model to rank the machine-generated dialog responses. Crowd-sourced human evaluation shows that our ranking method correlates better with real human preferences than baseline models.","既存のオープンドメインダイアログモデルは一般的に、ターゲットとなる人間の応答の複雑さを最小限に抑えるように訓練されています。しかし、人間の応答の中には、他のものよりも魅力的なものもあり、それによってフォローアップインタラクションが多く発生します。現在の会話モデルは文脈に関連したターンを生成できるようになってきているが、説得力のあるエージェントを生成するためには、これらのモデルが本当に魅力的なターンを予測し、最適化できる必要がある。我々は、フィードバック予測のための大規模なトレーニングデータセットを構築するために、ソーシャルメディアのフィードバックデータ（返信数とアップコメント数）を活用している。フィードバックとエンゲージメントの間の歪みを軽減するために、ランキング問題を交絡因子の少ない応答ペアの比較に変換しました。我々は、GPT-2ベースのモデルセットであるDialogRPTを1億3,300万組の人間のフィードバックデータ上で訓練し、その結果として得られたランカーは、いくつかのベースラインよりも優れた性能を示しました。特に、我々のランカーは、Redditのフィードバックを予測する上で、従来のダイアログの複雑さのベースラインを大きく上回る結果を得ました。最終的に、フィードバック予測モデルと人間のようなスコアリングモデルを組み合わせて、機械で生成されたダイアログの応答をランク付けする。クラウドソーシングによる人間の評価によると、我々のランキング手法はベースラインモデルよりも実際の人間の好みとの相関性が高いことが示された。",https://d3i71xaburhd42.cloudfront.net/32722fb49e981d0e53b1ff3c064850548f0b54e0/1-Figure1-1.png
Digital Voicing of Silent Speech,"['David Gaddy', 'Dan Klein']",http://arxiv.org/abs/2010.02960v1,"In this paper, we consider the task of digitally voicing silent speech, where silently mouthed words are converted to audible speech based on electromyography (EMG) sensor measurements that capture muscle impulses. While prior work has focused on training speech synthesis models from EMG collected during vocalized speech, we are the first to train from EMG collected during silently articulated speech. We introduce a method of training on silent EMG by transferring audio targets from vocalized to silent signals. Our method greatly improves intelligibility of audio generated from silent EMG compared to a baseline that only trains with vocalized data, decreasing transcription word error rate from 64% to 4% in one data condition and 88% to 68% in another. To spur further development on this task, we share our new dataset of silent and vocalized facial EMG measurements.",本論文では、無声発声音声をデジタル発声する課題を検討しています。これまでの研究では、発声時の筋電図から音声合成モデルを学習することが中心でしたが、本研究では無声発話時の筋電図から学習することに初めて成功しました。本研究では、発声時の筋電図から無声発話時の筋電図を学習する方法を紹介します。本研究では、無声筋電図から生成された音声の明瞭度を、発声されたデータのみで学習したベースラインと比較して大幅に向上させ、転写ワードエラー率をあるデータ条件では64%から4%に、別の条件では88%から68%に低下させた。このタスクのさらなる開発に拍車をかけるために、我々は無声と発声の顔面筋電図測定の新しいデータセットを共有しています。,https://d3i71xaburhd42.cloudfront.net/268a1ab0b76fa27595773840e7dce03f3f85156c/1-Figure1-1.png
Direct Segmentation Models for Streaming Speech Translation,"['Javier Iranzo-Sánchez', 'Adrià Giménez Pastor', 'Joan Albert Silvestre-Cerdà', 'Pau Baquero-Arnal', 'Jorge Civera Saiz', 'Alfons Juan']",,,なし,
Discern: Discourse-Aware Entailment Reasoning Network for Conversational Machine Reading,"['Yifan Gao', 'Chien-Sheng Wu', 'Jingjing Li', 'Shafiq Joty', 'Steven C.H. Hoi', 'Caiming Xiong', 'Irwin King', 'Michael Lyu']",http://arxiv.org/abs/2010.01838v3,"Document interpretation and dialog understanding are the two major challenges for conversational machine reading. In this work, we propose Discern, a discourse-aware entailment reasoning network to strengthen the connection and enhance the understanding for both document and dialog. Specifically, we split the document into clause-like elementary discourse units (EDU) using a pre-trained discourse segmentation model, and we train our model in a weakly-supervised manner to predict whether each EDU is entailed by the user feedback in a conversation. Based on the learned EDU and entailment representations, we either reply to the user our final decision ""yes/no/irrelevant"" of the initial question, or generate a follow-up question to inquiry more information. Our experiments on the ShARC benchmark (blind, held-out test set) show that Discern achieves state-of-the-art results of 78.3% macro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question generation. Code and models are released at https://github.com/Yifan-Gao/Discern.",会話型機械読解では、文書の解釈と対話の理解が2つの大きな課題となっている。本研究では、文書と対話の双方の接続を強化し、理解度を高めるために、Discernを提案している。具体的には、事前に学習した談話セグメンテーションモデルを用いて、文書を節のような初歩的な談話単位（EDU）に分割し、各EDUが会話の中でユーザのフィードバックによってエンテーリングされているかどうかを予測するために、弱教師付きでモデルを学習する。学習したEDUとエンテーリング表現に基づいて、我々はユーザに対して最初の質問の最終的な決定を「yesnoirrelevant」と回答するか、あるいはより多くの情報を問い合わせるためのフォローアップ質問を生成する。ShARCベンチマーク（ブラインド、ホールドアウトテストセット）での実験では、Discernが意思決定のマクロ平均精度78.3％、フォローアップ質問生成のマクロ平均精度64.0BLEU1という最先端の結果を達成していることを示しています。コードとモデルはhttps:/github.comYifan-GaoDiscernで公開されています。,https://d3i71xaburhd42.cloudfront.net/4571feb26d903053661efd2f2f144e010902f458/6-Table1-1.png
Discontinuous Constituent Parsing as Sequence Labeling,"['David Vilares', 'Carlos Gómez-Rodríguez']",http://arxiv.org/abs/2010.00633v1,"This paper reduces discontinuous parsing to sequence labeling. It first shows that existing reductions for constituent parsing as labeling do not support discontinuities. Second, it fills this gap and proposes to encode tree discontinuities as nearly ordered permutations of the input sequence. Third, it studies whether such discontinuous representations are learnable. The experiments show that despite the architectural simplicity, under the right representation, the models are fast and accurate.",この論文では、不連続解析をシーケンスラベリングに還元する。まず，ラベリングとしての構成要素解析のための既存の削減法が不連続性をサポートしていないことを示す．第二に，このギャップを埋め，木の不連続性を入力配列のほぼ順序付きの順列の組み合わせとして符号化することを提案する．第三に，このような不連続性表現が学習可能かどうかを研究する．実験により、アーキテクチャの単純さにもかかわらず、正しい表現の下では、モデルが高速で正確であることが示された。,https://d3i71xaburhd42.cloudfront.net/a921635fe8403a609e8118bd38cc3c651f6f5ca0/1-Figure1-1.png
Discourse Self-Attention for Discourse Element Identification in Argumentative Student Essays,"['Wei Song', 'Ziyao Song', 'Ruiji Fu', 'Lizhen Liu', 'Miaomiao Cheng', 'Ting Liu']",,,なし,
Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference,"['Jianguo Zhang', 'Kazuma Hashimoto', 'Wenhao Liu', 'Chien-Sheng Wu', 'Yao Wan', 'Philip Yu', 'Richard Socher', 'Caiming Xiong']",,,なし,
Discriminatively-Tuned Generative Classifiers for Robust Natural Language Inference,"['Xiaoan Ding', 'Tianyu Liu', 'Baobao Chang', 'Zhifang Sui', 'Kevin Gimpel']",http://arxiv.org/abs/2010.03760v1,"While discriminative neural network classifiers are generally preferred, recent work has shown advantages of generative classifiers in term of data efficiency and robustness. In this paper, we focus on natural language inference (NLI). We propose GenNLI, a generative classifier for NLI tasks, and empirically characterize its performance by comparing it to five baselines, including discriminative models and large-scale pretrained language representation models like BERT. We explore training objectives for discriminative fine-tuning of our generative classifiers, showing improvements over log loss fine-tuning from prior work . In particular, we find strong results with a simple unbounded modification to log loss, which we call the ""infinilog loss"". Our experiments show that GenNLI outperforms both discriminative and pretrained baselines across several challenging NLI experimental settings, including small training sets, imbalanced label distributions, and label noise.",一般的には識別的ニューラルネットワーク分類器が好まれるが、最近の研究ではデータの効率性やロバスト性の観点から生成的分類器の利点が示されている。本論文では、自然言語推論(NLI)に焦点を当てる。我々は、NLIタスクのための生成的分類器であるGenNLIを提案し、識別モデルやBERTのような大規模な事前学習済み言語表現モデルを含む5つのベースラインと比較することで、その性能を実証的に特徴付けている。我々は、我々の生成的分類器の識別的微調整のための訓練目標を探求し、先行研究の対数損失微調整よりも改善されていることを示した。特に、我々は「無限ログ損失」と呼ぶ単純な対数損失の無制限修正で強い結果が得られることを発見した。我々の実験では、小さな学習セット、不均衡なラベル分布、ラベルノイズを含むいくつかの困難なNLI実験設定において、GenNLIが識別的ベースラインと事前学習されたベースラインの両方を凌駕することが示されている。,https://d3i71xaburhd42.cloudfront.net/911c705abd1232653d9109c142238c2c73d49574/6-Table2-1.png
Disentangle-based Continual Graph Representation Learning,"['Xiaoyu Kou', 'Yankai Lin', 'Shaobo Liu', 'Peng Li', 'Jie Zhou', 'Yan Zhang']",http://arxiv.org/abs/2010.02565v1,"Graph embedding (GE) methods embed nodes (and/or edges) in graph into a low-dimensional semantic space, and have shown its effectiveness in modeling multi-relational data. However, existing GE models are not practical in real-world applications since it overlooked the streaming nature of incoming data. To address this issue, we study the problem of continual graph representation learning which aims to continually train a GE model on new data to learn incessantly emerging multi-relational data while avoiding catastrophically forgetting old learned knowledge. Moreover, we propose a disentangle-based continual graph representation learning (DiCGRL) framework inspired by the human's ability to learn procedural knowledge. The experimental results show that DiCGRL could effectively alleviate the catastrophic forgetting problem and outperform state-of-the-art continual learning models. The code and datasets are released on https://github.com/KXY-PUBLIC/DiCGRL.",グラフ埋め込み(GE)法は、グラフのノード(およびエッジ)を低次元の意味空間に埋め込む手法であり、多相関データのモデル化に有効であることが示されている。しかし、既存のGEモデルは、入力データのストリーミング性を見落としているため、実際のアプリケーションでは実用的ではない。この問題を解決するために、本研究では、絶え間なく出現する多関係データを学習するために、新しいデータ上でGEモデルを継続的に訓練し、学習した古い知識を壊滅的に忘れないようにすることを目的とした継続的グラフ表現学習の問題を研究している。さらに、人間の手続き的な知識を学習する能力にヒントを得たディセンタングルベースの継続的グラフ表現学習(DiCGRL)フレームワークを提案する。実験結果は、DiCGRLが壊滅的な忘却問題を効果的に緩和し、最先端の継続学習モデルを上回る性能を持つことを示している。コードとデータセットはhttps:/github.comKXY-PUBLICDiCGRLで公開されています。,https://d3i71xaburhd42.cloudfront.net/5c8239d961f06c8f7a9d1baf6bfd14fe0c1f4beb/1-Figure1-1.png
Dissecting Span Identification Tasks with Performance Prediction,"['Sean Papay', 'Roman Klinger', 'Sebastian Padó']",http://arxiv.org/abs/2010.02587v1,"Span identification (in short, span ID) tasks such as chunking, NER, or code-switching detection, ask models to identify and classify relevant spans in a text. Despite being a staple of NLP, and sharing a common structure, there is little insight on how these tasks' properties influence their difficulty, and thus little guidance on what model families work well on span ID tasks, and why. We analyze span ID tasks via performance prediction, estimating how well neural architectures do on different tasks. Our contributions are: (a) we identify key properties of span ID tasks that can inform performance prediction; (b) we carry out a large-scale experiment on English data, building a model to predict performance for unseen span ID tasks that can support architecture choices; (c), we investigate the parameters of the meta model, yielding new insights on how model and task properties interact to affect span ID performance. We find, e.g., that span frequency is especially important for LSTMs, and that CRFs help when spans are infrequent and boundaries non-distinctive.",チャンキング、NER、コード切り替え検出などのスパン識別（簡単に言えばスパン ID）タスクでは、モデルにテキスト内の関連するスパンを識別して分類するよう求めます。NLPの定番であり、共通の構造を共有しているにもかかわらず、これらのタスクの特性がタスクの難易度にどのような影響を与えるのかについての洞察はほとんどなく、したがって、どのモデルファミリーがスパン識別タスクに適しているのか、またその理由についての指針はほとんどありません。我々は、性能予測を用いてスパンIDタスクを分析し、異なるタスクでニューラルアーキテクチャがどの程度うまく機能するかを推定しています。我々の貢献は以下の通りです。(a) パフォーマンス予測に役立つスパン ID タスクの主要な特性を特定する。(b) 英語データを用いた大規模な実験を行い、アーキテクチャの選択を支援することができる見たことのないスパン ID タスクのパフォーマンスを予測するモデルを構築する。(c) メタモデルのパラメータを調査し、モデルとタスクの特性がどのように相互作用してスパン ID パフォーマンスに影響を与えるかについて新たな知見を得る。(c)メタモデルのパラメータを調査し、モデルとタスクの特性がどのように相互作用してスパンID性能に影響を与えるかについての新たな知見を得る。例えば、スパンの頻度はLSTMにとって特に重要であり、スパンが少なく境界が区別できない場合にはCRFが役立つことがわかった。,https://d3i71xaburhd42.cloudfront.net/de1d5940ddc0ed49efc10eee1aef8bcff711e0be/2-Table1-1.png
Distilling Multiple Domains for Neural Machine Translation,"['Anna Currey', 'Prashant Mathur', 'Georgiana Dinu']",,,なし,
"Diverse, Controllable, and Keyphrase-Aware: A Corpus and Method for News Multi-Headline Generation","['Dayiheng Liu', 'Yeyun Gong', 'Yu Yan', 'Jie Fu', 'Bo Shao', 'Daxin Jiang', 'Jiancheng Lv', 'Nan Duan']",http://arxiv.org/abs/2004.03875v2,"News headline generation aims to produce a short sentence to attract readers to read the news. One news article often contains multiple keyphrases that are of interest to different users, which can naturally have multiple reasonable headlines. However, most existing methods focus on the single headline generation. In this paper, we propose generating multiple headlines with keyphrases of user interests, whose main idea is to generate multiple keyphrases of interest to users for the news first, and then generate multiple keyphrase-relevant headlines. We propose a multi-source Transformer decoder, which takes three sources as inputs: (a) keyphrase, (b) keyphrase-filtered article, and (c) original article to generate keyphrase-relevant, high-quality, and diverse headlines. Furthermore, we propose a simple and effective method to mine the keyphrases of interest in the news article and build a first large-scale keyphrase-aware news headline corpus, which contains over 180K aligned triples of $<$news article, headline, keyphrase$>$. Extensive experimental comparisons on the real-world dataset show that the proposed method achieves state-of-the-art results in terms of quality and diversity",ニュースの見出し生成は、読者にニュースを読んでもらうための短い文章を生成することを目的としています。1つのニュース記事には、異なるユーザーが興味を持つ複数のキーワードが含まれていることが多く、当然ながら複数の合理的な見出しを持つことができます。しかし、既存のほとんどの手法は、単一の見出し生成に焦点を当てている。本稿では、まずニュースに対してユーザが興味を持つ複数のキーフレーズを生成し、そのキーフレーズに関連した複数の見出しを生成することを主眼とした、ユーザの興味のあるキーフレーズを含む複数の見出しを生成することを提案する。我々は、3つのソースを入力とするマルチソーストランスフォーマーデコーダを提案する。(a)キーフレーズ、(b)キーフレーズフィルタリングされた記事、(c)オリジナル記事の3つのソースを入力とし、キーフレーズに関連した高品質で多様な見出しを生成するマルチソーストランスフォーマーを提案する。さらに、ニュース記事に含まれる興味のあるキーフレーズをマイニングする簡単で効果的な方法を提案し、最初の大規模なキーフレーズを意識したニュース見出しコーパスを構築する。実世界のデータセットを用いた広範な実験比較により、提案手法が品質と多様性の点で最先端の結果を達成していることが示された。,https://d3i71xaburhd42.cloudfront.net/f226d43e2f8a0905b047a7035360ec37ccb0840a/2-Figure1-1.png
Diversiﬁed Multiple Instance Learning for Document-Level Multi-Aspect Sentiment Classiﬁcation,"['Yunjie Ji', 'Hao Liu', 'Bolei He', 'Xinyan Xiao', 'Hua Wu', 'Yanhua Yu']",,,なし,
Do “Undocumented Immigrants” == “Illegal Aliens”? Differentiating Denotation and Connotation in Vector Space,"['Albert Webson', 'Zhizhong Chen', 'Carsten Eickhoff', 'Ellie Pavlick']",,,なし,
Do sequence-to-sequence VAEs learn global features of sentences?,"['Tom Bosc', 'Pascal Vincent']",http://arxiv.org/abs/2004.07683v1,"A longstanding goal in NLP is to compute global sentence representations. Such representations would be useful for sample-efficient semi-supervised learning and controllable text generation. To learn to represent global and local information separately, Bowman & al. (2016) proposed to train a sequence-to-sequence model with the variational auto-encoder (VAE) objective. What precisely is encoded in these latent variables expected to capture global features? We measure which words benefit most from the latent information by decomposing the reconstruction loss per position in the sentence. Using this method, we see that VAEs are prone to memorizing the first words and the sentence length, drastically limiting their usefulness. To alleviate this, we propose variants based on bag-of-words assumptions and language model pretraining. These variants learn latents that are more global: they are more predictive of topic or sentiment labels, and their reconstructions are more faithful to the labels of the original documents.",NLPの長年の目標は大域的な文表現を計算することである。このような表現は、サンプル効率の良い半教師付き学習や制御可能なテキスト生成に有用であろう。大域情報と局所情報を別々に表現する学習を行うために、Bowman & al. (2016)は、変分自動エンコーダー(VAE)を目的としたシーケンス間モデルの学習を提案した。大域的特徴を捉えるために期待されるこれらの潜在変数に正確に何が符号化されているのか？我々は、文中の位置ごとの再構成損失を分解することで、どの単語が潜在情報から最も恩恵を受けるかを測定する。この方法を用いることで、VAEは最初の単語と文の長さを記憶する傾向があり、その有用性が大幅に制限されていることがわかります。これを軽減するために、我々は bag-of-words の仮定と言語モデルの事前学習に基づくバリアントを提案する。これらのバリアントは、よりグローバルな潜在能力を学習し、トピックや感情のラベルをより予測し、その再構成は元の文書のラベルにより忠実である。,https://d3i71xaburhd42.cloudfront.net/1d0ed337b637b3f1f4f277ba110bcc8813f82e2d/3-Table1-1.png
doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset,"['Song Feng', 'Hui Wan', 'Chulaka Gunasekara', 'Siva Patel', 'Sachindra Joshi', 'Luis Lastras']",,,なし,
Does my multimodal model learn cross-modal interactions? It’s harder to tell than you might think!,"['Jack Hessel', 'Lillian Lee']",,,なし,
Domain Knowledge Empowered Structured Neural Net for End-to-End Event Temporal Relation Extraction,"['Rujun Han', 'Yichao Zhou', 'Nanyun Peng']",http://arxiv.org/abs/2009.07373v2,"Extracting event temporal relations is a critical task for information extraction and plays an important role in natural language understanding. Prior systems leverage deep learning and pre-trained language models to improve the performance of the task. However, these systems often suffer from two short-comings: 1) when performing maximum a posteriori (MAP) inference based on neural models, previous systems only used structured knowledge that are assumed to be absolutely correct, i.e., hard constraints; 2) biased predictions on dominant temporal relations when training with a limited amount of data. To address these issues, we propose a framework that enhances deep neural network with distributional constraints constructed by probabilistic domain knowledge. We solve the constrained inference problem via Lagrangian Relaxation and apply it on end-to-end event temporal relation extraction tasks. Experimental results show our framework is able to improve the baseline neural network models with strong statistical significance on two widely used datasets in news and clinical domains.",イベントの時間的関係を抽出することは、情報抽出のための重要なタスクであり、自然言語理解において重要な役割を果たしている。これまでのシステムでは、ディープラーニングと事前学習された言語モデルを活用して、このタスクのパフォーマンスを向上させてきました。しかし、これらのシステムには、しばしば2つの欠点がある。1）ニューラルモデルに基づく最大事後推定（MAP）推論を行う場合、従来のシステムでは絶対的に正しいと仮定された構造化知識、すなわちハードな制約のみを使用していたこと、2）限られたデータ量で学習する場合、支配的な時間的関係に関する偏った予測を行っていたこと。これらの問題を解決するために、本研究では、確率的な領域知識で構成された分布制約を持つディープニューラルネットワークを強化するフレームワークを提案する。本研究では、ラグランジュ緩和を用いて制約付き推論問題を解決し、エンドツーエンドのイベント時間関係抽出タスクに適用する。実験の結果、本研究のフレームワークは、ニュースや臨床分野で広く利用されている2つのデータセットにおいて、ベースラインのニューラルネットワークモデルを統計的に有意に改善できることを示した。,https://d3i71xaburhd42.cloudfront.net/6e41d75f43c4673daf9abb20eec946b04e32dd8a/1-Figure1-1.png
Don't Read Too Much Into It: Adaptive Computation for Open-Domain Question Answering,"['Yuxiang Wu', 'Sebastian Riedel', 'Pasquale Minervini', 'Pontus Stenetorp']",,,なし,
DORB: Dynamically Optimizing Multiple Rewards with Bandits,"['Ramakanth Pasunuru', 'Han Guo', 'Mohit Bansal']",,,なし,
Double Graph Based Reasoning for Document-level Relation Extraction,"['Shuang Zeng', 'Runxin Xu', 'Baobao Chang', 'Lei Li']",http://arxiv.org/abs/2009.13752v1,"Document-level relation extraction aims to extract relations among entities within a document. Different from sentence-level relation extraction, it requires reasoning over multiple sentences across a document. In this paper, we propose Graph Aggregation-and-Inference Network (GAIN) featuring double graphs. GAIN first constructs a heterogeneous mention-level graph (hMG) to model complex interaction among different mentions across the document. It also constructs an entity-level graph (EG), based on which we propose a novel path reasoning mechanism to infer relations between entities. Experiments on the public dataset, DocRED, show GAIN achieves a significant performance improvement (2.85 on F1) over the previous state-of-the-art. Our code is available at https://github.com/DreamInvoker/GAIN .",文書レベルの関係抽出は、文書内のエンティティ間の関係を抽出することを目的としています。文レベルの関係抽出とは異なり、文書中の複数の文を対象とした推論が必要となる。本論文では、二重グラフを特徴とするGraph Aggregation-and-Inference Network (GAIN)を提案する。GAINは、まず、文書中の異なる言及の間の複雑な相互作用をモデル化するために、異種の言及レベルグラフ(hMG)を構築する。さらに、エンティティレベルグラフ(EG)を構築し、これに基づいてエンティティ間の関係を推論する新しい経路推論機構を提案する。公開データセットであるDocREDを用いた実験では、GAINが従来の最新技術と比較して大幅な性能向上（F1で2.85）を達成していることが示された。我々のコードは https:/github.comDreamInvokerGAIN で公開されています。,https://d3i71xaburhd42.cloudfront.net/fe9ff8daee1356463d1dc363249f504e8e6809b9/1-Figure1-1.png
DualTKB: A Dual Learning Bridge between Text and Knowledge Base,"['Pierre Dognin', 'Igor Melnyk', 'Inkit Padhi', 'Cícero Nogueira dos Santos', 'Payel Das']",,,なし,
DyERNIE: Dynamic Evolution of Riemannian Manifold Embeddings for Temporal Knowledge Graph Completion,"['Zhen Han', 'Peng Chen', 'Yunpu Ma', 'Volker Tresp']",,,なし,
Dynamic Anticipation and Completion for Multi-Hop Reasoning over Sparse Knowledge Graph,"['Xin Lv', 'Xu Han', 'Lei Hou', 'Juanzi Li', 'Zhiyuan Liu', 'Wei Zhang', 'YICHI ZHANG', 'Hao Kong', 'Suhui Wu']",http://arxiv.org/abs/2010.01899v1,"Multi-hop reasoning has been widely studied in recent years to seek an effective and interpretable method for knowledge graph (KG) completion. Most previous reasoning methods are designed for dense KGs with enough paths between entities, but cannot work well on those sparse KGs that only contain sparse paths for reasoning. On the one hand, sparse KGs contain less information, which makes it difficult for the model to choose correct paths. On the other hand, the lack of evidential paths to target entities also makes the reasoning process difficult. To solve these problems, we propose a multi-hop reasoning model named DacKGR over sparse KGs, by applying novel dynamic anticipation and completion strategies: (1) The anticipation strategy utilizes the latent prediction of embedding-based models to make our model perform more potential path search over sparse KGs. (2) Based on the anticipation information, the completion strategy dynamically adds edges as additional actions during the path search, which further alleviates the sparseness problem of KGs. The experimental results on five datasets sampled from Freebase, NELL and Wikidata show that our method outperforms state-of-the-art baselines. Our codes and datasets can be obtained from https://github.com/THU-KEG/DacKGR","マルチホップ推論は、知識グラフ（KG）補完のための効果的で解釈可能な方法を求めて、近年広く研究されている。これまでの推論手法の多くは、エンティティ間のパスが十分にある密なKGに対して設計されているが、推論のためのパスだけが疎なKGに対してはうまく機能しない。一方で、疎なｋｇは情報量が少ないため、モデルが正しいパスを選択することが困難である。一方で，対象となるエンティティへの証跡的なパスがないために，推論処理が困難である．これらの問題を解決するために、本研究では、疎なKGを対象としたマルチホップ推論モデルDacKGRを提案する。(1)先読み戦略では、埋め込み型モデルの潜在予測を利用して、疎なKGs上でより多くの潜在的な経路探索を行うことができるようにする。(2)補完戦略は，先読み情報に基づいて，経路探索中の追加動作としてエッジを動的に追加することで，KGsのスパースネス問題をさらに緩和することができる．Freebase, NELL, Wikidataからサンプリングした5つのデータセットを用いた実験結果から，我々の手法が最先端のベースラインを凌駕することが示された．我々のコードとデータセットは https:/github.comTHU-KEGDacKGR から入手できます。",https://d3i71xaburhd42.cloudfront.net/5d81c6e46b2d10a6b169b402d4d9806d3f18bcca/1-Figure1-1.png
Dynamic Context Selection for Document-level Neural Machine Translation via Reinforcement Learning,"['Xiaomian Kang', 'Yang Zhao', 'Jiajun Zhang', 'Chengqing Zong']",http://arxiv.org/abs/2010.04314v1,"Document-level neural machine translation has yielded attractive improvements. However, majority of existing methods roughly use all context sentences in a fixed scope. They neglect the fact that different source sentences need different sizes of context. To address this problem, we propose an effective approach to select dynamic context so that the document-level translation model can utilize the more useful selected context sentences to produce better translations. Specifically, we introduce a selection module that is independent of the translation module to score each candidate context sentence. Then, we propose two strategies to explicitly select a variable number of context sentences and feed them into the translation module. We train the two modules end-to-end via reinforcement learning. A novel reward is proposed to encourage the selection and utilization of dynamic context sentences. Experiments demonstrate that our approach can select adaptive context sentences for different source sentences, and significantly improves the performance of document-level translation methods.",文書レベルのニューラル機械翻訳は、魅力的な改善をもたらしてきました。しかし、既存の方法の大部分は、固定されたスコープ内のすべての文脈を大まかに使用しています。これらの手法では、原文によって必要とする文脈の大きさが異なるという事実を無視している。この問題に対処するために、我々は動的文脈を選択する効果的なアプローチを提案し、文書レベルの翻訳モデルがより有用な選択文脈を利用してより良い翻訳を生成できるようにする。具体的には、翻訳モジュールとは独立した選択モジュールを導入し、各候補文にスコアをつける。そして、可変数の文脈文を明示的に選択し、翻訳モジュールに送り込む2つの戦略を提案する。この2つのモジュールを強化学習によってエンドツーエンドで学習させる。動的文脈の選択と利用を促すために、新しい報酬を提案する。実験により、我々のアプローチが異なる原文に対しても適応的な文脈文を選択することができ、文書レベルの翻訳手法の性能を大幅に向上させることが実証された。,https://d3i71xaburhd42.cloudfront.net/4e362020296df7e519d2c8c1d5d8b388ed679433/1-Table1-1.png
Dynamic Data Selection and Weighting for Iterative Back-Translation,"['Zi-Yi Dou', 'Antonios Anastasopoulos', 'Graham Neubig']",http://arxiv.org/abs/2004.03672v2,"Back-translation has proven to be an effective method to utilize monolingual data in neural machine translation (NMT), and iteratively conducting back-translation can further improve the model performance. Selecting which monolingual data to back-translate is crucial, as we require that the resulting synthetic data are of high quality and reflect the target domain. To achieve these two goals, data selection and weighting strategies have been proposed, with a common practice being to select samples close to the target domain but also dissimilar to the average general-domain text. In this paper, we provide insights into this commonly used approach and generalize it to a dynamic curriculum learning strategy, which is applied to iterative back-translation models. In addition, we propose weighting strategies based on both the current quality of the sentence and its improvement over the previous iteration. We evaluate our models on domain adaptation, low-resource, and high-resource MT settings and on two language pairs. Experimental results demonstrate that our methods achieve improvements of up to 1.8 BLEU points over competitive baselines.",逆翻訳は、ニューラル機械翻訳（NMT）における単言語データの有効な利用方法であり、逆翻訳を反復的に行うことでモデルの性能をさらに向上させることができることがわかっている。逆翻訳する単言語データを選択することは、結果として得られる合成データが高品質で、かつ対象領域を反映したものであることが要求されるため、非常に重要である。これら2つの目標を達成するために、データの選択と重み付け戦略が提案されてきたが、一般的には、ターゲットドメインに近いサンプルを選択することが一般的であるが、平均的な一般ドメインのテキストとは異なるものを選択する。本論文では、この一般的に用いられているアプローチを理解し、それを動的なカリキュラム学習戦略に一般化し、反復的な逆翻訳モデルに適用する。さらに、現在の文の質と前回の反復よりも改善された文の質の両方に基づく重み付け戦略を提案する。本研究では、領域適応、低リソース、高リソースのMT設定、および2つの言語ペアを用いて、本手法を評価した。実験の結果、我々の手法は競合するベースラインと比較して最大1.8 BLEUポイントの改善を達成することが示された。,https://d3i71xaburhd42.cloudfront.net/432369921bd873442bda5e56bc68662e7c2e7493/1-Figure1-1.png
Effective Unsupervised Domain Adaptation with Adversarially Trained Language Models,"['Thuy-Trang Vu', 'Dinh Phung', 'Gholamreza Haffari']",http://arxiv.org/abs/2010.01739v1,"Recent work has shown the importance of adaptation of broad-coverage contextualised embedding models on the domain of the target task of interest. Current self-supervised adaptation methods are simplistic, as the training signal comes from a small percentage of \emph{randomly} masked-out tokens. In this paper, we show that careful masking strategies can bridge the knowledge gap of masked language models (MLMs) about the domains more effectively by allocating self-supervision where it is needed. Furthermore, we propose an effective training strategy by adversarially masking out those tokens which are harder to reconstruct by the underlying MLM. The adversarial objective leads to a challenging combinatorial optimisation problem over \emph{subsets} of tokens, which we tackle efficiently through relaxation to a variational lowerbound and dynamic programming. On six unsupervised domain adaptation tasks involving named entity recognition, our method strongly outperforms the random masking strategy and achieves up to +1.64 F1 score improvements.",最近の研究では、広い範囲をカバーする文脈に基づいた埋め込みモデルを、興味のある対象タスクのドメインに適応させることが重要であることが示されている。現在の自己学習型適応法は、学習信号が小さな割合のマスクアウトされたトークンから得られるため、単純なものとなっている。本論文では、慎重なマスキング戦略を用いることで、自己監視が必要な場所に自己監視を配置することで、より効果的に領域に関する知識ギャップを埋めることができることを示す。さらに、基礎となるMLMでは再構成が困難なトークンを敵対的にマスキングすることで、効果的な学習戦略を提案する。この逆問題は、トークンの「\emph{部分集合}」に対する組み合わせ最適化問題につながるが、変分下界への緩和と動的計画法を用いて効率的に取り組む。6つの教師なしドメイン適応課題において、本手法はランダムマスキング戦略を強く上回り、最大で+1.64のF1スコア改善を達成した。,https://d3i71xaburhd42.cloudfront.net/2102dc3d1b4e4f9d749f6a760319f5f05ea9a394/3-Figure1-1.png
Efficient Meta Lifelong-Learning with Limited Memory,"['Zirui Wang', 'Sanket Vaibhav Mehta', 'Barnabas Poczos', 'Jaime Carbonell']",http://arxiv.org/abs/2010.02500v1,"Current natural language processing models work well on a single task, yet they often fail to continuously learn new tasks without forgetting previous ones as they are re-trained throughout their lifetime, a challenge known as lifelong learning. State-of-the-art lifelong language learning methods store past examples in episodic memory and replay them at both training and inference time. However, as we show later in our experiments, there are three significant impediments: (1) needing unrealistically large memory module to achieve good performance, (2) suffering from negative transfer, (3) requiring multiple local adaptation steps for each test example that significantly slows down the inference speed. In this paper, we identify three common principles of lifelong learning methods and propose an efficient meta-lifelong framework that combines them in a synergistic fashion. To achieve sample efficiency, our method trains the model in a manner that it learns a better initialization for local adaptation. Extensive experiments on text classification and question answering benchmarks demonstrate the effectiveness of our framework by achieving state-of-the-art performance using merely 1% memory size and narrowing the gap with multi-task learning. We further show that our method alleviates both catastrophic forgetting and negative transfer at the same time.",現在の自然言語処理モデルは、単一のタスクに対しては十分に機能するが、生涯を通じて再訓練されるため、以前のタスクを忘れることなく新しいタスクを継続的に学習することができないことが多く、生涯学習として知られている課題である。最先端の生涯言語学習法は、過去の例をエピソード記憶に保存し、訓練時と推論時の両方で再生する。しかし、後の実験で示すように、この方法には3つの大きな障害がある。(1)性能を発揮するためには非現実的に大きなメモリモジュールが必要であること、(2)負の伝達の問題を抱えていること、(3)各テスト例に対して複数の局所適応ステップを必要とし、推論速度が著しく遅くなること、である。本論文では、生涯学習手法の3つの共通原理を明らかにし、それらを相乗的に組み合わせた効率的なメタ生涯学習フレームワークを提案する。サンプル効率を達成するために、我々の手法は、局所適応のためのより良い初期化を学習するようにモデルを訓練する。テキスト分類と質問回答のベンチマークに関する広範な実験により、わずか1%のメモリサイズを用いて最先端の性能を達成し、マルチタスク学習との差を縮めることで、我々のフレームワークの有効性を実証した。さらに、我々の手法が壊滅的な忘却と負の伝達の両方を同時に軽減することを示す。,https://d3i71xaburhd42.cloudfront.net/5585c7fcbda5d94e946fe9091860e2e574927ed8/6-Table1-1.png
Eliciting Knowledge from Language Models Using Automatically Generated Prompts,"['Taylor Shin', 'Yasaman Razeghi', 'Robert L Logan IV', 'Eric Wallace', 'Sameer Singh']",,,なし,
Embedding Words in Non-Vector Space with Unsupervised Graph Learning,"['Maksim Riabinin', 'Sergei Popov', 'Liudmila Prokhorenkova', 'Elena Voita']",,,なし,
Enabling Cross-Lingual AMR Parsing with Transfer Learning Techniques,"['Rexhina Blloshmi', 'Rocco Tripodi', 'Roberto Navigli']",,,なし,
End-to-End Emotion-Cause Pair Extraction based on Sliding Window Multi-Label Learning,"['Zixiang Ding', 'Rui Xia', 'Jianfei Yu']",,,なし,
End-to-End Slot Alignment and Recognition for Cross-Lingual {NLU},"['Weijia Xu', 'Batool Haider', 'Saab Mansour']",,,なし,
End-to-End Synthetic Data Generation for Domain Adaptation of Question Answering Systems,"['Siamak Shakeri', 'Cícero Nogueira dos Santos', 'Henghui Zhu', 'Patrick Ng', 'Feng Nan', 'Zhiguo Wang', 'Ramesh Nallapati', 'Bing Xiang']",http://arxiv.org/abs/2010.06028v1,"We propose an end-to-end approach for synthetic QA data generation. Our model comprises a single transformer-based encoder-decoder network that is trained end-to-end to generate both answers and questions. In a nutshell, we feed a passage to the encoder and ask the decoder to generate a question and an answer token-by-token. The likelihood produced in the generation process is used as a filtering score, which avoids the need for a separate filtering model. Our generator is trained by fine-tuning a pretrained LM using maximum likelihood estimation. The experimental results indicate significant improvements in the domain adaptation of QA models outperforming current state-of-the-art methods.",合成QAデータ生成のためのエンドツーエンドのアプローチを提案する。このモデルは、回答と質問の両方を生成するためにエンド・ツー・エンドで学習される、単一のトランスフォーマーベースのエンコーダ-デコーダネットワークから構成されています。簡単に言えば、エンコーダーに一節を与え、デコーダーに質問と回答をトークンごとに生成するように依頼します。生成プロセスで生成された尤度はフィルタリングスコアとして使用され、個別のフィルタリングモデルを必要としません。我々の生成器は、最尤推定を用いて事前に訓練されたLMを微調整することによって訓練される。実験結果から、QAモデルの領域適応性が大幅に向上し、現在の最先端の手法よりも優れていることが示された。,https://d3i71xaburhd42.cloudfront.net/4db3d482652f4aed1e76f9827ba7593e8f99c6ca/3-Figure1-1.png
Enhancing Aspect Term Extraction with Soft Prototypes,"['Zhuang Chen', 'Tieyun Qian']",,,なし,
"Ensemble Distillation for Structured Prediction: Calibrated, Accurate, Fast—Choose Three","['Steven Reich', 'David Mueller', 'Nicholas Andrews']",http://arxiv.org/abs/2010.06721v1,"Modern neural networks do not always produce well-calibrated predictions, even when trained with a proper scoring function such as cross-entropy. In classification settings, simple methods such as isotonic regression or temperature scaling may be used in conjunction with a held-out dataset to calibrate model outputs. However, extending these methods to structured prediction is not always straightforward or effective; furthermore, a held-out calibration set may not always be available. In this paper, we study ensemble distillation as a general framework for producing well-calibrated structured prediction models while avoiding the prohibitive inference-time cost of ensembles. We validate this framework on two tasks: named-entity recognition and machine translation. We find that, across both tasks, ensemble distillation produces models which retain much of, and occasionally improve upon, the performance and calibration benefits of ensembles, while only requiring a single model during test-time.",最新のニューラルネットワークは、クロスエントロピーのような適切なスコアリング関数で訓練されていても、常に十分に校正された予測値を生成するわけではありません。分類の設定では、アイソトニック回帰や温度スケーリングのような単純な方法が、モデルの出力を較正するために、ホールドアウトされたデータセットと組み合わせて使用されることがあります。しかし、これらの手法を構造化予測に拡張することは、必ずしも簡単で効果的とは限らない。本論文では、アンサンブルの法外な推論時間コストを回避しつつ、十分に校正された構造化予測モデルを生成するための一般的なフレームワークとして、アンサンブル蒸留を研究する。このフレームワークを、名前付きエンティティ認識と機械翻訳の2つのタスクで検証した。両方のタスクにおいて、アンサンブル蒸留により、アンサンブルの性能と較正の利点の多くを保持し、時にはそれを向上させるモデルが生成される一方で、テスト時間中に必要なのは1つのモデルのみであることがわかりました。,https://d3i71xaburhd42.cloudfront.net/65a40344a57020ee5d7209c1d70f40c8c4dd1d30/2-Figure1-1.png
Entities as Experts: Sparse Memory Access with Entity Supervision,"['Thibault Févry', 'Livio Baldini Soares', 'Nicholas FitzGerald', 'Eunsol Choi', 'Tom Kwiatkowski']",http://arxiv.org/abs/2004.07202v2,"We focus on the problem of capturing declarative knowledge about entities in the learned parameters of a language model. We introduce a new model - Entities as Experts (EAE) - that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EAE's entity representations are learned directly from text. We show that EAE's learned representations capture sufficient knowledge to answer TriviaQA questions such as ""Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?"", outperforming an encoder-generator Transformer model with 10x the parameters. According to the LAMA knowledge probes, EAE contains more factual knowledge than a similarly sized BERT, as well as previous approaches that integrate external sources of entity knowledge. Because EAE associates parameters with specific entities, it only needs to access a fraction of its parameters at inference time, and we show that the correct identification and representation of entities is essential to EAE's performance.",我々は、言語モデルの学習パラメータにエンティティに関する宣言的な知識を取り込む問題に焦点を当てている。我々は、テキストの一部で言及されているエンティティの個別の記憶にアクセスできる新しいモデル、Entities as Experts (EAE)を導入する。これまでのシーケンスモデルにエンティティの知識を統合する試みとは異なり、EAEのエンティティ表現はテキストから直接学習される。我々は、EAEの学習された表現が、「ロジャー・デルガド、アンソニー・アインリー、エリック・ロバーツが演じたドクター・フーの悪役は誰か」といったトリビアQAの質問に答えるのに十分な知識を捉えていることを示し、パラメータが10倍のエンコーダー・ジェネレーター・トランスフォーマー・モデルを上回ることを示した。LAMAの知識プローブによると、EAEは、同様のサイズのBERTと同様に、実体知識の外部ソースを統合する以前のアプローチよりも多くの事実知識を含んでいます。EAEはパラメータを特定のエンティティに関連付けるため、推論時に必要なのはパラメータのごく一部にアクセスするだけであり、エンティティの正しい識別と表現がEAEの性能に不可欠であることを示す。,https://d3i71xaburhd42.cloudfront.net/616ac5ee66b65a5ed556bfb7f38ef4bd41a3c03e/1-Figure1-1.png
Entity Enhanced BERT Pre-training for Chinese NER,"['Chen Jia', 'Yuefeng Shi', 'Qinrong Yang', 'Yue Zhang']",,,なし,
Entity Linking in 100 Languages,"['Jan A. Botha', 'Zifei Shan', 'Daniel Gillick']",,,なし,
ETC: Encoding Long and Structured Inputs in Transformers,"['Joshua Ainslie', 'Santiago Ontanon', 'Chris Alberti', 'Vaclav Cvicek', 'Zachary Fisher', 'Philip Pham', 'Anirudh Ravula', 'Sumit Sanghai', 'Qifan Wang', 'Li Yang']",http://arxiv.org/abs/2004.08483v4,"Transformer models have advanced the state of the art in many Natural Language Processing (NLP) tasks. In this paper, we present a new Transformer architecture, Extended Transformer Construction (ETC), that addresses two key challenges of standard Transformer architectures, namely scaling input length and encoding structured inputs. To scale attention to longer inputs, we introduce a novel global-local attention mechanism between global tokens and regular input tokens. We also show that combining global-local attention with relative position encodings and a Contrastive Predictive Coding (CPC) pre-training objective allows ETC to encode structured inputs. We achieve state-of-the-art results on four natural language datasets requiring long and/or structured inputs.",トランスモデルは、多くの自然言語処理(NLP)タスクにおいて最先端の技術を提供してきた。この論文では、標準的なトランス・アーキテクチャの2つの重要な課題、すなわち、入力の長さのスケーリングと構造化された入力のエンコーディングに対処する新しいトランス・アーキテクチャ、拡張トランス・コンストラクション(ETC)を紹介する。より長い入力に注意を向けるために、グローバルトークンと通常の入力トークンの間に新しいグローバル・ローカル注意メカニズムを導入する。また、グローバルローカル注意と相対位置符号化とコントラスト予測符号化(CPC)の事前学習目的を組み合わせることで、ETCが構造化入力を符号化できることを示す。本研究では、長い入力や構造化された入力を必要とする4つの自然言語データセットについて、最先端の結果を得ることができた。,
Evaluating and Characterizing Human Rationales,"['Samuel Carton', 'Anirudh Rathore', 'Chenhao Tan']",http://arxiv.org/abs/2010.04736v1,"Two main approaches for evaluating the quality of machine-generated rationales are: 1) using human rationales as a gold standard; and 2) automated metrics based on how rationales affect model behavior. An open question, however, is how human rationales fare with these automatic metrics. Analyzing a variety of datasets and models, we find that human rationales do not necessarily perform well on these metrics. To unpack this finding, we propose improved metrics to account for model-dependent baseline performance. We then propose two methods to further characterize rationale quality, one based on model retraining and one on using ""fidelity curves"" to reveal properties such as irrelevance and redundancy. Our work leads to actionable suggestions for evaluating and characterizing rationales.",機械で生成された理論的根拠の品質を評価するための2つの主要なアプローチがあります。1）人間の理論的根拠をゴールドスタンダードとして使用する方法と、2）理論的根拠がモデルの動作にどのように影響するかに基づいて自動化されたメトリクスを使用する方法である。しかし、これらの自動化されたメトリクスに対して、人間のラテラルがどのように評価されるかは未解決の問題である。さまざまなデータセットとモデルを分析した結果、人間の理論は必ずしもこれらのメトリクスでうまく機能しないことがわかりました。この発見を解明するために、モデル依存のベースライン性能を説明するための改良されたメトリクスを提案する。その上で、推論の品質をさらに特徴づけるための2つの方法を提案する。1つはモデルの再訓練に基づくもので、もう1つは「忠実度曲線」を使用して無関連性や冗長性などの特性を明らかにするものである。我々の研究は、根拠の評価と特徴付けのための実用的な提案につながる。,https://d3i71xaburhd42.cloudfront.net/087087d91598aa62a11061ed156f8f6e699a7930/2-Table1-1.png
Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy Link Prediction,"['Tara Safavi', 'Danai Koutra', 'Edgar Meij']",http://arxiv.org/abs/2004.01168v3,"Little is known about the trustworthiness of predictions made by knowledge graph embedding (KGE) models. In this paper we take initial steps toward this direction by investigating the calibration of KGE models, or the extent to which they output confidence scores that reflect the expected correctness of predicted knowledge graph triples. We first conduct an evaluation under the standard closed-world assumption (CWA), in which predicted triples not already in the knowledge graph are considered false, and show that existing calibration techniques are effective for KGE under this common but narrow assumption. Next, we introduce the more realistic but challenging open-world assumption (OWA), in which unobserved predictions are not considered true or false until ground-truth labels are obtained. Here, we show that existing calibration techniques are much less effective under the OWA than the CWA, and provide explanations for this discrepancy. Finally, to motivate the utility of calibration for KGE from a practitioner's perspective, we conduct a unique case study of human-AI collaboration, showing that calibrated predictions can improve human performance in a knowledge graph completion task.",ナレッジグラフ埋め込み(KGE)モデルによる予測の信頼性については、ほとんど知られていない。本論文では、KGEモデルのキャリブレーション、すなわち、予測されたナレッジグラフ・トリプルの正しさを反映した信頼度スコアがどの程度出力されているかを調べることにより、この方向性に向けての第一歩を踏み出す。まず、標準的な閉世界仮定(CWA)の下で評価を行い、ナレッジグラフに含まれていない予測されたトリプルは偽とみなされ、この一般的ではあるが狭い仮定の下で既存のキャリブレーション手法がKGEに対して有効であることを示す。次に、より現実的ではあるが困難なオープンワールド仮定(OWA)を紹介する。この仮定では、基底真実ラベルが得られるまで、観測されていない予測値は真とも偽ともみなされない。ここでは、既存の校正技術がOWAの下ではCWAよりもはるかに効果的でないことを示し、この矛盾の説明を行う。最後に、実務家の視点からKGEのためのキャリブレーションの有用性を動機づけるために、人間とAIのコラボレーションのユニークな事例研究を行い、キャリブレーションされた予測値がナレッジグラフ補完タスクにおける人間のパフォーマンスを向上させることを示す。,
Evaluating the Factual Consistency of Abstractive Text Summarization,"['Wojciech Kryscinski', 'Bryan McCann', 'Caiming Xiong', 'Richard Socher']",,,なし,
Event Extraction as Machine Reading Comprehension,"['Jian Liu', 'Yubo Chen', 'Kang Liu', 'Wei Bi', 'Xiaojiang Liu']",,,なし,
Event Extraction by Answering (Almost) Natural Questions,"['Xinya Du', 'Claire Cardie']",http://arxiv.org/abs/2004.13625v1,"The problem of event extraction requires detecting the event trigger and extracting its corresponding arguments. Existing work in event argument extraction typically relies heavily on entity recognition as a preprocessing/concurrent step, causing the well-known problem of error propagation. To avoid this issue, we introduce a new paradigm for event extraction by formulating it as a question answering (QA) task, which extracts the event arguments in an end-to-end manner. Empirical results demonstrate that our framework outperforms prior methods substantially; in addition, it is capable of extracting event arguments for roles not seen at training time (zero-shot learning setting).",イベント抽出の問題は、イベントトリガーを検出し、それに対応する引数を抽出する必要があります。これまでのイベント引数抽出の既存の作業は、一般的に前処理一貫ステップとして実体認識に大きく依存しており、よく知られているエラー伝播の問題を引き起こしていた。この問題を回避するために、本研究では、イベント引数抽出を質問応答（QA）タスクとして定式化し、イベント引数をエンドツーエンドで抽出する新しいパラダイムを導入する。経験的には、本フレームワークが先行手法を大幅に凌駕していることを示し、また、訓練時には見られないロール(ゼロショット学習設定)についてもイベント引数を抽出できることを示した。,https://d3i71xaburhd42.cloudfront.net/b5aaf562669925ea617a06ad334d424d34115658/1-Figure1-1.png
EXAMS: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering,"['Momchil Hardalov', 'Todor Mihaylov', 'Dimitrina Zlatkova', 'Yoan Dinkov', 'Ivan Koychev', 'Preslav Nakov']",,,なし,
Experience Grounds Language,"['Yonatan Bisk', 'Ari Holtzman', 'Jesse Thomason', 'Jacob Andreas', 'Yoshua Bengio', 'Joyce Chai', 'Mirella Lapata', 'Angeliki Lazaridou', 'Jonathan May', 'Aleksandr Nisnevich', 'Nicolas Pinto', 'Joseph Turian']",http://arxiv.org/abs/2004.10151v2,"Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle tasks after being trained on text alone, successful linguistic communication relies on a shared experience of the world. It is this shared experience that makes utterances meaningful. Natural language processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication.",言語理解の研究は、言語が記述する物理的な世界や、言語が促進する社会的相互作用に言語を関連付けることができないために妨げられています。言語処理モデルは、テキストだけで訓練された後、タスクに取り組むために信じられないほどの効果があるにもかかわらず、言語的コミュニケーションの成功は、世界の共有経験に依存しています。発話を意味のあるものにするのは、この共有された経験です。自然言語処理は多様な分野であり、その発展の過程では、新しい表現理論、モデル化技術、データ収集パラダイム、タスクなどの進歩があった。我々は、大規模でテキストのみのコーパス上で訓練された表現学習アプローチの現在の成功は、コミュニケーションの深い問題に対処するために、言語のより広範な物理的・社会的文脈に関する研究の平行した伝統を必要としていることを示唆している。,
Explainable Automated Fact-Checking for Public Health Claims,"['Neema Kotonya', 'Francesca Toni']",,,なし,
Explainable Clinical Decision Support from Text,"['Jinyue Feng', 'Chantal Shaib', 'Frank Rudzicz']",,,なし,
Exploiting Structured Knowledge in Text via Graph-Guided Representation Learning,"['Tao Shen', 'Yi Mao', 'Pengcheng He', 'Guodong Long', 'Adam Trischler', 'Weizhu Chen']",http://arxiv.org/abs/2004.14224v1,"In this work, we aim at equipping pre-trained language models with structured knowledge. We present two self-supervised tasks learning over raw text with the guidance from knowledge graphs. Building upon entity-level masked language models, our first contribution is an entity masking scheme that exploits relational knowledge underlying the text. This is fulfilled by using a linked knowledge graph to select informative entities and then masking their mentions. In addition we use knowledge graphs to obtain distractors for the masked entities, and propose a novel distractor-suppressed ranking objective which is optimized jointly with masked language model. In contrast to existing paradigms, our approach uses knowledge graphs implicitly, only during pre-training, to inject language models with structured knowledge via learning from raw text. It is more efficient than retrieval-based methods that perform entity linking and integration during finetuning and inference, and generalizes more effectively than the methods that directly learn from concatenated graph triples. Experiments show that our proposed model achieves improved performance on five benchmark datasets, including question answering and knowledge base completion tasks.",本研究では、事前学習された言語モデルに構造化された知識を付与することを目的としている。本研究では、知識グラフを用いて生のテキストを学習する2つの自己学習タスクを提示する。実体レベルのマスキング言語モデルに基づいて、我々の最初の貢献は、テキストの基礎となる関係知識を利用した実体マスキングスキームである。これは、リンクされたナレッジグラフを用いて、情報量の多いエンティティを選択し、その言及をマスキングすることで実現している。さらに、我々は、マスキングされたエンティティのために知識グラフを用いてディストラクターを取得し、マスキングされた言語モデルと共同で最適化された新しいディストラクター抑圧型ランキング目的を提案する。既存のパラダイムとは対照的に、我々のアプローチでは、知識グラフを暗黙的に使用し、事前学習時にのみ、生のテキストからの学習を介して構造化された知識を持つ言語モデルを注入する。このアプローチは，検索ベースの手法を用いて微調整や推論の際にエンティティリンクや統合を行う手法よりも効率的であり，連結されたグラフの三重項から直接学習する手法よりも効果的に一般化することができる．実験の結果、提案モデルは、質問回答や知識ベースの補完タスクを含む5つのベンチマークデータセットにおいて、性能向上を達成していることが示された。,https://d3i71xaburhd42.cloudfront.net/4f42a0782f8b25fff62214e70bc43ce88f914c19/2-Figure1-1.png
"Exploring and Evaluating Attributes, Values, and Structure for Entity Alignment","['Zhiyuan Liu', 'Yixin Cao', 'Liangming Pan', 'Juanzi Li', 'Zhiyuan Liu', 'Tat-Seng Chua']",http://arxiv.org/abs/2010.03249v1,"Entity alignment (EA) aims at building a unified Knowledge Graph (KG) of rich content by linking the equivalent entities from various KGs. GNN-based EA methods present promising performances by modeling the KG structure defined by relation triples. However, attribute triples can also provide crucial alignment signal but have not been well explored yet. In this paper, we propose to utilize an attributed value encoder and partition the KG into subgraphs to model the various types of attribute triples efficiently. Besides, the performances of current EA methods are overestimated because of the name-bias of existing EA datasets. To make an objective evaluation, we propose a hard experimental setting where we select equivalent entity pairs with very different names as the test set. Under both the regular and hard settings, our method achieves significant improvements ($5.10\%$ on average Hits@$1$ in DBP$15$k) over $12$ baselines in cross-lingual and monolingual datasets. Ablation studies on different subgraphs and a case study about attribute types further demonstrate the effectiveness of our method. Source code and data can be found at https://github.com/thunlp/explore-and-evaluate.",エンティティ・アライメント（EA）は、様々なKGから等価なエンティティをリンクすることで、リッチコンテンツの統一されたナレッジグラフ（KG）を構築することを目的としています。GNNベースのEA手法は、関係トリプルで定義されたKGの構造をモデル化することで、有望な性能を示している。しかし、属性トリプルは重要なアラインメント信号を提供することができるが、まだ十分な検討がなされていない。本論文では、属性値エンコーダーを利用し、KGをサブグラフに分割して、様々なタイプの属性トリプルを効率的にモデル化することを提案する。また，既存のEAのデータセットには名前の偏りがあるため，現行のEA手法の性能は過大評価されている．そこで、本研究では、名前の異なる等価なエンティティペアをテストセットとして選択するハードな実験設定を提案する。通常設定とハード設定の両方の下で、我々の手法は、クロスリンガルとモノリンガルのデータセットにおいて、$12$ベースラインよりも大幅な改善（DBP$15$kの平均Hits@$1$で$5.10%$の改善）を達成した。異なるサブグラフ上でのアブレーション研究と属性タイプに関するケーススタディは、我々の方法の有効性をさらに実証しています。ソースコードとデータは、https:/github.comthunlpexplore-and-evaluateにあります。,https://d3i71xaburhd42.cloudfront.net/6c51fa7ffe9b29530a84cdae3c6d239270d7f002/2-Figure1-1.png
Exploring and Predicting Transferability across NLP Tasks,"['Tu Vu', 'Tong Wang', 'Tsendsuren Munkhdalai', 'Alessandro Sordoni', 'Adam Trischler', 'Andrew Mattarella-Micke', 'Subhransu Maji', 'Mohit Iyyer']",http://arxiv.org/abs/2005.00770v2,"Recent advances in NLP demonstrate the effectiveness of training large-scale language models and transferring them to downstream tasks. Can fine-tuning these models on tasks other than language modeling further improve performance? In this paper, we conduct an extensive study of the transferability between 33 NLP tasks across three broad classes of problems (text classification, question answering, and sequence labeling). Our results show that transfer learning is more beneficial than previously thought, especially when target task data is scarce, and can improve performance even when the source task is small or differs substantially from the target task (e.g., part-of-speech tagging transfers well to the DROP QA dataset). We also develop task embeddings that can be used to predict the most transferable source tasks for a given target task, and we validate their effectiveness in experiments controlled for source and target data size. Overall, our experiments reveal that factors such as source data size, task and domain similarity, and task complexity all play a role in determining transferability.",最近のNLPの進歩は、大規模な言語モデルを学習し、それを下流のタスクに移すことの有効性を示している。これらのモデルを言語モデリング以外のタスクで微調整することで、性能をさらに向上させることができるのだろうか？本論文では、3つの幅広いクラスの問題（テキスト分類、質問応答、シーケンスラベリング）を対象に、33のNLPタスク間の伝達可能性について大規模な研究を行った。その結果、伝達学習は従来考えられていた以上に有益であり、特にターゲットタスクのデータが少ない場合には、ソースタスクが小さい場合やターゲットタスクと大きく異なる場合でもパフォーマンスを向上させることができることを示した（例えば、品詞タグ付けはDROP QAデータセットにうまく伝達される）。また、与えられたターゲットタスクに対して最も転送可能なソースタスクを予測するために使用できるタスクエンベッディングを開発し、ソースとターゲットのデータサイズを制御した実験でその有効性を検証した。全体的に、ソースデータサイズ、タスクとドメインの類似性、タスクの複雑さなどの要因がすべて転送可能性を決定する役割を果たしていることが明らかになった。,https://d3i71xaburhd42.cloudfront.net/ee026b977120087c76819959649e1d4fd42510f0/1-Figure1-1.png
Exploring Semantic Capacity of Terms,"['Jie Huang', 'Zilong Wang', 'Kevin Chang', 'Wen-mei Hwu', 'JinJun Xiong']",http://arxiv.org/abs/2010.01898v1,"We introduce and study semantic capacity of terms. For example, the semantic capacity of artificial intelligence is higher than that of linear regression since artificial intelligence possesses a broader meaning scope. Understanding semantic capacity of terms will help many downstream tasks in natural language processing. For this purpose, we propose a two-step model to investigate semantic capacity of terms, which takes a large text corpus as input and can evaluate semantic capacity of terms if the text corpus can provide enough co-occurrence information of terms. Extensive experiments in three fields demonstrate the effectiveness and rationality of our model compared with well-designed baselines and human-level evaluations.",本研究では、用語の意味能力について紹介し、研究を行う。例えば、人工知能は意味の範囲が広いため、線形回帰よりも意味能力が高い。用語の意味能力を理解することは、自然言語処理の下流の多くの作業に役立つであろう。この目的のために、本研究では、大規模なテキストコーパスを入力とし、テキストコーパスが用語の共起情報を十分に提供できれば、用語の意味能力を評価できる2段階のモデルを提案する。3つの分野での広範な実験により、よく設計されたベースラインや人間レベルの評価と比較して、本モデルの有効性と合理性が実証された。,https://d3i71xaburhd42.cloudfront.net/db318a57cbbe8f91a91e0567e4d58a9acb1c0153/2-Figure1-1.png
Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation,"['Francisco Vargas', 'Ryan Cotterell']",http://arxiv.org/abs/2009.09435v2,"Bolukbasi et al. (2016) presents one of the first gender bias mitigation techniques for word embeddings. Their method takes pre-trained word embeddings as input and attempts to isolate a linear subspace that captures most of the gender bias in the embeddings. As judged by an analogical evaluation task, their method virtually eliminates gender bias in the embeddings. However, an implicit and untested assumption of their method is that the bias sub-space is actually linear. In this work, we generalize their method to a kernelized, non-linear version. We take inspiration from kernel principal component analysis and derive a non-linear bias isolation technique. We discuss and overcome some of the practical drawbacks of our method for non-linear gender bias mitigation in word embeddings and analyze empirically whether the bias subspace is actually linear. Our analysis shows that gender bias is in fact well captured by a linear subspace, justifying the assumption of Bolukbasi et al. (2016).",Bolukbasiら（2016）は、単語エンベッディングのための最初のジェンダーバイアス緩和技術の1つを提示しています。彼らの手法は、事前に訓練された単語エンベッディングを入力として取り、エンベッディングにおけるジェンダーバイアスの大部分を捕捉する線形部分空間を分離しようとします。類推評価タスクによって判断されるように、彼らの方法は、事実上、エンベッディングにおけるジェンダーバイアスを排除します。しかし、彼らの手法の暗黙の仮定は、バイアス部分空間が実際には線形であるということである。本研究では、この手法をカーネル化された非線形バージョンに一般化する。我々はカーネル主成分分析からインスピレーションを得て、非線形バイアス分離技術を導出する。我々は、単語エンベッディングにおける非線形ジェンダーバイアス緩和のための我々の手法の実用的な欠点のいくつかを議論し、克服し、バイアス部分空間が実際に線形であるかどうかを経験的に分析する。我々の分析は、ジェンダーバイアスが実際には線形部分空間によって十分に捕捉されていることを示し、Bolukbasiら(2016)の仮定を正当化する。,https://d3i71xaburhd42.cloudfront.net/86e1aaa0c47659e08a896e9889384eb1e5401e6a/6-Figure1-1.png
Extracting Implicitly Asserted Propositions in Argumentation,"['Yohan Jo', 'Jacky Visser', 'Chris Reed', 'Eduard Hovy']",http://arxiv.org/abs/2010.02654v1,"Argumentation accommodates various rhetorical devices, such as questions, reported speech, and imperatives. These rhetorical tools usually assert argumentatively relevant propositions rather implicitly, so understanding their true meaning is key to understanding certain arguments properly. However, most argument mining systems and computational linguistics research have paid little attention to implicitly asserted propositions in argumentation. In this paper, we examine a wide range of computational methods for extracting propositions that are implicitly asserted in questions, reported speech, and imperatives in argumentation. By evaluating the models on a corpus of 2016 U.S. presidential debates and online commentary, we demonstrate the effectiveness and limitations of the computational models. Our study may inform future research on argument mining and the semantics of these rhetorical devices in argumentation.",議論は、質問、報告されたスピーチ、命令文などの様々な修辞的な装置に対応しています。これらの修辞手段は通常、議論に関連する命題を暗黙的に主張するので、その真の意味を理解することがある議論を正しく理解するための鍵となります。しかし、ほとんどの議論マイニングシステムや計算言語学の研究では、議論における暗黙的に主張された命題にはほとんど注目されていない。本論文では、議論における質問、報告された発話、命令文の中で暗黙に主張されている命題を抽出するための様々な計算手法を検討する。2016年米国大統領討論会のコーパスとオンライン解説を用いてモデルを評価することで、計算モデルの有効性と限界を実証した。この研究は、議論のマイニングと、議論におけるこれらの修辞的装置の意味論に関する将来の研究に役立つかもしれない。,https://d3i71xaburhd42.cloudfront.net/02fdf83b3519aa7e2cfbab2938ecae3143206571/4-Figure1-1.png
F^2-Softmax: Diversifying Neural Text Generation via Frequency Factorized Softmax,"['Byung-Ju Choi', 'Jimin Hong', 'David Park', 'Sang Wan Lee']",http://arxiv.org/abs/2009.09417v2,"Despite recent advances in neural text generation, encoding the rich diversity in human language remains elusive. We argue that the sub-optimal text generation is mainly attributable to the imbalanced token distribution, which particularly misdirects the learning model when trained with the maximum-likelihood objective. As a simple yet effective remedy, we propose two novel methods, F^2-Softmax and MefMax, for a balanced training even with the skewed frequency distribution. MefMax assigns tokens uniquely to frequency classes, trying to group tokens with similar frequencies and equalize frequency mass between the classes. F^2-Softmax then decomposes a probability distribution of the target token into a product of two conditional probabilities of (i) frequency class, and (ii) token from the target frequency class. Models learn more uniform probability distributions because they are confined to subsets of vocabularies. Significant performance gains on seven relevant metrics suggest the supremacy of our approach in improving not only the diversity but also the quality of generated texts.",近年のニューラルテキスト生成技術の進歩にもかかわらず、人間の言語の豊かな多様性を符号化することは未だに困難なままである。我々は、最適でないテキスト生成は、主にトークン分布の不均衡に起因するものであり、最尤目的語を用いて学習した場合には、特に学習モデルの方向性がずれてしまうことに起因すると主張している。単純でありながら効果的な解決策として、我々は、周波数分布が歪んでいてもバランスのとれた学習を行うために、F^2-SoftmaxとMefMaxの2つの新しい手法を提案する。MefMaxは、類似した周波数を持つトークンをグループ化し、クラス間の周波数質量を均等化しようとして、トークンを周波数クラスに一意に割り当てる。次に、F^2-Softmaxは、ターゲットトークンの確率分布を、(i)周波数クラスと(ii)ターゲット周波数クラスのトークンの2つの条件付き確率の積に分解します。モデルは、ボキャブラリーのサブセットに限定されているため、より均一な確率分布を学習します。関連する7つの指標について有意な性能向上が見られたことから、多様性だけでなく生成されるテキストの品質を向上させる上で、我々のアプローチが優れていることが示唆された。,https://d3i71xaburhd42.cloudfront.net/59d2e0c89c8c61ae12a8f43f78cd3e9fcded2ac2/2-Figure1-1.png
F1 is Not Enough! Models and Evaluation Towards User-Centered Explainable Question Answering,"['Hendrik Schuff', 'Heike Adel', 'Ngoc Thang Vu']",,,なし,
Facilitating the Communication of Politeness through Fine-Grained Paraphrasing,"['Liye Fu', 'Susan Fussell', 'Cristian Danescu-Niculescu-Mizil']",,,なし,
Fact or Fiction: Verifying Scientific Claims,"['David Wadden', 'Shanchuan Lin', 'Kyle Lo', 'Lucy Lu Wang', 'Madeleine van Zuylen', 'Arman Cohan', 'Hannaneh Hajishirzi']",http://arxiv.org/abs/2004.14974v6,"We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SciFact, and demonstrate that simple domain adaptation techniques substantially improve performance compared to models trained on Wikipedia or political news. We show that our system is able to verify claims related to COVID-19 by identifying evidence from the CORD-19 corpus. Our experiments indicate that SciFact will provide a challenging testbed for the development of new systems designed to retrieve and reason over corpora containing specialized domain knowledge. Data and code for this new task are publicly available at https://github.com/allenai/scifact. A leaderboard and COVID-19 fact-checking demo are available at https://scifact.apps.allenai.org.",科学的主張の検証とは、与えられた科学的主張を支持または反論する証拠を含む研究文献から抄録を選択し、各決定を正当化する根拠を特定する新しいタスクである。このタスクを研究するために、1.4Kの専門家が書いた科学的主張と、ラベルと論拠で注釈された証拠を含むアブストラクトとのペアのデータセットであるSciFactを構築します。SciFactのベースラインモデルを開発し、単純なドメイン適応技術により、Wikipediaや政治ニュースで学習したモデルと比較してパフォーマンスが大幅に向上することを実証しています。CORD-19コーパスから証拠を識別することで、COVID-19に関連する主張を検証できることを示しています。我々の実験は、SciFactが、専門的なドメイン知識を含むコーパスを検索して推論するように設計された新しいシステムの開発のための挑戦的なテストベッドを提供することを示しています。この新しいタスクのデータとコードは、https:/github.comallenaiscifactで公開されています。リーダーボードとCOVID-19のファクトチェックデモはhttps:/scifact.apps.allenai.orgで利用可能です。,https://d3i71xaburhd42.cloudfront.net/b770d84055c32febe922be9931c453fdbebe9002/1-Figure1-1.png
Fast semantic parsing with well-typedness guarantees,"['Matthias Lindemann', 'Jonas Groschwitz', 'Alexander Koller']",http://arxiv.org/abs/2009.07365v2,"AM dependency parsing is a linguistically principled method for neural semantic parsing with high accuracy across multiple graphbanks. It relies on a type system that models semantic valency but makes existing parsers slow. We describe an A* parser and a transition-based parser for AM dependency parsing which guarantee well-typedness and improve parsing speed by up to 3 orders of magnitude, while maintaining or improving accuracy.",AM依存性解析は、複数のグラフバンクにまたがって高精度なニューラル意味解析を行うための言語学的な原理に基づいた手法です。これは、意味的価数をモデル化する型システムに依存していますが、既存のパーサーでは処理速度が遅くなります。我々は、AM依存性解析のためのA*パーサと遷移ベースのパーサを説明します。これらのパーサは、精度を維持または向上させながら、型付けの良さを保証し、解析速度を最大3桁向上させます。,https://d3i71xaburhd42.cloudfront.net/60d99e00f7f96efea3099b9491a93bb8060ff502/2-Figure1-1.png
Feature Adaptation of Pre-Trained Language Models across Languages and Domains with Robust Self-Training,"['Hai Ye', 'Qingyu Tan', 'Ruidan He', 'Juntao Li', 'Hwee Tou Ng', 'Lidong Bing']",http://arxiv.org/abs/2009.11538v2,"Adapting pre-trained language models (PrLMs) (e.g., BERT) to new domains has gained much attention recently. Instead of fine-tuning PrLMs as done in most previous work, we investigate how to adapt the features of PrLMs to new domains without fine-tuning. We explore unsupervised domain adaptation (UDA) in this paper. With the features from PrLMs, we adapt the models trained with labeled data from the source domain to the unlabeled target domain. Self-training is widely used for UDA which predicts pseudo labels on the target domain data for training. However, the predicted pseudo labels inevitably include noise, which will negatively affect training a robust model. To improve the robustness of self-training, in this paper we present class-aware feature self-distillation (CFd) to learn discriminative features from PrLMs, in which PrLM features are self-distilled into a feature adaptation module and the features from the same class are more tightly clustered. We further extend CFd to a cross-language setting, in which language discrepancy is studied. Experiments on two monolingual and multilingual Amazon review datasets show that CFd can consistently improve the performance of self-training in cross-domain and cross-language settings.",最近、事前学習済み言語モデル（PrLMs）（例えば、BERT）を新しい領域に適応させることが注目されている。本研究では、これまでのほとんどの研究で行われているようにPrLMを微調整するのではなく、PrLMの特徴を微調整せずに新しい領域に適応させる方法を検討する。本論文では、教師なしドメイン適応(UDA)を探求する。PrLMsの特徴量を用いて、ソースドメインからラベル付けされたデータで学習したモデルを、ラベル付けされていないターゲットドメインに適応させる。UDAには自己学習が広く用いられており、学習対象領域のデータに擬似ラベルを予測して学習を行う。しかし、予測された擬似ラベルには必然的にノイズが含まれ、ロバストモデルの学習に悪影響を及ぼす。自己学習のロバスト性を向上させるために、本論文では、PrLMから識別的特徴を学習するために、クラスを意識した特徴自己ディスティル化(CFd)を提案する。我々はさらにCFdを言語の不一致を研究する言語横断的な設定に拡張した。2つの単言語と多言語のAmazonレビューデータセットを用いた実験により、CFdがクロスドメインとクロスランゲージの設定で自己学習のパフォーマンスを一貫して向上させることが示された。,https://d3i71xaburhd42.cloudfront.net/992f949de6d9c9355e6f1b224fdff4ac1967b2bf/3-Figure1-1.png
FedED: Federated Learning via Ensemble Distillation for Medical Relation Extraction,"['Dianbo Sui', 'Yubo Chen', 'Jun Zhao', 'Yantao Jia', 'Yuantao Xie', 'Weijian Sun']",,,なし,
Few-shot Complex Knowledge Base Question Answering via Meta Reinforcement Learning,"['Yuncheng Hua', 'Yuan-Fang Li', 'Gholamreza Haffari', 'Guilin Qi', 'Tongtong Wu']",,,なし,
Few-Shot Learning for Opinion Summarization,"['Arthur Bražinskas', 'Mirella Lapata', 'Ivan Titov']",,,なし,
Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness,"['Reina Akama', 'Sho Yokoi', 'Jun Suzuki', 'Kentaro Inui']",http://arxiv.org/abs/2004.14008v2,"Large-scale dialogue datasets have recently become available for training neural dialogue agents. However, these datasets have been reported to contain a non-negligible number of unacceptable utterance pairs. In this paper, we propose a method for scoring the quality of utterance pairs in terms of their connectivity and relatedness. The proposed scoring method is designed based on findings widely shared in the dialogue and linguistics research communities. We demonstrate that it has a relatively good correlation with the human judgment of dialogue quality. Furthermore, the method is applied to filter out potentially unacceptable utterance pairs from a large-scale noisy dialogue corpus to ensure its quality. We experimentally confirm that training data filtered by the proposed method improves the quality of neural dialogue agents in response generation.",近年、ニューラル対話エージェントの学習に大規模な対話データセットが利用できるようになってきた。しかし、これらのデータセットには、許容できない発話ペアが無視できないほど多く含まれていることが報告されている。本論文では、音声ペアの品質を、接続性と関連性の観点からスコアリングする手法を提案する。提案するスコアリング手法は、対話や言語学の研究コミュニティで広く共有されている知見に基づいて設計されている。その結果、人間による対話の質の判断と比較的良い相関関係があることを示した。さらに、大規模なノイズの多い対話コーパスから許容できない可能性のある発話ペアをフィルタリングし、対話の品質を確保することを試みた。本研究では、本手法を用いてフィルタリングした訓練データを用いて、ニューラル対話エージェントの応答生成の質を向上させることを実験的に確認した。,
Form2Seq : A Framework for Higher-Order Form Structure Extraction,"['Milan Aggarwal', 'Hiresh Gupta', 'Mausoom Sarkar', 'Balaji Krishnamurthy']",,,なし,
Friendly Topic Assistant for Transformer Based Abstractive Summarization,"['Zhengjue Wang', 'Zhibin Duan', 'Hao Zhang', 'chaojie wang', 'long tian', 'Bo Chen', 'Mingyuan Zhou']",,,なし,
From Zero to Hero: On the Limitations of Zero-Shot Language Transfer with Multilingual Transformers,"['Anne Lauscher', 'Vinit Ravishankar', 'Ivan Vulić', 'Goran Glavaš']",http://arxiv.org/abs/2005.00633v1,"Massively multilingual transformers pretrained with language modeling objectives (e.g., mBERT, XLM-R) have become a de facto default transfer paradigm for zero-shot cross-lingual transfer in NLP, offering unmatched transfer performance. Current downstream evaluations, however, verify their efficacy predominantly in transfer settings involving languages with sufficient amounts of pretraining data, and with lexically and typologically close languages. In this work, we analyze their limitations and show that cross-lingual transfer via massively multilingual transformers, much like transfer via cross-lingual word embeddings, is substantially less effective in resource-lean scenarios and for distant languages. Our experiments, encompassing three lower-level tasks (POS tagging, dependency parsing, NER), as well as two high-level semantic tasks (NLI, QA), empirically correlate transfer performance with linguistic similarity between the source and target languages, but also with the size of pretraining corpora of target languages. We also demonstrate a surprising effectiveness of inexpensive few-shot transfer (i.e., fine-tuning on a few target-language instances after fine-tuning in the source) across the board. This suggests that additional research efforts should be invested to reach beyond the limiting zero-shot conditions.",言語モデリング目的で事前訓練された多言語変換器（mBERT、XLM-Rなど）は、NLPにおけるゼロショット交差言語変換のための事実上のデフォルトの変換パラダイムとなっており、比類のない変換性能を提供している。しかし、現在の下流での評価では、十分な量の事前学習データがあり、語彙的にも類型的にも近い言語を含むトランスファー設定において、主にその有効性が検証されている。本研究では、これらの限界を分析し、大規模多言語変換器を用いた異言語間伝達は、異言語間の単語埋め込みを用いた伝達と同様に、リソースの少ないシナリオや遠い言語では、実質的に効果が低いことを示す。我々の実験では、3つの下位レベルのタスク（POSタグ付け、依存性解析、NER）と2つの上位レベルの意味的タスク（NLI、QA）を含んでおり、伝達性能はソース言語とターゲット言語の間の言語的類似性だけでなく、ターゲット言語の事前学習コーパスのサイズとも経験的に相関していた。また、安価な少数発の伝達（すなわち、原語で微調整を行った後、少数の対象言語のインスタンスで微調整を行うこと）が、全体的に驚くほど有効であることも実証した。このことは、限界的なゼロショット条件を超えるために、さらなる研究努力が必要であることを示唆している。,https://d3i71xaburhd42.cloudfront.net/0f509cf3445d1afce307d1eea66a411242147d90/6-Table1-1.png
Frustratingly Simple Few-Shot Named Entity Recognition with Structured Nearest Neighbor Learning,"['Yi Yang', 'Arzoo Katiyar']",,,なし,
Generating Dialogue Responses from a Semantic Latent Space,"['Wei-Jen Ko', 'Avik Ray', 'Yilin Shen', 'Hongxia Jin']",http://arxiv.org/abs/2010.01658v1,"Existing open-domain dialogue generation models are usually trained to mimic the gold response in the training set using cross-entropy loss on the vocabulary. However, a good response does not need to resemble the gold response, since there are multiple possible responses to a given prompt. In this work, we hypothesize that the current models are unable to integrate information from multiple semantically similar valid responses of a prompt, resulting in the generation of generic and uninformative responses. To address this issue, we propose an alternative to the end-to-end classification on vocabulary. We learn the pair relationship between the prompts and responses as a regression task on a latent space instead. In our novel dialog generation model, the representations of semantically related sentences are close to each other on the latent space. Human evaluation showed that learning the task on a continuous space can generate responses that are both relevant and informative.",既存のオープンドメイン対話生成モデルは、通常、語彙のクロスエントロピー損失を用いて、訓練セットのゴールド応答を模倣するように訓練される。しかし、与えられたプロンプトに対する応答は複数の可能性があるため、良い応答は必ずしも金色の応答に似ている必要はない。本研究では、現在のモデルでは、意味的に類似した複数の有効な応答からの情報を統合することができず、結果として汎用的で情報に乏しい応答が生成されてしまうという仮説を立てた。この問題を解決するために、本研究では、語彙に関するエンドツーエンドの分類に代わる方法を提案する。我々は、潜在空間の回帰タスクとしてプロンプトと応答の間のペア関係を学習する。我々の新しい対話生成モデルでは、意味的に関連する文の表現は潜在空間上で互いに近接している。人的評価の結果、連続空間上での学習により、関連性と情報量の多い応答を生成できることが示された。,https://d3i71xaburhd42.cloudfront.net/bf0a105ea66168b6ecafe4df8406c31069472519/3-Figure1-1.png
Generating Diverse Translation from Model Distribution with Dropout,"['Xuanfu Wu', 'Yang Feng', 'Chenze Shao']",http://arxiv.org/abs/2010.08178v1,"Despite the improvement of translation quality, neural machine translation (NMT) often suffers from the lack of diversity in its generation. In this paper, we propose to generate diverse translations by deriving a large number of possible models with Bayesian modelling and sampling models from them for inference. The possible models are obtained by applying concrete dropout to the NMT model and each of them has specific confidence for its prediction, which corresponds to a posterior model distribution under specific training data in the principle of Bayesian modeling. With variational inference, the posterior model distribution can be approximated with a variational distribution, from which the final models for inference are sampled. We conducted experiments on Chinese-English and English-German translation tasks and the results shows that our method makes a better trade-off between diversity and accuracy.",ニューラル機械翻訳(NMT)は、翻訳品質の向上にもかかわらず、その生成に多様性がないことに悩まされることが多い。本論文では、ベイズモデリングを用いて多数の可能性のあるモデルを導出し、その中からモデルをサンプリングして推論を行うことで、多様な翻訳を生成することを提案する。可能なモデルはNMTモデルに具体的なドロップアウトを適用して得られ、それぞれのモデルはその予測に対して特定の信頼度を持っており、これはベイズモデリングの原理における特定の訓練データの下での事後モデル分布に相当する。変分推論では、事後モデル分布を変分分布で近似することができ、そこから推論の最終モデルをサンプリングする。中英・英独の翻訳タスクを対象に実験を行った結果、我々の手法は多様性と精度のトレードオフがより良いことを示している。,https://d3i71xaburhd42.cloudfront.net/99959092c6eadcf359ed8f74de2168244bbe402e/6-Table1-1.png
Generating Fact Checking Briefs,"['Angela Fan', 'Aleksandra Piktus', 'Fabio Petroni', 'Guillaume Wenzek', 'Marzieh Saeidi', 'Andreas Vlachos', 'Antoine Bordes', 'Sebastian Riedel']",,,なし,
Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze,"['Ece Takmaz', 'Sandro Pezzelle', 'Lisa Beinborn', 'Raquel Fernández']",,,なし,
Generating Radiology Reports via Memory-driven Transformer,"['Zhihong Chen', 'Yan Song', 'Tsung-Hui Chang', 'Xiang Wan']",,,なし,
Generating similes e̶f̶f̶o̶r̶t̶l̶e̶s̶s̶l̶y̶ 𝘭𝘪𝘬𝘦 𝘢 𝘗𝘳𝘰: A Style Transfer Approach for Simile Generation,"['Tuhin Chakrabarty', 'Smaranda Muresan', 'Nanyun Peng']",,,なし,
"Generationary or: ""How we Went Beyond Word Sense Inventories and Learned to Gloss""","['Michele Bevilacqua', 'Marco Maru', 'Roberto Navigli']",,,なし,
Global-to-Local Neural Networks for Document-Level Relation Extraction,"['Difeng Wang', 'Wei Hu', 'Ermei Cao', 'Weijian Sun']",http://arxiv.org/abs/2009.10359v1,"Relation extraction (RE) aims to identify the semantic relations between named entities in text. Recent years have witnessed it raised to the document level, which requires complex reasoning with entities and mentions throughout an entire document. In this paper, we propose a novel model to document-level RE, by encoding the document information in terms of entity global and local representations as well as context relation representations. Entity global representations model the semantic information of all entities in the document, entity local representations aggregate the contextual information of multiple mentions of specific entities, and context relation representations encode the topic information of other relations. Experimental results demonstrate that our model achieves superior performance on two public datasets for document-level RE. It is particularly effective in extracting relations between entities of long distance and having multiple mentions.",関係抽出（RE）は、テキスト中の名前付きエンティティ間の意味的関係を特定することを目的としています。近年、関係抽出は文書レベルにまで引き上げられてきており、文書全体の実体や言及を用いた複雑な推論が必要とされている。本論文では、文書情報をエンティティグローバル表現とローカル表現、および文脈関係表現で符号化することにより、文書レベルでのREの新しいモデルを提案する。エンティティグローバル表現は文書中のすべてのエンティティの意味情報をモデル化し、エンティティローカル表現は特定のエンティティの複数の言及の文脈情報を集約し、コンテキスト関係表現は他の関係のトピック情報を符号化する。実験の結果、我々のモデルは2つの公開データセットにおいて、文書レベルのREのために優れた性能を達成していることが示された。特に、距離が長く、複数の言及を持つエンティティ間の関係を抽出するのに有効である。,https://d3i71xaburhd42.cloudfront.net/cb00cf22920d317e1e8b886dd19fd005a1b65111/1-Figure1-1.png
GLUCOSE: GeneraLized and COntextualized Story Explanations,"['Nasrin Mostafazadeh', 'Aditya Kalyanpur', 'Lori Moon', 'David Buchanan', 'Lauren Berkowitz', 'Or Biran', 'Jennifer Chu-Carroll']",http://arxiv.org/abs/2009.07758v1,"When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal mini-theories about the world, each grounded in a narrative context. To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focusing on events, states, motivations, and emotions. Each GLUCOSE entry includes a story-specific causal statement paired with an inference rule generalized from the statement. This paper details two concrete contributions: First, we present our platform for effectively crowdsourcing GLUCOSE data at scale, which uses semi-structured templates to elicit causal explanations. Using this platform, we collected 440K specific statements and general rules that capture implicit commonsense knowledge about everyday situations. Second, we show that existing knowledge resources and pretrained language models do not include or readily predict GLUCOSE's rich inferential content. However, when state-of-the-art neural models are trained on this knowledge, they can start to make commonsense inferences on unseen stories that match humans' mental models.",人間は、読んだり聞いたりすると、何が起こったのか、なぜ起こったのかという理解の骨組みとなる暗黙のコモンセンス推論を行います。同様のメンタルモデルを構築できるAIシステムへの一歩として、我々は、暗黙の常識的な因果知識の大規模データセットであるGLUCOSEを紹介します。GLUCOSEを構築するには、我々は、イベント、状態、動機、および感情に焦点を当てて、因果説明の10の次元を識別するために認知心理学に描いた。各GLUCOSEエントリは、ステートメントから一般化された推論ルールとペアのストーリー固有の因果文が含まれています。本論文では、2つの具体的な貢献を詳述する。第一に、GLUCOSEデータを効果的にクラウドソーシングするためのプラットフォームを提示する。このプラットフォームを用いて、日常的な状況についての暗黙の常識的知識を捉えた44万個の特定の文と一般的なルールを収集した。第二に、既存の知識資源や事前に訓練された言語モデルでは、GLUCOSEの豊富な推論的内容を含んでいない、あるいは容易に予測できないことを示した。しかし、最先端のニューラルモデルがこの知識に基づいて訓練されると、人間のメンタルモデルと一致する見たことのない物語についての常識的な推論を開始することができる。,https://d3i71xaburhd42.cloudfront.net/3065d646367f0d894bfb65b7a3a01b448db20b4f/2-Table1-1.png
Gone At Last: Removing the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training,"['Joe Stacey', 'Pasquale Minervini', 'Haim Dubossarsky', 'Sebastian Riedel', 'Tim Rocktäschel']",,,なし,
GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems,"['Lishan Huang', 'Zheng Ye', 'Jinghui Qin', 'Liang Lin', 'Xiaodan Liang']",http://arxiv.org/abs/2010.03994v1,"Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterance-level semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, GRADE incorporates both coarse-grained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgements. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.",対話のコヒーレンスを自動的に評価することは、高品質なオープンドメイン対話システムを開発する上で、困難ではあるが需要の高い能力である。しかし、現在の評価基準では、対話フローの微細なトピック遷移のダイナミクスは考慮されておらず、表面的な特徴や発話レベルのセマンティクスしか考慮されていないのが現状です。ここではまず、対話のトピックで構成されたグラフ構造が、対話の根底にあるコミュニケーションロジックを正確に表現できることを考え、より自然な方法で説得力のあるメトリクスを生成することを考える。このようなトピックレベルの対話グラフを利用して、新しい評価指標GRADE（Graph-enhanced Representations for Automatic Dialogue Evaluation）を提案する。具体的には、粗視化された発話レベルの文脈表現と、細視化されたトピックレベルのグラフ表現を組み合わせて、対話の一貫性を評価する。グラフ表現は、k-ホップ隣接表現とホップアテンション重みを含むコモンセンスグラフからのエビデンスで強化されたトピックレベルの対話グラフを推論することで得られる。実験の結果、本研究のGRADEは、多様な対話モデルを測定する上で、人間の判断とのピアソン相関やスピアマン相関の点で、他の最先端のメトリクスを大きく凌駕することを示した。また、今後の自動評価指標の研究を促進するために、大規模な人間評価ベンチマークを公開する。,https://d3i71xaburhd42.cloudfront.net/b37c3c2ae4571e6e96f5dbcf39c0b4a744810597/1-Figure1-1.png
Gradient-guided Unsupervised Lexically Constrained Text Generation,['Lei Sha'],,,なし,
Grammatical Error Correction in Low Error Density Domains: A New Benchmark and Analyses,"['Simon Flachs', 'Ophélie Lacroix', 'Helen Yannakoudakis', 'Marek Rei', 'Anders Søgaard']",http://arxiv.org/abs/2010.07574v1,"Evaluation of grammatical error correction (GEC) systems has primarily focused on essays written by non-native learners of English, which however is only part of the full spectrum of GEC applications. We aim to broaden the target domain of GEC and release CWEB, a new benchmark for GEC consisting of website text generated by English speakers of varying levels of proficiency. Website data is a common and important domain that contains far fewer grammatical errors than learner essays, which we show presents a challenge to state-of-the-art GEC systems. We demonstrate that a factor behind this is the inability of systems to rely on a strong internal language model in low error density domains. We hope this work shall facilitate the development of open-domain GEC models that generalize to different topics and genres.",文法的誤り訂正（GEC）システムの評価は、主に英語を母国語としない学習者が書いたエッセイを対象としていますが、これはGECの応用範囲のほんの一部に過ぎません。我々は、GECの対象領域を拡大し、様々なレベルの英語話者が作成したWebサイトのテキストから構成されるGECの新しいベンチマークであるCWEBをリリースします。ウェブサイトデータは、学習者のエッセイに比べて文法的な誤りがはるかに少ない、一般的で重要なドメインです。その背景には、エラー密度の低い領域ではシステムが強力な内部言語モデルに頼ることができないことがあることを示している。この研究により、異なるトピックやジャンルに一般化するオープンドメインのGECモデルの開発が促進されることを期待している。,https://d3i71xaburhd42.cloudfront.net/bf653319c217af18debb1c2ebebfbf1485dcaba8/1-Figure1-1.png
Graph Convolutions over Constituent Trees for Syntax-Aware Semantic Role Labeling,"['Diego Marcheggiani', 'Ivan Titov']",http://arxiv.org/abs/1909.09814v2,"Semantic role labeling (SRL) is the task of identifying predicates and labeling argument spans with semantic roles. Even though most semantic-role formalisms are built upon constituent syntax and only syntactic constituents can be labeled as arguments (e.g., FrameNet and PropBank), all the recent work on syntax-aware SRL relies on dependency representations of syntax. In contrast, we show how graph convolutional networks (GCNs) can be used to encode constituent structures and inform an SRL system. Nodes in our SpanGCN correspond to constituents. The computation is done in 3 stages. First, initial node representations are produced by `composing' word representations of the first and the last word in the constituent. Second, graph convolutions relying on the constituent tree are performed, yielding syntactically-informed constituent representations. Finally, the constituent representations are `decomposed' back into word representations which in turn are used as input to the SRL classifier. We evaluate SpanGCN against alternatives, including a model using GCNs over dependency trees, and show its effectiveness on standard CoNLL-2005, CoNLL-2012, and FrameNet benchmarks.",意味的役割ラベリング(SRL)は、述語を識別し、引数スパンを意味的役割でラベリングする作業である。ほとんどの意味役割形式は構成要素の構文に基づいて構築されており、構文的な構成要素のみを引数としてラベル付けすることができる（例：FrameNetやPropBank）にもかかわらず、構文を考慮したSRLに関する最近の研究はすべて構文の依存性表現に依存している。これとは対照的に、グラフ畳み込みネットワーク（GCN）を使用して構成構造を符号化し、SRLシステムに情報を提供する方法を示します。我々のSpanGCNのノードは構成要素に対応している。計算は3段階で行われます。第一に、初期ノード表現は、構成要素の最初の単語と最後の単語の単語表現を「合成」することによって生成されます。第二に、構成要素の木に依存したグラフの畳み込みが実行され、構文的に情報化された構成要素の表現が得られる。最後に、構成要素の表現を「分解」して単語表現に戻し、これをSRL分類器の入力として使用します。我々は、SpanGCNを、依存性木上のGCNを使用するモデルを含む代替モデルに対して評価し、標準的なCoNLL-2005、CoNLL-2012、およびFrameNetベンチマークでその有効性を示す。,https://d3i71xaburhd42.cloudfront.net/71c75a162ab75e9334045a23c6f85143d593582b/1-Figure1-1.png
GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems,"['Shiquan Yang', 'Rui Zhang', 'Sarah Erfani']",http://arxiv.org/abs/2010.01447v1,"End-to-end task-oriented dialogue systems aim to generate system responses directly from plain text inputs. There are two challenges for such systems: one is how to effectively incorporate external knowledge bases (KBs) into the learning framework; the other is how to accurately capture the semantics of dialogue history. In this paper, we address these two challenges by exploiting the graph structural information in the knowledge base and in the dependency parsing tree of the dialogue. To effectively leverage the structural information in dialogue history, we propose a new recurrent cell architecture which allows representation learning on graphs. To exploit the relations between entities in KBs, the model combines multi-hop reasoning ability based on the graph structure. Experimental results show that the proposed model achieves consistent improvement over state-of-the-art models on two different task-oriented dialogue datasets.",エンドツーエンドのタスク指向対話システムは、プレーンテキスト入力から直接システム応答を生成することを目的としている。このようなシステムには2つの課題がある。1つは外部の知識ベース（KB）を学習フレームワークに効果的に組み込む方法であり、もう1つは対話履歴のセマンティクスを正確に捉える方法である。本論文では、知識ベースと対話の依存性解析木に含まれるグラフ構造情報を活用することで、この2つの課題を解決する。対話履歴の構造情報を効果的に活用するために、グラフ上の表現学習を可能にする新しいリカレントセルアーキテクチャを提案する。KB内のエンティティ間の関係性を利用するために、このモデルはグラフ構造に基づくマルチホップ推論能力を組み合わせたものである。実験の結果、提案モデルは、2つの異なるタスク指向の対話データセットにおいて、最先端のモデルと比較して一貫した改善を達成していることが示された。,https://d3i71xaburhd42.cloudfront.net/8ea086d89e57444655191be51355b104b79feb4b/1-Figure1-1.png
Grounded Adaptation for Zero-shot Executable Semantic Parsing,"['Victor Zhong', 'Mike Lewis', 'Sida I. Wang', 'Luke Zettlemoyer']",http://arxiv.org/abs/2009.07396v2,"We propose Grounded Adaptation for Zero-shot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycle-consistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose input-output consistency are verified. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms data-augmentation in the training environment, performance increases with the amount of GAZP-synthesized data, and cycle-consistency is central to successful adaptation.",我々は、既存のセマンティックパーサーを新しい環境（例えば、新しいデータベーススキーマ）に適応させるために、ゼロショット実行可能なセマンティックパーシングのための接地適応（GAZP）を提案する。GAZPは、前方のセマンティックパーサーと後方の発話生成器を組み合わせて、新しい環境でデータ（発話やSQLクエリなど）を合成し、サイクルに一貫した例を選択してパーサーを適応させます。一般的に学習環境で検証されていない例を合成するデータ補強とは異なり、GAZPは入出力の整合性が検証された例を新しい環境で合成します。Spider、Sparc、CoSQLのゼロショット意味解析タスクにおいて、GAZPはベースラインパーサーの論理形式と実行精度を向上させた。我々の分析では、GAZPがトレーニング環境でのデータ補強よりも優れていること、GAZPで合成されたデータ量に応じて性能が向上すること、サイクルの一貫性が適応を成功させるための中心となることが示された。,https://d3i71xaburhd42.cloudfront.net/c4bd3c684b56d076c5ee3afec48fad4c9c14579c/2-Figure1-1.png
Grounded Compositional Outputs for Adaptive Language Modeling,"['Nikolaos Pappas', 'Phoebe Mulcaire', 'Noah A. Smith']",http://arxiv.org/abs/2009.11523v2,"Language models have emerged as a central component across NLP, and a great deal of progress depends on the ability to cheaply adapt them (e.g., through finetuning) to new domains and tasks. A language model's vocabulary$-$typically selected before training and permanently fixed later$-$affects its size and is part of what makes it resistant to such adaptation. Prior work has used compositional input embeddings based on surface forms to ameliorate this issue. In this work, we go one step beyond and propose a fully compositional output embedding layer for language models, which is further grounded in information from a structured lexicon (WordNet), namely semantically related words and free-text definitions. To our knowledge, the result is the first word-level language model with a size that does not depend on the training vocabulary. We evaluate the model on conventional language modeling as well as challenging cross-domain settings with an open vocabulary, finding that it matches or outperforms previous state-of-the-art output embedding methods and adaptation approaches. Our analysis attributes the improvements to sample efficiency: our model is more accurate for low-frequency words.",言語モデルはNLPの中心的なコンポーネントとして登場し、多くの進歩は、新しいドメインやタスクに安価に（例えば、微調整を通して）適応させることができるかどうかにかかっています。言語モデルの語彙$$-通常、訓練前に選択され、後で永久に固定される$$-は、その大きさに影響を与え、そのような適応に抵抗力を持たせるものの一部である。これまでの研究では、この問題を改善するために、表面形式に基づく構成的な入力埋め込みを使用してきました。本研究では、これをさらに一歩進めて、構造化辞書(WordNet)からの情報、すなわち意味的に関連する単語と自由文の定義に基づいた、言語モデルのための完全に構成的な出力埋め込み層を提案する。この結果は、学習語彙に依存しないサイズを持つ初めての単語レベル言語モデルである。このモデルを、従来の言語モデリングや、オープンボキャブラリーを用いた困難なクロスドメイン設定で評価したところ、これまでの最先端の出力埋め込み法や適応アプローチと一致するか、あるいはそれを上回る結果が得られた。我々の分析では、この改善はサンプル効率の向上に起因している。,https://d3i71xaburhd42.cloudfront.net/53d5930ecd9dcc3eb79ef576f61fea248602e850/3-Figure1-1.png
H2KGAT: Hierarchical Hyperbolic Knowledge Graph Attention Network,"['Shen Wang', 'Xiaokai Wei', 'Cícero Nogueira dos Santos', 'Zhiguo Wang', 'Ramesh Nallapati', 'Andrew Arnold', 'Bing Xiang', 'Philip S. Yu']",,,なし,
HABERTOR: An Efficient and Effective Deep Hatespeech Detector,"['Thanh Tran', 'Yifan Hu', 'Changwei Hu', 'Kevin Yen', 'Fei Tan', 'Kyumin Lee', 'Se Rim Park']",http://arxiv.org/abs/2010.08865v1,"We present our HABERTOR model for detecting hatespeech in large scale user-generated content. Inspired by the recent success of the BERT model, we propose several modifications to BERT to enhance the performance on the downstream hatespeech classification task. HABERTOR inherits BERT's architecture, but is different in four aspects: (i) it generates its own vocabularies and is pre-trained from the scratch using the largest scale hatespeech dataset; (ii) it consists of Quaternion-based factorized components, resulting in a much smaller number of parameters, faster training and inferencing, as well as less memory usage; (iii) it uses our proposed multi-source ensemble heads with a pooling layer for separate input sources, to further enhance its effectiveness; and (iv) it uses a regularized adversarial training with our proposed fine-grained and adaptive noise magnitude to enhance its robustness. Through experiments on the large-scale real-world hatespeech dataset with 1.4M annotated comments, we show that HABERTOR works better than 15 state-of-the-art hatespeech detection methods, including fine-tuning Language Models. In particular, comparing with BERT, our HABERTOR is 4~5 times faster in the training/inferencing phase, uses less than 1/3 of the memory, and has better performance, even though we pre-train it by using less than 1% of the number of words. Our generalizability analysis shows that HABERTOR transfers well to other unseen hatespeech datasets and is a more efficient and effective alternative to BERT for the hatespeech classification.",我々は、大規模なユーザー生成コンテンツにおけるヘイトスピーチを検出するためのHABERTORモデルを提示する。最近のBERTモデルの成功に触発されて、我々は、下流のヘイトスピーチ分類タスクの性能を向上させるために、BERTにいくつかの修正を提案する。HABERTORはBERTのアーキテクチャを継承しているが、4つの点で異なる。(i) 独自の語彙を生成し、最大規模の異口同音データセットを使用してゼロから事前訓練を行っている。(ii) クオータニオンベースの因数分解成分で構成されているため、パラメータ数が大幅に少なくなり、訓練と推論が高速化され、メモリ使用量も少なくなる。(iii) 別々の入力ソースのためのプーリング層を持つ我々の提案するマルチソースアンサンブルヘッドを使用して、その有効性をさらに高める。1.4Mの注釈付きコメントを含む大規模な実世界の口語音声データセットでの実験を通じて、HABERTORが、微調整言語モデルを含む15の最先端の口語音声検出手法よりも優れた働きをすることを示す。特に、BERTと比較して、我々のHABERTORは、単語数の1%未満を使用して事前訓練を行っているにもかかわらず、訓練段階で4～5倍高速であり、メモリ使用量は13未満であり、より優れた性能を有している。我々の一般化可能性分析は、HABERTORが他の目に見えない嫌声データセットにうまく移行し、嫌声分類のためのBERTのより効率的で効果的な代替手段であることを示している。,https://d3i71xaburhd42.cloudfront.net/3ae6450d4d1181b72d1a93aab832afec1b258c03/4-Figure1-1.png
Hate-Speech and Offensive Language Detection in Roman Urdu,"['Hammad Rizwan', 'Muhammad Haroon Shakeel', 'Asim Karim']",,,なし,
Help! Need Advice on Identifying Advice,"['Venkata Subrahmanyan Govindarajan', 'Benjamin Chen', 'Rebecca Warholic', 'Katrin Erk', 'Junyi Jessy Li']",,,なし,
HENIN: Learning Heterogeneous Neural Interaction Networks for Explainable Cyberbullying Detection on Social Media,"['Chen Hsin-Yu', 'Cheng-Te Li']",,,なし,
Hero: Hierarchical Encoder for Video+Language Omni-representation Pre-training,"['Linjie Li', 'Yen-Chun Chen', 'Yu Cheng', 'Zhe Gan', 'Licheng Yu', 'Jingjing Liu']",http://arxiv.org/abs/2005.00200v2,"We present HERO, a novel framework for large-scale video+language omni-representation learning. HERO encodes multimodal inputs in a hierarchical structure, where local context of a video frame is captured by a Cross-modal Transformer via multimodal fusion, and global video context is captured by a Temporal Transformer. In addition to standard Masked Language Modeling (MLM) and Masked Frame Modeling (MFM) objectives, we design two new pre-training tasks: (i) Video-Subtitle Matching (VSM), where the model predicts both global and local temporal alignment; and (ii) Frame Order Modeling (FOM), where the model predicts the right order of shuffled video frames. HERO is jointly trained on HowTo100M and large-scale TV datasets to gain deep understanding of complex social dynamics with multi-character interactions. Comprehensive experiments demonstrate that HERO achieves new state of the art on multiple benchmarks over Text-based Video/Video-moment Retrieval, Video Question Answering (QA), Video-and-language Inference and Video Captioning tasks across different domains. We also introduce two new challenging benchmarks How2QA and How2R for Video QA and Retrieval, collected from diverse video content over multimodalities.",本研究では、大規模ビデオ＋言語オムニリープレゼンテーション学習のための新しいフレームワークであるHEROを提案する。HEROはマルチモーダル入力を階層構造でエンコードし、ビデオフレームのローカルコンテキストはマルチモーダル融合を介してCross-modal Transformerによって、グローバルコンテキストはTemporal Transformerによって捕捉される。標準的なマスクド言語モデリング(MLM)とマスクドフレームモデリング(MLM)の目的に加えて、我々は2つの新しい事前学習タスクを設計した。(i) ビデオ字幕マッチング(VSM)では、モデルがグローバルとローカルの時間アライメントを予測し、(ii) フレーム順序モデリング(FOM)では、モデルがシャッフルされたビデオフレームの正しい順序を予測する。HEROは、HowTo100Mと大規模テレビデータセットを用いて共同で訓練され、複数のキャラクターのインタラクションを伴う複雑な社会的ダイナミクスを深く理解することができます。包括的な実験により、HEROがテキストベースの動画モーメント検索、動画質問応答（QA）、動画と言語の推論、動画キャプションタスクなど、異なる領域にまたがる複数のベンチマークにおいて、新たな技術を達成していることが実証された。また、マルチモーダリティの多様な動画コンテンツから収集した、動画QAと検索のための2つの新しい挑戦的なベンチマークHow2QAとHow2Rを紹介します。,https://d3i71xaburhd42.cloudfront.net/5546e6073f3b82967b12c87d6b90ba722c4b85c6/4-Figure1-1.png
Hierarchical Evidence Set Modeling for Automated Fact Extraction and Verification,"['Shyam Subramanian', 'Kyumin Lee']",http://arxiv.org/abs/2010.05111v1,"Automated fact extraction and verification is a challenging task that involves finding relevant evidence sentences from a reliable corpus to verify the truthfulness of a claim. Existing models either (i) concatenate all the evidence sentences, leading to the inclusion of redundant and noisy information; or (ii) process each claim-evidence sentence pair separately and aggregate all of them later, missing the early combination of related sentences for more accurate claim verification. Unlike the prior works, in this paper, we propose Hierarchical Evidence Set Modeling (HESM), a framework to extract evidence sets (each of which may contain multiple evidence sentences), and verify a claim to be supported, refuted or not enough info, by encoding and attending the claim and evidence sets at different levels of hierarchy. Our experimental results show that HESM outperforms 7 state-of-the-art methods for fact extraction and claim verification. Our source code is available at https://github.com/ShyamSubramanian/HESM.",自動化された事実抽出と検証は、クレームの真実性を検証するために、信頼できるコーパスから関連する証拠文を見つけることを含む、困難なタスクです。既存のモデルでは、(i)すべての証拠文を連結してしまうため、冗長でノイズの多い情報が含まれてしまうか、(ii)各主張と証拠文のペアを別々に処理し、後からすべてを集約してしまうため、より正確な主張の検証のために関連する文の早期の組み合わせを見逃してしまう。これまでの研究とは異なり、本論文では、Hierarchical Evidence Set Modeling (HESM)と呼ばれるフレームワークを提案する。我々の実験結果は、HESMが事実抽出と主張検証のための7つの最先端の手法を凌駕することを示している。我々のソースコードはhttps:/github.comShyamSubramanianHESMから入手可能です。,https://d3i71xaburhd42.cloudfront.net/88766b0cfea3ee2999d1277267e00e82828dbf22/2-Figure1-1.png
Hierarchical Graph Network for Multi-hop Question Answering,"['Yuwei Fang', 'Siqi Sun', 'Zhe Gan', 'Rohit Pillai', 'Shuohang Wang', 'Jingjing Liu']",http://arxiv.org/abs/1911.03631v4,"In this paper, we present Hierarchical Graph Network (HGN) for multi-hop question answering. To aggregate clues from scattered texts across multiple paragraphs, a hierarchical graph is created by constructing nodes on different levels of granularity (questions, paragraphs, sentences, entities), the representations of which are initialized with pre-trained contextual encoders. Given this hierarchical graph, the initial node representations are updated through graph propagation, and multi-hop reasoning is performed via traversing through the graph edges for each subsequent sub-task (e.g., paragraph selection, supporting facts extraction, answer prediction). By weaving heterogeneous nodes into an integral unified graph, this hierarchical differentiation of node granularity enables HGN to support different question answering sub-tasks simultaneously. Experiments on the HotpotQA benchmark demonstrate that the proposed model achieves new state of the art, outperforming existing multi-hop QA approaches.",本論文では、マルチホップ質問応答のための階層グラフネットワーク(HGN)を提案する。複数の段落に散らばったテキストからの手がかりを集約するために、異なるレベルの粒度（質問、段落、文、実体）のノードを構築することで階層的なグラフを作成する。この階層グラフが与えられると、初期ノードの表現はグラフ伝搬によって更新され、マルチホップ推論は、後続の各サブタスク（例：段落選択、支持事実抽出、回答予測）のために、グラフのエッジをトラバースすることによって実行されます。異種ノードを統合された統一グラフに織り込むことで、ノードの粒度を階層的に区別することで、HGNは異なる質問に答えるサブタスクを同時にサポートすることができます。HotpotQAベンチマークの実験では、提案モデルが既存のマルチホップQAアプローチを凌駕する新たな状態を達成していることが実証された。,https://d3i71xaburhd42.cloudfront.net/d74e0da493372fc03d0a537f1837add77983c938/6-Table1-1.png
HIT: Nested Named Entity Recognition via Head-Tail Pair and Token Interaction,"['Yu Wang', 'Yun Li', 'Hanghang Tong', 'Ziye Zhu']",,,なし,
How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking,"['Nicola De Cao', 'Michael Sejr Schlichtkrull', 'Wilker Aziz', 'Ivan Titov']",http://arxiv.org/abs/2004.14992v2,"Attribution methods assess the contribution of inputs to the model prediction. One way to do so is erasure: a subset of inputs is considered irrelevant if it can be removed without affecting the prediction. Though conceptually simple, erasure's objective is intractable and approximate search remains expensive with modern deep NLP models. Erasure is also susceptible to the hindsight bias: the fact that an input can be dropped does not mean that the model `knows' it can be dropped. The resulting pruning is over-aggressive and does not reflect how the model arrives at the prediction. To deal with these challenges, we introduce Differentiable Masking. DiffMask learns to mask-out subsets of the input while maintaining differentiability. The decision to include or disregard an input token is made with a simple model based on intermediate hidden layers of the analyzed model. First, this makes the approach efficient because we predict rather than search. Second, as with probing classifiers, this reveals what the network `knows' at the corresponding layers. This lets us not only plot attribution heatmaps but also analyze how decisions are formed across network layers. We use DiffMask to study BERT models on sentiment classification and question answering.",帰属法は、モデル予測に対するインプットの寄与度を評価する。予測に影響を与えずに入力のサブセットを削除できれば、その入力は無関係であるとみなされます。概念的には単純ですが、消去の目的は難しく、最新のディープ NLP モデルでは近似探索にコストがかかります。また、消去は後知恵バイアスの影響を受けやすく、入力を削除できるという事実は、モデルがそれを削除できることを「知っている」ことを意味しません。結果として生じる剪定は過剰に攻撃的で、モデルがどのように予測に到達したかを反映していません。これらの課題に対処するために，我々は微分可能なマスキングを導入した．DiffMask は微分可能性を維持しながら入力のサブセットをマスクアウトすることを学習します．入力トークンを含めるか無視するかの決定は，分析モデルの中間隠れ層に基づいた単純なモデルで行われます．第一に、探索ではなく予測を行うため、このアプローチは効率的である。第二に、プロービング分類器と同様に、ネットワークが対応する層で何を「知っているか」を明らかにします。これにより、帰属のヒートマップをプロットするだけでなく、ネットワークのレイヤー間でどのように意思決定が形成されているかを分析することができる。我々は DiffMask を用いて、感情分類と質問応答に関する BERT モデルを研究している。,https://d3i71xaburhd42.cloudfront.net/e4763b0540684de9ea380c62e0aa996f271b4ab0/1-Figure1-1.png
Human-centric dialog training via offline reinforcement learning,"['Natasha Jaques', 'Judy Hanwen Shen', 'Asma Ghandeharioun', 'Craig Ferguson', 'Agata Lapedriza', 'Noah Jones', 'Shixiang Gu', 'Rosalind Picard']",http://arxiv.org/abs/2010.05848v1,"How can we train a dialog model to produce better conversations by learning from human feedback, without the risk of humans teaching it harmful chat behaviors? We start by hosting models online, and gather human feedback from real-time, open-ended conversations, which we then use to train and improve the models using offline reinforcement learning (RL). We identify implicit conversational cues including language similarity, elicitation of laughter, sentiment, and more, which indicate positive human feedback, and embed these in multiple reward functions. A well-known challenge is that learning an RL policy in an offline setting usually fails due to the lack of ability to explore and the tendency to make over-optimistic estimates of future reward. These problems become even harder when using RL for language models, which can easily have a 20,000 action vocabulary and many possible reward functions. We solve the challenge by developing a novel class of offline RL algorithms. These algorithms use KL-control to penalize divergence from a pre-trained prior language model, and use a new strategy to make the algorithm pessimistic, instead of optimistic, in the face of uncertainty. We test the resulting dialog model with ratings from 80 users in an open-domain setting and find it achieves significant improvements over existing deep offline RL approaches. The novel offline RL method is viable for improving any existing generative dialog model using a static dataset of human feedback.","人間が有害なチャット行動を教えるリスクを冒すことなく、人間のフィードバックから学習することで、より良い会話を生成するための対話モデルをどのようにして訓練するのでしょうか？私たちはモデルをオンラインでホストすることから始め、リアルタイムのオープンエンドの会話から人間のフィードバックを収集し、オフライン強化学習(RL)を使ってモデルを訓練し改善するために使用します。言語の類似性、笑いの誘発、感情など、人間のポジティブなフィードバックを示す暗黙の会話の手がかりを特定し、複数の報酬関数に埋め込みます。よく知られている課題は、オフライン設定でRLポリシーを学習すると、探索する能力がなく、将来の報酬を過度に楽観的に見積もる傾向があるため、通常は失敗するということである。これらの問題は、20,000の行動語彙と多くの可能な報酬関数を簡単に持つことができる言語モデルにRLを使用する場合には、さらに難しくなる。我々は、新しいクラスのオフラインRLアルゴリズムを開発することにより、この問題を解決する。これらのアルゴリズムは、事前に訓練された事前言語モデルからの発散をペナルティを与えるためにKL制御を使用し、不確実性に直面した場合にアルゴリズムを楽観的ではなく悲観的にするための新しい戦略を使用する。結果として得られた対話モデルをオープンドメイン設定で80人のユーザからの評価を用いてテストしたところ、既存のディープオフラインRLアプローチよりも大幅に改善されていることがわかった。この新しいオフラインRL法は、人間のフィードバックの静的なデータセットを用いて、既存の生成対話モデルを改善することが可能である。",https://d3i71xaburhd42.cloudfront.net/4ba7f8624ff30beeb24a4fc6076b896b2944f555/2-Figure1-1.png
Human-in-the-loop Debugging Deep Text Classifiers,"['Piyawat Lertvittayakumjorn', 'Lucia Specia', 'Francesca Toni']",http://arxiv.org/abs/2010.04987v1,"Since obtaining a perfect training dataset (i.e., a dataset which is considerably large, unbiased, and well-representative of unseen cases) is hardly possible, many real-world text classifiers are trained on the available, yet imperfect, datasets. These classifiers are thus likely to have undesirable properties. For instance, they may have biases against some sub-populations or may not work effectively in the wild due to overfitting. In this paper, we propose FIND -- a framework which enables humans to debug deep learning text classifiers by disabling irrelevant hidden features. Experiments show that by using FIND, humans can improve CNN text classifiers which were trained under different types of imperfect datasets (including datasets with biases and datasets with dissimilar train-test distributions).",完全な学習データセット（つまり，かなり大規模で，偏りがなく，未見のケースをよく表しているデータセット）を得ることはほとんど不可能なので，多くの実世界のテキスト分類器は，利用可能ではあるが不完全なデータセットを用いて学習されます．そのため、これらの分類器は望ましくない特性を持つ可能性があります。例えば，これらの分類器は，ある部分集団に対して偏りを持っていたり，オーバーフィッティングのために自然界では効果的に動作しないことがあるかもしれません．この論文では、無関係な隠れた特徴を無効にすることで、人間がディープラーニングテキスト分類器をデバッグすることを可能にするフレームワークであるFINDを提案する。実験では，FINDを用いることで，異なるタイプの不完全なデータセット（バイアスを持つデータセットや非類似な訓練-テスト分布を持つデータセットを含む）で学習されたCNNテキスト分類器を改善できることが示された．,https://d3i71xaburhd42.cloudfront.net/c13318f8d65505bffa13280b9e2d762982fdc0db/4-Figure1-1.png
STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation,"['Nader Akoury', 'Shufan Wang', 'Josh Whiting', 'Stephen Hood', 'Nanyun Peng', 'Mohit Iyyer']",http://arxiv.org/abs/2010.01717v1,"Systems for story generation are asked to produce plausible and enjoyable stories given an input context. This task is underspecified, as a vast number of diverse stories can originate from a single input. The large output space makes it difficult to build and evaluate story generation models, as (1) existing datasets lack rich enough contexts to meaningfully guide models, and (2) existing evaluations (both crowdsourced and automatic) are unreliable for assessing long-form creative text. To address these issues, we introduce a dataset and evaluation platform built from STORIUM, an online collaborative storytelling community. Our author-generated dataset contains 6K lengthy stories (125M tokens) with fine-grained natural language annotations (e.g., character goals and attributes) interspersed throughout each narrative, forming a robust source for guiding models. We evaluate language models fine-tuned on our dataset by integrating them onto STORIUM, where real authors can query a model for suggested story continuations and then edit them. Automatic metrics computed over these edits correlate well with both user ratings of generated stories and qualitative feedback from semi-structured user interviews. We release both the STORIUM dataset and evaluation platform to spur more principled research into story generation.",物語生成のためのシステムには、入力された文脈が与えられたときに、説得力のある楽しい物語を生成することが求められています。この課題は、1つの入力から膨大な数の多様な物語が生まれる可能性があるため、あまり特定されていない。(1)既存のデータセットには、モデルを導くのに十分な豊かな文脈がないこと、(2)既存の評価（クラウドソーシングや自動評価の両方）は、長文の創作文を評価するのに信頼性が低いこと、などが挙げられる。これらの問題に対処するために、我々はオンラインの共同ストーリーテリングコミュニティであるSTORIUMから構築されたデータセットと評価プラットフォームを紹介する。我々が作成したデータセットは、6Kの長編ストーリー（125Mトークン）を収録しており、各ストーリーには細かい自然言語アノテーション（キャラクターの目標や属性など）が散りばめられており、ガイドモデルのためのロバストなソースを形成している。我々は、我々のデータセット上で微調整された言語モデルをSTORIUMに統合して評価している。ここでは、実際の作者が提案された物語の続きをモデルに問い合わせて編集することができる。これらの編集に基づいて計算された自動評価指標は、生成されたストーリーのユーザー評価と、半構造化されたユーザーインタビューからの定性的なフィードバックの両方とよく相関しています。私たちは、STORIUMデータセットと評価プラットフォームの両方を公開し、ストーリー生成に関するより原理的な研究に拍車をかけています。,https://d3i71xaburhd42.cloudfront.net/a0035379f93e0e95bdadd77a1d8eb27ba89dcf60/2-Figure1-1.png
Identifying Elements Essential for BERT’s Multilinguality,"['Philipp Dufter', 'Hinrich Schütze']",,,なし,
I’d rather just go to bed: Understanding Indirect Answers,"['Annie Louis', 'Dan Roth', 'Filip Radlinski']",http://arxiv.org/abs/2010.03450v1,"We revisit a pragmatic inference problem in dialog: understanding indirect responses to questions. Humans can interpret 'I'm starving.' in response to 'Hungry?', even without direct cue words such as 'yes' and 'no'. In dialog systems, allowing natural responses rather than closed vocabularies would be similarly beneficial. However, today's systems are only as sensitive to these pragmatic moves as their language model allows. We create and release the first large-scale English language corpus 'Circa' with 34,268 (polar question, indirect answer) pairs to enable progress on this task. The data was collected via elaborate crowdsourcing, and contains utterances with yes/no meaning, as well as uncertain, middle-ground, and conditional responses. We also present BERT-based neural models to predict such categories for a question-answer pair. We find that while transfer learning from entailment works reasonably, performance is not yet sufficient for robust dialog. Our models reach 82-88% accuracy for a 4-class distinction, and 74-85% for 6 classes.","我々は対話における実用的な推論の問題を再考する：質問に対する間接的な応答を理解する。人間は、「はい」や「いいえ」のような直接的な合言葉がなくても、「お腹がすいた」という答えに対して「お腹がすいた」と解釈することができる。対話システムにおいても、閉じたボキャブラリーではなく、自然な応答を可能にすることは、同様に有益である。しかし、今日のシステムは、言語モデルが許す限り、このような言葉遣いの動きに敏感でなければなりません。我々は、このタスクの進歩を可能にするために、34,268個のペア（極性の質問、間接的な回答）を持つ初の大規模な英語コーパス「Circa」を作成し、公開した。このデータは、精巧なクラウドソーシングによって収集されたものであり、yesnoの意味を持つ発話、不確実性のある発話、中間的な発話、条件付きの発話が含まれている。また、質問と回答のペアについて、このようなカテゴリを予測するためのBERTベースのニューラルモデルを提示する。エンテールメントからの伝達学習は合理的に機能するが、ロバストな対話にはまだ十分な性能ではないことがわかった。我々のモデルは、4クラスの区別では82-88％、6クラスでは74-85％の精度に達する。",https://d3i71xaburhd42.cloudfront.net/10cf0a1e04ed57f8fec1d2327a4ad67c9c539729/1-Table1-1.png
"If beam search is the answer, what was the question?","['Clara Meister', 'Ryan Cotterell', 'Tim Vieira']",http://arxiv.org/abs/2010.02650v1,"Quite surprisingly, exact maximum a posteriori (MAP) decoding of neural language generators frequently leads to low-quality results. Rather, most state-of-the-art results on language generation tasks are attained using beam search despite its overwhelmingly high search error rate. This implies that the MAP objective alone does not express the properties we desire in text, which merits the question: if beam search is the answer, what was the question? We frame beam search as the exact solution to a different decoding objective in order to gain insights into why high probability under a model alone may not indicate adequacy. We find that beam search enforces uniform information density in text, a property motivated by cognitive science. We suggest a set of decoding objectives that explicitly enforce this property and find that exact decoding with these objectives alleviates the problems encountered when decoding poorly calibrated language generation models. Additionally, we analyze the text produced using various decoding strategies and see that, in our neural machine translation experiments, the extent to which this property is adhered to strongly correlates with BLEU.",驚くべきことに、ニューラル言語生成器の正確な最大事後検証（MAP）復号化は、しばしば低品質の結果をもたらします。むしろ、言語生成タスクのほとんどの最先端の結果は、圧倒的に高い検索エラー率にもかかわらず、ビームサーチを用いて達成されています。このことは、MAPの目的だけでは、我々が望む特性をテキストで表現できないことを示唆しています。我々は、モデルの下での高い確率が妥当性を示さない理由を理解するために、ビームサーチを別の復号化目的の厳密な解としてフレーム化した。その結果、ビームサーチはテキストの情報密度を均一にすることができ、これは認知科学に基づく特性である。本研究では、この特性を明示的に強制するデコーディング目標を提案し、これらの目標を用いて正確なデコーディングを行うことで、校正されていない言語生成モデルをデコーディングする際に発生する問題を軽減できることを見いだした。さらに、様々なデコーディング戦略を用いて生成されたテキストを分析し、我々のニューラル機械翻訳実験では、この特性がどの程度守られているかがBLEUと強く相関していることがわかる。,https://d3i71xaburhd42.cloudfront.net/05cfd96eed27ceb2aa35285991a745a5cd119abc/1-Figure1-1.png
IGSQL: Database Schema Interaction Graph Based Neural Model for Context-Dependent Text-to-SQL Generation,"['Yitao Cai', 'Xiaojun Wan']",,,なし,
IGT2P: From Interlinear Glossed Texts to Paradigms,"['Sarah Moeller', 'Ling Liu', 'Changbing Yang', 'Katharina Kann', 'Mans Hulden']",,,なし,
IIRC: A Dataset of Incomplete Information Reading Comprehension Questions,"['James Ferguson', 'Matt Gardner', 'Hannaneh Hajishirzi', 'Tushar Khot', 'Pradeep Dasigi']",,,なし,
Imitation Attacks and Defenses for Black-box Machine Translation Systems,"['Eric Wallace', 'Mitchell Stern', 'Dawn Song']",http://arxiv.org/abs/2004.15015v2,"Adversaries may look to steal or attack black-box NLP systems, either for financial gain or to exploit model errors. One setting of particular interest is machine translation (MT), where models have high commercial value and errors can be costly. We investigate possible exploitations of black-box MT systems and explore a preliminary defense against such threats. We first show that MT systems can be stolen by querying them with monolingual sentences and training models to imitate their outputs. Using simulated experiments, we demonstrate that MT model stealing is possible even when imitation models have different input data or architectures than their target models. Applying these ideas, we train imitation models that reach within 0.6 BLEU of three production MT systems on both high-resource and low-resource language pairs. We then leverage the similarity of our imitation models to transfer adversarial examples to the production systems. We use gradient-based attacks that expose inputs which lead to semantically-incorrect translations, dropped content, and vulgar model outputs. To mitigate these vulnerabilities, we propose a defense that modifies translation outputs in order to misdirect the optimization of imitation models. This defense degrades the adversary's BLEU score and attack success rate at some cost in the defender's BLEU and inference speed.",敵対者は、ブラックボックスNLPシステムを盗み見たり攻撃したりして、金銭的な利益を得たり、モデルのエラーを悪用しようとする可能性があります。特に注目されているのは機械翻訳(MT)で、モデルには高い商業的価値があり、エラーにはコストがかかることがあります。我々は、ブラックボックスMTシステムの悪用の可能性を調査し、そのような脅威に対する予備的な防御策を探る。我々はまず、MTシステムを単言語の文で照会し、その出力を模倣するためにモデルを訓練することで、MTシステムが盗まれる可能性があることを示す。模擬実験を用いて、模倣モデルがターゲットモデルと異なる入力データやアーキテクチャを持っている場合でもMTモデルの盗用が可能であることを示す。これらのアイデアを応用して、高リソース言語ペアと低リソース言語ペアの両方で、3つの生産MTシステムの0.6BLEU以内に到達する模倣モデルを訓練する。次に、我々の模倣モデルの類似性を利用して、本番システムに敵対的な例を転送する。勾配ベースの攻撃を用いて、意味的に不正確な翻訳、コンテンツの削除、低俗なモデルの出力につながる入力を公開しています。これらの脆弱性を緩和するために、我々は模倣モデルの最適化を誤らせるために翻訳出力を修正する防御策を提案する。この防御策は、防御側のBLEUスコアと推論速度をある程度犠牲にして、敵のBLEUスコアと攻撃成功率を低下させる。,https://d3i71xaburhd42.cloudfront.net/d73561ab8318ce343f5cb15f96c74f210b6b24fa/2-Figure1-1.png
Improving AMR parsing with Sequence-to-Sequence Pre-training,"['Dongqin Xu', 'Junhui Li', 'Muhua Zhu', 'Min Zhang', 'Guodong Zhou']",http://arxiv.org/abs/2010.01771v1,"In the literature, the research on abstract meaning representation (AMR) parsing is much restricted by the size of human-curated dataset which is critical to build an AMR parser with good performance. To alleviate such data size restriction, pre-trained models have been drawing more and more attention in AMR parsing. However, previous pre-trained models, like BERT, are implemented for general purpose which may not work as expected for the specific task of AMR parsing. In this paper, we focus on sequence-to-sequence (seq2seq) AMR parsing and propose a seq2seq pre-training approach to build pre-trained models in both single and joint way on three relevant tasks, i.e., machine translation, syntactic parsing, and AMR parsing itself. Moreover, we extend the vanilla fine-tuning method to a multi-task learning fine-tuning method that optimizes for the performance of AMR parsing while endeavors to preserve the response of pre-trained models. Extensive experimental results on two English benchmark datasets show that both the single and joint pre-trained models significantly improve the performance (e.g., from 71.5 to 80.2 on AMR 2.0), which reaches the state of the art. The result is very encouraging since we achieve this with seq2seq models rather than complex models. We make our code and model available at https://github.com/xdqkid/S2S-AMR-Parser.",文献では、抽象的意味表現（AMR）構文解析の研究は、優れた性能を持つAMRパーサーを構築するために重要な人間が作成したデータセットのサイズに大きく制限されています。このようなデータサイズの制約を緩和するために、AMR解析では事前学習モデルがますます注目されています。しかし、BERTのような従来の事前学習モデルは汎用的な目的で実装されているため、AMRパーシングの特定のタスクに対して期待通りに動作しない可能性があります。この論文では、sequence-to-sequence (seq2seq) AMR解析に焦点を当て、3つの関連タスク、すなわち機械翻訳、構文解析、AMR解析自体について、単一および共同の方法で事前学習モデルを構築するseq2seq事前学習アプローチを提案します。さらに、バニラ微調整法をマルチタスク学習微調整法に拡張し、AMR解析の性能を最適化しながら、事前学習モデルの応答を維持するように努力している。2つの英語ベンチマークデータセットを用いた広範な実験結果によると、事前学習モデルを単独でも共同でも、AMR 2.0では71.5から80.2へと大幅に性能が向上し、最先端の性能に到達していることが示された。複雑なモデルではなく、seq2seqモデルでこれを達成しているので、この結果は非常に心強いものです。我々のコードとモデルはhttps:/github.comxdqkidS2S-AMR-Parserで公開しています。,https://d3i71xaburhd42.cloudfront.net/12b28c2d1b58234daa0f06ab43353c401eda1958/1-Figure1-1.png
Improving Detection and Categorization of Task-relevant Utterances through Integration of Discourse Structure and Ontological Knowledge,"['Sopan Khosla', 'Shikhar Vashishth', 'Jill Fain Lehman', 'Carolyn Rose']",,,なし,
Improving Grammatical Error Correction Models with Purpose-Built Adversarial Examples,"['Lihao Wang', 'Xiaoqing Zheng']",,,なし,
Improving Neural Topic Models using Knowledge Distillation,"['Alexander Miserlis Hoyle', 'Pranav Goel', 'Philip Resnik']",,,なし,
Improving Out-of-Scope Detection in Intent Classification by Using Embeddings of the Word Graph Space of the Classes,"['Paulo Cavalin', 'Victor Henrique Alves Ribeiro', 'Ana Appel', 'Claudio Pinhanez']",,,なし,
Improving Text Generation with Student-Forcing Optimal Transport,"['Jianqiao Li', 'Chunyuan Li', 'Guoyin Wang', 'Hao Fu', 'Yuhchen Lin', 'Liqun Chen', 'Yizhe Zhang', 'Chenyang Tao', 'Ruiyi Zhang', 'Wenlin Wang', 'Dinghan Shen', 'Qian Yang', 'Lawrence Carin']",,,なし,
Improving Word Sense Disambiguation with Translations,"['Yixing Luan', 'Bradley Hauer', 'Lili Mou', 'Grzegorz Kondrak']",,,なし,
Incomplete Utterance Rewriting as Semantic Segmentation,"['Qian Liu', 'Bei Chen', 'Jian-Guang LOU', 'Bin Zhou', 'Dongmei Zhang']",http://arxiv.org/abs/2009.13166v1,"Recent years the task of incomplete utterance rewriting has raised a large attention. Previous works usually shape it as a machine translation task and employ sequence to sequence based architecture with copy mechanism. In this paper, we present a novel and extensive approach, which formulates it as a semantic segmentation task. Instead of generating from scratch, such a formulation introduces edit operations and shapes the problem as prediction of a word-level edit matrix. Benefiting from being able to capture both local and global information, our approach achieves state-of-the-art performance on several public datasets. Furthermore, our approach is four times faster than the standard approach in inference.",近年、不完全音声の書き換え作業が大きな注目を集めている。これまでの研究では、通常、機械翻訳タスクとして形作られ、コピー機構を用いたシーケンス・ツー・シーケンス・ベースのアーキテクチャが採用されてきた。本論文では、このタスクを意味的セグメンテーションタスクとして定式化した、新規かつ広範なアプローチを提案する。このような定式化は、ゼロから生成するのではなく、編集操作を導入し、単語レベルの編集行列の予測として問題を形成する。ローカル情報とグローバル情報の両方を取り込むことができるという利点から、我々のアプローチは、いくつかの公開データセットで最先端の性能を達成している。さらに、我々のアプローチは、推論において標準的なアプローチの4倍の速さを実現している。,https://d3i71xaburhd42.cloudfront.net/4ebe5792fe2890590e7a5bf8ae0a29e0fb147ef9/1-Table1-1.png
Incorporating Multimodal Information in Open-Domain Web Keyphrase Extraction,"['Yansen Wang', 'Zhen Fan', 'Carolyn Rose']",,,なし,
Incremental Event Detection via Knowledge Consolidation Networks,"['Pengfei Cao', 'Yubo Chen', 'Jun Zhao', 'Taifeng Wang']",,,なし,
Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental NLU,"['Brielen Madureira', 'David Schlangen']",http://arxiv.org/abs/2010.05330v1,"While humans process language incrementally, the best language encoders currently used in NLP do not. Both bidirectional LSTMs and Transformers assume that the sequence that is to be encoded is available in full, to be processed either forwards and backwards (BiLSTMs) or as a whole (Transformers). We investigate how they behave under incremental interfaces, when partial output must be provided based on partial input seen up to a certain time step, which may happen in interactive systems. We test five models on various NLU datasets and compare their performance using three incremental evaluation metrics. The results support the possibility of using bidirectional encoders in incremental mode while retaining most of their non-incremental quality. The ""omni-directional"" BERT model, which achieves better non-incremental performance, is impacted more by the incremental access. This can be alleviated by adapting the training regime (truncated training), or the testing procedure, by delaying the output until some right context is available or by incorporating hypothetical right contexts generated by a language model like GPT-2.",人間は言語をインクリメンタルに処理しますが、現在NLPで使用されている最高の言語エンコーダーはそうではありません。双方向LSTMもトランスフォーマーも、符号化されるべきシーケンスが完全に利用可能であることを前提としており、前方と後方のどちらか（BiLSTM）、または全体（トランスフォーマー）として処理される。本研究では、ある時間ステップまでの部分入力に基づいて部分出力を提供しなければならないようなインクリメンタルなインタフェースの下で、トランスフォーマがどのように振る舞うかを調査する。5つのモデルを様々なNLUデータセットでテストし、3つのインクリメンタル評価指標を用いて性能を比較した。その結果、インクリメンタルではない品質のほとんどを維持しつつ、インクリメンタルモードで双方向性エンコーダを使用する可能性を支持することができた。より優れた非インクリメンタル性能を達成する「全方向性」BERT モデルは、インクリメンタルアクセスの影響をより大きく受ける。これは、訓練レジーム（truncated training）またはテスト手順を適応させること、正しい文脈が利用可能になるまで出力を遅らせること、または GPT-2 のような言語モデルによって生成された仮説的な正しい文脈を組み込むことによって、緩和することができる。,https://d3i71xaburhd42.cloudfront.net/cd91aaebc915cef22c68786657863404ce8abc17/2-Figure1-1.png
Inducing Target-specific Latent Structures for Aspect Sentiment Classification,"['Chenhua Chen', 'Zhiyang Teng', 'Yue Zhang']",,,なし,
Information Seeking in the Spirit of Learning: a Dataset for Conversational Curiosity,"['Pedro Rodriguez', 'Paul Crook', 'Seungwhan Moon', 'Zhiguang Wang']",http://arxiv.org/abs/2005.00172v1,"Open-ended human learning and information-seeking are increasingly mediated by technologies like digital assistants. However, such systems often fail to account for the user's pre-existing knowledge, which is a powerful way to increase engagement and to improve retention. Assuming a correlation between engagement and user responses such as ""liking"" messages or asking followup questions, we design a Wizard of Oz dialog task that tests the hypothesis that engagement increases when users are presented with facts that relate to their existing knowledge. Through crowd-sourcing of this experimental task we collected and now open-source 14K dialogs (181K utterances) where users and assistants converse about various aspects related to geographic entities. This dataset is annotated with pre-existing user knowledge, message-level dialog acts, message grounding to Wikipedia, user reactions to messages, and per-dialog ratings. Our analysis shows that responses which incorporate a user's prior knowledge do increase engagement. We incorporate this knowledge into a state-of-the-art multi-task model that reproduces human assistant policies, improving over content selection baselines by 13 points.",オープンエンド型の人間の学習や情報検索は、デジタルアシスタントのようなテクノロジーを利用して行われるようになってきています。しかし、このようなシステムでは、ユーザーの既存の知識を考慮に入れていないことが多く、エンゲージメントを高め、リテンションを向上させるための強力な方法となっています。エンゲージメントとメッセージの「いいね！」やフォローアップの質問などのユーザーの反応との間に相関関係があると仮定して、ユーザーが既存の知識に関連する事実を提示されるとエンゲージメントが高まるという仮説を検証するオズの魔法使いの対話タスクを設計した。この実験タスクのクラウドソーシングを通じて、ユーザーとアシスタントが地理的実体に関連する様々な側面について会話する14Kのダイアログ（181Kの発話）を収集し、現在オープンソース化している。このデータセットには、既存のユーザの知識、メッセージレベルの対話行為、ウィキペディアへのメッセージの根拠、メッセージに対するユーザの反応、および対話ごとの評価がアノテーションされている。我々の分析によると、ユーザーの事前知識を組み込んだ応答がエンゲージメントを高めることが示された。この知識を人間のアシスタントポリシーを再現する最新のマルチタスクモデルに組み込み、コンテンツ選択のベースラインよりも13ポイント向上させた。,https://d3i71xaburhd42.cloudfront.net/20b587bde85a204702c13180a24a8cdb7a42a057/2-Figure1-1.png
Information-Theoretic Probing with Minimum Description Length,"['Elena Voita', 'Ivan Titov']",http://arxiv.org/abs/2003.12298v1,"To measure how well pretrained representations encode some linguistic property, it is common to use accuracy of a probe, i.e. a classifier trained to predict the property from the representations. Despite widespread adoption of probes, differences in their accuracy fail to adequately reflect differences in representations. For example, they do not substantially favour pretrained representations over randomly initialized ones. Analogously, their accuracy can be similar when probing for genuine linguistic labels and probing for random synthetic tasks. To see reasonable differences in accuracy with respect to these random baselines, previous work had to constrain either the amount of probe training data or its model size. Instead, we propose an alternative to the standard probes, information-theoretic probing with minimum description length (MDL). With MDL probing, training a probe to predict labels is recast as teaching it to effectively transmit the data. Therefore, the measure of interest changes from probe accuracy to the description length of labels given representations. In addition to probe quality, the description length evaluates ""the amount of effort"" needed to achieve the quality. This amount of effort characterizes either (i) size of a probing model, or (ii) the amount of data needed to achieve the high quality. We consider two methods for estimating MDL which can be easily implemented on top of the standard probing pipelines: variational coding and online coding. We show that these methods agree in results and are more informative and stable than the standard probes.",事前に訓練された表現がどの程度言語的特性を符号化しているかを測定するには、プローブの精度、つまり表現から特性を予測するように訓練された分類器を使用するのが一般的です。プローブが広く普及しているにもかかわらず、プローブの精度の違いは、表現の違いを十分に反映していません。例えば、プローブは、ランダムに初期化されたものよりも事前に訓練された表現を実質的には好まない。同様に、真正な言語ラベルをプローブする場合と、ランダムな合成タスクをプローブする場合でも、精度は同じようになります。これらのランダムなベースラインに関して精度に妥当な違いを見出すためには、これまでの研究では、プローブの訓練データの量やモデルサイズを制限する必要がありました。その代わりに、我々は標準的なプローブに代わる、最小記述長(MDL)を用いた情報理論的なプローブを提案する。MDLプロービングでは、ラベルを予測するためにプローブを訓練することは、データを効果的に送信するためにプローブを教えることと同じことになります。したがって、注目すべき指標は、プローブの精度から、与えられた表現のラベルの記述長に変化します。記述長は、プローブの品質に加えて、品質を達成するために必要な「努力の量」を評価します。この努力量は、(i)プロービングモデルの大きさ、または(ii)高品質を達成するために必要なデータ量のいずれかを特徴づける。我々は、標準的なプロービングパイプラインの上に簡単に実装できるMDL推定のための2つの方法、すなわち、変分符号化とオンライン符号化を検討した。これらの方法は結果的に一致しており、標準的なプローブよりも情報量が多く安定していることを示す。,https://d3i71xaburhd42.cloudfront.net/f4b585c9a79dfce0807b445a09036ea0f9cbcdce/1-Figure1-1.png
"Infusing Disease Knowledge into BERT for Health Question Answering, Medical Inference and Disease Name Recognition","['Yun He', 'Ziwei Zhu', 'Yin Zhang', 'Qin Chen', 'James Caverlee']",http://arxiv.org/abs/2010.03746v1,"Knowledge of a disease includes information of various aspects of the disease, such as signs and symptoms, diagnosis and treatment. This disease knowledge is critical for many health-related and biomedical tasks, including consumer health question answering, medical language inference and disease name recognition. While pre-trained language models like BERT have shown success in capturing syntactic, semantic, and world knowledge from text, we find they can be further complemented by specific information like knowledge of symptoms, diagnoses, treatments, and other disease aspects. Hence, we integrate BERT with disease knowledge for improving these important tasks. Specifically, we propose a new disease knowledge infusion training procedure and evaluate it on a suite of BERT models including BERT, BioBERT, SciBERT, ClinicalBERT, BlueBERT, and ALBERT. Experiments over the three tasks show that these models can be enhanced in nearly all cases, demonstrating the viability of disease knowledge infusion. For example, accuracy of BioBERT on consumer health question answering is improved from 68.29% to 72.09%, while new SOTA results are observed in two datasets. We make our data and code freely available.",疾患の知識には、兆候や症状、診断、治療など、疾患の様々な側面に関する情報が含まれます。この疾患知識は、消費者の健康に関する質問への回答、医療言語推論、病名認識など、多くの健康関連および生物医学的作業に不可欠である。BERTのような事前訓練された言語モデルは、テキストから構文的、意味的、世界的知識を取り込むことに成功しているが、症状、診断、治療、および他の疾患の側面に関する知識のような特定の情報によってさらに補完されることがわかっている。そこで、これらの重要な作業を改善するために、BERTと疾患知識を統合する。具体的には、新しい疾患知識注入訓練法を提案し、BERT、BioBERT、SciBERT、ClinicalBERT、BlueBERT、ALBERTを含む一連のBERTモデルで評価する。3つのタスクにわたる実験では、これらのモデルがほぼすべてのケースで強化できることが示され、疾患知識注入の実行可能性が実証された。例えば、消費者の健康に関する質問に対するBioBERTの精度は68.29%から72.09%に改善され、2つのデータセットで新しいSOTAの結果が観察されています。我々は、データとコードを自由に利用できるようにしている。,https://d3i71xaburhd42.cloudfront.net/3b2664a15b46e95eecb9573f21c36892037b0264/1-Table1-1.png
Inquisitive Question Generation for High Level Text Comprehension,"['Wei-Jen Ko', 'TE-YUAN CHEN', 'Yiyan Huang', 'Greg Durrett', 'Junyi Jessy Li']",http://arxiv.org/abs/2010.01657v1,"Inquisitive probing questions come naturally to humans in a variety of settings, but is a challenging task for automatic systems. One natural type of question to ask tries to fill a gap in knowledge during text comprehension, like reading a news article: we might ask about background information, deeper reasons behind things occurring, or more. Despite recent progress with data-driven approaches, generating such questions is beyond the range of models trained on existing datasets. We introduce INQUISITIVE, a dataset of ~19K questions that are elicited while a person is reading through a document. Compared to existing datasets, INQUISITIVE questions target more towards high-level (semantic and discourse) comprehension of text. We show that readers engage in a series of pragmatic strategies to seek information. Finally, we evaluate question generation models based on GPT-2 and show that our model is able to generate reasonable questions although the task is challenging, and highlight the importance of context to generate INQUISITIVE questions.",探究的な質問は、様々な環境で人間には自然に備わっていますが、自動システムにとっては難しいタスクです。ニュース記事を読むように、テキストを理解する際に知識のギャップを埋めようとする質問の自然なタイプの1つがあります。最近のデータ駆動型のアプローチの進歩にもかかわらず、このような質問を生成することは、既存のデータセットで訓練されたモデルの範囲を超えています。我々はINQUISITIVEを紹介する。INQUISITIVEは、人が文書を読んでいる間に誘発される約19Kの質問からなるデータセットである。既存のデータセットと比較して、INQUISITIVEの質問は、テキストの高レベル（意味的・談話的）理解をより対象としている。読者が情報を求めるために、一連の実用的な戦略に従事していることを示す。最後に、GPT-2に基づいた質問生成モデルを評価し、我々のモデルが困難な課題であるにもかかわらず、妥当な質問を生成できることを示し、INQUISITIVE質問を生成するための文脈の重要性を強調する。,https://d3i71xaburhd42.cloudfront.net/8ad5b00825bb9fd39cf99700afe9e267e74fbbf3/1-Figure1-1.png
INSPIRED: Toward Sociable Recommendation Dialog Systems,"['Shirley Anugrah Hayati', 'Dongyeop Kang', 'Qingxiaoyang Zhu', 'Weiyan Shi', 'Zhou Yu']",http://arxiv.org/abs/2009.14306v2,"In recommendation dialogs, humans commonly disclose their preference and make recommendations in a friendly manner. However, this is a challenge when developing a sociable recommendation dialog system, due to the lack of dialog dataset annotated with such sociable strategies. Therefore, we present INSPIRED, a new dataset of 1,001 human-human dialogs for movie recommendation with measures for successful recommendations. To better understand how humans make recommendations in communication, we design an annotation scheme related to recommendation strategies based on social science theories and annotate these dialogs. Our analysis shows that sociable recommendation strategies, such as sharing personal opinions or communicating with encouragement, more frequently lead to successful recommendations. Based on our dataset, we train end-to-end recommendation dialog systems with and without our strategy labels. In both automatic and human evaluation, our model with strategy incorporation outperforms the baseline model. This work is a first step for building sociable recommendation dialog systems with a basis of social science theories.","勧告ダイアログでは、人間は自分の好みを開示し、友好的な方法で勧告を行うのが一般的である。しかし、このような社交的なレコメンデーション対話システムを開発する際には、そのような社交的な戦略をアノテーションした対話データセットが不足しているため、これが課題となっている。そこで、我々は、映画推薦のための1,001件の人間と人間の対話からなる新しいデータセットであるINSPIREDを発表した。本研究では、人間がコミュニケーションの中でどのように推薦を行うかを理解するために、社会科学の理論に基づいて推薦戦略に関連したアノテーションスキームを設計し、これらの対話をアノテーションする。その結果、個人的な意見の共有や励ましのコミュニケーションなど、社交的な推薦戦略の方が、より頻繁に推薦を成功させることがわかった。我々のデータセットに基づいて、我々は、我々の戦略ラベルの有無にかかわらず、エンドツーエンドの推薦ダイアログシステムを訓練した。自動評価と人間による評価の両方において、戦略を組み込んだモデルがベースラインモデルを上回る結果を得た。本研究は、社会科学の理論に基づいた社会的な推薦対話システムを構築するための第一歩である。",https://d3i71xaburhd42.cloudfront.net/943f1c9cae41d7635a40dc9d836edd94418e26c8/1-Figure1-1.png
Interactive Fiction Game Playing as Multi-Paragraph Reading Comprehension with Reinforcement Learning,"['Xiaoxiao Guo', 'Mo Yu', 'Yupeng Gao', 'Chuang Gan', 'Murray Campbell', 'Shiyu Chang']",http://arxiv.org/abs/2010.02386v1,"Interactive Fiction (IF) games with real human-written natural language texts provide a new natural evaluation for language understanding techniques. In contrast to previous text games with mostly synthetic texts, IF games pose language understanding challenges on the human-written textual descriptions of diverse and sophisticated game worlds and language generation challenges on the action command generation from less restricted combinatorial space. We take a novel perspective of IF game solving and re-formulate it as Multi-Passage Reading Comprehension (MPRC) tasks. Our approaches utilize the context-query attention mechanisms and the structured prediction in MPRC to efficiently generate and evaluate action outputs and apply an object-centric historical observation retrieval strategy to mitigate the partial observability of the textual observations. Extensive experiments on the recent IF benchmark (Jericho) demonstrate clear advantages of our approaches achieving high winning rates and low data requirements compared to all previous approaches. Our source code is available at: https://github.com/XiaoxiaoGuo/rcdqn.",実在の人間が書いた自然言語のテキストを用いたインタラクティブ・フィクション(IF)ゲームは、言語理解技術の新たな自然評価を提供するものである。従来の合成テキストを用いたテキストゲームとは対照的に、IFゲームは、多様で洗練されたゲーム世界の人間が書いたテキストの記述に言語理解の課題を、また、制限の少ない組み合わせ空間からのアクションコマンドの生成に言語生成の課題を課している。本研究では、IFゲームの解法を新たな視点から捉え、それをMPRC課題として再定義する。我々のアプローチは、MPRCにおける文脈問い合わせ注意メカニズムと構造化予測を利用して効率的にアクション出力を生成・評価し、テキスト観測の部分的な観測可能性を緩和するためにオブジェクト中心の履歴観測検索戦略を適用する。最近のIFベンチマーク(Jericho)での広範な実験により、我々のアプローチがこれまでのアプローチと比較して高い勝率と低いデータ要件を達成していることが明らかになった。我々のソースコードは以下から入手可能です：https:/github.comXiaoxiaoGuorcdqn.,https://d3i71xaburhd42.cloudfront.net/061d113a7b3f32deab6bc50fea676fa0b1e0f658/1-Figure1-1.png
Interactive Refinement of Cross-Lingual Word Embeddings,"['Michelle Yuan', 'Mozhi Zhang', 'Benjamin Van Durme', 'Leah Findlater', 'Jordan Boyd-Graber']",http://arxiv.org/abs/1911.03070v3,"Cross-lingual word embeddings transfer knowledge between languages: models trained on high-resource languages can predict in low-resource languages. We introduce CLIME, an interactive system to quickly refine cross-lingual word embeddings for a given classification problem. First, CLIME ranks words by their salience to the downstream task. Then, users mark similarity between keywords and their nearest neighbors in the embedding space. Finally, CLIME updates the embeddings using the annotations. We evaluate CLIME on identifying health-related text in four low-resource languages: Ilocano, Sinhalese, Tigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word semantics and have higher test accuracy than the original embeddings. CLIME often improves accuracy faster than an active learning baseline and can be easily combined with active learning to improve results.",言語間の知識の伝達：高リソースの言語で学習されたモデルは低リソースの言語で予測することができる。我々は、与えられた分類問題に対して、言語間の単語エンベッディングを迅速に洗練させるための対話型システムCLIMEを紹介する。まず、CLIMEは、下流のタスクに対する重要度によって単語をランク付けする。次に、ユーザーは埋め込み空間内のキーワードと最も近い隣人との間の類似性をマークします。最後に、CLIMEはアノテーションを用いてエンベッディングを更新する。4つの低リソース言語における健康関連テキストの識別についてCLIMEを評価した。イロカノ語、シンハラ語、チグリニャ語、ウイグル語である。CLIMEによって洗練されたエンベッディングは、元のエンベッディングに比べて、よりニュアンスのある単語の意味を捉え、より高いテスト精度を持つことがわかった。CLIMEは、多くの場合、アクティブ学習のベースラインよりも速く精度を向上させ、結果を向上させるためにアクティブ学習と簡単に組み合わせることができます。,https://d3i71xaburhd42.cloudfront.net/acaf372f91b60958c5c915005a6cb28cbc4f9b5f/1-Figure1-1.png
Interpretable Multi-dataset Evaluation for Named Entity Recognition,"['Jinlan Fu', 'Pengfei Liu', 'Graham Neubig']",,,なし,
Interpretation of NLP models through input marginalization,"['Siwon Kim', 'Jihun Yi', 'Eunji Kim', 'Sungroh Yoon']",,,なし,
Interpreting Open-Domain Modifiers: Decomposition of Wikipedia Categories into Disambiguated Property-Value Pairs,['Marius Pasca'],,,なし,
Interview: Large-scale Modeling of Media Dialog with Discourse Patterns and Knowledge Grounding,"['Bodhisattwa Prasad Majumder', 'Shuyang Li', 'Jianmo Ni', 'Julian McAuley']",,,なし,
Intrinsic Evaluation of Summarization Datasets,"['Rishi Bommasani', 'Claire Cardie']",,,なし,
Intrinsic Probing through Dimension Selection,"['Lucas Torroba Hennigen', 'Adina Williams', 'Ryan Cotterell']",http://arxiv.org/abs/2010.02812v1,"Most modern NLP systems make use of pre-trained contextual representations that attain astonishingly high performance on a variety of tasks. Such high performance should not be possible unless some form of linguistic structure inheres in these representations, and a wealth of research has sprung up on probing for it. In this paper, we draw a distinction between intrinsic probing, which examines how linguistic information is structured within a representation, and the extrinsic probing popular in prior work, which only argues for the presence of such information by showing that it can be successfully extracted. To enable intrinsic probing, we propose a novel framework based on a decomposable multivariate Gaussian probe that allows us to determine whether the linguistic information in word embeddings is dispersed or focal. We then probe fastText and BERT for various morphosyntactic attributes across 36 languages. We find that most attributes are reliably encoded by only a few neurons, with fastText concentrating its linguistic structure more than BERT.",最近のNLPシステムのほとんどは、事前に訓練された文脈表現を使用しており、様々なタスクで驚くほどの高いパフォーマンスを発揮します。このような高いパフォーマンスは、これらの表現に何らかの形で言語構造が内在していなければ実現できないはずであり、それを探るための研究が盛んに行われてきた。この論文では、表現の中に言語情報がどのように構造化されているかを調べる内在的プロービングと、先行研究でよく見られる外在的プロービングとを区別する。本質的プロービングを可能にするために、我々は、分解可能な多変量ガウスプローブに基づく新しいフレームワークを提案する。次に、36の言語の様々な形態統語属性について、fastTextとBERTをプローブする。その結果、ほとんどの属性はわずか数個のニューロンによって確実に符号化されており、fastTextはBERTよりも言語構造を集中させていることがわかった。,https://d3i71xaburhd42.cloudfront.net/3c4d3b7085ad5f02bc732b489ace590a7bbd58c9/1-Figure1-1.png
Introducing Syntactic Structures into Target Opinion Word Extraction with Deep Learning,"['Amir Pouran Ben Veyseh', 'Nasim Nouri', 'Franck Dernoncourt', 'Dejing Dou', 'Thien Huu Nguyen']",,,なし,
Investigating Cross-Linguistic Adjective Ordering Tendencies with a Latent-Variable Model,"['Jun Yen Leung', 'Guy Emerson', 'Ryan Cotterell']",http://arxiv.org/abs/2010.04755v1,"Across languages, multiple consecutive adjectives modifying a noun (e.g. ""the big red dog"") follow certain unmarked ordering rules. While explanatory accounts have been put forward, much of the work done in this area has relied primarily on the intuitive judgment of native speakers, rather than on corpus data. We present the first purely corpus-driven model of multi-lingual adjective ordering in the form of a latent-variable model that can accurately order adjectives across 24 different languages, even when the training and testing languages are different. We utilize this novel statistical model to provide strong converging evidence for the existence of universal, cross-linguistic, hierarchical adjective ordering tendencies.","言語間では、名詞を修飾する複数の連続した形容詞（例：""the big red dog""）は、特定の無印の順序規則に従う。これまでにも説明的な説明がなされてきたが、この分野での研究の多くは、コーパスデータではなく、主にネイティブスピーカーの直感的な判断に頼ってきた。本研究では、学習言語とテスト言語が異なっていても、24の異なる言語間で正確に形容詞を並べ替えることができる遅延変数モデルを用いた、純粋にコーパス駆動型の多言語形容詞順序付けの初のモデルを提示する。この新しい統計モデルを利用して、普遍的な、言語を超えた、階層的な形容詞の順序付けの傾向が存在することを示す強力な収束証拠を提供する。",https://d3i71xaburhd42.cloudfront.net/660dd796e703931c009e2518404abca5918862ed/4-Table1-1.png
Investigating Lexical Variability in Language Models,"['Charles Yu', 'Ryan Sie', 'Nicolas Tedeschi', 'Leon Bergen']",,,なし,
Is Chinese Word Segmentation a Solved Task? Rethinking Neural Chinese Word Segmentation,"['Jinlan Fu', 'Pengfei Liu', 'Qi Zhang', 'Xuanjing Huang']",,,なし,
Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected Reasoning,"['Harsh Trivedi', 'Niranjan Balasubramanian', 'Tushar Khot', 'Ashish Sabharwal']",http://arxiv.org/abs/2005.00789v2,"Has there been real progress in multi-hop question-answering? Models often exploit dataset artifacts to produce correct answers, without connecting information across multiple supporting facts. This limits our ability to measure true progress and defeats the purpose of building multihop QA datasets. We make three contributions towards addressing this. First, we formalize such undesirable behavior as disconnected reasoning across subsets of supporting facts. This allows developing a model-agnostic probe for measuring how much any model can cheat via disconnected reasoning. Second, using a notion of contrastive support sufficiency, we introduce an automatic transformation of existing datasets that reduces the amount of disconnected reasoning. Third, our experiments demonstrate that there hasn't been much progress in multifact reasoning. For a recent large-scale model (XLNet), we show that only 18% of its answer score is obtained through multifact reasoning, roughly the same as that of a simpler RNN baseline. Our transformation shows a substantial reduction in disconnected reasoning (nearly 19 points in answer F1). It is complementary to adversarial approaches, yielding further reductions in conjunction.",マルチホップの質問回答には本当に進歩があったのでしょうか？モデルはしばしばデータセットのアーティファクトを利用して正解を導き出しますが、複数の裏付けとなる事実にまたがって情報を結びつけることはできません。これでは、真の進歩を測定する能力が制限され、マルチホップQAデータセットを構築する目的が失われてしまいます。我々は、この問題に対処するために3つの貢献をする。第一に、我々はこのような望ましくない動作を、支持事実のサブセット間の切断された推論として形式化する。これにより、どのモデルでも切断された推論を介してどれだけ不正を行うことができるかを測定するためのモデルにとらわれないプローブを開発することができる。第二に、対照的支持充足の概念を用いて、切断された推論の量を減らす既存のデータセットの自動変換を導入する。第三に、我々の実験は、多要素推論があまり進歩していないことを示している。最近の大規模モデル(XLNet)では、その解答スコアの18%しか多因子推論によって得られていないことを示し、これは単純なRNNベースラインとほぼ同じである。我々の変換は、切断された推論の大幅な減少を示す（解答F1では19点近く）。これは、敵対的アプローチを補完するものであり、連携してさらなる削減をもたらす。,
ISAAQ - Mastering Textbook Questions with Pre-trained Transformers and Bottom-Up and Top-Down Attention,"['Jose Manuel Gomez-Perez', 'Raúl Ortega']",,,なし,
Iterative Domain-Repaired Back-Translation,"['Hao-Ran Wei', 'Zhirui Zhang', 'Boxing Chen', 'Weihua Luo']",,,なし,
Iterative Language-Based Image Editing via Self-Supervised Counterfactual Reasoning,"['Tsu-Jui Fu', 'Xin Wang', 'Scott Grafton', 'Miguel Eckstein', 'William Yang Wang']",http://arxiv.org/abs/2009.09566v2,"Iterative Language-Based Image Editing (IL-BIE) tasks follow iterative instructions to edit images step by step. Data scarcity is a significant issue for ILBIE as it is challenging to collect large-scale examples of images before and after instruction-based changes. However, humans still accomplish these editing tasks even when presented with an unfamiliar image-instruction pair. Such ability results from counterfactual thinking and the ability to think about alternatives to events that have happened already. In this paper, we introduce a Self-Supervised Counterfactual Reasoning (SSCR) framework that incorporates counterfactual thinking to overcome data scarcity. SSCR allows the model to consider out-of-distribution instructions paired with previous images. With the help of cross-task consistency (CTC), we train these counterfactual instructions in a self-supervised scenario. Extensive results show that SSCR improves the correctness of ILBIE in terms of both object identity and position, establishing a new state of the art (SOTA) on two IBLIE datasets (i-CLEVR and CoDraw). Even with only 50% of the training data, SSCR achieves a comparable result to using complete data.",反復的言語ベース画像編集（IL-BIE）タスクは、反復的な指示に従って画像を段階的に編集する。IL-BIEでは、指示に基づいた変更前と変更後の画像の大規模な例を収集することが困難であるため、データの不足が大きな課題となっています。しかし、人間は慣れない画像と指示のペアを提示された場合でも、これらの編集作業を達成しています。このような能力は、すでに起こった出来事の代替案を考える反事実思考の能力に由来している。本論文では、データの乏しさを克服するために、反事実思考を組み込んだSelf-Supervised Counterfactual Reasoning (SSR)フレームワークを紹介する。SSCRは、モデルが以前の画像と対になった分布外の指示を考慮することを可能にする。Cross-task consistency (CTC)の助けを借りて、自己監視付きシナリオでこれらのカウンターファクチュアル命令を訓練する。広範な結果は、SSRが物体の同一性と位置の両方の点でILBIEの正しさを改善し、2つのIBLIEデータセット(i-CLEVRとCoDraw)で新しいステートオブザアート(SOTA)を確立することを示している。訓練データの50%のみを用いても、完全データを用いた場合と同等の結果を得ることができた。,https://d3i71xaburhd42.cloudfront.net/9d683580050876a25624511b7c53676292e04e81/1-Figure1-1.png
Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation,"['Jason Lee', 'Raphael Shu', 'Kyunghyun Cho']",http://arxiv.org/abs/2009.07177v1,"We propose an efficient inference procedure for non-autoregressive machine translation that iteratively refines translation purely in the continuous space. Given a continuous latent variable model for machine translation (Shu et al., 2020), we train an inference network to approximate the gradient of the marginal log probability of the target sentence, using only the latent variable as input. This allows us to use gradient-based optimization to find the target sentence at inference time that approximately maximizes its marginal probability. As each refinement step only involves computation in the latent space of low dimensionality (we use 8 in our experiments), we avoid computational overhead incurred by existing non-autoregressive inference procedures that often refine in token space. We compare our approach to a recently proposed EM-like inference procedure (Shu et al., 2020) that optimizes in a hybrid space, consisting of both discrete and continuous variables. We evaluate our approach on WMT'14 En-De, WMT'16 Ro-En and IWSLT'16 De-En, and observe two advantages over the EM-like inference: (1) it is computationally efficient, i.e. each refinement step is twice as fast, and (2) it is more effective, resulting in higher marginal probabilities and BLEU scores with the same number of refinement steps. On WMT'14 En-De, for instance, our approach is able to decode 6.2 times faster than the autoregressive model with minimal degradation to translation quality (0.9 BLEU).","我々は、連続空間内で純粋に翻訳を反復的に精緻化する非自己回帰的機械翻訳のための効率的な推論手順を提案する。機械翻訳のための連続潜在変数モデル(Shu et al., 2020)を与えられた場合、潜在変数のみを入力として用いて、対象文の限界対数確率の勾配を近似するための推論ネットワークを訓練する。これにより、勾配に基づく最適化を用いて、その限界対数確率を近似的に最大化する推論時の対象文を見つけることができる。各精緻化ステップは低次元の潜在空間（実験では8を用いる）でのみ計算を行うため、トークン空間で精緻化を行うことが多い既存の非自己回帰的推論手法で発生する計算オーバーヘッドを回避することができる。我々は、離散変数と連続変数の両方からなるハイブリッド空間で最適化を行う最近提案されたEMのような推論手順(Shu et al., 2020)と我々のアプローチを比較する。WMT'14 En-De, WMT'16 Ro-En, IWSLT'16 De-En上で我々のアプローチを評価し、EM様推論よりも2つの利点を観察する。(1)計算効率が高い、すなわち、各絞り込みステップが2倍速い、(2)より効果的であり、同じ絞り込みステップ数でより高い限界確率とBLEUスコアが得られる、ということである。例えば、WMT'14 En-Deでは、我々のアプローチは、翻訳品質の低下（0.9 BLEU）を最小限に抑えながら、自己回帰モデルの6.2倍の速度で解読することができます。",https://d3i71xaburhd42.cloudfront.net/3aba4051edc0174c37b88ea4ff6f061c4b5fdeb7/5-Table1-1.png
Joint Constrained Learning for Event-Event Relation Extraction,"['Haoyu Wang', 'Muhao Chen', 'Hongming Zhang', 'Dan Roth']",http://arxiv.org/abs/2010.06727v1,"Understanding natural language involves recognizing how multiple event mentions structurally and temporally interact with each other. In this process, one can induce event complexes that organize multi-granular events with temporal order and membership relations interweaving among them. Due to the lack of jointly labeled data for these relational phenomena and the restriction on the structures they articulate, we propose a joint constrained learning framework for modeling event-event relations. Specifically, the framework enforces logical constraints within and across multiple temporal and subevent relations by converting these constraints into differentiable learning objectives. We show that our joint constrained learning approach effectively compensates for the lack of jointly labeled data, and outperforms SOTA methods on benchmarks for both temporal relation extraction and event hierarchy construction, replacing a commonly used but more expensive global inference process. We also present a promising case study showing the effectiveness of our approach in inducing event complexes on an external corpus.",自然言語を理解するには、複数の事象の言及が構造的・時間的にどのように相互作用するかを認識する必要がある。この過程で、時間的秩序とメンバーシップ関係を織り交ぜながら、複数の粒状のイベントを組織化するイベント複合体を誘導することができる。このような関係現象に対しては、共同ラベル化されたデータが不足していることと、それらが表現する構造に制約があることから、イベント-イベント関係をモデル化するための共同制約学習フレームワークを提案する。具体的には、このフレームワークでは、複数の時間的関係とサブイベント関係の間で論理的制約を課し、これらの制約を微分可能な学習目標に変換する。我々の共同制約学習アプローチは、共同ラベル付けされたデータの不足を効果的に補い、時間的関係の抽出とイベント階層の構築の両方において、一般的に使用されているがより高価な大域的推論プロセスに代わって、ベンチマークにおいてSOTA手法を上回る性能を発揮することを示す。また、外部コーパス上でのイベント複合体の誘導において、我々のアプローチが有効であることを示す有望な事例研究を紹介する。,https://d3i71xaburhd42.cloudfront.net/518a0d1669369511c6b2f0687b68d65da3938e12/1-Figure1-1.png
Joint Estimation and Analysis of Risk Behavior Ratings in Movie Scripts,"['Victor Martinez', 'Krishna Somandepalli', 'Yalda Tehranian-Uhls', 'Shrikanth Narayanan']",,,なし,
Keep CALM and Explore: Language Models for Action Generation in Text-based Games,"['Shunyu Yao', 'Rohan Rao', 'Matthew Hausknecht', 'Karthik Narasimhan']",http://arxiv.org/abs/2010.02903v1,"Text-based games present a unique challenge for autonomous agents to operate in natural language and handle enormous action spaces. In this paper, we propose the Contextual Action Language Model (CALM) to generate a compact set of action candidates at each game state. Our key insight is to train language models on human gameplay, where people demonstrate linguistic priors and a general game sense for promising actions conditioned on game history. We combine CALM with a reinforcement learning agent which re-ranks the generated action candidates to maximize in-game rewards. We evaluate our approach using the Jericho benchmark, on games unseen by CALM during training. Our method obtains a 69% relative improvement in average game score over the previous state-of-the-art model. Surprisingly, on half of these games, CALM is competitive with or better than other models that have access to ground truth admissible actions. Code and data are available at https://github.com/princeton-nlp/calm-textgame.",テキストベースのゲームでは、自然言語で動作し、膨大な行動空間を扱うことは、自律エージェントにとってユニークな課題である。本論文では、各ゲーム状態における行動候補のコンパクトなセットを生成するために、文脈に応じた行動言語モデル(CALM)を提案する。我々の重要な洞察は、人間がゲームの履歴を条件として有望な行動のために言語的な前駆詞と一般的なゲームセンスを示す人間のゲームプレイ上で言語モデルを訓練することである。我々はCALMと強化学習エージェントを組み合わせ、ゲーム内報酬を最大化するために生成された行動候補を再ランク付けする。我々は、Jerichoベンチマークを用いて、トレーニング中にCALMによって見られなかったゲームで我々のアプローチを評価する。我々の手法は、以前の最先端モデルと比較して、平均ゲームスコアで69%の相対的な改善を得ることができました。驚くべきことに、これらのゲームの半分について、CALMは、根拠のある真実を認めるアクションにアクセスできる他のモデルと競合するか、またはそれよりも優れています。コードとデータはhttps:/github.complinceton-nlpcalm-textgameから入手可能です。,https://d3i71xaburhd42.cloudfront.net/8aed57b61457655e8354f1b68b34ed1cc0a222ef/1-Figure1-1.png
Keeping Up Appearances: Computational Modeling of Face Acts in Persuasion Oriented Discussions,"['Ritam Dutt', 'Rishabh Joshi', 'Carolyn Rose']",http://arxiv.org/abs/2009.10815v2,"The notion of face refers to the public self-image of an individual that emerges both from the individual's own actions as well as from the interaction with others. Modeling face and understanding its state changes throughout a conversation is critical to the study of maintenance of basic human needs in and through interaction. Grounded in the politeness theory of Brown and Levinson (1978), we propose a generalized framework for modeling face acts in persuasion conversations, resulting in a reliable coding manual, an annotated corpus, and computational models. The framework reveals insights about differences in face act utilization between asymmetric roles in persuasion conversations. Using computational models, we are able to successfully identify face acts as well as predict a key conversational outcome (e.g. donation success). Finally, we model a latent representation of the conversational state to analyze the impact of predicted face acts on the probability of a positive conversational outcome and observe several correlations that corroborate previous findings.",顔の概念は、個人の公共的な自己イメージを意味し、個人自身の行動と他者との相互作用の両方から出現する。顔をモデル化し、会話を通してその状態の変化を理解することは、相互作用の中で、そして相互作用を通しての人間の基本的なニーズの維持の研究にとって重要である。本研究では、Brown and Levinson (1978)の礼儀正しさ理論に基づいて、説得会話における顔の行動をモデル化するための一般化されたフレームワークを提案し、信頼性の高いコーディングマニュアル、注釈付きコーパス、計算モデルを作成した。このフレームワークにより、説得会話における非対称的な役割間での顔役利用の違いについての洞察が得られる。計算モデルを用いて、重要な会話の結果（寄付の成功など）を予測すると同時に、顔の演技を識別することに成功した。最後に、会話状態の潜在表現をモデル化し、予測された面子行為が会話の肯定的な結果の確率に与える影響を分析し、これまでの知見を裏付けるいくつかの相関関係を観察する。,https://d3i71xaburhd42.cloudfront.net/2cb0f0bcfb0be8d799f363d7eb9a5a992e7d9cd1/3-Table1-1.png
KERMIT: Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations,"['Fabio Massimo Zanzotto', 'Andrea Santilli', 'Leonardo Ranaldi', 'Dario Onorati', 'Pierfrancesco Tommasino', 'Francesca Fallucchi']",,,なし,
KGLM: Pretrained Knowledge-Grounded Language Model for Data-to-Text Generation,"['Wenhu Chen', 'Yu Su', 'Xifeng Yan', 'William Yang Wang']",,,なし,
Knowledge Association with Hyperbolic Knowledge Graph Embeddings,"['Zequn Sun', 'Muhao Chen', 'Wei Hu', 'Chengming Wang', 'Jian Dai', 'Wei Zhang']",http://arxiv.org/abs/2010.02162v1,"Capturing associations for knowledge graphs (KGs) through entity alignment, entity type inference and other related tasks benefits NLP applications with comprehensive knowledge representations. Recent related methods built on Euclidean embeddings are challenged by the hierarchical structures and different scales of KGs. They also depend on high embedding dimensions to realize enough expressiveness. Differently, we explore with low-dimensional hyperbolic embeddings for knowledge association. We propose a hyperbolic relational graph neural network for KG embedding and capture knowledge associations with a hyperbolic transformation. Extensive experiments on entity alignment and type inference demonstrate the effectiveness and efficiency of our method.",実体のアラインメント、実体型推論、およびその他の関連するタスクを介して知識グラフ（KG）の関連付けをキャプチャすることは、包括的な知識表現を持つNLPアプリケーションに利益をもたらします。ユークリッド埋め込みに基づいて構築された最近の関連する手法は、KGの階層構造と異なるスケールのために課題があります。また，十分な表現力を実現するためには，高い埋め込み次元に依存している．そこで、我々は、知識関連付けのために低次元の双曲的埋め込みを用いることを検討している。本研究では、ハイパボリック関係グラフニューラルネットワークを提案し、ハイパボリック変換を用いて知識連想を捉える。実体の整列と型推論に関する広範な実験により、我々の手法の有効性と効率性を実証する。,https://d3i71xaburhd42.cloudfront.net/3d61a28b9429fc8f7047fc379a0134a3765edbcb/1-Figure1-1.png
Knowledge Graph Alignment with Entity-Pair Embedding,"['Zhichun Wang', 'Jinjian Yang', 'Xiaoju Ye']",,,なし,
Knowledge Graph Empowered Entity Description Generation,"['Liying Cheng', 'Dekun Wu', 'Lidong Bing', 'Yan Zhang', 'Zhanming Jie', 'Wei Lu', 'Luo Si']",http://arxiv.org/abs/2004.14813v1,"Existing works on KG-to-text generation take as input a few RDF triples or key-value pairs conveying the knowledge of some entities to generate a natural language description. Existing datasets, such as WikiBIO, WebNLG, and E2E, basically have a good alignment between an input triple/pair set and its output text. However in practice, the input knowledge could be more than enough, because the output description may only want to cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such practical scenario in KG-to-text. Our dataset involves exploring large knowledge graphs (KG) to retrieve abundant knowledge of various types of main entities, which makes the current graph-to-sequence models severely suffered from the problems of information loss and parameter explosion while generating the description text. We address these challenges by proposing a multi-graph structure that is able to represent the original graph information more comprehensively. Furthermore, we also incorporate aggregation methods that learn to ensemble the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture.","既存のKG-to-text生成の研究では、自然言語記述を生成するために、いくつかのエンティティの知識を伝えるいくつかのRDFトリプルやキーと値のペアを入力として使用しています。WikiBIO, WebNLG, E2Eなどの既存のデータセットは、基本的に入力されたトリプルペアセットとその出力テキストとの間で良好な整合性を持っている。しかし，実際には，入力された知識だけでは十分ではなく，出力される記述が最も重要な知識だけをカバーしたい場合もある．本論文では、このようなKG-to-textの実用的なシナリオの研究を容易にするために、大規模でチャレンジングなデータセットを紹介する。我々のデータセットでは、大規模な知識グラフ（KG）を探索して、様々な種類の主要なエンティティの豊富な知識を取得することになる。本研究では、元のグラフ情報をより包括的に表現できるマルチグラフ構造を提案することで、これらの課題を解決する。さらに、リッチなグラフ情報を学習してアンサンブルするアグリゲーション手法を組み込む。本研究では、このモデルアーキテクチャの有効性を広範な実験により実証している。",https://d3i71xaburhd42.cloudfront.net/6a7faadf68a49a1a9462738e5d1608cb02ff26d7/1-Figure1-1.png
Knowledge-Grounded Dialogue Generation with Pre-trained Language Models,"['Xueliang Zhao', 'wei wu', 'Can Xu', 'Chongyang Tao', 'Dongyan Zhao', 'Rui Yan']",http://arxiv.org/abs/2010.08824v1,"We study knowledge-grounded dialogue generation with pre-trained language models. To leverage the redundant external knowledge under capacity constraint, we propose equipping response generation defined by a pre-trained language model with a knowledge selection module, and an unsupervised approach to jointly optimizing knowledge selection and response generation with unlabeled dialogues. Empirical results on two benchmarks indicate that our model can significantly outperform state-of-the-art methods in both automatic evaluation and human judgment.",本研究では、事前学習された言語モデルを用いた知識に基づく対話生成について研究を行っている。容量制約下での冗長な外部知識を活用するために、事前学習された言語モデルで定義された応答生成に知識選択モジュールを付加し、ラベル付けされていない対話を用いて知識選択と応答生成を共同で最適化する教師なしアプローチを提案する。2つのベンチマークでの経験的な結果から、自動評価と人間の判断の両方において、我々のモデルが最先端の手法を大幅に上回ることが示された。,https://d3i71xaburhd42.cloudfront.net/3447a432f724aa36595643446acda5b78943db19/1-Table1-1.png
Knowledge-guided Open Attribute Value Extraction with Reinforcement Learning,"['Ye Liu', 'Sheng Zhang', 'Rui Song', 'Suo Feng', 'Yanghua Xiao']",http://arxiv.org/abs/2010.09189v1,"Open attribute value extraction for emerging entities is an important but challenging task. A lot of previous works formulate the problem as a \textit{question-answering} (QA) task. While the collections of articles from web corpus provide updated information about the emerging entities, the retrieved texts can be noisy, irrelevant, thus leading to inaccurate answers. Effectively filtering out noisy articles as well as bad answers is the key to improving extraction accuracy. Knowledge graph (KG), which contains rich, well organized information about entities, provides a good resource to address the challenge. In this work, we propose a knowledge-guided reinforcement learning (RL) framework for open attribute value extraction. Informed by relevant knowledge in KG, we trained a deep Q-network to sequentially compare extracted answers to improve extraction accuracy. The proposed framework is applicable to different information extraction system. Our experimental results show that our method outperforms the baselines by 16.5 - 27.8\%.",新興エンティティのためのオープン属性値抽出は、重要な課題であるが、挑戦的な課題である。これまでの多くの研究では，この問題を「問 題解決」として定式化している．(QA)タスクである。Webコーパスからの記事の収集は、出現したエンティティに関する最新の情報を提供しますが、検索されたテキストは、ノイズの多い、無関係なものである可能性があり、その結果、不正確な回答につながる可能性があります。抽出精度を向上させるためには、ノイズの多い記事や不適切な回答を効果的にフィルタリングすることが鍵となります。このような課題を解決するためには、エンティティに関する豊富で整理された情報を含むナレッジグラフ(KG)が適したリソースとなります。本研究では、オープン属性値抽出のための知識誘導型強化学習（RL）フレームワークを提案する。KGの関連知識をもとに、ディープQネットワークを学習させ、抽出された答えを逐次比較して抽出精度を向上させる。提案したフレームワークは、様々な情報抽出システムに適用可能である。実験の結果、本手法は16.5〜27.8%の確率でベースラインを上回ることが示された。,https://d3i71xaburhd42.cloudfront.net/e65e6c3e282983bfc14dcddd31bc232c82e6d4a0/2-Figure1-1.png
Language Generation with Multi-hop Reasoning on Commonsense Knowledge Graph,"['Haozhe Ji', 'Pei Ke', 'Shaohan Huang', 'Furu Wei', 'Xiaoyan Zhu', 'Minlie Huang']",http://arxiv.org/abs/2009.11692v1,"Despite the success of generative pre-trained language models on a series of text generation tasks, they still suffer in cases where reasoning over underlying commonsense knowledge is required during generation. Existing approaches that integrate commonsense knowledge into generative pre-trained language models simply transfer relational knowledge by post-training on individual knowledge triples while ignoring rich connections within the knowledge graph. We argue that exploiting both the structural and semantic information of the knowledge graph facilitates commonsense-aware text generation. In this paper, we propose Generation with Multi-Hop Reasoning Flow (GRF) that enables pre-trained models with dynamic multi-hop reasoning on multi-relational paths extracted from the external commonsense knowledge graph. We empirically show that our model outperforms existing baselines on three text generation tasks that require reasoning over commonsense knowledge. We also demonstrate the effectiveness of the dynamic multi-hop reasoning module with reasoning paths inferred by the model that provide rationale to the generation.",生成的事前学習型言語モデルは、一連のテキスト生成タスクで成功を収めているにもかかわらず、生成中に基礎となる常識的な知識に対する推論が必要な場合には、いまだに苦戦を強いられています。常識的知識を生成的事前学習言語モデルに統合する既存のアプローチは、知識グラフ内の豊富な接続を無視しながら、個々の知識トリプルに対する事後学習によって関係性知識を伝達するだけである。我々は、知識グラフの構造情報と意味情報の両方を利用することで、コモンセンスを意識したテキスト生成が容易になることを論じている。本論文では、外部のコモンセンス知識グラフから抽出された複数の関係性パスに対して動的なマルチホップ推論を行う事前学習モデルを可能にするGeneration with Multi-Hop Reasoning Flow (GRF)を提案する。本研究では、コモンセンス知識に基づく推論を必要とする3つのテキスト生成タスクにおいて、本モデルが既存のベースラインよりも優れていることを実証的に示す。また、動的マルチホップ推論モジュールの有効性を、生成に根拠を与えるモデルによって推論された推論パスを用いて実証する。,https://d3i71xaburhd42.cloudfront.net/7e8457393ff1b40ddd099f195af9d3b14c5a934f/1-Figure1-1.png
Language Model Prior for Low-Resource Neural Machine Translation,"['Christos Baziotis', 'Barry Haddow', 'Alexandra Birch']",http://arxiv.org/abs/2004.14928v1,"The scarcity of large parallel corpora is an important obstacle for neural machine translation. A common solution is to exploit the knowledge of language models (LM) trained on abundant monolingual data. In this work, we propose a novel approach to incorporate a LM as prior in a neural translation model (TM). Specifically, we add a regularization term, which pushes the output distributions of the TM to be probable under the LM prior, while avoiding wrong predictions when the TM ""disagrees"" with the LM. This objective relates to knowledge distillation, where the LM can be viewed as teaching the TM about the target language. The proposed approach does not compromise decoding speed, because the LM is used only at training time, unlike previous work that requires it during inference. We present an analysis of the effects that different methods have on the distributions of the TM. Results on two low-resource machine translation datasets show clear improvements even with limited monolingual data.","大規模な並列コーパスの不足は、ニューラル機械翻訳にとって重要な障害である。一般的な解決策は、豊富な単言語データ上で訓練された言語モデル(LM)の知識を利用することである。本研究では、ニューラル翻訳モデル(TM)にLMを事前に組み込む新しいアプローチを提案する。具体的には、ニューラル翻訳モデルの出力分布がLMの事前分布の下で確率的になるように正則化項を追加することで、ニューラル翻訳モデルがLMと ""不一致 ""した場合の誤った予測を回避しながら、ニューラル翻訳モデルの出力分布をLMの事前分布の下で確率的になるように押し上げる。この目的は知識の蒸留に関連しており、LM は TM に対象言語について教えるものとみなすことができる。これまでの研究では推論時にLMを必要としていたが、本研究では学習時にのみLMを使用するため、デコード速度を低下させることはない。本研究では、異なる手法が対象言語の分布に与える影響について分析を行った。2つの低リソースの機械翻訳データセットの結果は、限られた単言語データであっても明らかな改善を示している。",https://d3i71xaburhd42.cloudfront.net/e7246557d6cc04bebdfbba473c130d323e415ccd/3-Figure1-1.png
LAReQA: Language-agnostic answer retrieval from a multilingual pool,"['Uma Roy', 'Noah Constant', 'Rami Al-Rfou', 'Aditya Barua', 'Aaron Phillips', 'Yinfei Yang']",http://arxiv.org/abs/2004.05484v1,"We present LAReQA, a challenging new benchmark for language-agnostic answer retrieval from a multilingual candidate pool. Unlike previous cross-lingual tasks, LAReQA tests for ""strong"" cross-lingual alignment, requiring semantically related cross-language pairs to be closer in representation space than unrelated same-language pairs. Building on multilingual BERT (mBERT), we study different strategies for achieving strong alignment. We find that augmenting training data via machine translation is effective, and improves significantly over using mBERT out-of-the-box. Interestingly, the embedding baseline that performs the best on LAReQA falls short of competing baselines on zero-shot variants of our task that only target ""weak"" alignment. This finding underscores our claim that languageagnostic retrieval is a substantively new kind of cross-lingual evaluation.",我々は、多言語の候補者プールからの言語にとらわれない解答検索のための挑戦的な新しいベンチマークであるLAReQAを提示する。LAReQAは、これまでの言語横断タスクとは異なり、「強い」言語横断アライメントをテストし、意味的に関連のある言語横断ペアが、関連のない同一言語ペアよりも表現空間において近いことを要求する。多言語BERT（mBERT）をベースに、強いアライメントを達成するためのさまざまな戦略を研究している。その結果、機械翻訳による学習データの増強が効果的であり、mBERTをすぐに使用するよりも大幅に改善されることがわかった。興味深いことに、LAReQAで最も優れた性能を発揮する埋め込みベースラインは、「弱い」アライメントのみを目標とする我々のタスクのゼロショットバリアントでの競合ベースラインを下回っています。この発見は、言語にとらわれない検索が、実質的に新しい種類の言語横断評価であるという我々の主張を強調している。,https://d3i71xaburhd42.cloudfront.net/06dff9abd1c48fe1dd6b7eb4defe6ec182e9a488/1-Figure1-1.png
Latent Geographical Factors for Analyzing the Evolution of Dialects in Contact,['Yugo Murawaki'],,,なし,
Learn to Cross-lingual Transfer with Meta Graph Learning Across Heterogeneous Languages,"['Zheng Li', 'Mukul Kumar', 'William Headden', 'Bing Yin', 'Ying Wei', 'Yu Zhang', 'Qiang Yang']",,,なし,
Learning a Cost-Effective Annotation Policy for Question Answering,"['Bernhard Kratzwald', 'Stefan Feuerriegel', 'Huan Sun']",http://arxiv.org/abs/2010.03476v1,"State-of-the-art question answering (QA) relies upon large amounts of training data for which labeling is time consuming and thus expensive. For this reason, customizing QA systems is challenging. As a remedy, we propose a novel framework for annotating QA datasets that entails learning a cost-effective annotation policy and a semi-supervised annotation scheme. The latter reduces the human effort: it leverages the underlying QA system to suggest potential candidate annotations. Human annotators then simply provide binary feedback on these candidates. Our system is designed such that past annotations continuously improve the future performance and thus overall annotation cost. To the best of our knowledge, this is the first paper to address the problem of annotating questions with minimal annotation cost. We compare our framework against traditional manual annotations in an extensive set of experiments. We find that our approach can reduce up to 21.1% of the annotation cost.",最新の質問応答(QA)は、大量の学習データに依存しており、ラベリングには時間と費用がかかります。このため、QAシステムをカスタマイズすることは困難である。このため、QAシステムをカスタマイズすることは困難である。その解決策として、我々は、費用対効果の高いアノテーションポリシーと半教師付きアノテーションスキームを学習することを伴うQAデータセットのアノテーションのための新しいフレームワークを提案する。後者では、QAシステムを活用して潜在的なアノテーション候補を提案することで、人間の労力を減らすことができます。人間のアノテータは、これらの候補についてバイナリフィードバックを提供するだけです。我々のシステムは、過去のアノテーションが将来のパフォーマンスを継続的に向上させるように設計されており、その結果、全体的なアノテーションコストが向上しています。私たちの知る限りでは、本論文は最小限のアノテーションコストで問題をアノテーションする問題に取り組んだ最初の論文です。我々のフレームワークを従来の手動アノテーションと比較し、広範な実験を行いました。その結果、我々のアプローチはアノテーションコストを21.1%まで削減できることがわかった。,https://d3i71xaburhd42.cloudfront.net/c442375c9bccffdbb9c3ee25f03c13e472318cdc/2-Figure1-1.png
Learning a Simple and Effective Model for Multi-turn Response Generation with Auxiliary Tasks,"['YUFAN ZHAO', 'Can Xu', 'wei wu']",http://arxiv.org/abs/2004.01972v1,"We study multi-turn response generation for open-domain dialogues. The existing state-of-the-art addresses the problem with deep neural architectures. While these models improved response quality, their complexity also hinders the application of the models in real systems. In this work, we pursue a model that has a simple structure yet can effectively leverage conversation contexts for response generation. To this end, we propose four auxiliary tasks including word order recovery, utterance order recovery, masked word recovery, and masked utterance recovery, and optimize the objectives of these tasks together with maximizing the likelihood of generation. By this means, the auxiliary tasks that relate to context understanding can guide the learning of the generation model to achieve a better local optimum. Empirical studies with three benchmarks indicate that our model can significantly outperform state-of-the-art generation models in terms of response quality on both automatic evaluation and human judgment, and at the same time enjoys a much faster decoding process.",本研究では、オープンドメイン対話のためのマルチターン応答生成を研究している。既存の最先端技術では、ディープニューラルアーキテクチャを用いてこの問題に対処している。これらのモデルは応答品質を向上させる一方で、その複雑さが実システムへの適用の妨げとなっている。本研究では、シンプルな構造でありながら、会話の文脈を効果的に利用して応答を生成できるモデルを追求する。そのために、単語順回復、発話順回復、マスクされた単語回復、マスクされた発話回復の4つの補助タスクを提案し、これらのタスクの目的を生成可能性の最大化と合わせて最適化する。これにより、文脈理解に関連する補助タスクは、より良い局所最適を達成するために生成モデルの学習を導くことができる。3つのベンチマークを用いた実証研究により、本モデルは自動評価と人間の判断の両方において、応答品質の点で最先端の生成モデルを大幅に上回り、同時に復号化プロセスも大幅に高速化されていることが示された。,https://d3i71xaburhd42.cloudfront.net/7049707591d3bbf79e8826bb29e7dc00389b3365/3-Figure1-1.png
Learning Adaptive Segmentation Policy for Simultaneous Translation,"['Ruiqing Zhang', 'Chuanqiang Zhang', 'Zhongjun He', 'Hua Wu', 'Haifeng Wang']",,,なし,
Learning Explainable Linguistic Expressions with Neural Inductive Logic Programming for Sentence Classification,"['Prithviraj Sen', 'Marina Danilevsky', 'Yunyao Li', 'Siddhartha Brahma', 'Matthias Boehm', 'Laura Chiticariu', 'Rajasekar Krishnamurthy']",,,なし,
Learning from Context or Names? An Empirical Study on Neural Relation Extraction,"['Hao Peng', 'Tianyu Gao', 'Xu Han', 'Yankai Lin', 'Peng Li', 'Zhiyuan Liu', 'Maosong Sun', 'Jie Zhou']",http://arxiv.org/abs/2010.01923v1,"Neural models have achieved remarkable success on relation extraction (RE) benchmarks. However, there is no clear understanding which type of information affects existing RE models to make decisions and how to further improve the performance of these models. To this end, we empirically study the effect of two main information sources in text: textual context and entity mentions (names). We find that (i) while context is the main source to support the predictions, RE models also heavily rely on the information from entity mentions, most of which is type information, and (ii) existing datasets may leak shallow heuristics via entity mentions and thus contribute to the high performance on RE benchmarks. Based on the analyses, we propose an entity-masked contrastive pre-training framework for RE to gain a deeper understanding on both textual context and type information while avoiding rote memorization of entities or use of superficial cues in mentions. We carry out extensive experiments to support our views, and show that our framework can improve the effectiveness and robustness of neural models in different RE scenarios. All the code and datasets are released at https://github.com/thunlp/RE-Context-or-Names.",ニューラルモデルは、関係抽出(RE)ベンチマークにおいて顕著な成功を収めている。しかし、どのような情報が既存のREモデルの意思決定に影響を与えるのか、また、これらのモデルの性能をさらに向上させるにはどうすればよいのか、明確な理解は得られていない。そこで、我々は、テキスト中の2つの主要な情報源であるテキストのコンテキストとエンティティの言及（名前）の効果を実証的に研究した。その結果、(i) コンテキストが予測をサポートする主な情報源である一方で、REモデルはエンティティ言及からの情報にも大きく依存しており、そのほとんどがタイプ情報であること、(ii) 既存のデータセットがエンティティ言及を介して浅いヒューリスティックを漏らす可能性があり、その結果、REベンチマークの高い性能に寄与していることがわかった。これらの分析に基づいて、我々はREのために、エンティティの暗記や言及における表面的な手がかりの使用を避けつつ、テキストの文脈とタイプ情報の両方についてより深い理解を得るための、エンティティ・マスクされた対照的な事前学習フレームワークを提案する。我々の見解を支持するために広範な実験を行い、我々のフレームワークが異なるREシナリオにおけるニューラルモデルの有効性とロバスト性を改善できることを示す。全てのコードとデータセットは https:/github.comthunlpRE-Context-or-Names で公開されています。,https://d3i71xaburhd42.cloudfront.net/6a5608e6fee3ecc65361525906b0d092ad9952bb/1-Figure1-1.png
Learning from Task Descriptions,"['Orion Weller', 'Nicholas Lourie', 'Matt Gardner', 'Matthew Peters']",,,なし,
Learning Helpful Inductive Biases from Self-Supervised Pretraining,"['Alex Warstadt', 'Yian Zhang', 'Xiaocheng Li', 'Haokun Liu', 'Samuel R. Bowman']",,,なし,
Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models,"['Isabel Papadimitriou', 'Dan Jurafsky']",http://arxiv.org/abs/2004.14601v2,"We propose transfer learning as a method for analyzing the encoding of grammatical structure in neural language models. We train LSTMs on non-linguistic data and evaluate their performance on natural language to assess which kinds of data induce generalizable structural features that LSTMs can use for natural language. We find that training on non-linguistic data with latent structure (MIDI music or Java code) improves test performance on natural language, despite no overlap in surface form or vocabulary. Training on artificial languages containing recursion (hierarchical structure) also improves performance on natural language, again with no vocabulary overlap. Surprisingly, training on artificial languages consisting of sets of separated pairs of words, but with no recursion, improves performance on natural language as well as recursive languages do. Experiments on transfer between natural languages show that zero-shot performance on a test language is highly correlated with typological syntactic similarity to the training language, suggesting that representations induced from natural languages correspond to the cross-linguistic syntactic properties studied in linguistic typology. Our results provide insights into the ways that neural models represent abstract syntactic structure, and also about the kind of structural inductive biases which a learner needs to model language.",本研究では、ニューラル言語モデルにおける文法構造の符号化を解析するための手法として、伝達学習を提案する。本研究では、LSTMを非言語データ上で訓練し、自然言語上での性能を評価することで、どのようなデータがLSTMが自然言語で使用できる一般化可能な構造特徴を誘発するかを評価する。その結果、潜在的な構造を持つ非言語データ(MIDI音楽やJavaコード)を学習すると、表面形式や語彙に重なりがないにもかかわらず、自然言語でのテスト性能が向上することがわかった。再帰構造（階層構造）を含む人工言語での訓練もまた、語彙の重複がないにもかかわらず、自然言語のテスト性能を向上させる。驚くべきことに、再帰を含まないが、分離された単語のペアの集合からなる人工言語の訓練では、再帰を含まない場合と同様に、自然言語の性能が向上する。自然言語間の移行実験では、テスト言語でのゼロショット性能は訓練言語の類型論的統語的類似性と高い相関があることが示され、自然言語から誘導された表現が言語類型論で研究されている言語間の統語的特性に対応していることが示唆された。本研究の結果は、ニューラルモデルが抽象的な統語構造をどのように表現するのか、また、学習者が言語をモデル化するために必要な構造的帰納的バイアスの種類についての洞察を与えている。,
Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering,"['Harsh Jhamtani', 'Peter Clark']",http://arxiv.org/abs/2010.03274v1,"Despite the rapid progress in multihop question-answering (QA), models still have trouble explaining why an answer is correct, with limited explanation training data available to learn from. To address this, we introduce three explanation datasets in which explanations formed from corpus facts are annotated. Our first dataset, eQASC, contains over 98K explanation annotations for the multihop question answering dataset QASC, and is the first that annotates multiple candidate explanations for each answer. The second dataset eQASC-perturbed is constructed by crowd-sourcing perturbations (while preserving their validity) of a subset of explanations in QASC, to test consistency and generalization of explanation prediction models. The third dataset eOBQA is constructed by adding explanation annotations to the OBQA dataset to test generalization of models trained on eQASC. We show that this data can be used to significantly improve explanation quality (+14% absolute F1 over a strong retrieval baseline) using a BERT-based classifier, but still behind the upper bound, offering a new challenge for future research. We also explore a delexicalized chain representation in which repeated noun phrases are replaced by variables, thus turning them into generalized reasoning chains (for example: ""X is a Y"" AND ""Y has Z"" IMPLIES ""X has Z""). We find that generalized chains maintain performance while also being more robust to certain perturbations.","マルチホップ質問応答(QA)が急速に進歩しているにもかかわらず、モデルがなぜ正解なのかを説明することは困難であり、学習に利用できる説明学習データは限られている。この問題を解決するために、コーパスファクトから形成された説明をアノテーションした3つの説明データセットを紹介する。最初のデータセットであるeQASCは、マルチホップ質問回答データセットQASCの98K以上の説明アノテーションを含んでおり、各回答に対して複数の候補説明をアノテーションした最初のデータセットである。第2のデータセットeQASC-perturbedは、説明予測モデルの一貫性と一般化をテストするために、QASCの説明のサブセットの摂動を（その妥当性を維持したまま）クラウドソーシングして構築されています。3番目のデータセットであるeOBQAは、eQASCで学習されたモデルの一般化をテストするために、OBQAデータセットに説明注釈を追加して構築されている。我々は、このデータを用いて、BERTベースの分類器を用いて説明の品質を有意に向上させることができることを示す（強力な検索ベースラインに対して+14%の絶対F1）が、まだ上限値よりも遅れており、今後の研究のための新たな課題を提供している。我々はまた、繰り返しの名詞句を変数に置き換えて、一般化された推論の連鎖（例：""X is a Y"" AND ""Y has Z"" IMPLIES ""X has Z""）に変換する、非論理化された連鎖表現を探求している。一般化された連鎖は性能を維持しつつ、特定の摂動に対してより頑健であることがわかった。",
Learning to Pronounce Chinese Without a Pronunciation Dictionary,"['Christopher Chu', 'Scot Fang', 'Kevin Knight']",http://arxiv.org/abs/2010.04744v1,"We demonstrate a program that learns to pronounce Chinese text in Mandarin, without a pronunciation dictionary. From non-parallel streams of Chinese characters and Chinese pinyin syllables, it establishes a many-to-many mapping between characters and pronunciations. Using unsupervised methods, the program effectively deciphers writing into speech. Its token-level character-to-syllable accuracy is 89%, which significantly exceeds the 22% accuracy of prior work.",発音辞書を使わずに、中国語のテキストを北京語で発音することを学習するプログラムを実演します。漢字と中国語のピンイン音節の非平行ストリームから、文字と発音の間の多対多のマッピングを確立します。教師なしの手法を使用することで、このプログラムは文字を音声に変換することができます。トークンレベルの文字と音節の精度は89%で、これは従来の22%の精度を大幅に上回っています。,https://d3i71xaburhd42.cloudfront.net/6757225d841451950a5cea245b73e5ff1af34ff1/1-Figure1-1.png
Learning to Represent Image and Text with Denotation Graphs,"['Bowen Zhang', 'Hexiang Hu', 'Vihan Jain', 'Eugene Ie', 'Fei Sha']",http://arxiv.org/abs/2010.02949v1,"Learning to fuse vision and language information and representing them is an important research problem with many applications. Recent progresses have leveraged the ideas of pre-training (from language modeling) and attention layers in Transformers to learn representation from datasets containing images aligned with linguistic expressions that describe the images. In this paper, we propose learning representations from a set of implied, visually grounded expressions between image and text, automatically mined from those datasets. In particular, we use denotation graphs to represent how specific concepts (such as sentences describing images) can be linked to abstract and generic concepts (such as short phrases) that are also visually grounded. This type of generic-to-specific relations can be discovered using linguistic analysis tools. We propose methods to incorporate such relations into learning representation. We show that state-of-the-art multimodal learning models can be further improved by leveraging automatically harvested structural relations. The representations lead to stronger empirical results on downstream tasks of cross-modal image retrieval, referring expression, and compositional attribute-object recognition. Both our codes and the extracted denotation graphs on the Flickr30K and the COCO datasets are publically available on https://sha-lab.github.io/DG.",視覚情報と言語情報を融合して表現を学習することは、多くの応用が期待される重要な研究課題である。近年の進展は、トランスフォーマーにおける事前学習（言語モデリングからの）と注意層の考え方を活用し、画像を含むデータセットから、画像を記述する言語表現を並べて表現を学習することである。本論文では、画像とテキストの間にある視覚的に根拠のある暗黙の表現の集合から表現を学習することを提案する。具体的には、特定の概念（画像を記述する文章など）が、視覚的に根拠のある抽象的で一般的な概念（短いフレーズなど）とどのようにリンクされているかを、デノテーショングラフを用いて表現する。このような一般的な概念と特定の概念との関係は、言語分析ツールを用いて発見することができる。本研究では、このような関係を学習表現に組み込む方法を提案する。本研究では、構造的関係を自動的に取得することで、最新のマルチモーダル学習モデルがさらに改良されることを示す。この表現は、クロスモーダル画像検索、参照表現、構成的属性-物体認識などの下流の課題において、より強力な経験的結果をもたらす。Flickr30KとCOCOのデータセットにおける我々のコードと抽出されたデノテーショングラフは、両方ともhttps:/sha-lab.github.ioDGで公開されています。,https://d3i71xaburhd42.cloudfront.net/73068d13d6e53876c374ebd4c862ec01351c9f39/3-Figure1-1.png
Learning VAE-LDA Models with Rounded Reparameterization Trick,"['Runzhi Tian', 'Yongyi Mao', 'Richong Zhang']",,,なし,
Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers,"['Hanjie Chen', 'Yangfeng Ji']",http://arxiv.org/abs/2010.00667v1,"To build an interpretable neural text classifier, most of the prior work has focused on designing inherently interpretable models or finding faithful explanations. A new line of work on improving model interpretability has just started, and many existing methods require either prior information or human annotations as additional inputs in training. To address this limitation, we propose the variational word mask (VMASK) method to automatically learn task-specific important words and reduce irrelevant information on classification, which ultimately improves the interpretability of model predictions. The proposed method is evaluated with three neural text classifiers (CNN, LSTM, and BERT) on seven benchmark text classification datasets. Experiments show the effectiveness of VMASK in improving both model prediction accuracy and interpretability.","解釈可能なニューラルテキスト分類器を構築するために、これまでの研究のほとんどは、本質的に解釈可能なモデルを設計したり、忠実な説明を見つけたりすることに焦点を当ててきました。モデルの解釈可能性を向上させるための新しい研究が始まったばかりであり、多くの既存の手法では、学習時に事前情報や人間の注釈を追加入力として必要とする。この限界に対処するために、我々は、タスク固有の重要語を自動的に学習し、分類上の無関係な情報を減少させる変分語マスク(VMASK)法を提案し、最終的にモデル予測の解釈性を向上させる。提案手法は、7つのベンチマークテキスト分類データセットに対して、3つのニューラルテキスト分類器(CNN, LSTM, BERT)を用いて評価を行った。実験の結果、VMASKはモデル予測精度と解釈可能性の向上に有効であることが示された。",https://d3i71xaburhd42.cloudfront.net/9d4a144cc6b80d175164b1d2a969ad356743e1f7/1-Table1-1.png
Less is More: Attention Supervision with Counterfactuals for Text Classification,"['Seungtaek Choi', 'Haeju Park', 'Jinyoung Yeo', 'Seung-won Hwang']",,,なし,
Let's Stop Error Propagation in the End-to-End Relation Extraction Literature!,"['Bruno Taillé', 'Vincent Guigue', 'Geoffrey Scoutheeten', 'patrick Gallinari']",,,なし,
Leveraging Declarative Knowledge in Text and First-Order Logic for Fine-Grained Propaganda Detection,"['Ruize Wang', 'Duyu Tang', 'Nan Duan', 'Wanjun Zhong', 'Zhongyu Wei', 'Xuanjing Huang', 'Daxin Jiang', 'Ming Zhou']",http://arxiv.org/abs/2004.14201v2,"We study the detection of propagandistic text fragments in news articles. Instead of merely learning from input-output datapoints in training data, we introduce an approach to inject declarative knowledge of fine-grained propaganda techniques. Specifically, we leverage the declarative knowledge expressed in both first-order logic and natural language. The former refers to the logical consistency between coarse- and fine-grained predictions, which is used to regularize the training process with propositional Boolean expressions. The latter refers to the literal definition of each propaganda technique, which is utilized to get class representations for regularizing the model parameters. We conduct experiments on Propaganda Techniques Corpus, a large manually annotated dataset for fine-grained propaganda detection. Experiments show that our method achieves superior performance, demonstrating that leveraging declarative knowledge can help the model to make more accurate predictions.",本研究では，ニュース記事中のプロパガンダ的なテキスト断片の検出を研究している．本研究では、単に学習データの入出力データポイントから学習するのではなく、きめ細かいプロパガンダ手法の宣言的知識を注入するアプローチを導入している。具体的には、一次論理と自然言語の両方で表現される宣言的知識を活用する。前者は、粗視化された予測と細視化された予測の間の論理的整合性を指し、これを利用して命題のブール表現を用いて学習過程を正則化する。後者は、各プロパガンダ手法のリテラルな定義を指し、モデルパラメータを正則化するためのクラス表現を得るために利用される。本研究では、プロパガンダ手法コーパスを用いて実験を行っている。実験の結果、我々の手法が優れた性能を達成し、宣言的知識を活用することでモデルがより正確な予測を行うことができることを実証した。,https://d3i71xaburhd42.cloudfront.net/61275c81c4e87538172202dfc8c1e9a62d0a2e32/1-Figure1-1.png
Lifelong Language Knowledge Distillation,"['Yung-Sung Chuang', 'Shang-Yu Su', 'Yun-Nung Chen']",http://arxiv.org/abs/2010.02123v1,"It is challenging to perform lifelong language learning (LLL) on a stream of different tasks without any performance degradation comparing to the multi-task counterparts. To address this issue, we present Lifelong Language Knowledge Distillation (L2KD), a simple but efficient method that can be easily applied to existing LLL architectures in order to mitigate the degradation. Specifically, when the LLL model is trained on a new task, we assign a teacher model to first learn the new task, and pass the knowledge to the LLL model via knowledge distillation. Therefore, the LLL model can better adapt to the new task while keeping the previously learned knowledge. Experiments show that the proposed L2KD consistently improves previous state-of-the-art models, and the degradation comparing to multi-task models in LLL tasks is well mitigated for both sequence generation and text classification tasks.",生涯言語学習(LLL)は、マルチタスクと比較して性能の劣化を伴わずに、様々なタスクのストリーム上で実行することが困難である。この問題を解決するために、我々は、既存のLLLアーキテクチャに簡単に適用でき、性能劣化を軽減することができる、シンプルで効率的な手法である生涯言語知識ディスティレーション(L2KD)を提案する。具体的には、LLLモデルを新しいタスクで学習させる際に、まず教師モデルを割り当てて新しいタスクを学習させ、その知識を知識蒸留を介してLLLモデルに渡す。このため，LLLモデルは以前に学習した知識を保持したまま新しいタスクに適応することができる．実験の結果、提案したL2KDは、従来の最新モデルと比較して一貫して改善されており、LLLタスクにおけるマルチタスクモデルと比較して、シーケンス生成タスクとテキスト分類タスクの両方において、劣化が十分に緩和されていることが示された。,https://d3i71xaburhd42.cloudfront.net/02e906841452b9ed78a836ec15001e026688c993/1-Figure1-1.png
"Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text Generation","['Yan Zhang', 'Zhijiang Guo', 'Zhiyang Teng', 'Wei Lu', 'Shay B. Cohen', 'ZUOZHU LIU', 'Lidong Bing']",http://arxiv.org/abs/2010.04383v1,"AMR-to-text generation is used to transduce Abstract Meaning Representation structures (AMR) into text. A key challenge in this task is to efficiently learn effective graph representations. Previously, Graph Convolution Networks (GCNs) were used to encode input AMRs, however, vanilla GCNs are not able to capture non-local information and additionally, they follow a local (first-order) information aggregation scheme. To account for these issues, larger and deeper GCN models are required to capture more complex interactions. In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight Dynamic Graph Convolutional Networks (LDGCNs) that capture richer non-local interactions by synthesizing higher order information from the input graphs. We further develop two novel parameter saving strategies based on the group graph convolutions and weight tied convolutions to reduce memory usage and model complexity. With the help of these strategies, we are able to train a model with fewer parameters while maintaining the model capacity. Experiments demonstrate that LDGCNs outperform state-of-the-art models on two benchmark datasets for AMR-to-text generation with significantly fewer parameters.",AMR-to-text生成は、抽象意味表現構造（AMR）をテキストに変換するために用いられる。このタスクでは、効果的なグラフ表現を効率的に学習することが重要な課題である。従来、入力AMRの符号化にはグラフ畳み込みネットワーク（GCN）が用いられてきたが、バニラのGCNでは非局所的な情報を取り込むことができず、さらに局所的な（1次の）情報集約スキームに従ってしまうという問題があった。これらの問題を考慮して、より複雑な相互作用を捉えるためには、より大規模で深みのあるGCNモデルが必要である。本論文では、動的融合メカニズムを導入し、入力グラフから高次情報を合成することで、より豊かな非局所的相互作用を捉える軽量動的グラフ畳み込みネットワーク(LDGCN)を提案する。さらに、群グラフ畳み込みと重み縛り畳み込みに基づいた2つの新しいパラメータ節約戦略を開発し、メモリ使用量とモデルの複雑さを削減する。これらの戦略の助けを借りて、モデルの容量を維持しつつ、より少ないパラメータでモデルを学習することができるようになった。実験により、LDGCNが2つのベンチマークデータにおいて、パラメータを大幅に削減したAMR-to-text生成において、最先端のモデルよりも優れた性能を発揮することが示された。,https://d3i71xaburhd42.cloudfront.net/1ee577dcb7a275e79995501ec82157a5401ab3af/1-Figure1-1.png
Like hiking? You probably enjoy nature: Persona-grounded Dialog with Commonsense Expansions,"['Bodhisattwa Prasad Majumder', 'Harsh Jhamtani', 'Taylor Berg-Kirkpatrick', 'Julian McAuley']",http://arxiv.org/abs/2010.03205v1,"Existing persona-grounded dialog models often fail to capture simple implications of given persona descriptions, something which humans are able to do seamlessly. For example, state-of-the-art models cannot infer that interest in hiking might imply love for nature or longing for a break. In this paper, we propose to expand available persona sentences using existing commonsense knowledge bases and paraphrasing resources to imbue dialog models with access to an expanded and richer set of persona descriptions. Additionally, we introduce fine-grained grounding on personas by encouraging the model to make a discrete choice among persona sentences while synthesizing a dialog response. Since such a choice is not observed in the data, we model it using a discrete latent random variable and use variational learning to sample from hundreds of persona expansions. Our model outperforms competitive baselines on the PersonaChat dataset in terms of dialog quality and diversity while achieving persona-consistent and controllable dialog generation.",既存のペルソナに基づいた対話モデルでは、人間がシームレスに行うことができるペルソナ記述の単純な意味合いを捉えることができないことが多い。例えば、最新のモデルでは、ハイキングへの関心が自然への愛や休憩への憧れを暗示していると推論することはできない。本論文では、既存の常識的な知識ベースと言い換えリソースを用いて利用可能なペルソナ文を拡張し、対話モデルに拡張された豊かなペルソナ記述のセットへのアクセスを与えることを提案する。さらに、対話応答を合成する際に、モデルがペルソナ文の中から離散的な選択をするように促すことで、ペルソナに関するより詳細な根拠を導入する。このような選択はデータでは観測されないので、離散的な潜在ランダム変数を用いてモデル化し、変分学習を用いて何百ものペルソナ拡張からサンプルを作成する。我々のモデルは、対話の品質と多様性の点で、PersonaChatデータセット上の競合するベースラインよりも優れており、ペルソナの一貫性と制御可能な対話生成を実現している。,https://d3i71xaburhd42.cloudfront.net/2797f8c0398af676612698f2ccc1723a8692f271/1-Figure1-1.png
LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon Induction Through Non-Linear Mapping in Latent Space,"['Tasnim Mohiuddin', 'M Saiful Bari', 'Shafiq Joty']",http://arxiv.org/abs/2004.13889v1,"Most of the successful and predominant methods for bilingual lexicon induction (BLI) are mapping-based, where a linear mapping function is learned with the assumption that the word embedding spaces of different languages exhibit similar geometric structures (i.e., approximately isomorphic). However, several recent studies have criticized this simplified assumption showing that it does not hold in general even for closely related languages. In this work, we propose a novel semi-supervised method to learn cross-lingual word embeddings for BLI. Our model is independent of the isomorphic assumption and uses nonlinear mapping in the latent space of two independently trained auto-encoders. Through extensive experiments on fifteen (15) different language pairs (in both directions) comprising resource-rich and low-resource languages from two different datasets, we demonstrate that our method outperforms existing models by a good margin. Ablation studies show the importance of different model components and the necessity of non-linear mapping.",対訳辞書誘導（BLI）のための成功した手法の多くはマッピングベースの手法であり、異なる言語の単語埋め込み空間が類似の幾何学的構造を示す（すなわち、ほぼ同型である）という仮定のもとに線形マッピング関数を学習するものである。しかし、最近の研究では、この単純化された仮定が、密接な関係にある言語であっても一般的には保持されないことが指摘されている。本研究では、BLIのための言語間単語エンベッディングを学習するための新しい半教師付き手法を提案する。我々のモデルは、同型性の仮定に依存せず、独立して訓練された2つの自動エンコーダーの潜在空間における非線形写像を用いる。2つの異なるデータセットから、資源に富む言語と資源に乏しい言語からなる15の異なる言語ペア(両方向)を対象とした大規模な実験を通して、我々の手法が既存のモデルよりも優れていることを示した。アブレーション研究により、異なるモデル構成要素の重要性と非線形マッピングの必要性が示された。,https://d3i71xaburhd42.cloudfront.net/043f7d7dd61abba7499ffb4adeb6b696990d4be2/3-Figure1-1.png
Local Additivity Based Data Augmentation for Semi-supervised NER,"['Jiaao Chen', 'Zhenghui Wang', 'Ran Tian', 'Zichao Yang', 'Diyi Yang']",http://arxiv.org/abs/2010.01677v1,"Named Entity Recognition (NER) is one of the first stages in deep language understanding yet current NER models heavily rely on human-annotated data. In this work, to alleviate the dependence on labeled data, we propose a Local Additivity based Data Augmentation (LADA) method for semi-supervised NER, in which we create virtual samples by interpolating sequences close to each other. Our approach has two variations: Intra-LADA and Inter-LADA, where Intra-LADA performs interpolations among tokens within one sentence, and Inter-LADA samples different sentences to interpolate. Through linear additions between sampled training data, LADA creates an infinite amount of labeled data and improves both entity and context learning. We further extend LADA to the semi-supervised setting by designing a novel consistency loss for unlabeled data. Experiments conducted on two NER benchmarks demonstrate the effectiveness of our methods over several strong baselines. We have publicly released our code at https://github.com/GT-SALT/LADA.",名前付きエンティティ認識(NER)は深層言語理解の最初の段階の一つであるが、現在のNERモデルは人間の注釈付きデータに大きく依存している。本研究では、ラベル付きデータへの依存度を軽減するために、半教師付きNERのためのLocal Additivity based Data Augmentation (LADA)法を提案する。この手法には2つのバリエーションがある．イントラLADAとインターLADAの2つのバリエーションがあり，イントラLADAでは1つの文内のトークン間の補間を行い，インターLADAでは異なる文をサンプリングして補間を行う．LADAは、サンプリングされた学習データ間の線形加算により、無限のラベル付きデータを生成し、実体学習と文脈学習の両方を向上させることができる。さらに、ラベル付けされていないデータのための新しい一貫性損失を設計することで、LADAを半教師付き設定に拡張する。2つのNERベンチマークで行われた実験では、いくつかの強力なベースライン上での我々の手法の有効性が実証された。我々は我々のコードをhttps:/github.comGT-SALTLADAで公開している。,https://d3i71xaburhd42.cloudfront.net/e603ee43573b14b9c228207637be9080b619a2fe/3-Figure1-1.png
Localizing Q&A Semantic Parsers for Any Language In a Day,"['Mehrad Moradshahi', 'Giovanni Campagna', 'Sina Semnani', 'Silei Xu', 'Monica Lam']",,,なし,
Look at the First Sentence: Position Bias in Question Answering,"['Miyoung Ko', 'Jinhyuk Lee', 'Hyunjae Kim', 'Gangwoo Kim', 'Jaewoo Kang']",http://arxiv.org/abs/2004.14602v3,"Many extractive question answering models are trained to predict start and end positions of answers. The choice of predicting answers as positions is mainly due to its simplicity and effectiveness. In this study, we hypothesize that when the distribution of the answer positions is highly skewed in the training set (e.g., answers lie only in the k-th sentence of each passage), QA models predicting answers as positions can learn spurious positional cues and fail to give answers in different positions. We first illustrate this position bias in popular extractive QA models such as BiDAF and BERT and thoroughly examine how position bias propagates through each layer of BERT. To safely deliver position information without position bias, we train models with various de-biasing methods including entropy regularization and bias ensembling. Among them, we found that using the prior distribution of answer positions as a bias model is very effective at reducing position bias, recovering the performance of BERT from 37.48% to 81.64% when trained on a biased SQuAD dataset.",多くの抽出型質問回答モデルは、回答の開始位置と終了位置を予測するために訓練されています。回答を位置として予測するという選択は、主にその単純さと有効性によるものである。本研究では、学習セットにおいて解答位置の分布に大きな偏りがある場合（例えば、解答が各文章のk番目の文にしか存在しない場合）、位置として解答を予測するQAモデルは、偽の位置情報を学習し、異なる位置での解答に失敗する可能性があるという仮説を立てる。我々はまず、BiDAFやBERTのような一般的な抽出的QAモデルにおけるこの位置バイアスを説明し、位置バイアスがBERTの各層を介してどのように伝播するかを徹底的に検証する。位置バイアスのない安全な位置情報を提供するために、エントロピー正則化やバイアスアンサンブルを含む様々なデバイアス手法を用いてモデルを訓練した。その中でも、解答位置の事前分布をバイアスモデルとして使用することが位置バイアスの低減に非常に有効であり、バイアスのかかったSQuADデータセットで訓練した場合、BERTの性能は37.48%から81.64%に回復することがわかった。,https://d3i71xaburhd42.cloudfront.net/01e85c1cebcb6111e1b255ab57c45d3bfcafe737/1-Figure1-1.png
Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation,"['Maximiliana Behnke', 'Kenneth Heafield']",,,なし,
Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing,"['Xilun Chen', 'Asish Ghoshal', 'Yashar Mehdad', 'Luke Zettlemoyer', 'Sonal Gupta']",http://arxiv.org/abs/2010.03546v1,"Task-oriented semantic parsing is a critical component of virtual assistants, which is responsible for understanding the user's intents (set reminder, play music, etc.). Recent advances in deep learning have enabled several approaches to successfully parse more complex queries (Gupta et al., 2018; Rongali et al.,2020), but these models require a large amount of annotated training data to parse queries on new domains (e.g. reminder, music). In this paper, we focus on adapting task-oriented semantic parsers to low-resource domains, and propose a novel method that outperforms a supervised neural model at a 10-fold data reduction. In particular, we identify two fundamental factors for low-resource domain adaptation: better representation learning and better training techniques. Our representation learning uses BART (Lewis et al., 2019) to initialize our model which outperforms encoder-only pre-trained representations used in previous work. Furthermore, we train with optimization-based meta-learning (Finn et al., 2017) to improve generalization to low-resource domains. This approach significantly outperforms all baseline methods in the experiments on a newly collected multi-domain task-oriented semantic parsing dataset (TOPv2), which we release to the public.","タスク指向のセマンティック解析は、仮想アシスタントの重要なコンポーネントであり、ユーザーの意図（リマインダーを設定する、音楽を再生するなど）を理解する役割を担っている。ディープラーニングの最近の進歩により、より複雑なクエリの解析に成功するいくつかのアプローチが可能になった(Gupta et al.,2018; Rongali et al.,2020)が、これらのモデルは、新しいドメイン(リマインダー、音楽など)のクエリを解析するために、大量の注釈付き訓練データを必要とする。本論文では、タスク指向セマンティックパーサーを低リソースドメインに適応させることに焦点を当て、10倍のデータ削減で教師付きニューラルモデルを凌駕する新規な手法を提案する。特に、低リソース領域への適応のための2つの基本的な要因、すなわち、より優れた表現学習とより優れた訓練技術を明らかにした。我々の表現学習は、以前の研究で使用されたエンコーダのみの事前学習済み表現を上回るモデルの初期化にBART (Lewis et al., 2019)を使用している。さらに、低リソース領域への一般化を改善するために、最適化ベースのメタ学習(Finn et al., 2017)を用いて訓練を行う。このアプローチは、新たに収集したマルチドメインのタスク指向意味解析データセット(TOPv2)での実験において、すべてのベースライン手法を有意に上回る結果を得ており、公開している。",https://d3i71xaburhd42.cloudfront.net/e71885cfa161b3fce024cb75887c06727abe8800/1-Figure1-1.png
LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention,"['Ikuya Yamada', 'Akari Asai', 'Hiroyuki Shindo', 'Hideaki Takeda', 'Yuji Matsumoto']",http://arxiv.org/abs/2010.01057v1,"Entity representations are useful in natural language tasks involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer. The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. Our model is trained using a new pretraining task based on the masked language model of BERT. The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia. We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at https://github.com/studio-ousia/luke.",実体表現は、実体を含む自然言語タスクにおいて有用である。本論文では、双方向変換器に基づく単語と実体の新しい事前学習型文脈化表現を提案する。提案モデルは、与えられたテキスト中の単語と実体を独立したトークンとして扱い、それらの文脈化された表現を出力する。我々のモデルは、BERTのマスクド言語モデルに基づく新しい事前学習タスクを用いて学習される。このタスクは、ウィキペディアから検索された大規模な実体注釈付きコーパスの中で、ランダムにマスクされた単語と実体を予測することを含む。また、トランスフォーマーの自己注意メカニズムを拡張し、注意スコアを計算する際にトークン（単語や実体）の種類を考慮した、実体を意識した自己注意メカニズムを提案する。提案したモデルは、広範囲の実体関連タスクにおいて、印象的な実証的性能を達成した。特に、5つのよく知られたデータセットで最先端の結果が得られている。Open Entity (エンティティタイピング)、TACRED (関係分類)、CoNLL-2003 (名前付きエンティティ認識)、ReCoRD (クロース型質問応答)、SQuAD 1.1 (抽出型質問応答)の5つの有名なデータセットで最先端の結果を得ることができました。ソースコードと訓練済み表現は、https:/github.comstudio-ousialukeから入手可能です。,https://d3i71xaburhd42.cloudfront.net/eedf2748a9a1ba2779cde95fd8bad9c2260d5317/2-Figure1-1.png
MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer,"['Jonas Pfeiffer', 'Ivan Vulić', 'Iryna Gurevych', 'Sebastian Ruder']",http://arxiv.org/abs/2005.00052v3,"The main goal behind state-of-the-art pre-trained multilingual models such as multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in low-resource languages through zero-shot or few-shot cross-lingual transfer. However, due to limited model capacity, their transfer performance is the weakest exactly on such low-resource languages and languages unseen during pre-training. We propose MAD-X, an adapter-based framework that enables high portability and parameter-efficient transfer to arbitrary tasks and languages by learning modular language and task representations. In addition, we introduce a novel invertible adapter architecture and a strong baseline method for adapting a pre-trained multilingual model to a new language. MAD-X outperforms the state of the art in cross-lingual transfer across a representative set of typologically diverse languages on named entity recognition and causal commonsense reasoning, and achieves competitive results on question answering. Our code and adapters are available at AdapterHub.ml",多言語BERTやXLM-Rのような最新の事前学習済み多言語モデルの背後にある主な目的は、ゼロショットまたは数ショットの言語間移動を通じて、リソースの少ない言語でのNLPアプリケーションのブートストラップを可能にし、可能にすることです。しかし、モデルの容量が限られているため、このような低リソース言語や事前学習時に見られなかった言語では、その転送性能は最も弱いものとなっている。本研究では、モジュール化された言語とタスクの表現を学習することで、任意のタスクや言語への高い移植性とパラメータ効率の高い伝達を可能にするアダプタベースのフレームワークであるMAD-Xを提案する。さらに、新しい反転可能なアダプタアーキテクチャと、事前学習した多言語モデルを新しい言語に適応させるための強力なベースライン手法を紹介する。MAD-Xは、型別的に多様な言語の代表的なセットを横断した言語間移動において、名前付き実体認識と因果関係のある常識的推論において、最先端の技術を凌駕し、質問応答においても競争力のある結果を達成しています。コードとアダプタは AdapterHub.ml で入手可能です。,https://d3i71xaburhd42.cloudfront.net/7813ce9379fc76e83e3ece87ae2129dcdd25ca9c/3-Figure1-1.png
Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation,"['Nils Reimers', 'Iryna Gurevych']",http://arxiv.org/abs/2004.09813v2,"We present an easy and efficient method to extend existing sentence embedding models to new languages. This allows to create multilingual versions from previously monolingual models. The training is based on the idea that a translated sentence should be mapped to the same location in the vector space as the original sentence. We use the original (monolingual) model to generate sentence embeddings for the source language and then train a new system on translated sentences to mimic the original model. Compared to other methods for training multilingual sentence embeddings, this approach has several advantages: It is easy to extend existing models with relatively few samples to new languages, it is easier to ensure desired properties for the vector space, and the hardware requirements for training is lower. We demonstrate the effectiveness of our approach for 50+ languages from various language families. Code to extend sentence embeddings models to more than 400 languages is publicly available.",既存の文埋め込みモデルを新しい言語に拡張するための簡単で効率的な方法を提示する。これにより、以前の単言語モデルから多言語版を作成することができる。学習は、翻訳された文が元の文と同じベクトル空間内の同じ位置にマップされるべきであるという考えに基づいている。我々は、原文（単言語）モデルを使用して、原文のための文の埋め込みを生成し、その後、原文モデルを模倣するために、翻訳された文の上で新しいシステムを訓練する。このアプローチは、他の多言語文エンベッディングの学習方法と比較して、いくつかの利点があります。比較的少ないサンプル数で既存のモデルを新しい言語に拡張することが容易であり、ベクトル空間の望ましい特性を確保することが容易であり、学習のためのハードウェア要件が低い。我々は、様々な言語ファミリから50以上の言語に対して我々のアプローチの有効性を実証している。文埋め込みモデルを400以上の言語に拡張するコードが公開されている。,https://d3i71xaburhd42.cloudfront.net/b63075f3249e0c7f7e92da49fc87fc7f9df48d4b/2-Figure1-1.png
Masking as an Efficient Alternative to Finetuning for Pretrained Language Models,"['Mengjie Zhao', 'Tao Lin', 'Fei Mi', 'Martin Jaggi', 'Hinrich Schütze']",http://arxiv.org/abs/2004.12406v2,"We present an efficient method of utilizing pretrained language models, where we learn selective binary masks for pretrained weights in lieu of modifying them through finetuning. Extensive evaluations of masking BERT and RoBERTa on a series of NLP tasks show that our masking scheme yields performance comparable to finetuning, yet has a much smaller memory footprint when several tasks need to be inferred simultaneously. Through intrinsic evaluations, we show that representations computed by masked language models encode information necessary for solving downstream tasks. Analyzing the loss landscape, we show that masking and finetuning produce models that reside in minima that can be connected by a line segment with nearly constant test accuracy. This confirms that masking can be utilized as an efficient alternative to finetuning.",我々は、事前訓練された言語モデルを利用する効率的な方法を提示する。ここでは、事前訓練された重みを微調整によって変更する代わりに、事前訓練された重みに対する選択的なバイナリマスクを学習する。一連のNLPタスク上でのBERTとRoBERTaのマスキングの広範な評価により、我々のマスキングスキームは微調整に匹敵する性能を発揮するが、複数のタスクを同時に推論する必要がある場合には、メモリフットプリントがはるかに小さいことが示された。本質的な評価を通じて、マスクされた言語モデルによって計算された表現が、下流のタスクを解くために必要な情報をコード化していることを示しています。損失のランドスケープを分析すると、マスキングと微調整により、ほぼ一定のテスト精度で線分で結ぶことができる最小値に存在するモデルが生成されることが示された。このことから、マスキングが微調整の効率的な代替手段として利用できることが確認された。,https://d3i71xaburhd42.cloudfront.net/7fb301ea25f02dc7f4f7ee1360137503ee942c8c/5-Figure1-1.png
MAVEN: A Massive General Domain Event Detection Dataset,"['Xiaozhi Wang', 'Ziqi Wang', 'Xu Han', 'Wangyi Jiang', 'Rong Han', 'Zhiyuan Liu', 'Juanzi Li', 'Peng Li', 'Yankai Lin', 'Jie Zhou']",http://arxiv.org/abs/2004.13590v2,"Event detection (ED), which means identifying event trigger words and classifying event types, is the first and most fundamental step for extracting event knowledge from plain text. Most existing datasets exhibit the following issues that limit further development of ED: (1) Data scarcity. Existing small-scale datasets are not sufficient for training and stably benchmarking increasingly sophisticated modern neural methods. (2) Low coverage. Limited event types of existing datasets cannot well cover general-domain events, which restricts the applications of ED models. To alleviate these problems, we present a MAssive eVENt detection dataset (MAVEN), which contains 4,480 Wikipedia documents, 118,732 event mention instances, and 168 event types. MAVEN alleviates the data scarcity problem and covers much more general event types. We reproduce the recent state-of-the-art ED models and conduct a thorough evaluation on MAVEN. The experimental results show that existing ED methods cannot achieve promising results on MAVEN as on the small datasets, which suggests that ED in the real world remains a challenging task and requires further research efforts. We also discuss further directions for general domain ED with empirical analyses. The source code and dataset can be obtained from https://github.com/THU-KEG/MAVEN-dataset.","イベント検出（ED）は、イベントトリガーワードを特定し、イベントタイプを分類することを意味し、プレーンテキストからイベント知識を抽出するための最初の最も基本的なステップです。既存のデータセットの多くは、以下のような問題を持っており、EDのさらなる発展を制限しています。(1) データの希少性。既存の小規模なデータセットでは、ますます高度化する現代のニューラル手法を学習し、安定的にベンチマークするのに十分ではない。(2) カバレッジの低さ。既存のデータセットの限られたイベントタイプでは、一般領域のイベントを十分にカバーすることができず、EDモデルの応用が制限されます。これらの問題を軽減するために、我々は4,480のWikipedia文書、118,732のイベント言及インスタンス、168のイベントタイプを含むMAssive eVENt検出データセット(MAVEN)を提示する。MAVENはデータ不足の問題を緩和し、より一般的なイベントタイプをカバーしている。本研究では、最近の最先端のEDモデルを再現し、MAVENの徹底的な評価を行った。実験の結果、既存のED手法ではMAVENでは小規模なデータセットと同様に有望な結果が得られないことが示され、実世界でのEDは依然として困難な課題であり、さらなる研究努力が必要であることを示唆している。また、一般的な領域でのEDのための更なる方向性についても経験的な分析を交えて議論する。ソースコードとデータセットは、https:/github.comTHU-KEGMAVEN-datasetから入手できます。",https://d3i71xaburhd42.cloudfront.net/de5cbabbee5a91d4f22c4d05257b12e650c53672/1-Figure1-1.png
Measuring Information Propagation in Literary Social Networks,"['Matthew Sims', 'David Bamman']",http://arxiv.org/abs/2004.13980v2,"We present the task of modeling information propagation in literature, in which we seek to identify pieces of information passing from character A to character B to character C, only given a description of their activity in text. We describe a new pipeline for measuring information propagation in this domain and publish a new dataset for speaker attribution, enabling the evaluation of an important component of this pipeline on a wider range of literary texts than previously studied. Using this pipeline, we analyze the dynamics of information propagation in over 5,000 works of fiction, finding that information flows through characters that fill structural holes connecting different communities, and that characters who are women are depicted as filling this role much more frequently than characters who are men.","我々は、文学における情報伝播をモデル化する課題を提示する。この課題では、文字Aから文字B、文字Cへと伝わる情報の断片を特定しようとする。この領域における情報伝播を測定するための新しいパイプラインを記述し、話者帰属のための新しいデータセットを公開する。このパイプラインを用いて、5,000以上の小説作品における情報伝播のダイナミクスを分析したところ、情報は異なるコミュニティをつなぐ構造的な穴を埋める登場人物を介して流れ、女性の登場人物は男性の登場人物に比べて、この役割を果たすように描かれる頻度が高いことがわかった。",https://d3i71xaburhd42.cloudfront.net/fb3a974b22ebccab86d5b489df08bcf4ae17b918/1-Figure1-1.png
Measuring the Similarity of Grammatical Gender Systems by Comparing Partitions,"['Arya D. McCarthy', 'Adina Williams', 'Shijia Liu', 'David Yarowsky', 'Ryan Cotterell']",,,なし,
MedDialog: A Large-scale Medical Dialogue Dataset,"['Guangtao Zeng', 'Wenmian Yang', 'Zeqian Ju', 'Yue Yang', 'Sicheng Wang', 'Ruisi Zhang', 'Meng Zhou', 'Jiaqi Zeng', 'Xiangyu Dong', 'Ruoyu Zhang', 'Hongchao Fang', 'Penghui Zhu', 'Shu Chen', 'Pengtao Xie']",,,なし,
MEGA RST Discourse Treebanks with Structure and Nuclearity from Scalable Distant Sentiment Supervision,"['Patrick Huber', 'Giuseppe Carenini']",,,なし,
Message Passing for Hyper-Relational Knowledge Graphs,"['Mikhail Galkin', 'Priyansh Trivedi', 'Gaurav Maheshwari', 'Ricardo Usbeck', 'Jens Lehmann']",http://arxiv.org/abs/2009.10847v1,"Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating additional key-value pairs along with the main triple to disambiguate, or restrict the validity of a fact. In this work, we propose a message passing based graph encoder - StarE capable of modeling such hyper-relational KGs. Unlike existing approaches, StarE can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. We also demonstrate that existing benchmarks for evaluating link prediction (LP) performance on hyper-relational KGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset - WD50K. Our experiments demonstrate that StarE based LP model outperforms existing approaches across multiple benchmarks. We also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 MRR points compared to triple-based representations.",超相関ナレッジグラフ（KG）（例：ウィキデータ）では、主なトリプルに加えてキーと値のペアを追加して、事実の曖昧さを解消したり、事実の妥当性を制限したりすることができます。本研究では、このような超関係KGをモデル化できるメッセージパッシングベースのグラフエンコーダStarEを提案します。既存のアプローチとは異なり、StarEは、修飾子とトリプルの意味的な役割を維持したまま、任意の数の追加情報（修飾子）をメインのトリプルとともにエンコードすることができる。また、超関係KGのリンク予測(LP)性能を評価する既存のベンチマークには基本的な欠陥があることを示し、新しいウィキデータベースのデータセットWD50Kを開発しました。実験では、StarEベースのLPモデルが複数のベンチマークにおいて既存のアプローチよりも優れていることを実証しました。また、トリプルベースの表現と比較して最大25ポイントのMRRポイントの向上が見られ、リンク予測には修飾語の活用が不可欠であることを確認しました。,https://d3i71xaburhd42.cloudfront.net/fb02c6644008552c9bd0300329cd4221a029da6f/1-Figure1-1.png
Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining,"['Chengyu Wang', 'Minghui Qiu', 'jun huang', 'XIAOFENG HE']",http://arxiv.org/abs/2003.13003v2,"Pre-trained neural language models bring significant improvement for various NLP tasks, by fine-tuning the models on task-specific training sets. During fine-tuning, the parameters are initialized from pre-trained models directly, which ignores how the learning process of similar NLP tasks in different domains is correlated and mutually reinforced. In this paper, we propose an effective learning procedure named Meta Fine-Tuning (MFT), served as a meta-learner to solve a group of similar NLP tasks for neural language models. Instead of simply multi-task training over all the datasets, MFT only learns from typical instances of various domains to acquire highly transferable knowledge. It further encourages the language model to encode domain-invariant representations by optimizing a series of novel domain corruption loss functions. After MFT, the model can be fine-tuned for each domain with better parameter initializations and higher generalization ability. We implement MFT upon BERT to solve several multi-domain text mining tasks. Experimental results confirm the effectiveness of MFT and its usefulness for few-shot learning.",事前に学習されたニューラル言語モデルは、タスク固有の学習セット上でモデルを微調整することで、様々なNLPタスクに対して大きな改善をもたらす。微調整の際には、事前学習されたモデルから直接パラメータを初期化しているため、異なる領域の類似NLPタスクの学習過程がどのように相関し、相互に強化されているかを無視している。本論文では、ニューラル言語モデルのための類似NLPタスク群を解くためのメタ学習者として、メタ微調整(Meta Fine-Tuning: MFT)と呼ばれる効果的な学習手順を提案する。MFTでは、すべてのデータセットを対象としたマルチタスク学習を行うのではなく、様々な領域の典型的なインスタンスからのみ学習を行い、伝達性の高い知識を獲得することができる。MFTはさらに、一連の新しいドメイン破損損失関数を最適化することで、言語モデルがドメイン不変表現を符号化することを奨励する。MFTの後、モデルは、より良いパラメータ初期化とより高い一般化能力により、各領域に対して微調整することができる。我々は、複数ドメインのテキストマイニングタスクを解決するために、BERT上にMFTを実装した。実験結果は、MFTの有効性を確認し、その有用性を確認した。,https://d3i71xaburhd42.cloudfront.net/99ca297ef516e948924f1a455e46606284e37982/2-Figure1-1.png
META: Metadata-Empowered Weak Supervision for Text Classification,"['Dheeraj Mekala', 'Xinyang Zhang', 'Jingbo Shang']",,,なし,
Methods for Numeracy-Preserving Word Embeddings,"['Dhanasekar Sundararaman', 'Shijing Si', 'Vivek Subramanian', 'Guoyin Wang', 'Devamanyu Hazarika', 'Lawrence Carin']",,,なし,
MIME: MIMicking Emotions for Empathetic Response Generation,"['Navonil Majumder', 'Pengfei Hong', 'Shanshan Peng', 'Jiankun Lu', 'Deepanway Ghosal', 'Alexander Gelbukh', 'Rada Mihalcea', 'Soujanya Poria']",http://arxiv.org/abs/2010.01454v1,"Current approaches to empathetic response generation view the set of emotions expressed in the input text as a flat structure, where all the emotions are treated uniformly. We argue that empathetic responses often mimic the emotion of the user to a varying degree, depending on its positivity or negativity and content. We show that the consideration of this polarity-based emotion clusters and emotional mimicry results in improved empathy and contextual relevance of the response as compared to the state-of-the-art. Also, we introduce stochasticity into the emotion mixture that yields emotionally more varied empathetic responses than the previous work. We demonstrate the importance of these factors to empathetic response generation using both automatic- and human-based evaluations. The implementation of MIME is publicly available at https://github.com/declare-lab/MIME.",現在の共感応答生成のアプローチでは、入力テキストに表現された感情の集合を、すべての感情が一様に扱われるフラットな構造として捉えている。我々は、共感応答は、そのポジティブかネガティブかや内容によって、ユーザーの感情を様々な程度に模倣することが多いことを論じている。このような極性に基づいた感情クラスタと感情模倣を考慮することで、最先端の手法と比較して共感性が向上し、応答の文脈的関連性が向上することを示す。また、感情混合に確率論性を導入することで、これまでの研究よりも多様な共感反応が得られることを示した。本研究では、自動評価と人間ベースの評価の両方を用いて、共感応答生成におけるこれらの要因の重要性を実証する。MIMEの実装はhttps:/github.comdeclare-labMIMEで公開されています。,https://d3i71xaburhd42.cloudfront.net/2899ad28e9616779a251a78917e313b5e5011d78/1-Figure1-1.png
Mind Your Inflections! Improving NLP for Non-Standard Englishes with Base-Inflection Encoding,"['Samson Tan', 'Shafiq Joty', 'Lav Varshney', 'Min-Yen Kan']",,,なし,
MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems,"['Zhaojiang Lin', 'Andrea Madotto', 'Genta Indra Winata', 'Pascale Fung']",http://arxiv.org/abs/2009.12005v2,"In this paper, we propose Minimalist Transfer Learning (MinTL) to simplify the system design process of task-oriented dialogue systems and alleviate the over-dependency on annotated data. MinTL is a simple yet effective transfer learning framework, which allows us to plug-and-play pre-trained seq2seq models, and jointly learn dialogue state tracking and dialogue response generation. Unlike previous approaches, which use a copy mechanism to ""carryover"" the old dialogue states to the new one, we introduce Levenshtein belief spans (Lev), that allows efficient dialogue state tracking with a minimal generation length. We instantiate our learning framework with two pre-trained backbones: T5 and BART, and evaluate them on MultiWOZ. Extensive experiments demonstrate that: 1) our systems establish new state-of-the-art results on end-to-end response generation, 2) MinTL-based systems are more robust than baseline methods in the low resource setting, and they achieve competitive results with only 20\% training data, and 3) Lev greatly improves the inference efficiency.","本論文では、タスク指向の対話システムのシステム設計プロセスを簡素化し、アノテーションデータへの過大な依存を緩和するために、Minimalist Transfer Learning (MinTL)を提案する。MinTLはシンプルで効果的な伝達学習フレームワークであり、事前に学習したseq2seqモデルをプラグアンドプレイし、対話状態追跡と対話応答生成を共同で学習することができる。コピー機構を用いて古い対話状態を新しい対話状態に ""キャリーオーバー ""する従来のアプローチとは異なり、最小限の生成長で効率的な対話状態追跡を可能にするLevenshtein belief spans (Lev)を導入しています。学習フレームワークを2つの学習済みバックボーンを用いてインスタンス化する。T5とBARTを用いて学習フレームワークをインスタンス化し、MultiWOZ上で評価する。広範な実験により、以下のことが実証された。2) MinTLベースのシステムは低リソース環境下でもベースライン手法よりもロバストであり、わずか20%の学習データで競争力のある結果が得られること、3) Levは推論効率を大幅に向上させることを示した。",https://d3i71xaburhd42.cloudfront.net/28858688894da173dbdcc49899be6e22ea97bc63/3-Figure1-1.png
Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning,"['Haochen Liu', 'Wentao Wang', 'Yiqi Wang', 'Hui Liu', 'Zitao Liu', 'Jiliang Tang']",http://arxiv.org/abs/2009.13028v1,"Dialogue systems play an increasingly important role in various aspects of our daily life. It is evident from recent research that dialogue systems trained on human conversation data are biased. In particular, they can produce responses that reflect people's gender prejudice. Many debiasing methods have been developed for various natural language processing tasks, such as word embedding. However, they are not directly applicable to dialogue systems because they are likely to force dialogue models to generate similar responses for different genders. This greatly degrades the diversity of the generated responses and immensely hurts the performance of the dialogue models. In this paper, we propose a novel adversarial learning framework Debiased-Chat to train dialogue models free from gender bias while keeping their performance. Extensive experiments on two real-world conversation datasets show that our framework significantly reduces gender bias in dialogue models while maintaining the response quality.",対話システムは日常生活の様々な場面でますます重要な役割を果たしています。人間の会話データに基づいて訓練された対話システムには偏りがあることが最近の研究から明らかになっています。特に、対話システムは人々の性別の偏見を反映した応答を生成する可能性があります。言葉の埋め込みなど、様々な自然言語処理のために多くのデバイアス手法が開発されてきたが、それらは直接適用できるものではない。しかし、これらの手法は、対話モデルが異なるジェンダーに対して同じような応答を強制的に生成してしまう可能性があるため、対話システムに直接適用することはできません。これは、生成される応答の多様性を著しく低下させ、対話モデルの性能を著しく低下させる。本論文では、対話モデルの性能を維持しつつ、ジェンダーバイアスを排除した対話モデルを育成するための新しい敵対学習フレームワークDebiased-Chatを提案する。2つの実世界の会話データセットを用いた広範な実験により、我々のフレームワークは応答の質を維持しつつ、対話モデルのジェンダーバイアスを大幅に低減することが示された。,https://d3i71xaburhd42.cloudfront.net/ca0fe4f205e02f8c52a6f515cb9429b604d5a300/2-Table1-1.png
MLSUM: The Multilingual Summarization Corpus,"['Thomas Scialom', 'Paul-Alexis Dray', 'Sylvain Lamprier', 'Benjamin Piwowarski', 'Jacopo Staiano']",http://arxiv.org/abs/2004.14900v1,"We present MLSUM, the first large-scale MultiLingual SUMmarization dataset. Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -- namely, French, German, Spanish, Russian, Turkish. Together with English newspapers from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community. We report cross-lingual comparative analyses based on state-of-the-art systems. These highlight existing biases which motivate the use of a multi-lingual dataset.",我々は、初の大規模な多言語SUMmarizationデータセットであるMLSUMを発表する。オンライン新聞から取得したこのデータは、フランス語、ドイツ語、スペイン語、ロシア語、トルコ語の5つの言語で150万以上の記事要約ペアを含んでいる。人気のあるCNNDailyメールデータセットの英字新聞と一緒に、収集されたデータは、テキスト要約コミュニティのための新しい研究の方向性を可能にすることができる大規模な多言語データセットを形成しています。本研究では、最新のシステムに基づいた言語横断的な比較分析を報告する。これらは、多言語データセットの使用を動機づける既存のバイアスを浮き彫りにするものである。,https://d3i71xaburhd42.cloudfront.net/24e4d3370dc366d6b353d1d6818a0df266bb31b9/5-Table1-1.png
MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics,"['Anthony Chen', 'Gabriel Stanovsky', 'Sameer Singh', 'Matt Gardner']",http://arxiv.org/abs/2010.03636v2,"Posing reading comprehension as a generation problem provides a great deal of flexibility, allowing for open-ended questions with few restrictions on possible answers. However, progress is impeded by existing generation metrics, which rely on token overlap and are agnostic to the nuances of reading comprehension. To address this, we introduce a benchmark for training and evaluating generative reading comprehension metrics: MOdeling Correctness with Human Annotations. MOCHA contains 40K human judgement scores on model outputs from 6 diverse question answering datasets and an additional set of minimal pairs for evaluation. Using MOCHA, we train a Learned Evaluation metric for Reading Comprehension, LERC, to mimic human judgement scores. LERC outperforms baseline metrics by 10 to 36 absolute Pearson points on held-out annotations. When we evaluate robustness on minimal pairs, LERC achieves 80% accuracy, outperforming baselines by 14 to 26 absolute percentage points while leaving significant room for improvement. MOCHA presents a challenging problem for developing accurate and robust generative reading comprehension metrics.",読解力を世代問題とすることで、可能な答えをほとんど制限せずに自由な質問ができるようになり、非常に柔軟性が高まります。しかし、既存の生成メトリクスはトークンの重複に依存しており、読解のニュアンスに依存しないため、進歩が妨げられている。そこで、本研究では、生成的な読解メトリクスの学習と評価のためのベンチマークを紹介する。MOdeling Correctness with Human Annotations. MOCHAには、6つの多様な質問回答データセットからのモデル出力に対する40Kの人間判定スコアと、評価用の最小ペアの追加セットが含まれている。MOCHAを用いて、人間の判定スコアを模倣した読解力の学習済み評価指標LERCを訓練する。LERCはベースラインの評価基準を10〜36点上回る絶対ピアソンポイントを持つアノテーションを保持していた。最小ペアでのロバスト性を評価すると、LERCは80%の精度を達成し、ベースラインを14～26%の絶対的なパーセンテージポイントで上回り、改善の余地は大きい。MOCHAは、正確でロバストな生成的読解指標を開発するための挑戦的な問題を提示している。,https://d3i71xaburhd42.cloudfront.net/36351d2358317186cb6f90d4705dd1294d2b45ec/1-Figure1-1.png
MODE-LSTM: A Parameter-efficient Recurrent Network with Multi-Scale for Sentence Classification,"['Qianli Ma', 'Zhenxi Lin', 'Jiangyue Yan', 'Zipeng Chen', 'Liuhong Yu']",,,なし,
Modeling Protagonist Emotions for Emotion-Aware Storytelling,"['Faeze Brahman', 'Snigdha Chaturvedi']",http://arxiv.org/abs/2010.06822v1,"Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our models include Emotion Supervision (EmoSup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through reinforcement learning. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.",感情とその進化は、魅力的な物語を作る上で中心的な役割を果たしている。本論文では、ニューラル・ストーリーテリングにおける主人公の感情の軌跡をモデル化する初の研究を紹介する。我々は、与えられたストーリータイトルと主人公のための望ましい感情の弧に沿ったストーリーを生成する手法を設計する。我々のモデルには、Emotion Supervision (EmoSup)と2つのEmotion-Reinforced (EmoRL)モデルがある。EmoRLモデルは、強化学習によってストーリー生成プロセスを規則化するように設計された特別な報酬を使用しています。私たちの自動および手動評価では、これらのモデルは、ストーリーの質を犠牲にすることなく、ベースラインの方法と比較して、希望する感情の弧に沿ったストーリーを生成するのに有意に優れていることが実証されています。,https://d3i71xaburhd42.cloudfront.net/09a32ad79331ee137c4315b684af4e7ab93bf368/1-Figure1-1.png
Modeling the Music Genre Perception across Language-Bound Cultures,"['Elena V. Epure', 'Guillaume Salha', 'Manuel Moussallam', 'Romain Hennequin']",http://arxiv.org/abs/2010.06325v1,"The music genre perception expressed through human annotations of artists or albums varies significantly across language-bound cultures. These variations cannot be modeled as mere translations since we also need to account for cultural differences in the music genre perception. In this work, we study the feasibility of obtaining relevant cross-lingual, culture-specific music genre annotations based only on language-specific semantic representations, namely distributed concept embeddings and ontologies. Our study, focused on six languages, shows that unsupervised cross-lingual music genre annotation is feasible with high accuracy, especially when combining both types of representations. This approach of studying music genres is the most extensive to date and has many implications in musicology and music information retrieval. Besides, we introduce a new, domain-dependent cross-lingual corpus to benchmark state of the art multilingual pre-trained embedding models.",アーティストやアルバムの人間による注釈によって表現される音楽ジャンルの認識は、言語に縛られた文化によって大きく異なる。このような違いは単なる翻訳としてモデル化することはできない。本研究では、言語固有の意味表現、すなわち分散概念エンベッディングとオントロジーのみに基づいて、言語を超えた文化固有の音楽ジャンルのアノテーションを得ることの実現可能性を研究している。本研究では、6つの言語に焦点を当て、教師なしでの言語横断的な音楽ジャンルアノテーションが高精度で実現可能であること、特に両方のタイプの表現を組み合わせた場合に実現可能であることを示した。このような音楽ジャンル研究のアプローチは、これまでで最も広範なものであり、音楽学や音楽情報検索の分野で多くの意味を持っている。さらに、本研究では、事前学習された多言語エンベッディングモデルをベンチマークするために、ドメインに依存した新しいクロスリンガルコーパスを紹介する。,https://d3i71xaburhd42.cloudfront.net/2a813620ae137e611956a60c6fdc6d071ca47ea7/3-Table1-1.png
Modularized Transfomer-based Ranking Framework,"['Luyu Gao', 'Zhuyun Dai', 'Jamie Callan']",http://arxiv.org/abs/2004.13313v3,"Recent innovations in Transformer-based ranking models have advanced the state-of-the-art in information retrieval. However, these Transformers are computationally expensive, and their opaque hidden states make it hard to understand the ranking process. In this work, we modularize the Transformer ranker into separate modules for text representation and interaction. We show how this design enables substantially faster ranking using offline pre-computed representations and light-weight online interactions. The modular design is also easier to interpret and sheds light on the ranking process in Transformer rankers.",,
"MOSEAS: A Multimodal Language Dataset for Spanish, Portuguese, German and French","['AmirAli Bagher Zadeh', 'Yansheng Cao', 'Simon Hessner', 'Paul Pu Liang', 'Soujanya Poria', 'Louis-Philippe Morency']",,,なし,
MovieChats: Chat like Humans in a Closed Domain,"['Hui Su', 'Xiaoyu Shen', 'Zhou Xiao', 'Zheng Zhang', 'Ernie Chang', 'Cheng Zhang', 'Cheng Niu', 'Jie Zhou']",,,,
Multi-Dimensional Gender Bias Classification,"['Emily Dinan', 'Angela Fan', 'Ledell Wu', 'Jason Weston', 'Douwe Kiela', 'Adina Williams']",http://arxiv.org/abs/2005.00614v1,"Machine learning models are trained to find patterns in data. NLP models can inadvertently learn socially undesirable patterns when training on gender biased text. In this work, we propose a general framework that decomposes gender bias in text along several pragmatic and semantic dimensions: bias from the gender of the person being spoken about, bias from the gender of the person being spoken to, and bias from the gender of the speaker. Using this fine-grained framework, we automatically annotate eight large scale datasets with gender information. In addition, we collect a novel, crowdsourced evaluation benchmark of utterance-level gender rewrites. Distinguishing between gender bias along multiple dimensions is important, as it enables us to train finer-grained gender bias classifiers. We show our classifiers prove valuable for a variety of important applications, such as controlling for gender bias in generative models, detecting gender bias in arbitrary text, and shed light on offensive language in terms of genderedness.",,https://d3i71xaburhd42.cloudfront.net/ad9d93406f3cf3ffe5a640cb4d742f202339a511/1-Figure1-1.png
Multi-document Summarization with Maximal Marginal Relevance-guided Reinforcement Learning,"['Yuning Mao', 'Yanru Qu', 'Yiqing Xie', 'Xiang Ren', 'Jiawei Han']",http://arxiv.org/abs/2010.00117v1,"While neural sequence learning methods have made significant progress in single-document summarization (SDS), they produce unsatisfactory results on multi-document summarization (MDS). We observe two major challenges when adapting SDS advances to MDS: (1) MDS involves larger search space and yet more limited training data, setting obstacles for neural methods to learn adequate representations; (2) MDS needs to resolve higher information redundancy among the source documents, which SDS methods are less effective to handle. To close the gap, we present RL-MMR, Maximal Margin Relevance-guided Reinforcement Learning for MDS, which unifies advanced neural SDS methods and statistical measures used in classical MDS. RL-MMR casts MMR guidance on fewer promising candidates, which restrains the search space and thus leads to better representation learning. Additionally, the explicit redundancy measure in MMR helps the neural representation of the summary to better capture redundancy. Extensive experiments demonstrate that RL-MMR achieves state-of-the-art performance on benchmark MDS datasets. In particular, we show the benefits of incorporating MMR into end-to-end learning when adapting SDS to MDS in terms of both learning effectiveness and efficiency.",,https://d3i71xaburhd42.cloudfront.net/a7fe0a03d0598563bec65499bac37013d4481589/3-Figure1-1.png
Multi-Fact Correction in Abstractive Text Summarization,"['Yue Dong', 'Shuohang Wang', 'Zhe Gan', 'Yu Cheng', 'Jackie Chi Kit Cheung', 'Jingjing Liu']",http://arxiv.org/abs/2010.02443v1,"Pre-trained neural abstractive summarization systems have dominated extractive strategies on news summarization performance, at least in terms of ROUGE. However, system-generated abstractive summaries often face the pitfall of factual inconsistency: generating incorrect facts with respect to the source text. To address this challenge, we propose Span-Fact, a suite of two factual correction models that leverages knowledge learned from question answering models to make corrections in system-generated summaries via span selection. Our models employ single or multi-masking strategies to either iteratively or auto-regressively replace entities in order to ensure semantic consistency w.r.t. the source text, while retaining the syntactic structure of summaries generated by abstractive summarization models. Experiments show that our models significantly boost the factual consistency of system-generated summaries without sacrificing summary quality in terms of both automatic metrics and human evaluation.",,https://d3i71xaburhd42.cloudfront.net/37e06f3622c17dc6194b547c944462b2a513b878/1-Table1-1.png
Multi-hop Inference for Question-driven Summarization,"['Yang Deng', 'Wenxuan Zhang', 'Wai Lam']",http://arxiv.org/abs/2010.03738v1,"Question-driven summarization has been recently studied as an effective approach to summarizing the source document to produce concise but informative answers for non-factoid questions. In this work, we propose a novel question-driven abstractive summarization method, Multi-hop Selective Generator (MSG), to incorporate multi-hop reasoning into question-driven summarization and, meanwhile, provide justifications for the generated summaries. Specifically, we jointly model the relevance to the question and the interrelation among different sentences via a human-like multi-hop inference module, which captures important sentences for justifying the summarized answer. A gated selective pointer generator network with a multi-view coverage mechanism is designed to integrate diverse information from different perspectives. Experimental results show that the proposed method consistently outperforms state-of-the-art methods on two non-factoid QA datasets, namely WikiHow and PubMedQA.",,https://d3i71xaburhd42.cloudfront.net/897dc5d3fdee54990dd63b9436b34b6fc7529735/2-Figure1-1.png
Multi-Instance Multi-Label Learning Networks for Aspect-Category Sentiment Analysis,"['Yuncong Li', 'Cunxiang Yin', 'Sheng-hua Zhong', 'Xu Pan']",http://arxiv.org/abs/2010.02656v1,"Aspect-category sentiment analysis (ACSA) aims to predict sentiment polarities of sentences with respect to given aspect categories. To detect the sentiment toward a particular aspect category in a sentence, most previous methods first generate an aspect category-specific sentence representation for the aspect category, then predict the sentiment polarity based on the representation. These methods ignore the fact that the sentiment of an aspect category mentioned in a sentence is an aggregation of the sentiments of the words indicating the aspect category in the sentence, which leads to suboptimal performance. In this paper, we propose a Multi-Instance Multi-Label Learning Network for Aspect-Category sentiment analysis (AC-MIMLLN), which treats sentences as bags, words as instances, and the words indicating an aspect category as the key instances of the aspect category. Given a sentence and the aspect categories mentioned in the sentence, AC-MIMLLN first predicts the sentiments of the instances, then finds the key instances for the aspect categories, finally obtains the sentiments of the sentence toward the aspect categories by aggregating the key instance sentiments. Experimental results on three public datasets demonstrate the effectiveness of AC-MIMLLN.",,https://d3i71xaburhd42.cloudfront.net/73e0d7c1fbd59648e62b0f012732ee3f4b4b2ced/1-Figure1-1.png
Multi-modal Multi-label Emotion Detection with Modality and Label Dependence,"['Dong Zhang', 'Xincheng Ju', 'Junhui Li', 'Shoushan Li', 'Qiaoming Zhu', 'Guodong Zhou']",,,,
Multi-resolution Annotations for Emoji Prediction,"['Weicheng Ma', 'Ruibo Liu', 'Lili Wang', 'Soroush Vosoughi']",,,,
Multi-Stage Pre-training for Automated Chinese Essay Scoring,"['Wei Song', 'Kai Zhang', 'Ruiji Fu', 'Lizhen Liu', 'Ting Liu', 'Miaomiao Cheng']",,,,
Multi-Step Inference for Reasoning Over Paragraphs,"['Jiangming Liu', 'Matt Gardner', 'Shay B. Cohen', 'Mirella Lapata']",http://arxiv.org/abs/2004.02995v1,"Complex reasoning over text requires understanding and chaining together free-form predicates and logical connectives. Prior work has largely tried to do this either symbolically or with black-box transformers. We present a middle ground between these two extremes: a compositional model reminiscent of neural module networks that can perform chained logical reasoning. This model first finds relevant sentences in the context and then chains them together using neural modules. Our model gives significant performance improvements (up to 29\% relative error reduction when combined with a reranker) on ROPES, a recently-introduced complex reasoning dataset",,https://d3i71xaburhd42.cloudfront.net/919e0a6adf816ac6c1be4acb87e5a91574c880f3/1-Figure1-1.png
Multi-Task Learning for Logically Dependent Tasks from the Perspective of Causal Inference,"['Wenqing Chen', 'Jidong Tian', 'Liqiang Xiao', 'Hao He', 'Yaohui Jin']",,,,
Multi-task Learning for Multilingual Neural Machine Translation,"['Yiren Wang', 'ChengXiang Zhai', 'Hany Hassan']",http://arxiv.org/abs/2010.02523v1,"While monolingual data has been shown to be useful in improving bilingual neural machine translation (NMT), effectively and efficiently leveraging monolingual data for Multilingual NMT (MNMT) systems is a less explored area. In this work, we propose a multi-task learning (MTL) framework that jointly trains the model with the translation task on bitext data and two denoising tasks on the monolingual data. We conduct extensive empirical studies on MNMT systems with 10 language pairs from WMT datasets. We show that the proposed approach can effectively improve the translation quality for both high-resource and low-resource languages with large margin, achieving significantly better results than the individual bilingual models. We also demonstrate the efficacy of the proposed approach in the zero-shot setup for language pairs without bitext training data. Furthermore, we show the effectiveness of MTL over pre-training approaches for both NMT and cross-lingual transfer learning NLU tasks; the proposed approach outperforms massive scale models trained on single task.",,https://d3i71xaburhd42.cloudfront.net/8d2cb5d898a2299d96ca776f75908956ad6de03e/4-Figure1-1.png
Multi-turn Response Selection using Dialogue Dependency Relations,"['Qi Jia', 'Yizhu Liu', 'Siyu Ren', 'Kenny Zhu', 'Haifeng Tang']",http://arxiv.org/abs/2010.01502v1,"Multi-turn response selection is a task designed for developing dialogue agents. The performance on this task has a remarkable improvement with pre-trained language models. However, these models simply concatenate the turns in dialogue history as the input and largely ignore the dependencies between the turns. In this paper, we propose a dialogue extraction algorithm to transform a dialogue history into threads based on their dependency relations. Each thread can be regarded as a self-contained sub-dialogue. We also propose Thread-Encoder model to encode threads and candidates into compact representations by pre-trained Transformers and finally get the matching score through an attention layer. The experiments show that dependency relations are helpful for dialogue context understanding, and our model outperforms the state-of-the-art baselines on both DSTC7 and DSTC8*, with competitive results on UbuntuV2.",,https://d3i71xaburhd42.cloudfront.net/6368d5f85d335ffac0ef125b2144b0695d6b80ef/1-Figure1-1.png
Multi-Unit Transformers for Neural Machine Translation,"['Jianhao Yan', 'Fandong Meng', 'Jie Zhou']",,,,
Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization,"['Jiaao Chen', 'Diyi Yang']",http://arxiv.org/abs/2010.01672v1,"Text summarization is one of the most challenging and interesting problems in NLP. Although much attention has been paid to summarizing structured text like news reports or encyclopedia articles, summarizing conversations---an essential part of human-human/machine interaction where most important pieces of information are scattered across various utterances of different speakers---remains relatively under-investigated. This work proposes a multi-view sequence-to-sequence model by first extracting conversational structures of unstructured daily chats from different views to represent conversations and then utilizing a multi-view decoder to incorporate different views to generate dialogue summaries. Experiments on a large-scale dialogue summarization corpus demonstrated that our methods significantly outperformed previous state-of-the-art models via both automatic evaluations and human judgment. We also discussed specific challenges that current approaches faced with this task. We have publicly released our code at https://github.com/GT-SALT/Multi-View-Seq2Seq.",,https://d3i71xaburhd42.cloudfront.net/0ac7c7279f52e8cc98171254534276d9644cf92c/2-Table1-1.png
Multi-view Story Characterization from Movie Plot Synopses and Reviews,"['Sudipta Kar', 'Gustavo Aguilar', 'Mirella Lapata', 'Thamar Solorio']",http://arxiv.org/abs/1908.09083v2,"This paper considers the problem of characterizing stories by inferring properties such as theme and style using written synopses and reviews of movies. We experiment with a multi-label dataset of movie synopses and a tagset representing various attributes of stories (e.g., genre, type of events). Our proposed multi-view model encodes the synopses and reviews using hierarchical attention and shows improvement over methods that only use synopses. Finally, we demonstrate how can we take advantage of such a model to extract a complementary set of story-attributes from reviews without direct supervision. We have made our dataset and source code publicly available at https://ritual.uh.edu/ multiview-tag-2020.",,
MultiCQA: Zero-Shot Transfer of Self-Supervised Text Matching Models on a Massive Scale,"['Andreas Rücklé', 'Jonas Pfeiffer', 'Iryna Gurevych']",http://arxiv.org/abs/2010.00980v1,"We study the zero-shot transfer capabilities of text matching models on a massive scale, by self-supervised training on 140 source domains from community question answering forums in English. We investigate the model performances on nine benchmarks of answer selection and question similarity tasks, and show that all 140 models transfer surprisingly well, where the large majority of models substantially outperforms common IR baselines. We also demonstrate that considering a broad selection of source domains is crucial for obtaining the best zero-shot transfer performances, which contrasts the standard procedure that merely relies on the largest and most similar domains. In addition, we extensively study how to best combine multiple source domains. We propose to incorporate self-supervised with supervised multi-task learning on all available source domains. Our best zero-shot transfer model considerably outperforms in-domain BERT and the previous state of the art on six benchmarks. Fine-tuning of our model with in-domain data results in additional large gains and achieves the new state of the art on all nine benchmarks.",,https://d3i71xaburhd42.cloudfront.net/33add47a46818f2e6a63cfe84e539720111f844f/2-Figure1-1.png
Multilevel Text Alignment with Cross-Document Attention,"['Xuhui Zhou', 'Nikolaos Pappas', 'Noah A. Smith']",http://arxiv.org/abs/2010.01263v1,"Text alignment finds application in tasks such as citation recommendation and plagiarism detection. Existing alignment methods operate at a single, predefined level and cannot learn to align texts at, for example, sentence and document levels. We propose a new learning approach that equips previously established hierarchical attention encoders for representing documents with a cross-document attention component, enabling structural comparisons across different levels (document-to-document and sentence-to-document). Our component is weakly supervised from document pairs and can align at multiple levels. Our evaluation on predicting document-to-document relationships and sentence-to-document relationships on the tasks of citation recommendation and plagiarism detection shows that our approach outperforms previously established hierarchical, attention encoders based on recurrent and transformer contextualization that are unaware of structural correspondence between documents.",,https://d3i71xaburhd42.cloudfront.net/f54eb942cb470e732e8e111a447de992f502b43a/1-Figure1-1.png
Multilingual AMR-to-Text Generation,"['Angela Fan', 'Claire Gardent']",,,,
Multimodal Joint Attribute Prediction and Value Extraction for E-commerce Product,"['Tiangang Zhu', 'Yue Wang', 'Haoran Li', 'Youzheng Wu', 'Xiaodong He', 'Bowen Zhou']",http://arxiv.org/abs/2009.07162v1,"Product attribute values are essential in many e-commerce scenarios, such as customer service robots, product recommendations, and product retrieval. While in the real world, the attribute values of a product are usually incomplete and vary over time, which greatly hinders the practical applications. In this paper, we propose a multimodal method to jointly predict product attributes and extract values from textual product descriptions with the help of the product images. We argue that product attributes and values are highly correlated, e.g., it will be easier to extract the values on condition that the product attributes are given. Thus, we jointly model the attribute prediction and value extraction tasks from multiple aspects towards the interactions between attributes and values. Moreover, product images have distinct effects on our tasks for different product attributes and values. Thus, we selectively draw useful visual information from product images to enhance our model. We annotate a multimodal product attribute value dataset that contains 87,194 instances, and the experimental results on this dataset demonstrate that explicitly modeling the relationship between attributes and values facilitates our method to establish the correspondence between them, and selectively utilizing visual product information is necessary for the task. Our code and dataset will be released to the public.",,https://d3i71xaburhd42.cloudfront.net/97679b9616045bfa3723db15f360cf9f2c8b52ad/1-Figure1-1.png
Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis,"['Yao-Hung Hubert Tsai', 'Martin Ma', 'Muqiao Yang', 'Ruslan Salakhutdinov', 'Louis-Philippe Morency']",,,,
Multistage Fusion with Forget Gate for Multimodal Summarization in Open-Domain Videos,"['Nayu Liu', 'Xian Sun', 'Hongfeng Yu', 'Wenkai Zhang', 'Guangluan Xu']",,,,
MUTANT: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering,"['Tejas Gokhale', 'Pratyay Banerjee', 'Chitta Baral', 'Yezhou Yang']",http://arxiv.org/abs/2009.08566v2,"While progress has been made on the visual question answering leaderboards, models often utilize spurious correlations and priors in datasets under the i.i.d. setting. As such, evaluation on out-of-distribution (OOD) test samples has emerged as a proxy for generalization. In this paper, we present MUTANT, a training paradigm that exposes the model to perceptually similar, yet semantically distinct mutations of the input, to improve OOD generalization, such as the VQA-CP challenge. Under this paradigm, models utilize a consistency-constrained training objective to understand the effect of semantic changes in input (question-image pair) on the output (answer). Unlike existing methods on VQA-CP, MUTANT does not rely on the knowledge about the nature of train and test answer distributions. MUTANT establishes a new state-of-the-art accuracy on VQA-CP with a $10.57\%$ improvement. Our work opens up avenues for the use of semantic input mutations for OOD generalization in question answering.",,https://d3i71xaburhd42.cloudfront.net/72eb95e6424d0e667fe8df8d6ebd439b831406f6/1-Figure1-1.png
Named Entity Recognition Only from Word Embeddings,"['Ying Luo', 'Hai Zhao', 'Junlang Zhan']",,,,
Natural Language Processing for Achieving Sustainable Development: the Case of Neural Labelling to Enhance Community Profiling,"['Costanza Conforti', 'Stephanie Hirmer', 'Dai Morgan', 'Marco Basaldella', 'Yau Ben Or']",http://arxiv.org/abs/2004.12935v1,"In recent years, there has been an increasing interest in the application of Artificial Intelligence - and especially Machine Learning - to the field of Sustainable Development (SD). However, until now, NLP has not been applied in this context. In this research paper, we show the high potential of NLP applications to enhance the sustainability of projects. In particular, we focus on the case of community profiling in developing countries, where, in contrast to the developed world, a notable data gap exists. In this context, NLP could help to address the cost and time barrier of structuring qualitative data that prohibits its widespread use and associated benefits. We propose the new task of Automatic UPV classification, which is an extreme multi-class multi-label classification problem. We release Stories2Insights, an expert-annotated dataset, provide a detailed corpus analysis, and implement a number of strong neural baselines to address the task. Experimental results show that the problem is challenging, and leave plenty of room for future research at the intersection of NLP and SD.",,https://d3i71xaburhd42.cloudfront.net/8287618595ce3bf4e57bc2643f7010e6ef425231/3-Figure1-1.png
Near-imperceptible Neural Linguistic Steganography via Self-Adjusting Arithmetic Coding,"['Jiaming Shen', 'Heng Ji', 'Jiawei Han']",http://arxiv.org/abs/2010.00677v1,"Linguistic steganography studies how to hide secret messages in natural language cover texts. Traditional methods aim to transform a secret message into an innocent text via lexical substitution or syntactical modification. Recently, advances in neural language models (LMs) enable us to directly generate cover text conditioned on the secret message. In this study, we present a new linguistic steganography method which encodes secret messages using self-adjusting arithmetic coding based on a neural language model. We formally analyze the statistical imperceptibility of this method and empirically show it outperforms the previous state-of-the-art methods on four datasets by 15.3% and 38.9% in terms of bits/word and KL metrics, respectively. Finally, human evaluations show that 51% of generated cover texts can indeed fool eavesdroppers.",,https://d3i71xaburhd42.cloudfront.net/9d9f522113c388306672d24ca22a3ffd54b41e6e/1-Figure1-1.png
Neural Deepfake Detection with Factual Structure of Text,"['Wanjun Zhong', 'Duyu Tang', 'Zenan Xu', 'Ruize Wang', 'Nan Duan', 'Ming Zhou', 'Jiahai Wang', 'Jian Yin']",http://arxiv.org/abs/2010.07475v1,"Deepfake detection, the task of automatically discriminating machine-generated text, is increasingly critical with recent advances in natural language generative models. Existing approaches to deepfake detection typically represent documents with coarse-grained representations. However, they struggle to capture factual structures of documents, which is a discriminative factor between machine-generated and human-written text according to our statistical analysis. To address this, we propose a graph-based model that utilizes the factual structure of a document for deepfake detection of text. Our approach represents the factual structure of a given document as an entity graph, which is further utilized to learn sentence representations with a graph neural network. Sentence representations are then composed to a document representation for making predictions, where consistent relations between neighboring sentences are sequentially modeled. Results of experiments on two public deepfake datasets show that our approach significantly improves strong base models built with RoBERTa. Model analysis further indicates that our model can distinguish the difference in the factual structure between machine-generated text and human-written text.",,https://d3i71xaburhd42.cloudfront.net/5aa2d4d4b60516dfed64d1b2b235eb10fdefec68/1-Figure1-1.png
Neural Extractive Summarization with Hierarchical Attentive Heterogeneous Graph Network,"['Ruipeng Jia', 'Yanan Cao', 'Hengzhu Tang', 'Fang Fang', 'Cong Cao', 'Shi Wang']",,,,
Neural Mask Generator: Learning to Generate Adaptive Word Maskings for Language Model Adaptation,"['Minki Kang', 'Moonsu Han', 'Sung Ju Hwang']",http://arxiv.org/abs/2010.02705v1,"We propose a method to automatically generate a domain- and task-adaptive maskings of the given text for self-supervised pre-training, such that we can effectively adapt the language model to a particular target task (e.g. question answering). Specifically, we present a novel reinforcement learning-based framework which learns the masking policy, such that using the generated masks for further pre-training of the target language model helps improve task performance on unseen texts. We use off-policy actor-critic with entropy regularization and experience replay for reinforcement learning, and propose a Transformer-based policy network that can consider the relative importance of words in a given text. We validate our Neural Mask Generator (NMG) on several question answering and text classification datasets using BERT and DistilBERT as the language models, on which it outperforms rule-based masking strategies, by automatically learning optimal adaptive maskings.",,https://d3i71xaburhd42.cloudfront.net/27b0c5a5ae9ebcfacf7a97a13392d87df18bae88/2-Figure1-1.png
Neural Topic Modeling with Cycle-Consistent Adversarial Training,"['Xuemeng Hu', 'Rui Wang', 'Deyu Zhou', 'Yuxuan Xiong']",http://arxiv.org/abs/2009.13971v1,"Advances on deep generative models have attracted significant research interest in neural topic modeling. The recently proposed Adversarial-neural Topic Model models topics with an adversarially trained generator network and employs Dirichlet prior to capture the semantic patterns in latent topics. It is effective in discovering coherent topics but unable to infer topic distributions for given documents or utilize available document labels. To overcome such limitations, we propose Topic Modeling with Cycle-consistent Adversarial Training (ToMCAT) and its supervised version sToMCAT. ToMCAT employs a generator network to interpret topics and an encoder network to infer document topics. Adversarial training and cycle-consistent constraints are used to encourage the generator and the encoder to produce realistic samples that coordinate with each other. sToMCAT extends ToMCAT by incorporating document labels into the topic modeling process to help discover more coherent topics. The effectiveness of the proposed models is evaluated on unsupervised/supervised topic modeling and text classification. The experimental results show that our models can produce both coherent and informative topics, outperforming a number of competitive baselines.",,https://d3i71xaburhd42.cloudfront.net/98dfa5b198af1b24d73982e037c46bf778135f53/3-Figure1-1.png
Non-Autoregressive Machine Translation with Latent Alignments,"['Chitwan Saharia', 'William Chan', 'Saurabh Saxena', 'Mohammad Norouzi']",http://arxiv.org/abs/2004.07437v2,"This paper investigates two latent alignment models for non-autoregressive machine translation, namely CTC and Imputer. CTC generates outputs in a single step, makes strong conditional independence assumptions about output variables, and marginalizes out latent alignments using dynamic programming. Imputer generates outputs in a constant number of steps, and approximately marginalizes out possible generation orders and latent alignments for training. These models are simpler than existing non-autoregressive methods, since they do not require output length prediction as a pre-process. In addition, our architecture is simpler than typical encoder-decoder architectures, since input-output cross attention is not used. On the competitive WMT'14 En$\rightarrow$De task, our CTC model achieves 25.7 BLEU with a single generation step, while Imputer achieves 27.5 BLEU with 2 generation steps, and 28.0 BLEU with 4 generation steps. This compares favourably to the baseline autoregressive Transformer with 27.8 BLEU.",,https://d3i71xaburhd42.cloudfront.net/f6127bbe33d7e5776d3c313304b35d27e1051459/5-Figure1-1.png
"Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation","['Tahmid Hasan', 'Abhik Bhattacharjee', 'Kazi Samin', 'Masum Hasan', 'Madhusudan Basak', 'M. Sohel Rahman', 'Rifat Shahriyar']",http://arxiv.org/abs/2009.09359v2,"Despite being the seventh most widely spoken language in the world, Bengali has received much less attention in machine translation literature due to being low in resources. Most publicly available parallel corpora for Bengali are not large enough; and have rather poor quality, mostly because of incorrect sentence alignments resulting from erroneous sentence segmentation, and also because of a high volume of noise present in them. In this work, we build a customized sentence segmenter for Bengali and propose two novel methods for parallel corpus creation on low-resource setups: aligner ensembling and batch filtering. With the segmenter and the two methods combined, we compile a high-quality Bengali-English parallel corpus comprising of 2.75 million sentence pairs, more than 2 million of which were not available before. Training on neural models, we achieve an improvement of more than 9 BLEU score over previous approaches to Bengali-English machine translation. We also evaluate on a new test set of 1000 pairs made with extensive quality control. We release the segmenter, parallel corpus, and the evaluation set, thus elevating Bengali from its low-resource status. To the best of our knowledge, this is the first ever large scale study on Bengali-English machine translation. We believe our study will pave the way for future research on Bengali-English machine translation as well as other low-resource languages. Our data and code are available at https://github.com/csebuetnlp/banglanmt.",,https://d3i71xaburhd42.cloudfront.net/053d3585b3f8871669b578ecaa4fb681050ce21d/3-Table1-1.png
NwQM: A neural quality assessment framework for Wikipedia,"['Bhanu Prakash Reddy Guda', 'Sasi Bhushan Seelaboyina', 'Soumya Sarkar', 'Animesh Mukherjee']",,,,
OCR Post-Correction for Endangered Language Texts,"['Shruti Rijhwani', 'Antonios Anastasopoulos', 'Graham Neubig']",,,,
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models,"['Jonathan Pilault', 'Raymond Li', 'Sandeep Subramanian', 'Chris Pal']",,,,
On Losses for Modern Language Models,"['Stéphane Aroca-Ouellette', 'Frank Rudzicz']",http://arxiv.org/abs/2010.01694v1,"BERT set many state-of-the-art results over varied NLU benchmarks by pre-training over two tasks: masked language modelling (MLM) and next sentence prediction (NSP), the latter of which has been highly criticized. In this paper, we 1) clarify NSP's effect on BERT pre-training, 2) explore fourteen possible auxiliary pre-training tasks, of which seven are novel to modern language models, and 3) investigate different ways to include multiple tasks into pre-training. We show that NSP is detrimental to training due to its context splitting and shallow semantic signal. We also identify six auxiliary pre-training tasks -- sentence ordering, adjacent sentence prediction, TF prediction, TF-IDF prediction, a FastSent variant, and a Quick Thoughts variant -- that outperform a pure MLM baseline. Finally, we demonstrate that using multiple tasks in a multi-task pre-training framework provides better results than using any single auxiliary task. Using these methods, we outperform BERT Base on the GLUE benchmark using fewer than a quarter of the training tokens.",,https://d3i71xaburhd42.cloudfront.net/9a5938af01b4d83793b6743c3f7560b36c6a212f/5-Table1-1.png
On Negative Interference in Multilingual Language Models,"['Zirui Wang', 'Zachary C. Lipton', 'Yulia Tsvetkov']",,,,
On the Ability of Self-Attention Networks to Recognize Counter Languages,"['Satwik Bhattamishra', 'Kabir Ahuja', 'Navin Goyal']",,,,
On the Reliability and Validity of Detecting Approval of Political Actors in Tweets,"['Indira Sen', 'Fabian Flöck', 'Claudia Wagner']",,,,
On the Sentence Embeddings from BERT for Semantic Textual Similarity,"['Bohan Li', 'Hao Zhou', 'Junxian He', 'Mingxuan Wang', 'Yiming Yang', 'Lei Li']",,,,
Online Back-Parsing for AMR-to-Text Generation,"['Xuefeng Bai', 'Linfeng Song', 'Yue Zhang']",http://arxiv.org/abs/2010.04520v1,"AMR-to-text generation aims to recover a text containing the same meaning as an input AMR graph. Current research develops increasingly powerful graph encoders to better represent AMR graphs, with decoders based on standard language modeling being used to generate outputs. We propose a decoder that back predicts projected AMR graphs on the target sentence during text generation. As the result, our outputs can better preserve the input meaning than standard decoders. Experiments on two AMR benchmarks show the superiority of our model over the previous state-of-the-art system based on graph Transformer.",,https://d3i71xaburhd42.cloudfront.net/26dc459c45a97d816fb63bcf81c4fcc9a681713c/1-Figure1-1.png
Online Conversation Disentanglement with Pointer Networks,"['Tao Yu', 'Shafiq Joty']",,,,
Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space,"['Chunyuan Li', 'Xiang Gao', 'Yuan Li', 'Baolin Peng', 'Xiujun Li', 'Yizhe Zhang', 'Jianfeng Gao']",http://arxiv.org/abs/2004.04092v4,"When trained effectively, the Variational Autoencoder (VAE) can be both a powerful generative model and an effective representation learning framework for natural language. In this paper, we propose the first large-scale language VAE model, Optimus. A universal latent embedding space for sentences is first pre-trained on large text corpus, and then fine-tuned for various language generation and understanding tasks. Compared with GPT-2, Optimus enables guided language generation from an abstract level using the latent vectors. Compared with BERT, Optimus can generalize better on low-resource language understanding tasks due to the smooth latent space structure. Extensive experimental results on a wide range of language tasks demonstrate the effectiveness of Optimus. It achieves new state-of-the-art on VAE language modeling benchmarks. We hope that our first pre-trained big VAE language model itself and results can help the NLP community renew the interests of deep generative models in the era of large-scale pre-training, and make these principled methods more practical.",,https://d3i71xaburhd42.cloudfront.net/00696ba295d66f049d70272219f7fea4266171be/4-Figure1-1.png
PAIR: Planning and Iterative Refinement in Pre-trained Transformers for Long Text Generation,"['Xinyu Hua', 'Lu Wang']",http://arxiv.org/abs/2010.02301v1,"Pre-trained Transformers have enabled impressive breakthroughs in generating long and fluent text, yet their outputs are often ""rambling"" without coherently arranged content. In this work, we present a novel content-controlled text generation framework, PAIR, with planning and iterative refinement, which is built upon a large model, BART. We first adapt the BERT model to automatically construct the content plans, consisting of keyphrase assignments and their corresponding sentence-level positions. The BART model is employed for generation without modifying its structure. We then propose a refinement algorithm to gradually enhance the generation quality within the sequence-to-sequence framework. Evaluation with automatic metrics shows that adding planning consistently improves the generation quality on three distinct domains, with an average of 20 BLEU points and 12 METEOR points improvements. In addition, human judges rate our system outputs to be more relevant and coherent than comparisons without planning.",,https://d3i71xaburhd42.cloudfront.net/ff8a988d88ebe5d5ca116340baa34ae00ce011e8/1-Figure1-1.png
PALM: Pre-training an Autoencoding&autoregressive Language Model for Context-conditioned Generation,"['Bin Bi', 'Chenliang Li', 'Chen Wu', 'Ming Yan', 'Wei Wang', 'Songfang Huang', 'Fei Huang', 'Luo Si']",http://arxiv.org/abs/2004.07159v2,"Self-supervised pre-training, such as BERT, MASS and BART, has emerged as a powerful technique for natural language understanding and generation. Existing pre-training techniques employ autoencoding and/or autoregressive objectives to train Transformer-based models by recovering original word tokens from corrupted text with some masked tokens. The training goals of existing techniques are often inconsistent with the goals of many language generation tasks, such as generative question answering and conversational response generation, for producing new text given context. This work presents PALM with a novel scheme that jointly pre-trains an autoencoding and autoregressive language model on a large unlabeled corpus, specifically designed for generating new text conditioned on context. The new scheme alleviates the mismatch introduced by the existing denoising scheme between pre-training and fine-tuning where generation is more than reconstructing original text. An extensive set of experiments show that PALM achieves new state-of-the-art results on a variety of language generation benchmarks covering generative question answering (Rank 1 on the official MARCO leaderboard), abstractive summarization on CNN/DailyMail as well as Gigaword, question generation on SQuAD, and conversational response generation on Cornell Movie Dialogues.",,https://d3i71xaburhd42.cloudfront.net/e960a8684e33906582b94a53932138d3d502671b/4-Figure1-1.png
PARADE: A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge,"['Yun He', 'Zhuoer Wang', 'Yin Zhang', 'Ruihong Huang', 'James Caverlee']",http://arxiv.org/abs/2010.03725v1,"We present a new benchmark dataset called PARADE for paraphrase identification that requires specialized domain knowledge. PARADE contains paraphrases that overlap very little at the lexical and syntactic level but are semantically equivalent based on computer science domain knowledge, as well as non-paraphrases that overlap greatly at the lexical and syntactic level but are not semantically equivalent based on this domain knowledge. Experiments show that both state-of-the-art neural models and non-expert human annotators have poor performance on PARADE. For example, BERT after fine-tuning achieves an F1 score of 0.709, which is much lower than its performance on other paraphrase identification datasets. PARADE can serve as a resource for researchers interested in testing models that incorporate domain knowledge. We make our data and code freely available.",,https://d3i71xaburhd42.cloudfront.net/e663f431579bdde874795c4e0ae6b58249de695f/6-Figure1-1.png
Parallel Interactive Networks for Multi-Domain Dialogue State Generation,"['Junfan Chen', 'Richong Zhang', 'Yongyi Mao', 'Jie Xu']",http://arxiv.org/abs/2009.07616v2,"The dependencies between system and user utterances in the same turn and across different turns are not fully considered in existing multidomain dialogue state tracking (MDST) models. In this study, we argue that the incorporation of these dependencies is crucial for the design of MDST and propose Parallel Interactive Networks (PIN) to model these dependencies. Specifically, we integrate an interactive encoder to jointly model the in-turn dependencies and cross-turn dependencies. The slot-level context is introduced to extract more expressive features for different slots. And a distributed copy mechanism is utilized to selectively copy words from historical system utterances or historical user utterances. Empirical studies demonstrated the superiority of the proposed PIN model.",,https://d3i71xaburhd42.cloudfront.net/cbdfb9b83a3b53fd3b83d1feb0fa343e3418819c/1-Figure1-1.png
Pareto Probing: Trading-Off Accuracy and Complexity,"['Tiago Pimentel', 'Naomi Saphra', 'Adina Williams', 'Ryan Cotterell']",http://arxiv.org/abs/2010.02180v1,"The question of how to probe contextual word representations in a way that is principled and useful has seen significant recent attention. In our contribution to this discussion, we argue, first, for a probe metric that reflects the trade-off between probe complexity and performance: the Pareto hypervolume. To measure complexity, we present a number of parametric and non-parametric metrics. Our experiments with such metrics show that probe's performance curves often fail to align with widely accepted rankings between language representations (with, e.g., non-contextual representations outperforming contextual ones). These results lead us to argue, second, that common simplistic probe tasks such as POS labeling and dependency arc labeling, are inadequate to evaluate the properties encoded in contextual word representations. We propose full dependency parsing as an example probe task, and demonstrate it with the Pareto hypervolume. In support of our arguments, the results of this illustrative experiment conform closer to accepted rankings among contextual word representations.",,
Partially-Aligned Data-to-Text Generation with Distant Supervision,"['Zihao Fu', 'Bei Shi', 'Wai Lam', 'Lidong Bing', 'Zhiyuan Liu']",http://arxiv.org/abs/2010.01268v1,"The Data-to-Text task aims to generate human-readable text for describing some given structured data enabling more interpretability. However, the typical generation task is confined to a few particular domains since it requires well-aligned data which is difficult and expensive to obtain. Using partially-aligned data is an alternative way of solving the dataset scarcity problem. This kind of data is much easier to obtain since it can be produced automatically. However, using this kind of data induces the over-generation problem posing difficulties for existing models, which tends to add unrelated excerpts during the generation procedure. In order to effectively utilize automatically annotated partially-aligned datasets, we extend the traditional generation task to a refined task called Partially-Aligned Data-to-Text Generation (PADTG) which is more practical since it utilizes automatically annotated data for training and thus considerably expands the application domains. To tackle this new task, we propose a novel distant supervision generation framework. It firstly estimates the input data's supportiveness for each target word with an estimator and then applies a supportiveness adaptor and a rebalanced beam search to harness the over-generation problem in the training and generation phases respectively. We also contribute a partially-aligned dataset (The data and source code of this paper can be obtained from https://github.com/fuzihaofzh/distant_supervision_nlg by sampling sentences from Wikipedia and automatically extracting corresponding KB triples for each sentence from Wikidata. The experimental results show that our framework outperforms all baseline models as well as verify the feasibility of utilizing partially-aligned data.",,https://d3i71xaburhd42.cloudfront.net/0fb276e89b8b39cd9ef0108e6d9624ffae81c17a/1-Figure1-1.png
PathQG: Neural Question Generation from Facts,"['Siyuan Wang', 'Zhongyu Wei', 'Zhihao Fan', 'Zengfeng Huang', 'Weijian Sun', 'Qi ZHANG', 'Xuanjing Huang']",,,,
Personal Information Leakage Detection in Conversations,"['Qiongkai Xu', 'Lizhen Qu', 'Zeyu Gao', 'Gholamreza Haffari']",,,,
Planning and Generating Natural and Diverse Disfluent Texts as Augmentation for Disfluency Detection,"['Jingfeng Yang', 'Diyi Yang', 'Zhaoran Ma']",,,,
PlotMachines: Outline-Conditioned Generation with Dynamic Plot State Tracking,"['Hannah Rashkin', 'Asli Celikyilmaz', 'Yejin Choi', 'Jianfeng Gao']",http://arxiv.org/abs/2004.14967v2,"We propose the task of outline-conditioned story generation: given an outline as a set of phrases that describe key characters and events to appear in a story, the task is to generate a coherent narrative that is consistent with the provided outline. This task is challenging as the input only provides a rough sketch of the plot, and thus, models need to generate a story by interweaving the key points provided in the outline. This requires the model to keep track of the dynamic states of the latent plot, conditioning on the input outline while generating the full story. We present PlotMachines, a neural narrative model that learns to transform an outline into a coherent story by tracking the dynamic plot states. In addition, we enrich PlotMachines with high-level discourse structure so that the model can learn different writing styles corresponding to different parts of the narrative. Comprehensive experiments over three fiction and non-fiction datasets demonstrate that large-scale language models, such as GPT-2 and Grover, despite their impressive generation performance, are not sufficient in generating coherent narratives for the given outline, and dynamic plot state tracking is important for composing narratives with tighter, more consistent plots.",,https://d3i71xaburhd42.cloudfront.net/e7c698bdace380f7183dedbe657686f1885f615c/1-Figure1-1.png
Plug and Play Autoencoders for Conditional Text Generation,"['Florian Mai', 'Nikolaos Pappas', 'Ivan Montero', 'Noah A. Smith', 'James Henderson']",http://arxiv.org/abs/2010.02983v2,"Text autoencoders are commonly used for conditional generation tasks such as style transfer. We propose methods which are plug and play, where any pretrained autoencoder can be used, and only require learning a mapping within the autoencoder's embedding space, training embedding-to-embedding (Emb2Emb). This reduces the need for labeled training data for the task and makes the training procedure more efficient. Crucial to the success of this method is a loss term for keeping the mapped embedding on the manifold of the autoencoder and a mapping which is trained to navigate the manifold by learning offset vectors. Evaluations on style transfer tasks both with and without sequence-to-sequence supervision show that our method performs better than or comparable to strong baselines while being up to four times faster.",,https://d3i71xaburhd42.cloudfront.net/68a68b472a5f4755edd7816176b163f27832f027/1-Figure1-1.png
Point to the Expression: Solving Algebraic Word Problems using the Expression-Pointer Transformer Model,"['Bugeun Kim', 'Kyung Seo Ki', 'Donggeon Lee', 'Gahgene Gweon']",,,,
Pointer: Constrained Text Generation via Insertion-based Generative Pre-training,"['Yizhe Zhang', 'Guoyin Wang', 'Chunyuan Li', 'Zhe Gan', 'Chris Brockett', 'Bill Dolan']",http://arxiv.org/abs/2005.00558v2,"Large-scale pre-trained language models, such as BERT and GPT-2, have achieved excellent performance in language representation learning and free-form text generation. However, these models cannot be directly employed to generate text under specified lexical constraints. To address this challenge, we present POINTER (PrOgressive INsertion-based TransformER), a simple yet novel insertion-based approach for hard-constrained text generation. The proposed method operates by progressively inserting new tokens between existing tokens in a parallel manner. This procedure is recursively applied until a sequence is completed. The resulting coarse-to-fine hierarchy makes the generation process intuitive and interpretable. We pre-train our model with the proposed progressive insertion-based objective on a 12GB Wikipedia dataset, and fine-tune it on downstream hard-constrained generation tasks. Non-autoregressive decoding yields an empirically logarithmic time complexity during inference time. Experimental results on both News and Yelp datasets demonstrate that POINTER achieves state-of-the-art performance on constrained text generation. We released the pre-trained models and the source code to facilitate future research (https://github.com/dreasysnail/POINTER).",,
Position-Aware Tagging for Aspect Sentiment Triplet Extraction,"['Lu Xu', 'Hao Li', 'Wei Lu', 'Lidong Bing']",http://arxiv.org/abs/2010.02609v1,"Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first end-to-end model with a novel position-aware tagging scheme that is capable of jointly extracting the triplets. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness.",,https://d3i71xaburhd42.cloudfront.net/698dcd9b39fcc9ee2837dd44e099a781479d2426/1-Figure1-1.png
PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction,"['Xinyao Ma', 'Maarten Sap', 'Hannah Rashkin', 'Yejin Choi']",,,,
Pre-tokenization of Multi-word Expressions in Cross-lingual Word Embeddings,"['Naoki Otani', 'Satoru Ozaki', 'Xingyuan Zhao', 'Yucen Li', 'Micaelah St Johns', 'Lori Levin']",,,,
Pre-training Entity Relation Encoder with Intra-span and Inter-span Information,"['Yijun Wang', 'Changzhi Sun', 'Yuanbin Wu', 'Junchi Yan', 'Peng Gao', 'Guotong Xie']",,,,
Pre-training for Abstractive Document Summarization by Reinstating Source Text,"['Yanyan Zou', 'Xingxing Zhang', 'Wei Lu', 'Furu Wei', 'Ming Zhou']",http://arxiv.org/abs/2004.01853v4,"Abstractive document summarization is usually modeled as a sequence-to-sequence (Seq2Seq) learning problem. Unfortunately, training large Seq2Seq based summarization models on limited supervised summarization data is challenging. This paper presents three pre-training objectives which allow us to pre-train a Seq2Seq based abstractive summarization model on unlabeled text. The main idea is that, given an input text artificially constructed from a document, a model is pre-trained to reinstate the original document. These objectives include sentence reordering, next sentence generation, and masked document generation, which have close relations with the abstractive document summarization task. Experiments on two benchmark summarization datasets (i.e., CNN/DailyMail and New York Times) show that all three objectives can improve performance upon baselines. Compared to models pre-trained on large-scale data (more than 160GB), our method, with only 19GB text for pre-training, achieves comparable results, which demonstrates its effectiveness.",,
Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information,"['Zehui Lin', 'Xiao Pan', 'Mingxuan Wang', 'Xipeng Qiu', 'Jiangtao Feng', 'Hao Zhou', 'Lei Li']",http://arxiv.org/abs/2010.03142v1,"We investigate the following question for machine translation (MT): can we develop a single universal MT model to serve as the common seed and obtain derivative and improved models on arbitrary language pairs? We propose mRASP, an approach to pre-train a universal multilingual neural machine translation model. Our key idea in mRASP is its novel technique of random aligned substitution, which brings words and phrases with similar meanings across multiple languages closer in the representation space. We pre-train a mRASP model on 32 language pairs jointly with only public datasets. The model is then fine-tuned on downstream language pairs to obtain specialized MT models. We carry out extensive experiments on 42 translation directions across a diverse settings, including low, medium, rich resource, and as well as transferring to exotic language pairs. Experimental results demonstrate that mRASP achieves significant performance improvement compared to directly training on those target pairs. It is the first time to verify that multiple low-resource language pairs can be utilized to improve rich resource MT. Surprisingly, mRASP is even able to improve the translation quality on exotic languages that never occur in the pre-training corpus. Code, data, and pre-trained models are available at https://github.com/linzehui/mRASP.",,https://d3i71xaburhd42.cloudfront.net/464fd9eedfa9205896e443a3fa78887a9e3cc07f/3-Figure1-1.png
Predicting Clinical Trial Results by Implicit Evidence Integration,"['Qiao Jin', 'Chuanqi Tan', 'Mosha Chen', 'Xiaozhong Liu', 'Songfang Huang']",http://arxiv.org/abs/2010.05639v1,"Clinical trials provide essential guidance for practicing Evidence-Based Medicine, though often accompanying with unendurable costs and risks. To optimize the design of clinical trials, we introduce a novel Clinical Trial Result Prediction (CTRP) task. In the CTRP framework, a model takes a PICO-formatted clinical trial proposal with its background as input and predicts the result, i.e. how the Intervention group compares with the Comparison group in terms of the measured Outcome in the studied Population. While structured clinical evidence is prohibitively expensive for manual collection, we exploit large-scale unstructured sentences from medical literature that implicitly contain PICOs and results as evidence. Specifically, we pre-train a model to predict the disentangled results from such implicit evidence and fine-tune the model with limited data on the downstream datasets. Experiments on the benchmark Evidence Integration dataset show that the proposed model outperforms the baselines by large margins, e.g., with a 10.7% relative gain over BioBERT in macro-F1. Moreover, the performance improvement is also validated on another dataset composed of clinical trials related to COVID-19.",,https://d3i71xaburhd42.cloudfront.net/8c874cee36affd8f5631a747f89bba837f461cd2/2-Figure1-1.png
Predicting Stance and Rumor Veracity via Dual Hierarchical Transformer with Pretrained Encoders,"['Jianfei Yu', 'Jing Jiang', 'Ling Min Serena Khoo', 'Hai Leong Chieu', 'Rui Xia']",,,,
Probing Pretrained Language Models for Lexical Semantics,"['Ivan Vulić', 'Edoardo Maria Ponti', 'Robert Litschko', 'Goran Glavaš', 'Anna Korhonen']",http://arxiv.org/abs/2010.05731v1,"The success of large pretrained language models (LMs) such as BERT and RoBERTa has sparked interest in probing their representations, in order to unveil what types of knowledge they implicitly capture. While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context. In this work, we present a systematic empirical analysis across six typologically diverse languages and five different lexical tasks, addressing the following questions: 1) How do different lexical knowledge extraction strategies (monolingual versus multilingual source LM, out-of-context versus in-context encoding, inclusion of special tokens, and layer-wise averaging) impact performance? How consistent are the observed effects across tasks and languages? 2) Is lexical knowledge stored in few parameters, or is it scattered throughout the network? 3) How do these representations fare against traditional static word vectors in lexical tasks? 4) Does the lexical information emerging from independently trained monolingual LMs display latent similarities? Our main results indicate patterns and best practices that hold universally, but also point to prominent variations across languages and tasks. Moreover, we validate the claim that lower Transformer layers carry more type-level lexical knowledge, but also show that this knowledge is distributed across multiple layers.",,https://d3i71xaburhd42.cloudfront.net/9be1d1bf82f6ca6a7bf6a7d92f8f37b647e493d0/3-Table1-1.png
Probing Task-Oriented Dialogue Representation from Language Models,"['Chien-Sheng Wu', 'Caiming Xiong']",,,,
Profile Consistency Identification for Open-domain Dialogue Agents,"['Haoyu Song', 'Yan Wang', 'Wei-Nan Zhang', 'Zhengyu Zhao', 'Ting Liu', 'Xiaojiang Liu']",http://arxiv.org/abs/2009.09680v2,"Maintaining a consistent attribute profile is crucial for dialogue agents to naturally converse with humans. Existing studies on improving attribute consistency mainly explored how to incorporate attribute information in the responses, but few efforts have been made to identify the consistency relations between response and attribute profile. To facilitate the study of profile consistency identification, we create a large-scale human-annotated dataset with over 110K single-turn conversations and their key-value attribute profiles. Explicit relation between response and profile is manually labeled. We also propose a key-value structure information enriched BERT model to identify the profile consistency, and it gained improvements over strong baselines. Further evaluations on downstream tasks demonstrate that the profile consistency identification model is conducive for improving dialogue consistency.",,https://d3i71xaburhd42.cloudfront.net/57e1284db098c62c291b0fcf835511ba04a03b28/1-Figure1-1.png
Program Enhanced Fact Verification with Verbalization and Graph Attention Network,"['Xiaoyu Yang', 'Feng Nie', 'Yufei Feng', 'Quan Liu', 'Zhigang Chen', 'Xiaodan Zhu']",http://arxiv.org/abs/2010.03084v3,"Performing fact verification based on structured data is important for many real-life applications and is a challenging research problem, particularly when it involves both symbolic operations and informal inference based on language understanding. In this paper, we present a Program-enhanced Verbalization and Graph Attention Network (ProgVGAT) to integrate programs and execution into textual inference models. Specifically, a verbalization with program execution model is proposed to accumulate evidences that are embedded in operations over the tables. Built on that, we construct the graph attention verification networks, which are designed to fuse different sources of evidences from verbalized program execution, program structures, and the original statements and tables, to make the final verification decision. To support the above framework, we propose a program selection module optimized with a new training strategy based on margin loss, to produce more accurate programs, which is shown to be effective in enhancing the final verification results. Experimental results show that the proposed framework achieves the new state-of-the-art performance, a 74.4% accuracy, on the benchmark dataset TABFACT.",,https://d3i71xaburhd42.cloudfront.net/75998f7b3d4b047d0b20fe097ce2ec9ac818c645/1-Figure1-1.png
ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning,"['Michael Boratko', 'Xiang Li', ""Tim O'Gorman"", 'Rajarshi Das', 'Dan Le', 'Andrew McCallum']",http://arxiv.org/abs/2005.00771v2,"Given questions regarding some prototypical situation such as Name something that people usually do before they leave the house for work? a human can easily answer them via acquired experiences. There can be multiple right answers for such questions, with some more common for a situation than others. This paper introduces a new question answering dataset for training and evaluating common sense reasoning capabilities of artificial intelligence systems in such prototypical situations. The training set is gathered from an existing set of questions played in a long-running international game show FAMILY- FEUD. The hidden evaluation set is created by gathering answers for each question from 100 crowd-workers. We also propose a generative evaluation task where a model has to output a ranked list of answers, ideally covering all prototypical answers for a question. After presenting multiple competitive baseline models, we find that human performance still exceeds model scores on all evaluation metrics with a meaningful gap, supporting the challenging nature of the task.",,https://d3i71xaburhd42.cloudfront.net/c5bbf7be5ae1348a596cd1be8885a46714c1eb70/1-Figure1-1.png
PRover: Proof Generation for Interpretable Reasoning over Rules,"['Swarnadeep Saha', 'Sayan Ghosh', 'Shashank Srivastava', 'Mohit Bansal']",http://arxiv.org/abs/2010.02830v1,"Recent work by Clark et al. (2020) shows that transformers can act as 'soft theorem provers' by answering questions over explicitly provided knowledge in natural language. In our work, we take a step closer to emulating formal theorem provers, by proposing PROVER, an interpretable transformer-based model that jointly answers binary questions over rule-bases and generates the corresponding proofs. Our model learns to predict nodes and edges corresponding to proof graphs in an efficient constrained training paradigm. During inference, a valid proof, satisfying a set of global constraints is generated. We conduct experiments on synthetic, hand-authored, and human-paraphrased rule-bases to show promising results for QA and proof generation, with strong generalization performance. First, PROVER generates proofs with an accuracy of 87%, while retaining or improving performance on the QA task, compared to RuleTakers (up to 6% improvement on zero-shot evaluation). Second, when trained on questions requiring lower depths of reasoning, it generalizes significantly better to higher depths (up to 15% improvement). Third, PROVER obtains near perfect QA accuracy of 98% using only 40% of the training data. However, generating proofs for questions requiring higher depths of reasoning becomes challenging, and the accuracy drops to 65% for 'depth 5', indicating significant scope for future work. Our code and models are publicly available at https://github.com/swarnaHub/PRover",,https://d3i71xaburhd42.cloudfront.net/b4013141cceb937c46ea5f84f8c06f6bf1215106/1-Figure1-1.png
PyMT5: multi-mode translation of natural language and Python code with transformers,"['Colin Clement', 'Dawn Drain', 'Jonathan Timcheck', 'Alexey Svyatkovskiy', 'Neel Sundaresan']",,,,
Q-learning with Language Model for Edit-based Unsupervised Summarization,"['Ryosuke Kohita', 'Akifumi Wachi', 'Yang Zhao', 'Ryuki Tachibana']",http://arxiv.org/abs/2010.04379v1,"Unsupervised methods are promising for abstractive text summarization in that the parallel corpora is not required. However, their performance is still far from being satisfied, therefore research on promising solutions is on-going. In this paper, we propose a new approach based on Q-learning with an edit-based summarization. The method combines two key modules to form an Editorial Agent and Language Model converter (EALM). The agent predicts edit actions (e.t., delete, keep, and replace), and then the LM converter deterministically generates a summary on the basis of the action signals. Q-learning is leveraged to train the agent to produce proper edit actions. Experimental results show that EALM delivered competitive performance compared with the previous encoder-decoder-based methods, even with truly zero paired data (i.e., no validation set). Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. We also conduct qualitative analysis, providing insights into future study on unsupervised summarizers.",,https://d3i71xaburhd42.cloudfront.net/720b2e2797e6fce7bd7059584b19179e55d608da/1-Figure1-1.png
"QADiscourse - Discourse Relations as QA Pairs: Representation, Crowdsourcing and Baselines","['Valentina Pyatkin', 'Ayal Klein', 'Reut Tsarfaty', 'Ido Dagan']",,,,
Quantifying Intimacy In Language,"['Jiaxin Pei', 'David Jurgens']",,,,
Quantitative Argument Summarization and Beyond: Cross-Domain Key Point Analysis,"['Roy Bar-Haim', 'Yoav Kantor', 'Lilach Eden', 'Roni Friedman', 'Dan Lahav', 'Noam Slonim']",http://arxiv.org/abs/2010.05369v1,"When summarizing a collection of views, arguments or opinions on some topic, it is often desirable not only to extract the most salient points, but also to quantify their prevalence. Work on multi-document summarization has traditionally focused on creating textual summaries, which lack this quantitative aspect. Recent work has proposed to summarize arguments by mapping them to a small set of expert-generated key points, where the salience of each key point corresponds to the number of its matching arguments. The current work advances key point analysis in two important respects: first, we develop a method for automatic extraction of key points, which enables fully automatic analysis, and is shown to achieve performance comparable to a human expert. Second, we demonstrate that the applicability of key point analysis goes well beyond argumentation data. Using models trained on publicly available argumentation datasets, we achieve promising results in two additional domains: municipal surveys and user reviews. An additional contribution is an in-depth evaluation of argument-to-key point matching models, where we substantially outperform previous results.",,https://d3i71xaburhd42.cloudfront.net/728c02b737f03a4ed95f4d4a66583bf7df56c94b/3-Table1-1.png
Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation,"['Emily Dinan', 'Angela Fan', 'Adina Williams', 'Jack Urbanek', 'Douwe Kiela', 'Jason Weston']",http://arxiv.org/abs/1911.03842v2,"Models often easily learn biases present in the training data, and their predictions directly reflect this bias. We analyze gender bias in dialogue data, and examine how this bias is actually amplified in subsequent generative chit-chat dialogue models. We measure gender bias in six existing dialogue datasets, and focus on the most biased one, the multi-player text-based fantasy adventure dataset LIGHT, as a testbed for our bias mitigation techniques. The LIGHT dataset is highly imbalanced with respect to gender, containing predominantly male characters, likely because it is entirely collected by crowdworkers and reflects common biases that exist in fantasy or medieval settings. We consider three techniques to mitigate gender bias: counterfactual data augmentation, targeted data collection, and bias controlled training. We show that our proposed techniques mitigate gender bias in LIGHT by balancing the genderedness of generated dialogue utterances and are particularly effective in combination. We quantify performance using various evaluation methods---such as quantity of gendered words, a dialogue safety classifier, and human studies---all of which show that our models generate less gendered, but equally engaging chit-chat responses.",,https://d3i71xaburhd42.cloudfront.net/d92574321f34de8532e5269728e4d18640de63f5/2-Table1-1.png
Question Directed Graph Attention Network for Numerical Reasoning over Text,"['Kunlong Chen', 'Weidi Xu', 'Xingyi Cheng', 'Zou Xiaochuan', 'Yuyu Zhang', 'Le Song', 'Taifeng Wang', 'Yuan Qi', 'Wei Chu']",http://arxiv.org/abs/2009.07448v1,"Numerical reasoning over texts, such as addition, subtraction, sorting and counting, is a challenging machine reading comprehension task, since it requires both natural language understanding and arithmetic computation. To address this challenge, we propose a heterogeneous graph representation for the context of the passage and question needed for such reasoning, and design a question directed graph attention network to drive multi-step numerical reasoning over this context graph.",,https://d3i71xaburhd42.cloudfront.net/387d59877a641815d79516a7264ff5d20384c596/2-Figure1-1.png
Re-evaluating Evaluation in Text Summarization,"['Manik Bhandari', 'Pranav Narayan Gour', 'Atabak Ashfaq', 'Pengfei Liu', 'Graham Neubig']",http://arxiv.org/abs/2010.07100v1,"Automated evaluation metrics as a stand-in for manual evaluation are an essential part of the development of text-generation tasks such as text summarization. However, while the field has progressed, our standard metrics have not -- for nearly 20 years ROUGE has been the standard evaluation in most summarization papers. In this paper, we make an attempt to re-evaluate the evaluation method for text summarization: assessing the reliability of automatic metrics using top-scoring system outputs, both abstractive and extractive, on recently popular datasets for both system-level and summary-level evaluation settings. We find that conclusions about evaluation metrics on older datasets do not necessarily hold on modern datasets and systems.",,https://d3i71xaburhd42.cloudfront.net/e58edbeb41f3d2d24832e6e3abb94baac754e3f7/2-Table1-1.png
Re-examining the Role of Schema Linking in Text-to-SQL,"['Wenqiang Lei', 'Weixin Wang', 'Zhixin MA', 'Tian Gan', 'Wei Lu', 'Min-Yen Kan', 'Tat-Seng Chua']",,,,
Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting,"['Sanyuan Chen', 'Yutai Hou', 'Yiming Cui', 'Wanxiang Che', 'Ting Liu', 'Xiangzhan Yu']",http://arxiv.org/abs/2004.12651v1,"Deep pretrained language models have achieved great success in the way of pretraining first and then fine-tuning. But such a sequential transfer learning paradigm often confronts the catastrophic forgetting problem and leads to sub-optimal performance. To fine-tune with less forgetting, we propose a recall and learn mechanism, which adopts the idea of multi-task learning and jointly learns pretraining tasks and downstream tasks. Specifically, we propose a Pretraining Simulation mechanism to recall the knowledge from pretraining tasks without data, and an Objective Shifting mechanism to focus the learning on downstream tasks gradually. Experiments show that our method achieves state-of-the-art performance on the GLUE benchmark. Our method also enables BERT-base to achieve better performance than directly fine-tuning of BERT-large. Further, we provide the open-source RecAdam optimizer, which integrates the proposed mechanisms into Adam optimizer, to facility the NLP community.",,https://d3i71xaburhd42.cloudfront.net/f2f3c83db919a2429c4fcad2d0a0ed4e5294354a/4-Figure1-1.png
Recurrent Event Network: Autoregressive Structure Inference over Temporal Knowledge Graphs,"['Woojeong Jin', 'Meng Qu', 'Xisen Jin', 'Xiang Ren']",http://arxiv.org/abs/1904.05530v4,"Knowledge graph reasoning is a critical task in natural language processing. The task becomes more challenging on temporal knowledge graphs, where each fact is associated with a timestamp. Most existing methods focus on reasoning at past timestamps and they are not able to predict facts happening in the future. This paper proposes Recurrent Event Network (RE-NET), a novel autoregressive architecture for predicting future interactions. The occurrence of a fact (event) is modeled as a probability distribution conditioned on temporal sequences of past knowledge graphs. Specifically, our RE-NET employs a recurrent event encoder to encode past facts and uses a neighborhood aggregator to model the connection of facts at the same timestamp. Future facts can then be inferred in a sequential manner based on the two modules. We evaluate our proposed method via link prediction at future times on five public datasets. Through extensive experiments, we demonstrate the strength of RENET, especially on multi-step inference over future timestamps, and achieve state-of-the-art performance on all five datasets. Code and data can be found at https://github.com/INK-USC/RE-Net.",,
Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations,"['Kai Sun', 'Richong Zhang', 'Samuel Mensah', 'Yongyi Mao', 'xudong Liu']",http://arxiv.org/abs/2005.00162v2,"The idea of using multi-task learning approaches to address the joint extraction of entity and relation is motivated by the relatedness between the entity recognition task and the relation classification task. Existing methods using multi-task learning techniques to address the problem learn interactions among the two tasks through a shared network, where the shared information is passed into the task-specific networks for prediction. However, such an approach hinders the model from learning explicit interactions between the two tasks to improve the performance on the individual tasks. As a solution, we design a multi-task learning model which we refer to as recurrent interaction network which allows the learning of interactions dynamically, to effectively model task-specific features for classification. Empirical studies on two real-world datasets confirm the superiority of the proposed model.",,https://d3i71xaburhd42.cloudfront.net/94e6a971d994bb1a4e516622d5e34a09c56cb7ec/2-Figure1-1.png
"Refer, Reuse, Reduce: Grounding Subsequent References in Visual and Conversational Contexts","['Ece Takmaz', 'Mario Giulianelli', 'Sandro Pezzelle', 'Arabella Sinclair', 'Raquel Fernández']",,,,
Reformulating Unsupervised Style Transfer as Paraphrase Generation,"['Kalpesh Krishna', 'John Wieting', 'Mohit Iyyer']",http://arxiv.org/abs/2010.05700v1,"Modern NLP defines the task of style transfer as modifying the style of a given sentence without appreciably changing its semantics, which implies that the outputs of style transfer systems should be paraphrases of their inputs. However, many existing systems purportedly designed for style transfer inherently warp the input's meaning through attribute transfer, which changes semantic properties such as sentiment. In this paper, we reformulate unsupervised style transfer as a paraphrase generation problem, and present a simple methodology based on fine-tuning pretrained language models on automatically generated paraphrase data. Despite its simplicity, our method significantly outperforms state-of-the-art style transfer systems on both human and automatic evaluations. We also survey 23 style transfer papers and discover that existing automatic metrics can be easily gamed and propose fixed variants. Finally, we pivot to a more real-world style transfer setting by collecting a large dataset of 15M sentences in 11 diverse styles, which we use for an in-depth analysis of our system.",,https://d3i71xaburhd42.cloudfront.net/ccad27088b9098de4eaca8dc449b18766db4b3ab/1-Figure1-1.png
Regularizing Dialogue Generation by Imitating Implicit Scenarios,"['Shaoxiong Feng', 'Xuancheng Ren', 'Hongshen Chen', 'Bin Sun', 'Kan Li', 'Xu SUN']",http://arxiv.org/abs/2010.01893v2,"Human dialogues are scenario-based and appropriate responses generally relate to the latent context knowledge entailed by the specific scenario. To enable responses that are more meaningful and context-specific, we propose to improve generative dialogue systems from the scenario perspective, where both dialogue history and future conversation are taken into account to implicitly reconstruct the scenario knowledge. More importantly, the conversation scenarios are further internalized using imitation learning framework, where the conventional dialogue model that has no access to future conversations is effectively regularized by transferring the scenario knowledge contained in hierarchical supervising signals from the scenario-based dialogue model, so that the future conversation is not required in actual inference. Extensive evaluations show that our approach significantly outperforms state-of-the-art baselines on diversity and relevance, and expresses scenario-specific knowledge.",,https://d3i71xaburhd42.cloudfront.net/968eab562ad4e38164b027c16b4e1cb757dfd2f2/1-Figure1-1.png
Relation-aware Graph Attention Networks with Relational Position Encodings for Emotion Recognition in Conversations,"['Taichi Ishiwatari', 'Yuki Yasuda', 'Taro Miyazaki', 'Jun Goto']",,,,
Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference,"['Bang An', 'Jie Lyu', 'Zhenyi Wang', 'Chunyuan Li', 'Changwei Hu', 'Fei Tan', 'Ruiyi Zhang', 'Yifan Hu', 'Changyou Chen']",http://arxiv.org/abs/2009.09364v1,"The neural attention mechanism plays an important role in many natural language processing applications. In particular, the use of multi-head attention extends single-head attention by allowing a model to jointly attend information from different perspectives. Without explicit constraining, however, multi-head attention may suffer from attention collapse, an issue that makes different heads extract similar attentive features, thus limiting the model's representation power. In this paper, for the first time, we provide a novel understanding of multi-head attention from a Bayesian perspective. Based on the recently developed particle-optimization sampling techniques, we propose a non-parametric approach that explicitly improves the repulsiveness in multi-head attention and consequently strengthens model's expressiveness. Remarkably, our Bayesian interpretation provides theoretical inspirations on the not-well-understood questions: why and how one uses multi-head attention. Extensive experiments on various attention models and applications demonstrate that the proposed repulsive attention can improve the learned feature diversity, leading to more informative representations with consistent performance improvement on various tasks.",,https://d3i71xaburhd42.cloudfront.net/a51547aabbb94e7347fdad77ad8ff3c76182995a/5-Figure1-1.png
Response Selection for Multi-Party Conversations with Dynamic Topic Tracking,"['Weishi Wang', 'Steven C.H. Hoi', 'Shafiq Joty']",http://arxiv.org/abs/2010.07785v1,"While participants in a multi-party multi-turn conversation simultaneously engage in multiple conversation topics, existing response selection methods are developed mainly focusing on a two-party single-conversation scenario. Hence, the prolongation and transition of conversation topics are ignored by current methods. In this work, we frame response selection as a dynamic topic tracking task to match the topic between the response and relevant conversation context. With this new formulation, we propose a novel multi-task learning framework that supports efficient encoding through large pretrained models with only two utterances at once to perform dynamic topic disentanglement and response selection. We also propose Topic-BERT an essential pretraining step to embed topic information into BERT with self-supervised learning. Experimental results on the DSTC-8 Ubuntu IRC dataset show state-of-the-art results in response selection and topic disentanglement tasks outperforming existing methods by a good margin.",,https://d3i71xaburhd42.cloudfront.net/5b4fdb128ad7790ff3d72129a1f676abc05cd6a8/1-Figure1-1.png
Retrofitting Structure-aware Transformer Language Model for End Tasks,"['Hao Fei', 'Yafeng Ren', 'Donghong Ji']",http://arxiv.org/abs/2009.07408v1,"We consider retrofitting structure-aware Transformer-based language model for facilitating end tasks by proposing to exploit syntactic distance to encode both the phrasal constituency and dependency connection into the language model. A middle-layer structural learning strategy is leveraged for structure integration, accomplished with main semantic task training under multi-task learning scheme. Experimental results show that the retrofitted structure-aware Transformer language model achieves improved perplexity, meanwhile inducing accurate syntactic phrases. By performing structure-aware fine-tuning, our model achieves significant improvements for both semantic- and syntactic-dependent tasks.",,https://d3i71xaburhd42.cloudfront.net/d2ae43a84b50a9291858d431d42e4c00685289fc/1-Figure1-1.png
Revisiting modularized multilingual NMT to meet industrial demands,"['Sungwon Lyu', 'Bokyung Son', 'Kichang Yang', 'Jaekyoung Bae']",http://arxiv.org/abs/2010.09402v1,"The complete sharing of parameters for multilingual translation (1-1) has been the mainstream approach in current research. However, degraded performance due to the capacity bottleneck and low maintainability hinders its extensive adoption in industries. In this study, we revisit the multilingual neural machine translation model that only share modules among the same languages (M2) as a practical alternative to 1-1 to satisfy industrial requirements. Through comprehensive experiments, we identify the benefits of multi-way training and demonstrate that the M2 can enjoy these benefits without suffering from the capacity bottleneck. Furthermore, the interlingual space of the M2 allows convenient modification of the model. By leveraging trained modules, we find that incrementally added modules exhibit better performance than singly trained models. The zero-shot performance of the added modules is even comparable to supervised models. Our findings suggest that the M2 can be a competent candidate for multilingual translation in industries.",,https://d3i71xaburhd42.cloudfront.net/8dd1ccbef56f68a6f47c4d5b4fb1c7bc775acb62/2-Figure1-1.png
RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling,"['Jun Quan', 'Shian Zhang', 'Qian Cao', 'Zizhong Li', 'Deyi Xiong']",http://arxiv.org/abs/2010.08738v1,"In order to alleviate the shortage of multi-domain data and to capture discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a large-scale multi-domain Chinese Wizard-of-Oz dataset with Rich Semantic Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multi-turn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets. Both single- and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively. Each dialogue is labeled with comprehensive dialogue annotations, including dialogue goal in the form of natural language description, domain, dialogue states and acts at both the user and system side. In addition to traditional dialogue annotations, we especially provide linguistic annotations on discourse phenomena, e.g., ellipsis and coreference, in dialogues, which are useful for dialogue coreference and ellipsis resolution tasks. Apart from the fully annotated dataset, we also present a detailed description of the data collection procedure, statistics and analysis of the dataset. A series of benchmark models and results are reported, including natural language understanding (intent detection & slot filling), dialogue state tracking and dialogue context-to-text generation, as well as coreference and ellipsis resolution, which facilitate the baseline comparison for future research on this corpus.",,https://d3i71xaburhd42.cloudfront.net/26d4d6b52405b5b8670ca09728e2763f5c19377a/2-Table1-1.png
RNNs can generate bounded hierarchical languages with optimal memory,"['John Hewitt', 'Michael Hahn', 'Surya Ganguli', 'Percy Liang', 'Christopher D. Manning']",http://arxiv.org/abs/2010.07515v1,"Recurrent neural networks empirically generate natural language with high syntactic fidelity. However, their success is not well-understood theoretically. We provide theoretical insight into this success, proving in a finite-precision setting that RNNs can efficiently generate bounded hierarchical languages that reflect the scaffolding of natural language syntax. We introduce Dyck-($k$,$m$), the language of well-nested brackets (of $k$ types) and $m$-bounded nesting depth, reflecting the bounded memory needs and long-distance dependencies of natural language syntax. The best known results use $O(k^{\frac{m}{2}})$ memory (hidden units) to generate these languages. We prove that an RNN with $O(m \log k)$ hidden units suffices, an exponential reduction in memory, by an explicit construction. Finally, we show that no algorithm, even with unbounded computation, can suffice with $o(m \log k)$ hidden units.",,https://d3i71xaburhd42.cloudfront.net/d06e84ac9e912b415719f0e7f3163d59e0a329cd/1-Figure1-1.png
Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding,"['Alexander Ku', 'Peter Anderson', 'Roma Patel', 'Eugene Ie', 'Jason Baldridge']",http://arxiv.org/abs/2010.07954v1,"We introduce Room-Across-Room (RxR), a new Vision-and-Language Navigation (VLN) dataset. RxR is multilingual (English, Hindi, and Telugu) and larger (more paths and instructions) than other VLN datasets. It emphasizes the role of language in VLN by addressing known biases in paths and eliciting more references to visible entities. Furthermore, each word in an instruction is time-aligned to the virtual poses of instruction creators and validators. We establish baseline scores for monolingual and multilingual settings and multitask learning when including Room-to-Room annotations. We also provide results for a model that learns from synchronized pose traces by focusing only on portions of the panorama attended to in human demonstrations. The size, scope and detail of RxR dramatically expands the frontier for research on embodied language agents in simulated, photo-realistic environments.",,https://d3i71xaburhd42.cloudfront.net/5a94aaa3ad624608e46a75de49452a03de568a07/1-Figure1-1.png
Routing Enforced Generative Model for Recipe Generation,"['Zhiwei Yu', 'Hongyu Zang', 'Xiaojun Wan']",,,,
RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark,"['Tatiana Shavrina', 'Alena Fenogenova', 'Emelyanov Anton', 'Denis Shevelev', 'Ekaterina Artemova', 'Valentin Malykh', 'Vladislav Mikhailov', 'Maria Tikhonova', 'Andrey Chertok', 'Andrey Evlampiev']",,,,
Scalable Multi-Hop Relational Reasoning for Knowledge-Aware Question Answering,"['Yanlin Feng', 'Xinyue Chen', 'Bill Yuchen Lin', 'Peifeng Wang', 'Jun Yan', 'Xiang Ren']",http://arxiv.org/abs/2005.00646v2,"Existing work on augmenting question answering (QA) models with external knowledge (e.g., knowledge graphs) either struggle to model multi-hop relations efficiently, or lack transparency into the model's prediction rationale. In this paper, we propose a novel knowledge-aware approach that equips pre-trained language models (PTLMs) with a multi-hop relational reasoning module, named multi-hop graph relation network (MHGRN). It performs multi-hop, multi-relational reasoning over subgraphs extracted from external knowledge graphs. The proposed reasoning module unifies path-based reasoning methods and graph neural networks to achieve better interpretability and scalability. We also empirically show its effectiveness and scalability on CommonsenseQA and OpenbookQA datasets, and interpret its behaviors with case studies.",,https://d3i71xaburhd42.cloudfront.net/fc24216f48070d5a4ae52629b9025aba429d6e82/1-Figure1-1.png
Scalable Zero-shot Entity Linking with Dense Entity Retrieval,"['Ledell Wu', 'Fabio Petroni', 'Martin Josifoski', 'Sebastian Riedel', 'Luke Zettlemoyer']",http://arxiv.org/abs/1911.03814v3,"This paper introduces a conceptually simple, scalable, and highly effective BERT-based entity linking model, along with an extensive evaluation of its accuracy-speed trade-off. We present a two-stage zero-shot linking algorithm, where each entity is defined only by a short textual description. The first stage does retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then re-ranked with a cross-encoder, that concatenates the mention and entity text. Experiments demonstrate that this approach is state of the art on recent zero-shot benchmarks (6 point absolute gains) and also on more established non-zero-shot evaluations (e.g. TACKBP-2010), despite its relative simplicity (e.g. no explicit entity embeddings or manually engineered mention tables). We also show that bi-encoder linking is very fast with nearest neighbour search (e.g. linking with 5.9 million candidates in 2 milliseconds), and that much of the accuracy gain from the more expensive cross-encoder can be transferred to the bi-encoder via knowledge distillation. Our code and models are available at https://github.com/facebookresearch/BLINK.",,https://d3i71xaburhd42.cloudfront.net/592a6691373f3936631bc4ac122f69df09c842bd/2-Figure1-1.png
Scene Restoring for Narrative Machine Reading Comprehension,"['Zhixing Tian', 'Yuanzhe Zhang', 'Kang Liu', 'Jun Zhao', 'Yantao Jia', 'Zhicheng Sheng']",,,,
Selection and Generation: Learning towards Multi-Product Advertisement Post Generation,"['Zhangming Chan', 'Yuchi Zhang', 'Xiuying Chen', 'Shen Gao', 'Zhiqiang Zhang', 'Dongyan Zhao', 'Rui Yan']",,,,
Self-Induced Curriculum Learning in Self-Supervised Neural Machine Translation,"['Dana Ruiter', 'Josef van Genabith', 'Cristina España-Bonet']",http://arxiv.org/abs/2004.03151v2,"Self-supervised neural machine translation (SSNMT) jointly learns to identify and select suitable training data from comparable (rather than parallel) corpora and to translate, in a way that the two tasks support each other in a virtuous circle. In this study, we provide an in-depth analysis of the sampling choices the SSNMT model makes during training. We show how, without it having been told to do so, the model self-selects samples of increasing (i) complexity and (ii) task-relevance in combination with (iii) performing a denoising curriculum. We observe that the dynamics of the mutual-supervision signals of both system internal representation types are vital for the extraction and translation performance. We show that in terms of the Gunning-Fog Readability index, SSNMT starts extracting and learning from Wikipedia data suitable for high school students and quickly moves towards content suitable for first year undergraduate students.",,
Self-Supervised Knowledge Triplet Learning for Zero-shot Question Answering,"['Pratyay Banerjee', 'Chitta Baral']",http://arxiv.org/abs/2005.00316v2,"The aim of all Question Answering (QA) systems is to be able to generalize to unseen questions. Current supervised methods are reliant on expensive data annotation. Moreover, such annotations can introduce unintended annotator bias which makes systems focus more on the bias than the actual task. In this work, we propose Knowledge Triplet Learning (KTL), a self-supervised task over knowledge graphs. We propose heuristics to create synthetic graphs for commonsense and scientific knowledge. We propose methods of how to use KTL to perform zero-shot QA and our experiments show considerable improvements over large pre-trained transformer models.",,https://d3i71xaburhd42.cloudfront.net/0f86a865e52dd6c41b3fec4b87f3794fff1f224c/1-Figure1-1.png
Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks,"['Trapit Bansal', 'Rishikesh Jha', 'Tsendsuren Munkhdalai', 'Andrew McCallum']",,,,
Self-Supervised Text Planning for Paragraph Completion Task,"['Dongyeop Kang', 'Eduard Hovy']",http://arxiv.org/abs/2010.05141v1,"Despite the recent success of contextualized language models on various NLP tasks, language model itself cannot capture textual coherence of a long, multi-sentence document (e.g., a paragraph). Humans often make structural decisions on what and how to say about before making utterances. Guiding surface realization with such high-level decisions and structuring text in a coherent way is essentially called a planning process. Where can the model learn such high-level coherence? A paragraph itself contains various forms of inductive coherence signals called self-supervision in this work, such as sentence orders, topical keywords, rhetorical structures, and so on. Motivated by that, this work proposes a new paragraph completion task PARCOM; predicting masked sentences in a paragraph. However, the task suffers from predicting and selecting appropriate topical content with respect to the given context. To address that, we propose a self-supervised text planner SSPlanner that predicts what to say first (content prediction), then guides the pretrained language model (surface realization) using the predicted content. SSPlanner outperforms the baseline generation models on the paragraph completion task in both automatic and human evaluation. We also find that a combination of noun and verb types of keywords is the most effective for content selection. As more number of content keywords are provided, overall generation quality also increases.",,https://d3i71xaburhd42.cloudfront.net/06d2084c112802e9121083ec908197b8002cd6b5/2-Table1-1.png
SelfORE: Self-supervised Relational Feature Learning for Open Relation Extraction,"['Xuming Hu', 'Lijie Wen', 'Yusong Xu', 'Chenwei Zhang', 'Philip Yu']",http://arxiv.org/abs/2004.02438v2,"Open relation extraction is the task of extracting open-domain relation facts from natural language sentences. Existing works either utilize heuristics or distant-supervised annotations to train a supervised classifier over pre-defined relations, or adopt unsupervised methods with additional assumptions that have less discriminative power. In this work, we proposed a self-supervised framework named SelfORE, which exploits weak, self-supervised signals by leveraging large pretrained language model for adaptive clustering on contextualized relational features, and bootstraps the self-supervised signals by improving contextualized features in relation classification. Experimental results on three datasets show the effectiveness and robustness of SelfORE on open-domain Relation Extraction when comparing with competitive baselines.",,https://d3i71xaburhd42.cloudfront.net/860ae7d028df0a85d8f8b82fa2c7a817bcee10b7/2-Figure1-1.png
Semantic Evaluation for Text-to-SQL with Distilled Test Suite,"['Ruiqi Zhong', 'Tao Yu', 'Dan Klein']",http://arxiv.org/abs/2010.02840v1,"We propose test suite accuracy to approximate semantic accuracy for Text-to-SQL models. Our method distills a small test suite of databases that achieves high code coverage for the gold query from a large number of randomly generated databases. At evaluation time, it computes the denotation accuracy of the predicted queries on the distilled test suite, hence calculating a tight upper-bound for semantic accuracy efficiently. We use our proposed method to evaluate 21 models submitted to the Spider leader board and manually verify that our method is always correct on 100 examples. In contrast, the current Spider metric leads to a 2.5% false negative rate on average and 8.1% in the worst case, indicating that test suite accuracy is needed. Our implementation, along with distilled test suites for eleven Text-to-SQL datasets, is publicly available.",,https://d3i71xaburhd42.cloudfront.net/e6e8a2c56243847b77b604259cde9e10a2daccb8/1-Figure1-1.png
Semantic Role Labeling as Syntactic Dependency Parsing,"['Tianze Shi', 'Igor Malioutov', 'Ozan Irsoy']",,,,
Semantically-Aligned Universal Tree-Structured Solver for Math Word Problems,"['Jinghui Qin', 'Lihui Lin', 'Xiaodan Liang', 'Rumin Zhang', 'Liang Lin']",http://arxiv.org/abs/2010.06823v1,"A practical automatic textual math word problems (MWPs) solver should be able to solve various textual MWPs while most existing works only focused on one-unknown linear MWPs. Herein, we propose a simple but efficient method called Universal Expression Tree (UET) to make the first attempt to represent the equations of various MWPs uniformly. Then a semantically-aligned universal tree-structured solver (SAU-Solver) based on an encoder-decoder framework is proposed to resolve multiple types of MWPs in a unified model, benefiting from our UET representation. Our SAU-Solver generates a universal expression tree explicitly by deciding which symbol to generate according to the generated symbols' semantic meanings like human solving MWPs. Besides, our SAU-Solver also includes a novel subtree-level semanticallyaligned regularization to further enforce the semantic constraints and rationality of the generated expression tree by aligning with the contextual information. Finally, to validate the universality of our solver and extend the research boundary of MWPs, we introduce a new challenging Hybrid Math Word Problems dataset (HMWP), consisting of three types of MWPs. Experimental results on several MWPs datasets show that our model can solve universal types of MWPs and outperforms several state-of-the-art models.",,https://d3i71xaburhd42.cloudfront.net/f9c07ed1d2113c858b38861790af6a26310b8465/1-Figure1-1.png
Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction,"['Xu Zhao', 'Zihao Wang', 'Hao Wu', 'Yong Zhang']",http://arxiv.org/abs/2010.07101v1,"Semi-supervision is a promising paradigm for Bilingual Lexicon Induction (BLI) with limited annotations. However, previous semisupervised methods do not fully utilize the knowledge hidden in annotated and nonannotated data, which hinders further improvement of their performance. In this paper, we propose a new semi-supervised BLI framework to encourage the interaction between the supervised signal and unsupervised alignment. We design two message-passing mechanisms to transfer knowledge between annotated and non-annotated data, named prior optimal transport and bi-directional lexicon update respectively. Then, we perform semi-supervised learning based on a cyclic or a parallel parameter feeding routine to update our models. Our framework is a general framework that can incorporate any supervised and unsupervised BLI methods based on optimal transport. Experimental results on MUSE and VecMap datasets show significant improvement of our models. Ablation study also proves that the two-way interaction between the supervised signal and unsupervised alignment accounts for the gain of the overall performance. Results on distant language pairs further illustrate the advantage and robustness of our proposed method.",,https://d3i71xaburhd42.cloudfront.net/15678bfc6752de305a08a95ca74c03b7f6870047/3-Figure1-1.png
SentiLARE: Linguistic Knowledge Enhanced Language Representation for Sentiment Analysis,"['Pei Ke', 'Haozhe Ji', 'Siyang Liu', 'Xiaoyan Zhu', 'Minlie Huang']",,,,
Sentiment Analysis of Tweets using Heterogeneous Multi-layer Network Representation and Embedding,"['Loitongbam Gyanendro Singh', 'Anasua Mitra', 'Sanasam Ranbir Singh']",,,,
Seq2Edits: Sequence Transduction Using Span-level Edit Operations,"['Felix Stahlberg', 'Shankar Kumar']",http://arxiv.org/abs/2009.11136v1,"We propose Seq2Edits, an open-vocabulary approach to sequence editing for natural language processing (NLP) tasks with a high degree of overlap between input and output texts. In this approach, each sequence-to-sequence transduction is represented as a sequence of edit operations, where each operation either replaces an entire source span with target tokens or keeps it unchanged. We evaluate our method on five NLP tasks (text normalization, sentence fusion, sentence splitting & rephrasing, text simplification, and grammatical error correction) and report competitive results across the board. For grammatical error correction, our method speeds up inference by up to 5.2x compared to full sequence models because inference time depends on the number of edits rather than the number of target tokens. For text normalization, sentence fusion, and grammatical error correction, our approach improves explainability by associating each edit operation with a human-readable tag.",,https://d3i71xaburhd42.cloudfront.net/58ef9f9682c0ae4561dc30079a52867f108f704e/2-Figure1-1.png
SeqMix: Augmenting Active Sequence Labeling via Sequence Mixup,"['Rongzhi Zhang', 'Yue Yu', 'Chao Zhang']",http://arxiv.org/abs/2010.02322v1,"Active learning is an important technique for low-resource sequence labeling tasks. However, current active sequence labeling methods use the queried samples alone in each iteration, which is an inefficient way of leveraging human annotations. We propose a simple but effective data augmentation method to improve the label efficiency of active sequence labeling. Our method, SeqMix, simply augments the queried samples by generating extra labeled sequences in each iteration. The key difficulty is to generate plausible sequences along with token-level labels. In SeqMix, we address this challenge by performing mixup for both sequences and token-level labels of the queried samples. Furthermore, we design a discriminator during sequence mixup, which judges whether the generated sequences are plausible or not. Our experiments on Named Entity Recognition and Event Detection tasks show that SeqMix can improve the standard active sequence labeling method by $2.27\%$--$3.75\%$ in terms of $F_1$ scores. The code and data for SeqMix can be found at https://github.com/rz-zhang/SeqMix",,https://d3i71xaburhd42.cloudfront.net/3bb1e24eb3429f807397833105d1e137d9927767/5-Figure1-1.png
Sequential Modelling of the Evolution of Word Representations for Semantic Change Detection,"['Adam Tsakalidis', 'Maria Liakata']",,,,
SetConv: A New Approach for Learning from Imbalanced Data,"['Yang Gao', 'Yi-Fan Li', 'Yu Lin', 'Charu Aggarwal', 'Latifur Khan']",,,,
Shallow-to-Deep Training for Neural Machine Translation,"['Bei Li', 'Ziyang Wang', 'Hui Liu', 'Yufan Jiang', 'Quan Du', 'Tong Xiao', 'Huizhen Wang', 'Jingbo Zhu']",http://arxiv.org/abs/2010.03737v1,"Deep encoders have been proven to be effective in improving neural machine translation (NMT) systems, but training an extremely deep encoder is time consuming. Moreover, why deep models help NMT is an open question. In this paper, we investigate the behavior of a well-tuned deep Transformer system. We find that stacking layers is helpful in improving the representation ability of NMT models and adjacent layers perform similarly. This inspires us to develop a shallow-to-deep training method that learns deep models by stacking shallow models. In this way, we successfully train a Transformer system with a 54-layer encoder. Experimental results on WMT'16 English-German and WMT'14 English-French translation tasks show that it is $1.4$ $\times$ faster than training from scratch, and achieves a BLEU score of $30.33$ and $43.29$ on two tasks. The code is publicly available at https://github.com/libeineu/SDT-Training/.",,https://d3i71xaburhd42.cloudfront.net/53af14897ccca4f8d6c465ee133e859f99ddd7e7/2-Figure1-1.png
Short Text Topic Modeling with Topic Distribution Quantization and Negative Sampling Decoder,"['Xiaobao Wu', 'Chunping Li', 'Yan Zhu', 'Yishu Miao']",,,,
Simultaneous Machine Translation with Visual Context,"['Ozan Caglayan', 'Julia Ive', 'Veneta Haralampieva', 'Pranava Madhyastha', 'Loïc Barrault', 'Lucia Specia']",http://arxiv.org/abs/2009.07310v3,"Simultaneous machine translation (SiMT) aims to translate a continuous input text stream into another language with the lowest latency and highest quality possible. The translation thus has to start with an incomplete source text, which is read progressively, creating the need for anticipation. In this paper, we seek to understand whether the addition of visual information can compensate for the missing source context. To this end, we analyse the impact of different multimodal approaches and visual features on state-of-the-art SiMT frameworks. Our results show that visual context is helpful and that visually-grounded models based on explicit object region information are much better than commonly used global features, reaching up to 3 BLEU points improvement under low latency scenarios. Our qualitative analysis illustrates cases where only the multimodal systems are able to translate correctly from English into gender-marked languages, as well as deal with differences in word order, such as adjective-noun placement between English and French.",,https://d3i71xaburhd42.cloudfront.net/54d0a84d8548c42700e804ce834c03740887567d/1-Figure1-1.png
SLM: Learning a Discourse Language Representation with Sentence Unshuffling,"['Haejun Lee', 'Drew A. Hudson', 'Kangwook Lee', 'Christopher D. Manning']",,,,
Slot Attention with Value Normalization for Multi-domain Dialogue State Tracking,"['Yexiang Wang', 'Yi Guo', 'Siqi Zhu']",,,,
SLURP: A Spoken Language Understanding Resource Package,"['Emanuele Bastianelli', 'Andrea Vanzo', 'Pawel Swietojanski', 'Verena Rieser']",,,,
Social Chemistry 101: Learning to Reason about Social and Moral Norms,"['Maxwell Forbes', 'Jena D. Hwang', 'Vered Shwartz', 'Maarten Sap', 'Yejin Choi']",,,,
Social Media Attributions in the Context of Water Crisis,"['Rupak Sarkar', 'Sayantan Mahinder', 'Hirak Sarkar', 'Ashiqur KhudaBukhsh']",http://arxiv.org/abs/2001.01697v1,"Attribution of natural disasters/collective misfortune is a widely-studied political science problem. However, such studies are typically survey-centric or rely on a handful of experts to weigh in on the matter. In this paper, we explore how can we use social media data and an AI-driven approach to complement traditional surveys and automatically extract attribution factors. We focus on the most-recent Chennai water crisis which started off as a regional issue but rapidly escalated into a discussion topic with global importance following alarming water-crisis statistics. Specifically, we present a novel prediction task of attribution tie detection which identifies the factors held responsible for the crisis (e.g., poor city planning, exploding population etc.). On a challenging data set constructed from YouTube comments (72,098 comments posted by 43,859 users on 623 relevant videos to the crisis), we present a neural classifier to extract attribution ties that achieved a reasonable performance (Accuracy: 81.34\% on attribution detection and 71.19\% on attribution resolution).",,https://d3i71xaburhd42.cloudfront.net/4af9214f7e2e9fb21273c065ea5a7cb5db0cdf94/2-Table1-1.png
Solving Historical Dictionary Codes with a Neural Language Model,"['Christopher Chu', 'Raphael Valenti', 'Kevin Knight']",http://arxiv.org/abs/2010.04746v1,"We solve difficult word-based substitution codes by constructing a decoding lattice and searching that lattice with a neural language model. We apply our method to a set of enciphered letters exchanged between US Army General James Wilkinson and agents of the Spanish Crown in the late 1700s and early 1800s, obtained from the US Library of Congress. We are able to decipher 75.1% of the cipher-word tokens correctly.",,https://d3i71xaburhd42.cloudfront.net/57c183310a588470cd92b96fcc4243b27a12445c/1-Figure1-1.png
Span-based discontinuous constituency parsing: a family of exact chart-based algorithms with time complexities from O(n^6) down to O(n^3),['Caio Corro'],http://arxiv.org/abs/2003.13785v1,"We introduce a novel chart-based algorithm for span-based parsing of discontinuous constituency trees of block degree two, including ill-nested structures. In particular, we show that we can build variants of our parser with smaller search spaces and time complexities ranging from $\mathcal O(n^6)$ down to $\mathcal O(n^3)$. The cubic time variant covers 98\% of constituents observed in linguistic treebanks while having the same complexity as continuous constituency parsers. We evaluate our approach on German and English treebanks (Negra, Tiger and Discontinuous PTB) and report state-of-the-art results in the fully supervised setting. We also experiment with pre-trained word embeddings and \bert{}-based neural networks.",,https://d3i71xaburhd42.cloudfront.net/04edbe5f52f97ca2349e189431cda013194121c2/2-Figure1-1.png
Sparse Parallel Training for Hierarchical Dirichlet Process Topic Models,"['Alexander Terenin', 'Måns Magnusson', 'Leif Jonsson']",http://arxiv.org/abs/1906.02416v2,"To scale non-parametric extensions of probabilistic topic models such as Latent Dirichlet allocation to larger data sets, practitioners rely increasingly on parallel and distributed systems. In this work, we study data-parallel training for the hierarchical Dirichlet process (HDP) topic model. Based upon a representation of certain conditional distributions within an HDP, we propose a doubly sparse data-parallel sampler for the HDP topic model. This sampler utilizes all available sources of sparsity found in natural language - an important way to make computation efficient. We benchmark our method on a well-known corpus (PubMed) with 8m documents and 768m tokens, using a single multi-core machine in under four days.",,https://d3i71xaburhd42.cloudfront.net/026abb9905addd5dbdf954f3c906f63586dda736/2-Table1-1.png
Sparse Text Generation,"['Pedro Henrique Martins', 'Zita Marinho', 'André F. T. Martins']",http://arxiv.org/abs/2004.02644v3,"Current state-of-the-art text generators build on powerful language models such as GPT-2, achieving impressive performance. However, to avoid degenerate text, they require sampling from a modified softmax, via temperature parameters or ad-hoc truncation techniques, as in top-$k$ or nucleus sampling. This creates a mismatch between training and testing conditions. In this paper, we use the recently introduced entmax transformation to train and sample from a natively sparse language model, avoiding this mismatch. The result is a text generator with favorable performance in terms of fluency and consistency, fewer repetitions, and n-gram diversity closer to human text. In order to evaluate our model, we propose three new metrics for comparing sparse or truncated distributions: $\epsilon$-perplexity, sparsemax score, and Jensen-Shannon divergence. Human-evaluated experiments in story completion and dialogue generation show that entmax sampling leads to more engaging and coherent stories and conversations.",,https://d3i71xaburhd42.cloudfront.net/3a5f479d15a3300a2fbfb868f80339431b452a5b/1-Table1-1.png
Sparsity Makes Sense: Word Sense Disambiguation Using Sparse Contextualized Word Representations,['Gábor Berend'],,,,
Speakers Fill Semantic Gaps with Context,"['Tiago Pimentel', 'Rowan Hall Maudslay', 'Damian Blasi', 'Ryan Cotterell']",http://arxiv.org/abs/2010.02172v1,"Lexical ambiguity is widespread in language, allowing for the reuse of economical word forms and therefore making language more efficient. If ambiguous words cannot be disambiguated from context, however, this gain in efficiency might make language less clear---resulting in frequent miscommunication. For a language to be clear and efficiently encoded, we posit that the lexical ambiguity of a word type should correlate with how much information context provides about it, on average. To investigate whether this is the case, we operationalise the lexical ambiguity of a word as the entropy of meanings it can take, and provide two ways to estimate this---one which requires human annotation (using WordNet), and one which does not (using BERT), making it readily applicable to a large number of languages. We validate these measures by showing that, on six high-resource languages, there are significant Pearson correlations between our BERT-based estimate of ambiguity and the number of synonyms a word has in WordNet (e.g. $\rho = 0.40$ in English). We then test our main hypothesis---that a word's lexical ambiguity should negatively correlate with its contextual uncertainty---and find significant correlations on all 18 typologically diverse languages we analyse. This suggests that, in the presence of ambiguity, speakers compensate by making contexts more informative.",,
Spot The Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems,"['Jan Deriu', 'Don Tuggener', 'Pius von Däniken', 'Jon Ander Campos', 'Alvaro Rodrigo', 'Thiziri Belkacem', 'Aitor Soroa', 'Eneko Agirre', 'Mark Cieliebak']",http://arxiv.org/abs/2010.02140v1,"The lack of time-efficient and reliable evaluation methods hamper the development of conversational dialogue systems (chatbots). Evaluations requiring humans to converse with chatbots are time and cost-intensive, put high cognitive demands on the human judges, and yield low-quality results. In this work, we introduce \emph{Spot The Bot}, a cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots. Human judges then only annotate for each entity in a conversation whether they think it is human or not (assuming there are humans participants in these conversations). These annotations then allow us to rank chatbots regarding their ability to mimic the conversational behavior of humans. Since we expect that all bots are eventually recognized as such, we incorporate a metric that measures which chatbot can uphold human-like behavior the longest, i.e., \emph{Survival Analysis}. This metric has the ability to correlate a bot's performance to certain of its characteristics (e.g., \ fluency or sensibleness), yielding interpretable results. The comparably low cost of our framework allows for frequent evaluations of chatbots during their evaluation cycle. We empirically validate our claims by applying \emph{Spot The Bot} to three domains, evaluating several state-of-the-art chatbots, and drawing comparisons to related work. The framework is released as a ready-to-use tool.",,https://d3i71xaburhd42.cloudfront.net/9c72b6a869cbec916d5e6b05c4ea36056c93c52c/3-Figure1-1.png
SRLGRN: Semantic Role Labeling Graph Reasoning Network,"['Chen Zheng', 'Parisa Kordjamshidi']",http://arxiv.org/abs/2010.03604v1,"This work deals with the challenge of learning and reasoning over multi-hop question answering (QA). We propose a graph reasoning network based on the semantic structure of the sentences to learn cross paragraph reasoning paths and find the supporting facts and the answer jointly. The proposed graph is a heterogeneous document-level graph that contains nodes of type sentence (question, title, and other sentences), and semantic role labeling sub-graphs per sentence that contain arguments as nodes and predicates as edges. Incorporating the argument types, the argument phrases, and the semantics of the edges originated from SRL predicates into the graph encoder helps in finding and also the explainability of the reasoning paths. Our proposed approach shows competitive performance on the HotpotQA distractor setting benchmark compared to the recent state-of-the-art models.",,https://d3i71xaburhd42.cloudfront.net/f43b961048255ebdf04d13ff95eb60a0f07e8c98/1-Figure1-1.png
SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness,"['Nathan Ng', 'Kyunghyun Cho', 'Marzyeh Ghassemi']",http://arxiv.org/abs/2009.10195v2,"Models that perform well on a training domain often fail to generalize to out-of-domain (OOD) examples. Data augmentation is a common method used to prevent overfitting and improve OOD generalization. However, in natural language, it is difficult to generate new examples that stay on the underlying data manifold. We introduce SSMBA, a data augmentation method for generating synthetic training examples by using a pair of corruption and reconstruction functions to move randomly on a data manifold. We investigate the use of SSMBA in the natural language domain, leveraging the manifold assumption to reconstruct corrupted text with masked language models. In experiments on robustness benchmarks across 3 tasks and 9 datasets, SSMBA consistently outperforms existing data augmentation methods and baseline models on both in-domain and OOD data, achieving gains of 0.8% accuracy on OOD Amazon reviews, 1.8% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 German-English.",,https://d3i71xaburhd42.cloudfront.net/67f343b5212d3a71965d2c217bb567f8af0bbcdb/1-Figure1-1.png
Stepwise Extractive Summarization and Planning with Structured Transformers,"['Shashi Narayan', 'Joshua Maynez', 'Jakub Adamek', 'Daniele Pighin', 'Blaz Bratanic', 'Ryan McDonald']",http://arxiv.org/abs/2010.02744v1,"We propose encoder-centric stepwise models for extractive summarization using structured transformers -- HiBERT and Extended Transformers. We enable stepwise summarization by injecting the previously generated summary into the structured transformer as an auxiliary sub-structure. Our models are not only efficient in modeling the structure of long inputs, but they also do not rely on task-specific redundancy-aware modeling, making them a general purpose extractive content planner for different tasks. When evaluated on CNN/DailyMail extractive summarization, stepwise models achieve state-of-the-art performance in terms of Rouge without any redundancy aware modeling or sentence filtering. This also holds true for Rotowire table-to-text generation, where our models surpass previously reported metrics for content selection, planning and ordering, highlighting the strength of stepwise modeling. Amongst the two structured transformers we test, stepwise Extended Transformers provides the best performance across both datasets and sets a new standard for these challenges.",,https://d3i71xaburhd42.cloudfront.net/46e7383e6fb8da77479d0a828c7a24d924302169/4-Figure1-1.png
STL-CQA: Structure-based Transformers with Localization and Encoding for Chart Question Answering,"['Hrituraj Singh', 'Sumit Shekhar']",,,,
Structural Supervision Improves Few-Shot Learning and Syntactic Generalization in Neural Language Models,"['Ethan Wilcox', 'Peng Qian', 'Richard Futrell', 'Ryosuke Kohita', 'Roger Levy', 'Miguel Ballesteros']",http://arxiv.org/abs/2010.05725v1,"Humans can learn structural properties about a word from minimal experience, and deploy their learned syntactic representations uniformly in different grammatical contexts. We assess the ability of modern neural language models to reproduce this behavior in English and evaluate the effect of structural supervision on learning outcomes. First, we assess few-shot learning capabilities by developing controlled experiments that probe models' syntactic nominal number and verbal argument structure generalizations for tokens seen as few as two times during training. Second, we assess invariance properties of learned representation: the ability of a model to transfer syntactic generalizations from a base context (e.g., a simple declarative active-voice sentence) to a transformed context (e.g., an interrogative sentence). We test four models trained on the same dataset: an n-gram baseline, an LSTM, and two LSTM-variants trained with explicit structural supervision (Dyer et al.,2016; Charniak et al., 2016). We find that in most cases, the neural models are able to induce the proper syntactic generalizations after minimal exposure, often from just two examples during training, and that the two structurally supervised models generalize more accurately than the LSTM model. All neural models are able to leverage information learned in base contexts to drive expectations in transformed contexts, indicating that they have learned some invariance properties of syntax.",,https://d3i71xaburhd42.cloudfront.net/df8108f1f803c92e6d00d1244a355a35c3d64fa6/3-Figure1-1.png
Structured Attention for Unsupervised Dialogue Structure Induction,"['Liang Qiu', 'Yizhou Zhao', 'Weiyan Shi', 'Yuan Liang', 'Feng Shi', 'Tao Yuan', 'Zhou Yu', 'Song-Chun Zhu']",http://arxiv.org/abs/2009.08552v2,"Inducing a meaningful structural representation from one or a set of dialogues is a crucial but challenging task in computational linguistics. Advancement made in this area is critical for dialogue system design and discourse analysis. It can also be extended to solve grammatical inference. In this work, we propose to incorporate structured attention layers into a Variational Recurrent Neural Network (VRNN) model with discrete latent states to learn dialogue structure in an unsupervised fashion. Compared to a vanilla VRNN, structured attention enables a model to focus on different parts of the source sentence embeddings while enforcing a structural inductive bias. Experiments show that on two-party dialogue datasets, VRNN with structured attention learns semantic structures that are similar to templates used to generate this dialogue corpus. While on multi-party dialogue datasets, our model learns an interactive structure demonstrating its capability of distinguishing speakers or addresses, automatically disentangling dialogues without explicit human annotation.",,https://d3i71xaburhd42.cloudfront.net/40e9deebb5f73a9bf907f0ca72d4524e952be854/1-Figure1-1.png
Structured Pruning of Large Language Models,"['Ziheng Wang', 'Jeremy Wohlwend', 'Tao Lei']",http://arxiv.org/abs/1910.04732v1,"Large language models have recently achieved state of the art performance across a wide variety of natural language tasks. Meanwhile, the size of these models and their latency have significantly increased, which makes their usage costly, and raises an interesting question: do language models need to be large? We study this question through the lens of model compression. We present a novel, structured pruning approach based on low rank factorization and augmented Lagrangian L0 norm regularization. Our structured approach achieves significant inference speedups while matching or outperforming our unstructured pruning baseline at various sparsity levels. We apply our method to state of the art models on the enwiki8 dataset and obtain a 1.19 perplexity score with just 5M parameters, vastly outperforming a model of the same size trained from scratch. We also demonstrate that our method can be applied to language model fine-tuning by pruning the BERT model on several downstream classification benchmarks.",,https://d3i71xaburhd42.cloudfront.net/83b8108014e3db4f46354a28ae68193f143c4e7e/5-Table1-1.png
Sub-Instruction Aware Vision-and-Language Navigation,"['Yicong Hong', 'Cristian Rodriguez', 'Qi Wu', 'Stephen Gould']",http://arxiv.org/abs/2004.02707v2,"Vision-and-language navigation requires an agent to navigate through a real 3D environment following natural language instructions. Despite significant advances, few previous works are able to fully utilize the strong correspondence between the visual and textual sequences. Meanwhile, due to the lack of intermediate supervision, the agent's performance at following each part of the instruction cannot be assessed during navigation. In this work, we focus on the granularity of the visual and language sequences as well as the traceability of agents through the completion of an instruction. We provide agents with fine-grained annotations during training and find that they are able to follow the instruction better and have a higher chance of reaching the target at test time. We enrich the benchmark dataset Room-to-Room (R2R) with sub-instructions and their corresponding paths. To make use of this data, we propose effective sub-instruction attention and shifting modules that select and attend to a single sub-instruction at each time-step. We implement our sub-instruction modules in four state-of-the-art agents, compare with their baseline models, and show that our proposed method improves the performance of all four agents. We release the Fine-Grained R2R dataset (FGR2R) and the code at https://github.com/YicongHong/Fine-Grained-R2R.",,https://d3i71xaburhd42.cloudfront.net/f09e5903530e035e0d4b68fd63fb515d076d1354/1-Figure1-1.png
SubjQA: A Dataset for Subjectivity and Review Comprehension,"['Johannes Bjerva', 'Nikita Bhutani', 'Behzad Golshan', 'Wang-Chiew Tan', 'Isabelle Augenstein']",http://arxiv.org/abs/2004.14283v3,"Subjectivity is the expression of internal opinions or beliefs which cannot be objectively observed or verified, and has been shown to be important for sentiment analysis and word-sense disambiguation. Furthermore, subjectivity is an important aspect of user-generated data. In spite of this, subjectivity has not been investigated in contexts where such data is widespread, such as in question answering (QA). We therefore investigate the relationship between subjectivity and QA, while developing a new dataset. We compare and contrast with analyses from previous work, and verify that findings regarding subjectivity still hold when using recently developed NLP architectures. We find that subjectivity is also an important feature in the case of QA, albeit with more intricate interactions between subjectivity and QA performance. For instance, a subjective question may or may not be associated with a subjective answer. We release an English QA dataset (SubjQA) based on customer reviews, containing subjectivity annotations for questions and answer spans across 6 distinct domains.",,
Substance over Style: Document-Level Targeted Content Transfer,"['Allison Hegel', 'Sudha Rao', 'Asli Celikyilmaz', 'Bill Dolan']",http://arxiv.org/abs/2010.08618v1,"Existing language models excel at writing from scratch, but many real-world scenarios require rewriting an existing document to fit a set of constraints. Although sentence-level rewriting has been fairly well-studied, little work has addressed the challenge of rewriting an entire document coherently. In this work, we introduce the task of document-level targeted content transfer and address it in the recipe domain, with a recipe as the document and a dietary restriction (such as vegan or dairy-free) as the targeted constraint. We propose a novel model for this task based on the generative pre-trained language model (GPT-2) and train on a large number of roughly-aligned recipe pairs (https://github.com/microsoft/document-level-targeted-content-transfer). Both automatic and human evaluations show that our model out-performs existing methods by generating coherent and diverse rewrites that obey the constraint while remaining close to the original document. Finally, we analyze our model's rewrites to assess progress toward the goal of making language generation more attuned to constraints that are substantive rather than stylistic.",,https://d3i71xaburhd42.cloudfront.net/03763454e488be8530468b3f99c93d5211c7748f/1-Figure1-1.png
Surprisal Predicts Code-Switching in Chinese-English Bilingual Text,"['Jesús Calvillo', 'Le Fang', 'Jeremy Cole', 'David Reitter']",,,,
SynSetExpan: An Iterative Framework for Joint Entity Set Expansion and Synonym Discovery,"['Jiaming Shen', 'Wenda Qiu', 'Jingbo Shang', 'Michelle Vanni', 'Xiang Ren', 'Jiawei Han']",http://arxiv.org/abs/2009.13827v1,"Entity set expansion and synonym discovery are two critical NLP tasks. Previous studies accomplish them separately, without exploring their interdependencies. In this work, we hypothesize that these two tasks are tightly coupled because two synonymous entities tend to have similar likelihoods of belonging to various semantic classes. This motivates us to design SynSetExpan, a novel framework that enables two tasks to mutually enhance each other. SynSetExpan uses a synonym discovery model to include popular entities' infrequent synonyms into the set, which boosts the set expansion recall. Meanwhile, the set expansion model, being able to determine whether an entity belongs to a semantic class, can generate pseudo training data to fine-tune the synonym discovery model towards better accuracy. To facilitate the research on studying the interplays of these two tasks, we create the first large-scale Synonym-Enhanced Set Expansion (SE2) dataset via crowdsourcing. Extensive experiments on the SE2 dataset and previous benchmarks demonstrate the effectiveness of SynSetExpan for both entity set expansion and synonym discovery tasks.",,https://d3i71xaburhd42.cloudfront.net/2827dc0c707233cc575ecd162c343f0da2de9095/1-Figure1-1.png
Systematic Comparison of Neural Architectures and Training Approaches for Open Information Extraction,"['Patrick Hohenecker', 'Frank Mtumbuka', 'Vid Kocijan', 'Thomas Lukasiewicz']",,,,
T3: Tree-Autoencoder Regularized Adversarial Text Generation for Targeted Attack,"['Boxin Wang', 'Hengzhi Pei', 'Boyuan Pan', 'Qian Chen', 'Shuohang Wang', 'Bo Li']",http://arxiv.org/abs/1912.10375v2,"Adversarial attacks against natural language processing systems, which perform seemingly innocuous modifications to inputs, can induce arbitrary mistakes to the target models. Though raised great concerns, such adversarial attacks can be leveraged to estimate the robustness of NLP models. Compared with the adversarial example generation in continuous data domain (e.g., image), generating adversarial text that preserves the original meaning is challenging since the text space is discrete and non-differentiable. To handle these challenges, we propose a target-controllable adversarial attack framework T3, which is applicable to a range of NLP tasks. In particular, we propose a tree-based autoencoder to embed the discrete text data into a continuous representation space, upon which we optimize the adversarial perturbation. A novel tree-based decoder is then applied to regularize the syntactic correctness of the generated text and manipulate it on either sentence (T3(Sent)) or word (T3(Word)) level. We consider two most representative NLP tasks: sentiment analysis and question answering (QA). Extensive experimental results and human studies show that T3 generated adversarial texts can successfully manipulate the NLP models to output the targeted incorrect answer without misleading the human. Moreover, we show that the generated adversarial texts have high transferability which enables the black-box attacks in practice. Our work sheds light on an effective and general way to examine the robustness of NLP models. Our code is publicly available at https://github.com/AI-secure/T3/.",,
Tackling the Low-resource Challenge for Canonical Segmentation,"['Manuel Mager', 'Özlem Çetinoğlu', 'Katharina Kann']",http://arxiv.org/abs/2010.02804v1,"Canonical morphological segmentation consists of dividing words into their standardized morphemes. Here, we are interested in approaches for the task when training data is limited. We compare model performance in a simulated low-resource setting for the high-resource languages German, English, and Indonesian to experiments on new datasets for the truly low-resource languages Popoluca and Tepehua. We explore two new models for the task, borrowing from the closely related area of morphological generation: an LSTM pointer-generator and a sequence-to-sequence model with hard monotonic attention trained with imitation learning. We find that, in the low-resource setting, the novel approaches outperform existing ones on all languages by up to 11.4% accuracy. However, while accuracy in emulated low-resource scenarios is over 50% for all languages, for the truly low-resource languages Popoluca and Tepehua, our best model only obtains 37.4% and 28.4% accuracy, respectively. Thus, we conclude that canonical segmentation is still a challenging task for low-resource languages.",,https://d3i71xaburhd42.cloudfront.net/fd2dc47c38945c0364641ac1085239b076454d40/1-Figure1-1.png
Targeted Finetuning for NMT with Conditional Generative-Discriminative Loss,"['Prathyusha Jwalapuram', 'Shafiq Joty', 'Youlin Shen']",,,,
Task-Completion Dialogue Policy Learning via Monte Carlo Tree Search with Dueling Network,"['Sihan Wang', 'kaijie zhou', 'Kunfeng Lai', 'Jianping Shen']",,,,
"Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based Sentiment Analysis","['Xiaoyu Xing', 'Zhijing Jin', 'Di Jin', 'Bingning Wang', 'Qi Zhang', 'Xuanjing Huang']",http://arxiv.org/abs/2009.07964v3,"Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards a specific aspect in the text. However, existing ABSA test sets cannot be used to probe whether a model can distinguish the sentiment of the target aspect from the non-target aspects. To solve this problem, we develop a simple but effective approach to enrich ABSA test sets. Specifically, we generate new examples to disentangle the confounding sentiments of the non-target aspects from the target aspect's sentiment. Based on the SemEval 2014 dataset, we construct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the aspect robustness of ABSA models. Over 92% data of ARTS show high fluency and desired sentiment on all aspects by human evaluation. Using ARTS, we analyze the robustness of nine ABSA models, and observe, surprisingly, that their accuracy drops by up to 69.73%. We explore several ways to improve aspect robustness, and find that adversarial training can improve models' performance on ARTS by up to 32.85%. Our code and new test set are available at https://github.com/zhijing-jin/ARTS_TestSet",,https://d3i71xaburhd42.cloudfront.net/289acc534f43eacf841f61038908152ceea6b16c/2-Table1-1.png
TeaForN: Teacher-Forcing with N-grams,"['Sebastian Goodman', 'Nan Ding', 'Radu Soricut']",http://arxiv.org/abs/2010.03494v2,"Sequence generation models trained with teacher-forcing suffer from issues related to exposure bias and lack of differentiability across timesteps. Our proposed method, Teacher-Forcing with N-grams (TeaForN), addresses both these problems directly, through the use of a stack of N decoders trained to decode along a secondary time axis that allows model parameter updates based on N prediction steps. TeaForN can be used with a wide class of decoder architectures and requires minimal modifications from a standard teacher-forcing setup. Empirically, we show that TeaForN boosts generation quality on one Machine Translation benchmark, WMT 2014 English-French, and two News Summarization benchmarks, CNN/Dailymail and Gigaword.",,https://d3i71xaburhd42.cloudfront.net/3a35bf4eb3d6bc8931e52e2cf95dc5187b96804c/3-Figure1-1.png
TED-CDB: A Large-Scale Chinese Discourse Relation Dataset on TED Talks,"['Wanqiu Long', 'Bonnie Webber', 'Deyi Xiong']",,,,
Tell Me How to Ask Again: Question Data Augmentation with Controllable Rewriting in Continuous Space,"['Dayiheng Liu', 'Yeyun Gong', 'Jie Fu', 'Yu Yan', 'Jiusheng Chen', 'Jiancheng Lv', 'Nan Duan', 'Ming Zhou']",http://arxiv.org/abs/2010.01475v1,"In this paper, we propose a novel data augmentation method, referred to as Controllable Rewriting based Question Data Augmentation (CRQDA), for machine reading comprehension (MRC), question generation, and question-answering natural language inference tasks. We treat the question data augmentation task as a constrained question rewriting problem to generate context-relevant, high-quality, and diverse question data samples. CRQDA utilizes a Transformer autoencoder to map the original discrete question into a continuous embedding space. It then uses a pre-trained MRC model to revise the question representation iteratively with gradient-based optimization. Finally, the revised question representations are mapped back into the discrete space, which serve as additional question data. Comprehensive experiments on SQuAD 2.0, SQuAD 1.1 question generation, and QNLI tasks demonstrate the effectiveness of CRQDA",,https://d3i71xaburhd42.cloudfront.net/0b3c09efb22ed51d976cdc78d679fcc44fcdd3c6/4-Figure1-1.png
TeMP: Temporal Message Passing for Temporal Knowledge Graph Completion,"['Jiapeng Wu', 'Meng Cao', 'Jackie Chi Kit Cheung', 'William L. Hamilton']",http://arxiv.org/abs/2010.03526v1,"Inferring missing facts in temporal knowledge graphs (TKGs) is a fundamental and challenging task. Previous works have approached this problem by augmenting methods for static knowledge graphs to leverage time-dependent representations. However, these methods do not explicitly leverage multi-hop structural information and temporal facts from recent time steps to enhance their predictions. Additionally, prior work does not explicitly address the temporal sparsity and variability of entity distributions in TKGs. We propose the Temporal Message Passing (TeMP) framework to address these challenges by combining graph neural networks, temporal dynamics models, data imputation and frequency-based gating techniques. Experiments on standard TKG tasks show that our approach provides substantial gains compared to the previous state of the art, achieving a 10.7% average relative improvement in Hits@10 across three standard benchmarks. Our analysis also reveals important sources of variability both within and across TKG datasets, and we introduce several simple but strong baselines that outperform the prior state of the art in certain settings.",,https://d3i71xaburhd42.cloudfront.net/c50143bbe3a913950f9c07c30f58fa4782e775c4/2-Figure1-1.png
Template Guided Text Generation for Task Oriented Dialogue,"['Mihir Kale', 'Abhinav Rastogi']",,,,
Temporal Knowledge Base Completion: New Algorithms and Evaluation Protocols,"['Prachi Jain', 'Sushant Rathi', 'Mausam -', 'Soumen Chakrabarti']",http://arxiv.org/abs/2005.05035v2,"Temporal knowledge bases associate relational (s,r,o) triples with a set of times (or a single time instant) when the relation is valid. While time-agnostic KB completion (KBC) has witnessed significant research, temporal KB completion (TKBC) is in its early days. In this paper, we consider predicting missing entities (link prediction) and missing time intervals (time prediction) as joint TKBC tasks where entities, relations, and time are all embedded in a uniform, compatible space. We present TIMEPLEX, a novel time-aware KBC method, that also automatically exploits the recurrent nature of some relations and temporal interactions between pairs of relations. TIMEPLEX achieves state-of-the-art performance on both prediction tasks. We also find that existing TKBC models heavily overestimate link prediction performance due to imperfect evaluation mechanisms. In response, we propose improved TKBC evaluation protocols for both link and time prediction tasks, dealing with subtle issues that arise from the partial overlap of time intervals in gold instances and system predictions.",,https://d3i71xaburhd42.cloudfront.net/012c5dfc6023abc182598a6ab4ef9184d3b1c5df/4-Table1-1.png
TernaryBERT: Distillation-aware Ultra-low Bit BERT,"['Wei Zhang', 'Lu Hou', 'Yichun Yin', 'Lifeng Shang', 'Xiao Chen', 'Xin Jiang', 'Qun Liu']",http://arxiv.org/abs/2009.12812v3,"Transformer-based pre-training models like BERT have achieved remarkable performance in many natural language processing tasks.However, these models are both computation and memory expensive, hindering their deployment to resource-constrained devices. In this work, we propose TernaryBERT, which ternarizes the weights in a fine-tuned BERT model. Specifically, we use both approximation-based and loss-aware ternarization methods and empirically investigate the ternarization granularity of different parts of BERT. Moreover, to reduce the accuracy degradation caused by the lower capacity of low bits, we leverage the knowledge distillation technique in the training process. Experiments on the GLUE benchmark and SQuAD show that our proposed TernaryBERT outperforms the other BERT quantization methods, and even achieves comparable performance as the full-precision model while being 14.9x smaller.",,https://d3i71xaburhd42.cloudfront.net/097210dc65924f8ce59523faf444e635523dc714/1-Figure1-1.png
TESA: A Task in Entity Semantic Aggregation for Abstractive Summarization,"['Clément Jumel', 'Annie Louis', 'Jackie Chi Kit Cheung']",,,,
Text Segmentation by Cross Segment Attention,"['Michal Lukasik', 'Boris Dadachev', 'Kishore Papineni', 'Goncalo Simoes']",http://arxiv.org/abs/2004.14535v1,"Document and discourse segmentation are two fundamental NLP tasks pertaining to breaking up text into constituents, which are commonly used to help downstream tasks such as information retrieval or text summarization. In this work, we propose three transformer-based architectures and provide comprehensive comparisons with previously proposed approaches on three standard datasets. We establish a new state-of-the-art, reducing in particular the error rates by a large margin in all cases. We further analyze model sizes and find that we can build models with many fewer parameters while keeping good performance, thus facilitating real-world applications.",,https://d3i71xaburhd42.cloudfront.net/f6dcdfa0ec70d61c47e5dad29dfe96f67b5f680e/5-Table1-1.png
Textual Data Augmentation for Efficient Active Learning on Tiny Datasets,"['Husam Quteineh', 'Spyridon Samothrakis', 'Richard Sutcliffe']",,,,
"The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions","['Xiang Zhou', 'Yixin Nie', 'Hao Tan', 'Mohit Bansal']",http://arxiv.org/abs/2004.13606v1,"We find that the performance of state-of-the-art models on Natural Language Inference (NLI) and Reading Comprehension (RC) analysis/stress sets can be highly unstable. This raises three questions: (1) How will the instability affect the reliability of the conclusions drawn based on these analysis sets? (2) Where does this instability come from? (3) How should we handle this instability and what are some potential solutions? For the first question, we conduct a thorough empirical study over analysis sets and find that in addition to the unstable final performance, the instability exists all along the training curve. We also observe lower-than-expected correlations between the analysis validation set and standard validation set, questioning the effectiveness of the current model-selection routine. Next, to answer the second question, we give both theoretical explanations and empirical evidence regarding the source of the instability, demonstrating that the instability mainly comes from high inter-example correlations within analysis sets. Finally, for the third question, we discuss an initial attempt to mitigate the instability and suggest guidelines for future work such as reporting the decomposed variance for more interpretable results and fair comparison across models. Our code is publicly available at: https://github. com/owenzx/InstabilityAnalysis",,https://d3i71xaburhd42.cloudfront.net/930d2b331f127d7833ef1badbcaaea9ff4e2fffc/1-Figure1-1.png
The Grammar of Emergent Languages,"['Oskar van der Wal', 'Silvan de Boer', 'Elia Bruni', 'Dieuwke Hupkes']",http://arxiv.org/abs/2010.02069v2,"In this paper, we consider the syntactic properties of languages emerged in referential games, using unsupervised grammar induction (UGI) techniques originally designed to analyse natural language. We show that the considered UGI techniques are appropriate to analyse emergent languages and we then study if the languages that emerge in a typical referential game setup exhibit syntactic structure, and to what extent this depends on the maximum message length and number of symbols that the agents are allowed to use. Our experiments demonstrate that a certain message length and vocabulary size are required for structure to emerge, but they also illustrate that more sophisticated game scenarios are required to obtain syntactic properties more akin to those observed in human language. We argue that UGI techniques should be part of the standard toolkit for analysing emergent languages and release a comprehensive library to facilitate such analysis for future researchers.",,https://d3i71xaburhd42.cloudfront.net/2ab588d4f7e148b2893bcf3b2fa09383c4096482/3-Table1-1.png
The Secret is in the Spectra: Predicting Cross-lingual Task Performance with Spectral Similarity Measures,"['Haim Dubossarsky', 'Ivan Vulić', 'Roi Reichart', 'Anna Korhonen']",http://arxiv.org/abs/2001.11136v2,"Performance in cross-lingual NLP tasks is impacted by the (dis)similarity of languages at hand: e.g., previous work has suggested there is a connection between the expected success of bilingual lexicon induction (BLI) and the assumption of (approximate) isomorphism between monolingual embedding spaces. In this work we present a large-scale study focused on the correlations between monolingual embedding space similarity and task performance, covering thousands of language pairs and four different tasks: BLI, parsing, POS tagging and MT. We hypothesize that statistics of the spectrum of each monolingual embedding space indicate how well they can be aligned. We then introduce several isomorphism measures between two embedding spaces, based on the relevant statistics of their individual spectra. We empirically show that 1) language similarity scores derived from such spectral isomorphism measures are strongly associated with performance observed in different cross-lingual tasks, and 2) our spectral-based measures consistently outperform previous standard isomorphism measures, while being computationally more tractable and easier to interpret. Finally, our measures capture complementary information to typologically driven language distance measures, and the combination of measures from the two families yields even higher task performance correlations.",,
The World is not Binary: Learning to Rank with Grayscale Data for Dialogue Response Selection,"['Zibo Lin', 'Deng Cai', 'Yan Wang', 'Xiaojiang Liu', 'Haitao Zheng', 'Shuming Shi']",http://arxiv.org/abs/2004.02421v4,"Response selection plays a vital role in building retrieval-based conversation systems. Despite that response selection is naturally a learning-to-rank problem, most prior works take a point-wise view and train binary classifiers for this task: each response candidate is labeled either relevant (one) or irrelevant (zero). On the one hand, this formalization can be sub-optimal due to its ignorance of the diversity of response quality. On the other hand, annotating grayscale data for learning-to-rank can be prohibitively expensive and challenging. In this work, we show that grayscale data can be automatically constructed without human effort. Our method employs off-the-shelf response retrieval models and response generation models as automatic grayscale data generators. With the constructed grayscale data, we propose multi-level ranking objectives for training, which can (1) teach a matching model to capture more fine-grained context-response relevance difference and (2) reduce the train-test discrepancy in terms of distractor strength. Our method is simple, effective, and universal. Experiments on three benchmark datasets and four state-of-the-art matching models show that the proposed approach brings significant and consistent performance improvements.",,
To Schedule or not to Schedule: Extracting Task Specific Temporal Entities and Associated Negation Constraints,"['Barun Patra', 'Chala Fufa', 'Pamela Bhattacharya', 'Charles Lee']",,,,
TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue,"['Chien-Sheng Wu', 'Steven C.H. Hoi', 'Richard Socher', 'Caiming Xiong']",http://arxiv.org/abs/2004.06871v3,"The underlying difference of linguistic patterns between general text and task-oriented dialogue makes existing pre-trained language models less useful in practice. In this work, we unify nine human-human and multi-turn task-oriented dialogue datasets for language modeling. To better model dialogue behavior during pre-training, we incorporate user and system tokens into the masked language modeling. We propose a contrastive objective function to simulate the response selection task. Our pre-trained task-oriented dialogue BERT (TOD-BERT) outperforms strong baselines like BERT on four downstream task-oriented dialogue applications, including intention recognition, dialogue state tracking, dialogue act prediction, and response selection. We also show that TOD-BERT has a stronger few-shot ability that can mitigate the data scarcity problem for task-oriented dialogue.",,https://d3i71xaburhd42.cloudfront.net/b6dbae35c9c8cca8a21c22282b353a859e6a9235/3-Table1-1.png
Token-level Adaptive Training for Neural Machine Translation,"['Shuhao Gu', 'Jinchao Zhang', 'Fandong Meng', 'Yang Feng', 'Wanying Xie', 'Jie Zhou', 'Dong Yu']",http://arxiv.org/abs/2010.04380v1,"There exists a token imbalance phenomenon in natural language as different tokens appear with different frequencies, which leads to different learning difficulties for tokens in Neural Machine Translation (NMT). The vanilla NMT model usually adopts trivial equal-weighted objectives for target tokens with different frequencies and tends to generate more high-frequency tokens and less low-frequency tokens compared with the golden token distribution. However, low-frequency tokens may carry critical semantic information that will affect the translation quality once they are neglected. In this paper, we explored target token-level adaptive objectives based on token frequencies to assign appropriate weights for each target token during training. We aimed that those meaningful but relatively low-frequency words could be assigned with larger weights in objectives to encourage the model to pay more attention to these tokens. Our method yields consistent improvements in translation quality on ZH-EN, EN-RO, and EN-DE translation tasks, especially on sentences that contain more low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases compared with baseline, respectively. Further analyses show that our method can also improve the lexical diversity of translation.",,https://d3i71xaburhd42.cloudfront.net/1c0eb2dd9fd8289b3c6501f35c07fd21e94242de/1-Table1-1.png
Top-Rank-Focused Adaptive Vote Collection for the Evaluation of Domain-Specific Semantic Models,"['Pierangelo Lombardo', 'Alessio Boiardi', 'Luca Colombo', 'Angelo Schiavone', 'Nicolò Tamagnone']",http://arxiv.org/abs/2010.04486v1,"The growth of domain-specific applications of semantic models, boosted by the recent achievements of unsupervised embedding learning algorithms, demands domain-specific evaluation datasets. In many cases, content-based recommenders being a prime example, these models are required to rank words or texts according to their semantic relatedness to a given concept, with particular focus on top ranks. In this work, we give a threefold contribution to address these requirements: (i) we define a protocol for the construction, based on adaptive pairwise comparisons, of a relatedness-based evaluation dataset tailored on the available resources and optimized to be particularly accurate in top-rank evaluation; (ii) we define appropriate metrics, extensions of well-known ranking correlation coefficients, to evaluate a semantic model via the aforementioned dataset by taking into account the greater significance of top ranks. Finally, (iii) we define a stochastic transitivity model to simulate semantic-driven pairwise comparisons, which confirms the effectiveness of the proposed dataset construction protocol.",,https://d3i71xaburhd42.cloudfront.net/892d2e2c904dfd9a13c0a1e4c98f789a34bd2015/3-Figure1-1.png
TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions,"['Qiang Ning', 'Hao Wu', 'Rujun Han', 'Nanyun Peng', 'Matt Gardner', 'Dan Roth']",http://arxiv.org/abs/2005.00242v2,"A critical part of reading is being able to understand the temporal relationships between events described in a passage of text, even when those relationships are not explicitly stated. However, current machine reading comprehension benchmarks have practically no questions that test temporal phenomena, so systems trained on these benchmarks have no capacity to answer questions such as ""what happened before/after [some event]?"" We introduce TORQUE, a new English reading comprehension benchmark built on 3.2k news snippets with 21k human-generated questions querying temporal relationships. Results show that RoBERTa-large achieves an exact-match score of 51% on the test set of TORQUE, about 30% behind human performance.",,https://d3i71xaburhd42.cloudfront.net/36d6c8895bbc755964b8b2136c6fd6087a7af089/1-Figure1-1.png
ToTTo: A Controlled Table-To-Text Generation Dataset,"['Ankur Parikh', 'Xuezhi Wang', 'Sebastian Gehrmann', 'Manaal Faruqui', 'Bhuwan Dhingra', 'Diyi Yang', 'Dipanjan Das']",,,,
Towards Debiasing NLU Models from Unknown Biases,"['Prasetya Ajie Utama', 'Nafise Sadat Moosavi', 'Iryna Gurevych']",http://arxiv.org/abs/2009.12303v4,"NLU models often exploit biases to achieve high dataset-specific performance without properly learning the intended task. Recently proposed debiasing methods are shown to be effective in mitigating this tendency. However, these methods rely on a major assumption that the types of bias should be known a-priori, which limits their application to many NLU tasks and datasets. In this work, we present the first step to bridge this gap by introducing a self-debiasing framework that prevents models from mainly utilizing biases without knowing them in advance. The proposed framework is general and complementary to the existing debiasing methods. We show that it allows these existing methods to retain the improvement on the challenge datasets (i.e., sets of examples designed to expose models' reliance on biases) without specifically targeting certain biases. Furthermore, the evaluation suggests that applying the framework results in improved overall robustness.",,https://d3i71xaburhd42.cloudfront.net/930da59bb56d1b779d6d4ec42a6d91e436c62e71/2-Figure1-1.png
Towards Detecting and Exploiting Disambiguation Biases in Neural Machine Translation,"['Denis Emelin', 'Ivan Titov', 'Rico Sennrich']",,,,
Towards Enhancing Faithfulness for Neural Machine Translation,"['Rongxiang Weng', 'Heng Yu', 'Xiangpeng Wei', 'Weihua Luo']",,,,
Towards Interpretable Reasoning over Paragraph Effects in Situation,"['Mucheng Ren', 'Xiubo Geng', 'Tao QIN', 'Heyan Huang', 'Daxin Jiang']",http://arxiv.org/abs/2010.01272v1,"We focus on the task of reasoning over paragraph effects in situation, which requires a model to understand the cause and effect described in a background paragraph, and apply the knowledge to a novel situation. Existing works ignore the complicated reasoning process and solve it with a one-step ""black box"" model. Inspired by human cognitive processes, in this paper we propose a sequential approach for this task which explicitly models each step of the reasoning process with neural network modules. In particular, five reasoning modules are designed and learned in an end-to-end manner, which leads to a more interpretable model. Experimental results on the ROPES dataset demonstrate the effectiveness and explainability of our proposed approach.",,https://d3i71xaburhd42.cloudfront.net/c68093780a785f541125cc6ffb8edd47b0bf3f1f/3-Figure1-1.png
Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text,"['Dongfang Li', 'Baotian Hu', 'Qingcai Chen', 'Weihua Peng', 'Anqi Wang']",,,,
Towards More Accurate Uncertainty Estimation In Text Classification,"['Jianfeng He', 'Xuchao Zhang', 'Shuo Lei', 'Zhiqian Chen', 'Fanglan Chen', 'Abdulaziz Alhamadani', 'Bei Xiao', 'ChangTien Lu']",,,,
Towards Persona-Based Empathetic Conversational Models,"['Peixiang Zhong', 'Chen Zhang', 'Hao Wang', 'Yong Liu', 'Chunyan Miao']",http://arxiv.org/abs/2004.12316v6,"Empathetic conversational models have been shown to improve user satisfaction and task outcomes in numerous domains. In Psychology, persona has been shown to be highly correlated to personality, which in turn influences empathy. In addition, our empirical analysis also suggests that persona plays an important role in empathetic conversations. To this end, we propose a new task towards persona-based empathetic conversations and present the first empirical study on the impact of persona on empathetic responding. Specifically, we first present a novel large-scale multi-domain dataset for persona-based empathetic conversations. We then propose CoBERT, an efficient BERT-based response selection model that obtains the state-of-the-art performance on our dataset. Finally, we conduct extensive experiments to investigate the impact of persona on empathetic responding. Notably, our results show that persona improves empathetic responding more when CoBERT is trained on empathetic conversations than non-empathetic ones, establishing an empirical link between persona and empathy in human conversations.",,https://d3i71xaburhd42.cloudfront.net/7b73f7e59fe584a8760d86731fec503e2ae8b52c/1-Figure1-1.png
Training for Gibbs Sampling on Conditional Random Fields with Neural Scoring Factors,"['Sida Gao', 'Matthew R. Gormley']",,,,
Training Question Answering Models From Synthetic Data,"['Raul Puri', 'Ryan Spring', 'Mohammad Shoeybi', 'Mostofa Patwary', 'Bryan Catanzaro']",http://arxiv.org/abs/2002.09599v1,"Question and answer generation is a data augmentation method that aims to improve question answering (QA) models given the limited amount of human labeled data. However, a considerable gap remains between synthetic and human-generated question-answer pairs. This work aims to narrow this gap by taking advantage of large language models and explores several factors such as model size, quality of pretrained models, scale of data synthesized, and algorithmic choices. On the SQuAD1.1 question answering task, we achieve higher accuracy using solely synthetic questions and answers than when using the SQuAD1.1 training set questions alone. Removing access to real Wikipedia data, we synthesize questions and answers from a synthetic corpus generated by an 8.3 billion parameter GPT-2 model. With no access to human supervision and only access to other models, we are able to train state of the art question answering networks on entirely model-generated data that achieve 88.4 Exact Match (EM) and 93.9 F1 score on the SQuAD1.1 dev set. We further apply our methodology to SQuAD2.0 and show a 2.8 absolute gain on EM score compared to prior work using synthetic data.",,https://d3i71xaburhd42.cloudfront.net/bb9a6231611a8efd678f30334c294052e5062142/1-Table1-1.png
Transformer Based Multi-Source Domain Adaptation,"['Dustin Wright', 'Isabelle Augenstein']",http://arxiv.org/abs/2009.07806v1,"In practical machine learning settings, the data on which a model must make predictions often come from a different distribution than the data it was trained on. Here, we investigate the problem of unsupervised multi-source domain adaptation, where a model is trained on labelled data from multiple source domains and must make predictions on a domain for which no labelled data has been seen. Prior work with CNNs and RNNs has demonstrated the benefit of mixture of experts, where the predictions of multiple domain expert classifiers are combined; as well as domain adversarial training, to induce a domain agnostic representation space. Inspired by this, we investigate how such methods can be effectively applied to large pretrained transformer models. We find that domain adversarial training has an effect on the learned representations of these models while having little effect on their performance, suggesting that large transformer-based models are already relatively robust across domains. Additionally, we show that mixture of experts leads to significant performance improvements by comparing several variants of mixing functions, including one novel mixture based on attention. Finally, we demonstrate that the predictions of large pretrained transformer based domain experts are highly homogenous, making it challenging to learn effective functions for mixing their predictions.",,https://d3i71xaburhd42.cloudfront.net/e505303ba5287f468773fbef22ab1abf6875efca/1-Figure1-1.png
Translation Artifacts in Cross-lingual Transfer Learning,"['Mikel Artetxe', 'Gorka Labaka', 'Eneko Agirre']",http://arxiv.org/abs/2004.04721v3,"Both human and machine translation play a central role in cross-lingual transfer learning: many multilingual datasets have been created through professional translation services, and using machine translation to translate either the test set or the training set is a widely used transfer technique. In this paper, we show that such translation process can introduce subtle artifacts that have a notable impact in existing cross-lingual models. For instance, in natural language inference, translating the premise and the hypothesis independently can reduce the lexical overlap between them, which current models are highly sensitive to. We show that some previous findings in cross-lingual transfer learning need to be reconsidered in the light of this phenomenon. Based on the gained insights, we also improve the state-of-the-art in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points, respectively.",,https://d3i71xaburhd42.cloudfront.net/98ced81fa9c0c5e4f77f833a9fc64d0c5426f943/4-Table1-1.png
Translationese in Machine Translation Evaluation,"['Yvette Graham', 'Barry Haddow', 'Philipp Koehn']",http://arxiv.org/abs/1906.09833v1,"The term translationese has been used to describe the presence of unusual features of translated text. In this paper, we provide a detailed analysis of the adverse effects of translationese on machine translation evaluation results. Our analysis shows evidence to support differences in text originally written in a given language relative to translated text and this can potentially negatively impact the accuracy of machine translation evaluations. For this reason we recommend that reverse-created test data be omitted from future machine translation test sets. In addition, we provide a re-evaluation of a past high-profile machine translation evaluation claiming human-parity of MT, as well as analysis of the since re-evaluations of it. We find potential ways of improving the reliability of all three past evaluations. One important issue not previously considered is the statistical power of significance tests applied in past evaluations that aim to investigate human-parity of MT. Since the very aim of such evaluations is to reveal legitimate ties between human and MT systems, power analysis is of particular importance, where low power could result in claims of human parity that in fact simply correspond to Type II error. We therefore provide a detailed power analysis of tests used in such evaluations to provide an indication of a suitable minimum sample size of translations for such studies. Subsequently, since no past evaluation that aimed to investigate claims of human parity ticks all boxes in terms of accuracy and reliability, we rerun the evaluation of the systems claiming human parity. Finally, we provide a comprehensive check-list for future machine translation evaluation.",,https://d3i71xaburhd42.cloudfront.net/1a42817843b58e28025374b22b00cdc9e3eed1a2/2-Figure1-1.png
Two are Better Than One: Joint Entity and Relation Extraction with Table-Sequence Encoders,"['Jue WANG', 'Wei Lu']",http://arxiv.org/abs/2010.03851v1,"Named entity recognition and relation extraction are two important fundamental problems. Joint learning algorithms have been proposed to solve both tasks simultaneously, and many of them cast the joint task as a table-filling problem. However, they typically focused on learning a single encoder (usually learning representation in the form of a table) to capture information required for both tasks within the same space. We argue that it can be beneficial to design two distinct encoders to capture such two different types of information in the learning process. In this work, we propose the novel {\em table-sequence encoders} where two different encoders -- a table encoder and a sequence encoder are designed to help each other in the representation learning process. Our experiments confirm the advantages of having {\em two} encoders over {\em one} encoder. On several standard datasets, our model shows significant improvements over existing approaches.",,
Type B Reflexivization as an Unambiguous Testbed for Multilingual Multi-Task Gender Bias,"['Ana Valeria González', 'Maria Barrett', 'Rasmus Hvingelby', 'Kellie Webster', 'Anders Søgaard']",http://arxiv.org/abs/2009.11982v2,"The one-sided focus on English in previous studies of gender bias in NLP misses out on opportunities in other languages: English challenge datasets such as GAP and WinoGender highlight model preferences that are ""hallucinatory"", e.g., disambiguating gender-ambiguous occurrences of 'doctor' as male doctors. We show that for languages with type B reflexivization, e.g., Swedish and Russian, we can construct multi-task challenge datasets for detecting gender bias that lead to unambiguously wrong model predictions: In these languages, the direct translation of 'the doctor removed his mask' is not ambiguous between a coreferential reading and a disjoint reading. Instead, the coreferential reading requires a non-gendered pronoun, and the gendered, possessive pronouns are anti-reflexive. We present a multilingual, multi-task challenge dataset, which spans four languages and four NLP tasks and focuses only on this phenomenon. We find evidence for gender bias across all task-language combinations and correlate model bias with national labor market statistics.",,https://d3i71xaburhd42.cloudfront.net/3cf1da52ee85335972533e56f9a5c1383ebbf2a3/1-Table1-1.png
UDapter: Language Adaptation for Truly Universal Dependency Parsing,"['Ahmet Üstün', 'Arianna Bisazza', 'Gosse Bouma', 'Gertjan van Noord']",http://arxiv.org/abs/2004.14327v2,"Recent advances in multilingual dependency parsing have brought the idea of a truly universal parser closer to reality. However, cross-language interference and restrained model capacity remain major obstacles. To address this, we propose a novel multilingual task adaptation approach based on contextual parameter generation and adapter modules. This approach enables to learn adapters via language embeddings while sharing model parameters across languages. It also allows for an easy but effective integration of existing linguistic typology features into the parsing network. The resulting parser, UDapter, outperforms strong monolingual and multilingual baselines on the majority of both high-resource and low-resource (zero-shot) languages, showing the success of the proposed adaptation approach. Our in-depth analyses show that soft parameter sharing via typological features is key to this success.",,https://d3i71xaburhd42.cloudfront.net/3b233bdb697cc43effa1eb6d2868ff14efbbab7a/4-Figure1-1.png
Uncertainty-Aware Label Refinement for Sequence Labeling,"['Tao Gui', 'Jiacheng Ye', 'Qi Zhang', 'Zhengyan Li', 'Zichu Fei', 'Yeyun Gong', 'Xuanjing Huang']",,,,
Uncertainty-Aware Semantic Augmentation for Neural Machine Translation,"['Xiangpeng Wei', 'Heng Yu', 'Yue Hu', 'Rongxiang Weng', 'Luxi Xing', 'Weihua Luo']",http://arxiv.org/abs/2010.04411v1,"As a sequence-to-sequence generation task, neural machine translation (NMT) naturally contains intrinsic uncertainty, where a single sentence in one language has multiple valid counterparts in the other. However, the dominant methods for NMT only observe one of them from the parallel corpora for the model training but have to deal with adequate variations under the same meaning at inference. This leads to a discrepancy of the data distribution between the training and the inference phases. To address this problem, we propose uncertainty-aware semantic augmentation, which explicitly captures the universal semantic information among multiple semantically-equivalent source sentences and enhances the hidden representations with this information for better translations. Extensive experiments on various translation tasks reveal that our approach significantly outperforms the strong baselines and the existing methods.",,https://d3i71xaburhd42.cloudfront.net/e38c81a7659df65b63ea55560ade4a29d8608c4f/3-Figure1-1.png
Understanding Procedural Text using Interactive Entity Networks,"['Jizhi Tang', 'Yansong Feng', 'Dongyan Zhao']",,,,
Understanding the Difficulty of Training Transformers,"['Liyuan Liu', 'Xiaodong Liu', 'Jianfeng Gao', 'Weizhu Chen', 'Jiawei Han']",http://arxiv.org/abs/2004.08249v2,"Transformers have proved effective in many NLP tasks. However, their training requires non-trivial efforts regarding designing cutting-edge optimizers and learning rate schedulers carefully (e.g., conventional SGD fails to train Transformers effectively). Our objective here is to understand $\textit{what complicates Transformer training}$ from both empirical and theoretical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that influences training substantially -- for each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable, since it amplifies small parameter perturbations (e.g., parameter updates) and results in significant disturbances in the model output. Yet we observe that a light dependency limits the model potential and leads to inferior trained models. Inspired by our analysis, we propose Admin ($\textbf{Ad}$aptive $\textbf{m}$odel $\textbf{in}$itialization) to stabilize stabilize the early stage's training and unleash its full potential in the late stage. Extensive experiments show that Admin is more stable, converges faster, and leads to better performance. Implementations are released at: https://github.com/LiyuanLucasLiu/Transforemr-Clinic.",,https://d3i71xaburhd42.cloudfront.net/85d04daa9366a5cd42de4182eb3428003e4710a2/1-Figure1-1.png
Understanding the Mechanics of SPIGOT: Surrogate Gradients for Latent Structure Learning,"['Tsvetomila Mihaylova', 'Vlad Niculae', 'André F. T. Martins']",http://arxiv.org/abs/2010.02357v1,"Latent structure models are a powerful tool for modeling language data: they can mitigate the error propagation and annotation bottleneck in pipeline systems, while simultaneously uncovering linguistic insights about the data. One challenge with end-to-end training of these models is the argmax operation, which has null gradient. In this paper, we focus on surrogate gradients, a popular strategy to deal with this problem. We explore latent structure learning through the angle of pulling back the downstream learning objective. In this paradigm, we discover a principled motivation for both the straight-through estimator (STE) as well as the recently-proposed SPIGOT - a variant of STE for structured models. Our perspective leads to new algorithms in the same family. We empirically compare the known and the novel pulled-back estimators against the popular alternatives, yielding new insight for practitioners and revealing intriguing failure cases.",,https://d3i71xaburhd42.cloudfront.net/8a8e7c02ffbf54083692827b7d700e35f15f5f68/2-Figure1-1.png
UniConv: A Unified Conversational Neural Architecture for Multi-domain Task-oriented Dialogues,"['Hung Le', 'Doyen Sahoo', 'Chenghao Liu', 'Nancy Chen', 'Steven C.H. Hoi']",http://arxiv.org/abs/2004.14307v1,"Building an end-to-end conversational agent for multi-domain task-oriented dialogue has been an open challenge for two main reasons. First, tracking dialogue states of multiple domains is non-trivial as the dialogue agent must obtain complete states from all relevant domains, some of which might have shared slots among domains as well as unique slots specifically for one domain only. Second, the dialogue agent must also process various types of information across domains, including dialogue context, dialogue states, and database, to generate natural responses to users. Unlike the existing approaches that are often designed to train each module separately, we propose ""UniConv"" -- a novel unified neural architecture for end-to-end conversational systems in multi-domain task-oriented dialogues, which is designed to jointly train (i) a Bi-level State Tracker which tracks dialogue states by learning signals at both slot and domain level independently, and (ii) a Joint Dialogue Act and Response Generator which incorporates information from various input components and models dialogue acts and target responses simultaneously. We conduct comprehensive experiments in dialogue state tracking, context-to-text, and end-to-end settings on the MultiWOZ2.1 benchmark, achieving superior performance over competitive baselines in all tasks. Our code and models will be released.",,https://d3i71xaburhd42.cloudfront.net/b48526b18a7bb0dac5151dd5428e12eeea6ff6a2/2-Table1-1.png
Unified Feature and Instance Based Domain adaptation for End-to-End Aspect-based Sentiment Analysis,"['Chenggong Gong', 'Jianfei Yu', 'Rui Xia']",,,,
UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation,"['Jian Guan', 'Minlie Huang']",http://arxiv.org/abs/2009.07602v1,"Despite the success of existing referenced metrics (e.g., BLEU and MoverScore), they correlate poorly with human judgments for open-ended text generation including story or dialog generation because of the notorious one-to-many issue: there are many plausible outputs for the same input, which may differ substantially in literal or semantics from the limited number of given references. To alleviate this issue, we propose UNION, a learnable unreferenced metric for evaluating open-ended story generation, which measures the quality of a generated story without any reference. Built on top of BERT, UNION is trained to distinguish human-written stories from negative samples and recover the perturbation in negative stories. We propose an approach of constructing negative samples by mimicking the errors commonly observed in existing NLG models, including repeated plots, conflicting logic, and long-range incoherence. Experiments on two story datasets demonstrate that UNION is a reliable measure for evaluating the quality of generated stories, which correlates better with human judgments and is more generalizable than existing state-of-the-art metrics.",,https://d3i71xaburhd42.cloudfront.net/70aa38ddb852ff33fcf990792ca0690047464f99/3-Figure1-1.png
Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start,"['Wenpeng Yin', 'Nazneen Fatema Rajani', 'Dragomir Radev', 'Richard Socher', 'Caiming Xiong']",http://arxiv.org/abs/2010.02584v1,"A standard way to address different NLP problems is by first constructing a problem-specific dataset, then building a model to fit this dataset. To build the ultimate artificial intelligence, we desire a single machine that can handle diverse new problems, for which task-specific annotations are limited. We bring up textual entailment as a unified solver for such NLP problems. However, current research of textual entailment has not spilled much ink on the following questions: (i) How well does a pretrained textual entailment system generalize across domains with only a handful of domain-specific examples? and (ii) When is it worth transforming an NLP task into textual entailment? We argue that the transforming is unnecessary if we can obtain rich annotations for this task. Textual entailment really matters particularly when the target NLP task has insufficient annotations. Universal NLP can be probably achieved through different routines. In this work, we introduce Universal Few-shot textual Entailment (UFO-Entail). We demonstrate that this framework enables a pretrained entailment model to work well on new entailment domains in a few-shot setting, and show its effectiveness as a unified solver for several downstream NLP tasks such as question answering and coreference resolution when the end-task annotations are limited. Code: https://github.com/salesforce/UniversalFewShotNLP",,https://d3i71xaburhd42.cloudfront.net/e2d38543bd3cf813c63df336b21b003156ed48a8/3-Figure1-1.png
Unsupervised Adaptation of Question Answering Systems via Generative Self-training,"['Steven Rennie', 'Etienne Marcheret', 'Neil Mallinar', 'David Nahamoo', 'Vaibhava Goel']",,,,
Unsupervised Commonsense Question Answering with Self-Talk,"['Vered Shwartz', 'Peter West', 'Ronan Le Bras', 'Chandra Bhagavatula', 'Yejin Choi']",http://arxiv.org/abs/2004.05483v2,"Natural language understanding involves reading between the lines with implicit background knowledge. Current systems either rely on pre-trained language models as the sole implicit source of world knowledge, or resort to external knowledge bases (KBs) to incorporate additional relevant knowledge. We propose an unsupervised framework based on self-talk as a novel alternative to multiple-choice commonsense tasks. Inspired by inquiry-based discovery learning (Bruner, 1961), our approach inquires language models with a number of information seeking questions such as ""$\textit{what is the definition of ...}$"" to discover additional background knowledge. Empirical results demonstrate that the self-talk procedure substantially improves the performance of zero-shot language model baselines on four out of six commonsense benchmarks, and competes with models that obtain knowledge from external KBs. While our approach improves performance on several benchmarks, the self-talk induced knowledge even when leading to correct answers is not always seen as useful by human judges, raising interesting questions about the inner-workings of pre-trained language models for commonsense reasoning.",,https://d3i71xaburhd42.cloudfront.net/9808d59113029d96f48a0376b1578dbab5427bb4/1-Figure1-1.png
Unsupervised Cross-Lingual Part-of-Speech Tagging for Truly Low-Resource Scenarios,"['Ramy Eskander', 'Smaranda Muresan', 'Michael Collins']",,,,
Unsupervised Discovery of Implicit Gender Bias,"['Anjalie Field', 'Yulia Tsvetkov']",http://arxiv.org/abs/2004.08361v2,"Despite their prevalence in society, social biases are difficult to identify, primarily because human judgements in this domain can be unreliable. We take an unsupervised approach to identifying gender bias against women at a comment level and present a model that can surface text likely to contain bias. Our main challenge is forcing the model to focus on signs of implicit bias, rather than other artifacts in the data. Thus, our methodology involves reducing the influence of confounds through propensity matching and adversarial learning. Our analysis shows how biased comments directed towards female politicians contain mixed criticisms, while comments directed towards other female public figures focus on appearance and sexualization. Ultimately, our work offers a way to capture subtle biases in various domains without relying on subjective human judgements.",,https://d3i71xaburhd42.cloudfront.net/6676b814818f6d10f3e501cb80f3181817cc2a05/2-Figure1-1.png
Unsupervised Natural Language Inference via Decoupled Multimodal Contrastive Learning,"['Wanyun Cui', 'Guangyu Zheng', 'Wei Wang']",http://arxiv.org/abs/2010.08200v1,"We propose to solve the natural language inference problem without any supervision from the inference labels via task-agnostic multimodal pretraining. Although recent studies of multimodal self-supervised learning also represent the linguistic and visual context, their encoders for different modalities are coupled. Thus they cannot incorporate visual information when encoding plain text alone. In this paper, we propose Multimodal Aligned Contrastive Decoupled learning (MACD) network. MACD forces the decoupled text encoder to represent the visual information via contrastive learning. Therefore, it embeds visual knowledge even for plain text inference. We conducted comprehensive experiments over plain text inference datasets (i.e. SNLI and STS-B). The unsupervised MACD even outperforms the fully-supervised BiLSTM and BiLSTM+ELMO on STS-B.",,https://d3i71xaburhd42.cloudfront.net/dcc03cce582910458ea6ed58745952b020cf3893/2-Figure1-1.png
Unsupervised Parsing via Constituency Tests,"['Steven Cao', 'Nikita Kitaev', 'Dan Klein']",http://arxiv.org/abs/2010.03146v1,"We propose a method for unsupervised parsing based on the linguistic notion of a constituency test. One type of constituency test involves modifying the sentence via some transformation (e.g. replacing the span with a pronoun) and then judging the result (e.g. checking if it is grammatical). Motivated by this idea, we design an unsupervised parser by specifying a set of transformations and using an unsupervised neural acceptability model to make grammaticality decisions. To produce a tree given a sentence, we score each span by aggregating its constituency test judgments, and we choose the binary tree with the highest total score. While this approach already achieves performance in the range of current methods, we further improve accuracy by fine-tuning the grammaticality model through a refinement procedure, where we alternate between improving the estimated trees and improving the grammaticality model. The refined model achieves 62.8 F1 on the Penn Treebank test set, an absolute improvement of 7.6 points over the previous best published result.",,https://d3i71xaburhd42.cloudfront.net/84ff4418686ccac01f752cb95cf34dea601424e6/3-Table1-1.png
Unsupervised Parsing with S-DIORA: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders,"['Andrew Drozdov', 'Subendhu Rongali', 'Yi-Pei Chen', ""Tim O'Gorman"", 'Mohit Iyyer', 'Andrew McCallum']",,,,
Unsupervised Question Decomposition for Question Answering,"['Ethan Perez', 'Patrick Lewis', 'Wen-tau Yih', 'Kyunghyun Cho', 'Douwe Kiela']",http://arxiv.org/abs/2002.09758v3,"We aim to improve question answering (QA) by decomposing hard questions into simpler sub-questions that existing QA systems are capable of answering. Since labeling questions with decompositions is cumbersome, we take an unsupervised approach to produce sub-questions, also enabling us to leverage millions of questions from the internet. Specifically, we propose an algorithm for One-to-N Unsupervised Sequence transduction (ONUS) that learns to map one hard, multi-hop question to many simpler, single-hop sub-questions. We answer sub-questions with an off-the-shelf QA model and give the resulting answers to a recomposition model that combines them into a final answer. We show large QA improvements on HotpotQA over a strong baseline on the original, out-of-domain, and multi-hop dev sets. ONUS automatically learns to decompose different kinds of questions, while matching the utility of supervised and heuristic decomposition methods for QA and exceeding those methods in fluency. Qualitatively, we find that using sub-questions is promising for shedding light on why a QA system makes a prediction.",,https://d3i71xaburhd42.cloudfront.net/a0d9cb1f91382ec763f7aba0609cf9a6324e0b68/1-Figure1-1.png
Unsupervised Reference-Free Summary Quality Evaluation via Contrastive Learning,"['Hanlu Wu', 'Tengfei Ma', 'Lingfei Wu', 'Tariro Manyumwa', 'Shouling Ji']",http://arxiv.org/abs/2010.01781v1,"Evaluation of a document summarization system has been a critical factor to impact the success of the summarization task. Previous approaches, such as ROUGE, mainly consider the informativeness of the assessed summary and require human-generated references for each test summary. In this work, we propose to evaluate the summary qualities without reference summaries by unsupervised contrastive learning. Specifically, we design a new metric which covers both linguistic qualities and semantic informativeness based on BERT. To learn the metric, for each summary, we construct different types of negative samples with respect to different aspects of the summary qualities, and train our model with a ranking loss. Experiments on Newsroom and CNN/Daily Mail demonstrate that our new evaluation method outperforms other metrics even without reference summaries. Furthermore, we show that our method is general and transferable across datasets.",,https://d3i71xaburhd42.cloudfront.net/1c930f42baf6fcfbc087ea0d983b783ea7b37f73/2-Table1-1.png
Unsupervised Stance Detection for Arguments from Consequences,"['Jonathan Kobbe', 'Ioana Hulpuș', 'Heiner Stuckenschmidt']",,,,
Variational Hierarchical Dialog Autoencoder for Dialog State Tracking Data Augmentation,"['Kang Min Yoo', 'Hanbit Lee', 'Franck Dernoncourt', 'Trung Bui', 'Walter Chang', 'Sang-goo Lee']",http://arxiv.org/abs/2001.08604v3,"Recent works have shown that generative data augmentation, where synthetic samples generated from deep generative models complement the training dataset, benefit NLP tasks. In this work, we extend this approach to the task of dialog state tracking for goal-oriented dialogs. Due to the inherent hierarchical structure of goal-oriented dialogs over utterances and related annotations, the deep generative model must be capable of capturing the coherence among different hierarchies and types of dialog features. We propose the Variational Hierarchical Dialog Autoencoder (VHDA) for modeling the complete aspects of goal-oriented dialogs, including linguistic features and underlying structured annotations, namely speaker information, dialog acts, and goals. The proposed architecture is designed to model each aspect of goal-oriented dialogs using inter-connected latent variables and learns to generate coherent goal-oriented dialogs from the latent spaces. To overcome training issues that arise from training complex variational models, we propose appropriate training strategies. Experiments on various dialog datasets show that our model improves the downstream dialog trackers' robustness via generative data augmentation. We also discover additional benefits of our unified approach to modeling goal-oriented dialogs: dialog response generation and user simulation, where our model outperforms previous strong baselines.",,https://d3i71xaburhd42.cloudfront.net/95e7d6fc58e56f9224e66177070d36c4cc1c8883/3-Figure1-1.png
VCDM: Leveraging Variational Bi-encoding and Deep Contextualized Word Representations for Improved Definition Modeling,"['Machel Reid', 'Edison Marrese-Taylor', 'Yutaka Matsuo']",http://arxiv.org/abs/2010.03124v1,"In this paper, we tackle the task of definition modeling, where the goal is to learn to generate definitions of words and phrases. Existing approaches for this task are discriminative, combining distributional and lexical semantics in an implicit rather than direct way. To tackle this issue we propose a generative model for the task, introducing a continuous latent variable to explicitly model the underlying relationship between a phrase used within a context and its definition. We rely on variational inference for estimation and leverage contextualized word embeddings for improved performance. Our approach is evaluated on four existing challenging benchmarks with the addition of two new datasets, ""Cambridge"" and the first non-English corpus ""Robert"", which we release to complement our empirical study. Our Variational Contextual Definition Modeler (VCDM) achieves state-of-the-art performance in terms of automatic and human evaluation metrics, demonstrating the effectiveness of our approach.",,https://d3i71xaburhd42.cloudfront.net/08b2d12699b25f0536cdc48dc823e4afd1264a07/11-Table1-1.png
VD-BERT: A Unified Vision and Dialog Transformer with BERT,"['Yue Wang', 'Shafiq Joty', 'Michael Lyu', 'Irwin King', 'Caiming Xiong', 'Steven C.H. Hoi']",http://arxiv.org/abs/2004.13278v2,"Visual dialog is a challenging vision-language task, where a dialog agent needs to answer a series of questions through reasoning on the image content and dialog history. Prior work has mostly focused on various attention mechanisms to model such intricate interactions. By contrast, in this work, we propose VD-BERT, a simple yet effective framework of unified vision-dialog Transformer that leverages the pretrained BERT language models for Visual Dialog tasks. The model is unified in that (1) it captures all the interactions between the image and the multi-turn dialog using a single-stream Transformer encoder, and (2) it supports both answer ranking and answer generation seamlessly through the same architecture. More crucially, we adapt BERT for the effective fusion of vision and dialog contents via visually grounded training. Without the need of pretraining on external vision-language data, our model yields new state of the art, achieving the top position in both single-model and ensemble settings (74.54 and 75.35 NDCG scores) on the visual dialog leaderboard.",,https://d3i71xaburhd42.cloudfront.net/ec6071541ae7e08bc94bec8df22bf3db7ec66e79/1-Figure1-1.png
Vector-Vector-Matrix Architecture: A Novel Hardware-Aware Framework for Low-Latency Inference in NLP Applications,"['Matthew Khoury', 'Rumen Dangovski', 'Longwu Ou', 'Preslav Nakov', 'Yichen Shen', 'Li Jing']",http://arxiv.org/abs/2010.08412v1,"Deep neural networks have become the standard approach to building reliable Natural Language Processing (NLP) applications, ranging from Neural Machine Translation (NMT) to dialogue systems. However, improving accuracy by increasing the model size requires a large number of hardware computations, which can slow down NLP applications significantly at inference time. To address this issue, we propose a novel vector-vector-matrix architecture (VVMA), which greatly reduces the latency at inference time for NMT. This architecture takes advantage of specialized hardware that has low-latency vector-vector operations and higher-latency vector-matrix operations. It also reduces the number of parameters and FLOPs for virtually all models that rely on efficient matrix multipliers without significantly impacting accuracy. We present empirical results suggesting that our framework can reduce the latency of sequence-to-sequence and Transformer models used for NMT by a factor of four. Finally, we show evidence suggesting that our VVMA extends to other domains, and we discuss novel hardware for its efficient use.",,https://d3i71xaburhd42.cloudfront.net/a4c1fedaefad0fb6fb971d4434b6a186f839b8f9/1-Figure1-1.png
Video2Commonsense: Generating Commonsense Descriptions to Enrich Video Captioning,"['Zhiyuan Fang', 'Tejas Gokhale', 'Pratyay Banerjee', 'Chitta Baral', 'Yezhou Yang']",http://arxiv.org/abs/2003.05162v3,"Captioning is a crucial and challenging task for video understanding. In videos that involve active agents such as humans, the agent's actions can bring about myriad changes in the scene. Observable changes such as movements, manipulations, and transformations of the objects in the scene, are reflected in conventional video captioning. Unlike images, actions in videos are also inherently linked to social aspects such as intentions (why the action is taking place), effects (what changes due to the action), and attributes that describe the agent. Thus for video understanding, such as when captioning videos or when answering questions about videos, one must have an understanding of these commonsense aspects. We present the first work on generating commonsense captions directly from videos, to describe latent aspects such as intentions, effects, and attributes. We present a new dataset ""Video-to-Commonsense (V2C)"" that contains $\sim9k$ videos of human agents performing various actions, annotated with 3 types of commonsense descriptions. Additionally we explore the use of open-ended video-based commonsense question answering (V2C-QA) as a way to enrich our captions. Both the generation task and the QA task can be used to enrich video captions.",,
Visually Grounded Compound PCFGs,"['Yanpeng Zhao', 'Ivan Titov']",http://arxiv.org/abs/2009.12404v1,"Exploiting visual groundings for language understanding has recently been drawing much attention. In this work, we study visually grounded grammar induction and learn a constituency parser from both unlabeled text and its visual groundings. Existing work on this task (Shi et al., 2019) optimizes a parser via Reinforce and derives the learning signal only from the alignment of images and sentences. While their model is relatively accurate overall, its error distribution is very uneven, with low performance on certain constituents types (e.g., 26.2% recall on verb phrases, VPs) and high on others (e.g., 79.6% recall on noun phrases, NPs). This is not surprising as the learning signal is likely insufficient for deriving all aspects of phrase-structure syntax and gradient estimates are noisy. We show that using an extension of probabilistic context-free grammar model we can do fully-differentiable end-to-end visually grounded learning. Additionally, this enables us to complement the image-text alignment loss with a language modeling objective. On the MSCOCO test captions, our model establishes a new state of the art, outperforming its non-grounded version and, thus, confirming the effectiveness of visual groundings in constituency grammar induction. It also substantially outperforms the previous grounded model, with largest improvements on more `abstract' categories (e.g., +55.1% recall on VPs).",,https://d3i71xaburhd42.cloudfront.net/c1e5c4d8c52e17ece0bbb4e8b564e8b903a20e39/7-Table1-1.png
Visually Grounded Continual Learning of Compositional Phrases,"['Xisen Jin', 'Junyi Du', 'Arka Sadhu', 'Ram Nevatia', 'Xiang Ren']",http://arxiv.org/abs/2005.00785v4,"Humans acquire language continually with much more limited access to data samples at a time, as compared to contemporary NLP systems. To study this human-like language acquisition ability, we present VisCOLL, a visually grounded language learning task, which simulates the continual acquisition of compositional phrases from streaming visual scenes. In the task, models are trained on a paired image-caption stream which has shifting object distribution; while being constantly evaluated by a visually-grounded masked language prediction task on held-out test sets. VisCOLL compounds the challenges of continual learning (i.e., learning from continuously shifting data distribution) and compositional generalization (i.e., generalizing to novel compositions). To facilitate research on VisCOLL, we construct two datasets, COCO-shift and Flickr-shift, and benchmark them using different continual learning methods. Results reveal that SoTA continual learning approaches provide little to no improvements on VisCOLL, since storing examples of all possible compositions is infeasible. We conduct further ablations and analysis to guide future work.",,
VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles,"['Mingzhe Li', 'Xiuying Chen', 'Shen Gao', 'Zhangming Chan', 'Dongyan Zhao', 'Rui Yan']",http://arxiv.org/abs/2010.05406v1,"A popular multimedia news format nowadays is providing users with a lively video and a corresponding news article, which is employed by influential news media including CNN, BBC, and social media including Twitter and Weibo. In such a case, automatically choosing a proper cover frame of the video and generating an appropriate textual summary of the article can help editors save time, and readers make the decision more effectively. Hence, in this paper, we propose the task of Video-based Multimodal Summarization with Multimodal Output (VMSMO) to tackle such a problem. The main challenge in this task is to jointly model the temporal dependency of video with semantic meaning of article. To this end, we propose a Dual-Interaction-based Multimodal Summarizer (DIMS), consisting of a dual interaction module and multimodal generator. In the dual interaction module, we propose a conditional self-attention mechanism that captures local semantic information within video and a global-attention mechanism that handles the semantic relationship between news text and video from a high level. Extensive experiments conducted on a large-scale real-world VMSMO dataset show that DIMS achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations.",,https://d3i71xaburhd42.cloudfront.net/3ed35a45f0d912afe37b915a30e2b254b946e10d/1-Figure1-1.png
"Vokenization: Improving Language Understanding via Contextualized, Visually-Grounded Supervision","['Hao Tan', 'Mohit Bansal']",http://arxiv.org/abs/2010.06775v1,"Humans learn language by listening, speaking, writing, reading, and also, via interaction with the multimodal real world. Existing language pre-training frameworks show the effectiveness of text-only self-supervision while we explore the idea of a visually-supervised language model in this paper. We find that the main reason hindering this exploration is the large divergence in magnitude and distributions between the visually-grounded language datasets and pure-language corpora. Therefore, we develop a technique named ""vokenization"" that extrapolates multimodal alignments to language-only data by contextually mapping language tokens to their related images (which we call ""vokens""). The ""vokenizer"" is trained on relatively small image captioning datasets and we then apply it to generate vokens for large language corpora. Trained with these contextually generated vokens, our visually-supervised language models show consistent improvements over self-supervised alternatives on multiple pure-language tasks such as GLUE, SQuAD, and SWAG. Code and pre-trained models publicly available at https://github.com/airsplay/vokenization",,https://d3i71xaburhd42.cloudfront.net/dedcdc1fb3a6def9772dce674d89150923dd75b9/1-Figure1-1.png
VolTAGE: Volatility forecasting via Text-Audio fusion with Graph convolution networks for Earnings calls,"['Ramit Sawhney', 'Piyush Khanna', 'Arshiya Aggarwal', 'Taru Jain', 'Puneet Mathur', 'Rajiv Ratn Shah']",,,,
Wasserstein Distance Regularized Sequence Representation for Text Matching in Asymmetrical Domains,"['Weijie Yu', 'Chen Xu', 'Jun Xu', 'Liang Pang', 'Xiaopeng Gao', 'Xiaozhao Wang', 'Ji-Rong Wen']",http://arxiv.org/abs/2010.07717v2,"One approach to matching texts from asymmetrical domains is projecting the input sequences into a common semantic space as feature vectors upon which the matching function can be readily defined and learned. In real-world matching practices, it is often observed that with the training goes on, the feature vectors projected from different domains tend to be indistinguishable. The phenomenon, however, is often overlooked in existing matching models. As a result, the feature vectors are constructed without any regularization, which inevitably increases the difficulty of learning the downstream matching functions. In this paper, we propose a novel match method tailored for text matching in asymmetrical domains, called WD-Match. In WD-Match, a Wasserstein distance-based regularizer is defined to regularize the features vectors projected from different domains. As a result, the method enforces the feature projection function to generate vectors such that those correspond to different domains cannot be easily discriminated. The training process of WD-Match amounts to a game that minimizes the matching loss regularized by the Wasserstein distance. WD-Match can be used to improve different text matching methods, by using the method as its underlying matching model. Four popular text matching methods have been exploited in the paper. Experimental results based on four publicly available benchmarks showed that WD-Match consistently outperformed the underlying methods and the baselines.",,https://d3i71xaburhd42.cloudfront.net/819aff442c5391235a3bb44b1133f37b50541601/2-Figure1-1.png
We Can Detect Your Bias: Predicting the Political Ideology of News Articles,"['Ramy Baly', 'Giovanni Da San Martino', 'James Glass', 'Preslav Nakov']",http://arxiv.org/abs/2010.05338v1,"We explore the task of predicting the leading political ideology or bias of news articles. First, we collect and release a large dataset of 34,737 articles that were manually annotated for political ideology -left, center, or right-, which is well-balanced across both topics and media. We further use a challenging experimental setup where the test examples come from media that were not seen during training, which prevents the model from learning to detect the source of the target news article instead of predicting its political ideology. From a modeling perspective, we propose an adversarial media adaptation, as well as a specially adapted triplet loss. We further add background information about the source, and we show that it is quite helpful for improving article-level prediction. Our experimental results show very sizable improvements over using state-of-the-art pre-trained Transformers in this challenging setup.",,
Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in News Media,"['Shamik Roy', 'Dan Goldwasser']",http://arxiv.org/abs/2009.09609v1,"In this paper we suggest a minimally-supervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.",,
Weakly Supervised Subevent Knowledge Acquisition,"['Wenlin Yao', 'Zeyu Dai', 'Maitreyi Ramaswamy', 'Bonan Min', 'Ruihong Huang']",,,,
Weakly-Supervised Text Classification Using Label Names Only,"['Yu Meng', 'Yunyi Zhang', 'Jiaxin Huang', 'Chenyan Xiong', 'Heng Ji', 'Chao Zhang', 'Jiawei Han']",,,,
What Can We Learn from Collective Human Opinions on Natural Language Inference Data?,"['Yixin Nie', 'Xiang Zhou', 'Mohit Bansal']",http://arxiv.org/abs/2010.03532v2,"Despite the subjective nature of many NLP tasks, most NLU evaluations have focused on using the majority label with presumably high agreement as the ground truth. Less attention has been paid to the distribution of human opinions. We collect ChaosNLI, a dataset with a total of 464,500 annotations to study Collective HumAn OpinionS in oft-used NLI evaluation sets. This dataset is created by collecting 100 annotations per example for 3,113 examples in SNLI and MNLI and 1,532 examples in Abductive-NLI. Analysis reveals that: (1) high human disagreement exists in a noticeable amount of examples in these datasets; (2) the state-of-the-art models lack the ability to recover the distribution over human labels; (3) models achieve near-perfect accuracy on the subset of data with a high level of human agreement, whereas they can barely beat a random guess on the data with low levels of human agreement, which compose most of the common errors made by state-of-the-art models on the evaluation sets. This questions the validity of improving model performance on old metrics for the low-agreement part of evaluation datasets. Hence, we argue for a detailed examination of human agreement in future data collection efforts, and evaluating model outputs against the distribution over collective human opinions. The ChaosNLI dataset and experimental scripts are available at https://github.com/easonnie/ChaosNLI",,
What do Models Learn from Question Answering Datasets?,"['Priyanka Sen', 'Amir Saffari']",http://arxiv.org/abs/2004.03490v2,"While models have reached superhuman performance on popular question answering (QA) datasets such as SQuAD, they have yet to outperform humans on the task of question answering itself. In this paper, we investigate if models are learning reading comprehension from QA datasets by evaluating BERT-based models across five datasets. We evaluate models on their generalizability to out-of-domain examples, responses to missing or incorrect data, and ability to handle question variations. We find that no single dataset is robust to all of our experiments and identify shortcomings in both datasets and evaluation methods. Following our analysis, we make recommendations for building future QA datasets that better evaluate the task of question answering through reading comprehension. We also release code to convert QA datasets to a shared format for easier experimentation at https://github.com/amazon-research/qa-dataset-converter.",,
What Do Position Embeddings Learn? An Empirical Study of Pre-Trained Language Model Positional Encoding,"['Yu-An Wang', 'Yun-Nung Chen']",http://arxiv.org/abs/2010.04903v1,"In recent years, pre-trained Transformers have dominated the majority of NLP benchmark tasks. Many variants of pre-trained Transformers have kept breaking out, and most focus on designing different pre-training objectives or variants of self-attention. Embedding the position information in the self-attention mechanism is also an indispensable factor in Transformers however is often discussed at will. Therefore, this paper carries out an empirical study on position embeddings of mainstream pre-trained Transformers, which mainly focuses on two questions: 1) Do position embeddings really learn the meaning of positions? 2) How do these different learned position embeddings affect Transformers for NLP tasks? This paper focuses on providing a new insight of pre-trained position embeddings through feature-level analysis and empirical experiments on most of iconic NLP tasks. It is believed that our experimental results can guide the future work to choose the suitable positional encoding function for specific tasks given the application property.",,
What Do You Mean by That? - A Parser-Independent Interactive Approach for Enhancing Text-to-SQL,"['Yuntao Li', 'Bei Chen', 'Qian Liu', 'Yan Gao', 'Jian-Guang LOU', 'Yan Zhang', 'Dongmei Zhang']",,,,
What Have We Achieved on Text Summarization?,"['Dandan Huang', 'Leyang Cui', 'Sen Yang', 'Guangsheng Bao', 'Wang Kun', 'Jun Xie', 'Yue Zhang']",http://arxiv.org/abs/2010.04529v1,"Deep learning has led to significant improvement in text summarization with various methods investigated and improved ROUGE scores reported over the years. However, gaps still exist between summaries produced by automatic summarizers and human professionals. Aiming to gain more understanding of summarization systems with respect to their strengths and limits on a fine-grained syntactic and semantic level, we consult the Multidimensional Quality Metric(MQM) and quantify 8 major sources of errors on 10 representative summarization models manually. Primarily, we find that 1) under similar settings, extractive summarizers are in general better than their abstractive counterparts thanks to strength in faithfulness and factual-consistency; 2) milestone techniques such as copy, coverage and hybrid extractive/abstractive methods do bring specific improvements but also demonstrate limitations; 3) pre-training techniques, and in particular sequence-to-sequence pre-training, are highly effective for improving text summarization, with BART giving the best results.",,
What is More Likely to Happen Next? Video-and-Language Future Event Prediction,"['Jie Lei', 'Licheng Yu', 'Tamara Berg', 'Mohit Bansal']",http://arxiv.org/abs/2010.07999v1,"Given a video with aligned dialogue, people can often infer what is more likely to happen next. Making such predictions requires not only a deep understanding of the rich dynamics underlying the video and dialogue, but also a significant amount of commonsense knowledge. In this work, we explore whether AI models are able to learn to make such multimodal commonsense next-event predictions. To support research in this direction, we collect a new dataset, named Video-and-Language Event Prediction (VLEP), with 28,726 future event prediction examples (along with their rationales) from 10,234 diverse TV Show and YouTube Lifestyle Vlog video clips. In order to promote the collection of non-trivial challenging examples, we employ an adversarial human-and-model-in-the-loop data collection procedure. We also present a strong baseline incorporating information from video, dialogue, and commonsense knowledge. Experiments show that each type of information is useful for this challenging task, and that compared to the high human performance on VLEP, our model provides a good starting point but leaves large room for future work. Our dataset and code are available at: https://github.com/jayleicn/VideoLanguageFuturePred",,
What time is it? Temporal Analysis of Novels,"['Allen Kim', 'Charuta Pethe', 'Steve Skiena']",,,,
"When BERT Plays the Lottery, All Tickets Are Winning","['Sai Prasanna', 'Anna Rogers', 'Anna Rumshisky']",http://arxiv.org/abs/2005.00561v1,"Much of the recent success in NLP is due to the large Transformer-based models such as BERT (Devlin et al, 2019). However, these models have been shown to be reducible to a smaller number of self-attention heads and layers. We consider this phenomenon from the perspective of the lottery ticket hypothesis. For fine-tuned BERT, we show that (a) it is possible to find a subnetwork of elements that achieves performance comparable with that of the full model, and (b) similarly-sized subnetworks sampled from the rest of the model perform worse. However, the ""bad"" subnetworks can be fine-tuned separately to achieve only slightly worse performance than the ""good"" ones, indicating that most weights in the pre-trained BERT are potentially useful. We also show that the ""good"" subnetworks vary considerably across GLUE tasks, opening up the possibilities to learn what knowledge BERT actually uses at inference time.",,
When Hearst Is not Enough: Improving Hypernymy Detection from Corpus with Distributional Models,"['Changlong Yu', 'Jialong Han', 'Peifeng Wang', 'Yangqiu Song', 'Hongming Zhang', 'Wilfred Ng', 'Shuming Shi']",http://arxiv.org/abs/2010.04941v1,"We address hypernymy detection, i.e., whether an is-a relationship exists between words (x, y), with the help of large textual corpora. Most conventional approaches to this task have been categorized to be either pattern-based or distributional. Recent studies suggest that pattern-based ones are superior, if large-scale Hearst pairs are extracted and fed, with the sparsity of unseen (x, y) pairs relieved. However, they become invalid in some specific sparsity cases, where x or y is not involved in any pattern. For the first time, this paper quantifies the non-negligible existence of those specific cases. We also demonstrate that distributional methods are ideal to make up for pattern-based ones in such cases. We devise a complementary framework, under which a pattern-based and a distributional model collaborate seamlessly in cases which they each prefer. On several benchmark datasets, our framework achieves competitive improvements and the case study shows its better interpretability.",,https://d3i71xaburhd42.cloudfront.net/2c10d429767f11b085f8f887d480573e753659b5/1-Figure1-1.png
Where are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News,"['Nguyen Vo', 'Kyumin Lee']",http://arxiv.org/abs/2010.03159v1,"Although many fact-checking systems have been developed in academia and industry, fake news is still proliferating on social media. These systems mostly focus on fact-checking but usually neglect online users who are the main drivers of the spread of misinformation. How can we use fact-checked information to improve users' consciousness of fake news to which they are exposed? How can we stop users from spreading fake news? To tackle these questions, we propose a novel framework to search for fact-checking articles, which address the content of an original tweet (that may contain misinformation) posted by online users. The search can directly warn fake news posters and online users (e.g. the posters' followers) about misinformation, discourage them from spreading fake news, and scale up verified content on social media. Our framework uses both text and images to search for fact-checking articles, and achieves promising results on real-world datasets. Our code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.",,
Where Are You? Localization from Embodied Dialog,"['Meera Hahn', 'Jacob Krantz', 'Dhruv Batra', 'Devi Parikh', 'James Rehg', 'Stefan Lee', 'Peter Anderson']",,,,
Which *BERT? A Survey Organizing Contextualized Encoders,"['Patrick Xia', 'Shijie Wu', 'Benjamin Van Durme']",,,,
Widget Captioning: Generating Natural Language Description for Mobile User Interface Elements,"['Yang Li', 'Gang Li', 'Luheng He', 'Jingjie Zheng', 'Hong Li', 'Zhiwei Guan']",http://arxiv.org/abs/2010.04295v1,"Natural language descriptions of user interface (UI) elements such as alternative text are crucial for accessibility and language-based interaction in general. Yet, these descriptions are constantly missing in mobile UIs. We propose widget captioning, a novel task for automatically generating language descriptions for UI elements from multimodal input including both the image and the structural representations of user interfaces. We collected a large-scale dataset for widget captioning with crowdsourcing. Our dataset contains 162,859 language phrases created by human workers for annotating 61,285 UI elements across 21,750 unique UI screens. We thoroughly analyze the dataset, and train and evaluate a set of deep model configurations to investigate how each feature modality as well as the choice of learning strategies impact the quality of predicted captions. The task formulation and the dataset as well as our benchmark models contribute a solid basis for this novel multimodal captioning task that connects language and user interfaces.",,
Will I Sound Like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness,"['Hyunwoo Kim', 'Byeongchang Kim', 'Gunhee Kim']",http://arxiv.org/abs/2004.05816v2,"We explore the task of improving persona consistency of dialogue agents. Recent models tackling consistency often train with additional Natural Language Inference (NLI) labels or attach trained extra modules to the generative agent for maintaining consistency. However, such additional labels and training can be demanding. Also, we find even the best-performing persona-based agents are insensitive to contradictory words. Inspired by social cognition and pragmatics, we endow existing dialogue agents with public self-consciousness on the fly through an imaginary listener. Our approach, based on the Rational Speech Acts framework (Frank and Goodman, 2012), can enforce dialogue agents to refrain from uttering contradiction. We further extend the framework by learning the distractor selection, which has been usually done manually or randomly. Results on Dialogue NLI (Welleck et al., 2019) and PersonaChat (Zhang et al., 2018) dataset show that our approach reduces contradiction and improves consistency of existing dialogue models. Moreover, we show that it can be generalized to improve context-consistency beyond persona in dialogues.",,
With Little Power Comes Great Responsibility,"['Dallas Card', 'Peter Henderson', 'Urvashi Khandelwal', 'Robin Jia', 'Kyle Mahowald', 'Dan Jurafsky']",http://arxiv.org/abs/2010.06595v1,"Despite its importance to experimental design, statistical power (the probability that, given a real effect, an experiment will reject the null hypothesis) has largely been ignored by the NLP community. Underpowered experiments make it more difficult to discern the difference between statistical noise and meaningful model improvements, and increase the chances of exaggerated findings. By meta-analyzing a set of existing NLP papers and datasets, we characterize typical power for a variety of settings and conclude that underpowered experiments are common in the NLP literature. In particular, for several tasks in the popular GLUE benchmark, small test sets mean that most attempted comparisons to state of the art models will not be adequately powered. Similarly, based on reasonable assumptions, we find that the most typical experimental design for human rating studies will be underpowered to detect small model differences, of the sort that are frequently studied. For machine translation, we find that typical test sets of 2000 sentences have approximately 75% power to detect differences of 1 BLEU point. To improve the situation going forward, we give an overview of best practices for power analysis in NLP and release a series of notebooks to assist with future power analyses.",,
With More Contexts Comes Better Performance: Contextualized Sense Embeddings for All-Round Word Sense Disambiguation,"['Bianca Scarlini', 'Tommaso Pasini', 'Roberto Navigli']",,,,
Word class flexibility: A deep contextualized approach,"['Bai Li', 'Guillaume Thomas', 'Yang Xu', 'Frank Rudzicz']",http://arxiv.org/abs/2009.09241v1,"Word class flexibility refers to the phenomenon whereby a single word form is used across different grammatical categories. Extensive work in linguistic typology has sought to characterize word class flexibility across languages, but quantifying this phenomenon accurately and at scale has been fraught with difficulties. We propose a principled methodology to explore regularity in word class flexibility. Our method builds on recent work in contextualized word embeddings to quantify semantic shift between word classes (e.g., noun-to-verb, verb-to-noun), and we apply this method to 37 languages. We find that contextualized embeddings not only capture human judgment of class variation within words in English, but also uncover shared tendencies in class flexibility across languages. Specifically, we find greater semantic variation when flexible lemmas are used in their dominant word class, supporting the view that word class flexibility is a directional process. Our work highlights the utility of deep contextualized models in linguistic typology.",,
Word Rotator's Distance,"['Sho Yokoi', 'Ryo Takahashi', 'Reina Akama', 'Jun Suzuki', 'Kentaro Inui']",http://arxiv.org/abs/2004.15003v2,"One key principle for assessing textual similarity is measuring the degree of semantic overlap between two texts by considering the word alignment. Such alignment-based approaches are both intuitive and interpretable; however, they are empirically inferior to the simple cosine similarity between general-purpose sentence vectors. To remedy this, we focus on the fact that the norm of word vectors is a good proxy for word importance, and the angle of them is a good proxy for word similarity. Alignment-based approaches do not distinguish the norm and direction, whereas sentence-vector approaches automatically use the norm as the word importance. Accordingly, we propose to decouple word vectors into their norm and direction then computing the alignment-based similarity using earth mover's distance (optimal transport cost), which we refer to as word rotator's distance. Furthermore, we demonstrate how to grow the norm and direction of word vectors (vector converter); this is a new systematic approach derived from the sentence-vector estimation methods, which can significantly improve the performance of the proposed method. On several STS benchmarks, our simple proposed methods outperformed not only alignment-based approaches but also strong baselines.",,
Writing Strategies for Science Communication: Data and Computational Analysis,"['Tal August', 'Lauren Kim', 'Katharina Reinecke', 'Noah A. Smith']",,,,
X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models,"['Zhengbao Jiang', 'Antonios Anastasopoulos', 'Jun Araki', 'Haibo Ding', 'Graham Neubig']",http://arxiv.org/abs/2010.06189v2,"Language models (LMs) have proven surprisingly successful at capturing factual knowledge by completing cloze-style fill-in-the-blank questions such as ""Punta Cana is located in _."" However, while knowledge is both written and queried in many languages, studies on LMs' factual representation ability have almost invariably been performed on English. To assess factual knowledge retrieval in LMs in different languages, we create a multilingual benchmark of cloze-style probes for \langnum typologically diverse languages. To properly handle language variations, we expand probing methods from single- to multi-word entities, and develop several decoding algorithms to generate multi-token predictions. Extensive experimental results provide insights about how well (or poorly) current state-of-the-art LMs perform at this task in languages with more or fewer available resources. We further propose a code-switching-based method to improve the ability of multilingual LMs to access knowledge, and verify its effectiveness on several benchmark languages. Benchmark data and code have been released at https://x-factr.github.io.",,
"X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers","['Jaemin Cho', 'jiasen lu', 'Dustin Schwenk', 'Hannaneh Hajishirzi', 'Aniruddha Kembhavi']",http://arxiv.org/abs/2009.11278v1,"Mirroring the success of masked language models, vision-and-language counterparts like ViLBERT, LXMERT and UNITER have achieved state of the art performance on a variety of multimodal discriminative tasks like visual question answering and visual grounding. Recent work has also successfully adapted such models towards the generative task of image captioning. This begs the question: Can these models go the other way and generate images from pieces of text? Our analysis of a popular representative from this model family - LXMERT - finds that it is unable to generate rich and semantically meaningful imagery with its current training setup. We introduce X-LXMERT, an extension to LXMERT with training refinements including: discretizing visual representations, using uniform masking with a large range of masking ratios and aligning the right pre-training datasets to the right objectives which enables it to paint. X-LXMERT's image generation capabilities rival state of the art generative models while its question answering and captioning abilities remains comparable to LXMERT. Finally, we demonstrate the generality of these training refinements by adding image generation capabilities into UNITER to produce X-UNITER.",,
X-SRL: A Parallel Cross-Lingual Semantic Role Labeling Dataset,"['Angel Daza', 'Anette Frank']",,,,
XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning,"['Edoardo Maria Ponti', 'Goran Glavaš', 'Olga Majewska', 'Qianchu Liu', 'Ivan Vulić', 'Anna Korhonen']",http://arxiv.org/abs/2005.00333v1,"In order to simulate human language capacity, natural language processing systems must complement the explicit information derived from raw text with the ability to reason about the possible causes and outcomes of everyday situations. Moreover, the acquired world knowledge should generalise to new languages, modulo cultural differences. Advances in machine commonsense reasoning and cross-lingual transfer depend on the availability of challenging evaluation benchmarks. Motivated by both demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a typologically diverse multilingual dataset for causal commonsense reasoning in 11 languages. We benchmark a range of state-of-the-art models on this novel dataset, revealing that current methods based on multilingual pretraining and zero-shot fine-tuning transfer suffer from the curse of multilinguality and fall short of performance in monolingual settings by a large margin. Finally, we propose ways to adapt these models to out-of-sample resource-lean languages where only a small corpus or a bilingual dictionary is available, and report substantial improvements over the random baseline. XCOPA is available at github.com/cambridgeltl/xcopa.",,
"XGLUE: A New Benchmark Datasetfor Cross-lingual Pre-training, Understanding and Generation","['Yaobo Liang', 'Nan Duan', 'Yeyun Gong', 'Ning Wu', 'Fenfei Guo', 'Weizhen Qi', 'Ming Gong', 'Linjun Shou', 'Daxin Jiang', 'Guihong Cao', 'Xiaodong Fan', 'Ruofei Zhang', 'Rahul Agrawal', 'Edward Cui', 'Sining Wei', 'Taroon Bharti', 'Ying Qiao', 'Jiun-Hung Chen', 'Winnie Wu', 'Shuguang Liu', 'Fan Yang', 'Daniel Campos', 'Rangan Majumder', 'Ming Zhou']",http://arxiv.org/abs/2004.01401v3,"In this paper, we introduce XGLUE, a new benchmark dataset that can be used to train large-scale cross-lingual pre-trained models using multilingual and bilingual corpora and evaluate their performance across a diverse set of cross-lingual tasks. Comparing to GLUE(Wang et al., 2019), which is labeled in English for natural language understanding tasks only, XGLUE has two main advantages: (1) it provides 11 diversified tasks that cover both natural language understanding and generation scenarios; (2) for each task, it provides labeled data in multiple languages. We extend a recent cross-lingual pre-trained model Unicoder(Huang et al., 2019) to cover both understanding and generation tasks, which is evaluated on XGLUE as a strong baseline. We also evaluate the base versions (12-layer) of Multilingual BERT, XLM and XLM-R for comparison.",,
XL-WiC: A Multilingual Benchmark for Evaluating Semantic Contextualization,"['Alessandro Raganato', 'Tommaso Pasini', 'Jose Camacho-Collados', 'Mohammad Taher Pilehvar']",http://arxiv.org/abs/2010.06478v1,"The ability to correctly model distinct meanings of a word is crucial for the effectiveness of semantic representation techniques. However, most existing evaluation benchmarks for assessing this criterion are tied to sense inventories (usually WordNet), restricting their usage to a small subset of knowledge-based representation techniques. The Word-in-Context dataset (WiC) addresses the dependence on sense inventories by reformulating the standard disambiguation task as a binary classification problem; but, it is limited to the English language. We put forward a large multilingual benchmark, XL-WiC, featuring gold standards in 12 new languages from varied language families and with different degrees of resource availability, opening room for evaluation scenarios such as zero-shot cross-lingual transfer. We perform a series of experiments to determine the reliability of the datasets and to set performance baselines for several recent contextualized multilingual models. Experimental results show that even when no tagged instances are available for a target language, models trained solely on the English data can attain competitive performance in the task of distinguishing different meanings of a word, even for distant languages. XL-WiC is available at https://pilehvar.github.io/xlwic/.",,
XXXXX: A Neural Framework for MT Evaluation,"['Ricardo Rei', 'Craig Stewart', 'Ana C Farinha', 'Alon Lavie']",,,,
Zero-Shot Cross-Lingual Transfer with Meta Learning,"['Farhad Nooralahzadeh', 'Giannis Bekoulis', 'Johannes Bjerva', 'Isabelle Augenstein']",http://arxiv.org/abs/2003.02739v4,"Learning what to share between tasks has been a topic of great importance recently, as strategic sharing of knowledge has been shown to improve downstream task performance. This is particularly important for multilingual applications, as most languages in the world are under-resourced. Here, we consider the setting of training models on multiple different languages at the same time, when little or no data is available for languages other than English. We show that this challenging setup can be approached using meta-learning, where, in addition to training a source language model, another model learns to select which training instances are the most beneficial to the first. We experiment using standard supervised, zero-shot cross-lingual, as well as few-shot cross-lingual settings for different natural language understanding tasks (natural language inference, question answering). Our extensive experimental setup demonstrates the consistent effectiveness of meta-learning for a total of 15 languages. We improve upon the state-of-the-art for zero-shot and few-shot NLI (on MultiNLI and XNLI) and QA (on the MLQA dataset). A comprehensive error analysis indicates that the correlation of typological features between languages can partly explain when parameter sharing learned via meta-learning is beneficial.",,
Zero-Shot Crosslingual Sentence Simplification,"['Jonathan Mallinson', 'Rico Sennrich', 'Mirella Lapata']",,,,
